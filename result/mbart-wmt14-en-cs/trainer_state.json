{
  "best_global_step": 25500,
  "best_metric": 21.857035357064195,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 50,
  "global_step": 44703,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0006711184188450052,
      "grad_norm": 2.3757450580596924,
      "learning_rate": 1.3412816691505219e-06,
      "loss": 2.9346,
      "step": 10
    },
    {
      "epoch": 0.0013422368376900104,
      "grad_norm": 2.313237428665161,
      "learning_rate": 2.8315946348733235e-06,
      "loss": 2.9223,
      "step": 20
    },
    {
      "epoch": 0.0020133552565350155,
      "grad_norm": 2.186739444732666,
      "learning_rate": 4.321907600596125e-06,
      "loss": 2.9106,
      "step": 30
    },
    {
      "epoch": 0.0026844736753800207,
      "grad_norm": 2.220937728881836,
      "learning_rate": 5.812220566318928e-06,
      "loss": 2.841,
      "step": 40
    },
    {
      "epoch": 0.003355592094225026,
      "grad_norm": 2.0375354290008545,
      "learning_rate": 7.302533532041729e-06,
      "loss": 2.8877,
      "step": 50
    },
    {
      "epoch": 0.003355592094225026,
      "eval_bleu": 2.1335696184715798,
      "eval_gen_len": 31.427,
      "eval_loss": 3.22851300239563,
      "eval_runtime": 64.1264,
      "eval_samples_per_second": 15.594,
      "eval_steps_per_second": 0.982,
      "step": 50
    },
    {
      "epoch": 0.004026710513070031,
      "grad_norm": 2.000795841217041,
      "learning_rate": 8.792846497764531e-06,
      "loss": 2.8628,
      "step": 60
    },
    {
      "epoch": 0.004697828931915037,
      "grad_norm": 2.1590442657470703,
      "learning_rate": 1.0283159463487333e-05,
      "loss": 2.8365,
      "step": 70
    },
    {
      "epoch": 0.0053689473507600415,
      "grad_norm": 1.9916753768920898,
      "learning_rate": 1.1773472429210134e-05,
      "loss": 2.8394,
      "step": 80
    },
    {
      "epoch": 0.006040065769605047,
      "grad_norm": 1.6367740631103516,
      "learning_rate": 1.3263785394932937e-05,
      "loss": 2.7987,
      "step": 90
    },
    {
      "epoch": 0.006711184188450052,
      "grad_norm": 1.0283416509628296,
      "learning_rate": 1.4754098360655739e-05,
      "loss": 2.8708,
      "step": 100
    },
    {
      "epoch": 0.006711184188450052,
      "eval_bleu": 13.177955265910455,
      "eval_gen_len": 28.676,
      "eval_loss": 3.067736864089966,
      "eval_runtime": 58.0801,
      "eval_samples_per_second": 17.218,
      "eval_steps_per_second": 1.085,
      "step": 100
    },
    {
      "epoch": 0.007382302607295057,
      "grad_norm": 1.0047439336776733,
      "learning_rate": 1.624441132637854e-05,
      "loss": 2.8195,
      "step": 110
    },
    {
      "epoch": 0.008053421026140062,
      "grad_norm": 0.9417328834533691,
      "learning_rate": 1.7734724292101342e-05,
      "loss": 2.767,
      "step": 120
    },
    {
      "epoch": 0.008724539444985068,
      "grad_norm": 0.9575021862983704,
      "learning_rate": 1.9225037257824145e-05,
      "loss": 2.7941,
      "step": 130
    },
    {
      "epoch": 0.009395657863830073,
      "grad_norm": 0.8757460117340088,
      "learning_rate": 2.0715350223546945e-05,
      "loss": 2.7405,
      "step": 140
    },
    {
      "epoch": 0.010066776282675077,
      "grad_norm": 0.8321242928504944,
      "learning_rate": 2.2205663189269748e-05,
      "loss": 2.7672,
      "step": 150
    },
    {
      "epoch": 0.010066776282675077,
      "eval_bleu": 20.750870771702495,
      "eval_gen_len": 28.654,
      "eval_loss": 3.037199020385742,
      "eval_runtime": 58.2417,
      "eval_samples_per_second": 17.17,
      "eval_steps_per_second": 1.082,
      "step": 150
    },
    {
      "epoch": 0.010737894701520083,
      "grad_norm": 0.7707125544548035,
      "learning_rate": 2.369597615499255e-05,
      "loss": 2.7318,
      "step": 160
    },
    {
      "epoch": 0.011409013120365089,
      "grad_norm": 0.8705901503562927,
      "learning_rate": 2.518628912071535e-05,
      "loss": 2.7682,
      "step": 170
    },
    {
      "epoch": 0.012080131539210094,
      "grad_norm": 0.9174737930297852,
      "learning_rate": 2.667660208643815e-05,
      "loss": 2.7845,
      "step": 180
    },
    {
      "epoch": 0.012751249958055098,
      "grad_norm": 0.9190022349357605,
      "learning_rate": 2.8166915052160954e-05,
      "loss": 2.7232,
      "step": 190
    },
    {
      "epoch": 0.013422368376900104,
      "grad_norm": 0.7769641280174255,
      "learning_rate": 2.965722801788376e-05,
      "loss": 2.7411,
      "step": 200
    },
    {
      "epoch": 0.013422368376900104,
      "eval_bleu": 20.851656555492884,
      "eval_gen_len": 28.822,
      "eval_loss": 3.0276975631713867,
      "eval_runtime": 58.5718,
      "eval_samples_per_second": 17.073,
      "eval_steps_per_second": 1.076,
      "step": 200
    },
    {
      "epoch": 0.01409348679574511,
      "grad_norm": 0.814629316329956,
      "learning_rate": 3.114754098360656e-05,
      "loss": 2.7383,
      "step": 210
    },
    {
      "epoch": 0.014764605214590115,
      "grad_norm": 0.87481290102005,
      "learning_rate": 3.263785394932936e-05,
      "loss": 2.7339,
      "step": 220
    },
    {
      "epoch": 0.01543572363343512,
      "grad_norm": 0.8693840503692627,
      "learning_rate": 3.412816691505216e-05,
      "loss": 2.7501,
      "step": 230
    },
    {
      "epoch": 0.016106842052280124,
      "grad_norm": 0.9024845957756042,
      "learning_rate": 3.5618479880774966e-05,
      "loss": 2.7696,
      "step": 240
    },
    {
      "epoch": 0.01677796047112513,
      "grad_norm": 0.8752681612968445,
      "learning_rate": 3.710879284649776e-05,
      "loss": 2.7674,
      "step": 250
    },
    {
      "epoch": 0.01677796047112513,
      "eval_bleu": 20.749020246331874,
      "eval_gen_len": 28.845,
      "eval_loss": 3.019930839538574,
      "eval_runtime": 58.8635,
      "eval_samples_per_second": 16.988,
      "eval_steps_per_second": 1.07,
      "step": 250
    },
    {
      "epoch": 0.017449078889970136,
      "grad_norm": 0.9122612476348877,
      "learning_rate": 3.859910581222057e-05,
      "loss": 2.6986,
      "step": 260
    },
    {
      "epoch": 0.01812019730881514,
      "grad_norm": 0.8483641743659973,
      "learning_rate": 4.008941877794337e-05,
      "loss": 2.7498,
      "step": 270
    },
    {
      "epoch": 0.018791315727660147,
      "grad_norm": 0.8390552401542664,
      "learning_rate": 4.157973174366617e-05,
      "loss": 2.697,
      "step": 280
    },
    {
      "epoch": 0.019462434146505152,
      "grad_norm": 0.799140989780426,
      "learning_rate": 4.3070044709388975e-05,
      "loss": 2.6963,
      "step": 290
    },
    {
      "epoch": 0.020133552565350155,
      "grad_norm": 0.933955192565918,
      "learning_rate": 4.456035767511177e-05,
      "loss": 2.6949,
      "step": 300
    },
    {
      "epoch": 0.020133552565350155,
      "eval_bleu": 20.573560222690624,
      "eval_gen_len": 28.748,
      "eval_loss": 3.0192623138427734,
      "eval_runtime": 58.3571,
      "eval_samples_per_second": 17.136,
      "eval_steps_per_second": 1.08,
      "step": 300
    },
    {
      "epoch": 0.02080467098419516,
      "grad_norm": 0.8741021156311035,
      "learning_rate": 4.6050670640834574e-05,
      "loss": 2.7419,
      "step": 310
    },
    {
      "epoch": 0.021475789403040166,
      "grad_norm": 0.9245598316192627,
      "learning_rate": 4.754098360655738e-05,
      "loss": 2.7913,
      "step": 320
    },
    {
      "epoch": 0.02214690782188517,
      "grad_norm": 0.9072372913360596,
      "learning_rate": 4.903129657228018e-05,
      "loss": 2.714,
      "step": 330
    },
    {
      "epoch": 0.022818026240730177,
      "grad_norm": 0.8193541169166565,
      "learning_rate": 5.052160953800298e-05,
      "loss": 2.7244,
      "step": 340
    },
    {
      "epoch": 0.023489144659575183,
      "grad_norm": 0.7812542915344238,
      "learning_rate": 5.201192250372579e-05,
      "loss": 2.7221,
      "step": 350
    },
    {
      "epoch": 0.023489144659575183,
      "eval_bleu": 20.658251041227654,
      "eval_gen_len": 28.752,
      "eval_loss": 3.0196022987365723,
      "eval_runtime": 58.968,
      "eval_samples_per_second": 16.958,
      "eval_steps_per_second": 1.068,
      "step": 350
    },
    {
      "epoch": 0.02416026307842019,
      "grad_norm": 0.7876976728439331,
      "learning_rate": 5.350223546944859e-05,
      "loss": 2.6722,
      "step": 360
    },
    {
      "epoch": 0.024831381497265194,
      "grad_norm": 0.7957009077072144,
      "learning_rate": 5.4992548435171386e-05,
      "loss": 2.7047,
      "step": 370
    },
    {
      "epoch": 0.025502499916110196,
      "grad_norm": 0.9316913485527039,
      "learning_rate": 5.6482861400894196e-05,
      "loss": 2.6593,
      "step": 380
    },
    {
      "epoch": 0.0261736183349552,
      "grad_norm": 0.860569953918457,
      "learning_rate": 5.7973174366616986e-05,
      "loss": 2.6967,
      "step": 390
    },
    {
      "epoch": 0.026844736753800207,
      "grad_norm": 0.8974018096923828,
      "learning_rate": 5.9463487332339796e-05,
      "loss": 2.7207,
      "step": 400
    },
    {
      "epoch": 0.026844736753800207,
      "eval_bleu": 20.289559341660688,
      "eval_gen_len": 28.565,
      "eval_loss": 3.020678758621216,
      "eval_runtime": 58.2588,
      "eval_samples_per_second": 17.165,
      "eval_steps_per_second": 1.081,
      "step": 400
    },
    {
      "epoch": 0.027515855172645213,
      "grad_norm": 0.9507898688316345,
      "learning_rate": 6.095380029806259e-05,
      "loss": 2.7945,
      "step": 410
    },
    {
      "epoch": 0.02818697359149022,
      "grad_norm": 0.9410880208015442,
      "learning_rate": 6.24441132637854e-05,
      "loss": 2.6854,
      "step": 420
    },
    {
      "epoch": 0.028858092010335224,
      "grad_norm": 0.8554876446723938,
      "learning_rate": 6.39344262295082e-05,
      "loss": 2.7269,
      "step": 430
    },
    {
      "epoch": 0.02952921042918023,
      "grad_norm": 0.945984423160553,
      "learning_rate": 6.5424739195231e-05,
      "loss": 2.694,
      "step": 440
    },
    {
      "epoch": 0.030200328848025235,
      "grad_norm": 0.898169994354248,
      "learning_rate": 6.691505216095381e-05,
      "loss": 2.7223,
      "step": 450
    },
    {
      "epoch": 0.030200328848025235,
      "eval_bleu": 20.826589694374587,
      "eval_gen_len": 28.716,
      "eval_loss": 3.0077412128448486,
      "eval_runtime": 58.3443,
      "eval_samples_per_second": 17.14,
      "eval_steps_per_second": 1.08,
      "step": 450
    },
    {
      "epoch": 0.03087144726687024,
      "grad_norm": 0.8088089227676392,
      "learning_rate": 6.840536512667661e-05,
      "loss": 2.6736,
      "step": 460
    },
    {
      "epoch": 0.03154256568571524,
      "grad_norm": 0.8531967997550964,
      "learning_rate": 6.98956780923994e-05,
      "loss": 2.7286,
      "step": 470
    },
    {
      "epoch": 0.03221368410456025,
      "grad_norm": 0.8122155070304871,
      "learning_rate": 7.13859910581222e-05,
      "loss": 2.6961,
      "step": 480
    },
    {
      "epoch": 0.032884802523405254,
      "grad_norm": 0.8487108945846558,
      "learning_rate": 7.287630402384501e-05,
      "loss": 2.7166,
      "step": 490
    },
    {
      "epoch": 0.03355592094225026,
      "grad_norm": 0.9363486170768738,
      "learning_rate": 7.436661698956782e-05,
      "loss": 2.7572,
      "step": 500
    },
    {
      "epoch": 0.03355592094225026,
      "eval_bleu": 20.373885102488977,
      "eval_gen_len": 28.639,
      "eval_loss": 3.013827323913574,
      "eval_runtime": 58.1102,
      "eval_samples_per_second": 17.209,
      "eval_steps_per_second": 1.084,
      "step": 500
    },
    {
      "epoch": 0.034227039361095266,
      "grad_norm": 1.0677491426467896,
      "learning_rate": 7.585692995529062e-05,
      "loss": 2.8182,
      "step": 510
    },
    {
      "epoch": 0.03489815777994027,
      "grad_norm": 0.890253484249115,
      "learning_rate": 7.734724292101341e-05,
      "loss": 2.7339,
      "step": 520
    },
    {
      "epoch": 0.03556927619878528,
      "grad_norm": 0.9160050749778748,
      "learning_rate": 7.883755588673621e-05,
      "loss": 2.7796,
      "step": 530
    },
    {
      "epoch": 0.03624039461763028,
      "grad_norm": 0.8302462697029114,
      "learning_rate": 8.032786885245902e-05,
      "loss": 2.7011,
      "step": 540
    },
    {
      "epoch": 0.03691151303647529,
      "grad_norm": 0.9066144824028015,
      "learning_rate": 8.181818181818183e-05,
      "loss": 2.7693,
      "step": 550
    },
    {
      "epoch": 0.03691151303647529,
      "eval_bleu": 20.52058061093925,
      "eval_gen_len": 28.571,
      "eval_loss": 3.014765501022339,
      "eval_runtime": 58.7373,
      "eval_samples_per_second": 17.025,
      "eval_steps_per_second": 1.073,
      "step": 550
    },
    {
      "epoch": 0.037582631455320294,
      "grad_norm": 0.9279568791389465,
      "learning_rate": 8.330849478390463e-05,
      "loss": 2.6561,
      "step": 560
    },
    {
      "epoch": 0.0382537498741653,
      "grad_norm": 0.9181082844734192,
      "learning_rate": 8.479880774962744e-05,
      "loss": 2.7208,
      "step": 570
    },
    {
      "epoch": 0.038924868293010305,
      "grad_norm": 0.81389319896698,
      "learning_rate": 8.628912071535022e-05,
      "loss": 2.6807,
      "step": 580
    },
    {
      "epoch": 0.039595986711855304,
      "grad_norm": 0.8340194821357727,
      "learning_rate": 8.777943368107303e-05,
      "loss": 2.7509,
      "step": 590
    },
    {
      "epoch": 0.04026710513070031,
      "grad_norm": 0.7684484720230103,
      "learning_rate": 8.926974664679582e-05,
      "loss": 2.7315,
      "step": 600
    },
    {
      "epoch": 0.04026710513070031,
      "eval_bleu": 20.696295251541756,
      "eval_gen_len": 28.727,
      "eval_loss": 3.0094385147094727,
      "eval_runtime": 58.8839,
      "eval_samples_per_second": 16.983,
      "eval_steps_per_second": 1.07,
      "step": 600
    },
    {
      "epoch": 0.040938223549545315,
      "grad_norm": 0.9137141108512878,
      "learning_rate": 9.076005961251863e-05,
      "loss": 2.6689,
      "step": 610
    },
    {
      "epoch": 0.04160934196839032,
      "grad_norm": 0.7940019965171814,
      "learning_rate": 9.225037257824144e-05,
      "loss": 2.7234,
      "step": 620
    },
    {
      "epoch": 0.042280460387235326,
      "grad_norm": 0.9076220989227295,
      "learning_rate": 9.374068554396424e-05,
      "loss": 2.6688,
      "step": 630
    },
    {
      "epoch": 0.04295157880608033,
      "grad_norm": 0.8062429428100586,
      "learning_rate": 9.523099850968704e-05,
      "loss": 2.6763,
      "step": 640
    },
    {
      "epoch": 0.04362269722492534,
      "grad_norm": 0.8734063506126404,
      "learning_rate": 9.672131147540983e-05,
      "loss": 2.6493,
      "step": 650
    },
    {
      "epoch": 0.04362269722492534,
      "eval_bleu": 20.5444392054843,
      "eval_gen_len": 28.701,
      "eval_loss": 3.013101816177368,
      "eval_runtime": 58.5601,
      "eval_samples_per_second": 17.076,
      "eval_steps_per_second": 1.076,
      "step": 650
    },
    {
      "epoch": 0.04429381564377034,
      "grad_norm": 0.8622155785560608,
      "learning_rate": 9.821162444113264e-05,
      "loss": 2.6569,
      "step": 660
    },
    {
      "epoch": 0.04496493406261535,
      "grad_norm": 0.9076696038246155,
      "learning_rate": 9.970193740685544e-05,
      "loss": 2.6782,
      "step": 670
    },
    {
      "epoch": 0.045636052481460354,
      "grad_norm": 0.8196679949760437,
      "learning_rate": 0.00010119225037257825,
      "loss": 2.7273,
      "step": 680
    },
    {
      "epoch": 0.04630717090030536,
      "grad_norm": 0.8320221900939941,
      "learning_rate": 0.00010268256333830105,
      "loss": 2.7083,
      "step": 690
    },
    {
      "epoch": 0.046978289319150365,
      "grad_norm": 0.88948655128479,
      "learning_rate": 0.00010417287630402386,
      "loss": 2.7097,
      "step": 700
    },
    {
      "epoch": 0.046978289319150365,
      "eval_bleu": 20.532002308478305,
      "eval_gen_len": 28.795,
      "eval_loss": 3.0094008445739746,
      "eval_runtime": 59.1327,
      "eval_samples_per_second": 16.911,
      "eval_steps_per_second": 1.065,
      "step": 700
    },
    {
      "epoch": 0.04764940773799537,
      "grad_norm": 0.8125301003456116,
      "learning_rate": 0.00010566318926974665,
      "loss": 2.7438,
      "step": 710
    },
    {
      "epoch": 0.04832052615684038,
      "grad_norm": 0.8081013560295105,
      "learning_rate": 0.00010715350223546945,
      "loss": 2.738,
      "step": 720
    },
    {
      "epoch": 0.04899164457568538,
      "grad_norm": 0.8204091787338257,
      "learning_rate": 0.00010864381520119225,
      "loss": 2.7274,
      "step": 730
    },
    {
      "epoch": 0.04966276299453039,
      "grad_norm": 0.8540447354316711,
      "learning_rate": 0.00011013412816691507,
      "loss": 2.7059,
      "step": 740
    },
    {
      "epoch": 0.05033388141337539,
      "grad_norm": 0.8180471062660217,
      "learning_rate": 0.00011162444113263785,
      "loss": 2.6914,
      "step": 750
    },
    {
      "epoch": 0.05033388141337539,
      "eval_bleu": 20.81038865002893,
      "eval_gen_len": 28.617,
      "eval_loss": 3.004587411880493,
      "eval_runtime": 58.5234,
      "eval_samples_per_second": 17.087,
      "eval_steps_per_second": 1.076,
      "step": 750
    },
    {
      "epoch": 0.05100499983222039,
      "grad_norm": 0.8318853378295898,
      "learning_rate": 0.00011311475409836065,
      "loss": 2.7535,
      "step": 760
    },
    {
      "epoch": 0.0516761182510654,
      "grad_norm": 0.8973262310028076,
      "learning_rate": 0.00011460506706408347,
      "loss": 2.7383,
      "step": 770
    },
    {
      "epoch": 0.0523472366699104,
      "grad_norm": 0.8088759779930115,
      "learning_rate": 0.00011609538002980627,
      "loss": 2.6728,
      "step": 780
    },
    {
      "epoch": 0.05301835508875541,
      "grad_norm": 0.8145114183425903,
      "learning_rate": 0.00011758569299552906,
      "loss": 2.6432,
      "step": 790
    },
    {
      "epoch": 0.053689473507600415,
      "grad_norm": 0.7833325266838074,
      "learning_rate": 0.00011907600596125187,
      "loss": 2.6554,
      "step": 800
    },
    {
      "epoch": 0.053689473507600415,
      "eval_bleu": 20.553989615545866,
      "eval_gen_len": 28.753,
      "eval_loss": 3.004363775253296,
      "eval_runtime": 59.2805,
      "eval_samples_per_second": 16.869,
      "eval_steps_per_second": 1.063,
      "step": 800
    },
    {
      "epoch": 0.05436059192644542,
      "grad_norm": 0.8595842123031616,
      "learning_rate": 0.00012056631892697467,
      "loss": 2.6761,
      "step": 810
    },
    {
      "epoch": 0.055031710345290426,
      "grad_norm": 0.8145135641098022,
      "learning_rate": 0.00012205663189269747,
      "loss": 2.6168,
      "step": 820
    },
    {
      "epoch": 0.05570282876413543,
      "grad_norm": 0.8920451998710632,
      "learning_rate": 0.00012354694485842028,
      "loss": 2.6671,
      "step": 830
    },
    {
      "epoch": 0.05637394718298044,
      "grad_norm": 0.8210507035255432,
      "learning_rate": 0.00012503725782414307,
      "loss": 2.7195,
      "step": 840
    },
    {
      "epoch": 0.05704506560182544,
      "grad_norm": 0.863037645816803,
      "learning_rate": 0.00012652757078986587,
      "loss": 2.6492,
      "step": 850
    },
    {
      "epoch": 0.05704506560182544,
      "eval_bleu": 20.33701386422866,
      "eval_gen_len": 28.678,
      "eval_loss": 3.006293535232544,
      "eval_runtime": 58.5595,
      "eval_samples_per_second": 17.077,
      "eval_steps_per_second": 1.076,
      "step": 850
    },
    {
      "epoch": 0.05771618402067045,
      "grad_norm": 0.9037032723426819,
      "learning_rate": 0.00012801788375558867,
      "loss": 2.7041,
      "step": 860
    },
    {
      "epoch": 0.058387302439515454,
      "grad_norm": 0.8146870732307434,
      "learning_rate": 0.0001295081967213115,
      "loss": 2.7057,
      "step": 870
    },
    {
      "epoch": 0.05905842085836046,
      "grad_norm": 0.8164362907409668,
      "learning_rate": 0.00013099850968703429,
      "loss": 2.6814,
      "step": 880
    },
    {
      "epoch": 0.059729539277205465,
      "grad_norm": 0.8950605988502502,
      "learning_rate": 0.00013248882265275708,
      "loss": 2.719,
      "step": 890
    },
    {
      "epoch": 0.06040065769605047,
      "grad_norm": 0.8337576389312744,
      "learning_rate": 0.00013397913561847988,
      "loss": 2.6595,
      "step": 900
    },
    {
      "epoch": 0.06040065769605047,
      "eval_bleu": 20.471402897304607,
      "eval_gen_len": 28.588,
      "eval_loss": 3.0109810829162598,
      "eval_runtime": 59.3489,
      "eval_samples_per_second": 16.85,
      "eval_steps_per_second": 1.062,
      "step": 900
    },
    {
      "epoch": 0.061071776114895476,
      "grad_norm": 0.8730890154838562,
      "learning_rate": 0.0001354694485842027,
      "loss": 2.722,
      "step": 910
    },
    {
      "epoch": 0.06174289453374048,
      "grad_norm": 0.8388220071792603,
      "learning_rate": 0.0001369597615499255,
      "loss": 2.6582,
      "step": 920
    },
    {
      "epoch": 0.06241401295258548,
      "grad_norm": 0.7905502319335938,
      "learning_rate": 0.0001384500745156483,
      "loss": 2.7045,
      "step": 930
    },
    {
      "epoch": 0.06308513137143049,
      "grad_norm": 0.821524977684021,
      "learning_rate": 0.00013994038748137112,
      "loss": 2.6971,
      "step": 940
    },
    {
      "epoch": 0.0637562497902755,
      "grad_norm": 0.9114919304847717,
      "learning_rate": 0.0001414307004470939,
      "loss": 2.7203,
      "step": 950
    },
    {
      "epoch": 0.0637562497902755,
      "eval_bleu": 20.13649067454443,
      "eval_gen_len": 28.532,
      "eval_loss": 3.01092791557312,
      "eval_runtime": 59.2381,
      "eval_samples_per_second": 16.881,
      "eval_steps_per_second": 1.064,
      "step": 950
    },
    {
      "epoch": 0.0644273682091205,
      "grad_norm": 0.869955837726593,
      "learning_rate": 0.00014292101341281668,
      "loss": 2.6812,
      "step": 960
    },
    {
      "epoch": 0.06509848662796551,
      "grad_norm": 0.7525922060012817,
      "learning_rate": 0.00014441132637853948,
      "loss": 2.6394,
      "step": 970
    },
    {
      "epoch": 0.06576960504681051,
      "grad_norm": 0.8365543484687805,
      "learning_rate": 0.0001459016393442623,
      "loss": 2.6691,
      "step": 980
    },
    {
      "epoch": 0.06644072346565552,
      "grad_norm": 0.8219516277313232,
      "learning_rate": 0.0001473919523099851,
      "loss": 2.6804,
      "step": 990
    },
    {
      "epoch": 0.06711184188450052,
      "grad_norm": 0.8941384553909302,
      "learning_rate": 0.0001488822652757079,
      "loss": 2.7155,
      "step": 1000
    },
    {
      "epoch": 0.06711184188450052,
      "eval_bleu": 20.174252071792626,
      "eval_gen_len": 28.7,
      "eval_loss": 3.019942283630371,
      "eval_runtime": 59.2918,
      "eval_samples_per_second": 16.866,
      "eval_steps_per_second": 1.063,
      "step": 1000
    },
    {
      "epoch": 0.06778296030334552,
      "grad_norm": 0.8874906897544861,
      "learning_rate": 0.00015037257824143072,
      "loss": 2.6562,
      "step": 1010
    },
    {
      "epoch": 0.06845407872219053,
      "grad_norm": 0.82135009765625,
      "learning_rate": 0.00015186289120715352,
      "loss": 2.6571,
      "step": 1020
    },
    {
      "epoch": 0.06912519714103553,
      "grad_norm": 0.8041913509368896,
      "learning_rate": 0.0001533532041728763,
      "loss": 2.6694,
      "step": 1030
    },
    {
      "epoch": 0.06979631555988054,
      "grad_norm": 0.9156535267829895,
      "learning_rate": 0.0001548435171385991,
      "loss": 2.6887,
      "step": 1040
    },
    {
      "epoch": 0.07046743397872554,
      "grad_norm": 0.8413767218589783,
      "learning_rate": 0.00015633383010432193,
      "loss": 2.6527,
      "step": 1050
    },
    {
      "epoch": 0.07046743397872554,
      "eval_bleu": 20.66683996236026,
      "eval_gen_len": 28.954,
      "eval_loss": 3.004363775253296,
      "eval_runtime": 59.3892,
      "eval_samples_per_second": 16.838,
      "eval_steps_per_second": 1.061,
      "step": 1050
    },
    {
      "epoch": 0.07113855239757055,
      "grad_norm": 0.8705973625183105,
      "learning_rate": 0.00015782414307004473,
      "loss": 2.6643,
      "step": 1060
    },
    {
      "epoch": 0.07180967081641555,
      "grad_norm": 0.7860819101333618,
      "learning_rate": 0.00015931445603576753,
      "loss": 2.6379,
      "step": 1070
    },
    {
      "epoch": 0.07248078923526056,
      "grad_norm": 0.8578693866729736,
      "learning_rate": 0.00016080476900149032,
      "loss": 2.6736,
      "step": 1080
    },
    {
      "epoch": 0.07315190765410556,
      "grad_norm": 0.8615450859069824,
      "learning_rate": 0.00016229508196721312,
      "loss": 2.6391,
      "step": 1090
    },
    {
      "epoch": 0.07382302607295058,
      "grad_norm": 0.8800402283668518,
      "learning_rate": 0.00016378539493293591,
      "loss": 2.6869,
      "step": 1100
    },
    {
      "epoch": 0.07382302607295058,
      "eval_bleu": 20.25004873397731,
      "eval_gen_len": 28.756,
      "eval_loss": 3.0142946243286133,
      "eval_runtime": 58.9853,
      "eval_samples_per_second": 16.953,
      "eval_steps_per_second": 1.068,
      "step": 1100
    },
    {
      "epoch": 0.07449414449179557,
      "grad_norm": 0.84691321849823,
      "learning_rate": 0.0001652757078986587,
      "loss": 2.6939,
      "step": 1110
    },
    {
      "epoch": 0.07516526291064059,
      "grad_norm": 0.8369666934013367,
      "learning_rate": 0.00016676602086438153,
      "loss": 2.6139,
      "step": 1120
    },
    {
      "epoch": 0.07583638132948559,
      "grad_norm": 0.8054178953170776,
      "learning_rate": 0.00016825633383010433,
      "loss": 2.5869,
      "step": 1130
    },
    {
      "epoch": 0.0765074997483306,
      "grad_norm": 0.8205292224884033,
      "learning_rate": 0.00016974664679582713,
      "loss": 2.6642,
      "step": 1140
    },
    {
      "epoch": 0.0771786181671756,
      "grad_norm": 0.7379977703094482,
      "learning_rate": 0.00017123695976154995,
      "loss": 2.619,
      "step": 1150
    },
    {
      "epoch": 0.0771786181671756,
      "eval_bleu": 20.458528492557527,
      "eval_gen_len": 28.702,
      "eval_loss": 3.011309862136841,
      "eval_runtime": 59.3293,
      "eval_samples_per_second": 16.855,
      "eval_steps_per_second": 1.062,
      "step": 1150
    },
    {
      "epoch": 0.07784973658602061,
      "grad_norm": 0.7980982661247253,
      "learning_rate": 0.00017272727272727275,
      "loss": 2.7085,
      "step": 1160
    },
    {
      "epoch": 0.07852085500486561,
      "grad_norm": 0.8651555776596069,
      "learning_rate": 0.00017421758569299554,
      "loss": 2.6505,
      "step": 1170
    },
    {
      "epoch": 0.07919197342371061,
      "grad_norm": 0.8127865791320801,
      "learning_rate": 0.00017570789865871834,
      "loss": 2.6683,
      "step": 1180
    },
    {
      "epoch": 0.07986309184255562,
      "grad_norm": 0.7746748328208923,
      "learning_rate": 0.00017719821162444114,
      "loss": 2.6599,
      "step": 1190
    },
    {
      "epoch": 0.08053421026140062,
      "grad_norm": 0.861386239528656,
      "learning_rate": 0.00017868852459016393,
      "loss": 2.6487,
      "step": 1200
    },
    {
      "epoch": 0.08053421026140062,
      "eval_bleu": 20.505191151049452,
      "eval_gen_len": 28.76,
      "eval_loss": 3.006695032119751,
      "eval_runtime": 59.3827,
      "eval_samples_per_second": 16.84,
      "eval_steps_per_second": 1.061,
      "step": 1200
    },
    {
      "epoch": 0.08120532868024563,
      "grad_norm": 0.8303239345550537,
      "learning_rate": 0.00018017883755588673,
      "loss": 2.6358,
      "step": 1210
    },
    {
      "epoch": 0.08187644709909063,
      "grad_norm": 0.8551878929138184,
      "learning_rate": 0.00018166915052160955,
      "loss": 2.6648,
      "step": 1220
    },
    {
      "epoch": 0.08254756551793564,
      "grad_norm": 0.8097975850105286,
      "learning_rate": 0.00018315946348733235,
      "loss": 2.6571,
      "step": 1230
    },
    {
      "epoch": 0.08321868393678064,
      "grad_norm": 0.8580490946769714,
      "learning_rate": 0.00018464977645305514,
      "loss": 2.6911,
      "step": 1240
    },
    {
      "epoch": 0.08388980235562565,
      "grad_norm": 0.7908260822296143,
      "learning_rate": 0.00018614008941877797,
      "loss": 2.6296,
      "step": 1250
    },
    {
      "epoch": 0.08388980235562565,
      "eval_bleu": 20.283458917345047,
      "eval_gen_len": 28.766,
      "eval_loss": 3.013366222381592,
      "eval_runtime": 59.5655,
      "eval_samples_per_second": 16.788,
      "eval_steps_per_second": 1.058,
      "step": 1250
    },
    {
      "epoch": 0.08456092077447065,
      "grad_norm": 0.8357235193252563,
      "learning_rate": 0.00018763040238450076,
      "loss": 2.6426,
      "step": 1260
    },
    {
      "epoch": 0.08523203919331566,
      "grad_norm": 0.740831732749939,
      "learning_rate": 0.00018912071535022356,
      "loss": 2.6012,
      "step": 1270
    },
    {
      "epoch": 0.08590315761216066,
      "grad_norm": 0.8027945756912231,
      "learning_rate": 0.00019061102831594636,
      "loss": 2.6394,
      "step": 1280
    },
    {
      "epoch": 0.08657427603100568,
      "grad_norm": 0.854237973690033,
      "learning_rate": 0.00019210134128166915,
      "loss": 2.6998,
      "step": 1290
    },
    {
      "epoch": 0.08724539444985067,
      "grad_norm": 0.8676015734672546,
      "learning_rate": 0.00019359165424739195,
      "loss": 2.6887,
      "step": 1300
    },
    {
      "epoch": 0.08724539444985067,
      "eval_bleu": 20.445694219260357,
      "eval_gen_len": 28.638,
      "eval_loss": 3.0076045989990234,
      "eval_runtime": 59.2714,
      "eval_samples_per_second": 16.872,
      "eval_steps_per_second": 1.063,
      "step": 1300
    },
    {
      "epoch": 0.08791651286869569,
      "grad_norm": 0.761589527130127,
      "learning_rate": 0.00019508196721311475,
      "loss": 2.6839,
      "step": 1310
    },
    {
      "epoch": 0.08858763128754069,
      "grad_norm": 0.8529909253120422,
      "learning_rate": 0.00019657228017883757,
      "loss": 2.6912,
      "step": 1320
    },
    {
      "epoch": 0.0892587497063857,
      "grad_norm": 0.8163550496101379,
      "learning_rate": 0.00019806259314456037,
      "loss": 2.6668,
      "step": 1330
    },
    {
      "epoch": 0.0899298681252307,
      "grad_norm": 0.8769946694374084,
      "learning_rate": 0.00019955290611028316,
      "loss": 2.6556,
      "step": 1340
    },
    {
      "epoch": 0.0906009865440757,
      "grad_norm": 0.7762491106987,
      "learning_rate": 0.000199999987139222,
      "loss": 2.6578,
      "step": 1350
    },
    {
      "epoch": 0.0906009865440757,
      "eval_bleu": 19.903168624247346,
      "eval_gen_len": 28.464,
      "eval_loss": 3.0239741802215576,
      "eval_runtime": 58.6638,
      "eval_samples_per_second": 17.046,
      "eval_steps_per_second": 1.074,
      "step": 1350
    },
    {
      "epoch": 0.09127210496292071,
      "grad_norm": 0.7777621150016785,
      "learning_rate": 0.00019999992414766426,
      "loss": 2.6929,
      "step": 1360
    },
    {
      "epoch": 0.0919432233817657,
      "grad_norm": 0.7771252393722534,
      "learning_rate": 0.00019999980866317607,
      "loss": 2.6611,
      "step": 1370
    },
    {
      "epoch": 0.09261434180061072,
      "grad_norm": 0.7978625297546387,
      "learning_rate": 0.00019999964068581806,
      "loss": 2.6206,
      "step": 1380
    },
    {
      "epoch": 0.09328546021945572,
      "grad_norm": 0.7497276663780212,
      "learning_rate": 0.00019999942021567844,
      "loss": 2.6752,
      "step": 1390
    },
    {
      "epoch": 0.09395657863830073,
      "grad_norm": 0.8038361668586731,
      "learning_rate": 0.00019999914725287287,
      "loss": 2.6699,
      "step": 1400
    },
    {
      "epoch": 0.09395657863830073,
      "eval_bleu": 20.34669890401539,
      "eval_gen_len": 28.722,
      "eval_loss": 3.0063846111297607,
      "eval_runtime": 59.3307,
      "eval_samples_per_second": 16.855,
      "eval_steps_per_second": 1.062,
      "step": 1400
    },
    {
      "epoch": 0.09462769705714573,
      "grad_norm": 0.799091100692749,
      "learning_rate": 0.00019999882179754468,
      "loss": 2.6487,
      "step": 1410
    },
    {
      "epoch": 0.09529881547599074,
      "grad_norm": 0.7998604774475098,
      "learning_rate": 0.00019999844384986472,
      "loss": 2.7025,
      "step": 1420
    },
    {
      "epoch": 0.09596993389483574,
      "grad_norm": 0.85130774974823,
      "learning_rate": 0.0001999980134100314,
      "loss": 2.7223,
      "step": 1430
    },
    {
      "epoch": 0.09664105231368075,
      "grad_norm": 0.7714011073112488,
      "learning_rate": 0.0001999975304782706,
      "loss": 2.5938,
      "step": 1440
    },
    {
      "epoch": 0.09731217073252575,
      "grad_norm": 0.7632842063903809,
      "learning_rate": 0.0001999969950548359,
      "loss": 2.6495,
      "step": 1450
    },
    {
      "epoch": 0.09731217073252575,
      "eval_bleu": 20.000064869074258,
      "eval_gen_len": 28.762,
      "eval_loss": 3.009476900100708,
      "eval_runtime": 58.7525,
      "eval_samples_per_second": 17.021,
      "eval_steps_per_second": 1.072,
      "step": 1450
    },
    {
      "epoch": 0.09798328915137076,
      "grad_norm": 0.7342961430549622,
      "learning_rate": 0.0001999964071400083,
      "loss": 2.6283,
      "step": 1460
    },
    {
      "epoch": 0.09865440757021576,
      "grad_norm": 0.7483336925506592,
      "learning_rate": 0.00019999576673409645,
      "loss": 2.6549,
      "step": 1470
    },
    {
      "epoch": 0.09932552598906078,
      "grad_norm": 0.799523651599884,
      "learning_rate": 0.00019999507383743653,
      "loss": 2.6266,
      "step": 1480
    },
    {
      "epoch": 0.09999664440790577,
      "grad_norm": 0.7884394526481628,
      "learning_rate": 0.00019999432845039223,
      "loss": 2.6403,
      "step": 1490
    },
    {
      "epoch": 0.10066776282675079,
      "grad_norm": 0.7719035744667053,
      "learning_rate": 0.00019999353057335487,
      "loss": 2.6094,
      "step": 1500
    },
    {
      "epoch": 0.10066776282675079,
      "eval_bleu": 19.731369176089615,
      "eval_gen_len": 29.137,
      "eval_loss": 3.0139338970184326,
      "eval_runtime": 65.1404,
      "eval_samples_per_second": 15.351,
      "eval_steps_per_second": 0.967,
      "step": 1500
    },
    {
      "epoch": 0.10133888124559579,
      "grad_norm": 0.7987237572669983,
      "learning_rate": 0.0001999926802067432,
      "loss": 2.6823,
      "step": 1510
    },
    {
      "epoch": 0.10200999966444078,
      "grad_norm": 0.8101581335067749,
      "learning_rate": 0.0001999917773510037,
      "loss": 2.6369,
      "step": 1520
    },
    {
      "epoch": 0.1026811180832858,
      "grad_norm": 0.7751731872558594,
      "learning_rate": 0.00019999082200661023,
      "loss": 2.6264,
      "step": 1530
    },
    {
      "epoch": 0.1033522365021308,
      "grad_norm": 0.743645191192627,
      "learning_rate": 0.0001999898141740643,
      "loss": 2.6533,
      "step": 1540
    },
    {
      "epoch": 0.10402335492097581,
      "grad_norm": 0.8728232979774475,
      "learning_rate": 0.00019998875385389498,
      "loss": 2.6754,
      "step": 1550
    },
    {
      "epoch": 0.10402335492097581,
      "eval_bleu": 19.938866289650164,
      "eval_gen_len": 29.04,
      "eval_loss": 3.0089547634124756,
      "eval_runtime": 64.5222,
      "eval_samples_per_second": 15.499,
      "eval_steps_per_second": 0.976,
      "step": 1550
    },
    {
      "epoch": 0.1046944733398208,
      "grad_norm": 0.7632548213005066,
      "learning_rate": 0.0001999876410466588,
      "loss": 2.6299,
      "step": 1560
    },
    {
      "epoch": 0.10536559175866582,
      "grad_norm": 0.8103184103965759,
      "learning_rate": 0.00019998647575293998,
      "loss": 2.64,
      "step": 1570
    },
    {
      "epoch": 0.10603671017751082,
      "grad_norm": 0.9090927243232727,
      "learning_rate": 0.00019998525797335016,
      "loss": 2.6522,
      "step": 1580
    },
    {
      "epoch": 0.10670782859635583,
      "grad_norm": 0.8423330187797546,
      "learning_rate": 0.00019998398770852864,
      "loss": 2.6342,
      "step": 1590
    },
    {
      "epoch": 0.10737894701520083,
      "grad_norm": 0.769882082939148,
      "learning_rate": 0.00019998266495914216,
      "loss": 2.6401,
      "step": 1600
    },
    {
      "epoch": 0.10737894701520083,
      "eval_bleu": 20.395359684182573,
      "eval_gen_len": 28.686,
      "eval_loss": 3.0080904960632324,
      "eval_runtime": 58.5847,
      "eval_samples_per_second": 17.069,
      "eval_steps_per_second": 1.075,
      "step": 1600
    },
    {
      "epoch": 0.10805006543404584,
      "grad_norm": 0.7907959222793579,
      "learning_rate": 0.0001999812897258851,
      "loss": 2.6875,
      "step": 1610
    },
    {
      "epoch": 0.10872118385289084,
      "grad_norm": 0.7764168381690979,
      "learning_rate": 0.00019997986200947943,
      "loss": 2.6819,
      "step": 1620
    },
    {
      "epoch": 0.10939230227173585,
      "grad_norm": 1.0988547801971436,
      "learning_rate": 0.0001999783818106745,
      "loss": 2.6909,
      "step": 1630
    },
    {
      "epoch": 0.11006342069058085,
      "grad_norm": 0.6950260996818542,
      "learning_rate": 0.0001999768491302473,
      "loss": 2.6253,
      "step": 1640
    },
    {
      "epoch": 0.11073453910942586,
      "grad_norm": 0.8073287010192871,
      "learning_rate": 0.00019997526396900247,
      "loss": 2.6256,
      "step": 1650
    },
    {
      "epoch": 0.11073453910942586,
      "eval_bleu": 19.75941226053096,
      "eval_gen_len": 28.516,
      "eval_loss": 3.013404369354248,
      "eval_runtime": 58.6108,
      "eval_samples_per_second": 17.062,
      "eval_steps_per_second": 1.075,
      "step": 1650
    },
    {
      "epoch": 0.11140565752827086,
      "grad_norm": 0.7380000948905945,
      "learning_rate": 0.00019997362632777205,
      "loss": 2.6812,
      "step": 1660
    },
    {
      "epoch": 0.11207677594711588,
      "grad_norm": 0.7829627394676208,
      "learning_rate": 0.00019997193620741567,
      "loss": 2.6154,
      "step": 1670
    },
    {
      "epoch": 0.11274789436596087,
      "grad_norm": 0.7556002736091614,
      "learning_rate": 0.00019997019360882062,
      "loss": 2.6059,
      "step": 1680
    },
    {
      "epoch": 0.11341901278480587,
      "grad_norm": 0.9222731590270996,
      "learning_rate": 0.0001999683985329015,
      "loss": 2.6817,
      "step": 1690
    },
    {
      "epoch": 0.11409013120365089,
      "grad_norm": 0.847168505191803,
      "learning_rate": 0.0001999665509806007,
      "loss": 2.6629,
      "step": 1700
    },
    {
      "epoch": 0.11409013120365089,
      "eval_bleu": 19.93893674566937,
      "eval_gen_len": 28.561,
      "eval_loss": 3.014146327972412,
      "eval_runtime": 58.7855,
      "eval_samples_per_second": 17.011,
      "eval_steps_per_second": 1.072,
      "step": 1700
    },
    {
      "epoch": 0.11476124962249588,
      "grad_norm": 0.7581436634063721,
      "learning_rate": 0.00019996465095288807,
      "loss": 2.6897,
      "step": 1710
    },
    {
      "epoch": 0.1154323680413409,
      "grad_norm": 0.7957221865653992,
      "learning_rate": 0.0001999626984507609,
      "loss": 2.6958,
      "step": 1720
    },
    {
      "epoch": 0.1161034864601859,
      "grad_norm": 0.8109757304191589,
      "learning_rate": 0.00019996069347524416,
      "loss": 2.6247,
      "step": 1730
    },
    {
      "epoch": 0.11677460487903091,
      "grad_norm": 0.7699851989746094,
      "learning_rate": 0.00019995863602739037,
      "loss": 2.625,
      "step": 1740
    },
    {
      "epoch": 0.1174457232978759,
      "grad_norm": 0.7488811016082764,
      "learning_rate": 0.00019995652610827947,
      "loss": 2.6312,
      "step": 1750
    },
    {
      "epoch": 0.1174457232978759,
      "eval_bleu": 19.501744068423907,
      "eval_gen_len": 28.533,
      "eval_loss": 3.0184426307678223,
      "eval_runtime": 58.4818,
      "eval_samples_per_second": 17.099,
      "eval_steps_per_second": 1.077,
      "step": 1750
    },
    {
      "epoch": 0.11811684171672092,
      "grad_norm": 0.7681069374084473,
      "learning_rate": 0.00019995436371901906,
      "loss": 2.6307,
      "step": 1760
    },
    {
      "epoch": 0.11878796013556592,
      "grad_norm": 0.8456167578697205,
      "learning_rate": 0.00019995214886074422,
      "loss": 2.6302,
      "step": 1770
    },
    {
      "epoch": 0.11945907855441093,
      "grad_norm": 0.7518228888511658,
      "learning_rate": 0.00019994988153461765,
      "loss": 2.6894,
      "step": 1780
    },
    {
      "epoch": 0.12013019697325593,
      "grad_norm": 0.7799319624900818,
      "learning_rate": 0.00019994756174182945,
      "loss": 2.681,
      "step": 1790
    },
    {
      "epoch": 0.12080131539210094,
      "grad_norm": 0.7447225451469421,
      "learning_rate": 0.0001999451894835974,
      "loss": 2.594,
      "step": 1800
    },
    {
      "epoch": 0.12080131539210094,
      "eval_bleu": 20.00134228984097,
      "eval_gen_len": 28.753,
      "eval_loss": 3.0078017711639404,
      "eval_runtime": 59.329,
      "eval_samples_per_second": 16.855,
      "eval_steps_per_second": 1.062,
      "step": 1800
    },
    {
      "epoch": 0.12147243381094594,
      "grad_norm": 0.7783031463623047,
      "learning_rate": 0.00019994276476116677,
      "loss": 2.6324,
      "step": 1810
    },
    {
      "epoch": 0.12214355222979095,
      "grad_norm": 0.7578281760215759,
      "learning_rate": 0.00019994028757581037,
      "loss": 2.5975,
      "step": 1820
    },
    {
      "epoch": 0.12281467064863595,
      "grad_norm": 0.7575814723968506,
      "learning_rate": 0.00019993775792882855,
      "loss": 2.6194,
      "step": 1830
    },
    {
      "epoch": 0.12348578906748096,
      "grad_norm": 0.8070423007011414,
      "learning_rate": 0.00019993517582154918,
      "loss": 2.6564,
      "step": 1840
    },
    {
      "epoch": 0.12415690748632596,
      "grad_norm": 0.8573471307754517,
      "learning_rate": 0.00019993254125532766,
      "loss": 2.5877,
      "step": 1850
    },
    {
      "epoch": 0.12415690748632596,
      "eval_bleu": 20.10914172064592,
      "eval_gen_len": 28.667,
      "eval_loss": 3.0091209411621094,
      "eval_runtime": 59.3169,
      "eval_samples_per_second": 16.859,
      "eval_steps_per_second": 1.062,
      "step": 1850
    },
    {
      "epoch": 0.12482802590517096,
      "grad_norm": 0.8360574245452881,
      "learning_rate": 0.000199929854231547,
      "loss": 2.6869,
      "step": 1860
    },
    {
      "epoch": 0.12549914432401596,
      "grad_norm": 0.8297503590583801,
      "learning_rate": 0.00019992711475161768,
      "loss": 2.6687,
      "step": 1870
    },
    {
      "epoch": 0.12617026274286097,
      "grad_norm": 0.8337427377700806,
      "learning_rate": 0.00019992432281697774,
      "loss": 2.6621,
      "step": 1880
    },
    {
      "epoch": 0.12684138116170598,
      "grad_norm": 0.7916382551193237,
      "learning_rate": 0.00019992147842909277,
      "loss": 2.6465,
      "step": 1890
    },
    {
      "epoch": 0.127512499580551,
      "grad_norm": 0.7928901314735413,
      "learning_rate": 0.0001999185815894558,
      "loss": 2.6288,
      "step": 1900
    },
    {
      "epoch": 0.127512499580551,
      "eval_bleu": 19.83451119294777,
      "eval_gen_len": 28.592,
      "eval_loss": 3.005156993865967,
      "eval_runtime": 59.1755,
      "eval_samples_per_second": 16.899,
      "eval_steps_per_second": 1.065,
      "step": 1900
    },
    {
      "epoch": 0.12818361799939598,
      "grad_norm": 0.8025777339935303,
      "learning_rate": 0.00019991563229958755,
      "loss": 2.5905,
      "step": 1910
    },
    {
      "epoch": 0.128854736418241,
      "grad_norm": 0.739020824432373,
      "learning_rate": 0.00019991263056103614,
      "loss": 2.5967,
      "step": 1920
    },
    {
      "epoch": 0.129525854837086,
      "grad_norm": 0.8072446584701538,
      "learning_rate": 0.00019990957637537732,
      "loss": 2.6787,
      "step": 1930
    },
    {
      "epoch": 0.13019697325593102,
      "grad_norm": 0.764003574848175,
      "learning_rate": 0.00019990646974421428,
      "loss": 2.6198,
      "step": 1940
    },
    {
      "epoch": 0.130868091674776,
      "grad_norm": 0.7379930019378662,
      "learning_rate": 0.00019990331066917775,
      "loss": 2.7003,
      "step": 1950
    },
    {
      "epoch": 0.130868091674776,
      "eval_bleu": 20.516398595452046,
      "eval_gen_len": 28.648,
      "eval_loss": 3.0047500133514404,
      "eval_runtime": 59.2605,
      "eval_samples_per_second": 16.875,
      "eval_steps_per_second": 1.063,
      "step": 1950
    },
    {
      "epoch": 0.13153921009362102,
      "grad_norm": 0.7173508405685425,
      "learning_rate": 0.00019990009915192612,
      "loss": 2.609,
      "step": 1960
    },
    {
      "epoch": 0.13221032851246603,
      "grad_norm": 0.748325765132904,
      "learning_rate": 0.00019989683519414512,
      "loss": 2.6174,
      "step": 1970
    },
    {
      "epoch": 0.13288144693131104,
      "grad_norm": 0.7768097519874573,
      "learning_rate": 0.0001998935187975482,
      "loss": 2.6457,
      "step": 1980
    },
    {
      "epoch": 0.13355256535015603,
      "grad_norm": 0.754940927028656,
      "learning_rate": 0.0001998901499638761,
      "loss": 2.6598,
      "step": 1990
    },
    {
      "epoch": 0.13422368376900104,
      "grad_norm": 0.7645187377929688,
      "learning_rate": 0.00019988672869489731,
      "loss": 2.616,
      "step": 2000
    },
    {
      "epoch": 0.13422368376900104,
      "eval_bleu": 20.000002540918658,
      "eval_gen_len": 28.76,
      "eval_loss": 3.0072476863861084,
      "eval_runtime": 59.3659,
      "eval_samples_per_second": 16.845,
      "eval_steps_per_second": 1.061,
      "step": 2000
    },
    {
      "epoch": 0.13489480218784605,
      "grad_norm": 0.7948493957519531,
      "learning_rate": 0.00019988325499240773,
      "loss": 2.6119,
      "step": 2010
    },
    {
      "epoch": 0.13556592060669104,
      "grad_norm": 0.7439639568328857,
      "learning_rate": 0.00019987972885823082,
      "loss": 2.6138,
      "step": 2020
    },
    {
      "epoch": 0.13623703902553605,
      "grad_norm": 0.8125005960464478,
      "learning_rate": 0.00019987615029421756,
      "loss": 2.6855,
      "step": 2030
    },
    {
      "epoch": 0.13690815744438106,
      "grad_norm": 0.7729895710945129,
      "learning_rate": 0.00019987251930224641,
      "loss": 2.6164,
      "step": 2040
    },
    {
      "epoch": 0.13757927586322607,
      "grad_norm": 0.7732176184654236,
      "learning_rate": 0.00019986883588422346,
      "loss": 2.6035,
      "step": 2050
    },
    {
      "epoch": 0.13757927586322607,
      "eval_bleu": 19.773072917323542,
      "eval_gen_len": 28.565,
      "eval_loss": 3.0015077590942383,
      "eval_runtime": 59.8457,
      "eval_samples_per_second": 16.71,
      "eval_steps_per_second": 1.053,
      "step": 2050
    },
    {
      "epoch": 0.13825039428207106,
      "grad_norm": 0.796116292476654,
      "learning_rate": 0.00019986510004208215,
      "loss": 2.6188,
      "step": 2060
    },
    {
      "epoch": 0.13892151270091607,
      "grad_norm": 0.7154659628868103,
      "learning_rate": 0.00019986131177778357,
      "loss": 2.6607,
      "step": 2070
    },
    {
      "epoch": 0.13959263111976108,
      "grad_norm": 0.7367361783981323,
      "learning_rate": 0.00019985747109331636,
      "loss": 2.5683,
      "step": 2080
    },
    {
      "epoch": 0.1402637495386061,
      "grad_norm": 0.8126523494720459,
      "learning_rate": 0.0001998535779906965,
      "loss": 2.6116,
      "step": 2090
    },
    {
      "epoch": 0.14093486795745108,
      "grad_norm": 0.7536521553993225,
      "learning_rate": 0.00019984963247196767,
      "loss": 2.6336,
      "step": 2100
    },
    {
      "epoch": 0.14093486795745108,
      "eval_bleu": 20.35083287845577,
      "eval_gen_len": 28.832,
      "eval_loss": 2.9934425354003906,
      "eval_runtime": 59.1648,
      "eval_samples_per_second": 16.902,
      "eval_steps_per_second": 1.065,
      "step": 2100
    },
    {
      "epoch": 0.1416059863762961,
      "grad_norm": 0.7565605640411377,
      "learning_rate": 0.00019984563453920092,
      "loss": 2.6062,
      "step": 2110
    },
    {
      "epoch": 0.1422771047951411,
      "grad_norm": 0.778634786605835,
      "learning_rate": 0.000199841584194495,
      "loss": 2.5978,
      "step": 2120
    },
    {
      "epoch": 0.14294822321398612,
      "grad_norm": 0.7491517663002014,
      "learning_rate": 0.00019983748143997593,
      "loss": 2.6135,
      "step": 2130
    },
    {
      "epoch": 0.1436193416328311,
      "grad_norm": 0.7277877330780029,
      "learning_rate": 0.00019983332627779746,
      "loss": 2.6812,
      "step": 2140
    },
    {
      "epoch": 0.14429046005167612,
      "grad_norm": 0.8235312700271606,
      "learning_rate": 0.0001998291187101407,
      "loss": 2.661,
      "step": 2150
    },
    {
      "epoch": 0.14429046005167612,
      "eval_bleu": 20.274550338018557,
      "eval_gen_len": 28.713,
      "eval_loss": 2.994933605194092,
      "eval_runtime": 59.6646,
      "eval_samples_per_second": 16.76,
      "eval_steps_per_second": 1.056,
      "step": 2150
    },
    {
      "epoch": 0.14496157847052113,
      "grad_norm": 0.7442207932472229,
      "learning_rate": 0.00019982485873921437,
      "loss": 2.5948,
      "step": 2160
    },
    {
      "epoch": 0.14563269688936614,
      "grad_norm": 0.7947060465812683,
      "learning_rate": 0.00019982054636725463,
      "loss": 2.6629,
      "step": 2170
    },
    {
      "epoch": 0.14630381530821113,
      "grad_norm": 0.7633037567138672,
      "learning_rate": 0.00019981618159652516,
      "loss": 2.5393,
      "step": 2180
    },
    {
      "epoch": 0.14697493372705614,
      "grad_norm": 0.7681461572647095,
      "learning_rate": 0.0001998117644293172,
      "loss": 2.6429,
      "step": 2190
    },
    {
      "epoch": 0.14764605214590115,
      "grad_norm": 0.7045911550521851,
      "learning_rate": 0.00019980729486794937,
      "loss": 2.6297,
      "step": 2200
    },
    {
      "epoch": 0.14764605214590115,
      "eval_bleu": 20.007219651783625,
      "eval_gen_len": 28.78,
      "eval_loss": 2.993955135345459,
      "eval_runtime": 60.2352,
      "eval_samples_per_second": 16.602,
      "eval_steps_per_second": 1.046,
      "step": 2200
    },
    {
      "epoch": 0.14831717056474614,
      "grad_norm": 0.8014165163040161,
      "learning_rate": 0.00019980277291476798,
      "loss": 2.6463,
      "step": 2210
    },
    {
      "epoch": 0.14898828898359115,
      "grad_norm": 0.7136631608009338,
      "learning_rate": 0.0001997981985721467,
      "loss": 2.632,
      "step": 2220
    },
    {
      "epoch": 0.14965940740243616,
      "grad_norm": 0.7567936182022095,
      "learning_rate": 0.0001997935718424867,
      "loss": 2.6724,
      "step": 2230
    },
    {
      "epoch": 0.15033052582128117,
      "grad_norm": 0.7215164303779602,
      "learning_rate": 0.00019978889272821671,
      "loss": 2.6348,
      "step": 2240
    },
    {
      "epoch": 0.15100164424012616,
      "grad_norm": 0.7477201819419861,
      "learning_rate": 0.00019978416123179294,
      "loss": 2.6353,
      "step": 2250
    },
    {
      "epoch": 0.15100164424012616,
      "eval_bleu": 20.272807063846553,
      "eval_gen_len": 28.735,
      "eval_loss": 3.000305652618408,
      "eval_runtime": 60.3431,
      "eval_samples_per_second": 16.572,
      "eval_steps_per_second": 1.044,
      "step": 2250
    },
    {
      "epoch": 0.15167276265897117,
      "grad_norm": 0.7537184357643127,
      "learning_rate": 0.00019977937735569915,
      "loss": 2.6034,
      "step": 2260
    },
    {
      "epoch": 0.15234388107781618,
      "grad_norm": 0.7539804577827454,
      "learning_rate": 0.00019977454110244643,
      "loss": 2.6209,
      "step": 2270
    },
    {
      "epoch": 0.1530149994966612,
      "grad_norm": 0.7355387806892395,
      "learning_rate": 0.00019976965247457353,
      "loss": 2.5847,
      "step": 2280
    },
    {
      "epoch": 0.15368611791550618,
      "grad_norm": 0.7887433767318726,
      "learning_rate": 0.00019976471147464665,
      "loss": 2.628,
      "step": 2290
    },
    {
      "epoch": 0.1543572363343512,
      "grad_norm": 0.7090144157409668,
      "learning_rate": 0.00019975971810525946,
      "loss": 2.6248,
      "step": 2300
    },
    {
      "epoch": 0.1543572363343512,
      "eval_bleu": 20.161510776358796,
      "eval_gen_len": 28.577,
      "eval_loss": 3.005370616912842,
      "eval_runtime": 60.1275,
      "eval_samples_per_second": 16.631,
      "eval_steps_per_second": 1.048,
      "step": 2300
    },
    {
      "epoch": 0.1550283547531962,
      "grad_norm": 0.7528431415557861,
      "learning_rate": 0.0001997546723690331,
      "loss": 2.712,
      "step": 2310
    },
    {
      "epoch": 0.15569947317204122,
      "grad_norm": 0.7374621033668518,
      "learning_rate": 0.00019974957426861624,
      "loss": 2.6822,
      "step": 2320
    },
    {
      "epoch": 0.1563705915908862,
      "grad_norm": 0.7011844515800476,
      "learning_rate": 0.00019974442380668502,
      "loss": 2.6455,
      "step": 2330
    },
    {
      "epoch": 0.15704171000973122,
      "grad_norm": 0.7647737264633179,
      "learning_rate": 0.0001997392209859431,
      "loss": 2.6472,
      "step": 2340
    },
    {
      "epoch": 0.15771282842857623,
      "grad_norm": 0.8349627256393433,
      "learning_rate": 0.00019973396580912157,
      "loss": 2.6089,
      "step": 2350
    },
    {
      "epoch": 0.15771282842857623,
      "eval_bleu": 20.533229948547742,
      "eval_gen_len": 28.76,
      "eval_loss": 2.995434522628784,
      "eval_runtime": 59.6875,
      "eval_samples_per_second": 16.754,
      "eval_steps_per_second": 1.055,
      "step": 2350
    },
    {
      "epoch": 0.15838394684742121,
      "grad_norm": 0.72677081823349,
      "learning_rate": 0.00019972865827897905,
      "loss": 2.6249,
      "step": 2360
    },
    {
      "epoch": 0.15905506526626623,
      "grad_norm": 0.7857693433761597,
      "learning_rate": 0.00019972329839830158,
      "loss": 2.5846,
      "step": 2370
    },
    {
      "epoch": 0.15972618368511124,
      "grad_norm": 0.9046860933303833,
      "learning_rate": 0.00019971788616990276,
      "loss": 2.5923,
      "step": 2380
    },
    {
      "epoch": 0.16039730210395625,
      "grad_norm": 0.7660042643547058,
      "learning_rate": 0.0001997124215966236,
      "loss": 2.6419,
      "step": 2390
    },
    {
      "epoch": 0.16106842052280124,
      "grad_norm": 0.7905299663543701,
      "learning_rate": 0.00019970690468133263,
      "loss": 2.5754,
      "step": 2400
    },
    {
      "epoch": 0.16106842052280124,
      "eval_bleu": 20.21338604632374,
      "eval_gen_len": 28.718,
      "eval_loss": 2.999154806137085,
      "eval_runtime": 61.5043,
      "eval_samples_per_second": 16.259,
      "eval_steps_per_second": 1.024,
      "step": 2400
    },
    {
      "epoch": 0.16173953894164625,
      "grad_norm": 0.8038133382797241,
      "learning_rate": 0.00019970133542692584,
      "loss": 2.5984,
      "step": 2410
    },
    {
      "epoch": 0.16241065736049126,
      "grad_norm": 0.7385947108268738,
      "learning_rate": 0.0001996957138363267,
      "loss": 2.6754,
      "step": 2420
    },
    {
      "epoch": 0.16308177577933627,
      "grad_norm": 0.7240557074546814,
      "learning_rate": 0.00019969003991248617,
      "loss": 2.61,
      "step": 2430
    },
    {
      "epoch": 0.16375289419818126,
      "grad_norm": 0.7758882641792297,
      "learning_rate": 0.00019968431365838263,
      "loss": 2.5625,
      "step": 2440
    },
    {
      "epoch": 0.16442401261702627,
      "grad_norm": 0.8167327046394348,
      "learning_rate": 0.00019967853507702198,
      "loss": 2.6928,
      "step": 2450
    },
    {
      "epoch": 0.16442401261702627,
      "eval_bleu": 20.736146668210953,
      "eval_gen_len": 28.78,
      "eval_loss": 2.9972078800201416,
      "eval_runtime": 61.0312,
      "eval_samples_per_second": 16.385,
      "eval_steps_per_second": 1.032,
      "step": 2450
    },
    {
      "epoch": 0.16509513103587128,
      "grad_norm": 0.7718505263328552,
      "learning_rate": 0.00019967270417143752,
      "loss": 2.6411,
      "step": 2460
    },
    {
      "epoch": 0.1657662494547163,
      "grad_norm": 0.7447357773780823,
      "learning_rate": 0.00019966682094469014,
      "loss": 2.5679,
      "step": 2470
    },
    {
      "epoch": 0.16643736787356128,
      "grad_norm": 0.7274142503738403,
      "learning_rate": 0.00019966088539986808,
      "loss": 2.5437,
      "step": 2480
    },
    {
      "epoch": 0.1671084862924063,
      "grad_norm": 0.7203602194786072,
      "learning_rate": 0.0001996548975400871,
      "loss": 2.619,
      "step": 2490
    },
    {
      "epoch": 0.1677796047112513,
      "grad_norm": 0.6916893124580383,
      "learning_rate": 0.00019964885736849038,
      "loss": 2.6178,
      "step": 2500
    },
    {
      "epoch": 0.1677796047112513,
      "eval_bleu": 20.26436639443629,
      "eval_gen_len": 28.927,
      "eval_loss": 2.9947988986968994,
      "eval_runtime": 64.1921,
      "eval_samples_per_second": 15.578,
      "eval_steps_per_second": 0.981,
      "step": 2500
    },
    {
      "epoch": 0.16845072313009632,
      "grad_norm": 0.77774578332901,
      "learning_rate": 0.00019964276488824862,
      "loss": 2.6364,
      "step": 2510
    },
    {
      "epoch": 0.1691218415489413,
      "grad_norm": 0.7280966639518738,
      "learning_rate": 0.0001996366201025599,
      "loss": 2.613,
      "step": 2520
    },
    {
      "epoch": 0.16979295996778632,
      "grad_norm": 0.7987455129623413,
      "learning_rate": 0.00019963042301464985,
      "loss": 2.6573,
      "step": 2530
    },
    {
      "epoch": 0.17046407838663133,
      "grad_norm": 0.7608428001403809,
      "learning_rate": 0.00019962417362777147,
      "loss": 2.5773,
      "step": 2540
    },
    {
      "epoch": 0.17113519680547631,
      "grad_norm": 0.743161141872406,
      "learning_rate": 0.00019961787194520527,
      "loss": 2.6155,
      "step": 2550
    },
    {
      "epoch": 0.17113519680547631,
      "eval_bleu": 20.275753082594736,
      "eval_gen_len": 28.678,
      "eval_loss": 3.002073287963867,
      "eval_runtime": 59.9384,
      "eval_samples_per_second": 16.684,
      "eval_steps_per_second": 1.051,
      "step": 2550
    },
    {
      "epoch": 0.17180631522432133,
      "grad_norm": 0.811863899230957,
      "learning_rate": 0.00019961151797025917,
      "loss": 2.6022,
      "step": 2560
    },
    {
      "epoch": 0.17247743364316634,
      "grad_norm": 0.7879582047462463,
      "learning_rate": 0.00019960511170626858,
      "loss": 2.6182,
      "step": 2570
    },
    {
      "epoch": 0.17314855206201135,
      "grad_norm": 0.7388882040977478,
      "learning_rate": 0.00019959865315659632,
      "loss": 2.5964,
      "step": 2580
    },
    {
      "epoch": 0.17381967048085634,
      "grad_norm": 0.8094993233680725,
      "learning_rate": 0.0001995921423246327,
      "loss": 2.6328,
      "step": 2590
    },
    {
      "epoch": 0.17449078889970135,
      "grad_norm": 0.7868372201919556,
      "learning_rate": 0.00019958557921379542,
      "loss": 2.6278,
      "step": 2600
    },
    {
      "epoch": 0.17449078889970135,
      "eval_bleu": 20.761039713723772,
      "eval_gen_len": 28.726,
      "eval_loss": 2.997741222381592,
      "eval_runtime": 60.1128,
      "eval_samples_per_second": 16.635,
      "eval_steps_per_second": 1.048,
      "step": 2600
    },
    {
      "epoch": 0.17516190731854636,
      "grad_norm": 0.7077382206916809,
      "learning_rate": 0.00019957896382752965,
      "loss": 2.5346,
      "step": 2610
    },
    {
      "epoch": 0.17583302573739137,
      "grad_norm": 0.7603703737258911,
      "learning_rate": 0.000199572296169308,
      "loss": 2.5931,
      "step": 2620
    },
    {
      "epoch": 0.17650414415623636,
      "grad_norm": 0.8232329487800598,
      "learning_rate": 0.0001995655762426306,
      "loss": 2.6893,
      "step": 2630
    },
    {
      "epoch": 0.17717526257508137,
      "grad_norm": 0.7509725689888,
      "learning_rate": 0.00019955880405102486,
      "loss": 2.6393,
      "step": 2640
    },
    {
      "epoch": 0.17784638099392638,
      "grad_norm": 0.7308981418609619,
      "learning_rate": 0.0001995519795980457,
      "loss": 2.6421,
      "step": 2650
    },
    {
      "epoch": 0.17784638099392638,
      "eval_bleu": 19.916793123436353,
      "eval_gen_len": 28.674,
      "eval_loss": 3.008622884750366,
      "eval_runtime": 60.1821,
      "eval_samples_per_second": 16.616,
      "eval_steps_per_second": 1.047,
      "step": 2650
    },
    {
      "epoch": 0.1785174994127714,
      "grad_norm": 0.7992612719535828,
      "learning_rate": 0.0001995451028872755,
      "loss": 2.6153,
      "step": 2660
    },
    {
      "epoch": 0.17918861783161638,
      "grad_norm": 0.7198909521102905,
      "learning_rate": 0.00019953817392232405,
      "loss": 2.6399,
      "step": 2670
    },
    {
      "epoch": 0.1798597362504614,
      "grad_norm": 0.8472693562507629,
      "learning_rate": 0.0001995311927068286,
      "loss": 2.6466,
      "step": 2680
    },
    {
      "epoch": 0.1805308546693064,
      "grad_norm": 0.7358072400093079,
      "learning_rate": 0.00019952415924445375,
      "loss": 2.6443,
      "step": 2690
    },
    {
      "epoch": 0.1812019730881514,
      "grad_norm": 0.8042113184928894,
      "learning_rate": 0.0001995170735388916,
      "loss": 2.5987,
      "step": 2700
    },
    {
      "epoch": 0.1812019730881514,
      "eval_bleu": 20.282056708893943,
      "eval_gen_len": 28.616,
      "eval_loss": 2.993335485458374,
      "eval_runtime": 59.9864,
      "eval_samples_per_second": 16.67,
      "eval_steps_per_second": 1.05,
      "step": 2700
    },
    {
      "epoch": 0.1818730915069964,
      "grad_norm": 0.6609035134315491,
      "learning_rate": 0.0001995099355938616,
      "loss": 2.5036,
      "step": 2710
    },
    {
      "epoch": 0.18254420992584142,
      "grad_norm": 0.7263293266296387,
      "learning_rate": 0.00019950274541311077,
      "loss": 2.5917,
      "step": 2720
    },
    {
      "epoch": 0.18321532834468643,
      "grad_norm": 0.7996187210083008,
      "learning_rate": 0.00019949550300041335,
      "loss": 2.5772,
      "step": 2730
    },
    {
      "epoch": 0.1838864467635314,
      "grad_norm": 0.739556610584259,
      "learning_rate": 0.00019948820835957113,
      "loss": 2.5815,
      "step": 2740
    },
    {
      "epoch": 0.18455756518237643,
      "grad_norm": 0.7856312394142151,
      "learning_rate": 0.0001994808614944133,
      "loss": 2.6246,
      "step": 2750
    },
    {
      "epoch": 0.18455756518237643,
      "eval_bleu": 20.204134914814198,
      "eval_gen_len": 28.659,
      "eval_loss": 2.9965031147003174,
      "eval_runtime": 60.3173,
      "eval_samples_per_second": 16.579,
      "eval_steps_per_second": 1.044,
      "step": 2750
    },
    {
      "epoch": 0.18522868360122144,
      "grad_norm": 0.7955170273780823,
      "learning_rate": 0.00019947346240879643,
      "loss": 2.7038,
      "step": 2760
    },
    {
      "epoch": 0.18589980202006645,
      "grad_norm": 0.7082071304321289,
      "learning_rate": 0.00019946601110660452,
      "loss": 2.6304,
      "step": 2770
    },
    {
      "epoch": 0.18657092043891144,
      "grad_norm": 0.7868518829345703,
      "learning_rate": 0.000199458507591749,
      "loss": 2.6214,
      "step": 2780
    },
    {
      "epoch": 0.18724203885775645,
      "grad_norm": 0.7359386682510376,
      "learning_rate": 0.00019945095186816865,
      "loss": 2.5584,
      "step": 2790
    },
    {
      "epoch": 0.18791315727660146,
      "grad_norm": 0.7564102411270142,
      "learning_rate": 0.00019944334393982974,
      "loss": 2.6372,
      "step": 2800
    },
    {
      "epoch": 0.18791315727660146,
      "eval_bleu": 20.500285287144415,
      "eval_gen_len": 28.792,
      "eval_loss": 2.98947811126709,
      "eval_runtime": 60.845,
      "eval_samples_per_second": 16.435,
      "eval_steps_per_second": 1.035,
      "step": 2800
    },
    {
      "epoch": 0.18858427569544647,
      "grad_norm": 0.6991502046585083,
      "learning_rate": 0.00019943568381072585,
      "loss": 2.5857,
      "step": 2810
    },
    {
      "epoch": 0.18925539411429146,
      "grad_norm": 0.6964161992073059,
      "learning_rate": 0.00019942797148487807,
      "loss": 2.5828,
      "step": 2820
    },
    {
      "epoch": 0.18992651253313647,
      "grad_norm": 1.3814386129379272,
      "learning_rate": 0.00019942020696633476,
      "loss": 2.6379,
      "step": 2830
    },
    {
      "epoch": 0.19059763095198148,
      "grad_norm": 0.7528887391090393,
      "learning_rate": 0.0001994123902591718,
      "loss": 2.6245,
      "step": 2840
    },
    {
      "epoch": 0.19126874937082647,
      "grad_norm": 0.749428927898407,
      "learning_rate": 0.0001994045213674924,
      "loss": 2.6525,
      "step": 2850
    },
    {
      "epoch": 0.19126874937082647,
      "eval_bleu": 20.275678182324988,
      "eval_gen_len": 28.587,
      "eval_loss": 2.9895591735839844,
      "eval_runtime": 59.9096,
      "eval_samples_per_second": 16.692,
      "eval_steps_per_second": 1.052,
      "step": 2850
    },
    {
      "epoch": 0.19193986778967148,
      "grad_norm": 0.739234983921051,
      "learning_rate": 0.00019939660029542712,
      "loss": 2.6287,
      "step": 2860
    },
    {
      "epoch": 0.1926109862085165,
      "grad_norm": 0.7865644693374634,
      "learning_rate": 0.00019938862704713405,
      "loss": 2.6546,
      "step": 2870
    },
    {
      "epoch": 0.1932821046273615,
      "grad_norm": 0.7998560070991516,
      "learning_rate": 0.00019938060162679854,
      "loss": 2.6095,
      "step": 2880
    },
    {
      "epoch": 0.1939532230462065,
      "grad_norm": 0.6871066689491272,
      "learning_rate": 0.00019937252403863336,
      "loss": 2.6293,
      "step": 2890
    },
    {
      "epoch": 0.1946243414650515,
      "grad_norm": 0.7228070497512817,
      "learning_rate": 0.00019936439428687872,
      "loss": 2.6262,
      "step": 2900
    },
    {
      "epoch": 0.1946243414650515,
      "eval_bleu": 20.492640074614716,
      "eval_gen_len": 28.604,
      "eval_loss": 2.989865303039551,
      "eval_runtime": 59.7076,
      "eval_samples_per_second": 16.748,
      "eval_steps_per_second": 1.055,
      "step": 2900
    },
    {
      "epoch": 0.19529545988389652,
      "grad_norm": 0.7506971955299377,
      "learning_rate": 0.00019935621237580212,
      "loss": 2.5944,
      "step": 2910
    },
    {
      "epoch": 0.19596657830274153,
      "grad_norm": 0.7142948508262634,
      "learning_rate": 0.00019934797830969852,
      "loss": 2.6059,
      "step": 2920
    },
    {
      "epoch": 0.1966376967215865,
      "grad_norm": 0.7812061309814453,
      "learning_rate": 0.00019933969209289022,
      "loss": 2.6313,
      "step": 2930
    },
    {
      "epoch": 0.19730881514043153,
      "grad_norm": 0.7879235148429871,
      "learning_rate": 0.0001993313537297269,
      "loss": 2.634,
      "step": 2940
    },
    {
      "epoch": 0.19797993355927654,
      "grad_norm": 0.7967762351036072,
      "learning_rate": 0.0001993229632245856,
      "loss": 2.643,
      "step": 2950
    },
    {
      "epoch": 0.19797993355927654,
      "eval_bleu": 20.4111890863338,
      "eval_gen_len": 28.706,
      "eval_loss": 2.9908995628356934,
      "eval_runtime": 59.5127,
      "eval_samples_per_second": 16.803,
      "eval_steps_per_second": 1.059,
      "step": 2950
    },
    {
      "epoch": 0.19865105197812155,
      "grad_norm": 0.7911101579666138,
      "learning_rate": 0.0001993145205818708,
      "loss": 2.597,
      "step": 2960
    },
    {
      "epoch": 0.19932217039696654,
      "grad_norm": 0.7063222527503967,
      "learning_rate": 0.0001993060258060142,
      "loss": 2.6639,
      "step": 2970
    },
    {
      "epoch": 0.19999328881581155,
      "grad_norm": 0.7234312295913696,
      "learning_rate": 0.00019929747890147503,
      "loss": 2.5799,
      "step": 2980
    },
    {
      "epoch": 0.20066440723465656,
      "grad_norm": 0.7516416907310486,
      "learning_rate": 0.0001992888798727398,
      "loss": 2.6162,
      "step": 2990
    },
    {
      "epoch": 0.20133552565350157,
      "grad_norm": 0.7292804718017578,
      "learning_rate": 0.00019928022872432236,
      "loss": 2.6416,
      "step": 3000
    },
    {
      "epoch": 0.20133552565350157,
      "eval_bleu": 20.329120518514756,
      "eval_gen_len": 28.786,
      "eval_loss": 2.9950599670410156,
      "eval_runtime": 60.0126,
      "eval_samples_per_second": 16.663,
      "eval_steps_per_second": 1.05,
      "step": 3000
    },
    {
      "epoch": 0.20200664407234656,
      "grad_norm": 0.7027068138122559,
      "learning_rate": 0.00019927152546076404,
      "loss": 2.5828,
      "step": 3010
    },
    {
      "epoch": 0.20267776249119157,
      "grad_norm": 0.7003584504127502,
      "learning_rate": 0.00019926277008663337,
      "loss": 2.5792,
      "step": 3020
    },
    {
      "epoch": 0.20334888091003658,
      "grad_norm": 0.7630143761634827,
      "learning_rate": 0.00019925396260652632,
      "loss": 2.5635,
      "step": 3030
    },
    {
      "epoch": 0.20401999932888157,
      "grad_norm": 0.8110774755477905,
      "learning_rate": 0.00019924510302506615,
      "loss": 2.6268,
      "step": 3040
    },
    {
      "epoch": 0.20469111774772658,
      "grad_norm": 0.7606729865074158,
      "learning_rate": 0.00019923619134690364,
      "loss": 2.563,
      "step": 3050
    },
    {
      "epoch": 0.20469111774772658,
      "eval_bleu": 20.486712227710715,
      "eval_gen_len": 28.722,
      "eval_loss": 2.9939322471618652,
      "eval_runtime": 60.3008,
      "eval_samples_per_second": 16.584,
      "eval_steps_per_second": 1.045,
      "step": 3050
    },
    {
      "epoch": 0.2053622361665716,
      "grad_norm": 0.7318727374076843,
      "learning_rate": 0.00019922722757671668,
      "loss": 2.6084,
      "step": 3060
    },
    {
      "epoch": 0.2060333545854166,
      "grad_norm": 0.7457121014595032,
      "learning_rate": 0.0001992182117192107,
      "loss": 2.6272,
      "step": 3070
    },
    {
      "epoch": 0.2067044730042616,
      "grad_norm": 0.7835901975631714,
      "learning_rate": 0.00019920914377911833,
      "loss": 2.5905,
      "step": 3080
    },
    {
      "epoch": 0.2073755914231066,
      "grad_norm": 0.7500843405723572,
      "learning_rate": 0.00019920002376119965,
      "loss": 2.6352,
      "step": 3090
    },
    {
      "epoch": 0.20804670984195162,
      "grad_norm": 0.6968700289726257,
      "learning_rate": 0.00019919085167024198,
      "loss": 2.5946,
      "step": 3100
    },
    {
      "epoch": 0.20804670984195162,
      "eval_bleu": 20.604428525950155,
      "eval_gen_len": 28.617,
      "eval_loss": 2.9924628734588623,
      "eval_runtime": 59.0421,
      "eval_samples_per_second": 16.937,
      "eval_steps_per_second": 1.067,
      "step": 3100
    },
    {
      "epoch": 0.20871782826079663,
      "grad_norm": 0.7831801176071167,
      "learning_rate": 0.00019918162751106003,
      "loss": 2.6542,
      "step": 3110
    },
    {
      "epoch": 0.2093889466796416,
      "grad_norm": 0.7096216082572937,
      "learning_rate": 0.00019917235128849586,
      "loss": 2.5738,
      "step": 3120
    },
    {
      "epoch": 0.21006006509848663,
      "grad_norm": 0.7555150985717773,
      "learning_rate": 0.00019916302300741884,
      "loss": 2.6688,
      "step": 3130
    },
    {
      "epoch": 0.21073118351733164,
      "grad_norm": 0.7689664959907532,
      "learning_rate": 0.00019915364267272567,
      "loss": 2.6235,
      "step": 3140
    },
    {
      "epoch": 0.21140230193617665,
      "grad_norm": 0.7312436699867249,
      "learning_rate": 0.0001991442102893403,
      "loss": 2.6001,
      "step": 3150
    },
    {
      "epoch": 0.21140230193617665,
      "eval_bleu": 20.578765664295766,
      "eval_gen_len": 28.711,
      "eval_loss": 2.993058919906616,
      "eval_runtime": 60.701,
      "eval_samples_per_second": 16.474,
      "eval_steps_per_second": 1.038,
      "step": 3150
    },
    {
      "epoch": 0.21207342035502164,
      "grad_norm": 0.7479978203773499,
      "learning_rate": 0.00019913472586221412,
      "loss": 2.5944,
      "step": 3160
    },
    {
      "epoch": 0.21274453877386665,
      "grad_norm": 0.6799353957176208,
      "learning_rate": 0.0001991251893963258,
      "loss": 2.5862,
      "step": 3170
    },
    {
      "epoch": 0.21341565719271166,
      "grad_norm": 0.6981016397476196,
      "learning_rate": 0.0001991156008966813,
      "loss": 2.5568,
      "step": 3180
    },
    {
      "epoch": 0.21408677561155665,
      "grad_norm": 0.7144182324409485,
      "learning_rate": 0.00019910596036831388,
      "loss": 2.571,
      "step": 3190
    },
    {
      "epoch": 0.21475789403040166,
      "grad_norm": 0.7312679886817932,
      "learning_rate": 0.00019909626781628416,
      "loss": 2.5747,
      "step": 3200
    },
    {
      "epoch": 0.21475789403040166,
      "eval_bleu": 20.821320281334987,
      "eval_gen_len": 28.607,
      "eval_loss": 2.991034984588623,
      "eval_runtime": 60.0486,
      "eval_samples_per_second": 16.653,
      "eval_steps_per_second": 1.049,
      "step": 3200
    },
    {
      "epoch": 0.21542901244924667,
      "grad_norm": 0.8077501654624939,
      "learning_rate": 0.00019908652324568009,
      "loss": 2.6245,
      "step": 3210
    },
    {
      "epoch": 0.21610013086809168,
      "grad_norm": 0.7479832768440247,
      "learning_rate": 0.0001990767266616168,
      "loss": 2.6358,
      "step": 3220
    },
    {
      "epoch": 0.21677124928693667,
      "grad_norm": 0.6941120028495789,
      "learning_rate": 0.0001990668780692369,
      "loss": 2.5628,
      "step": 3230
    },
    {
      "epoch": 0.21744236770578168,
      "grad_norm": 0.7294138073921204,
      "learning_rate": 0.0001990569774737101,
      "loss": 2.5978,
      "step": 3240
    },
    {
      "epoch": 0.2181134861246267,
      "grad_norm": 0.7840386033058167,
      "learning_rate": 0.00019904702488023364,
      "loss": 2.6936,
      "step": 3250
    },
    {
      "epoch": 0.2181134861246267,
      "eval_bleu": 20.643770750761803,
      "eval_gen_len": 28.728,
      "eval_loss": 2.9913668632507324,
      "eval_runtime": 60.0521,
      "eval_samples_per_second": 16.652,
      "eval_steps_per_second": 1.049,
      "step": 3250
    },
    {
      "epoch": 0.2187846045434717,
      "grad_norm": 0.7697552442550659,
      "learning_rate": 0.00019903702029403183,
      "loss": 2.6189,
      "step": 3260
    },
    {
      "epoch": 0.2194557229623167,
      "grad_norm": 0.7429506778717041,
      "learning_rate": 0.00019902696372035643,
      "loss": 2.6256,
      "step": 3270
    },
    {
      "epoch": 0.2201268413811617,
      "grad_norm": 0.7085646390914917,
      "learning_rate": 0.00019901685516448642,
      "loss": 2.6228,
      "step": 3280
    },
    {
      "epoch": 0.22079795980000672,
      "grad_norm": 0.7059530019760132,
      "learning_rate": 0.00019900669463172809,
      "loss": 2.6408,
      "step": 3290
    },
    {
      "epoch": 0.22146907821885173,
      "grad_norm": 0.7007046341896057,
      "learning_rate": 0.00019899648212741498,
      "loss": 2.6313,
      "step": 3300
    },
    {
      "epoch": 0.22146907821885173,
      "eval_bleu": 20.824129787405234,
      "eval_gen_len": 28.751,
      "eval_loss": 2.9877641201019287,
      "eval_runtime": 60.2656,
      "eval_samples_per_second": 16.593,
      "eval_steps_per_second": 1.045,
      "step": 3300
    },
    {
      "epoch": 0.2221401966376967,
      "grad_norm": 0.7350589036941528,
      "learning_rate": 0.00019898621765690794,
      "loss": 2.5841,
      "step": 3310
    },
    {
      "epoch": 0.22281131505654173,
      "grad_norm": 0.7823600769042969,
      "learning_rate": 0.00019897590122559513,
      "loss": 2.6295,
      "step": 3320
    },
    {
      "epoch": 0.22348243347538674,
      "grad_norm": 0.688605010509491,
      "learning_rate": 0.0001989655328388919,
      "loss": 2.6218,
      "step": 3330
    },
    {
      "epoch": 0.22415355189423175,
      "grad_norm": 0.6944583058357239,
      "learning_rate": 0.00019895511250224098,
      "loss": 2.554,
      "step": 3340
    },
    {
      "epoch": 0.22482467031307674,
      "grad_norm": 0.7143927216529846,
      "learning_rate": 0.0001989446402211123,
      "loss": 2.5867,
      "step": 3350
    },
    {
      "epoch": 0.22482467031307674,
      "eval_bleu": 20.34841268355813,
      "eval_gen_len": 28.541,
      "eval_loss": 2.9942820072174072,
      "eval_runtime": 59.5605,
      "eval_samples_per_second": 16.79,
      "eval_steps_per_second": 1.058,
      "step": 3350
    },
    {
      "epoch": 0.22549578873192175,
      "grad_norm": 0.7471349239349365,
      "learning_rate": 0.00019893411600100305,
      "loss": 2.6148,
      "step": 3360
    },
    {
      "epoch": 0.22616690715076676,
      "grad_norm": 0.7054682374000549,
      "learning_rate": 0.00019892353984743771,
      "loss": 2.6273,
      "step": 3370
    },
    {
      "epoch": 0.22683802556961175,
      "grad_norm": 0.7677162289619446,
      "learning_rate": 0.00019891291176596802,
      "loss": 2.6126,
      "step": 3380
    },
    {
      "epoch": 0.22750914398845676,
      "grad_norm": 0.6947832107543945,
      "learning_rate": 0.00019890223176217297,
      "loss": 2.6005,
      "step": 3390
    },
    {
      "epoch": 0.22818026240730177,
      "grad_norm": 0.7461768388748169,
      "learning_rate": 0.00019889149984165884,
      "loss": 2.6123,
      "step": 3400
    },
    {
      "epoch": 0.22818026240730177,
      "eval_bleu": 20.408676339405297,
      "eval_gen_len": 29.024,
      "eval_loss": 2.9874989986419678,
      "eval_runtime": 63.6453,
      "eval_samples_per_second": 15.712,
      "eval_steps_per_second": 0.99,
      "step": 3400
    },
    {
      "epoch": 0.22885138082614678,
      "grad_norm": 0.7306861877441406,
      "learning_rate": 0.0001988807160100591,
      "loss": 2.6082,
      "step": 3410
    },
    {
      "epoch": 0.22952249924499177,
      "grad_norm": 0.7164007425308228,
      "learning_rate": 0.00019886988027303451,
      "loss": 2.5758,
      "step": 3420
    },
    {
      "epoch": 0.23019361766383678,
      "grad_norm": 0.6863749027252197,
      "learning_rate": 0.0001988589926362731,
      "loss": 2.5973,
      "step": 3430
    },
    {
      "epoch": 0.2308647360826818,
      "grad_norm": 0.7177653312683105,
      "learning_rate": 0.00019884805310549006,
      "loss": 2.6512,
      "step": 3440
    },
    {
      "epoch": 0.2315358545015268,
      "grad_norm": 0.7030311822891235,
      "learning_rate": 0.00019883706168642793,
      "loss": 2.6259,
      "step": 3450
    },
    {
      "epoch": 0.2315358545015268,
      "eval_bleu": 20.86641862790853,
      "eval_gen_len": 28.71,
      "eval_loss": 2.9851601123809814,
      "eval_runtime": 59.9337,
      "eval_samples_per_second": 16.685,
      "eval_steps_per_second": 1.051,
      "step": 3450
    },
    {
      "epoch": 0.2322069729203718,
      "grad_norm": 0.7318644523620605,
      "learning_rate": 0.0001988260183848564,
      "loss": 2.5869,
      "step": 3460
    },
    {
      "epoch": 0.2328780913392168,
      "grad_norm": 0.7161346077919006,
      "learning_rate": 0.00019881492320657243,
      "loss": 2.6165,
      "step": 3470
    },
    {
      "epoch": 0.23354920975806182,
      "grad_norm": 0.7905128598213196,
      "learning_rate": 0.0001988037761574002,
      "loss": 2.6026,
      "step": 3480
    },
    {
      "epoch": 0.23422032817690683,
      "grad_norm": 0.7151086330413818,
      "learning_rate": 0.00019879257724319117,
      "loss": 2.5719,
      "step": 3490
    },
    {
      "epoch": 0.2348914465957518,
      "grad_norm": 0.7127346992492676,
      "learning_rate": 0.00019878132646982392,
      "loss": 2.6105,
      "step": 3500
    },
    {
      "epoch": 0.2348914465957518,
      "eval_bleu": 20.695532280011328,
      "eval_gen_len": 28.879,
      "eval_loss": 2.9882609844207764,
      "eval_runtime": 63.5152,
      "eval_samples_per_second": 15.744,
      "eval_steps_per_second": 0.992,
      "step": 3500
    },
    {
      "epoch": 0.23556256501459683,
      "grad_norm": 0.7545278072357178,
      "learning_rate": 0.00019877002384320437,
      "loss": 2.5669,
      "step": 3510
    },
    {
      "epoch": 0.23623368343344184,
      "grad_norm": 0.7338562607765198,
      "learning_rate": 0.00019875866936926558,
      "loss": 2.6523,
      "step": 3520
    },
    {
      "epoch": 0.23690480185228682,
      "grad_norm": 0.731262743473053,
      "learning_rate": 0.00019874726305396786,
      "loss": 2.6184,
      "step": 3530
    },
    {
      "epoch": 0.23757592027113184,
      "grad_norm": 0.7975136041641235,
      "learning_rate": 0.0001987358049032987,
      "loss": 2.5807,
      "step": 3540
    },
    {
      "epoch": 0.23824703868997685,
      "grad_norm": 0.7986760139465332,
      "learning_rate": 0.00019872429492327287,
      "loss": 2.6258,
      "step": 3550
    },
    {
      "epoch": 0.23824703868997685,
      "eval_bleu": 20.847383100500185,
      "eval_gen_len": 28.754,
      "eval_loss": 2.9861347675323486,
      "eval_runtime": 60.3747,
      "eval_samples_per_second": 16.563,
      "eval_steps_per_second": 1.043,
      "step": 3550
    },
    {
      "epoch": 0.23891815710882186,
      "grad_norm": 0.6585221290588379,
      "learning_rate": 0.00019871273311993222,
      "loss": 2.6227,
      "step": 3560
    },
    {
      "epoch": 0.23958927552766685,
      "grad_norm": 0.7351182103157043,
      "learning_rate": 0.00019870111949934599,
      "loss": 2.588,
      "step": 3570
    },
    {
      "epoch": 0.24026039394651186,
      "grad_norm": 0.7631537318229675,
      "learning_rate": 0.00019868945406761044,
      "loss": 2.6382,
      "step": 3580
    },
    {
      "epoch": 0.24093151236535687,
      "grad_norm": 0.7342894673347473,
      "learning_rate": 0.0001986777368308491,
      "loss": 2.6278,
      "step": 3590
    },
    {
      "epoch": 0.24160263078420188,
      "grad_norm": 0.7784115076065063,
      "learning_rate": 0.00019866596779521273,
      "loss": 2.6189,
      "step": 3600
    },
    {
      "epoch": 0.24160263078420188,
      "eval_bleu": 20.535797277910117,
      "eval_gen_len": 28.856,
      "eval_loss": 2.99468994140625,
      "eval_runtime": 63.2794,
      "eval_samples_per_second": 15.803,
      "eval_steps_per_second": 0.996,
      "step": 3600
    },
    {
      "epoch": 0.24227374920304687,
      "grad_norm": 0.6975091695785522,
      "learning_rate": 0.00019865414696687922,
      "loss": 2.6358,
      "step": 3610
    },
    {
      "epoch": 0.24294486762189188,
      "grad_norm": 0.705864667892456,
      "learning_rate": 0.0001986422743520537,
      "loss": 2.6429,
      "step": 3620
    },
    {
      "epoch": 0.2436159860407369,
      "grad_norm": 0.7143750190734863,
      "learning_rate": 0.00019863034995696847,
      "loss": 2.6143,
      "step": 3630
    },
    {
      "epoch": 0.2442871044595819,
      "grad_norm": 0.7491647005081177,
      "learning_rate": 0.00019861837378788293,
      "loss": 2.5633,
      "step": 3640
    },
    {
      "epoch": 0.2449582228784269,
      "grad_norm": 0.803781270980835,
      "learning_rate": 0.0001986063458510838,
      "loss": 2.5477,
      "step": 3650
    },
    {
      "epoch": 0.2449582228784269,
      "eval_bleu": 20.24263655717394,
      "eval_gen_len": 28.583,
      "eval_loss": 2.9967803955078125,
      "eval_runtime": 59.9095,
      "eval_samples_per_second": 16.692,
      "eval_steps_per_second": 1.052,
      "step": 3650
    },
    {
      "epoch": 0.2456293412972719,
      "grad_norm": 0.7342158555984497,
      "learning_rate": 0.00019859426615288488,
      "loss": 2.5346,
      "step": 3660
    },
    {
      "epoch": 0.24630045971611692,
      "grad_norm": 0.7307527661323547,
      "learning_rate": 0.00019858213469962712,
      "loss": 2.5911,
      "step": 3670
    },
    {
      "epoch": 0.24697157813496193,
      "grad_norm": 0.7691668272018433,
      "learning_rate": 0.00019856995149767875,
      "loss": 2.5868,
      "step": 3680
    },
    {
      "epoch": 0.2476426965538069,
      "grad_norm": 0.7135769128799438,
      "learning_rate": 0.00019855771655343503,
      "loss": 2.6138,
      "step": 3690
    },
    {
      "epoch": 0.24831381497265193,
      "grad_norm": 0.7178957462310791,
      "learning_rate": 0.00019854542987331848,
      "loss": 2.5552,
      "step": 3700
    },
    {
      "epoch": 0.24831381497265193,
      "eval_bleu": 20.821297411407215,
      "eval_gen_len": 28.818,
      "eval_loss": 2.979572296142578,
      "eval_runtime": 60.7174,
      "eval_samples_per_second": 16.47,
      "eval_steps_per_second": 1.038,
      "step": 3700
    },
    {
      "epoch": 0.24898493339149694,
      "grad_norm": 0.6645212769508362,
      "learning_rate": 0.00019853309146377878,
      "loss": 2.6,
      "step": 3710
    },
    {
      "epoch": 0.24965605181034192,
      "grad_norm": 0.655619204044342,
      "learning_rate": 0.00019852070133129265,
      "loss": 2.6127,
      "step": 3720
    },
    {
      "epoch": 0.25032717022918693,
      "grad_norm": 0.7197704315185547,
      "learning_rate": 0.00019850825948236405,
      "loss": 2.5671,
      "step": 3730
    },
    {
      "epoch": 0.2509982886480319,
      "grad_norm": 0.6834465265274048,
      "learning_rate": 0.00019849576592352412,
      "loss": 2.6043,
      "step": 3740
    },
    {
      "epoch": 0.25166940706687696,
      "grad_norm": 0.7599366903305054,
      "learning_rate": 0.0001984832206613311,
      "loss": 2.5865,
      "step": 3750
    },
    {
      "epoch": 0.25166940706687696,
      "eval_bleu": 21.010978992156538,
      "eval_gen_len": 28.748,
      "eval_loss": 2.974825859069824,
      "eval_runtime": 61.0775,
      "eval_samples_per_second": 16.373,
      "eval_steps_per_second": 1.031,
      "step": 3750
    },
    {
      "epoch": 0.25234052548572194,
      "grad_norm": 0.7256234884262085,
      "learning_rate": 0.00019847062370237034,
      "loss": 2.5858,
      "step": 3760
    },
    {
      "epoch": 0.253011643904567,
      "grad_norm": 0.719427764415741,
      "learning_rate": 0.00019845797505325437,
      "loss": 2.5777,
      "step": 3770
    },
    {
      "epoch": 0.25368276232341197,
      "grad_norm": 0.7547644376754761,
      "learning_rate": 0.00019844527472062283,
      "loss": 2.6306,
      "step": 3780
    },
    {
      "epoch": 0.25435388074225695,
      "grad_norm": 0.702033281326294,
      "learning_rate": 0.00019843252271114253,
      "loss": 2.6169,
      "step": 3790
    },
    {
      "epoch": 0.255024999161102,
      "grad_norm": 0.7940483689308167,
      "learning_rate": 0.00019841971903150735,
      "loss": 2.5892,
      "step": 3800
    },
    {
      "epoch": 0.255024999161102,
      "eval_bleu": 21.078113167227823,
      "eval_gen_len": 28.727,
      "eval_loss": 2.981746196746826,
      "eval_runtime": 60.4764,
      "eval_samples_per_second": 16.535,
      "eval_steps_per_second": 1.042,
      "step": 3800
    },
    {
      "epoch": 0.255696117579947,
      "grad_norm": 0.7176576852798462,
      "learning_rate": 0.00019840686368843832,
      "loss": 2.6153,
      "step": 3810
    },
    {
      "epoch": 0.25636723599879196,
      "grad_norm": 0.7290921807289124,
      "learning_rate": 0.00019839395668868365,
      "loss": 2.5708,
      "step": 3820
    },
    {
      "epoch": 0.257038354417637,
      "grad_norm": 0.7512289881706238,
      "learning_rate": 0.00019838099803901852,
      "loss": 2.4992,
      "step": 3830
    },
    {
      "epoch": 0.257709472836482,
      "grad_norm": 0.7290319204330444,
      "learning_rate": 0.00019836798774624536,
      "loss": 2.5824,
      "step": 3840
    },
    {
      "epoch": 0.25838059125532703,
      "grad_norm": 0.6957743167877197,
      "learning_rate": 0.00019835492581719367,
      "loss": 2.6077,
      "step": 3850
    },
    {
      "epoch": 0.25838059125532703,
      "eval_bleu": 20.928206278506554,
      "eval_gen_len": 28.766,
      "eval_loss": 2.977318525314331,
      "eval_runtime": 60.5126,
      "eval_samples_per_second": 16.525,
      "eval_steps_per_second": 1.041,
      "step": 3850
    },
    {
      "epoch": 0.259051709674172,
      "grad_norm": 0.7746332883834839,
      "learning_rate": 0.00019834181225872,
      "loss": 2.6033,
      "step": 3860
    },
    {
      "epoch": 0.259722828093017,
      "grad_norm": 0.7083954215049744,
      "learning_rate": 0.0001983286470777081,
      "loss": 2.6181,
      "step": 3870
    },
    {
      "epoch": 0.26039394651186204,
      "grad_norm": 0.6988908648490906,
      "learning_rate": 0.0001983154302810687,
      "loss": 2.5547,
      "step": 3880
    },
    {
      "epoch": 0.261065064930707,
      "grad_norm": 0.7001622319221497,
      "learning_rate": 0.00019830216187573975,
      "loss": 2.6315,
      "step": 3890
    },
    {
      "epoch": 0.261736183349552,
      "grad_norm": 0.7418914437294006,
      "learning_rate": 0.00019828884186868622,
      "loss": 2.6098,
      "step": 3900
    },
    {
      "epoch": 0.261736183349552,
      "eval_bleu": 20.271667521506878,
      "eval_gen_len": 28.606,
      "eval_loss": 2.987474203109741,
      "eval_runtime": 59.9834,
      "eval_samples_per_second": 16.671,
      "eval_steps_per_second": 1.05,
      "step": 3900
    },
    {
      "epoch": 0.26240730176839705,
      "grad_norm": 0.7359031438827515,
      "learning_rate": 0.00019827547026690014,
      "loss": 2.5393,
      "step": 3910
    },
    {
      "epoch": 0.26307842018724203,
      "grad_norm": 0.6781796216964722,
      "learning_rate": 0.00019826204707740067,
      "loss": 2.6069,
      "step": 3920
    },
    {
      "epoch": 0.263749538606087,
      "grad_norm": 0.7102953791618347,
      "learning_rate": 0.0001982485723072341,
      "loss": 2.5949,
      "step": 3930
    },
    {
      "epoch": 0.26442065702493206,
      "grad_norm": 0.682923436164856,
      "learning_rate": 0.00019823504596347367,
      "loss": 2.5746,
      "step": 3940
    },
    {
      "epoch": 0.26509177544377704,
      "grad_norm": 0.7350333333015442,
      "learning_rate": 0.00019822146805321977,
      "loss": 2.5847,
      "step": 3950
    },
    {
      "epoch": 0.26509177544377704,
      "eval_bleu": 20.76286724156936,
      "eval_gen_len": 28.632,
      "eval_loss": 2.984022855758667,
      "eval_runtime": 60.4276,
      "eval_samples_per_second": 16.549,
      "eval_steps_per_second": 1.043,
      "step": 3950
    },
    {
      "epoch": 0.2657628938626221,
      "grad_norm": 0.7070503234863281,
      "learning_rate": 0.00019820783858359988,
      "loss": 2.6332,
      "step": 3960
    },
    {
      "epoch": 0.26643401228146707,
      "grad_norm": 0.7186373472213745,
      "learning_rate": 0.00019819415756176846,
      "loss": 2.5967,
      "step": 3970
    },
    {
      "epoch": 0.26710513070031205,
      "grad_norm": 0.695643424987793,
      "learning_rate": 0.00019818042499490716,
      "loss": 2.6226,
      "step": 3980
    },
    {
      "epoch": 0.2677762491191571,
      "grad_norm": 0.7184262871742249,
      "learning_rate": 0.00019816664089022457,
      "loss": 2.6114,
      "step": 3990
    },
    {
      "epoch": 0.2684473675380021,
      "grad_norm": 0.6552141308784485,
      "learning_rate": 0.00019815280525495635,
      "loss": 2.5992,
      "step": 4000
    },
    {
      "epoch": 0.2684473675380021,
      "eval_bleu": 20.773204284935517,
      "eval_gen_len": 28.627,
      "eval_loss": 2.9770257472991943,
      "eval_runtime": 59.4688,
      "eval_samples_per_second": 16.816,
      "eval_steps_per_second": 1.059,
      "step": 4000
    },
    {
      "epoch": 0.26911848595684706,
      "grad_norm": 0.7569146156311035,
      "learning_rate": 0.00019813891809636525,
      "loss": 2.5984,
      "step": 4010
    },
    {
      "epoch": 0.2697896043756921,
      "grad_norm": 0.74873948097229,
      "learning_rate": 0.0001981249794217411,
      "loss": 2.6435,
      "step": 4020
    },
    {
      "epoch": 0.2704607227945371,
      "grad_norm": 0.6649028658866882,
      "learning_rate": 0.00019811098923840068,
      "loss": 2.5736,
      "step": 4030
    },
    {
      "epoch": 0.2711318412133821,
      "grad_norm": 0.737966775894165,
      "learning_rate": 0.00019809694755368787,
      "loss": 2.6172,
      "step": 4040
    },
    {
      "epoch": 0.2718029596322271,
      "grad_norm": 0.7679627537727356,
      "learning_rate": 0.00019808285437497352,
      "loss": 2.5889,
      "step": 4050
    },
    {
      "epoch": 0.2718029596322271,
      "eval_bleu": 20.898853332508953,
      "eval_gen_len": 28.856,
      "eval_loss": 2.9751901626586914,
      "eval_runtime": 60.331,
      "eval_samples_per_second": 16.575,
      "eval_steps_per_second": 1.044,
      "step": 4050
    },
    {
      "epoch": 0.2724740780510721,
      "grad_norm": 0.764166533946991,
      "learning_rate": 0.00019806870970965563,
      "loss": 2.5753,
      "step": 4060
    },
    {
      "epoch": 0.27314519646991714,
      "grad_norm": 0.7436963319778442,
      "learning_rate": 0.00019805451356515912,
      "loss": 2.5795,
      "step": 4070
    },
    {
      "epoch": 0.2738163148887621,
      "grad_norm": 0.6859549283981323,
      "learning_rate": 0.000198040265948936,
      "loss": 2.5704,
      "step": 4080
    },
    {
      "epoch": 0.2744874333076071,
      "grad_norm": 0.7264612317085266,
      "learning_rate": 0.00019802596686846518,
      "loss": 2.6388,
      "step": 4090
    },
    {
      "epoch": 0.27515855172645215,
      "grad_norm": 0.7324177622795105,
      "learning_rate": 0.00019801161633125274,
      "loss": 2.6069,
      "step": 4100
    },
    {
      "epoch": 0.27515855172645215,
      "eval_bleu": 20.687484019602877,
      "eval_gen_len": 28.644,
      "eval_loss": 2.9858946800231934,
      "eval_runtime": 59.5966,
      "eval_samples_per_second": 16.779,
      "eval_steps_per_second": 1.057,
      "step": 4100
    },
    {
      "epoch": 0.27582967014529713,
      "grad_norm": 0.765762448310852,
      "learning_rate": 0.0001979972143448317,
      "loss": 2.583,
      "step": 4110
    },
    {
      "epoch": 0.2765007885641421,
      "grad_norm": 0.6992439031600952,
      "learning_rate": 0.0001979827609167621,
      "loss": 2.5769,
      "step": 4120
    },
    {
      "epoch": 0.27717190698298716,
      "grad_norm": 0.6172285079956055,
      "learning_rate": 0.00019796825605463095,
      "loss": 2.5416,
      "step": 4130
    },
    {
      "epoch": 0.27784302540183214,
      "grad_norm": 0.7197881937026978,
      "learning_rate": 0.00019795369976605227,
      "loss": 2.5693,
      "step": 4140
    },
    {
      "epoch": 0.2785141438206772,
      "grad_norm": 0.767930269241333,
      "learning_rate": 0.00019793909205866712,
      "loss": 2.6368,
      "step": 4150
    },
    {
      "epoch": 0.2785141438206772,
      "eval_bleu": 20.535541695778694,
      "eval_gen_len": 28.648,
      "eval_loss": 2.9790761470794678,
      "eval_runtime": 60.3854,
      "eval_samples_per_second": 16.56,
      "eval_steps_per_second": 1.043,
      "step": 4150
    },
    {
      "epoch": 0.27918526223952217,
      "grad_norm": 0.8649194836616516,
      "learning_rate": 0.00019792443294014352,
      "loss": 2.6402,
      "step": 4160
    },
    {
      "epoch": 0.27985638065836715,
      "grad_norm": 0.7718081474304199,
      "learning_rate": 0.00019790972241817643,
      "loss": 2.6137,
      "step": 4170
    },
    {
      "epoch": 0.2805274990772122,
      "grad_norm": 0.6718665957450867,
      "learning_rate": 0.0001978949605004879,
      "loss": 2.5673,
      "step": 4180
    },
    {
      "epoch": 0.2811986174960572,
      "grad_norm": 0.6910493969917297,
      "learning_rate": 0.00019788014719482688,
      "loss": 2.5479,
      "step": 4190
    },
    {
      "epoch": 0.28186973591490216,
      "grad_norm": 0.7278178334236145,
      "learning_rate": 0.0001978652825089693,
      "loss": 2.5149,
      "step": 4200
    },
    {
      "epoch": 0.28186973591490216,
      "eval_bleu": 20.849105078435063,
      "eval_gen_len": 28.693,
      "eval_loss": 2.9811785221099854,
      "eval_runtime": 60.7509,
      "eval_samples_per_second": 16.461,
      "eval_steps_per_second": 1.037,
      "step": 4200
    },
    {
      "epoch": 0.2825408543337472,
      "grad_norm": 0.7230704426765442,
      "learning_rate": 0.00019785036645071806,
      "loss": 2.6096,
      "step": 4210
    },
    {
      "epoch": 0.2832119727525922,
      "grad_norm": 0.8252542018890381,
      "learning_rate": 0.00019783539902790308,
      "loss": 2.5612,
      "step": 4220
    },
    {
      "epoch": 0.2838830911714372,
      "grad_norm": 0.7365025281906128,
      "learning_rate": 0.00019782038024838118,
      "loss": 2.5909,
      "step": 4230
    },
    {
      "epoch": 0.2845542095902822,
      "grad_norm": 0.6902940273284912,
      "learning_rate": 0.0001978053101200362,
      "loss": 2.6334,
      "step": 4240
    },
    {
      "epoch": 0.2852253280091272,
      "grad_norm": 0.7014371156692505,
      "learning_rate": 0.00019779018865077882,
      "loss": 2.6083,
      "step": 4250
    },
    {
      "epoch": 0.2852253280091272,
      "eval_bleu": 20.91862940471508,
      "eval_gen_len": 28.616,
      "eval_loss": 2.9804203510284424,
      "eval_runtime": 59.3328,
      "eval_samples_per_second": 16.854,
      "eval_steps_per_second": 1.062,
      "step": 4250
    },
    {
      "epoch": 0.28589644642797224,
      "grad_norm": 0.7423205971717834,
      "learning_rate": 0.00019777501584854686,
      "loss": 2.6341,
      "step": 4260
    },
    {
      "epoch": 0.2865675648468172,
      "grad_norm": 0.7407596111297607,
      "learning_rate": 0.00019775979172130488,
      "loss": 2.5943,
      "step": 4270
    },
    {
      "epoch": 0.2872386832656622,
      "grad_norm": 0.788908064365387,
      "learning_rate": 0.00019774451627704452,
      "loss": 2.6095,
      "step": 4280
    },
    {
      "epoch": 0.28790980168450725,
      "grad_norm": 0.7252932190895081,
      "learning_rate": 0.00019772918952378428,
      "loss": 2.5718,
      "step": 4290
    },
    {
      "epoch": 0.28858092010335223,
      "grad_norm": 0.7461588382720947,
      "learning_rate": 0.00019771381146956968,
      "loss": 2.5263,
      "step": 4300
    },
    {
      "epoch": 0.28858092010335223,
      "eval_bleu": 20.897896490757784,
      "eval_gen_len": 28.736,
      "eval_loss": 2.9804580211639404,
      "eval_runtime": 59.5429,
      "eval_samples_per_second": 16.795,
      "eval_steps_per_second": 1.058,
      "step": 4300
    },
    {
      "epoch": 0.2892520385221972,
      "grad_norm": 0.7202906608581543,
      "learning_rate": 0.00019769838212247307,
      "loss": 2.5483,
      "step": 4310
    },
    {
      "epoch": 0.28992315694104226,
      "grad_norm": 0.7683253884315491,
      "learning_rate": 0.0001976829014905938,
      "loss": 2.6038,
      "step": 4320
    },
    {
      "epoch": 0.29059427535988724,
      "grad_norm": 0.6668274998664856,
      "learning_rate": 0.0001976673695820581,
      "loss": 2.5587,
      "step": 4330
    },
    {
      "epoch": 0.2912653937787323,
      "grad_norm": 0.6689532399177551,
      "learning_rate": 0.00019765178640501917,
      "loss": 2.5964,
      "step": 4340
    },
    {
      "epoch": 0.29193651219757727,
      "grad_norm": 0.7391462922096252,
      "learning_rate": 0.00019763615196765702,
      "loss": 2.561,
      "step": 4350
    },
    {
      "epoch": 0.29193651219757727,
      "eval_bleu": 20.007556200241353,
      "eval_gen_len": 28.464,
      "eval_loss": 3.012956142425537,
      "eval_runtime": 59.0105,
      "eval_samples_per_second": 16.946,
      "eval_steps_per_second": 1.068,
      "step": 4350
    },
    {
      "epoch": 0.29260763061642225,
      "grad_norm": 0.7144589424133301,
      "learning_rate": 0.00019762046627817866,
      "loss": 2.6131,
      "step": 4360
    },
    {
      "epoch": 0.2932787490352673,
      "grad_norm": 0.7078742980957031,
      "learning_rate": 0.00019760472934481795,
      "loss": 2.6304,
      "step": 4370
    },
    {
      "epoch": 0.2939498674541123,
      "grad_norm": 0.7054657340049744,
      "learning_rate": 0.00019758894117583573,
      "loss": 2.5751,
      "step": 4380
    },
    {
      "epoch": 0.29462098587295726,
      "grad_norm": 0.704757809638977,
      "learning_rate": 0.00019757310177951961,
      "loss": 2.563,
      "step": 4390
    },
    {
      "epoch": 0.2952921042918023,
      "grad_norm": 0.7088823914527893,
      "learning_rate": 0.00019755721116418426,
      "loss": 2.5996,
      "step": 4400
    },
    {
      "epoch": 0.2952921042918023,
      "eval_bleu": 21.14596486252808,
      "eval_gen_len": 28.656,
      "eval_loss": 2.978306770324707,
      "eval_runtime": 59.478,
      "eval_samples_per_second": 16.813,
      "eval_steps_per_second": 1.059,
      "step": 4400
    },
    {
      "epoch": 0.2959632227106473,
      "grad_norm": 0.7938721776008606,
      "learning_rate": 0.00019754126933817104,
      "loss": 2.6117,
      "step": 4410
    },
    {
      "epoch": 0.2966343411294923,
      "grad_norm": 0.6967214345932007,
      "learning_rate": 0.00019752527630984828,
      "loss": 2.5984,
      "step": 4420
    },
    {
      "epoch": 0.2973054595483373,
      "grad_norm": 0.7727292776107788,
      "learning_rate": 0.0001975092320876113,
      "loss": 2.5923,
      "step": 4430
    },
    {
      "epoch": 0.2979765779671823,
      "grad_norm": 0.7309204339981079,
      "learning_rate": 0.00019749313667988207,
      "loss": 2.5874,
      "step": 4440
    },
    {
      "epoch": 0.29864769638602734,
      "grad_norm": 0.702807605266571,
      "learning_rate": 0.00019747699009510964,
      "loss": 2.559,
      "step": 4450
    },
    {
      "epoch": 0.29864769638602734,
      "eval_bleu": 21.035160834902264,
      "eval_gen_len": 28.726,
      "eval_loss": 2.978630542755127,
      "eval_runtime": 59.4061,
      "eval_samples_per_second": 16.833,
      "eval_steps_per_second": 1.06,
      "step": 4450
    },
    {
      "epoch": 0.2993188148048723,
      "grad_norm": 0.7231067419052124,
      "learning_rate": 0.00019746079234176977,
      "loss": 2.5756,
      "step": 4460
    },
    {
      "epoch": 0.2999899332237173,
      "grad_norm": 0.7299306988716125,
      "learning_rate": 0.00019744454342836515,
      "loss": 2.5933,
      "step": 4470
    },
    {
      "epoch": 0.30066105164256235,
      "grad_norm": 0.7063997387886047,
      "learning_rate": 0.00019742824336342537,
      "loss": 2.5873,
      "step": 4480
    },
    {
      "epoch": 0.30133217006140733,
      "grad_norm": 0.6692501902580261,
      "learning_rate": 0.00019741189215550676,
      "loss": 2.5657,
      "step": 4490
    },
    {
      "epoch": 0.3020032884802523,
      "grad_norm": 0.700355589389801,
      "learning_rate": 0.00019739548981319259,
      "loss": 2.5503,
      "step": 4500
    },
    {
      "epoch": 0.3020032884802523,
      "eval_bleu": 20.98973079163562,
      "eval_gen_len": 28.72,
      "eval_loss": 2.9744412899017334,
      "eval_runtime": 59.6452,
      "eval_samples_per_second": 16.766,
      "eval_steps_per_second": 1.056,
      "step": 4500
    },
    {
      "epoch": 0.30267440689909736,
      "grad_norm": 0.7293838858604431,
      "learning_rate": 0.00019737903634509292,
      "loss": 2.5224,
      "step": 4510
    },
    {
      "epoch": 0.30334552531794234,
      "grad_norm": 0.6960646510124207,
      "learning_rate": 0.00019736253175984465,
      "loss": 2.5644,
      "step": 4520
    },
    {
      "epoch": 0.30401664373678733,
      "grad_norm": 0.6482838988304138,
      "learning_rate": 0.00019734597606611154,
      "loss": 2.5374,
      "step": 4530
    },
    {
      "epoch": 0.30468776215563237,
      "grad_norm": 0.8153813481330872,
      "learning_rate": 0.00019732936927258418,
      "loss": 2.5733,
      "step": 4540
    },
    {
      "epoch": 0.30535888057447735,
      "grad_norm": 0.7134957909584045,
      "learning_rate": 0.00019731271138797996,
      "loss": 2.6098,
      "step": 4550
    },
    {
      "epoch": 0.30535888057447735,
      "eval_bleu": 20.52354994096926,
      "eval_gen_len": 28.656,
      "eval_loss": 2.9809749126434326,
      "eval_runtime": 59.7656,
      "eval_samples_per_second": 16.732,
      "eval_steps_per_second": 1.054,
      "step": 4550
    },
    {
      "epoch": 0.3060299989933224,
      "grad_norm": 0.7245392203330994,
      "learning_rate": 0.0001972960024210431,
      "loss": 2.6061,
      "step": 4560
    },
    {
      "epoch": 0.3067011174121674,
      "grad_norm": 0.743340790271759,
      "learning_rate": 0.0001972792423805446,
      "loss": 2.5972,
      "step": 4570
    },
    {
      "epoch": 0.30737223583101236,
      "grad_norm": 0.7067209482192993,
      "learning_rate": 0.00019726243127528236,
      "loss": 2.6023,
      "step": 4580
    },
    {
      "epoch": 0.3080433542498574,
      "grad_norm": 0.6920807957649231,
      "learning_rate": 0.000197245569114081,
      "loss": 2.5789,
      "step": 4590
    },
    {
      "epoch": 0.3087144726687024,
      "grad_norm": 0.6902974843978882,
      "learning_rate": 0.00019722865590579195,
      "loss": 2.5901,
      "step": 4600
    },
    {
      "epoch": 0.3087144726687024,
      "eval_bleu": 20.684027270329057,
      "eval_gen_len": 28.566,
      "eval_loss": 2.984848976135254,
      "eval_runtime": 59.1188,
      "eval_samples_per_second": 16.915,
      "eval_steps_per_second": 1.066,
      "step": 4600
    },
    {
      "epoch": 0.3093855910875474,
      "grad_norm": 0.6900456547737122,
      "learning_rate": 0.0001972116916592935,
      "loss": 2.6051,
      "step": 4610
    },
    {
      "epoch": 0.3100567095063924,
      "grad_norm": 0.6614658832550049,
      "learning_rate": 0.00019719467638349068,
      "loss": 2.6135,
      "step": 4620
    },
    {
      "epoch": 0.3107278279252374,
      "grad_norm": 0.7191168069839478,
      "learning_rate": 0.00019717761008731526,
      "loss": 2.5405,
      "step": 4630
    },
    {
      "epoch": 0.31139894634408244,
      "grad_norm": 0.6717041730880737,
      "learning_rate": 0.00019716049277972587,
      "loss": 2.5807,
      "step": 4640
    },
    {
      "epoch": 0.3120700647629274,
      "grad_norm": 0.706214427947998,
      "learning_rate": 0.00019714332446970793,
      "loss": 2.5596,
      "step": 4650
    },
    {
      "epoch": 0.3120700647629274,
      "eval_bleu": 20.932779787043415,
      "eval_gen_len": 28.821,
      "eval_loss": 2.9736456871032715,
      "eval_runtime": 59.5838,
      "eval_samples_per_second": 16.783,
      "eval_steps_per_second": 1.057,
      "step": 4650
    },
    {
      "epoch": 0.3127411831817724,
      "grad_norm": 0.7145355343818665,
      "learning_rate": 0.00019712610516627358,
      "loss": 2.6302,
      "step": 4660
    },
    {
      "epoch": 0.31341230160061745,
      "grad_norm": 0.7328811883926392,
      "learning_rate": 0.00019710883487846173,
      "loss": 2.6107,
      "step": 4670
    },
    {
      "epoch": 0.31408342001946243,
      "grad_norm": 0.6602303385734558,
      "learning_rate": 0.00019709151361533807,
      "loss": 2.5912,
      "step": 4680
    },
    {
      "epoch": 0.3147545384383074,
      "grad_norm": 0.771793782711029,
      "learning_rate": 0.00019707414138599502,
      "loss": 2.5691,
      "step": 4690
    },
    {
      "epoch": 0.31542565685715246,
      "grad_norm": 0.7109788060188293,
      "learning_rate": 0.00019705671819955184,
      "loss": 2.5808,
      "step": 4700
    },
    {
      "epoch": 0.31542565685715246,
      "eval_bleu": 20.631832434315765,
      "eval_gen_len": 28.696,
      "eval_loss": 2.9763479232788086,
      "eval_runtime": 59.9445,
      "eval_samples_per_second": 16.682,
      "eval_steps_per_second": 1.051,
      "step": 4700
    },
    {
      "epoch": 0.31609677527599744,
      "grad_norm": 0.6763365864753723,
      "learning_rate": 0.0001970392440651544,
      "loss": 2.6104,
      "step": 4710
    },
    {
      "epoch": 0.31676789369484243,
      "grad_norm": 0.7036507725715637,
      "learning_rate": 0.0001970217189919755,
      "loss": 2.5293,
      "step": 4720
    },
    {
      "epoch": 0.31743901211368747,
      "grad_norm": 0.6850948333740234,
      "learning_rate": 0.0001970041429892145,
      "loss": 2.6162,
      "step": 4730
    },
    {
      "epoch": 0.31811013053253245,
      "grad_norm": 0.7403717637062073,
      "learning_rate": 0.00019698651606609753,
      "loss": 2.5679,
      "step": 4740
    },
    {
      "epoch": 0.3187812489513775,
      "grad_norm": 0.6761935353279114,
      "learning_rate": 0.00019696883823187755,
      "loss": 2.5046,
      "step": 4750
    },
    {
      "epoch": 0.3187812489513775,
      "eval_bleu": 20.523473031756332,
      "eval_gen_len": 28.679,
      "eval_loss": 2.9806315898895264,
      "eval_runtime": 59.5644,
      "eval_samples_per_second": 16.789,
      "eval_steps_per_second": 1.058,
      "step": 4750
    },
    {
      "epoch": 0.3194523673702225,
      "grad_norm": 0.7618234753608704,
      "learning_rate": 0.00019695110949583414,
      "loss": 2.5733,
      "step": 4760
    },
    {
      "epoch": 0.32012348578906746,
      "grad_norm": 0.6789370775222778,
      "learning_rate": 0.0001969333298672737,
      "loss": 2.5588,
      "step": 4770
    },
    {
      "epoch": 0.3207946042079125,
      "grad_norm": 0.7276270985603333,
      "learning_rate": 0.0001969154993555292,
      "loss": 2.6022,
      "step": 4780
    },
    {
      "epoch": 0.3214657226267575,
      "grad_norm": 0.7130004167556763,
      "learning_rate": 0.00019689761796996052,
      "loss": 2.615,
      "step": 4790
    },
    {
      "epoch": 0.3221368410456025,
      "grad_norm": 0.6937243938446045,
      "learning_rate": 0.000196879685719954,
      "loss": 2.5641,
      "step": 4800
    },
    {
      "epoch": 0.3221368410456025,
      "eval_bleu": 20.490393198023785,
      "eval_gen_len": 28.557,
      "eval_loss": 2.9775948524475098,
      "eval_runtime": 59.1862,
      "eval_samples_per_second": 16.896,
      "eval_steps_per_second": 1.064,
      "step": 4800
    },
    {
      "epoch": 0.3228079594644475,
      "grad_norm": 0.7431281805038452,
      "learning_rate": 0.00019686170261492286,
      "loss": 2.6573,
      "step": 4810
    },
    {
      "epoch": 0.3234790778832925,
      "grad_norm": 0.7708145380020142,
      "learning_rate": 0.00019684366866430702,
      "loss": 2.6364,
      "step": 4820
    },
    {
      "epoch": 0.32415019630213754,
      "grad_norm": 0.729075014591217,
      "learning_rate": 0.000196825583877573,
      "loss": 2.5765,
      "step": 4830
    },
    {
      "epoch": 0.3248213147209825,
      "grad_norm": 0.734951913356781,
      "learning_rate": 0.000196807448264214,
      "loss": 2.5676,
      "step": 4840
    },
    {
      "epoch": 0.3254924331398275,
      "grad_norm": 0.7236040830612183,
      "learning_rate": 0.00019678926183375,
      "loss": 2.608,
      "step": 4850
    },
    {
      "epoch": 0.3254924331398275,
      "eval_bleu": 20.818107282176936,
      "eval_gen_len": 28.567,
      "eval_loss": 2.975956439971924,
      "eval_runtime": 58.998,
      "eval_samples_per_second": 16.95,
      "eval_steps_per_second": 1.068,
      "step": 4850
    },
    {
      "epoch": 0.32616355155867255,
      "grad_norm": 0.7415920495986938,
      "learning_rate": 0.00019677102459572754,
      "loss": 2.6659,
      "step": 4860
    },
    {
      "epoch": 0.32683466997751753,
      "grad_norm": 0.7591438889503479,
      "learning_rate": 0.00019675273655971997,
      "loss": 2.5262,
      "step": 4870
    },
    {
      "epoch": 0.3275057883963625,
      "grad_norm": 0.7740582823753357,
      "learning_rate": 0.00019673439773532713,
      "loss": 2.5817,
      "step": 4880
    },
    {
      "epoch": 0.32817690681520756,
      "grad_norm": 0.6950958371162415,
      "learning_rate": 0.0001967160081321757,
      "loss": 2.5776,
      "step": 4890
    },
    {
      "epoch": 0.32884802523405254,
      "grad_norm": 0.735284149646759,
      "learning_rate": 0.00019669756775991888,
      "loss": 2.6357,
      "step": 4900
    },
    {
      "epoch": 0.32884802523405254,
      "eval_bleu": 20.706805803457836,
      "eval_gen_len": 28.575,
      "eval_loss": 2.9836814403533936,
      "eval_runtime": 59.9048,
      "eval_samples_per_second": 16.693,
      "eval_steps_per_second": 1.052,
      "step": 4900
    },
    {
      "epoch": 0.32951914365289753,
      "grad_norm": 0.7166444063186646,
      "learning_rate": 0.00019667907662823656,
      "loss": 2.6062,
      "step": 4910
    },
    {
      "epoch": 0.33019026207174257,
      "grad_norm": 0.7450997233390808,
      "learning_rate": 0.00019666053474683533,
      "loss": 2.5711,
      "step": 4920
    },
    {
      "epoch": 0.33086138049058755,
      "grad_norm": 0.7899550795555115,
      "learning_rate": 0.0001966419421254483,
      "loss": 2.5722,
      "step": 4930
    },
    {
      "epoch": 0.3315324989094326,
      "grad_norm": 0.7545067667961121,
      "learning_rate": 0.0001966232987738354,
      "loss": 2.5751,
      "step": 4940
    },
    {
      "epoch": 0.3322036173282776,
      "grad_norm": 0.6822296977043152,
      "learning_rate": 0.00019660460470178297,
      "loss": 2.5544,
      "step": 4950
    },
    {
      "epoch": 0.3322036173282776,
      "eval_bleu": 20.979455904889825,
      "eval_gen_len": 28.816,
      "eval_loss": 2.9750661849975586,
      "eval_runtime": 59.7713,
      "eval_samples_per_second": 16.73,
      "eval_steps_per_second": 1.054,
      "step": 4950
    },
    {
      "epoch": 0.33287473574712256,
      "grad_norm": 0.7496841549873352,
      "learning_rate": 0.00019658585991910412,
      "loss": 2.5747,
      "step": 4960
    },
    {
      "epoch": 0.3335458541659676,
      "grad_norm": 0.7088358402252197,
      "learning_rate": 0.0001965670644356386,
      "loss": 2.5435,
      "step": 4970
    },
    {
      "epoch": 0.3342169725848126,
      "grad_norm": 0.7057792544364929,
      "learning_rate": 0.00019654821826125263,
      "loss": 2.5552,
      "step": 4980
    },
    {
      "epoch": 0.3348880910036576,
      "grad_norm": 0.7277622222900391,
      "learning_rate": 0.00019652932140583917,
      "loss": 2.5358,
      "step": 4990
    },
    {
      "epoch": 0.3355592094225026,
      "grad_norm": 0.685235857963562,
      "learning_rate": 0.00019651037387931775,
      "loss": 2.5222,
      "step": 5000
    },
    {
      "epoch": 0.3355592094225026,
      "eval_bleu": 21.020601012425214,
      "eval_gen_len": 28.9,
      "eval_loss": 2.9728808403015137,
      "eval_runtime": 60.5801,
      "eval_samples_per_second": 16.507,
      "eval_steps_per_second": 1.04,
      "step": 5000
    },
    {
      "epoch": 0.3362303278413476,
      "grad_norm": 0.6865158677101135,
      "learning_rate": 0.00019649137569163446,
      "loss": 2.6071,
      "step": 5010
    },
    {
      "epoch": 0.33690144626019264,
      "grad_norm": 0.6835871934890747,
      "learning_rate": 0.00019647232685276206,
      "loss": 2.6063,
      "step": 5020
    },
    {
      "epoch": 0.3375725646790376,
      "grad_norm": 0.7014021277427673,
      "learning_rate": 0.00019645322737269977,
      "loss": 2.5298,
      "step": 5030
    },
    {
      "epoch": 0.3382436830978826,
      "grad_norm": 0.7029457092285156,
      "learning_rate": 0.00019643407726147353,
      "loss": 2.5951,
      "step": 5040
    },
    {
      "epoch": 0.33891480151672765,
      "grad_norm": 0.6883698105812073,
      "learning_rate": 0.00019641487652913585,
      "loss": 2.5991,
      "step": 5050
    },
    {
      "epoch": 0.33891480151672765,
      "eval_bleu": 20.511056944971752,
      "eval_gen_len": 28.637,
      "eval_loss": 2.9774765968322754,
      "eval_runtime": 58.8053,
      "eval_samples_per_second": 17.005,
      "eval_steps_per_second": 1.071,
      "step": 5050
    },
    {
      "epoch": 0.33958591993557263,
      "grad_norm": 0.7866101861000061,
      "learning_rate": 0.00019639562518576566,
      "loss": 2.5737,
      "step": 5060
    },
    {
      "epoch": 0.3402570383544176,
      "grad_norm": 0.7179826498031616,
      "learning_rate": 0.00019637632324146864,
      "loss": 2.5578,
      "step": 5070
    },
    {
      "epoch": 0.34092815677326266,
      "grad_norm": 0.690585732460022,
      "learning_rate": 0.00019635697070637692,
      "loss": 2.6778,
      "step": 5080
    },
    {
      "epoch": 0.34159927519210764,
      "grad_norm": 0.6476895809173584,
      "learning_rate": 0.00019633756759064922,
      "loss": 2.5965,
      "step": 5090
    },
    {
      "epoch": 0.34227039361095263,
      "grad_norm": 0.7574399709701538,
      "learning_rate": 0.00019631811390447083,
      "loss": 2.593,
      "step": 5100
    },
    {
      "epoch": 0.34227039361095263,
      "eval_bleu": 21.147169250851302,
      "eval_gen_len": 28.666,
      "eval_loss": 2.972025156021118,
      "eval_runtime": 59.0963,
      "eval_samples_per_second": 16.922,
      "eval_steps_per_second": 1.066,
      "step": 5100
    },
    {
      "epoch": 0.34294151202979767,
      "grad_norm": 0.7128443717956543,
      "learning_rate": 0.00019629860965805356,
      "loss": 2.5365,
      "step": 5110
    },
    {
      "epoch": 0.34361263044864265,
      "grad_norm": 0.7256544232368469,
      "learning_rate": 0.0001962790548616358,
      "loss": 2.5974,
      "step": 5120
    },
    {
      "epoch": 0.3442837488674877,
      "grad_norm": 0.6889531016349792,
      "learning_rate": 0.00019625944952548235,
      "loss": 2.6122,
      "step": 5130
    },
    {
      "epoch": 0.3449548672863327,
      "grad_norm": 0.668502926826477,
      "learning_rate": 0.0001962397936598847,
      "loss": 2.5231,
      "step": 5140
    },
    {
      "epoch": 0.34562598570517766,
      "grad_norm": 0.7406266331672668,
      "learning_rate": 0.0001962200872751608,
      "loss": 2.536,
      "step": 5150
    },
    {
      "epoch": 0.34562598570517766,
      "eval_bleu": 20.77267547948408,
      "eval_gen_len": 28.764,
      "eval_loss": 2.9751577377319336,
      "eval_runtime": 59.9802,
      "eval_samples_per_second": 16.672,
      "eval_steps_per_second": 1.05,
      "step": 5150
    },
    {
      "epoch": 0.3462971041240227,
      "grad_norm": 0.6888054609298706,
      "learning_rate": 0.00019620033038165514,
      "loss": 2.5428,
      "step": 5160
    },
    {
      "epoch": 0.3469682225428677,
      "grad_norm": 0.7405663132667542,
      "learning_rate": 0.0001961805229897386,
      "loss": 2.5973,
      "step": 5170
    },
    {
      "epoch": 0.3476393409617127,
      "grad_norm": 0.8041243553161621,
      "learning_rate": 0.0001961606651098088,
      "loss": 2.6032,
      "step": 5180
    },
    {
      "epoch": 0.3483104593805577,
      "grad_norm": 0.7186203002929688,
      "learning_rate": 0.00019614075675228963,
      "loss": 2.5491,
      "step": 5190
    },
    {
      "epoch": 0.3489815777994027,
      "grad_norm": 0.7033202648162842,
      "learning_rate": 0.00019612079792763161,
      "loss": 2.523,
      "step": 5200
    },
    {
      "epoch": 0.3489815777994027,
      "eval_bleu": 20.359794433633265,
      "eval_gen_len": 28.738,
      "eval_loss": 2.975613832473755,
      "eval_runtime": 59.5386,
      "eval_samples_per_second": 16.796,
      "eval_steps_per_second": 1.058,
      "step": 5200
    },
    {
      "epoch": 0.3496526962182477,
      "grad_norm": 0.6666491031646729,
      "learning_rate": 0.00019610078864631177,
      "loss": 2.5485,
      "step": 5210
    },
    {
      "epoch": 0.3503238146370927,
      "grad_norm": 0.7554156184196472,
      "learning_rate": 0.00019608072891883347,
      "loss": 2.545,
      "step": 5220
    },
    {
      "epoch": 0.3509949330559377,
      "grad_norm": 0.7136368155479431,
      "learning_rate": 0.00019606061875572674,
      "loss": 2.6153,
      "step": 5230
    },
    {
      "epoch": 0.35166605147478275,
      "grad_norm": 0.8587257862091064,
      "learning_rate": 0.00019604045816754798,
      "loss": 2.5585,
      "step": 5240
    },
    {
      "epoch": 0.35233716989362773,
      "grad_norm": 0.7128363847732544,
      "learning_rate": 0.0001960202471648801,
      "loss": 2.5934,
      "step": 5250
    },
    {
      "epoch": 0.35233716989362773,
      "eval_bleu": 20.73794488048615,
      "eval_gen_len": 28.572,
      "eval_loss": 2.988924980163574,
      "eval_runtime": 59.3628,
      "eval_samples_per_second": 16.846,
      "eval_steps_per_second": 1.061,
      "step": 5250
    },
    {
      "epoch": 0.3530082883124727,
      "grad_norm": 0.670261025428772,
      "learning_rate": 0.00019599998575833242,
      "loss": 2.5601,
      "step": 5260
    },
    {
      "epoch": 0.35367940673131776,
      "grad_norm": 0.6985403895378113,
      "learning_rate": 0.00019597967395854077,
      "loss": 2.5412,
      "step": 5270
    },
    {
      "epoch": 0.35435052515016274,
      "grad_norm": 0.6007075905799866,
      "learning_rate": 0.0001959593117761674,
      "loss": 2.561,
      "step": 5280
    },
    {
      "epoch": 0.3550216435690077,
      "grad_norm": 0.7032061219215393,
      "learning_rate": 0.0001959388992219011,
      "loss": 2.6185,
      "step": 5290
    },
    {
      "epoch": 0.35569276198785277,
      "grad_norm": 0.7576121091842651,
      "learning_rate": 0.00019591843630645692,
      "loss": 2.5294,
      "step": 5300
    },
    {
      "epoch": 0.35569276198785277,
      "eval_bleu": 20.510411457279584,
      "eval_gen_len": 28.67,
      "eval_loss": 2.9875175952911377,
      "eval_runtime": 58.7795,
      "eval_samples_per_second": 17.013,
      "eval_steps_per_second": 1.072,
      "step": 5300
    },
    {
      "epoch": 0.35636388040669775,
      "grad_norm": 0.7877925634384155,
      "learning_rate": 0.0001958979230405765,
      "loss": 2.5789,
      "step": 5310
    },
    {
      "epoch": 0.3570349988255428,
      "grad_norm": 0.6876471042633057,
      "learning_rate": 0.00019587735943502787,
      "loss": 2.5455,
      "step": 5320
    },
    {
      "epoch": 0.3577061172443878,
      "grad_norm": 0.7350231409072876,
      "learning_rate": 0.00019585674550060548,
      "loss": 2.579,
      "step": 5330
    },
    {
      "epoch": 0.35837723566323276,
      "grad_norm": 0.6945357322692871,
      "learning_rate": 0.00019583608124813017,
      "loss": 2.6059,
      "step": 5340
    },
    {
      "epoch": 0.3590483540820778,
      "grad_norm": 0.7056697607040405,
      "learning_rate": 0.00019581536668844925,
      "loss": 2.5477,
      "step": 5350
    },
    {
      "epoch": 0.3590483540820778,
      "eval_bleu": 20.773895364475884,
      "eval_gen_len": 28.736,
      "eval_loss": 2.9739952087402344,
      "eval_runtime": 59.2025,
      "eval_samples_per_second": 16.891,
      "eval_steps_per_second": 1.064,
      "step": 5350
    },
    {
      "epoch": 0.3597194725009228,
      "grad_norm": 0.7245542407035828,
      "learning_rate": 0.0001957946018324364,
      "loss": 2.581,
      "step": 5360
    },
    {
      "epoch": 0.3603905909197678,
      "grad_norm": 0.7176703214645386,
      "learning_rate": 0.0001957737866909917,
      "loss": 2.5313,
      "step": 5370
    },
    {
      "epoch": 0.3610617093386128,
      "grad_norm": 0.6643800735473633,
      "learning_rate": 0.00019575292127504162,
      "loss": 2.5314,
      "step": 5380
    },
    {
      "epoch": 0.3617328277574578,
      "grad_norm": 0.7101724147796631,
      "learning_rate": 0.0001957320055955391,
      "loss": 2.6013,
      "step": 5390
    },
    {
      "epoch": 0.3624039461763028,
      "grad_norm": 0.7423315644264221,
      "learning_rate": 0.0001957110396634633,
      "loss": 2.6132,
      "step": 5400
    },
    {
      "epoch": 0.3624039461763028,
      "eval_bleu": 20.817427129094202,
      "eval_gen_len": 28.807,
      "eval_loss": 2.9705922603607178,
      "eval_runtime": 60.602,
      "eval_samples_per_second": 16.501,
      "eval_steps_per_second": 1.04,
      "step": 5400
    },
    {
      "epoch": 0.3630750645951478,
      "grad_norm": 0.6860975027084351,
      "learning_rate": 0.00019569002348981992,
      "loss": 2.5933,
      "step": 5410
    },
    {
      "epoch": 0.3637461830139928,
      "grad_norm": 0.734699547290802,
      "learning_rate": 0.00019566895708564102,
      "loss": 2.5687,
      "step": 5420
    },
    {
      "epoch": 0.36441730143283785,
      "grad_norm": 0.7644690275192261,
      "learning_rate": 0.0001956478404619849,
      "loss": 2.5603,
      "step": 5430
    },
    {
      "epoch": 0.36508841985168283,
      "grad_norm": 0.7326026558876038,
      "learning_rate": 0.00019562667362993635,
      "loss": 2.5956,
      "step": 5440
    },
    {
      "epoch": 0.3657595382705278,
      "grad_norm": 0.6852909922599792,
      "learning_rate": 0.00019560545660060645,
      "loss": 2.6138,
      "step": 5450
    },
    {
      "epoch": 0.3657595382705278,
      "eval_bleu": 21.200503024832905,
      "eval_gen_len": 28.68,
      "eval_loss": 2.970147132873535,
      "eval_runtime": 59.6032,
      "eval_samples_per_second": 16.778,
      "eval_steps_per_second": 1.057,
      "step": 5450
    },
    {
      "epoch": 0.36643065668937286,
      "grad_norm": 0.6732479929924011,
      "learning_rate": 0.00019558418938513266,
      "loss": 2.6366,
      "step": 5460
    },
    {
      "epoch": 0.36710177510821784,
      "grad_norm": 0.6709529757499695,
      "learning_rate": 0.00019556287199467876,
      "loss": 2.5206,
      "step": 5470
    },
    {
      "epoch": 0.3677728935270628,
      "grad_norm": 0.8190493583679199,
      "learning_rate": 0.00019554150444043487,
      "loss": 2.6452,
      "step": 5480
    },
    {
      "epoch": 0.36844401194590787,
      "grad_norm": 0.7653325796127319,
      "learning_rate": 0.0001955200867336175,
      "loss": 2.5762,
      "step": 5490
    },
    {
      "epoch": 0.36911513036475285,
      "grad_norm": 0.7255885004997253,
      "learning_rate": 0.0001954986188854694,
      "loss": 2.6333,
      "step": 5500
    },
    {
      "epoch": 0.36911513036475285,
      "eval_bleu": 20.78405541732447,
      "eval_gen_len": 28.656,
      "eval_loss": 2.9743661880493164,
      "eval_runtime": 58.9112,
      "eval_samples_per_second": 16.975,
      "eval_steps_per_second": 1.069,
      "step": 5500
    },
    {
      "epoch": 0.3697862487835979,
      "grad_norm": 0.7492936849594116,
      "learning_rate": 0.0001954771009072597,
      "loss": 2.5743,
      "step": 5510
    },
    {
      "epoch": 0.3704573672024429,
      "grad_norm": 0.6406501531600952,
      "learning_rate": 0.00019545553281028383,
      "loss": 2.5792,
      "step": 5520
    },
    {
      "epoch": 0.37112848562128786,
      "grad_norm": 0.7356184124946594,
      "learning_rate": 0.00019543391460586352,
      "loss": 2.6093,
      "step": 5530
    },
    {
      "epoch": 0.3717996040401329,
      "grad_norm": 0.702046811580658,
      "learning_rate": 0.00019541224630534676,
      "loss": 2.5774,
      "step": 5540
    },
    {
      "epoch": 0.3724707224589779,
      "grad_norm": 0.6520161628723145,
      "learning_rate": 0.00019539052792010795,
      "loss": 2.5645,
      "step": 5550
    },
    {
      "epoch": 0.3724707224589779,
      "eval_bleu": 21.343079442558583,
      "eval_gen_len": 28.803,
      "eval_loss": 2.971343755722046,
      "eval_runtime": 61.4084,
      "eval_samples_per_second": 16.284,
      "eval_steps_per_second": 1.026,
      "step": 5550
    },
    {
      "epoch": 0.3731418408778229,
      "grad_norm": 0.6543736457824707,
      "learning_rate": 0.00019536875946154768,
      "loss": 2.5691,
      "step": 5560
    },
    {
      "epoch": 0.3738129592966679,
      "grad_norm": 0.7209049463272095,
      "learning_rate": 0.00019534694094109291,
      "loss": 2.5026,
      "step": 5570
    },
    {
      "epoch": 0.3744840777155129,
      "grad_norm": 0.7148378491401672,
      "learning_rate": 0.00019532507237019677,
      "loss": 2.5973,
      "step": 5580
    },
    {
      "epoch": 0.3751551961343579,
      "grad_norm": 0.6869332790374756,
      "learning_rate": 0.00019530315376033874,
      "loss": 2.5361,
      "step": 5590
    },
    {
      "epoch": 0.3758263145532029,
      "grad_norm": 0.7368311285972595,
      "learning_rate": 0.00019528118512302455,
      "loss": 2.5328,
      "step": 5600
    },
    {
      "epoch": 0.3758263145532029,
      "eval_bleu": 20.951061968503527,
      "eval_gen_len": 28.853,
      "eval_loss": 2.967339038848877,
      "eval_runtime": 59.8635,
      "eval_samples_per_second": 16.705,
      "eval_steps_per_second": 1.052,
      "step": 5600
    },
    {
      "epoch": 0.3764974329720479,
      "grad_norm": 0.7038910388946533,
      "learning_rate": 0.0001952591664697862,
      "loss": 2.5828,
      "step": 5610
    },
    {
      "epoch": 0.37716855139089295,
      "grad_norm": 0.7199209332466125,
      "learning_rate": 0.00019523709781218193,
      "loss": 2.6186,
      "step": 5620
    },
    {
      "epoch": 0.37783966980973793,
      "grad_norm": 0.6849480867385864,
      "learning_rate": 0.00019521497916179625,
      "loss": 2.5761,
      "step": 5630
    },
    {
      "epoch": 0.3785107882285829,
      "grad_norm": 0.7192690968513489,
      "learning_rate": 0.00019519281053023986,
      "loss": 2.5885,
      "step": 5640
    },
    {
      "epoch": 0.37918190664742796,
      "grad_norm": 0.6596370935440063,
      "learning_rate": 0.00019517059192914978,
      "loss": 2.5561,
      "step": 5650
    },
    {
      "epoch": 0.37918190664742796,
      "eval_bleu": 20.97780831004814,
      "eval_gen_len": 28.637,
      "eval_loss": 2.9728293418884277,
      "eval_runtime": 59.8819,
      "eval_samples_per_second": 16.7,
      "eval_steps_per_second": 1.052,
      "step": 5650
    },
    {
      "epoch": 0.37985302506627294,
      "grad_norm": 0.674046516418457,
      "learning_rate": 0.00019514832337018913,
      "loss": 2.5084,
      "step": 5660
    },
    {
      "epoch": 0.3805241434851179,
      "grad_norm": 0.7488659620285034,
      "learning_rate": 0.00019512600486504744,
      "loss": 2.5788,
      "step": 5670
    },
    {
      "epoch": 0.38119526190396297,
      "grad_norm": 0.7186298370361328,
      "learning_rate": 0.0001951036364254403,
      "loss": 2.56,
      "step": 5680
    },
    {
      "epoch": 0.38186638032280795,
      "grad_norm": 0.6815887093544006,
      "learning_rate": 0.0001950812180631096,
      "loss": 2.534,
      "step": 5690
    },
    {
      "epoch": 0.38253749874165294,
      "grad_norm": 0.6476221680641174,
      "learning_rate": 0.00019505874978982334,
      "loss": 2.568,
      "step": 5700
    },
    {
      "epoch": 0.38253749874165294,
      "eval_bleu": 20.721891262962018,
      "eval_gen_len": 28.904,
      "eval_loss": 2.970269203186035,
      "eval_runtime": 62.2508,
      "eval_samples_per_second": 16.064,
      "eval_steps_per_second": 1.012,
      "step": 5700
    },
    {
      "epoch": 0.383208617160498,
      "grad_norm": 0.7532376050949097,
      "learning_rate": 0.00019503623161737585,
      "loss": 2.5966,
      "step": 5710
    },
    {
      "epoch": 0.38387973557934296,
      "grad_norm": 0.6572343707084656,
      "learning_rate": 0.00019501366355758758,
      "loss": 2.5285,
      "step": 5720
    },
    {
      "epoch": 0.384550853998188,
      "grad_norm": 0.7295920848846436,
      "learning_rate": 0.00019499104562230516,
      "loss": 2.5572,
      "step": 5730
    },
    {
      "epoch": 0.385221972417033,
      "grad_norm": 0.6975518465042114,
      "learning_rate": 0.00019496837782340137,
      "loss": 2.5563,
      "step": 5740
    },
    {
      "epoch": 0.38589309083587797,
      "grad_norm": 0.7239846587181091,
      "learning_rate": 0.0001949456601727753,
      "loss": 2.5372,
      "step": 5750
    },
    {
      "epoch": 0.38589309083587797,
      "eval_bleu": 20.776236829440407,
      "eval_gen_len": 28.979,
      "eval_loss": 2.9685301780700684,
      "eval_runtime": 62.9921,
      "eval_samples_per_second": 15.875,
      "eval_steps_per_second": 1.0,
      "step": 5750
    },
    {
      "epoch": 0.386564209254723,
      "grad_norm": 0.6223499774932861,
      "learning_rate": 0.00019492289268235204,
      "loss": 2.5787,
      "step": 5760
    },
    {
      "epoch": 0.387235327673568,
      "grad_norm": 0.6954643130302429,
      "learning_rate": 0.00019490007536408302,
      "loss": 2.5811,
      "step": 5770
    },
    {
      "epoch": 0.387906446092413,
      "grad_norm": 0.715225100517273,
      "learning_rate": 0.0001948772082299456,
      "loss": 2.6055,
      "step": 5780
    },
    {
      "epoch": 0.388577564511258,
      "grad_norm": 0.6971032023429871,
      "learning_rate": 0.00019485429129194353,
      "loss": 2.6072,
      "step": 5790
    },
    {
      "epoch": 0.389248682930103,
      "grad_norm": 0.6701017022132874,
      "learning_rate": 0.0001948313245621065,
      "loss": 2.5761,
      "step": 5800
    },
    {
      "epoch": 0.389248682930103,
      "eval_bleu": 21.08645519432146,
      "eval_gen_len": 28.751,
      "eval_loss": 2.9755868911743164,
      "eval_runtime": 60.1312,
      "eval_samples_per_second": 16.63,
      "eval_steps_per_second": 1.048,
      "step": 5800
    },
    {
      "epoch": 0.38991980134894805,
      "grad_norm": 0.6646223068237305,
      "learning_rate": 0.00019480830805249054,
      "loss": 2.549,
      "step": 5810
    },
    {
      "epoch": 0.39059091976779303,
      "grad_norm": 0.6866862177848816,
      "learning_rate": 0.0001947852417751776,
      "loss": 2.5506,
      "step": 5820
    },
    {
      "epoch": 0.391262038186638,
      "grad_norm": 0.6952441930770874,
      "learning_rate": 0.00019476212574227585,
      "loss": 2.5801,
      "step": 5830
    },
    {
      "epoch": 0.39193315660548306,
      "grad_norm": 0.7220419049263,
      "learning_rate": 0.00019473895996591968,
      "loss": 2.6041,
      "step": 5840
    },
    {
      "epoch": 0.39260427502432804,
      "grad_norm": 0.7204790711402893,
      "learning_rate": 0.0001947157444582694,
      "loss": 2.5623,
      "step": 5850
    },
    {
      "epoch": 0.39260427502432804,
      "eval_bleu": 20.719320550426342,
      "eval_gen_len": 28.633,
      "eval_loss": 2.98568058013916,
      "eval_runtime": 58.6874,
      "eval_samples_per_second": 17.039,
      "eval_steps_per_second": 1.073,
      "step": 5850
    },
    {
      "epoch": 0.393275393443173,
      "grad_norm": 0.6815495491027832,
      "learning_rate": 0.00019469247923151157,
      "loss": 2.5901,
      "step": 5860
    },
    {
      "epoch": 0.39394651186201807,
      "grad_norm": 0.7172901630401611,
      "learning_rate": 0.00019466916429785878,
      "loss": 2.6167,
      "step": 5870
    },
    {
      "epoch": 0.39461763028086305,
      "grad_norm": 0.7230990529060364,
      "learning_rate": 0.00019464579966954975,
      "loss": 2.5258,
      "step": 5880
    },
    {
      "epoch": 0.39528874869970804,
      "grad_norm": 0.7123627066612244,
      "learning_rate": 0.00019462238535884922,
      "loss": 2.5989,
      "step": 5890
    },
    {
      "epoch": 0.3959598671185531,
      "grad_norm": 0.6754409074783325,
      "learning_rate": 0.00019459892137804809,
      "loss": 2.5616,
      "step": 5900
    },
    {
      "epoch": 0.3959598671185531,
      "eval_bleu": 20.924649257901745,
      "eval_gen_len": 28.843,
      "eval_loss": 2.9671452045440674,
      "eval_runtime": 58.9576,
      "eval_samples_per_second": 16.961,
      "eval_steps_per_second": 1.069,
      "step": 5900
    },
    {
      "epoch": 0.39663098553739806,
      "grad_norm": 0.691304087638855,
      "learning_rate": 0.0001945754077394633,
      "loss": 2.5906,
      "step": 5910
    },
    {
      "epoch": 0.3973021039562431,
      "grad_norm": 0.7009619474411011,
      "learning_rate": 0.0001945518444554379,
      "loss": 2.57,
      "step": 5920
    },
    {
      "epoch": 0.3979732223750881,
      "grad_norm": 0.7933809161186218,
      "learning_rate": 0.00019452823153834087,
      "loss": 2.6045,
      "step": 5930
    },
    {
      "epoch": 0.39864434079393307,
      "grad_norm": 0.6765295267105103,
      "learning_rate": 0.00019450456900056739,
      "loss": 2.604,
      "step": 5940
    },
    {
      "epoch": 0.3993154592127781,
      "grad_norm": 0.7434633374214172,
      "learning_rate": 0.0001944808568545386,
      "loss": 2.5225,
      "step": 5950
    },
    {
      "epoch": 0.3993154592127781,
      "eval_bleu": 20.67117357535185,
      "eval_gen_len": 28.801,
      "eval_loss": 2.973773717880249,
      "eval_runtime": 59.0582,
      "eval_samples_per_second": 16.932,
      "eval_steps_per_second": 1.067,
      "step": 5950
    },
    {
      "epoch": 0.3999865776316231,
      "grad_norm": 0.7628158926963806,
      "learning_rate": 0.00019445709511270174,
      "loss": 2.5647,
      "step": 5960
    },
    {
      "epoch": 0.4006576960504681,
      "grad_norm": 0.7130264639854431,
      "learning_rate": 0.00019443328378753006,
      "loss": 2.5283,
      "step": 5970
    },
    {
      "epoch": 0.4013288144693131,
      "grad_norm": 0.7443342208862305,
      "learning_rate": 0.00019440942289152276,
      "loss": 2.5328,
      "step": 5980
    },
    {
      "epoch": 0.4019999328881581,
      "grad_norm": 0.6983796954154968,
      "learning_rate": 0.0001943855124372052,
      "loss": 2.5379,
      "step": 5990
    },
    {
      "epoch": 0.40267105130700315,
      "grad_norm": 0.7443739771842957,
      "learning_rate": 0.00019436155243712867,
      "loss": 2.608,
      "step": 6000
    },
    {
      "epoch": 0.40267105130700315,
      "eval_bleu": 20.7602680751104,
      "eval_gen_len": 28.841,
      "eval_loss": 2.9711403846740723,
      "eval_runtime": 59.0241,
      "eval_samples_per_second": 16.942,
      "eval_steps_per_second": 1.067,
      "step": 6000
    },
    {
      "epoch": 0.40334216972584813,
      "grad_norm": 0.7101954221725464,
      "learning_rate": 0.0001943375429038705,
      "loss": 2.5581,
      "step": 6010
    },
    {
      "epoch": 0.4040132881446931,
      "grad_norm": 0.7029477953910828,
      "learning_rate": 0.000194313483850034,
      "loss": 2.5711,
      "step": 6020
    },
    {
      "epoch": 0.40468440656353816,
      "grad_norm": 0.8254942297935486,
      "learning_rate": 0.00019428937528824847,
      "loss": 2.5314,
      "step": 6030
    },
    {
      "epoch": 0.40535552498238314,
      "grad_norm": 0.6760151386260986,
      "learning_rate": 0.0001942652172311692,
      "loss": 2.6163,
      "step": 6040
    },
    {
      "epoch": 0.4060266434012281,
      "grad_norm": 0.7326645255088806,
      "learning_rate": 0.0001942410096914775,
      "loss": 2.5716,
      "step": 6050
    },
    {
      "epoch": 0.4060266434012281,
      "eval_bleu": 20.73647589021993,
      "eval_gen_len": 28.888,
      "eval_loss": 2.9691426753997803,
      "eval_runtime": 59.9506,
      "eval_samples_per_second": 16.68,
      "eval_steps_per_second": 1.051,
      "step": 6050
    },
    {
      "epoch": 0.40669776182007317,
      "grad_norm": 0.8112921714782715,
      "learning_rate": 0.0001942167526818806,
      "loss": 2.5497,
      "step": 6060
    },
    {
      "epoch": 0.40736888023891815,
      "grad_norm": 0.6260494589805603,
      "learning_rate": 0.00019419244621511178,
      "loss": 2.5339,
      "step": 6070
    },
    {
      "epoch": 0.40803999865776314,
      "grad_norm": 0.7074530720710754,
      "learning_rate": 0.00019416809030393012,
      "loss": 2.5619,
      "step": 6080
    },
    {
      "epoch": 0.4087111170766082,
      "grad_norm": 0.7200037240982056,
      "learning_rate": 0.00019414368496112086,
      "loss": 2.5422,
      "step": 6090
    },
    {
      "epoch": 0.40938223549545316,
      "grad_norm": 0.6589011549949646,
      "learning_rate": 0.00019411923019949508,
      "loss": 2.5636,
      "step": 6100
    },
    {
      "epoch": 0.40938223549545316,
      "eval_bleu": 20.85466789876524,
      "eval_gen_len": 28.785,
      "eval_loss": 2.969956159591675,
      "eval_runtime": 59.4148,
      "eval_samples_per_second": 16.831,
      "eval_steps_per_second": 1.06,
      "step": 6100
    },
    {
      "epoch": 0.4100533539142982,
      "grad_norm": 0.698528528213501,
      "learning_rate": 0.00019409472603188976,
      "loss": 2.5981,
      "step": 6110
    },
    {
      "epoch": 0.4107244723331432,
      "grad_norm": 0.70123291015625,
      "learning_rate": 0.0001940701724711679,
      "loss": 2.5985,
      "step": 6120
    },
    {
      "epoch": 0.41139559075198817,
      "grad_norm": 0.6959134340286255,
      "learning_rate": 0.00019404556953021835,
      "loss": 2.5717,
      "step": 6130
    },
    {
      "epoch": 0.4120667091708332,
      "grad_norm": 0.7151190042495728,
      "learning_rate": 0.000194020917221956,
      "loss": 2.5947,
      "step": 6140
    },
    {
      "epoch": 0.4127378275896782,
      "grad_norm": 0.7435920834541321,
      "learning_rate": 0.00019399621555932152,
      "loss": 2.5897,
      "step": 6150
    },
    {
      "epoch": 0.4127378275896782,
      "eval_bleu": 20.850302322870533,
      "eval_gen_len": 28.693,
      "eval_loss": 2.970914363861084,
      "eval_runtime": 58.7927,
      "eval_samples_per_second": 17.009,
      "eval_steps_per_second": 1.072,
      "step": 6150
    },
    {
      "epoch": 0.4134089460085232,
      "grad_norm": 0.7112203240394592,
      "learning_rate": 0.0001939714645552816,
      "loss": 2.5732,
      "step": 6160
    },
    {
      "epoch": 0.4140800644273682,
      "grad_norm": 0.7048845291137695,
      "learning_rate": 0.0001939466642228287,
      "loss": 2.5888,
      "step": 6170
    },
    {
      "epoch": 0.4147511828462132,
      "grad_norm": 0.7379851937294006,
      "learning_rate": 0.0001939218145749813,
      "loss": 2.5677,
      "step": 6180
    },
    {
      "epoch": 0.41542230126505825,
      "grad_norm": 0.7378771305084229,
      "learning_rate": 0.00019389691562478374,
      "loss": 2.568,
      "step": 6190
    },
    {
      "epoch": 0.41609341968390323,
      "grad_norm": 0.7710219621658325,
      "learning_rate": 0.00019387196738530617,
      "loss": 2.5661,
      "step": 6200
    },
    {
      "epoch": 0.41609341968390323,
      "eval_bleu": 20.52516478541769,
      "eval_gen_len": 28.595,
      "eval_loss": 2.9723994731903076,
      "eval_runtime": 58.905,
      "eval_samples_per_second": 16.976,
      "eval_steps_per_second": 1.07,
      "step": 6200
    },
    {
      "epoch": 0.4167645381027482,
      "grad_norm": 0.7423829436302185,
      "learning_rate": 0.0001938469698696447,
      "loss": 2.587,
      "step": 6210
    },
    {
      "epoch": 0.41743565652159326,
      "grad_norm": 0.6787625551223755,
      "learning_rate": 0.00019382192309092122,
      "loss": 2.5275,
      "step": 6220
    },
    {
      "epoch": 0.41810677494043824,
      "grad_norm": 0.755835235118866,
      "learning_rate": 0.00019379682706228358,
      "loss": 2.5245,
      "step": 6230
    },
    {
      "epoch": 0.4187778933592832,
      "grad_norm": 0.7164017558097839,
      "learning_rate": 0.0001937716817969054,
      "loss": 2.5904,
      "step": 6240
    },
    {
      "epoch": 0.41944901177812827,
      "grad_norm": 0.7296414971351624,
      "learning_rate": 0.00019374648730798616,
      "loss": 2.5831,
      "step": 6250
    },
    {
      "epoch": 0.41944901177812827,
      "eval_bleu": 20.478563525892934,
      "eval_gen_len": 28.717,
      "eval_loss": 2.976774215698242,
      "eval_runtime": 58.8317,
      "eval_samples_per_second": 16.998,
      "eval_steps_per_second": 1.071,
      "step": 6250
    },
    {
      "epoch": 0.42012013019697325,
      "grad_norm": 0.6888325810432434,
      "learning_rate": 0.00019372124360875128,
      "loss": 2.5256,
      "step": 6260
    },
    {
      "epoch": 0.42079124861581824,
      "grad_norm": 0.6891016364097595,
      "learning_rate": 0.00019369595071245185,
      "loss": 2.5661,
      "step": 6270
    },
    {
      "epoch": 0.4214623670346633,
      "grad_norm": 0.7028437256813049,
      "learning_rate": 0.00019367060863236486,
      "loss": 2.5641,
      "step": 6280
    },
    {
      "epoch": 0.42213348545350826,
      "grad_norm": 0.7255116701126099,
      "learning_rate": 0.00019364521738179314,
      "loss": 2.5237,
      "step": 6290
    },
    {
      "epoch": 0.4228046038723533,
      "grad_norm": 0.7145838141441345,
      "learning_rate": 0.00019361977697406534,
      "loss": 2.555,
      "step": 6300
    },
    {
      "epoch": 0.4228046038723533,
      "eval_bleu": 20.532771414451428,
      "eval_gen_len": 28.64,
      "eval_loss": 2.96665096282959,
      "eval_runtime": 59.0656,
      "eval_samples_per_second": 16.93,
      "eval_steps_per_second": 1.067,
      "step": 6300
    },
    {
      "epoch": 0.4234757222911983,
      "grad_norm": 0.6369190216064453,
      "learning_rate": 0.00019359428742253583,
      "loss": 2.5662,
      "step": 6310
    },
    {
      "epoch": 0.42414684071004327,
      "grad_norm": 0.7235345244407654,
      "learning_rate": 0.0001935687487405849,
      "loss": 2.5278,
      "step": 6320
    },
    {
      "epoch": 0.4248179591288883,
      "grad_norm": 0.7635943293571472,
      "learning_rate": 0.0001935431609416185,
      "loss": 2.6175,
      "step": 6330
    },
    {
      "epoch": 0.4254890775477333,
      "grad_norm": 0.7795218825340271,
      "learning_rate": 0.00019351752403906844,
      "loss": 2.5712,
      "step": 6340
    },
    {
      "epoch": 0.4261601959665783,
      "grad_norm": 0.7024038434028625,
      "learning_rate": 0.00019349183804639233,
      "loss": 2.5289,
      "step": 6350
    },
    {
      "epoch": 0.4261601959665783,
      "eval_bleu": 20.66522994988361,
      "eval_gen_len": 28.768,
      "eval_loss": 2.965303897857666,
      "eval_runtime": 59.9322,
      "eval_samples_per_second": 16.686,
      "eval_steps_per_second": 1.051,
      "step": 6350
    },
    {
      "epoch": 0.4268313143854233,
      "grad_norm": 0.6692753434181213,
      "learning_rate": 0.00019346610297707345,
      "loss": 2.5829,
      "step": 6360
    },
    {
      "epoch": 0.4275024328042683,
      "grad_norm": 0.7077900171279907,
      "learning_rate": 0.000193440318844621,
      "loss": 2.5177,
      "step": 6370
    },
    {
      "epoch": 0.4281735512231133,
      "grad_norm": 0.7024410963058472,
      "learning_rate": 0.0001934144856625697,
      "loss": 2.5294,
      "step": 6380
    },
    {
      "epoch": 0.42884466964195833,
      "grad_norm": 0.6504769325256348,
      "learning_rate": 0.00019338860344448027,
      "loss": 2.5353,
      "step": 6390
    },
    {
      "epoch": 0.4295157880608033,
      "grad_norm": 0.7984690070152283,
      "learning_rate": 0.000193362672203939,
      "loss": 2.5781,
      "step": 6400
    },
    {
      "epoch": 0.4295157880608033,
      "eval_bleu": 20.630730227498283,
      "eval_gen_len": 28.642,
      "eval_loss": 2.9658470153808594,
      "eval_runtime": 58.8654,
      "eval_samples_per_second": 16.988,
      "eval_steps_per_second": 1.07,
      "step": 6400
    },
    {
      "epoch": 0.43018690647964836,
      "grad_norm": 0.7654983401298523,
      "learning_rate": 0.00019333669195455798,
      "loss": 2.5654,
      "step": 6410
    },
    {
      "epoch": 0.43085802489849334,
      "grad_norm": 0.755468487739563,
      "learning_rate": 0.000193310662709975,
      "loss": 2.5569,
      "step": 6420
    },
    {
      "epoch": 0.4315291433173383,
      "grad_norm": 0.7323150634765625,
      "learning_rate": 0.0001932845844838536,
      "loss": 2.5969,
      "step": 6430
    },
    {
      "epoch": 0.43220026173618337,
      "grad_norm": 0.6999425888061523,
      "learning_rate": 0.00019325845728988304,
      "loss": 2.565,
      "step": 6440
    },
    {
      "epoch": 0.43287138015502835,
      "grad_norm": 0.6951403021812439,
      "learning_rate": 0.0001932322811417782,
      "loss": 2.5183,
      "step": 6450
    },
    {
      "epoch": 0.43287138015502835,
      "eval_bleu": 20.937178063842087,
      "eval_gen_len": 28.923,
      "eval_loss": 2.962320566177368,
      "eval_runtime": 59.7104,
      "eval_samples_per_second": 16.747,
      "eval_steps_per_second": 1.055,
      "step": 6450
    },
    {
      "epoch": 0.43354249857387334,
      "grad_norm": 0.8023139238357544,
      "learning_rate": 0.0001932060560532798,
      "loss": 2.553,
      "step": 6460
    },
    {
      "epoch": 0.4342136169927184,
      "grad_norm": 0.7417179942131042,
      "learning_rate": 0.00019317978203815407,
      "loss": 2.5902,
      "step": 6470
    },
    {
      "epoch": 0.43488473541156336,
      "grad_norm": 0.6550167798995972,
      "learning_rate": 0.00019315345911019309,
      "loss": 2.5236,
      "step": 6480
    },
    {
      "epoch": 0.4355558538304084,
      "grad_norm": 0.7388861179351807,
      "learning_rate": 0.00019312708728321453,
      "loss": 2.573,
      "step": 6490
    },
    {
      "epoch": 0.4362269722492534,
      "grad_norm": 0.6968861222267151,
      "learning_rate": 0.00019310066657106175,
      "loss": 2.5841,
      "step": 6500
    },
    {
      "epoch": 0.4362269722492534,
      "eval_bleu": 21.036048770454673,
      "eval_gen_len": 28.838,
      "eval_loss": 2.9647653102874756,
      "eval_runtime": 59.6533,
      "eval_samples_per_second": 16.764,
      "eval_steps_per_second": 1.056,
      "step": 6500
    },
    {
      "epoch": 0.43689809066809837,
      "grad_norm": 0.7566262483596802,
      "learning_rate": 0.00019307419698760375,
      "loss": 2.5604,
      "step": 6510
    },
    {
      "epoch": 0.4375692090869434,
      "grad_norm": 0.7764774560928345,
      "learning_rate": 0.0001930476785467352,
      "loss": 2.6044,
      "step": 6520
    },
    {
      "epoch": 0.4382403275057884,
      "grad_norm": 0.7284246683120728,
      "learning_rate": 0.00019302111126237644,
      "loss": 2.581,
      "step": 6530
    },
    {
      "epoch": 0.4389114459246334,
      "grad_norm": 0.6994310021400452,
      "learning_rate": 0.0001929944951484734,
      "loss": 2.5775,
      "step": 6540
    },
    {
      "epoch": 0.4395825643434784,
      "grad_norm": 0.7116411328315735,
      "learning_rate": 0.00019296783021899769,
      "loss": 2.5893,
      "step": 6550
    },
    {
      "epoch": 0.4395825643434784,
      "eval_bleu": 21.037069266164078,
      "eval_gen_len": 28.929,
      "eval_loss": 2.960613489151001,
      "eval_runtime": 59.931,
      "eval_samples_per_second": 16.686,
      "eval_steps_per_second": 1.051,
      "step": 6550
    },
    {
      "epoch": 0.4402536827623234,
      "grad_norm": 0.7513084411621094,
      "learning_rate": 0.00019294111648794653,
      "loss": 2.5966,
      "step": 6560
    },
    {
      "epoch": 0.4409248011811684,
      "grad_norm": 0.7828385829925537,
      "learning_rate": 0.00019291435396934272,
      "loss": 2.6019,
      "step": 6570
    },
    {
      "epoch": 0.44159591960001343,
      "grad_norm": 0.7471861243247986,
      "learning_rate": 0.0001928875426772347,
      "loss": 2.5469,
      "step": 6580
    },
    {
      "epoch": 0.4422670380188584,
      "grad_norm": 0.6875467896461487,
      "learning_rate": 0.00019286068262569658,
      "loss": 2.5212,
      "step": 6590
    },
    {
      "epoch": 0.44293815643770346,
      "grad_norm": 0.7257959842681885,
      "learning_rate": 0.0001928337738288279,
      "loss": 2.5869,
      "step": 6600
    },
    {
      "epoch": 0.44293815643770346,
      "eval_bleu": 20.744313335081294,
      "eval_gen_len": 28.946,
      "eval_loss": 2.9630916118621826,
      "eval_runtime": 60.6165,
      "eval_samples_per_second": 16.497,
      "eval_steps_per_second": 1.039,
      "step": 6600
    },
    {
      "epoch": 0.44360927485654844,
      "grad_norm": 0.6837352514266968,
      "learning_rate": 0.00019280681630075397,
      "loss": 2.5492,
      "step": 6610
    },
    {
      "epoch": 0.4442803932753934,
      "grad_norm": 0.771479070186615,
      "learning_rate": 0.00019277981005562554,
      "loss": 2.6019,
      "step": 6620
    },
    {
      "epoch": 0.44495151169423847,
      "grad_norm": 0.7213574051856995,
      "learning_rate": 0.00019275275510761907,
      "loss": 2.5677,
      "step": 6630
    },
    {
      "epoch": 0.44562263011308345,
      "grad_norm": 0.6619523763656616,
      "learning_rate": 0.0001927256514709364,
      "loss": 2.5282,
      "step": 6640
    },
    {
      "epoch": 0.44629374853192844,
      "grad_norm": 0.722646951675415,
      "learning_rate": 0.00019269849915980506,
      "loss": 2.6021,
      "step": 6650
    },
    {
      "epoch": 0.44629374853192844,
      "eval_bleu": 20.80363673237927,
      "eval_gen_len": 28.646,
      "eval_loss": 2.9622530937194824,
      "eval_runtime": 59.3166,
      "eval_samples_per_second": 16.859,
      "eval_steps_per_second": 1.062,
      "step": 6650
    },
    {
      "epoch": 0.4469648669507735,
      "grad_norm": 0.6701001524925232,
      "learning_rate": 0.00019267129818847817,
      "loss": 2.5764,
      "step": 6660
    },
    {
      "epoch": 0.44763598536961846,
      "grad_norm": 0.7411020994186401,
      "learning_rate": 0.00019264404857123428,
      "loss": 2.5736,
      "step": 6670
    },
    {
      "epoch": 0.4483071037884635,
      "grad_norm": 0.6816343665122986,
      "learning_rate": 0.00019261675032237753,
      "loss": 2.5872,
      "step": 6680
    },
    {
      "epoch": 0.4489782222073085,
      "grad_norm": 0.7325164079666138,
      "learning_rate": 0.00019258940345623758,
      "loss": 2.585,
      "step": 6690
    },
    {
      "epoch": 0.44964934062615347,
      "grad_norm": 0.6245982050895691,
      "learning_rate": 0.00019256200798716962,
      "loss": 2.5209,
      "step": 6700
    },
    {
      "epoch": 0.44964934062615347,
      "eval_bleu": 20.78601838303905,
      "eval_gen_len": 28.706,
      "eval_loss": 2.9637959003448486,
      "eval_runtime": 59.5894,
      "eval_samples_per_second": 16.782,
      "eval_steps_per_second": 1.057,
      "step": 6700
    },
    {
      "epoch": 0.4503204590449985,
      "grad_norm": 0.7039061188697815,
      "learning_rate": 0.00019253456392955432,
      "loss": 2.5459,
      "step": 6710
    },
    {
      "epoch": 0.4509915774638435,
      "grad_norm": 0.7355355024337769,
      "learning_rate": 0.00019250707129779793,
      "loss": 2.5769,
      "step": 6720
    },
    {
      "epoch": 0.4516626958826885,
      "grad_norm": 0.7308525443077087,
      "learning_rate": 0.00019247953010633208,
      "loss": 2.5854,
      "step": 6730
    },
    {
      "epoch": 0.4523338143015335,
      "grad_norm": 0.6654305458068848,
      "learning_rate": 0.00019245194036961402,
      "loss": 2.5561,
      "step": 6740
    },
    {
      "epoch": 0.4530049327203785,
      "grad_norm": 0.7094462513923645,
      "learning_rate": 0.0001924243021021264,
      "loss": 2.563,
      "step": 6750
    },
    {
      "epoch": 0.4530049327203785,
      "eval_bleu": 20.50123345280741,
      "eval_gen_len": 28.67,
      "eval_loss": 2.964608907699585,
      "eval_runtime": 60.025,
      "eval_samples_per_second": 16.66,
      "eval_steps_per_second": 1.05,
      "step": 6750
    },
    {
      "epoch": 0.4536760511392235,
      "grad_norm": 0.7667806148529053,
      "learning_rate": 0.0001923966153183774,
      "loss": 2.5895,
      "step": 6760
    },
    {
      "epoch": 0.45434716955806853,
      "grad_norm": 0.6964237689971924,
      "learning_rate": 0.00019236888003290055,
      "loss": 2.5817,
      "step": 6770
    },
    {
      "epoch": 0.4550182879769135,
      "grad_norm": 0.6106667518615723,
      "learning_rate": 0.000192341096260255,
      "loss": 2.5106,
      "step": 6780
    },
    {
      "epoch": 0.45568940639575856,
      "grad_norm": 0.7228162288665771,
      "learning_rate": 0.00019231326401502528,
      "loss": 2.4838,
      "step": 6790
    },
    {
      "epoch": 0.45636052481460354,
      "grad_norm": 0.6376764178276062,
      "learning_rate": 0.00019228538331182132,
      "loss": 2.5579,
      "step": 6800
    },
    {
      "epoch": 0.45636052481460354,
      "eval_bleu": 20.626127396153677,
      "eval_gen_len": 28.832,
      "eval_loss": 2.968050241470337,
      "eval_runtime": 59.941,
      "eval_samples_per_second": 16.683,
      "eval_steps_per_second": 1.051,
      "step": 6800
    },
    {
      "epoch": 0.4570316432334485,
      "grad_norm": 0.7132574319839478,
      "learning_rate": 0.00019225745416527853,
      "loss": 2.5227,
      "step": 6810
    },
    {
      "epoch": 0.45770276165229357,
      "grad_norm": 0.6989864706993103,
      "learning_rate": 0.0001922294765900578,
      "loss": 2.5747,
      "step": 6820
    },
    {
      "epoch": 0.45837388007113855,
      "grad_norm": 0.7881021499633789,
      "learning_rate": 0.00019220145060084534,
      "loss": 2.5983,
      "step": 6830
    },
    {
      "epoch": 0.45904499848998354,
      "grad_norm": 0.6777361631393433,
      "learning_rate": 0.00019217337621235282,
      "loss": 2.5669,
      "step": 6840
    },
    {
      "epoch": 0.4597161169088286,
      "grad_norm": 0.7178295254707336,
      "learning_rate": 0.00019214525343931737,
      "loss": 2.5723,
      "step": 6850
    },
    {
      "epoch": 0.4597161169088286,
      "eval_bleu": 20.64972205375798,
      "eval_gen_len": 28.956,
      "eval_loss": 2.964933395385742,
      "eval_runtime": 62.7196,
      "eval_samples_per_second": 15.944,
      "eval_steps_per_second": 1.004,
      "step": 6850
    },
    {
      "epoch": 0.46038723532767356,
      "grad_norm": 0.7404553890228271,
      "learning_rate": 0.00019211708229650143,
      "loss": 2.5828,
      "step": 6860
    },
    {
      "epoch": 0.46105835374651855,
      "grad_norm": 0.734150767326355,
      "learning_rate": 0.0001920888627986929,
      "loss": 2.566,
      "step": 6870
    },
    {
      "epoch": 0.4617294721653636,
      "grad_norm": 0.6923914551734924,
      "learning_rate": 0.00019206059496070497,
      "loss": 2.6199,
      "step": 6880
    },
    {
      "epoch": 0.46240059058420857,
      "grad_norm": 0.7562163472175598,
      "learning_rate": 0.00019203227879737632,
      "loss": 2.5929,
      "step": 6890
    },
    {
      "epoch": 0.4630717090030536,
      "grad_norm": 0.6955287456512451,
      "learning_rate": 0.00019200391432357095,
      "loss": 2.5237,
      "step": 6900
    },
    {
      "epoch": 0.4630717090030536,
      "eval_bleu": 20.543439747525724,
      "eval_gen_len": 28.718,
      "eval_loss": 2.967543363571167,
      "eval_runtime": 60.1172,
      "eval_samples_per_second": 16.634,
      "eval_steps_per_second": 1.048,
      "step": 6900
    },
    {
      "epoch": 0.4637428274218986,
      "grad_norm": 0.7037602663040161,
      "learning_rate": 0.0001919755015541782,
      "loss": 2.5832,
      "step": 6910
    },
    {
      "epoch": 0.4644139458407436,
      "grad_norm": 0.7952628135681152,
      "learning_rate": 0.0001919470405041128,
      "loss": 2.5528,
      "step": 6920
    },
    {
      "epoch": 0.4650850642595886,
      "grad_norm": 0.693916916847229,
      "learning_rate": 0.00019191853118831476,
      "loss": 2.5323,
      "step": 6930
    },
    {
      "epoch": 0.4657561826784336,
      "grad_norm": 0.7205097675323486,
      "learning_rate": 0.00019188997362174949,
      "loss": 2.5571,
      "step": 6940
    },
    {
      "epoch": 0.4664273010972786,
      "grad_norm": 0.7613552808761597,
      "learning_rate": 0.00019186136781940767,
      "loss": 2.5932,
      "step": 6950
    },
    {
      "epoch": 0.4664273010972786,
      "eval_bleu": 20.629397342516352,
      "eval_gen_len": 28.694,
      "eval_loss": 2.9617044925689697,
      "eval_runtime": 59.603,
      "eval_samples_per_second": 16.778,
      "eval_steps_per_second": 1.057,
      "step": 6950
    },
    {
      "epoch": 0.46709841951612363,
      "grad_norm": 0.7173516154289246,
      "learning_rate": 0.00019183271379630536,
      "loss": 2.5315,
      "step": 6960
    },
    {
      "epoch": 0.4677695379349686,
      "grad_norm": 0.72591233253479,
      "learning_rate": 0.00019180401156748396,
      "loss": 2.5556,
      "step": 6970
    },
    {
      "epoch": 0.46844065635381366,
      "grad_norm": 0.6928781270980835,
      "learning_rate": 0.00019177526114801002,
      "loss": 2.5575,
      "step": 6980
    },
    {
      "epoch": 0.46911177477265864,
      "grad_norm": 0.7125066518783569,
      "learning_rate": 0.0001917464625529756,
      "loss": 2.5911,
      "step": 6990
    },
    {
      "epoch": 0.4697828931915036,
      "grad_norm": 0.7139533758163452,
      "learning_rate": 0.00019171761579749784,
      "loss": 2.5603,
      "step": 7000
    },
    {
      "epoch": 0.4697828931915036,
      "eval_bleu": 20.64519756949798,
      "eval_gen_len": 28.772,
      "eval_loss": 2.9633727073669434,
      "eval_runtime": 59.5569,
      "eval_samples_per_second": 16.791,
      "eval_steps_per_second": 1.058,
      "step": 7000
    },
    {
      "epoch": 0.47045401161034867,
      "grad_norm": 0.7035785913467407,
      "learning_rate": 0.0001916887208967193,
      "loss": 2.5493,
      "step": 7010
    },
    {
      "epoch": 0.47112513002919365,
      "grad_norm": 0.711948037147522,
      "learning_rate": 0.0001916597778658078,
      "loss": 2.5607,
      "step": 7020
    },
    {
      "epoch": 0.47179624844803864,
      "grad_norm": 0.7015835046768188,
      "learning_rate": 0.00019163078671995633,
      "loss": 2.5422,
      "step": 7030
    },
    {
      "epoch": 0.4724673668668837,
      "grad_norm": 0.7125394344329834,
      "learning_rate": 0.0001916017474743833,
      "loss": 2.6046,
      "step": 7040
    },
    {
      "epoch": 0.47313848528572866,
      "grad_norm": 0.6848505735397339,
      "learning_rate": 0.00019157266014433214,
      "loss": 2.5729,
      "step": 7050
    },
    {
      "epoch": 0.47313848528572866,
      "eval_bleu": 20.621812620187722,
      "eval_gen_len": 28.677,
      "eval_loss": 2.9686858654022217,
      "eval_runtime": 59.0275,
      "eval_samples_per_second": 16.941,
      "eval_steps_per_second": 1.067,
      "step": 7050
    },
    {
      "epoch": 0.47380960370457365,
      "grad_norm": 0.6725437045097351,
      "learning_rate": 0.00019154352474507177,
      "loss": 2.5339,
      "step": 7060
    },
    {
      "epoch": 0.4744807221234187,
      "grad_norm": 0.7102304697036743,
      "learning_rate": 0.0001915143412918962,
      "loss": 2.5736,
      "step": 7070
    },
    {
      "epoch": 0.47515184054226367,
      "grad_norm": 0.6806737780570984,
      "learning_rate": 0.00019148510980012464,
      "loss": 2.529,
      "step": 7080
    },
    {
      "epoch": 0.4758229589611087,
      "grad_norm": 0.7068418860435486,
      "learning_rate": 0.00019145583028510165,
      "loss": 2.5728,
      "step": 7090
    },
    {
      "epoch": 0.4764940773799537,
      "grad_norm": 0.6611405611038208,
      "learning_rate": 0.00019142650276219683,
      "loss": 2.5365,
      "step": 7100
    },
    {
      "epoch": 0.4764940773799537,
      "eval_bleu": 20.758512753711592,
      "eval_gen_len": 28.649,
      "eval_loss": 2.965134859085083,
      "eval_runtime": 59.1752,
      "eval_samples_per_second": 16.899,
      "eval_steps_per_second": 1.065,
      "step": 7100
    },
    {
      "epoch": 0.4771651957987987,
      "grad_norm": 0.6252397298812866,
      "learning_rate": 0.00019139712724680513,
      "loss": 2.5743,
      "step": 7110
    },
    {
      "epoch": 0.4778363142176437,
      "grad_norm": 0.7058793306350708,
      "learning_rate": 0.0001913677037543466,
      "loss": 2.6087,
      "step": 7120
    },
    {
      "epoch": 0.4785074326364887,
      "grad_norm": 0.6993135213851929,
      "learning_rate": 0.0001913382323002665,
      "loss": 2.6199,
      "step": 7130
    },
    {
      "epoch": 0.4791785510553337,
      "grad_norm": 0.8456076383590698,
      "learning_rate": 0.00019130871290003532,
      "loss": 2.5884,
      "step": 7140
    },
    {
      "epoch": 0.47984966947417873,
      "grad_norm": 0.6552648544311523,
      "learning_rate": 0.00019127914556914862,
      "loss": 2.5695,
      "step": 7150
    },
    {
      "epoch": 0.47984966947417873,
      "eval_bleu": 21.006321418913195,
      "eval_gen_len": 28.872,
      "eval_loss": 2.9622862339019775,
      "eval_runtime": 59.8202,
      "eval_samples_per_second": 16.717,
      "eval_steps_per_second": 1.053,
      "step": 7150
    },
    {
      "epoch": 0.4805207878930237,
      "grad_norm": 0.6960366368293762,
      "learning_rate": 0.00019124953032312718,
      "loss": 2.5734,
      "step": 7160
    },
    {
      "epoch": 0.48119190631186876,
      "grad_norm": 0.6881344318389893,
      "learning_rate": 0.00019121986717751696,
      "loss": 2.5699,
      "step": 7170
    },
    {
      "epoch": 0.48186302473071374,
      "grad_norm": 0.6813328862190247,
      "learning_rate": 0.00019119015614788896,
      "loss": 2.5513,
      "step": 7180
    },
    {
      "epoch": 0.4825341431495587,
      "grad_norm": 0.7105774283409119,
      "learning_rate": 0.00019116039724983942,
      "loss": 2.4921,
      "step": 7190
    },
    {
      "epoch": 0.48320526156840377,
      "grad_norm": 0.7231072187423706,
      "learning_rate": 0.00019113059049898968,
      "loss": 2.5223,
      "step": 7200
    },
    {
      "epoch": 0.48320526156840377,
      "eval_bleu": 20.754791283616076,
      "eval_gen_len": 28.738,
      "eval_loss": 2.9649746417999268,
      "eval_runtime": 58.964,
      "eval_samples_per_second": 16.96,
      "eval_steps_per_second": 1.068,
      "step": 7200
    },
    {
      "epoch": 0.48387637998724875,
      "grad_norm": 0.6855787038803101,
      "learning_rate": 0.00019110073591098616,
      "loss": 2.5994,
      "step": 7210
    },
    {
      "epoch": 0.48454749840609374,
      "grad_norm": 0.7618501782417297,
      "learning_rate": 0.00019107083350150046,
      "loss": 2.586,
      "step": 7220
    },
    {
      "epoch": 0.4852186168249388,
      "grad_norm": 0.7047410011291504,
      "learning_rate": 0.0001910408832862292,
      "loss": 2.612,
      "step": 7230
    },
    {
      "epoch": 0.48588973524378376,
      "grad_norm": 0.7269008755683899,
      "learning_rate": 0.00019101088528089417,
      "loss": 2.5351,
      "step": 7240
    },
    {
      "epoch": 0.48656085366262875,
      "grad_norm": 0.7152213454246521,
      "learning_rate": 0.0001909808395012422,
      "loss": 2.5811,
      "step": 7250
    },
    {
      "epoch": 0.48656085366262875,
      "eval_bleu": 20.874254071950983,
      "eval_gen_len": 28.96,
      "eval_loss": 2.966104030609131,
      "eval_runtime": 62.9425,
      "eval_samples_per_second": 15.888,
      "eval_steps_per_second": 1.001,
      "step": 7250
    },
    {
      "epoch": 0.4872319720814738,
      "grad_norm": 0.6768462061882019,
      "learning_rate": 0.00019095074596304522,
      "loss": 2.5912,
      "step": 7260
    },
    {
      "epoch": 0.48790309050031877,
      "grad_norm": 0.7357741594314575,
      "learning_rate": 0.00019092060468210018,
      "loss": 2.5689,
      "step": 7270
    },
    {
      "epoch": 0.4885742089191638,
      "grad_norm": 0.7115773558616638,
      "learning_rate": 0.00019089041567422918,
      "loss": 2.5584,
      "step": 7280
    },
    {
      "epoch": 0.4892453273380088,
      "grad_norm": 0.7201570868492126,
      "learning_rate": 0.00019086017895527933,
      "loss": 2.584,
      "step": 7290
    },
    {
      "epoch": 0.4899164457568538,
      "grad_norm": 0.7081653475761414,
      "learning_rate": 0.00019082989454112273,
      "loss": 2.5423,
      "step": 7300
    },
    {
      "epoch": 0.4899164457568538,
      "eval_bleu": 20.65390740790278,
      "eval_gen_len": 28.802,
      "eval_loss": 2.961024761199951,
      "eval_runtime": 59.7841,
      "eval_samples_per_second": 16.727,
      "eval_steps_per_second": 1.054,
      "step": 7300
    },
    {
      "epoch": 0.4905875641756988,
      "grad_norm": 0.6752400994300842,
      "learning_rate": 0.00019079956244765666,
      "loss": 2.5783,
      "step": 7310
    },
    {
      "epoch": 0.4912586825945438,
      "grad_norm": 0.6706027388572693,
      "learning_rate": 0.00019076918269080327,
      "loss": 2.5947,
      "step": 7320
    },
    {
      "epoch": 0.4919298010133888,
      "grad_norm": 0.7695715427398682,
      "learning_rate": 0.00019073875528650977,
      "loss": 2.6039,
      "step": 7330
    },
    {
      "epoch": 0.49260091943223383,
      "grad_norm": 0.7058404088020325,
      "learning_rate": 0.0001907082802507485,
      "loss": 2.5516,
      "step": 7340
    },
    {
      "epoch": 0.4932720378510788,
      "grad_norm": 0.6882909536361694,
      "learning_rate": 0.0001906777575995166,
      "loss": 2.5664,
      "step": 7350
    },
    {
      "epoch": 0.4932720378510788,
      "eval_bleu": 20.65626091684208,
      "eval_gen_len": 28.828,
      "eval_loss": 2.959986686706543,
      "eval_runtime": 59.9034,
      "eval_samples_per_second": 16.694,
      "eval_steps_per_second": 1.052,
      "step": 7350
    },
    {
      "epoch": 0.49394315626992386,
      "grad_norm": 0.7421833276748657,
      "learning_rate": 0.00019064718734883643,
      "loss": 2.5596,
      "step": 7360
    },
    {
      "epoch": 0.49461427468876884,
      "grad_norm": 0.6898102760314941,
      "learning_rate": 0.00019061656951475513,
      "loss": 2.5324,
      "step": 7370
    },
    {
      "epoch": 0.4952853931076138,
      "grad_norm": 0.710668683052063,
      "learning_rate": 0.00019058590411334496,
      "loss": 2.5503,
      "step": 7380
    },
    {
      "epoch": 0.49595651152645887,
      "grad_norm": 0.7486669421195984,
      "learning_rate": 0.0001905551911607031,
      "loss": 2.5657,
      "step": 7390
    },
    {
      "epoch": 0.49662762994530385,
      "grad_norm": 0.7698072791099548,
      "learning_rate": 0.00019052443067295167,
      "loss": 2.5673,
      "step": 7400
    },
    {
      "epoch": 0.49662762994530385,
      "eval_bleu": 20.478870281572167,
      "eval_gen_len": 29.072,
      "eval_loss": 2.961869955062866,
      "eval_runtime": 62.4645,
      "eval_samples_per_second": 16.009,
      "eval_steps_per_second": 1.009,
      "step": 7400
    },
    {
      "epoch": 0.49729874836414883,
      "grad_norm": 0.6925027966499329,
      "learning_rate": 0.00019049362266623776,
      "loss": 2.5813,
      "step": 7410
    },
    {
      "epoch": 0.4979698667829939,
      "grad_norm": 0.7624210119247437,
      "learning_rate": 0.00019046276715673342,
      "loss": 2.6159,
      "step": 7420
    },
    {
      "epoch": 0.49864098520183886,
      "grad_norm": 0.6922113299369812,
      "learning_rate": 0.00019043186416063565,
      "loss": 2.5721,
      "step": 7430
    },
    {
      "epoch": 0.49931210362068384,
      "grad_norm": 0.7441298365592957,
      "learning_rate": 0.00019040091369416633,
      "loss": 2.5297,
      "step": 7440
    },
    {
      "epoch": 0.4999832220395289,
      "grad_norm": 0.6436293125152588,
      "learning_rate": 0.00019036991577357223,
      "loss": 2.5709,
      "step": 7450
    },
    {
      "epoch": 0.4999832220395289,
      "eval_bleu": 20.499768675786125,
      "eval_gen_len": 28.722,
      "eval_loss": 2.960500478744507,
      "eval_runtime": 58.4266,
      "eval_samples_per_second": 17.115,
      "eval_steps_per_second": 1.078,
      "step": 7450
    },
    {
      "epoch": 0.5006543404583739,
      "grad_norm": 0.7033135294914246,
      "learning_rate": 0.00019033887041512517,
      "loss": 2.5259,
      "step": 7460
    },
    {
      "epoch": 0.5013254588772189,
      "grad_norm": 0.6656261682510376,
      "learning_rate": 0.00019030777763512168,
      "loss": 2.5844,
      "step": 7470
    },
    {
      "epoch": 0.5019965772960638,
      "grad_norm": 0.7086334824562073,
      "learning_rate": 0.0001902766374498834,
      "loss": 2.5373,
      "step": 7480
    },
    {
      "epoch": 0.5026676957149089,
      "grad_norm": 0.681466817855835,
      "learning_rate": 0.00019024544987575662,
      "loss": 2.5448,
      "step": 7490
    },
    {
      "epoch": 0.5033388141337539,
      "grad_norm": 0.6420974135398865,
      "learning_rate": 0.00019021421492911272,
      "loss": 2.5581,
      "step": 7500
    },
    {
      "epoch": 0.5033388141337539,
      "eval_bleu": 20.676359699809908,
      "eval_gen_len": 28.752,
      "eval_loss": 2.9655234813690186,
      "eval_runtime": 59.025,
      "eval_samples_per_second": 16.942,
      "eval_steps_per_second": 1.067,
      "step": 7500
    },
    {
      "epoch": 0.504009932552599,
      "grad_norm": 0.6366434097290039,
      "learning_rate": 0.0001901829326263478,
      "loss": 2.5846,
      "step": 7510
    },
    {
      "epoch": 0.5046810509714439,
      "grad_norm": 0.6585820317268372,
      "learning_rate": 0.00019015160298388288,
      "loss": 2.5961,
      "step": 7520
    },
    {
      "epoch": 0.5053521693902889,
      "grad_norm": 0.6875059008598328,
      "learning_rate": 0.00019012022601816382,
      "loss": 2.5604,
      "step": 7530
    },
    {
      "epoch": 0.506023287809134,
      "grad_norm": 0.7006106376647949,
      "learning_rate": 0.0001900888017456613,
      "loss": 2.5566,
      "step": 7540
    },
    {
      "epoch": 0.5066944062279789,
      "grad_norm": 0.7340990900993347,
      "learning_rate": 0.00019005733018287089,
      "loss": 2.573,
      "step": 7550
    },
    {
      "epoch": 0.5066944062279789,
      "eval_bleu": 20.768943570526694,
      "eval_gen_len": 28.941,
      "eval_loss": 2.961421489715576,
      "eval_runtime": 59.0273,
      "eval_samples_per_second": 16.941,
      "eval_steps_per_second": 1.067,
      "step": 7550
    },
    {
      "epoch": 0.5073655246468239,
      "grad_norm": 0.660864531993866,
      "learning_rate": 0.00019002581134631297,
      "loss": 2.5441,
      "step": 7560
    },
    {
      "epoch": 0.508036643065669,
      "grad_norm": 0.7590190172195435,
      "learning_rate": 0.0001899942452525326,
      "loss": 2.6129,
      "step": 7570
    },
    {
      "epoch": 0.5087077614845139,
      "grad_norm": 0.7409668564796448,
      "learning_rate": 0.00018996263191809991,
      "loss": 2.6116,
      "step": 7580
    },
    {
      "epoch": 0.509378879903359,
      "grad_norm": 0.7014874815940857,
      "learning_rate": 0.00018993097135960957,
      "loss": 2.532,
      "step": 7590
    },
    {
      "epoch": 0.510049998322204,
      "grad_norm": 0.7151486277580261,
      "learning_rate": 0.0001898992635936812,
      "loss": 2.5566,
      "step": 7600
    },
    {
      "epoch": 0.510049998322204,
      "eval_bleu": 20.83380473409856,
      "eval_gen_len": 28.725,
      "eval_loss": 2.9644970893859863,
      "eval_runtime": 58.9582,
      "eval_samples_per_second": 16.961,
      "eval_steps_per_second": 1.069,
      "step": 7600
    },
    {
      "epoch": 0.5107211167410489,
      "grad_norm": 0.6979407072067261,
      "learning_rate": 0.00018986750863695913,
      "loss": 2.5605,
      "step": 7610
    },
    {
      "epoch": 0.511392235159894,
      "grad_norm": 0.733670711517334,
      "learning_rate": 0.0001898357065061125,
      "loss": 2.5368,
      "step": 7620
    },
    {
      "epoch": 0.512063353578739,
      "grad_norm": 0.6505081057548523,
      "learning_rate": 0.00018980385721783513,
      "loss": 2.5477,
      "step": 7630
    },
    {
      "epoch": 0.5127344719975839,
      "grad_norm": 0.6824465990066528,
      "learning_rate": 0.00018977196078884574,
      "loss": 2.5283,
      "step": 7640
    },
    {
      "epoch": 0.513405590416429,
      "grad_norm": 0.6782556772232056,
      "learning_rate": 0.00018974001723588764,
      "loss": 2.571,
      "step": 7650
    },
    {
      "epoch": 0.513405590416429,
      "eval_bleu": 20.503262194775758,
      "eval_gen_len": 28.622,
      "eval_loss": 2.966671943664551,
      "eval_runtime": 59.127,
      "eval_samples_per_second": 16.913,
      "eval_steps_per_second": 1.066,
      "step": 7650
    },
    {
      "epoch": 0.514076708835274,
      "grad_norm": 0.7048411965370178,
      "learning_rate": 0.00018970802657572902,
      "loss": 2.5742,
      "step": 7660
    },
    {
      "epoch": 0.5147478272541189,
      "grad_norm": 0.6894292235374451,
      "learning_rate": 0.00018967598882516266,
      "loss": 2.564,
      "step": 7670
    },
    {
      "epoch": 0.515418945672964,
      "grad_norm": 0.7185097336769104,
      "learning_rate": 0.00018964390400100621,
      "loss": 2.5385,
      "step": 7680
    },
    {
      "epoch": 0.516090064091809,
      "grad_norm": 0.6452571153640747,
      "learning_rate": 0.00018961177212010183,
      "loss": 2.598,
      "step": 7690
    },
    {
      "epoch": 0.5167611825106541,
      "grad_norm": 0.7328448295593262,
      "learning_rate": 0.0001895795931993166,
      "loss": 2.5724,
      "step": 7700
    },
    {
      "epoch": 0.5167611825106541,
      "eval_bleu": 20.395194161419372,
      "eval_gen_len": 28.878,
      "eval_loss": 2.967318058013916,
      "eval_runtime": 62.2505,
      "eval_samples_per_second": 16.064,
      "eval_steps_per_second": 1.012,
      "step": 7700
    },
    {
      "epoch": 0.517432300929499,
      "grad_norm": 0.7038909792900085,
      "learning_rate": 0.00018954736725554217,
      "loss": 2.55,
      "step": 7710
    },
    {
      "epoch": 0.518103419348344,
      "grad_norm": 0.700912594795227,
      "learning_rate": 0.00018951509430569486,
      "loss": 2.5834,
      "step": 7720
    },
    {
      "epoch": 0.5187745377671891,
      "grad_norm": 0.7233515381813049,
      "learning_rate": 0.00018948277436671573,
      "loss": 2.5533,
      "step": 7730
    },
    {
      "epoch": 0.519445656186034,
      "grad_norm": 0.6462708711624146,
      "learning_rate": 0.00018945040745557047,
      "loss": 2.5486,
      "step": 7740
    },
    {
      "epoch": 0.520116774604879,
      "grad_norm": 0.6846954226493835,
      "learning_rate": 0.00018941799358924944,
      "loss": 2.5316,
      "step": 7750
    },
    {
      "epoch": 0.520116774604879,
      "eval_bleu": 20.740513265819413,
      "eval_gen_len": 28.835,
      "eval_loss": 2.9591987133026123,
      "eval_runtime": 59.2418,
      "eval_samples_per_second": 16.88,
      "eval_steps_per_second": 1.063,
      "step": 7750
    },
    {
      "epoch": 0.5207878930237241,
      "grad_norm": 0.6763660907745361,
      "learning_rate": 0.00018938553278476762,
      "loss": 2.5416,
      "step": 7760
    },
    {
      "epoch": 0.521459011442569,
      "grad_norm": 0.632117509841919,
      "learning_rate": 0.00018935302505916466,
      "loss": 2.5447,
      "step": 7770
    },
    {
      "epoch": 0.522130129861414,
      "grad_norm": 0.6840952634811401,
      "learning_rate": 0.00018932047042950482,
      "loss": 2.5919,
      "step": 7780
    },
    {
      "epoch": 0.5228012482802591,
      "grad_norm": 0.6839354634284973,
      "learning_rate": 0.000189287868912877,
      "loss": 2.573,
      "step": 7790
    },
    {
      "epoch": 0.523472366699104,
      "grad_norm": 0.7480424642562866,
      "learning_rate": 0.00018925522052639474,
      "loss": 2.663,
      "step": 7800
    },
    {
      "epoch": 0.523472366699104,
      "eval_bleu": 20.55665779615584,
      "eval_gen_len": 28.648,
      "eval_loss": 2.9622390270233154,
      "eval_runtime": 58.9261,
      "eval_samples_per_second": 16.97,
      "eval_steps_per_second": 1.069,
      "step": 7800
    },
    {
      "epoch": 0.5241434851179491,
      "grad_norm": 0.6727577447891235,
      "learning_rate": 0.00018922252528719616,
      "loss": 2.5468,
      "step": 7810
    },
    {
      "epoch": 0.5248146035367941,
      "grad_norm": 0.6702200174331665,
      "learning_rate": 0.00018918978321244386,
      "loss": 2.5478,
      "step": 7820
    },
    {
      "epoch": 0.525485721955639,
      "grad_norm": 0.7328378558158875,
      "learning_rate": 0.00018915699431932518,
      "loss": 2.5629,
      "step": 7830
    },
    {
      "epoch": 0.5261568403744841,
      "grad_norm": 0.6514014601707458,
      "learning_rate": 0.00018912415862505202,
      "loss": 2.4972,
      "step": 7840
    },
    {
      "epoch": 0.5268279587933291,
      "grad_norm": 0.6493043899536133,
      "learning_rate": 0.00018909127614686076,
      "loss": 2.5584,
      "step": 7850
    },
    {
      "epoch": 0.5268279587933291,
      "eval_bleu": 20.620779167320656,
      "eval_gen_len": 28.663,
      "eval_loss": 2.969120740890503,
      "eval_runtime": 59.0174,
      "eval_samples_per_second": 16.944,
      "eval_steps_per_second": 1.067,
      "step": 7850
    },
    {
      "epoch": 0.527499077212174,
      "grad_norm": 0.7486986517906189,
      "learning_rate": 0.0001890583469020124,
      "loss": 2.5576,
      "step": 7860
    },
    {
      "epoch": 0.5281701956310191,
      "grad_norm": 0.6851825714111328,
      "learning_rate": 0.00018902537090779254,
      "loss": 2.5399,
      "step": 7870
    },
    {
      "epoch": 0.5288413140498641,
      "grad_norm": 0.700345516204834,
      "learning_rate": 0.00018899234818151118,
      "loss": 2.5199,
      "step": 7880
    },
    {
      "epoch": 0.529512432468709,
      "grad_norm": 0.7219380140304565,
      "learning_rate": 0.00018895927874050297,
      "loss": 2.5002,
      "step": 7890
    },
    {
      "epoch": 0.5301835508875541,
      "grad_norm": 0.7190829515457153,
      "learning_rate": 0.00018892616260212698,
      "loss": 2.5672,
      "step": 7900
    },
    {
      "epoch": 0.5301835508875541,
      "eval_bleu": 20.654659349114098,
      "eval_gen_len": 28.704,
      "eval_loss": 2.963559150695801,
      "eval_runtime": 58.9747,
      "eval_samples_per_second": 16.956,
      "eval_steps_per_second": 1.068,
      "step": 7900
    },
    {
      "epoch": 0.5308546693063991,
      "grad_norm": 0.6791065335273743,
      "learning_rate": 0.00018889299978376694,
      "loss": 2.5191,
      "step": 7910
    },
    {
      "epoch": 0.5315257877252442,
      "grad_norm": 0.7280360460281372,
      "learning_rate": 0.000188859790302831,
      "loss": 2.5662,
      "step": 7920
    },
    {
      "epoch": 0.5321969061440891,
      "grad_norm": 0.7260386943817139,
      "learning_rate": 0.00018882653417675175,
      "loss": 2.6455,
      "step": 7930
    },
    {
      "epoch": 0.5328680245629341,
      "grad_norm": 0.6922085881233215,
      "learning_rate": 0.00018879323142298633,
      "loss": 2.5926,
      "step": 7940
    },
    {
      "epoch": 0.5335391429817792,
      "grad_norm": 0.693021833896637,
      "learning_rate": 0.00018875988205901634,
      "loss": 2.6028,
      "step": 7950
    },
    {
      "epoch": 0.5335391429817792,
      "eval_bleu": 20.823739336785735,
      "eval_gen_len": 28.864,
      "eval_loss": 2.9604570865631104,
      "eval_runtime": 60.0956,
      "eval_samples_per_second": 16.64,
      "eval_steps_per_second": 1.048,
      "step": 7950
    },
    {
      "epoch": 0.5342102614006241,
      "grad_norm": 0.7080903053283691,
      "learning_rate": 0.00018872648610234786,
      "loss": 2.5949,
      "step": 7960
    },
    {
      "epoch": 0.5348813798194691,
      "grad_norm": 0.7040042281150818,
      "learning_rate": 0.00018869304357051143,
      "loss": 2.6555,
      "step": 7970
    },
    {
      "epoch": 0.5355524982383142,
      "grad_norm": 0.7021758556365967,
      "learning_rate": 0.00018865955448106201,
      "loss": 2.5696,
      "step": 7980
    },
    {
      "epoch": 0.5362236166571591,
      "grad_norm": 0.6628636717796326,
      "learning_rate": 0.00018862601885157905,
      "loss": 2.6138,
      "step": 7990
    },
    {
      "epoch": 0.5368947350760042,
      "grad_norm": 0.7050763368606567,
      "learning_rate": 0.00018859243669966635,
      "loss": 2.6108,
      "step": 8000
    },
    {
      "epoch": 0.5368947350760042,
      "eval_bleu": 20.82430850099479,
      "eval_gen_len": 28.758,
      "eval_loss": 2.9609875679016113,
      "eval_runtime": 59.3066,
      "eval_samples_per_second": 16.862,
      "eval_steps_per_second": 1.062,
      "step": 8000
    },
    {
      "epoch": 0.5375658534948492,
      "grad_norm": 0.6907671093940735,
      "learning_rate": 0.0001885588080429522,
      "loss": 2.5148,
      "step": 8010
    },
    {
      "epoch": 0.5382369719136941,
      "grad_norm": 0.6755040884017944,
      "learning_rate": 0.00018852513289908932,
      "loss": 2.5301,
      "step": 8020
    },
    {
      "epoch": 0.5389080903325392,
      "grad_norm": 0.6968406438827515,
      "learning_rate": 0.00018849141128575474,
      "loss": 2.5329,
      "step": 8030
    },
    {
      "epoch": 0.5395792087513842,
      "grad_norm": 0.6758775115013123,
      "learning_rate": 0.00018845764322064995,
      "loss": 2.5439,
      "step": 8040
    },
    {
      "epoch": 0.5402503271702291,
      "grad_norm": 0.6830512881278992,
      "learning_rate": 0.00018842382872150083,
      "loss": 2.5521,
      "step": 8050
    },
    {
      "epoch": 0.5402503271702291,
      "eval_bleu": 20.934043580691633,
      "eval_gen_len": 28.86,
      "eval_loss": 2.959381341934204,
      "eval_runtime": 59.427,
      "eval_samples_per_second": 16.827,
      "eval_steps_per_second": 1.06,
      "step": 8050
    },
    {
      "epoch": 0.5409214455890742,
      "grad_norm": 0.6901206374168396,
      "learning_rate": 0.00018838996780605759,
      "loss": 2.5293,
      "step": 8060
    },
    {
      "epoch": 0.5415925640079192,
      "grad_norm": 0.6389092803001404,
      "learning_rate": 0.00018835606049209482,
      "loss": 2.5432,
      "step": 8070
    },
    {
      "epoch": 0.5422636824267641,
      "grad_norm": 0.679087221622467,
      "learning_rate": 0.0001883221067974115,
      "loss": 2.5041,
      "step": 8080
    },
    {
      "epoch": 0.5429348008456092,
      "grad_norm": 0.7048007845878601,
      "learning_rate": 0.00018828810673983097,
      "loss": 2.5781,
      "step": 8090
    },
    {
      "epoch": 0.5436059192644542,
      "grad_norm": 0.6871178150177002,
      "learning_rate": 0.00018825406033720082,
      "loss": 2.5829,
      "step": 8100
    },
    {
      "epoch": 0.5436059192644542,
      "eval_bleu": 20.92783006951422,
      "eval_gen_len": 28.667,
      "eval_loss": 2.961977243423462,
      "eval_runtime": 59.3961,
      "eval_samples_per_second": 16.836,
      "eval_steps_per_second": 1.061,
      "step": 8100
    },
    {
      "epoch": 0.5442770376832993,
      "grad_norm": 0.7286919951438904,
      "learning_rate": 0.00018821996760739302,
      "loss": 2.5651,
      "step": 8110
    },
    {
      "epoch": 0.5449481561021442,
      "grad_norm": 0.7783398628234863,
      "learning_rate": 0.00018818582856830384,
      "loss": 2.5553,
      "step": 8120
    },
    {
      "epoch": 0.5456192745209892,
      "grad_norm": 0.6838525533676147,
      "learning_rate": 0.0001881516432378539,
      "loss": 2.5342,
      "step": 8130
    },
    {
      "epoch": 0.5462903929398343,
      "grad_norm": 0.7343071699142456,
      "learning_rate": 0.00018811741163398814,
      "loss": 2.5706,
      "step": 8140
    },
    {
      "epoch": 0.5469615113586792,
      "grad_norm": 0.6913207769393921,
      "learning_rate": 0.00018808313377467568,
      "loss": 2.5274,
      "step": 8150
    },
    {
      "epoch": 0.5469615113586792,
      "eval_bleu": 20.450428168520073,
      "eval_gen_len": 28.641,
      "eval_loss": 2.975206136703491,
      "eval_runtime": 59.2507,
      "eval_samples_per_second": 16.877,
      "eval_steps_per_second": 1.063,
      "step": 8150
    },
    {
      "epoch": 0.5476326297775242,
      "grad_norm": 0.766120970249176,
      "learning_rate": 0.00018804880967791002,
      "loss": 2.6009,
      "step": 8160
    },
    {
      "epoch": 0.5483037481963693,
      "grad_norm": 0.6817499995231628,
      "learning_rate": 0.00018801443936170885,
      "loss": 2.5494,
      "step": 8170
    },
    {
      "epoch": 0.5489748666152142,
      "grad_norm": 0.7512232661247253,
      "learning_rate": 0.0001879800228441142,
      "loss": 2.5607,
      "step": 8180
    },
    {
      "epoch": 0.5496459850340593,
      "grad_norm": 0.7162403464317322,
      "learning_rate": 0.00018794556014319237,
      "loss": 2.5859,
      "step": 8190
    },
    {
      "epoch": 0.5503171034529043,
      "grad_norm": 0.6559749841690063,
      "learning_rate": 0.0001879110512770338,
      "loss": 2.5377,
      "step": 8200
    },
    {
      "epoch": 0.5503171034529043,
      "eval_bleu": 21.024969406157027,
      "eval_gen_len": 28.662,
      "eval_loss": 2.960249662399292,
      "eval_runtime": 59.0998,
      "eval_samples_per_second": 16.921,
      "eval_steps_per_second": 1.066,
      "step": 8200
    },
    {
      "epoch": 0.5509882218717492,
      "grad_norm": 0.7105274796485901,
      "learning_rate": 0.00018787649626375322,
      "loss": 2.5401,
      "step": 8210
    },
    {
      "epoch": 0.5516593402905943,
      "grad_norm": 0.7114341855049133,
      "learning_rate": 0.00018784189512148963,
      "loss": 2.5665,
      "step": 8220
    },
    {
      "epoch": 0.5523304587094393,
      "grad_norm": 0.7063767910003662,
      "learning_rate": 0.0001878072478684061,
      "loss": 2.6034,
      "step": 8230
    },
    {
      "epoch": 0.5530015771282842,
      "grad_norm": 0.6879712343215942,
      "learning_rate": 0.00018777255452269009,
      "loss": 2.5658,
      "step": 8240
    },
    {
      "epoch": 0.5536726955471293,
      "grad_norm": 0.732601523399353,
      "learning_rate": 0.00018773781510255318,
      "loss": 2.5233,
      "step": 8250
    },
    {
      "epoch": 0.5536726955471293,
      "eval_bleu": 20.54796839301087,
      "eval_gen_len": 29.163,
      "eval_loss": 2.969637870788574,
      "eval_runtime": 65.3148,
      "eval_samples_per_second": 15.31,
      "eval_steps_per_second": 0.965,
      "step": 8250
    },
    {
      "epoch": 0.5543438139659743,
      "grad_norm": 0.6376473307609558,
      "learning_rate": 0.00018770302962623102,
      "loss": 2.5724,
      "step": 8260
    },
    {
      "epoch": 0.5550149323848192,
      "grad_norm": 0.7193272709846497,
      "learning_rate": 0.00018766819811198365,
      "loss": 2.5634,
      "step": 8270
    },
    {
      "epoch": 0.5556860508036643,
      "grad_norm": 0.6548462510108948,
      "learning_rate": 0.00018763332057809514,
      "loss": 2.5815,
      "step": 8280
    },
    {
      "epoch": 0.5563571692225093,
      "grad_norm": 0.6895740032196045,
      "learning_rate": 0.00018759839704287368,
      "loss": 2.558,
      "step": 8290
    },
    {
      "epoch": 0.5570282876413544,
      "grad_norm": 0.7934114336967468,
      "learning_rate": 0.00018756342752465171,
      "loss": 2.5681,
      "step": 8300
    },
    {
      "epoch": 0.5570282876413544,
      "eval_bleu": 20.67721146827233,
      "eval_gen_len": 28.744,
      "eval_loss": 2.9557301998138428,
      "eval_runtime": 59.4108,
      "eval_samples_per_second": 16.832,
      "eval_steps_per_second": 1.06,
      "step": 8300
    },
    {
      "epoch": 0.5576994060601993,
      "grad_norm": 0.6819393038749695,
      "learning_rate": 0.00018752841204178582,
      "loss": 2.5702,
      "step": 8310
    },
    {
      "epoch": 0.5583705244790443,
      "grad_norm": 0.7319605350494385,
      "learning_rate": 0.0001874933506126566,
      "loss": 2.6064,
      "step": 8320
    },
    {
      "epoch": 0.5590416428978894,
      "grad_norm": 0.7004058957099915,
      "learning_rate": 0.00018745824325566888,
      "loss": 2.5331,
      "step": 8330
    },
    {
      "epoch": 0.5597127613167343,
      "grad_norm": 0.7006226181983948,
      "learning_rate": 0.00018742308998925152,
      "loss": 2.4854,
      "step": 8340
    },
    {
      "epoch": 0.5603838797355793,
      "grad_norm": 0.7426981925964355,
      "learning_rate": 0.00018738789083185754,
      "loss": 2.5397,
      "step": 8350
    },
    {
      "epoch": 0.5603838797355793,
      "eval_bleu": 20.58236772489202,
      "eval_gen_len": 28.789,
      "eval_loss": 2.95550799369812,
      "eval_runtime": 59.4023,
      "eval_samples_per_second": 16.834,
      "eval_steps_per_second": 1.061,
      "step": 8350
    },
    {
      "epoch": 0.5610549981544244,
      "grad_norm": 0.6382885575294495,
      "learning_rate": 0.00018735264580196405,
      "loss": 2.4922,
      "step": 8360
    },
    {
      "epoch": 0.5617261165732693,
      "grad_norm": 0.6797400712966919,
      "learning_rate": 0.00018731735491807217,
      "loss": 2.5841,
      "step": 8370
    },
    {
      "epoch": 0.5623972349921144,
      "grad_norm": 0.6613810658454895,
      "learning_rate": 0.00018728201819870712,
      "loss": 2.524,
      "step": 8380
    },
    {
      "epoch": 0.5630683534109594,
      "grad_norm": 0.7640516757965088,
      "learning_rate": 0.00018724663566241825,
      "loss": 2.526,
      "step": 8390
    },
    {
      "epoch": 0.5637394718298043,
      "grad_norm": 0.680022120475769,
      "learning_rate": 0.00018721120732777887,
      "loss": 2.5277,
      "step": 8400
    },
    {
      "epoch": 0.5637394718298043,
      "eval_bleu": 21.20806023601023,
      "eval_gen_len": 28.821,
      "eval_loss": 2.9570157527923584,
      "eval_runtime": 59.6024,
      "eval_samples_per_second": 16.778,
      "eval_steps_per_second": 1.057,
      "step": 8400
    },
    {
      "epoch": 0.5644105902486494,
      "grad_norm": 0.6729101538658142,
      "learning_rate": 0.00018717573321338636,
      "loss": 2.5686,
      "step": 8410
    },
    {
      "epoch": 0.5650817086674944,
      "grad_norm": 0.7189227938652039,
      "learning_rate": 0.00018714021333786213,
      "loss": 2.566,
      "step": 8420
    },
    {
      "epoch": 0.5657528270863393,
      "grad_norm": 0.7570497393608093,
      "learning_rate": 0.00018710464771985166,
      "loss": 2.5224,
      "step": 8430
    },
    {
      "epoch": 0.5664239455051844,
      "grad_norm": 0.7093820571899414,
      "learning_rate": 0.00018706903637802434,
      "loss": 2.579,
      "step": 8440
    },
    {
      "epoch": 0.5670950639240294,
      "grad_norm": 0.6924270391464233,
      "learning_rate": 0.00018703337933107368,
      "loss": 2.5388,
      "step": 8450
    },
    {
      "epoch": 0.5670950639240294,
      "eval_bleu": 20.815431950787733,
      "eval_gen_len": 28.88,
      "eval_loss": 2.957719087600708,
      "eval_runtime": 60.1815,
      "eval_samples_per_second": 16.616,
      "eval_steps_per_second": 1.047,
      "step": 8450
    },
    {
      "epoch": 0.5677661823428743,
      "grad_norm": 0.7427591681480408,
      "learning_rate": 0.00018699767659771706,
      "loss": 2.5676,
      "step": 8460
    },
    {
      "epoch": 0.5684373007617194,
      "grad_norm": 0.729706883430481,
      "learning_rate": 0.000186961928196696,
      "loss": 2.5451,
      "step": 8470
    },
    {
      "epoch": 0.5691084191805644,
      "grad_norm": 0.6501044034957886,
      "learning_rate": 0.00018692613414677577,
      "loss": 2.6011,
      "step": 8480
    },
    {
      "epoch": 0.5697795375994095,
      "grad_norm": 0.7116053700447083,
      "learning_rate": 0.00018689029446674582,
      "loss": 2.5314,
      "step": 8490
    },
    {
      "epoch": 0.5704506560182544,
      "grad_norm": 0.6915543675422668,
      "learning_rate": 0.00018685440917541946,
      "loss": 2.5586,
      "step": 8500
    },
    {
      "epoch": 0.5704506560182544,
      "eval_bleu": 21.338006875449086,
      "eval_gen_len": 28.814,
      "eval_loss": 2.958536386489868,
      "eval_runtime": 59.5981,
      "eval_samples_per_second": 16.779,
      "eval_steps_per_second": 1.057,
      "step": 8500
    },
    {
      "epoch": 0.5711217744370994,
      "grad_norm": 0.7104238271713257,
      "learning_rate": 0.0001868184782916339,
      "loss": 2.6295,
      "step": 8510
    },
    {
      "epoch": 0.5717928928559445,
      "grad_norm": 0.7254042625427246,
      "learning_rate": 0.00018678250183425037,
      "loss": 2.5916,
      "step": 8520
    },
    {
      "epoch": 0.5724640112747894,
      "grad_norm": 0.6426904201507568,
      "learning_rate": 0.00018674647982215396,
      "loss": 2.5282,
      "step": 8530
    },
    {
      "epoch": 0.5731351296936344,
      "grad_norm": 0.7566561102867126,
      "learning_rate": 0.0001867104122742537,
      "loss": 2.5653,
      "step": 8540
    },
    {
      "epoch": 0.5738062481124795,
      "grad_norm": 0.7001218199729919,
      "learning_rate": 0.00018667429920948253,
      "loss": 2.5185,
      "step": 8550
    },
    {
      "epoch": 0.5738062481124795,
      "eval_bleu": 20.830427472342222,
      "eval_gen_len": 28.863,
      "eval_loss": 2.9555814266204834,
      "eval_runtime": 60.1654,
      "eval_samples_per_second": 16.621,
      "eval_steps_per_second": 1.047,
      "step": 8550
    },
    {
      "epoch": 0.5744773665313244,
      "grad_norm": 0.7026042342185974,
      "learning_rate": 0.00018663814064679723,
      "loss": 2.4836,
      "step": 8560
    },
    {
      "epoch": 0.5751484849501695,
      "grad_norm": 0.6425732970237732,
      "learning_rate": 0.00018660193660517856,
      "loss": 2.5371,
      "step": 8570
    },
    {
      "epoch": 0.5758196033690145,
      "grad_norm": 0.6540849804878235,
      "learning_rate": 0.00018656568710363107,
      "loss": 2.5413,
      "step": 8580
    },
    {
      "epoch": 0.5764907217878594,
      "grad_norm": 0.6648764610290527,
      "learning_rate": 0.00018652939216118317,
      "loss": 2.5475,
      "step": 8590
    },
    {
      "epoch": 0.5771618402067045,
      "grad_norm": 0.734247088432312,
      "learning_rate": 0.00018649305179688718,
      "loss": 2.5288,
      "step": 8600
    },
    {
      "epoch": 0.5771618402067045,
      "eval_bleu": 21.10369419447801,
      "eval_gen_len": 28.798,
      "eval_loss": 2.9596595764160156,
      "eval_runtime": 59.6733,
      "eval_samples_per_second": 16.758,
      "eval_steps_per_second": 1.056,
      "step": 8600
    },
    {
      "epoch": 0.5778329586255495,
      "grad_norm": 0.7057855725288391,
      "learning_rate": 0.00018645666602981926,
      "loss": 2.5603,
      "step": 8610
    },
    {
      "epoch": 0.5785040770443944,
      "grad_norm": 0.6749910116195679,
      "learning_rate": 0.00018642023487907934,
      "loss": 2.5191,
      "step": 8620
    },
    {
      "epoch": 0.5791751954632395,
      "grad_norm": 0.762695848941803,
      "learning_rate": 0.00018638375836379123,
      "loss": 2.5402,
      "step": 8630
    },
    {
      "epoch": 0.5798463138820845,
      "grad_norm": 0.6835897564888,
      "learning_rate": 0.00018634723650310254,
      "loss": 2.5175,
      "step": 8640
    },
    {
      "epoch": 0.5805174323009294,
      "grad_norm": 0.7055345177650452,
      "learning_rate": 0.0001863106693161847,
      "loss": 2.5196,
      "step": 8650
    },
    {
      "epoch": 0.5805174323009294,
      "eval_bleu": 20.781766697685878,
      "eval_gen_len": 28.642,
      "eval_loss": 2.957890510559082,
      "eval_runtime": 59.867,
      "eval_samples_per_second": 16.704,
      "eval_steps_per_second": 1.052,
      "step": 8650
    },
    {
      "epoch": 0.5811885507197745,
      "grad_norm": 0.6769084930419922,
      "learning_rate": 0.00018627405682223284,
      "loss": 2.5564,
      "step": 8660
    },
    {
      "epoch": 0.5818596691386195,
      "grad_norm": 0.6532343626022339,
      "learning_rate": 0.00018623739904046602,
      "loss": 2.5414,
      "step": 8670
    },
    {
      "epoch": 0.5825307875574646,
      "grad_norm": 0.7122054696083069,
      "learning_rate": 0.00018620069599012697,
      "loss": 2.5821,
      "step": 8680
    },
    {
      "epoch": 0.5832019059763095,
      "grad_norm": 0.6748215556144714,
      "learning_rate": 0.00018616394769048223,
      "loss": 2.5602,
      "step": 8690
    },
    {
      "epoch": 0.5838730243951545,
      "grad_norm": 0.703536331653595,
      "learning_rate": 0.00018612715416082204,
      "loss": 2.5955,
      "step": 8700
    },
    {
      "epoch": 0.5838730243951545,
      "eval_bleu": 20.752316277572163,
      "eval_gen_len": 28.639,
      "eval_loss": 2.95839262008667,
      "eval_runtime": 58.7768,
      "eval_samples_per_second": 17.014,
      "eval_steps_per_second": 1.072,
      "step": 8700
    },
    {
      "epoch": 0.5845441428139996,
      "grad_norm": 0.6990696787834167,
      "learning_rate": 0.00018609031542046042,
      "loss": 2.5645,
      "step": 8710
    },
    {
      "epoch": 0.5852152612328445,
      "grad_norm": 0.6733023524284363,
      "learning_rate": 0.00018605343148873517,
      "loss": 2.5421,
      "step": 8720
    },
    {
      "epoch": 0.5858863796516895,
      "grad_norm": 0.6496073007583618,
      "learning_rate": 0.0001860165023850077,
      "loss": 2.5679,
      "step": 8730
    },
    {
      "epoch": 0.5865574980705346,
      "grad_norm": 0.7026729583740234,
      "learning_rate": 0.00018597952812866324,
      "loss": 2.5489,
      "step": 8740
    },
    {
      "epoch": 0.5872286164893795,
      "grad_norm": 0.7646923661231995,
      "learning_rate": 0.00018594250873911063,
      "loss": 2.5723,
      "step": 8750
    },
    {
      "epoch": 0.5872286164893795,
      "eval_bleu": 20.633838759385412,
      "eval_gen_len": 28.681,
      "eval_loss": 2.96125864982605,
      "eval_runtime": 59.1741,
      "eval_samples_per_second": 16.899,
      "eval_steps_per_second": 1.065,
      "step": 8750
    },
    {
      "epoch": 0.5878997349082246,
      "grad_norm": 0.7258631587028503,
      "learning_rate": 0.00018590544423578245,
      "loss": 2.5785,
      "step": 8760
    },
    {
      "epoch": 0.5885708533270696,
      "grad_norm": 0.6935256719589233,
      "learning_rate": 0.00018586833463813505,
      "loss": 2.5916,
      "step": 8770
    },
    {
      "epoch": 0.5892419717459145,
      "grad_norm": 0.7579182386398315,
      "learning_rate": 0.00018583117996564822,
      "loss": 2.5867,
      "step": 8780
    },
    {
      "epoch": 0.5899130901647596,
      "grad_norm": 0.64875328540802,
      "learning_rate": 0.00018579398023782566,
      "loss": 2.488,
      "step": 8790
    },
    {
      "epoch": 0.5905842085836046,
      "grad_norm": 0.7045663595199585,
      "learning_rate": 0.00018575673547419457,
      "loss": 2.5003,
      "step": 8800
    },
    {
      "epoch": 0.5905842085836046,
      "eval_bleu": 21.331745736300558,
      "eval_gen_len": 28.864,
      "eval_loss": 2.9527432918548584,
      "eval_runtime": 59.9993,
      "eval_samples_per_second": 16.667,
      "eval_steps_per_second": 1.05,
      "step": 8800
    },
    {
      "epoch": 0.5912553270024495,
      "grad_norm": 0.7238126397132874,
      "learning_rate": 0.0001857194456943058,
      "loss": 2.553,
      "step": 8810
    },
    {
      "epoch": 0.5919264454212946,
      "grad_norm": 0.6867280602455139,
      "learning_rate": 0.00018568211091773393,
      "loss": 2.584,
      "step": 8820
    },
    {
      "epoch": 0.5925975638401396,
      "grad_norm": 0.6793977618217468,
      "learning_rate": 0.0001856447311640771,
      "loss": 2.5277,
      "step": 8830
    },
    {
      "epoch": 0.5932686822589845,
      "grad_norm": 0.7116599678993225,
      "learning_rate": 0.00018560730645295694,
      "loss": 2.5455,
      "step": 8840
    },
    {
      "epoch": 0.5939398006778296,
      "grad_norm": 0.625359058380127,
      "learning_rate": 0.00018556983680401888,
      "loss": 2.4982,
      "step": 8850
    },
    {
      "epoch": 0.5939398006778296,
      "eval_bleu": 21.563818994485395,
      "eval_gen_len": 28.976,
      "eval_loss": 2.9554052352905273,
      "eval_runtime": 59.7949,
      "eval_samples_per_second": 16.724,
      "eval_steps_per_second": 1.054,
      "step": 8850
    },
    {
      "epoch": 0.5946109190966746,
      "grad_norm": 0.7028990387916565,
      "learning_rate": 0.00018553232223693188,
      "loss": 2.5922,
      "step": 8860
    },
    {
      "epoch": 0.5952820375155197,
      "grad_norm": 0.6722476482391357,
      "learning_rate": 0.00018549476277138837,
      "loss": 2.595,
      "step": 8870
    },
    {
      "epoch": 0.5959531559343646,
      "grad_norm": 0.6743056774139404,
      "learning_rate": 0.00018545715842710448,
      "loss": 2.5876,
      "step": 8880
    },
    {
      "epoch": 0.5966242743532096,
      "grad_norm": 0.6977289319038391,
      "learning_rate": 0.00018541950922381986,
      "loss": 2.5832,
      "step": 8890
    },
    {
      "epoch": 0.5972953927720547,
      "grad_norm": 0.6649413108825684,
      "learning_rate": 0.00018538181518129766,
      "loss": 2.5763,
      "step": 8900
    },
    {
      "epoch": 0.5972953927720547,
      "eval_bleu": 21.229464223067005,
      "eval_gen_len": 28.841,
      "eval_loss": 2.9532790184020996,
      "eval_runtime": 62.2494,
      "eval_samples_per_second": 16.064,
      "eval_steps_per_second": 1.012,
      "step": 8900
    },
    {
      "epoch": 0.5979665111908996,
      "grad_norm": 0.726865828037262,
      "learning_rate": 0.00018534407631932458,
      "loss": 2.5551,
      "step": 8910
    },
    {
      "epoch": 0.5986376296097446,
      "grad_norm": 0.7624341249465942,
      "learning_rate": 0.00018530629265771094,
      "loss": 2.5819,
      "step": 8920
    },
    {
      "epoch": 0.5993087480285897,
      "grad_norm": 0.7293897867202759,
      "learning_rate": 0.00018526846421629042,
      "loss": 2.554,
      "step": 8930
    },
    {
      "epoch": 0.5999798664474346,
      "grad_norm": 0.817901074886322,
      "learning_rate": 0.0001852305910149204,
      "loss": 2.5275,
      "step": 8940
    },
    {
      "epoch": 0.6006509848662797,
      "grad_norm": 0.7139449119567871,
      "learning_rate": 0.00018519267307348156,
      "loss": 2.5331,
      "step": 8950
    },
    {
      "epoch": 0.6006509848662797,
      "eval_bleu": 20.88695359789752,
      "eval_gen_len": 28.797,
      "eval_loss": 2.9561424255371094,
      "eval_runtime": 62.6213,
      "eval_samples_per_second": 15.969,
      "eval_steps_per_second": 1.006,
      "step": 8950
    },
    {
      "epoch": 0.6013221032851247,
      "grad_norm": 0.7236172556877136,
      "learning_rate": 0.0001851547104118782,
      "loss": 2.5791,
      "step": 8960
    },
    {
      "epoch": 0.6019932217039696,
      "grad_norm": 0.708051860332489,
      "learning_rate": 0.00018511670305003803,
      "loss": 2.5662,
      "step": 8970
    },
    {
      "epoch": 0.6026643401228147,
      "grad_norm": 0.6862062811851501,
      "learning_rate": 0.00018507865100791224,
      "loss": 2.5863,
      "step": 8980
    },
    {
      "epoch": 0.6033354585416597,
      "grad_norm": 0.7245525121688843,
      "learning_rate": 0.0001850405543054755,
      "loss": 2.5398,
      "step": 8990
    },
    {
      "epoch": 0.6040065769605046,
      "grad_norm": 0.6999377012252808,
      "learning_rate": 0.0001850024129627258,
      "loss": 2.5617,
      "step": 9000
    },
    {
      "epoch": 0.6040065769605046,
      "eval_bleu": 21.25395824244856,
      "eval_gen_len": 28.747,
      "eval_loss": 2.957735061645508,
      "eval_runtime": 63.643,
      "eval_samples_per_second": 15.713,
      "eval_steps_per_second": 0.99,
      "step": 9000
    },
    {
      "epoch": 0.6046776953793497,
      "grad_norm": 0.7040273547172546,
      "learning_rate": 0.00018496422699968484,
      "loss": 2.4795,
      "step": 9010
    },
    {
      "epoch": 0.6053488137981947,
      "grad_norm": 0.7142210602760315,
      "learning_rate": 0.00018492599643639746,
      "loss": 2.5055,
      "step": 9020
    },
    {
      "epoch": 0.6060199322170396,
      "grad_norm": 0.6642273664474487,
      "learning_rate": 0.000184887721292932,
      "loss": 2.4939,
      "step": 9030
    },
    {
      "epoch": 0.6066910506358847,
      "grad_norm": 0.7208720445632935,
      "learning_rate": 0.00018484940158938027,
      "loss": 2.5314,
      "step": 9040
    },
    {
      "epoch": 0.6073621690547297,
      "grad_norm": 0.6414919495582581,
      "learning_rate": 0.00018481103734585742,
      "loss": 2.5452,
      "step": 9050
    },
    {
      "epoch": 0.6073621690547297,
      "eval_bleu": 20.80213655143905,
      "eval_gen_len": 28.648,
      "eval_loss": 2.9584712982177734,
      "eval_runtime": 64.7119,
      "eval_samples_per_second": 15.453,
      "eval_steps_per_second": 0.974,
      "step": 9050
    },
    {
      "epoch": 0.6080332874735747,
      "grad_norm": 0.7137303352355957,
      "learning_rate": 0.0001847726285825019,
      "loss": 2.4979,
      "step": 9060
    },
    {
      "epoch": 0.6087044058924197,
      "grad_norm": 0.6644724011421204,
      "learning_rate": 0.00018473417531947574,
      "loss": 2.5396,
      "step": 9070
    },
    {
      "epoch": 0.6093755243112647,
      "grad_norm": 0.7300440073013306,
      "learning_rate": 0.00018469567757696412,
      "loss": 2.511,
      "step": 9080
    },
    {
      "epoch": 0.6100466427301098,
      "grad_norm": 0.7448053956031799,
      "learning_rate": 0.00018465713537517563,
      "loss": 2.5604,
      "step": 9090
    },
    {
      "epoch": 0.6107177611489547,
      "grad_norm": 0.7174923419952393,
      "learning_rate": 0.00018461854873434228,
      "loss": 2.5257,
      "step": 9100
    },
    {
      "epoch": 0.6107177611489547,
      "eval_bleu": 20.80038399665244,
      "eval_gen_len": 28.597,
      "eval_loss": 2.9631736278533936,
      "eval_runtime": 64.8554,
      "eval_samples_per_second": 15.419,
      "eval_steps_per_second": 0.971,
      "step": 9100
    },
    {
      "epoch": 0.6113888795677997,
      "grad_norm": 0.6865736246109009,
      "learning_rate": 0.0001845799176747193,
      "loss": 2.5542,
      "step": 9110
    },
    {
      "epoch": 0.6120599979866448,
      "grad_norm": 0.7321072816848755,
      "learning_rate": 0.00018454124221658526,
      "loss": 2.5594,
      "step": 9120
    },
    {
      "epoch": 0.6127311164054897,
      "grad_norm": 0.7225392460823059,
      "learning_rate": 0.00018450252238024213,
      "loss": 2.5944,
      "step": 9130
    },
    {
      "epoch": 0.6134022348243348,
      "grad_norm": 0.6849175691604614,
      "learning_rate": 0.00018446375818601505,
      "loss": 2.5912,
      "step": 9140
    },
    {
      "epoch": 0.6140733532431798,
      "grad_norm": 0.6809595823287964,
      "learning_rate": 0.00018442494965425251,
      "loss": 2.5279,
      "step": 9150
    },
    {
      "epoch": 0.6140733532431798,
      "eval_bleu": 20.846283950503757,
      "eval_gen_len": 28.64,
      "eval_loss": 2.9638614654541016,
      "eval_runtime": 64.2549,
      "eval_samples_per_second": 15.563,
      "eval_steps_per_second": 0.98,
      "step": 9150
    },
    {
      "epoch": 0.6147444716620247,
      "grad_norm": 0.691705048084259,
      "learning_rate": 0.0001843860968053263,
      "loss": 2.5149,
      "step": 9160
    },
    {
      "epoch": 0.6154155900808698,
      "grad_norm": 0.8012112975120544,
      "learning_rate": 0.00018434719965963132,
      "loss": 2.5588,
      "step": 9170
    },
    {
      "epoch": 0.6160867084997148,
      "grad_norm": 0.6546405553817749,
      "learning_rate": 0.00018430825823758596,
      "loss": 2.5306,
      "step": 9180
    },
    {
      "epoch": 0.6167578269185597,
      "grad_norm": 0.6611922979354858,
      "learning_rate": 0.00018426927255963166,
      "loss": 2.5306,
      "step": 9190
    },
    {
      "epoch": 0.6174289453374048,
      "grad_norm": 0.7572994828224182,
      "learning_rate": 0.00018423024264623317,
      "loss": 2.5093,
      "step": 9200
    },
    {
      "epoch": 0.6174289453374048,
      "eval_bleu": 20.784281162986947,
      "eval_gen_len": 28.627,
      "eval_loss": 2.957918882369995,
      "eval_runtime": 64.9898,
      "eval_samples_per_second": 15.387,
      "eval_steps_per_second": 0.969,
      "step": 9200
    },
    {
      "epoch": 0.6181000637562498,
      "grad_norm": 0.7100931406021118,
      "learning_rate": 0.0001841911685178785,
      "loss": 2.5239,
      "step": 9210
    },
    {
      "epoch": 0.6187711821750947,
      "grad_norm": 0.6523833870887756,
      "learning_rate": 0.00018415205019507876,
      "loss": 2.5321,
      "step": 9220
    },
    {
      "epoch": 0.6194423005939398,
      "grad_norm": 0.6869339346885681,
      "learning_rate": 0.00018411288769836835,
      "loss": 2.5029,
      "step": 9230
    },
    {
      "epoch": 0.6201134190127848,
      "grad_norm": 0.7365865707397461,
      "learning_rate": 0.0001840736810483048,
      "loss": 2.5252,
      "step": 9240
    },
    {
      "epoch": 0.6207845374316298,
      "grad_norm": 0.7212538719177246,
      "learning_rate": 0.0001840344302654689,
      "loss": 2.5437,
      "step": 9250
    },
    {
      "epoch": 0.6207845374316298,
      "eval_bleu": 20.53858273993032,
      "eval_gen_len": 28.752,
      "eval_loss": 2.957688570022583,
      "eval_runtime": 64.6436,
      "eval_samples_per_second": 15.469,
      "eval_steps_per_second": 0.975,
      "step": 9250
    },
    {
      "epoch": 0.6214556558504748,
      "grad_norm": 0.7273173928260803,
      "learning_rate": 0.0001839951353704645,
      "loss": 2.5631,
      "step": 9260
    },
    {
      "epoch": 0.6221267742693198,
      "grad_norm": 0.6733984351158142,
      "learning_rate": 0.00018395579638391863,
      "loss": 2.5154,
      "step": 9270
    },
    {
      "epoch": 0.6227978926881649,
      "grad_norm": 0.7513166069984436,
      "learning_rate": 0.0001839164133264816,
      "loss": 2.5536,
      "step": 9280
    },
    {
      "epoch": 0.6234690111070098,
      "grad_norm": 0.6813255548477173,
      "learning_rate": 0.00018387698621882663,
      "loss": 2.6084,
      "step": 9290
    },
    {
      "epoch": 0.6241401295258548,
      "grad_norm": 0.6686986684799194,
      "learning_rate": 0.00018383751508165027,
      "loss": 2.5544,
      "step": 9300
    },
    {
      "epoch": 0.6241401295258548,
      "eval_bleu": 21.118470823110194,
      "eval_gen_len": 28.931,
      "eval_loss": 2.954052209854126,
      "eval_runtime": 65.3947,
      "eval_samples_per_second": 15.292,
      "eval_steps_per_second": 0.963,
      "step": 9300
    },
    {
      "epoch": 0.6248112479446999,
      "grad_norm": 0.7850327491760254,
      "learning_rate": 0.00018379799993567203,
      "loss": 2.5022,
      "step": 9310
    },
    {
      "epoch": 0.6254823663635448,
      "grad_norm": 0.699165403842926,
      "learning_rate": 0.00018375844080163465,
      "loss": 2.5313,
      "step": 9320
    },
    {
      "epoch": 0.6261534847823899,
      "grad_norm": 0.6770480871200562,
      "learning_rate": 0.00018371883770030382,
      "loss": 2.5099,
      "step": 9330
    },
    {
      "epoch": 0.6268246032012349,
      "grad_norm": 0.7317603826522827,
      "learning_rate": 0.0001836791906524684,
      "loss": 2.5887,
      "step": 9340
    },
    {
      "epoch": 0.6274957216200798,
      "grad_norm": 0.6475546956062317,
      "learning_rate": 0.00018363949967894038,
      "loss": 2.5337,
      "step": 9350
    },
    {
      "epoch": 0.6274957216200798,
      "eval_bleu": 20.8243474715763,
      "eval_gen_len": 28.962,
      "eval_loss": 2.9527111053466797,
      "eval_runtime": 66.6142,
      "eval_samples_per_second": 15.012,
      "eval_steps_per_second": 0.946,
      "step": 9350
    },
    {
      "epoch": 0.6281668400389249,
      "grad_norm": 0.699264407157898,
      "learning_rate": 0.00018359976480055462,
      "loss": 2.4985,
      "step": 9360
    },
    {
      "epoch": 0.6288379584577699,
      "grad_norm": 0.78072589635849,
      "learning_rate": 0.00018355998603816921,
      "loss": 2.4756,
      "step": 9370
    },
    {
      "epoch": 0.6295090768766148,
      "grad_norm": 0.700693666934967,
      "learning_rate": 0.00018352016341266519,
      "loss": 2.5372,
      "step": 9380
    },
    {
      "epoch": 0.6301801952954599,
      "grad_norm": 0.747799277305603,
      "learning_rate": 0.00018348029694494663,
      "loss": 2.5489,
      "step": 9390
    },
    {
      "epoch": 0.6308513137143049,
      "grad_norm": 0.6952205300331116,
      "learning_rate": 0.0001834403866559406,
      "loss": 2.6034,
      "step": 9400
    },
    {
      "epoch": 0.6308513137143049,
      "eval_bleu": 21.12007926349387,
      "eval_gen_len": 28.8,
      "eval_loss": 2.950144052505493,
      "eval_runtime": 64.6039,
      "eval_samples_per_second": 15.479,
      "eval_steps_per_second": 0.975,
      "step": 9400
    },
    {
      "epoch": 0.6315224321331498,
      "grad_norm": 0.6492530107498169,
      "learning_rate": 0.00018340043256659725,
      "loss": 2.5893,
      "step": 9410
    },
    {
      "epoch": 0.6321935505519949,
      "grad_norm": 0.678679883480072,
      "learning_rate": 0.00018336043469788962,
      "loss": 2.5608,
      "step": 9420
    },
    {
      "epoch": 0.6328646689708399,
      "grad_norm": 0.6656964421272278,
      "learning_rate": 0.0001833203930708138,
      "loss": 2.5696,
      "step": 9430
    },
    {
      "epoch": 0.6335357873896849,
      "grad_norm": 0.7968226075172424,
      "learning_rate": 0.00018328030770638885,
      "loss": 2.5213,
      "step": 9440
    },
    {
      "epoch": 0.6342069058085299,
      "grad_norm": 0.6503877639770508,
      "learning_rate": 0.00018324017862565673,
      "loss": 2.6018,
      "step": 9450
    },
    {
      "epoch": 0.6342069058085299,
      "eval_bleu": 20.941832889657285,
      "eval_gen_len": 28.854,
      "eval_loss": 2.954528331756592,
      "eval_runtime": 65.2381,
      "eval_samples_per_second": 15.328,
      "eval_steps_per_second": 0.966,
      "step": 9450
    },
    {
      "epoch": 0.6348780242273749,
      "grad_norm": 0.6257529854774475,
      "learning_rate": 0.00018320000584968243,
      "loss": 2.5561,
      "step": 9460
    },
    {
      "epoch": 0.63554914264622,
      "grad_norm": 0.6587355732917786,
      "learning_rate": 0.00018315978939955377,
      "loss": 2.4808,
      "step": 9470
    },
    {
      "epoch": 0.6362202610650649,
      "grad_norm": 0.6895677447319031,
      "learning_rate": 0.0001831195292963816,
      "loss": 2.5219,
      "step": 9480
    },
    {
      "epoch": 0.63689137948391,
      "grad_norm": 0.6538282036781311,
      "learning_rate": 0.00018307922556129965,
      "loss": 2.6219,
      "step": 9490
    },
    {
      "epoch": 0.637562497902755,
      "grad_norm": 0.6921252012252808,
      "learning_rate": 0.00018303887821546452,
      "loss": 2.5671,
      "step": 9500
    },
    {
      "epoch": 0.637562497902755,
      "eval_bleu": 21.191221978492308,
      "eval_gen_len": 28.849,
      "eval_loss": 2.9522347450256348,
      "eval_runtime": 64.9829,
      "eval_samples_per_second": 15.389,
      "eval_steps_per_second": 0.969,
      "step": 9500
    },
    {
      "epoch": 0.6382336163215999,
      "grad_norm": 0.7206107974052429,
      "learning_rate": 0.00018299848728005577,
      "loss": 2.5255,
      "step": 9510
    },
    {
      "epoch": 0.638904734740445,
      "grad_norm": 0.7360306978225708,
      "learning_rate": 0.0001829580527762758,
      "loss": 2.5831,
      "step": 9520
    },
    {
      "epoch": 0.63957585315929,
      "grad_norm": 0.6986502408981323,
      "learning_rate": 0.0001829175747253498,
      "loss": 2.5234,
      "step": 9530
    },
    {
      "epoch": 0.6402469715781349,
      "grad_norm": 0.6978016495704651,
      "learning_rate": 0.00018287705314852604,
      "loss": 2.5488,
      "step": 9540
    },
    {
      "epoch": 0.64091808999698,
      "grad_norm": 0.6336493492126465,
      "learning_rate": 0.00018283648806707536,
      "loss": 2.56,
      "step": 9550
    },
    {
      "epoch": 0.64091808999698,
      "eval_bleu": 20.729984363617774,
      "eval_gen_len": 28.711,
      "eval_loss": 2.9575002193450928,
      "eval_runtime": 64.6517,
      "eval_samples_per_second": 15.467,
      "eval_steps_per_second": 0.974,
      "step": 9550
    },
    {
      "epoch": 0.641589208415825,
      "grad_norm": 0.6840581297874451,
      "learning_rate": 0.00018279587950229166,
      "loss": 2.5412,
      "step": 9560
    },
    {
      "epoch": 0.6422603268346699,
      "grad_norm": 0.7734331488609314,
      "learning_rate": 0.00018275522747549156,
      "loss": 2.5309,
      "step": 9570
    },
    {
      "epoch": 0.642931445253515,
      "grad_norm": 0.7492107152938843,
      "learning_rate": 0.00018271453200801452,
      "loss": 2.5178,
      "step": 9580
    },
    {
      "epoch": 0.64360256367236,
      "grad_norm": 0.6502007246017456,
      "learning_rate": 0.00018267379312122278,
      "loss": 2.5452,
      "step": 9590
    },
    {
      "epoch": 0.644273682091205,
      "grad_norm": 0.6831963658332825,
      "learning_rate": 0.00018263301083650143,
      "loss": 2.5725,
      "step": 9600
    },
    {
      "epoch": 0.644273682091205,
      "eval_bleu": 20.918142663676836,
      "eval_gen_len": 28.82,
      "eval_loss": 2.9574899673461914,
      "eval_runtime": 67.5383,
      "eval_samples_per_second": 14.806,
      "eval_steps_per_second": 0.933,
      "step": 9600
    },
    {
      "epoch": 0.64494480051005,
      "grad_norm": 0.685712993144989,
      "learning_rate": 0.00018259218517525827,
      "loss": 2.542,
      "step": 9610
    },
    {
      "epoch": 0.645615918928895,
      "grad_norm": 0.7122795581817627,
      "learning_rate": 0.0001825513161589239,
      "loss": 2.5574,
      "step": 9620
    },
    {
      "epoch": 0.64628703734774,
      "grad_norm": 0.6786217093467712,
      "learning_rate": 0.0001825104038089517,
      "loss": 2.5146,
      "step": 9630
    },
    {
      "epoch": 0.646958155766585,
      "grad_norm": 0.6275219917297363,
      "learning_rate": 0.0001824694481468178,
      "loss": 2.5189,
      "step": 9640
    },
    {
      "epoch": 0.64762927418543,
      "grad_norm": 0.7558532357215881,
      "learning_rate": 0.00018242844919402098,
      "loss": 2.5516,
      "step": 9650
    },
    {
      "epoch": 0.64762927418543,
      "eval_bleu": 21.00052908254354,
      "eval_gen_len": 28.69,
      "eval_loss": 2.9543912410736084,
      "eval_runtime": 67.4345,
      "eval_samples_per_second": 14.829,
      "eval_steps_per_second": 0.934,
      "step": 9650
    },
    {
      "epoch": 0.6483003926042751,
      "grad_norm": 0.6707338094711304,
      "learning_rate": 0.00018238740697208282,
      "loss": 2.5127,
      "step": 9660
    },
    {
      "epoch": 0.64897151102312,
      "grad_norm": 0.6480664014816284,
      "learning_rate": 0.00018234632150254768,
      "loss": 2.5301,
      "step": 9670
    },
    {
      "epoch": 0.649642629441965,
      "grad_norm": 0.6939001083374023,
      "learning_rate": 0.00018230519280698247,
      "loss": 2.5743,
      "step": 9680
    },
    {
      "epoch": 0.6503137478608101,
      "grad_norm": 0.6765983700752258,
      "learning_rate": 0.00018226402090697688,
      "loss": 2.5214,
      "step": 9690
    },
    {
      "epoch": 0.650984866279655,
      "grad_norm": 0.7556585073471069,
      "learning_rate": 0.00018222280582414323,
      "loss": 2.5754,
      "step": 9700
    },
    {
      "epoch": 0.650984866279655,
      "eval_bleu": 20.93271553986251,
      "eval_gen_len": 28.785,
      "eval_loss": 2.9533588886260986,
      "eval_runtime": 67.2406,
      "eval_samples_per_second": 14.872,
      "eval_steps_per_second": 0.937,
      "step": 9700
    },
    {
      "epoch": 0.6516559846985001,
      "grad_norm": 0.6646212339401245,
      "learning_rate": 0.0001821815475801166,
      "loss": 2.5269,
      "step": 9710
    },
    {
      "epoch": 0.6523271031173451,
      "grad_norm": 0.7170664072036743,
      "learning_rate": 0.00018214024619655467,
      "loss": 2.5708,
      "step": 9720
    },
    {
      "epoch": 0.65299822153619,
      "grad_norm": 0.6428417563438416,
      "learning_rate": 0.00018209890169513772,
      "loss": 2.5507,
      "step": 9730
    },
    {
      "epoch": 0.6536693399550351,
      "grad_norm": 0.6438339352607727,
      "learning_rate": 0.0001820575140975687,
      "loss": 2.5347,
      "step": 9740
    },
    {
      "epoch": 0.6543404583738801,
      "grad_norm": 0.6774465441703796,
      "learning_rate": 0.00018201608342557324,
      "loss": 2.5369,
      "step": 9750
    },
    {
      "epoch": 0.6543404583738801,
      "eval_bleu": 20.838591188857063,
      "eval_gen_len": 28.966,
      "eval_loss": 2.954188823699951,
      "eval_runtime": 68.0717,
      "eval_samples_per_second": 14.69,
      "eval_steps_per_second": 0.925,
      "step": 9750
    },
    {
      "epoch": 0.655011576792725,
      "grad_norm": 0.6882110834121704,
      "learning_rate": 0.0001819746097008995,
      "loss": 2.5683,
      "step": 9760
    },
    {
      "epoch": 0.6556826952115701,
      "grad_norm": 0.7007005214691162,
      "learning_rate": 0.00018193309294531825,
      "loss": 2.5619,
      "step": 9770
    },
    {
      "epoch": 0.6563538136304151,
      "grad_norm": 0.8638646602630615,
      "learning_rate": 0.0001818915331806229,
      "loss": 2.5355,
      "step": 9780
    },
    {
      "epoch": 0.65702493204926,
      "grad_norm": 0.715554416179657,
      "learning_rate": 0.00018184993042862942,
      "loss": 2.4951,
      "step": 9790
    },
    {
      "epoch": 0.6576960504681051,
      "grad_norm": 0.6716174483299255,
      "learning_rate": 0.00018180828471117626,
      "loss": 2.5553,
      "step": 9800
    },
    {
      "epoch": 0.6576960504681051,
      "eval_bleu": 21.117720111263203,
      "eval_gen_len": 28.88,
      "eval_loss": 2.951097011566162,
      "eval_runtime": 67.7638,
      "eval_samples_per_second": 14.757,
      "eval_steps_per_second": 0.93,
      "step": 9800
    },
    {
      "epoch": 0.6583671688869501,
      "grad_norm": 0.7185279130935669,
      "learning_rate": 0.00018176659605012455,
      "loss": 2.5576,
      "step": 9810
    },
    {
      "epoch": 0.6590382873057951,
      "grad_norm": 0.6678670048713684,
      "learning_rate": 0.00018172486446735794,
      "loss": 2.6114,
      "step": 9820
    },
    {
      "epoch": 0.6597094057246401,
      "grad_norm": 0.6829019784927368,
      "learning_rate": 0.0001816830899847825,
      "loss": 2.5133,
      "step": 9830
    },
    {
      "epoch": 0.6603805241434851,
      "grad_norm": 0.6913893818855286,
      "learning_rate": 0.00018164127262432694,
      "loss": 2.5679,
      "step": 9840
    },
    {
      "epoch": 0.6610516425623302,
      "grad_norm": 0.6931599974632263,
      "learning_rate": 0.0001815994124079424,
      "loss": 2.5139,
      "step": 9850
    },
    {
      "epoch": 0.6610516425623302,
      "eval_bleu": 20.93325232871558,
      "eval_gen_len": 29.012,
      "eval_loss": 2.9513120651245117,
      "eval_runtime": 70.9714,
      "eval_samples_per_second": 14.09,
      "eval_steps_per_second": 0.888,
      "step": 9850
    },
    {
      "epoch": 0.6617227609811751,
      "grad_norm": 0.6860634088516235,
      "learning_rate": 0.00018155750935760262,
      "loss": 2.5885,
      "step": 9860
    },
    {
      "epoch": 0.6623938794000201,
      "grad_norm": 0.751924455165863,
      "learning_rate": 0.00018151556349530368,
      "loss": 2.5782,
      "step": 9870
    },
    {
      "epoch": 0.6630649978188652,
      "grad_norm": 0.6847085952758789,
      "learning_rate": 0.00018147357484306426,
      "loss": 2.5705,
      "step": 9880
    },
    {
      "epoch": 0.6637361162377101,
      "grad_norm": 0.7670444846153259,
      "learning_rate": 0.0001814315434229254,
      "loss": 2.5341,
      "step": 9890
    },
    {
      "epoch": 0.6644072346565552,
      "grad_norm": 0.6809249520301819,
      "learning_rate": 0.00018138946925695071,
      "loss": 2.5503,
      "step": 9900
    },
    {
      "epoch": 0.6644072346565552,
      "eval_bleu": 21.05392197092074,
      "eval_gen_len": 28.874,
      "eval_loss": 2.9562721252441406,
      "eval_runtime": 67.4729,
      "eval_samples_per_second": 14.821,
      "eval_steps_per_second": 0.934,
      "step": 9900
    },
    {
      "epoch": 0.6650783530754002,
      "grad_norm": 0.7457565665245056,
      "learning_rate": 0.0001813473523672261,
      "loss": 2.5174,
      "step": 9910
    },
    {
      "epoch": 0.6657494714942451,
      "grad_norm": 0.6646441221237183,
      "learning_rate": 0.00018130519277586004,
      "loss": 2.5155,
      "step": 9920
    },
    {
      "epoch": 0.6664205899130902,
      "grad_norm": 0.6990154385566711,
      "learning_rate": 0.0001812629905049833,
      "loss": 2.5884,
      "step": 9930
    },
    {
      "epoch": 0.6670917083319352,
      "grad_norm": 0.6981431245803833,
      "learning_rate": 0.00018122074557674913,
      "loss": 2.5968,
      "step": 9940
    },
    {
      "epoch": 0.6677628267507801,
      "grad_norm": 0.6750298738479614,
      "learning_rate": 0.00018117845801333314,
      "loss": 2.5672,
      "step": 9950
    },
    {
      "epoch": 0.6677628267507801,
      "eval_bleu": 21.041201645111357,
      "eval_gen_len": 28.871,
      "eval_loss": 2.9459164142608643,
      "eval_runtime": 67.4643,
      "eval_samples_per_second": 14.823,
      "eval_steps_per_second": 0.934,
      "step": 9950
    },
    {
      "epoch": 0.6684339451696252,
      "grad_norm": 0.6848027110099792,
      "learning_rate": 0.00018113612783693332,
      "loss": 2.5775,
      "step": 9960
    },
    {
      "epoch": 0.6691050635884702,
      "grad_norm": 0.7428997755050659,
      "learning_rate": 0.0001810937550697701,
      "loss": 2.5565,
      "step": 9970
    },
    {
      "epoch": 0.6697761820073151,
      "grad_norm": 0.7328925728797913,
      "learning_rate": 0.0001810513397340861,
      "loss": 2.6175,
      "step": 9980
    },
    {
      "epoch": 0.6704473004261602,
      "grad_norm": 0.6892388463020325,
      "learning_rate": 0.00018100888185214643,
      "loss": 2.5369,
      "step": 9990
    },
    {
      "epoch": 0.6711184188450052,
      "grad_norm": 0.6647701263427734,
      "learning_rate": 0.00018096638144623854,
      "loss": 2.6105,
      "step": 10000
    },
    {
      "epoch": 0.6711184188450052,
      "eval_bleu": 20.96867037979472,
      "eval_gen_len": 28.93,
      "eval_loss": 2.9514458179473877,
      "eval_runtime": 67.7351,
      "eval_samples_per_second": 14.763,
      "eval_steps_per_second": 0.93,
      "step": 10000
    },
    {
      "epoch": 0.6717895372638502,
      "grad_norm": 0.6626648306846619,
      "learning_rate": 0.0001809238385386721,
      "loss": 2.5866,
      "step": 10010
    },
    {
      "epoch": 0.6724606556826952,
      "grad_norm": 0.6526308655738831,
      "learning_rate": 0.0001808812531517792,
      "loss": 2.5397,
      "step": 10020
    },
    {
      "epoch": 0.6731317741015402,
      "grad_norm": 0.7219635248184204,
      "learning_rate": 0.00018083862530791412,
      "loss": 2.5427,
      "step": 10030
    },
    {
      "epoch": 0.6738028925203853,
      "grad_norm": 0.7386281490325928,
      "learning_rate": 0.00018079595502945348,
      "loss": 2.5585,
      "step": 10040
    },
    {
      "epoch": 0.6744740109392302,
      "grad_norm": 0.6322831511497498,
      "learning_rate": 0.00018075324233879622,
      "loss": 2.4695,
      "step": 10050
    },
    {
      "epoch": 0.6744740109392302,
      "eval_bleu": 20.813407268604635,
      "eval_gen_len": 28.819,
      "eval_loss": 2.9560179710388184,
      "eval_runtime": 67.1728,
      "eval_samples_per_second": 14.887,
      "eval_steps_per_second": 0.938,
      "step": 10050
    },
    {
      "epoch": 0.6751451293580752,
      "grad_norm": 0.7349467277526855,
      "learning_rate": 0.00018071048725836348,
      "loss": 2.5197,
      "step": 10060
    },
    {
      "epoch": 0.6758162477769203,
      "grad_norm": 0.6541041135787964,
      "learning_rate": 0.00018066768981059867,
      "loss": 2.5463,
      "step": 10070
    },
    {
      "epoch": 0.6764873661957652,
      "grad_norm": 0.7319788932800293,
      "learning_rate": 0.00018062485001796744,
      "loss": 2.5717,
      "step": 10080
    },
    {
      "epoch": 0.6771584846146103,
      "grad_norm": 0.743518590927124,
      "learning_rate": 0.00018058196790295768,
      "loss": 2.4994,
      "step": 10090
    },
    {
      "epoch": 0.6778296030334553,
      "grad_norm": 0.6717811822891235,
      "learning_rate": 0.00018053904348807947,
      "loss": 2.5008,
      "step": 10100
    },
    {
      "epoch": 0.6778296030334553,
      "eval_bleu": 20.73885317483351,
      "eval_gen_len": 28.638,
      "eval_loss": 2.9549777507781982,
      "eval_runtime": 66.4354,
      "eval_samples_per_second": 15.052,
      "eval_steps_per_second": 0.948,
      "step": 10100
    },
    {
      "epoch": 0.6785007214523002,
      "grad_norm": 0.6636238098144531,
      "learning_rate": 0.0001804960767958651,
      "loss": 2.5191,
      "step": 10110
    },
    {
      "epoch": 0.6791718398711453,
      "grad_norm": 0.7029763460159302,
      "learning_rate": 0.0001804530678488691,
      "loss": 2.5284,
      "step": 10120
    },
    {
      "epoch": 0.6798429582899903,
      "grad_norm": 0.7046762108802795,
      "learning_rate": 0.0001804100166696681,
      "loss": 2.4945,
      "step": 10130
    },
    {
      "epoch": 0.6805140767088352,
      "grad_norm": 0.6804378628730774,
      "learning_rate": 0.000180366923280861,
      "loss": 2.5716,
      "step": 10140
    },
    {
      "epoch": 0.6811851951276803,
      "grad_norm": 0.7004556059837341,
      "learning_rate": 0.00018032378770506874,
      "loss": 2.5508,
      "step": 10150
    },
    {
      "epoch": 0.6811851951276803,
      "eval_bleu": 20.790772256306347,
      "eval_gen_len": 28.85,
      "eval_loss": 2.9490246772766113,
      "eval_runtime": 67.498,
      "eval_samples_per_second": 14.815,
      "eval_steps_per_second": 0.933,
      "step": 10150
    },
    {
      "epoch": 0.6818563135465253,
      "grad_norm": 0.6691088676452637,
      "learning_rate": 0.00018028060996493452,
      "loss": 2.5664,
      "step": 10160
    },
    {
      "epoch": 0.6825274319653702,
      "grad_norm": 0.6659103035926819,
      "learning_rate": 0.00018023739008312357,
      "loss": 2.5984,
      "step": 10170
    },
    {
      "epoch": 0.6831985503842153,
      "grad_norm": 0.7596732378005981,
      "learning_rate": 0.00018019412808232331,
      "loss": 2.5004,
      "step": 10180
    },
    {
      "epoch": 0.6838696688030603,
      "grad_norm": 0.6560961604118347,
      "learning_rate": 0.00018015082398524328,
      "loss": 2.5177,
      "step": 10190
    },
    {
      "epoch": 0.6845407872219053,
      "grad_norm": 0.6625583171844482,
      "learning_rate": 0.000180107477814615,
      "loss": 2.5651,
      "step": 10200
    },
    {
      "epoch": 0.6845407872219053,
      "eval_bleu": 20.72985008620629,
      "eval_gen_len": 29.219,
      "eval_loss": 2.946045398712158,
      "eval_runtime": 74.0381,
      "eval_samples_per_second": 13.507,
      "eval_steps_per_second": 0.851,
      "step": 10200
    },
    {
      "epoch": 0.6852119056407503,
      "grad_norm": 0.6822656393051147,
      "learning_rate": 0.00018006408959319226,
      "loss": 2.5435,
      "step": 10210
    },
    {
      "epoch": 0.6858830240595953,
      "grad_norm": 0.6926633715629578,
      "learning_rate": 0.0001800206593437508,
      "loss": 2.5631,
      "step": 10220
    },
    {
      "epoch": 0.6865541424784403,
      "grad_norm": 0.7526974081993103,
      "learning_rate": 0.00017997718708908836,
      "loss": 2.591,
      "step": 10230
    },
    {
      "epoch": 0.6872252608972853,
      "grad_norm": 0.7130200862884521,
      "learning_rate": 0.00017993367285202495,
      "loss": 2.5475,
      "step": 10240
    },
    {
      "epoch": 0.6878963793161303,
      "grad_norm": 0.6209903955459595,
      "learning_rate": 0.00017989011665540242,
      "loss": 2.559,
      "step": 10250
    },
    {
      "epoch": 0.6878963793161303,
      "eval_bleu": 20.862106497692025,
      "eval_gen_len": 28.935,
      "eval_loss": 2.955808162689209,
      "eval_runtime": 69.833,
      "eval_samples_per_second": 14.32,
      "eval_steps_per_second": 0.902,
      "step": 10250
    },
    {
      "epoch": 0.6885674977349754,
      "grad_norm": 0.6751705408096313,
      "learning_rate": 0.0001798465185220847,
      "loss": 2.5255,
      "step": 10260
    },
    {
      "epoch": 0.6892386161538203,
      "grad_norm": 0.7102377414703369,
      "learning_rate": 0.00017980287847495777,
      "loss": 2.5336,
      "step": 10270
    },
    {
      "epoch": 0.6899097345726654,
      "grad_norm": 0.7118927836418152,
      "learning_rate": 0.0001797591965369296,
      "loss": 2.5505,
      "step": 10280
    },
    {
      "epoch": 0.6905808529915104,
      "grad_norm": 0.6849641799926758,
      "learning_rate": 0.00017971547273093008,
      "loss": 2.552,
      "step": 10290
    },
    {
      "epoch": 0.6912519714103553,
      "grad_norm": 0.6875266432762146,
      "learning_rate": 0.00017967170707991118,
      "loss": 2.5888,
      "step": 10300
    },
    {
      "epoch": 0.6912519714103553,
      "eval_bleu": 20.775835377394664,
      "eval_gen_len": 28.636,
      "eval_loss": 2.95562744140625,
      "eval_runtime": 66.7773,
      "eval_samples_per_second": 14.975,
      "eval_steps_per_second": 0.943,
      "step": 10300
    },
    {
      "epoch": 0.6919230898292004,
      "grad_norm": 0.6112798452377319,
      "learning_rate": 0.00017962789960684677,
      "loss": 2.5093,
      "step": 10310
    },
    {
      "epoch": 0.6925942082480454,
      "grad_norm": 0.6954853534698486,
      "learning_rate": 0.00017958405033473277,
      "loss": 2.5652,
      "step": 10320
    },
    {
      "epoch": 0.6932653266668903,
      "grad_norm": 0.6839171648025513,
      "learning_rate": 0.0001795401592865868,
      "loss": 2.5499,
      "step": 10330
    },
    {
      "epoch": 0.6939364450857354,
      "grad_norm": 0.6648792028427124,
      "learning_rate": 0.00017949622648544874,
      "loss": 2.5631,
      "step": 10340
    },
    {
      "epoch": 0.6946075635045804,
      "grad_norm": 0.733937680721283,
      "learning_rate": 0.00017945225195438016,
      "loss": 2.5844,
      "step": 10350
    },
    {
      "epoch": 0.6946075635045804,
      "eval_bleu": 21.1101123055173,
      "eval_gen_len": 28.749,
      "eval_loss": 2.9487688541412354,
      "eval_runtime": 68.1405,
      "eval_samples_per_second": 14.676,
      "eval_steps_per_second": 0.925,
      "step": 10350
    },
    {
      "epoch": 0.6952786819234253,
      "grad_norm": 0.712047278881073,
      "learning_rate": 0.00017940823571646456,
      "loss": 2.5836,
      "step": 10360
    },
    {
      "epoch": 0.6959498003422704,
      "grad_norm": 0.6378219723701477,
      "learning_rate": 0.0001793641777948074,
      "loss": 2.5202,
      "step": 10370
    },
    {
      "epoch": 0.6966209187611154,
      "grad_norm": 0.7595226764678955,
      "learning_rate": 0.00017932007821253601,
      "loss": 2.5295,
      "step": 10380
    },
    {
      "epoch": 0.6972920371799604,
      "grad_norm": 0.6666404604911804,
      "learning_rate": 0.0001792759369927996,
      "loss": 2.4917,
      "step": 10390
    },
    {
      "epoch": 0.6979631555988054,
      "grad_norm": 0.7978073954582214,
      "learning_rate": 0.00017923175415876912,
      "loss": 2.6312,
      "step": 10400
    },
    {
      "epoch": 0.6979631555988054,
      "eval_bleu": 21.306898520904788,
      "eval_gen_len": 28.913,
      "eval_loss": 2.9499764442443848,
      "eval_runtime": 67.1858,
      "eval_samples_per_second": 14.884,
      "eval_steps_per_second": 0.938,
      "step": 10400
    },
    {
      "epoch": 0.6986342740176504,
      "grad_norm": 0.6946805119514465,
      "learning_rate": 0.0001791875297336375,
      "loss": 2.5033,
      "step": 10410
    },
    {
      "epoch": 0.6993053924364954,
      "grad_norm": 0.7847577333450317,
      "learning_rate": 0.00017914326374061945,
      "loss": 2.5675,
      "step": 10420
    },
    {
      "epoch": 0.6999765108553404,
      "grad_norm": 0.6855554580688477,
      "learning_rate": 0.00017909895620295152,
      "loss": 2.5321,
      "step": 10430
    },
    {
      "epoch": 0.7006476292741854,
      "grad_norm": 0.6675292253494263,
      "learning_rate": 0.00017905460714389202,
      "loss": 2.5481,
      "step": 10440
    },
    {
      "epoch": 0.7013187476930305,
      "grad_norm": 0.7107117772102356,
      "learning_rate": 0.00017901021658672111,
      "loss": 2.5512,
      "step": 10450
    },
    {
      "epoch": 0.7013187476930305,
      "eval_bleu": 20.95612613731959,
      "eval_gen_len": 28.567,
      "eval_loss": 2.9522361755371094,
      "eval_runtime": 66.6552,
      "eval_samples_per_second": 15.003,
      "eval_steps_per_second": 0.945,
      "step": 10450
    },
    {
      "epoch": 0.7019898661118754,
      "grad_norm": 0.6494339108467102,
      "learning_rate": 0.00017896578455474073,
      "loss": 2.5377,
      "step": 10460
    },
    {
      "epoch": 0.7026609845307205,
      "grad_norm": 0.764520525932312,
      "learning_rate": 0.00017892131107127455,
      "loss": 2.5832,
      "step": 10470
    },
    {
      "epoch": 0.7033321029495655,
      "grad_norm": 0.6979736089706421,
      "learning_rate": 0.000178876796159668,
      "loss": 2.5768,
      "step": 10480
    },
    {
      "epoch": 0.7040032213684104,
      "grad_norm": 0.674286961555481,
      "learning_rate": 0.00017883223984328832,
      "loss": 2.5521,
      "step": 10490
    },
    {
      "epoch": 0.7046743397872555,
      "grad_norm": 0.6347930431365967,
      "learning_rate": 0.00017878764214552438,
      "loss": 2.509,
      "step": 10500
    },
    {
      "epoch": 0.7046743397872555,
      "eval_bleu": 20.31357224981829,
      "eval_gen_len": 28.762,
      "eval_loss": 2.958967924118042,
      "eval_runtime": 67.8569,
      "eval_samples_per_second": 14.737,
      "eval_steps_per_second": 0.928,
      "step": 10500
    },
    {
      "epoch": 0.7053454582061005,
      "grad_norm": 0.6627693176269531,
      "learning_rate": 0.00017874300308978692,
      "loss": 2.5807,
      "step": 10510
    },
    {
      "epoch": 0.7060165766249454,
      "grad_norm": 0.6983107924461365,
      "learning_rate": 0.0001786983226995083,
      "loss": 2.537,
      "step": 10520
    },
    {
      "epoch": 0.7066876950437905,
      "grad_norm": 0.7081577777862549,
      "learning_rate": 0.0001786536009981425,
      "loss": 2.5109,
      "step": 10530
    },
    {
      "epoch": 0.7073588134626355,
      "grad_norm": 0.6958649158477783,
      "learning_rate": 0.00017860883800916536,
      "loss": 2.5851,
      "step": 10540
    },
    {
      "epoch": 0.7080299318814804,
      "grad_norm": 0.6252196431159973,
      "learning_rate": 0.00017856403375607425,
      "loss": 2.5368,
      "step": 10550
    },
    {
      "epoch": 0.7080299318814804,
      "eval_bleu": 20.663535493622703,
      "eval_gen_len": 28.856,
      "eval_loss": 2.950594663619995,
      "eval_runtime": 67.5331,
      "eval_samples_per_second": 14.808,
      "eval_steps_per_second": 0.933,
      "step": 10550
    },
    {
      "epoch": 0.7087010503003255,
      "grad_norm": 0.7523007988929749,
      "learning_rate": 0.00017851918826238827,
      "loss": 2.4767,
      "step": 10560
    },
    {
      "epoch": 0.7093721687191705,
      "grad_norm": 0.698573112487793,
      "learning_rate": 0.00017847430155164818,
      "loss": 2.5554,
      "step": 10570
    },
    {
      "epoch": 0.7100432871380155,
      "grad_norm": 0.6612185835838318,
      "learning_rate": 0.0001784293736474163,
      "loss": 2.5311,
      "step": 10580
    },
    {
      "epoch": 0.7107144055568605,
      "grad_norm": 0.6471808552742004,
      "learning_rate": 0.00017838440457327662,
      "loss": 2.5777,
      "step": 10590
    },
    {
      "epoch": 0.7113855239757055,
      "grad_norm": 0.7190441489219666,
      "learning_rate": 0.00017833939435283477,
      "loss": 2.5419,
      "step": 10600
    },
    {
      "epoch": 0.7113855239757055,
      "eval_bleu": 20.712799212882235,
      "eval_gen_len": 28.752,
      "eval_loss": 2.9471194744110107,
      "eval_runtime": 66.6675,
      "eval_samples_per_second": 15.0,
      "eval_steps_per_second": 0.945,
      "step": 10600
    },
    {
      "epoch": 0.7120566423945505,
      "grad_norm": 0.6578951478004456,
      "learning_rate": 0.00017829434300971794,
      "loss": 2.6061,
      "step": 10610
    },
    {
      "epoch": 0.7127277608133955,
      "grad_norm": 0.6753025650978088,
      "learning_rate": 0.00017824925056757494,
      "loss": 2.5219,
      "step": 10620
    },
    {
      "epoch": 0.7133988792322405,
      "grad_norm": 0.7708796858787537,
      "learning_rate": 0.00017820411705007612,
      "loss": 2.5798,
      "step": 10630
    },
    {
      "epoch": 0.7140699976510856,
      "grad_norm": 0.6972006559371948,
      "learning_rate": 0.00017815894248091337,
      "loss": 2.5889,
      "step": 10640
    },
    {
      "epoch": 0.7147411160699305,
      "grad_norm": 0.6357483863830566,
      "learning_rate": 0.0001781137268838002,
      "loss": 2.5465,
      "step": 10650
    },
    {
      "epoch": 0.7147411160699305,
      "eval_bleu": 20.900353796305303,
      "eval_gen_len": 28.828,
      "eval_loss": 2.9460463523864746,
      "eval_runtime": 66.8137,
      "eval_samples_per_second": 14.967,
      "eval_steps_per_second": 0.943,
      "step": 10650
    },
    {
      "epoch": 0.7154122344887756,
      "grad_norm": 0.6261963248252869,
      "learning_rate": 0.00017806847028247163,
      "loss": 2.5229,
      "step": 10660
    },
    {
      "epoch": 0.7160833529076206,
      "grad_norm": 0.7019736170768738,
      "learning_rate": 0.00017802317270068416,
      "loss": 2.5554,
      "step": 10670
    },
    {
      "epoch": 0.7167544713264655,
      "grad_norm": 0.6550186276435852,
      "learning_rate": 0.00017797783416221584,
      "loss": 2.5266,
      "step": 10680
    },
    {
      "epoch": 0.7174255897453106,
      "grad_norm": 0.7231163382530212,
      "learning_rate": 0.00017793245469086623,
      "loss": 2.5348,
      "step": 10690
    },
    {
      "epoch": 0.7180967081641556,
      "grad_norm": 0.6724648475646973,
      "learning_rate": 0.00017788703431045639,
      "loss": 2.5232,
      "step": 10700
    },
    {
      "epoch": 0.7180967081641556,
      "eval_bleu": 21.008473746422094,
      "eval_gen_len": 28.73,
      "eval_loss": 2.9465763568878174,
      "eval_runtime": 66.9928,
      "eval_samples_per_second": 14.927,
      "eval_steps_per_second": 0.94,
      "step": 10700
    },
    {
      "epoch": 0.7187678265830005,
      "grad_norm": 0.6966484189033508,
      "learning_rate": 0.00017784157304482875,
      "loss": 2.5921,
      "step": 10710
    },
    {
      "epoch": 0.7194389450018456,
      "grad_norm": 0.6636307835578918,
      "learning_rate": 0.00017779607091784736,
      "loss": 2.4662,
      "step": 10720
    },
    {
      "epoch": 0.7201100634206906,
      "grad_norm": 0.7382411360740662,
      "learning_rate": 0.00017775052795339762,
      "loss": 2.4796,
      "step": 10730
    },
    {
      "epoch": 0.7207811818395355,
      "grad_norm": 0.6922010779380798,
      "learning_rate": 0.00017770494417538633,
      "loss": 2.5391,
      "step": 10740
    },
    {
      "epoch": 0.7214523002583806,
      "grad_norm": 0.7064087390899658,
      "learning_rate": 0.0001776593196077418,
      "loss": 2.5149,
      "step": 10750
    },
    {
      "epoch": 0.7214523002583806,
      "eval_bleu": 20.661004423633244,
      "eval_gen_len": 28.95,
      "eval_loss": 2.9521913528442383,
      "eval_runtime": 69.8646,
      "eval_samples_per_second": 14.313,
      "eval_steps_per_second": 0.902,
      "step": 10750
    },
    {
      "epoch": 0.7221234186772256,
      "grad_norm": 0.6934796571731567,
      "learning_rate": 0.00017761365427441378,
      "loss": 2.5704,
      "step": 10760
    },
    {
      "epoch": 0.7227945370960706,
      "grad_norm": 0.7205908894538879,
      "learning_rate": 0.00017756794819937327,
      "loss": 2.5571,
      "step": 10770
    },
    {
      "epoch": 0.7234656555149156,
      "grad_norm": 0.6758162379264832,
      "learning_rate": 0.00017752220140661277,
      "loss": 2.5899,
      "step": 10780
    },
    {
      "epoch": 0.7241367739337606,
      "grad_norm": 0.690430223941803,
      "learning_rate": 0.00017747641392014618,
      "loss": 2.5206,
      "step": 10790
    },
    {
      "epoch": 0.7248078923526056,
      "grad_norm": 0.671042263507843,
      "learning_rate": 0.00017743058576400866,
      "loss": 2.6125,
      "step": 10800
    },
    {
      "epoch": 0.7248078923526056,
      "eval_bleu": 20.95339505086412,
      "eval_gen_len": 28.869,
      "eval_loss": 2.9454798698425293,
      "eval_runtime": 66.0203,
      "eval_samples_per_second": 15.147,
      "eval_steps_per_second": 0.954,
      "step": 10800
    },
    {
      "epoch": 0.7254790107714506,
      "grad_norm": 0.7843872904777527,
      "learning_rate": 0.00017738471696225676,
      "loss": 2.5427,
      "step": 10810
    },
    {
      "epoch": 0.7261501291902956,
      "grad_norm": 0.6883403062820435,
      "learning_rate": 0.00017733880753896845,
      "loss": 2.5145,
      "step": 10820
    },
    {
      "epoch": 0.7268212476091407,
      "grad_norm": 0.6631940007209778,
      "learning_rate": 0.00017729285751824287,
      "loss": 2.531,
      "step": 10830
    },
    {
      "epoch": 0.7274923660279856,
      "grad_norm": 0.7403614521026611,
      "learning_rate": 0.00017724686692420058,
      "loss": 2.5418,
      "step": 10840
    },
    {
      "epoch": 0.7281634844468307,
      "grad_norm": 0.7175118923187256,
      "learning_rate": 0.00017720083578098343,
      "loss": 2.4994,
      "step": 10850
    },
    {
      "epoch": 0.7281634844468307,
      "eval_bleu": 20.873654109811163,
      "eval_gen_len": 29.077,
      "eval_loss": 2.9503393173217773,
      "eval_runtime": 71.2901,
      "eval_samples_per_second": 14.027,
      "eval_steps_per_second": 0.884,
      "step": 10850
    },
    {
      "epoch": 0.7288346028656757,
      "grad_norm": 0.7426323890686035,
      "learning_rate": 0.00017715476411275452,
      "loss": 2.5541,
      "step": 10860
    },
    {
      "epoch": 0.7295057212845206,
      "grad_norm": 0.6888414025306702,
      "learning_rate": 0.0001771086519436982,
      "loss": 2.5941,
      "step": 10870
    },
    {
      "epoch": 0.7301768397033657,
      "grad_norm": 0.8148025870323181,
      "learning_rate": 0.00017706249929802019,
      "loss": 2.5077,
      "step": 10880
    },
    {
      "epoch": 0.7308479581222107,
      "grad_norm": 0.662096381187439,
      "learning_rate": 0.00017701630619994734,
      "loss": 2.578,
      "step": 10890
    },
    {
      "epoch": 0.7315190765410556,
      "grad_norm": 0.6321911215782166,
      "learning_rate": 0.00017697007267372778,
      "loss": 2.5057,
      "step": 10900
    },
    {
      "epoch": 0.7315190765410556,
      "eval_bleu": 21.304332648269675,
      "eval_gen_len": 28.742,
      "eval_loss": 2.950517416000366,
      "eval_runtime": 66.856,
      "eval_samples_per_second": 14.958,
      "eval_steps_per_second": 0.942,
      "step": 10900
    },
    {
      "epoch": 0.7321901949599007,
      "grad_norm": 0.6872837543487549,
      "learning_rate": 0.00017692379874363086,
      "loss": 2.5567,
      "step": 10910
    },
    {
      "epoch": 0.7328613133787457,
      "grad_norm": 0.668024480342865,
      "learning_rate": 0.00017687748443394715,
      "loss": 2.5008,
      "step": 10920
    },
    {
      "epoch": 0.7335324317975906,
      "grad_norm": 0.7209057807922363,
      "learning_rate": 0.0001768311297689884,
      "loss": 2.5218,
      "step": 10930
    },
    {
      "epoch": 0.7342035502164357,
      "grad_norm": 0.6631208062171936,
      "learning_rate": 0.00017678473477308754,
      "loss": 2.564,
      "step": 10940
    },
    {
      "epoch": 0.7348746686352807,
      "grad_norm": 0.6802679896354675,
      "learning_rate": 0.0001767382994705987,
      "loss": 2.5397,
      "step": 10950
    },
    {
      "epoch": 0.7348746686352807,
      "eval_bleu": 20.634883990524347,
      "eval_gen_len": 28.775,
      "eval_loss": 2.950349807739258,
      "eval_runtime": 67.8046,
      "eval_samples_per_second": 14.748,
      "eval_steps_per_second": 0.929,
      "step": 10950
    },
    {
      "epoch": 0.7355457870541257,
      "grad_norm": 0.7418601512908936,
      "learning_rate": 0.00017669182388589715,
      "loss": 2.5387,
      "step": 10960
    },
    {
      "epoch": 0.7362169054729707,
      "grad_norm": 0.6927939057350159,
      "learning_rate": 0.0001766453080433793,
      "loss": 2.5612,
      "step": 10970
    },
    {
      "epoch": 0.7368880238918157,
      "grad_norm": 0.6933494210243225,
      "learning_rate": 0.0001765987519674627,
      "loss": 2.5186,
      "step": 10980
    },
    {
      "epoch": 0.7375591423106607,
      "grad_norm": 0.7240042686462402,
      "learning_rate": 0.00017655215568258603,
      "loss": 2.535,
      "step": 10990
    },
    {
      "epoch": 0.7382302607295057,
      "grad_norm": 0.7253953218460083,
      "learning_rate": 0.00017650551921320903,
      "loss": 2.5663,
      "step": 11000
    },
    {
      "epoch": 0.7382302607295057,
      "eval_bleu": 20.967286629828994,
      "eval_gen_len": 28.977,
      "eval_loss": 2.9498074054718018,
      "eval_runtime": 70.7131,
      "eval_samples_per_second": 14.142,
      "eval_steps_per_second": 0.891,
      "step": 11000
    },
    {
      "epoch": 0.7389013791483507,
      "grad_norm": 0.7279258966445923,
      "learning_rate": 0.00017645884258381256,
      "loss": 2.6144,
      "step": 11010
    },
    {
      "epoch": 0.7395724975671958,
      "grad_norm": 0.7234809398651123,
      "learning_rate": 0.00017641212581889863,
      "loss": 2.5484,
      "step": 11020
    },
    {
      "epoch": 0.7402436159860407,
      "grad_norm": 0.7703099250793457,
      "learning_rate": 0.0001763653689429902,
      "loss": 2.5588,
      "step": 11030
    },
    {
      "epoch": 0.7409147344048858,
      "grad_norm": 0.686703622341156,
      "learning_rate": 0.00017631857198063139,
      "loss": 2.5113,
      "step": 11040
    },
    {
      "epoch": 0.7415858528237308,
      "grad_norm": 0.6659794449806213,
      "learning_rate": 0.0001762717349563873,
      "loss": 2.5141,
      "step": 11050
    },
    {
      "epoch": 0.7415858528237308,
      "eval_bleu": 21.06544534648378,
      "eval_gen_len": 29.058,
      "eval_loss": 2.949357748031616,
      "eval_runtime": 70.4673,
      "eval_samples_per_second": 14.191,
      "eval_steps_per_second": 0.894,
      "step": 11050
    },
    {
      "epoch": 0.7422569712425757,
      "grad_norm": 0.7103404402732849,
      "learning_rate": 0.00017622485789484403,
      "loss": 2.5551,
      "step": 11060
    },
    {
      "epoch": 0.7429280896614208,
      "grad_norm": 0.7270678281784058,
      "learning_rate": 0.0001761779408206088,
      "loss": 2.58,
      "step": 11070
    },
    {
      "epoch": 0.7435992080802658,
      "grad_norm": 0.7717673778533936,
      "learning_rate": 0.00017613098375830974,
      "loss": 2.5194,
      "step": 11080
    },
    {
      "epoch": 0.7442703264991107,
      "grad_norm": 0.5958802700042725,
      "learning_rate": 0.00017608398673259602,
      "loss": 2.5435,
      "step": 11090
    },
    {
      "epoch": 0.7449414449179558,
      "grad_norm": 0.7874841690063477,
      "learning_rate": 0.00017603694976813777,
      "loss": 2.5542,
      "step": 11100
    },
    {
      "epoch": 0.7449414449179558,
      "eval_bleu": 21.16527951093878,
      "eval_gen_len": 28.899,
      "eval_loss": 2.9444854259490967,
      "eval_runtime": 68.0096,
      "eval_samples_per_second": 14.704,
      "eval_steps_per_second": 0.926,
      "step": 11100
    },
    {
      "epoch": 0.7456125633368008,
      "grad_norm": 0.653188943862915,
      "learning_rate": 0.0001759898728896261,
      "loss": 2.5598,
      "step": 11110
    },
    {
      "epoch": 0.7462836817556457,
      "grad_norm": 0.7079604268074036,
      "learning_rate": 0.00017594275612177308,
      "loss": 2.5242,
      "step": 11120
    },
    {
      "epoch": 0.7469548001744908,
      "grad_norm": 0.6862925887107849,
      "learning_rate": 0.00017589559948931165,
      "loss": 2.5573,
      "step": 11130
    },
    {
      "epoch": 0.7476259185933358,
      "grad_norm": 0.6751267910003662,
      "learning_rate": 0.00017584840301699577,
      "loss": 2.5495,
      "step": 11140
    },
    {
      "epoch": 0.7482970370121808,
      "grad_norm": 0.6697641611099243,
      "learning_rate": 0.00017580116672960024,
      "loss": 2.5209,
      "step": 11150
    },
    {
      "epoch": 0.7482970370121808,
      "eval_bleu": 21.106960317575947,
      "eval_gen_len": 28.74,
      "eval_loss": 2.946622371673584,
      "eval_runtime": 67.3832,
      "eval_samples_per_second": 14.84,
      "eval_steps_per_second": 0.935,
      "step": 11150
    },
    {
      "epoch": 0.7489681554310258,
      "grad_norm": 0.6819168329238892,
      "learning_rate": 0.0001757538906519208,
      "loss": 2.5951,
      "step": 11160
    },
    {
      "epoch": 0.7496392738498708,
      "grad_norm": 0.7012832760810852,
      "learning_rate": 0.0001757065748087741,
      "loss": 2.5119,
      "step": 11170
    },
    {
      "epoch": 0.7503103922687158,
      "grad_norm": 0.6968886256217957,
      "learning_rate": 0.0001756592192249976,
      "loss": 2.5091,
      "step": 11180
    },
    {
      "epoch": 0.7509815106875608,
      "grad_norm": 0.7088165879249573,
      "learning_rate": 0.00017561182392544965,
      "loss": 2.5106,
      "step": 11190
    },
    {
      "epoch": 0.7516526291064058,
      "grad_norm": 0.6918373703956604,
      "learning_rate": 0.00017556438893500946,
      "loss": 2.5502,
      "step": 11200
    },
    {
      "epoch": 0.7516526291064058,
      "eval_bleu": 20.905271233074313,
      "eval_gen_len": 28.964,
      "eval_loss": 2.9503872394561768,
      "eval_runtime": 69.1123,
      "eval_samples_per_second": 14.469,
      "eval_steps_per_second": 0.912,
      "step": 11200
    },
    {
      "epoch": 0.7523237475252509,
      "grad_norm": 0.6592450141906738,
      "learning_rate": 0.00017551691427857705,
      "loss": 2.57,
      "step": 11210
    },
    {
      "epoch": 0.7529948659440958,
      "grad_norm": 0.656226396560669,
      "learning_rate": 0.0001754693999810733,
      "loss": 2.552,
      "step": 11220
    },
    {
      "epoch": 0.7536659843629409,
      "grad_norm": 0.6175928115844727,
      "learning_rate": 0.00017542184606743986,
      "loss": 2.5189,
      "step": 11230
    },
    {
      "epoch": 0.7543371027817859,
      "grad_norm": 0.6723144054412842,
      "learning_rate": 0.00017537425256263918,
      "loss": 2.5064,
      "step": 11240
    },
    {
      "epoch": 0.7550082212006308,
      "grad_norm": 0.6368762850761414,
      "learning_rate": 0.00017532661949165457,
      "loss": 2.5639,
      "step": 11250
    },
    {
      "epoch": 0.7550082212006308,
      "eval_bleu": 21.46234921170609,
      "eval_gen_len": 29.052,
      "eval_loss": 2.945087194442749,
      "eval_runtime": 70.7799,
      "eval_samples_per_second": 14.128,
      "eval_steps_per_second": 0.89,
      "step": 11250
    },
    {
      "epoch": 0.7556793396194759,
      "grad_norm": 0.6428797245025635,
      "learning_rate": 0.00017527894687948995,
      "loss": 2.5257,
      "step": 11260
    },
    {
      "epoch": 0.7563504580383209,
      "grad_norm": 0.6809651255607605,
      "learning_rate": 0.00017523123475117017,
      "loss": 2.4883,
      "step": 11270
    },
    {
      "epoch": 0.7570215764571658,
      "grad_norm": 0.7206113338470459,
      "learning_rate": 0.0001751834831317407,
      "loss": 2.5405,
      "step": 11280
    },
    {
      "epoch": 0.7576926948760109,
      "grad_norm": 0.7028821110725403,
      "learning_rate": 0.00017513569204626777,
      "loss": 2.5464,
      "step": 11290
    },
    {
      "epoch": 0.7583638132948559,
      "grad_norm": 0.68695467710495,
      "learning_rate": 0.0001750878615198384,
      "loss": 2.543,
      "step": 11300
    },
    {
      "epoch": 0.7583638132948559,
      "eval_bleu": 21.111508589328015,
      "eval_gen_len": 28.899,
      "eval_loss": 2.9448912143707275,
      "eval_runtime": 67.5959,
      "eval_samples_per_second": 14.794,
      "eval_steps_per_second": 0.932,
      "step": 11300
    },
    {
      "epoch": 0.7590349317137008,
      "grad_norm": 0.6802505850791931,
      "learning_rate": 0.0001750399915775602,
      "loss": 2.5351,
      "step": 11310
    },
    {
      "epoch": 0.7597060501325459,
      "grad_norm": 0.6789311766624451,
      "learning_rate": 0.0001749920822445615,
      "loss": 2.5265,
      "step": 11320
    },
    {
      "epoch": 0.7603771685513909,
      "grad_norm": 0.7047219276428223,
      "learning_rate": 0.00017494413354599141,
      "loss": 2.5901,
      "step": 11330
    },
    {
      "epoch": 0.7610482869702359,
      "grad_norm": 0.7184047102928162,
      "learning_rate": 0.00017489614550701961,
      "loss": 2.5365,
      "step": 11340
    },
    {
      "epoch": 0.7617194053890809,
      "grad_norm": 0.6948058009147644,
      "learning_rate": 0.00017484811815283638,
      "loss": 2.5175,
      "step": 11350
    },
    {
      "epoch": 0.7617194053890809,
      "eval_bleu": 21.174153607750032,
      "eval_gen_len": 29.094,
      "eval_loss": 2.9444267749786377,
      "eval_runtime": 70.5946,
      "eval_samples_per_second": 14.165,
      "eval_steps_per_second": 0.892,
      "step": 11350
    },
    {
      "epoch": 0.7623905238079259,
      "grad_norm": 0.7296558022499084,
      "learning_rate": 0.0001748000515086528,
      "loss": 2.5988,
      "step": 11360
    },
    {
      "epoch": 0.7630616422267709,
      "grad_norm": 0.7240709066390991,
      "learning_rate": 0.0001747519455997004,
      "loss": 2.5679,
      "step": 11370
    },
    {
      "epoch": 0.7637327606456159,
      "grad_norm": 0.7856075167655945,
      "learning_rate": 0.00017470380045123146,
      "loss": 2.5382,
      "step": 11380
    },
    {
      "epoch": 0.764403879064461,
      "grad_norm": 0.7135448455810547,
      "learning_rate": 0.00017465561608851876,
      "loss": 2.4948,
      "step": 11390
    },
    {
      "epoch": 0.7650749974833059,
      "grad_norm": 0.6952425837516785,
      "learning_rate": 0.00017460739253685569,
      "loss": 2.6352,
      "step": 11400
    },
    {
      "epoch": 0.7650749974833059,
      "eval_bleu": 20.254665929831834,
      "eval_gen_len": 28.924,
      "eval_loss": 2.9534926414489746,
      "eval_runtime": 64.3914,
      "eval_samples_per_second": 15.53,
      "eval_steps_per_second": 0.978,
      "step": 11400
    },
    {
      "epoch": 0.7657461159021509,
      "grad_norm": 0.6506470441818237,
      "learning_rate": 0.00017455912982155625,
      "loss": 2.554,
      "step": 11410
    },
    {
      "epoch": 0.766417234320996,
      "grad_norm": 0.6515897512435913,
      "learning_rate": 0.00017451082796795497,
      "loss": 2.6034,
      "step": 11420
    },
    {
      "epoch": 0.767088352739841,
      "grad_norm": 0.7414047718048096,
      "learning_rate": 0.00017446248700140693,
      "loss": 2.5794,
      "step": 11430
    },
    {
      "epoch": 0.7677594711586859,
      "grad_norm": 0.7340644598007202,
      "learning_rate": 0.00017441410694728774,
      "loss": 2.512,
      "step": 11440
    },
    {
      "epoch": 0.768430589577531,
      "grad_norm": 0.6786364316940308,
      "learning_rate": 0.00017436568783099353,
      "loss": 2.5767,
      "step": 11450
    },
    {
      "epoch": 0.768430589577531,
      "eval_bleu": 21.142046786884467,
      "eval_gen_len": 28.941,
      "eval_loss": 2.945443868637085,
      "eval_runtime": 63.5477,
      "eval_samples_per_second": 15.736,
      "eval_steps_per_second": 0.991,
      "step": 11450
    },
    {
      "epoch": 0.769101707996376,
      "grad_norm": 0.6953631043434143,
      "learning_rate": 0.0001743172296779409,
      "loss": 2.5274,
      "step": 11460
    },
    {
      "epoch": 0.7697728264152209,
      "grad_norm": 0.7216240167617798,
      "learning_rate": 0.00017426873251356705,
      "loss": 2.5709,
      "step": 11470
    },
    {
      "epoch": 0.770443944834066,
      "grad_norm": 0.7157938480377197,
      "learning_rate": 0.0001742201963633295,
      "loss": 2.5372,
      "step": 11480
    },
    {
      "epoch": 0.771115063252911,
      "grad_norm": 0.706731915473938,
      "learning_rate": 0.00017417162125270635,
      "loss": 2.5617,
      "step": 11490
    },
    {
      "epoch": 0.7717861816717559,
      "grad_norm": 0.6945808529853821,
      "learning_rate": 0.00017412300720719612,
      "loss": 2.5655,
      "step": 11500
    },
    {
      "epoch": 0.7717861816717559,
      "eval_bleu": 20.47039991803655,
      "eval_gen_len": 28.782,
      "eval_loss": 2.950313091278076,
      "eval_runtime": 66.9567,
      "eval_samples_per_second": 14.935,
      "eval_steps_per_second": 0.941,
      "step": 11500
    },
    {
      "epoch": 0.772457300090601,
      "grad_norm": 0.6961724758148193,
      "learning_rate": 0.00017407435425231777,
      "loss": 2.5912,
      "step": 11510
    },
    {
      "epoch": 0.773128418509446,
      "grad_norm": 0.6956660747528076,
      "learning_rate": 0.0001740256624136107,
      "loss": 2.5527,
      "step": 11520
    },
    {
      "epoch": 0.773799536928291,
      "grad_norm": 0.634628176689148,
      "learning_rate": 0.00017397693171663462,
      "loss": 2.4934,
      "step": 11530
    },
    {
      "epoch": 0.774470655347136,
      "grad_norm": 0.8141909241676331,
      "learning_rate": 0.0001739281621869698,
      "loss": 2.5963,
      "step": 11540
    },
    {
      "epoch": 0.775141773765981,
      "grad_norm": 0.7276056408882141,
      "learning_rate": 0.0001738793538502168,
      "loss": 2.5145,
      "step": 11550
    },
    {
      "epoch": 0.775141773765981,
      "eval_bleu": 20.452838325871447,
      "eval_gen_len": 28.602,
      "eval_loss": 2.9563796520233154,
      "eval_runtime": 67.0884,
      "eval_samples_per_second": 14.906,
      "eval_steps_per_second": 0.939,
      "step": 11550
    },
    {
      "epoch": 0.775812892184826,
      "grad_norm": 0.69050532579422,
      "learning_rate": 0.00017383050673199657,
      "loss": 2.5206,
      "step": 11560
    },
    {
      "epoch": 0.776484010603671,
      "grad_norm": 0.6799372434616089,
      "learning_rate": 0.0001737816208579504,
      "loss": 2.5128,
      "step": 11570
    },
    {
      "epoch": 0.777155129022516,
      "grad_norm": 0.7014333009719849,
      "learning_rate": 0.00017373269625373995,
      "loss": 2.5215,
      "step": 11580
    },
    {
      "epoch": 0.777826247441361,
      "grad_norm": 0.6880388855934143,
      "learning_rate": 0.00017368373294504713,
      "loss": 2.5057,
      "step": 11590
    },
    {
      "epoch": 0.778497365860206,
      "grad_norm": 0.76747727394104,
      "learning_rate": 0.00017363473095757435,
      "loss": 2.5297,
      "step": 11600
    },
    {
      "epoch": 0.778497365860206,
      "eval_bleu": 20.615539457468177,
      "eval_gen_len": 28.705,
      "eval_loss": 2.9586870670318604,
      "eval_runtime": 66.9912,
      "eval_samples_per_second": 14.927,
      "eval_steps_per_second": 0.94,
      "step": 11600
    },
    {
      "epoch": 0.779168484279051,
      "grad_norm": 0.7205276489257812,
      "learning_rate": 0.00017358569031704411,
      "loss": 2.4955,
      "step": 11610
    },
    {
      "epoch": 0.7798396026978961,
      "grad_norm": 0.819526195526123,
      "learning_rate": 0.00017353661104919937,
      "loss": 2.545,
      "step": 11620
    },
    {
      "epoch": 0.780510721116741,
      "grad_norm": 0.7283115386962891,
      "learning_rate": 0.00017348749317980326,
      "loss": 2.5459,
      "step": 11630
    },
    {
      "epoch": 0.7811818395355861,
      "grad_norm": 0.7121266722679138,
      "learning_rate": 0.0001734383367346392,
      "loss": 2.5724,
      "step": 11640
    },
    {
      "epoch": 0.7818529579544311,
      "grad_norm": 0.7040840983390808,
      "learning_rate": 0.00017338914173951092,
      "loss": 2.4978,
      "step": 11650
    },
    {
      "epoch": 0.7818529579544311,
      "eval_bleu": 20.95691019318735,
      "eval_gen_len": 28.753,
      "eval_loss": 2.9515419006347656,
      "eval_runtime": 67.2145,
      "eval_samples_per_second": 14.878,
      "eval_steps_per_second": 0.937,
      "step": 11650
    },
    {
      "epoch": 0.782524076373276,
      "grad_norm": 0.7279627323150635,
      "learning_rate": 0.00017333990822024223,
      "loss": 2.5546,
      "step": 11660
    },
    {
      "epoch": 0.7831951947921211,
      "grad_norm": 0.708296537399292,
      "learning_rate": 0.0001732906362026774,
      "loss": 2.5517,
      "step": 11670
    },
    {
      "epoch": 0.7838663132109661,
      "grad_norm": 0.6996859312057495,
      "learning_rate": 0.00017324132571268063,
      "loss": 2.546,
      "step": 11680
    },
    {
      "epoch": 0.784537431629811,
      "grad_norm": 0.7114112973213196,
      "learning_rate": 0.00017319197677613662,
      "loss": 2.4988,
      "step": 11690
    },
    {
      "epoch": 0.7852085500486561,
      "grad_norm": 0.651915431022644,
      "learning_rate": 0.00017314258941894997,
      "loss": 2.4939,
      "step": 11700
    },
    {
      "epoch": 0.7852085500486561,
      "eval_bleu": 20.840125013857833,
      "eval_gen_len": 28.883,
      "eval_loss": 2.9463489055633545,
      "eval_runtime": 67.9271,
      "eval_samples_per_second": 14.722,
      "eval_steps_per_second": 0.927,
      "step": 11700
    },
    {
      "epoch": 0.7858796684675011,
      "grad_norm": 0.626251220703125,
      "learning_rate": 0.0001730931636670456,
      "loss": 2.5715,
      "step": 11710
    },
    {
      "epoch": 0.786550786886346,
      "grad_norm": 0.7525676488876343,
      "learning_rate": 0.0001730436995463686,
      "loss": 2.5035,
      "step": 11720
    },
    {
      "epoch": 0.7872219053051911,
      "grad_norm": 0.7228103280067444,
      "learning_rate": 0.0001729941970828841,
      "loss": 2.5415,
      "step": 11730
    },
    {
      "epoch": 0.7878930237240361,
      "grad_norm": 0.6582031846046448,
      "learning_rate": 0.00017294465630257743,
      "loss": 2.5344,
      "step": 11740
    },
    {
      "epoch": 0.7885641421428811,
      "grad_norm": 0.6743517518043518,
      "learning_rate": 0.00017289507723145406,
      "loss": 2.5519,
      "step": 11750
    },
    {
      "epoch": 0.7885641421428811,
      "eval_bleu": 20.67845301255588,
      "eval_gen_len": 28.776,
      "eval_loss": 2.953026294708252,
      "eval_runtime": 67.1013,
      "eval_samples_per_second": 14.903,
      "eval_steps_per_second": 0.939,
      "step": 11750
    },
    {
      "epoch": 0.7892352605617261,
      "grad_norm": 0.6591427326202393,
      "learning_rate": 0.00017284545989553943,
      "loss": 2.5731,
      "step": 11760
    },
    {
      "epoch": 0.7899063789805711,
      "grad_norm": 0.7685933113098145,
      "learning_rate": 0.00017279580432087927,
      "loss": 2.5881,
      "step": 11770
    },
    {
      "epoch": 0.7905774973994161,
      "grad_norm": 0.662340521812439,
      "learning_rate": 0.00017274611053353915,
      "loss": 2.5692,
      "step": 11780
    },
    {
      "epoch": 0.7912486158182611,
      "grad_norm": 0.7160519957542419,
      "learning_rate": 0.00017269637855960488,
      "loss": 2.5935,
      "step": 11790
    },
    {
      "epoch": 0.7919197342371062,
      "grad_norm": 0.7023179531097412,
      "learning_rate": 0.00017264660842518224,
      "loss": 2.5263,
      "step": 11800
    },
    {
      "epoch": 0.7919197342371062,
      "eval_bleu": 20.90327389026697,
      "eval_gen_len": 28.848,
      "eval_loss": 2.949442148208618,
      "eval_runtime": 67.4161,
      "eval_samples_per_second": 14.833,
      "eval_steps_per_second": 0.934,
      "step": 11800
    },
    {
      "epoch": 0.7925908526559512,
      "grad_norm": 0.7310783863067627,
      "learning_rate": 0.00017259680015639704,
      "loss": 2.5424,
      "step": 11810
    },
    {
      "epoch": 0.7932619710747961,
      "grad_norm": 0.6549587845802307,
      "learning_rate": 0.00017254695377939516,
      "loss": 2.5703,
      "step": 11820
    },
    {
      "epoch": 0.7939330894936412,
      "grad_norm": 0.727388858795166,
      "learning_rate": 0.00017249706932034235,
      "loss": 2.5483,
      "step": 11830
    },
    {
      "epoch": 0.7946042079124862,
      "grad_norm": 0.7777060270309448,
      "learning_rate": 0.00017244714680542456,
      "loss": 2.5323,
      "step": 11840
    },
    {
      "epoch": 0.7952753263313311,
      "grad_norm": 0.6617782115936279,
      "learning_rate": 0.0001723971862608475,
      "loss": 2.5544,
      "step": 11850
    },
    {
      "epoch": 0.7952753263313311,
      "eval_bleu": 20.936474777174684,
      "eval_gen_len": 28.801,
      "eval_loss": 2.9524033069610596,
      "eval_runtime": 67.3638,
      "eval_samples_per_second": 14.845,
      "eval_steps_per_second": 0.935,
      "step": 11850
    },
    {
      "epoch": 0.7959464447501762,
      "grad_norm": 0.7368456721305847,
      "learning_rate": 0.00017234718771283702,
      "loss": 2.5537,
      "step": 11860
    },
    {
      "epoch": 0.7966175631690212,
      "grad_norm": 0.8304107785224915,
      "learning_rate": 0.00017229715118763882,
      "loss": 2.5298,
      "step": 11870
    },
    {
      "epoch": 0.7972886815878661,
      "grad_norm": 0.7278929352760315,
      "learning_rate": 0.00017224707671151853,
      "loss": 2.5596,
      "step": 11880
    },
    {
      "epoch": 0.7979598000067112,
      "grad_norm": 0.7599664926528931,
      "learning_rate": 0.00017219696431076175,
      "loss": 2.5393,
      "step": 11890
    },
    {
      "epoch": 0.7986309184255562,
      "grad_norm": 0.6692876219749451,
      "learning_rate": 0.00017214681401167399,
      "loss": 2.577,
      "step": 11900
    },
    {
      "epoch": 0.7986309184255562,
      "eval_bleu": 20.826889341911713,
      "eval_gen_len": 29.177,
      "eval_loss": 2.950000762939453,
      "eval_runtime": 71.7577,
      "eval_samples_per_second": 13.936,
      "eval_steps_per_second": 0.878,
      "step": 11900
    },
    {
      "epoch": 0.7993020368444012,
      "grad_norm": 0.6504721641540527,
      "learning_rate": 0.00017209662584058059,
      "loss": 2.5466,
      "step": 11910
    },
    {
      "epoch": 0.7999731552632462,
      "grad_norm": 0.6365048289299011,
      "learning_rate": 0.00017204639982382688,
      "loss": 2.5744,
      "step": 11920
    },
    {
      "epoch": 0.8006442736820912,
      "grad_norm": 0.6742818355560303,
      "learning_rate": 0.0001719961359877779,
      "loss": 2.5406,
      "step": 11930
    },
    {
      "epoch": 0.8013153921009362,
      "grad_norm": 0.649966299533844,
      "learning_rate": 0.00017194583435881867,
      "loss": 2.534,
      "step": 11940
    },
    {
      "epoch": 0.8019865105197812,
      "grad_norm": 0.7123164534568787,
      "learning_rate": 0.000171895494963354,
      "loss": 2.5681,
      "step": 11950
    },
    {
      "epoch": 0.8019865105197812,
      "eval_bleu": 21.06035807323094,
      "eval_gen_len": 28.821,
      "eval_loss": 2.9508893489837646,
      "eval_runtime": 67.7079,
      "eval_samples_per_second": 14.769,
      "eval_steps_per_second": 0.93,
      "step": 11950
    },
    {
      "epoch": 0.8026576289386262,
      "grad_norm": 0.6911179423332214,
      "learning_rate": 0.00017184511782780858,
      "loss": 2.5437,
      "step": 11960
    },
    {
      "epoch": 0.8033287473574712,
      "grad_norm": 0.7040723562240601,
      "learning_rate": 0.0001717947029786268,
      "loss": 2.5156,
      "step": 11970
    },
    {
      "epoch": 0.8039998657763162,
      "grad_norm": 0.6880275011062622,
      "learning_rate": 0.00017174425044227295,
      "loss": 2.5083,
      "step": 11980
    },
    {
      "epoch": 0.8046709841951613,
      "grad_norm": 0.6972112059593201,
      "learning_rate": 0.00017169376024523102,
      "loss": 2.522,
      "step": 11990
    },
    {
      "epoch": 0.8053421026140063,
      "grad_norm": 0.7057710289955139,
      "learning_rate": 0.0001716432324140049,
      "loss": 2.5803,
      "step": 12000
    },
    {
      "epoch": 0.8053421026140063,
      "eval_bleu": 20.569224716965966,
      "eval_gen_len": 29.154,
      "eval_loss": 2.9521894454956055,
      "eval_runtime": 72.0213,
      "eval_samples_per_second": 13.885,
      "eval_steps_per_second": 0.875,
      "step": 12000
    },
    {
      "epoch": 0.8060132210328512,
      "grad_norm": 0.7643245458602905,
      "learning_rate": 0.0001715926669751181,
      "loss": 2.4967,
      "step": 12010
    },
    {
      "epoch": 0.8066843394516963,
      "grad_norm": 0.7097739577293396,
      "learning_rate": 0.00017154206395511386,
      "loss": 2.5401,
      "step": 12020
    },
    {
      "epoch": 0.8073554578705413,
      "grad_norm": 0.7235851287841797,
      "learning_rate": 0.0001714914233805553,
      "loss": 2.5675,
      "step": 12030
    },
    {
      "epoch": 0.8080265762893862,
      "grad_norm": 0.6807438135147095,
      "learning_rate": 0.00017144074527802516,
      "loss": 2.5433,
      "step": 12040
    },
    {
      "epoch": 0.8086976947082313,
      "grad_norm": 0.7443094253540039,
      "learning_rate": 0.0001713900296741258,
      "loss": 2.5346,
      "step": 12050
    },
    {
      "epoch": 0.8086976947082313,
      "eval_bleu": 20.573692649442982,
      "eval_gen_len": 29.097,
      "eval_loss": 2.9494130611419678,
      "eval_runtime": 71.0828,
      "eval_samples_per_second": 14.068,
      "eval_steps_per_second": 0.886,
      "step": 12050
    },
    {
      "epoch": 0.8093688131270763,
      "grad_norm": 0.753372848033905,
      "learning_rate": 0.00017133927659547946,
      "loss": 2.5749,
      "step": 12060
    },
    {
      "epoch": 0.8100399315459212,
      "grad_norm": 0.6857530474662781,
      "learning_rate": 0.00017128848606872782,
      "loss": 2.5198,
      "step": 12070
    },
    {
      "epoch": 0.8107110499647663,
      "grad_norm": 0.6724787950515747,
      "learning_rate": 0.00017123765812053244,
      "loss": 2.5238,
      "step": 12080
    },
    {
      "epoch": 0.8113821683836113,
      "grad_norm": 0.7536911964416504,
      "learning_rate": 0.0001711867927775743,
      "loss": 2.5712,
      "step": 12090
    },
    {
      "epoch": 0.8120532868024563,
      "grad_norm": 0.7508702278137207,
      "learning_rate": 0.00017113589006655428,
      "loss": 2.5945,
      "step": 12100
    },
    {
      "epoch": 0.8120532868024563,
      "eval_bleu": 20.703106891155556,
      "eval_gen_len": 29.011,
      "eval_loss": 2.9528188705444336,
      "eval_runtime": 70.452,
      "eval_samples_per_second": 14.194,
      "eval_steps_per_second": 0.894,
      "step": 12100
    },
    {
      "epoch": 0.8127244052213013,
      "grad_norm": 0.7754359841346741,
      "learning_rate": 0.00017108495001419262,
      "loss": 2.5336,
      "step": 12110
    },
    {
      "epoch": 0.8133955236401463,
      "grad_norm": 0.7133001685142517,
      "learning_rate": 0.0001710339726472293,
      "loss": 2.6142,
      "step": 12120
    },
    {
      "epoch": 0.8140666420589913,
      "grad_norm": 0.7541532516479492,
      "learning_rate": 0.0001709829579924238,
      "loss": 2.5189,
      "step": 12130
    },
    {
      "epoch": 0.8147377604778363,
      "grad_norm": 0.705237627029419,
      "learning_rate": 0.00017093190607655532,
      "loss": 2.5376,
      "step": 12140
    },
    {
      "epoch": 0.8154088788966813,
      "grad_norm": 0.6810922026634216,
      "learning_rate": 0.00017088081692642247,
      "loss": 2.4865,
      "step": 12150
    },
    {
      "epoch": 0.8154088788966813,
      "eval_bleu": 20.81779498158539,
      "eval_gen_len": 28.806,
      "eval_loss": 2.952139139175415,
      "eval_runtime": 65.0298,
      "eval_samples_per_second": 15.378,
      "eval_steps_per_second": 0.969,
      "step": 12150
    },
    {
      "epoch": 0.8160799973155263,
      "grad_norm": 0.6868711709976196,
      "learning_rate": 0.00017082969056884348,
      "loss": 2.525,
      "step": 12160
    },
    {
      "epoch": 0.8167511157343713,
      "grad_norm": 0.6577426791191101,
      "learning_rate": 0.00017077852703065608,
      "loss": 2.5501,
      "step": 12170
    },
    {
      "epoch": 0.8174222341532164,
      "grad_norm": 0.7833941578865051,
      "learning_rate": 0.00017072732633871752,
      "loss": 2.549,
      "step": 12180
    },
    {
      "epoch": 0.8180933525720614,
      "grad_norm": 0.6099527478218079,
      "learning_rate": 0.00017067608851990463,
      "loss": 2.5204,
      "step": 12190
    },
    {
      "epoch": 0.8187644709909063,
      "grad_norm": 0.7065662145614624,
      "learning_rate": 0.00017062481360111356,
      "loss": 2.5088,
      "step": 12200
    },
    {
      "epoch": 0.8187644709909063,
      "eval_bleu": 20.351899870393794,
      "eval_gen_len": 28.945,
      "eval_loss": 2.950176477432251,
      "eval_runtime": 61.886,
      "eval_samples_per_second": 16.159,
      "eval_steps_per_second": 1.018,
      "step": 12200
    },
    {
      "epoch": 0.8194355894097514,
      "grad_norm": 0.6879181265830994,
      "learning_rate": 0.00017057350160926013,
      "loss": 2.5578,
      "step": 12210
    },
    {
      "epoch": 0.8201067078285964,
      "grad_norm": 0.6821224689483643,
      "learning_rate": 0.00017052215257127947,
      "loss": 2.5143,
      "step": 12220
    },
    {
      "epoch": 0.8207778262474413,
      "grad_norm": 0.6585990786552429,
      "learning_rate": 0.00017047076651412625,
      "loss": 2.5499,
      "step": 12230
    },
    {
      "epoch": 0.8214489446662864,
      "grad_norm": 0.7363858222961426,
      "learning_rate": 0.00017041934346477452,
      "loss": 2.5803,
      "step": 12240
    },
    {
      "epoch": 0.8221200630851314,
      "grad_norm": 0.6888251900672913,
      "learning_rate": 0.00017036788345021778,
      "loss": 2.5397,
      "step": 12250
    },
    {
      "epoch": 0.8221200630851314,
      "eval_bleu": 20.48490093193552,
      "eval_gen_len": 29.354,
      "eval_loss": 2.951218843460083,
      "eval_runtime": 69.5714,
      "eval_samples_per_second": 14.374,
      "eval_steps_per_second": 0.906,
      "step": 12250
    },
    {
      "epoch": 0.8227911815039763,
      "grad_norm": 0.6968580484390259,
      "learning_rate": 0.00017031638649746893,
      "loss": 2.5582,
      "step": 12260
    },
    {
      "epoch": 0.8234622999228214,
      "grad_norm": 0.7391836047172546,
      "learning_rate": 0.00017026485263356019,
      "loss": 2.5512,
      "step": 12270
    },
    {
      "epoch": 0.8241334183416664,
      "grad_norm": 0.6816040873527527,
      "learning_rate": 0.00017021328188554326,
      "loss": 2.5202,
      "step": 12280
    },
    {
      "epoch": 0.8248045367605114,
      "grad_norm": 0.7540592551231384,
      "learning_rate": 0.0001701616742804892,
      "loss": 2.5226,
      "step": 12290
    },
    {
      "epoch": 0.8254756551793564,
      "grad_norm": 0.7157480716705322,
      "learning_rate": 0.00017011002984548829,
      "loss": 2.5362,
      "step": 12300
    },
    {
      "epoch": 0.8254756551793564,
      "eval_bleu": 21.10327668272752,
      "eval_gen_len": 28.924,
      "eval_loss": 2.9445254802703857,
      "eval_runtime": 60.6802,
      "eval_samples_per_second": 16.48,
      "eval_steps_per_second": 1.038,
      "step": 12300
    },
    {
      "epoch": 0.8261467735982014,
      "grad_norm": 0.7592250108718872,
      "learning_rate": 0.00017005834860765026,
      "loss": 2.5399,
      "step": 12310
    },
    {
      "epoch": 0.8268178920170464,
      "grad_norm": 0.6359797716140747,
      "learning_rate": 0.00017000663059410417,
      "loss": 2.548,
      "step": 12320
    },
    {
      "epoch": 0.8274890104358914,
      "grad_norm": 0.7252846956253052,
      "learning_rate": 0.00016995487583199828,
      "loss": 2.5008,
      "step": 12330
    },
    {
      "epoch": 0.8281601288547364,
      "grad_norm": 0.6748124361038208,
      "learning_rate": 0.00016990308434850022,
      "loss": 2.5065,
      "step": 12340
    },
    {
      "epoch": 0.8288312472735814,
      "grad_norm": 0.6341248154640198,
      "learning_rate": 0.0001698512561707969,
      "loss": 2.5056,
      "step": 12350
    },
    {
      "epoch": 0.8288312472735814,
      "eval_bleu": 20.526853488442608,
      "eval_gen_len": 28.977,
      "eval_loss": 2.946622848510742,
      "eval_runtime": 61.579,
      "eval_samples_per_second": 16.239,
      "eval_steps_per_second": 1.023,
      "step": 12350
    },
    {
      "epoch": 0.8295023656924264,
      "grad_norm": 0.6634450554847717,
      "learning_rate": 0.00016979939132609443,
      "loss": 2.5767,
      "step": 12360
    },
    {
      "epoch": 0.8301734841112715,
      "grad_norm": 0.6160123944282532,
      "learning_rate": 0.00016974748984161826,
      "loss": 2.5234,
      "step": 12370
    },
    {
      "epoch": 0.8308446025301165,
      "grad_norm": 0.6828749179840088,
      "learning_rate": 0.000169695551744613,
      "loss": 2.5013,
      "step": 12380
    },
    {
      "epoch": 0.8315157209489614,
      "grad_norm": 0.7360215783119202,
      "learning_rate": 0.0001696435770623425,
      "loss": 2.5634,
      "step": 12390
    },
    {
      "epoch": 0.8321868393678065,
      "grad_norm": 0.7131897807121277,
      "learning_rate": 0.00016959156582208978,
      "loss": 2.5038,
      "step": 12400
    },
    {
      "epoch": 0.8321868393678065,
      "eval_bleu": 20.843140696949725,
      "eval_gen_len": 29.008,
      "eval_loss": 2.9455437660217285,
      "eval_runtime": 61.6529,
      "eval_samples_per_second": 16.22,
      "eval_steps_per_second": 1.022,
      "step": 12400
    },
    {
      "epoch": 0.8328579577866515,
      "grad_norm": 0.6394587755203247,
      "learning_rate": 0.0001695395180511571,
      "loss": 2.5177,
      "step": 12410
    },
    {
      "epoch": 0.8335290762054964,
      "grad_norm": 0.659876823425293,
      "learning_rate": 0.00016948743377686592,
      "loss": 2.541,
      "step": 12420
    },
    {
      "epoch": 0.8342001946243415,
      "grad_norm": 0.7081223726272583,
      "learning_rate": 0.0001694353130265568,
      "loss": 2.5796,
      "step": 12430
    },
    {
      "epoch": 0.8348713130431865,
      "grad_norm": 0.6629865765571594,
      "learning_rate": 0.00016938315582758944,
      "loss": 2.5663,
      "step": 12440
    },
    {
      "epoch": 0.8355424314620314,
      "grad_norm": 0.6709829568862915,
      "learning_rate": 0.00016933096220734278,
      "loss": 2.5365,
      "step": 12450
    },
    {
      "epoch": 0.8355424314620314,
      "eval_bleu": 20.17640068734344,
      "eval_gen_len": 28.806,
      "eval_loss": 2.9510042667388916,
      "eval_runtime": 60.5619,
      "eval_samples_per_second": 16.512,
      "eval_steps_per_second": 1.04,
      "step": 12450
    },
    {
      "epoch": 0.8362135498808765,
      "grad_norm": 0.7043548822402954,
      "learning_rate": 0.0001692787321932147,
      "loss": 2.5124,
      "step": 12460
    },
    {
      "epoch": 0.8368846682997215,
      "grad_norm": 0.7061871290206909,
      "learning_rate": 0.00016922646581262236,
      "loss": 2.5343,
      "step": 12470
    },
    {
      "epoch": 0.8375557867185665,
      "grad_norm": 0.7099971771240234,
      "learning_rate": 0.0001691741630930019,
      "loss": 2.5525,
      "step": 12480
    },
    {
      "epoch": 0.8382269051374115,
      "grad_norm": 0.7109832167625427,
      "learning_rate": 0.00016912182406180856,
      "loss": 2.5442,
      "step": 12490
    },
    {
      "epoch": 0.8388980235562565,
      "grad_norm": 0.6722378134727478,
      "learning_rate": 0.00016906944874651672,
      "loss": 2.5082,
      "step": 12500
    },
    {
      "epoch": 0.8388980235562565,
      "eval_bleu": 20.789707835760534,
      "eval_gen_len": 28.913,
      "eval_loss": 2.9442381858825684,
      "eval_runtime": 60.8089,
      "eval_samples_per_second": 16.445,
      "eval_steps_per_second": 1.036,
      "step": 12500
    },
    {
      "epoch": 0.8395691419751015,
      "grad_norm": 0.8237881660461426,
      "learning_rate": 0.00016901703717461968,
      "loss": 2.5154,
      "step": 12510
    },
    {
      "epoch": 0.8402402603939465,
      "grad_norm": 0.7830245494842529,
      "learning_rate": 0.00016896458937362983,
      "loss": 2.5457,
      "step": 12520
    },
    {
      "epoch": 0.8409113788127915,
      "grad_norm": 0.6897457242012024,
      "learning_rate": 0.0001689121053710786,
      "loss": 2.4826,
      "step": 12530
    },
    {
      "epoch": 0.8415824972316365,
      "grad_norm": 0.7263143062591553,
      "learning_rate": 0.00016885958519451642,
      "loss": 2.5479,
      "step": 12540
    },
    {
      "epoch": 0.8422536156504815,
      "grad_norm": 0.7093539237976074,
      "learning_rate": 0.00016880702887151264,
      "loss": 2.544,
      "step": 12550
    },
    {
      "epoch": 0.8422536156504815,
      "eval_bleu": 20.43633507499528,
      "eval_gen_len": 29.053,
      "eval_loss": 2.951131820678711,
      "eval_runtime": 64.4876,
      "eval_samples_per_second": 15.507,
      "eval_steps_per_second": 0.977,
      "step": 12550
    },
    {
      "epoch": 0.8429247340693266,
      "grad_norm": 0.7219638228416443,
      "learning_rate": 0.00016875443642965564,
      "loss": 2.5267,
      "step": 12560
    },
    {
      "epoch": 0.8435958524881715,
      "grad_norm": 0.6138253211975098,
      "learning_rate": 0.00016870180789655282,
      "loss": 2.5391,
      "step": 12570
    },
    {
      "epoch": 0.8442669709070165,
      "grad_norm": 0.6990343928337097,
      "learning_rate": 0.00016864914329983038,
      "loss": 2.5256,
      "step": 12580
    },
    {
      "epoch": 0.8449380893258616,
      "grad_norm": 0.7132797837257385,
      "learning_rate": 0.0001685964426671336,
      "loss": 2.5103,
      "step": 12590
    },
    {
      "epoch": 0.8456092077447066,
      "grad_norm": 0.7616413235664368,
      "learning_rate": 0.00016854370602612656,
      "loss": 2.5113,
      "step": 12600
    },
    {
      "epoch": 0.8456092077447066,
      "eval_bleu": 20.877113645918275,
      "eval_gen_len": 29.053,
      "eval_loss": 2.946302890777588,
      "eval_runtime": 63.6871,
      "eval_samples_per_second": 15.702,
      "eval_steps_per_second": 0.989,
      "step": 12600
    },
    {
      "epoch": 0.8462803261635515,
      "grad_norm": 0.7127696871757507,
      "learning_rate": 0.0001684909334044923,
      "loss": 2.5807,
      "step": 12610
    },
    {
      "epoch": 0.8469514445823966,
      "grad_norm": 0.6404547095298767,
      "learning_rate": 0.00016843812482993274,
      "loss": 2.5764,
      "step": 12620
    },
    {
      "epoch": 0.8476225630012416,
      "grad_norm": 0.7866703271865845,
      "learning_rate": 0.00016838528033016867,
      "loss": 2.5314,
      "step": 12630
    },
    {
      "epoch": 0.8482936814200865,
      "grad_norm": 0.6592109799385071,
      "learning_rate": 0.00016833239993293975,
      "loss": 2.5084,
      "step": 12640
    },
    {
      "epoch": 0.8489647998389316,
      "grad_norm": 0.6857773661613464,
      "learning_rate": 0.00016827948366600443,
      "loss": 2.5034,
      "step": 12650
    },
    {
      "epoch": 0.8489647998389316,
      "eval_bleu": 20.81099072282424,
      "eval_gen_len": 28.846,
      "eval_loss": 2.948495626449585,
      "eval_runtime": 59.5065,
      "eval_samples_per_second": 16.805,
      "eval_steps_per_second": 1.059,
      "step": 12650
    },
    {
      "epoch": 0.8496359182577766,
      "grad_norm": 0.6404989361763,
      "learning_rate": 0.00016822653155714007,
      "loss": 2.5061,
      "step": 12660
    },
    {
      "epoch": 0.8503070366766216,
      "grad_norm": 0.7301089763641357,
      "learning_rate": 0.0001681735436341428,
      "loss": 2.5074,
      "step": 12670
    },
    {
      "epoch": 0.8509781550954666,
      "grad_norm": 0.650905430316925,
      "learning_rate": 0.00016812051992482757,
      "loss": 2.5253,
      "step": 12680
    },
    {
      "epoch": 0.8516492735143116,
      "grad_norm": 0.6906124353408813,
      "learning_rate": 0.00016806746045702805,
      "loss": 2.4427,
      "step": 12690
    },
    {
      "epoch": 0.8523203919331566,
      "grad_norm": 0.7588697671890259,
      "learning_rate": 0.00016801436525859675,
      "loss": 2.5691,
      "step": 12700
    },
    {
      "epoch": 0.8523203919331566,
      "eval_bleu": 21.06003697632755,
      "eval_gen_len": 28.986,
      "eval_loss": 2.942582845687866,
      "eval_runtime": 60.1003,
      "eval_samples_per_second": 16.639,
      "eval_steps_per_second": 1.048,
      "step": 12700
    },
    {
      "epoch": 0.8529915103520016,
      "grad_norm": 0.741191029548645,
      "learning_rate": 0.00016796123435740493,
      "loss": 2.5745,
      "step": 12710
    },
    {
      "epoch": 0.8536626287708466,
      "grad_norm": 0.6641952395439148,
      "learning_rate": 0.0001679080677813426,
      "loss": 2.5097,
      "step": 12720
    },
    {
      "epoch": 0.8543337471896916,
      "grad_norm": 0.683497965335846,
      "learning_rate": 0.00016785486555831843,
      "loss": 2.5027,
      "step": 12730
    },
    {
      "epoch": 0.8550048656085366,
      "grad_norm": 0.6752790212631226,
      "learning_rate": 0.00016780162771625986,
      "loss": 2.4952,
      "step": 12740
    },
    {
      "epoch": 0.8556759840273817,
      "grad_norm": 0.666836678981781,
      "learning_rate": 0.00016774835428311305,
      "loss": 2.5737,
      "step": 12750
    },
    {
      "epoch": 0.8556759840273817,
      "eval_bleu": 21.009723789391696,
      "eval_gen_len": 28.944,
      "eval_loss": 2.9438564777374268,
      "eval_runtime": 59.0719,
      "eval_samples_per_second": 16.929,
      "eval_steps_per_second": 1.066,
      "step": 12750
    },
    {
      "epoch": 0.8563471024462266,
      "grad_norm": 0.622226357460022,
      "learning_rate": 0.00016769504528684276,
      "loss": 2.5413,
      "step": 12760
    },
    {
      "epoch": 0.8570182208650716,
      "grad_norm": 0.6901332139968872,
      "learning_rate": 0.00016764170075543247,
      "loss": 2.561,
      "step": 12770
    },
    {
      "epoch": 0.8576893392839167,
      "grad_norm": 0.7319225072860718,
      "learning_rate": 0.00016758832071688432,
      "loss": 2.5235,
      "step": 12780
    },
    {
      "epoch": 0.8583604577027617,
      "grad_norm": 0.7329808473587036,
      "learning_rate": 0.00016753490519921907,
      "loss": 2.4767,
      "step": 12790
    },
    {
      "epoch": 0.8590315761216066,
      "grad_norm": 0.6754375100135803,
      "learning_rate": 0.00016748145423047615,
      "loss": 2.5525,
      "step": 12800
    },
    {
      "epoch": 0.8590315761216066,
      "eval_bleu": 21.130200546556395,
      "eval_gen_len": 29.189,
      "eval_loss": 2.9426462650299072,
      "eval_runtime": 62.4334,
      "eval_samples_per_second": 16.017,
      "eval_steps_per_second": 1.009,
      "step": 12800
    },
    {
      "epoch": 0.8597026945404517,
      "grad_norm": 0.6666945815086365,
      "learning_rate": 0.00016742796783871352,
      "loss": 2.5346,
      "step": 12810
    },
    {
      "epoch": 0.8603738129592967,
      "grad_norm": 0.6946540474891663,
      "learning_rate": 0.00016737444605200778,
      "loss": 2.5037,
      "step": 12820
    },
    {
      "epoch": 0.8610449313781416,
      "grad_norm": 0.7280264496803284,
      "learning_rate": 0.00016732088889845416,
      "loss": 2.5597,
      "step": 12830
    },
    {
      "epoch": 0.8617160497969867,
      "grad_norm": 0.7335625290870667,
      "learning_rate": 0.0001672672964061663,
      "loss": 2.5604,
      "step": 12840
    },
    {
      "epoch": 0.8623871682158317,
      "grad_norm": 0.687792181968689,
      "learning_rate": 0.00016721366860327657,
      "loss": 2.5458,
      "step": 12850
    },
    {
      "epoch": 0.8623871682158317,
      "eval_bleu": 21.23798131687061,
      "eval_gen_len": 28.962,
      "eval_loss": 2.938779830932617,
      "eval_runtime": 58.9946,
      "eval_samples_per_second": 16.951,
      "eval_steps_per_second": 1.068,
      "step": 12850
    },
    {
      "epoch": 0.8630582866346767,
      "grad_norm": 0.6770226359367371,
      "learning_rate": 0.00016716000551793576,
      "loss": 2.5403,
      "step": 12860
    },
    {
      "epoch": 0.8637294050535217,
      "grad_norm": 0.7196308374404907,
      "learning_rate": 0.00016710630717831323,
      "loss": 2.5232,
      "step": 12870
    },
    {
      "epoch": 0.8644005234723667,
      "grad_norm": 0.6929464936256409,
      "learning_rate": 0.00016705257361259682,
      "loss": 2.5442,
      "step": 12880
    },
    {
      "epoch": 0.8650716418912117,
      "grad_norm": 0.7028316259384155,
      "learning_rate": 0.00016699880484899294,
      "loss": 2.5275,
      "step": 12890
    },
    {
      "epoch": 0.8657427603100567,
      "grad_norm": 0.7087201476097107,
      "learning_rate": 0.00016694500091572634,
      "loss": 2.6142,
      "step": 12900
    },
    {
      "epoch": 0.8657427603100567,
      "eval_bleu": 20.63461632384156,
      "eval_gen_len": 28.902,
      "eval_loss": 2.946261405944824,
      "eval_runtime": 58.7658,
      "eval_samples_per_second": 17.017,
      "eval_steps_per_second": 1.072,
      "step": 12900
    },
    {
      "epoch": 0.8664138787289017,
      "grad_norm": 0.7124201059341431,
      "learning_rate": 0.0001668911618410403,
      "loss": 2.5071,
      "step": 12910
    },
    {
      "epoch": 0.8670849971477467,
      "grad_norm": 0.7053448557853699,
      "learning_rate": 0.00016683728765319657,
      "loss": 2.5227,
      "step": 12920
    },
    {
      "epoch": 0.8677561155665917,
      "grad_norm": 0.7100698351860046,
      "learning_rate": 0.00016678337838047533,
      "loss": 2.6081,
      "step": 12930
    },
    {
      "epoch": 0.8684272339854368,
      "grad_norm": 0.6787061095237732,
      "learning_rate": 0.00016672943405117514,
      "loss": 2.5402,
      "step": 12940
    },
    {
      "epoch": 0.8690983524042817,
      "grad_norm": 0.7239281535148621,
      "learning_rate": 0.00016667545469361297,
      "loss": 2.5499,
      "step": 12950
    },
    {
      "epoch": 0.8690983524042817,
      "eval_bleu": 20.701573947732676,
      "eval_gen_len": 29.174,
      "eval_loss": 2.9459760189056396,
      "eval_runtime": 61.5971,
      "eval_samples_per_second": 16.235,
      "eval_steps_per_second": 1.023,
      "step": 12950
    },
    {
      "epoch": 0.8697694708231267,
      "grad_norm": 0.7451655864715576,
      "learning_rate": 0.0001666214403361242,
      "loss": 2.6177,
      "step": 12960
    },
    {
      "epoch": 0.8704405892419718,
      "grad_norm": 0.691570520401001,
      "learning_rate": 0.0001665673910070626,
      "loss": 2.5173,
      "step": 12970
    },
    {
      "epoch": 0.8711117076608168,
      "grad_norm": 0.7241866588592529,
      "learning_rate": 0.00016651330673480018,
      "loss": 2.5851,
      "step": 12980
    },
    {
      "epoch": 0.8717828260796617,
      "grad_norm": 0.6278634071350098,
      "learning_rate": 0.0001664591875477275,
      "loss": 2.5405,
      "step": 12990
    },
    {
      "epoch": 0.8724539444985068,
      "grad_norm": 0.6202264428138733,
      "learning_rate": 0.00016640503347425324,
      "loss": 2.5659,
      "step": 13000
    },
    {
      "epoch": 0.8724539444985068,
      "eval_bleu": 20.903360348474454,
      "eval_gen_len": 29.037,
      "eval_loss": 2.9490163326263428,
      "eval_runtime": 61.9504,
      "eval_samples_per_second": 16.142,
      "eval_steps_per_second": 1.017,
      "step": 13000
    },
    {
      "epoch": 0.8731250629173518,
      "grad_norm": 0.7416893243789673,
      "learning_rate": 0.00016635084454280448,
      "loss": 2.5436,
      "step": 13010
    },
    {
      "epoch": 0.8737961813361967,
      "grad_norm": 0.7450571656227112,
      "learning_rate": 0.0001662966207818267,
      "loss": 2.5086,
      "step": 13020
    },
    {
      "epoch": 0.8744672997550418,
      "grad_norm": 0.7629091739654541,
      "learning_rate": 0.00016624236221978348,
      "loss": 2.5132,
      "step": 13030
    },
    {
      "epoch": 0.8751384181738868,
      "grad_norm": 0.72730952501297,
      "learning_rate": 0.0001661880688851567,
      "loss": 2.5182,
      "step": 13040
    },
    {
      "epoch": 0.8758095365927318,
      "grad_norm": 0.7544692158699036,
      "learning_rate": 0.00016613374080644668,
      "loss": 2.5098,
      "step": 13050
    },
    {
      "epoch": 0.8758095365927318,
      "eval_bleu": 20.454371871542183,
      "eval_gen_len": 29.101,
      "eval_loss": 2.944272041320801,
      "eval_runtime": 62.3635,
      "eval_samples_per_second": 16.035,
      "eval_steps_per_second": 1.01,
      "step": 13050
    },
    {
      "epoch": 0.8764806550115768,
      "grad_norm": 0.6973986029624939,
      "learning_rate": 0.00016607937801217172,
      "loss": 2.5169,
      "step": 13060
    },
    {
      "epoch": 0.8771517734304218,
      "grad_norm": 0.728855550289154,
      "learning_rate": 0.00016602498053086854,
      "loss": 2.5374,
      "step": 13070
    },
    {
      "epoch": 0.8778228918492668,
      "grad_norm": 0.7478200793266296,
      "learning_rate": 0.00016597054839109196,
      "loss": 2.5847,
      "step": 13080
    },
    {
      "epoch": 0.8784940102681118,
      "grad_norm": 0.7312617301940918,
      "learning_rate": 0.00016591608162141503,
      "loss": 2.5571,
      "step": 13090
    },
    {
      "epoch": 0.8791651286869568,
      "grad_norm": 0.7138590216636658,
      "learning_rate": 0.000165861580250429,
      "loss": 2.4923,
      "step": 13100
    },
    {
      "epoch": 0.8791651286869568,
      "eval_bleu": 20.423307504975703,
      "eval_gen_len": 28.898,
      "eval_loss": 2.946214437484741,
      "eval_runtime": 59.0233,
      "eval_samples_per_second": 16.942,
      "eval_steps_per_second": 1.067,
      "step": 13100
    },
    {
      "epoch": 0.8798362471058018,
      "grad_norm": 0.724503219127655,
      "learning_rate": 0.00016580704430674322,
      "loss": 2.5464,
      "step": 13110
    },
    {
      "epoch": 0.8805073655246468,
      "grad_norm": 0.6450487971305847,
      "learning_rate": 0.00016575247381898524,
      "loss": 2.4716,
      "step": 13120
    },
    {
      "epoch": 0.8811784839434919,
      "grad_norm": 0.7152171730995178,
      "learning_rate": 0.00016569786881580077,
      "loss": 2.5628,
      "step": 13130
    },
    {
      "epoch": 0.8818496023623368,
      "grad_norm": 0.6833230257034302,
      "learning_rate": 0.0001656432293258535,
      "loss": 2.5369,
      "step": 13140
    },
    {
      "epoch": 0.8825207207811818,
      "grad_norm": 0.7027158141136169,
      "learning_rate": 0.00016558855537782545,
      "loss": 2.5381,
      "step": 13150
    },
    {
      "epoch": 0.8825207207811818,
      "eval_bleu": 20.663310190916228,
      "eval_gen_len": 29.159,
      "eval_loss": 2.9482009410858154,
      "eval_runtime": 61.8717,
      "eval_samples_per_second": 16.162,
      "eval_steps_per_second": 1.018,
      "step": 13150
    },
    {
      "epoch": 0.8831918392000269,
      "grad_norm": 0.6504112482070923,
      "learning_rate": 0.0001655338470004165,
      "loss": 2.4739,
      "step": 13160
    },
    {
      "epoch": 0.8838629576188719,
      "grad_norm": 0.7595437169075012,
      "learning_rate": 0.00016547910422234474,
      "loss": 2.5625,
      "step": 13170
    },
    {
      "epoch": 0.8845340760377168,
      "grad_norm": 0.7141870856285095,
      "learning_rate": 0.0001654243270723463,
      "loss": 2.5245,
      "step": 13180
    },
    {
      "epoch": 0.8852051944565619,
      "grad_norm": 0.6474687457084656,
      "learning_rate": 0.00016536951557917528,
      "loss": 2.544,
      "step": 13190
    },
    {
      "epoch": 0.8858763128754069,
      "grad_norm": 0.6906260251998901,
      "learning_rate": 0.00016531466977160394,
      "loss": 2.5287,
      "step": 13200
    },
    {
      "epoch": 0.8858763128754069,
      "eval_bleu": 21.081519659866125,
      "eval_gen_len": 28.874,
      "eval_loss": 2.9513471126556396,
      "eval_runtime": 59.1813,
      "eval_samples_per_second": 16.897,
      "eval_steps_per_second": 1.065,
      "step": 13200
    },
    {
      "epoch": 0.8865474312942518,
      "grad_norm": 0.7165260314941406,
      "learning_rate": 0.00016525978967842238,
      "loss": 2.5275,
      "step": 13210
    },
    {
      "epoch": 0.8872185497130969,
      "grad_norm": 0.6674185395240784,
      "learning_rate": 0.00016520487532843884,
      "loss": 2.4957,
      "step": 13220
    },
    {
      "epoch": 0.8878896681319419,
      "grad_norm": 0.7095386981964111,
      "learning_rate": 0.00016514992675047949,
      "loss": 2.5004,
      "step": 13230
    },
    {
      "epoch": 0.8885607865507869,
      "grad_norm": 0.7119724750518799,
      "learning_rate": 0.00016509494397338846,
      "loss": 2.5731,
      "step": 13240
    },
    {
      "epoch": 0.8892319049696319,
      "grad_norm": 0.6980023980140686,
      "learning_rate": 0.0001650399270260279,
      "loss": 2.5465,
      "step": 13250
    },
    {
      "epoch": 0.8892319049696319,
      "eval_bleu": 20.739713977976542,
      "eval_gen_len": 28.973,
      "eval_loss": 2.948546886444092,
      "eval_runtime": 62.1563,
      "eval_samples_per_second": 16.088,
      "eval_steps_per_second": 1.014,
      "step": 13250
    },
    {
      "epoch": 0.8899030233884769,
      "grad_norm": 0.748548150062561,
      "learning_rate": 0.00016498487593727773,
      "loss": 2.5285,
      "step": 13260
    },
    {
      "epoch": 0.8905741418073219,
      "grad_norm": 0.7744008898735046,
      "learning_rate": 0.000164929790736036,
      "loss": 2.5926,
      "step": 13270
    },
    {
      "epoch": 0.8912452602261669,
      "grad_norm": 0.7008325457572937,
      "learning_rate": 0.0001648746714512185,
      "loss": 2.484,
      "step": 13280
    },
    {
      "epoch": 0.8919163786450119,
      "grad_norm": 0.6751188635826111,
      "learning_rate": 0.00016481951811175906,
      "loss": 2.4803,
      "step": 13290
    },
    {
      "epoch": 0.8925874970638569,
      "grad_norm": 0.6765577793121338,
      "learning_rate": 0.00016476433074660922,
      "loss": 2.5231,
      "step": 13300
    },
    {
      "epoch": 0.8925874970638569,
      "eval_bleu": 21.031333473872404,
      "eval_gen_len": 29.105,
      "eval_loss": 2.946045398712158,
      "eval_runtime": 61.7682,
      "eval_samples_per_second": 16.19,
      "eval_steps_per_second": 1.02,
      "step": 13300
    },
    {
      "epoch": 0.8932586154827019,
      "grad_norm": 0.7404818534851074,
      "learning_rate": 0.00016470910938473852,
      "loss": 2.516,
      "step": 13310
    },
    {
      "epoch": 0.893929733901547,
      "grad_norm": 0.7279889583587646,
      "learning_rate": 0.0001646538540551343,
      "loss": 2.5602,
      "step": 13320
    },
    {
      "epoch": 0.8946008523203919,
      "grad_norm": 0.6551169157028198,
      "learning_rate": 0.00016459856478680168,
      "loss": 2.5137,
      "step": 13330
    },
    {
      "epoch": 0.8952719707392369,
      "grad_norm": 0.6413667798042297,
      "learning_rate": 0.00016454324160876364,
      "loss": 2.5733,
      "step": 13340
    },
    {
      "epoch": 0.895943089158082,
      "grad_norm": 0.6723196506500244,
      "learning_rate": 0.000164487884550061,
      "loss": 2.6105,
      "step": 13350
    },
    {
      "epoch": 0.895943089158082,
      "eval_bleu": 20.948802504123375,
      "eval_gen_len": 28.851,
      "eval_loss": 2.943316698074341,
      "eval_runtime": 59.363,
      "eval_samples_per_second": 16.846,
      "eval_steps_per_second": 1.061,
      "step": 13350
    },
    {
      "epoch": 0.896614207576927,
      "grad_norm": 0.7011889219284058,
      "learning_rate": 0.0001644324936397523,
      "loss": 2.5087,
      "step": 13360
    },
    {
      "epoch": 0.8972853259957719,
      "grad_norm": 0.6974877119064331,
      "learning_rate": 0.00016437706890691387,
      "loss": 2.4936,
      "step": 13370
    },
    {
      "epoch": 0.897956444414617,
      "grad_norm": 0.7055418491363525,
      "learning_rate": 0.00016432161038063985,
      "loss": 2.5613,
      "step": 13380
    },
    {
      "epoch": 0.898627562833462,
      "grad_norm": 0.7364673614501953,
      "learning_rate": 0.00016426611809004197,
      "loss": 2.5786,
      "step": 13390
    },
    {
      "epoch": 0.8992986812523069,
      "grad_norm": 0.6924917697906494,
      "learning_rate": 0.00016421059206424987,
      "loss": 2.5092,
      "step": 13400
    },
    {
      "epoch": 0.8992986812523069,
      "eval_bleu": 20.86860927777151,
      "eval_gen_len": 28.885,
      "eval_loss": 2.9434149265289307,
      "eval_runtime": 58.6147,
      "eval_samples_per_second": 17.061,
      "eval_steps_per_second": 1.075,
      "step": 13400
    },
    {
      "epoch": 0.899969799671152,
      "grad_norm": 0.7672932147979736,
      "learning_rate": 0.00016415503233241076,
      "loss": 2.5188,
      "step": 13410
    },
    {
      "epoch": 0.900640918089997,
      "grad_norm": 0.6467047929763794,
      "learning_rate": 0.00016409943892368962,
      "loss": 2.5265,
      "step": 13420
    },
    {
      "epoch": 0.901312036508842,
      "grad_norm": 0.734917938709259,
      "learning_rate": 0.00016404381186726908,
      "loss": 2.5343,
      "step": 13430
    },
    {
      "epoch": 0.901983154927687,
      "grad_norm": 0.731179416179657,
      "learning_rate": 0.00016398815119234941,
      "loss": 2.5362,
      "step": 13440
    },
    {
      "epoch": 0.902654273346532,
      "grad_norm": 0.7042742967605591,
      "learning_rate": 0.00016393245692814857,
      "loss": 2.5081,
      "step": 13450
    },
    {
      "epoch": 0.902654273346532,
      "eval_bleu": 21.092237515982443,
      "eval_gen_len": 28.811,
      "eval_loss": 2.9423274993896484,
      "eval_runtime": 58.9781,
      "eval_samples_per_second": 16.955,
      "eval_steps_per_second": 1.068,
      "step": 13450
    },
    {
      "epoch": 0.903325391765377,
      "grad_norm": 0.7067385911941528,
      "learning_rate": 0.00016387672910390212,
      "loss": 2.4822,
      "step": 13460
    },
    {
      "epoch": 0.903996510184222,
      "grad_norm": 0.7515788674354553,
      "learning_rate": 0.0001638209677488633,
      "loss": 2.5737,
      "step": 13470
    },
    {
      "epoch": 0.904667628603067,
      "grad_norm": 0.6708040833473206,
      "learning_rate": 0.0001637651728923028,
      "loss": 2.5412,
      "step": 13480
    },
    {
      "epoch": 0.905338747021912,
      "grad_norm": 0.6945619583129883,
      "learning_rate": 0.00016370934456350913,
      "loss": 2.5725,
      "step": 13490
    },
    {
      "epoch": 0.906009865440757,
      "grad_norm": 0.801564633846283,
      "learning_rate": 0.00016365348279178812,
      "loss": 2.5898,
      "step": 13500
    },
    {
      "epoch": 0.906009865440757,
      "eval_bleu": 21.26904872501033,
      "eval_gen_len": 28.936,
      "eval_loss": 2.9421274662017822,
      "eval_runtime": 58.8215,
      "eval_samples_per_second": 17.001,
      "eval_steps_per_second": 1.071,
      "step": 13500
    },
    {
      "epoch": 0.906680983859602,
      "grad_norm": 0.6615591049194336,
      "learning_rate": 0.00016359758760646335,
      "loss": 2.5315,
      "step": 13510
    },
    {
      "epoch": 0.907352102278447,
      "grad_norm": 0.7285473942756653,
      "learning_rate": 0.0001635416590368758,
      "loss": 2.518,
      "step": 13520
    },
    {
      "epoch": 0.908023220697292,
      "grad_norm": 0.6729462146759033,
      "learning_rate": 0.00016348569711238412,
      "loss": 2.5851,
      "step": 13530
    },
    {
      "epoch": 0.9086943391161371,
      "grad_norm": 0.7326106429100037,
      "learning_rate": 0.0001634297018623643,
      "loss": 2.514,
      "step": 13540
    },
    {
      "epoch": 0.9093654575349821,
      "grad_norm": 0.6659019589424133,
      "learning_rate": 0.00016337367331620997,
      "loss": 2.5173,
      "step": 13550
    },
    {
      "epoch": 0.9093654575349821,
      "eval_bleu": 21.054109363058778,
      "eval_gen_len": 28.897,
      "eval_loss": 2.948059320449829,
      "eval_runtime": 59.0549,
      "eval_samples_per_second": 16.933,
      "eval_steps_per_second": 1.067,
      "step": 13550
    },
    {
      "epoch": 0.910036575953827,
      "grad_norm": 0.6782572865486145,
      "learning_rate": 0.00016331761150333214,
      "loss": 2.5471,
      "step": 13560
    },
    {
      "epoch": 0.9107076943726721,
      "grad_norm": 0.6942088007926941,
      "learning_rate": 0.00016326151645315934,
      "loss": 2.5025,
      "step": 13570
    },
    {
      "epoch": 0.9113788127915171,
      "grad_norm": 0.7752900719642639,
      "learning_rate": 0.00016320538819513753,
      "loss": 2.6148,
      "step": 13580
    },
    {
      "epoch": 0.912049931210362,
      "grad_norm": 0.7082003355026245,
      "learning_rate": 0.0001631492267587301,
      "loss": 2.5188,
      "step": 13590
    },
    {
      "epoch": 0.9127210496292071,
      "grad_norm": 0.7480839490890503,
      "learning_rate": 0.00016309303217341788,
      "loss": 2.5351,
      "step": 13600
    },
    {
      "epoch": 0.9127210496292071,
      "eval_bleu": 20.528118245772607,
      "eval_gen_len": 29.073,
      "eval_loss": 2.9455580711364746,
      "eval_runtime": 62.2867,
      "eval_samples_per_second": 16.055,
      "eval_steps_per_second": 1.011,
      "step": 13600
    },
    {
      "epoch": 0.9133921680480521,
      "grad_norm": 0.6495299935340881,
      "learning_rate": 0.000163036804468699,
      "loss": 2.5298,
      "step": 13610
    },
    {
      "epoch": 0.914063286466897,
      "grad_norm": 0.6708548069000244,
      "learning_rate": 0.00016298054367408908,
      "loss": 2.5101,
      "step": 13620
    },
    {
      "epoch": 0.9147344048857421,
      "grad_norm": 0.6414597034454346,
      "learning_rate": 0.00016292424981912115,
      "loss": 2.5409,
      "step": 13630
    },
    {
      "epoch": 0.9154055233045871,
      "grad_norm": 0.708324134349823,
      "learning_rate": 0.00016286792293334544,
      "loss": 2.4775,
      "step": 13640
    },
    {
      "epoch": 0.9160766417234321,
      "grad_norm": 0.6595095992088318,
      "learning_rate": 0.0001628115630463297,
      "loss": 2.5139,
      "step": 13650
    },
    {
      "epoch": 0.9160766417234321,
      "eval_bleu": 20.629524763321434,
      "eval_gen_len": 28.824,
      "eval_loss": 2.9437808990478516,
      "eval_runtime": 59.2331,
      "eval_samples_per_second": 16.882,
      "eval_steps_per_second": 1.064,
      "step": 13650
    },
    {
      "epoch": 0.9167477601422771,
      "grad_norm": 0.7091180086135864,
      "learning_rate": 0.0001627551701876588,
      "loss": 2.546,
      "step": 13660
    },
    {
      "epoch": 0.9174188785611221,
      "grad_norm": 0.680827260017395,
      "learning_rate": 0.00016269874438693514,
      "loss": 2.4954,
      "step": 13670
    },
    {
      "epoch": 0.9180899969799671,
      "grad_norm": 0.7657648324966431,
      "learning_rate": 0.00016264228567377818,
      "loss": 2.4998,
      "step": 13680
    },
    {
      "epoch": 0.9187611153988121,
      "grad_norm": 0.6867204904556274,
      "learning_rate": 0.00016258579407782487,
      "loss": 2.4983,
      "step": 13690
    },
    {
      "epoch": 0.9194322338176572,
      "grad_norm": 0.6919980049133301,
      "learning_rate": 0.00016252926962872924,
      "loss": 2.5344,
      "step": 13700
    },
    {
      "epoch": 0.9194322338176572,
      "eval_bleu": 21.05115795763171,
      "eval_gen_len": 28.911,
      "eval_loss": 2.942711353302002,
      "eval_runtime": 59.5136,
      "eval_samples_per_second": 16.803,
      "eval_steps_per_second": 1.059,
      "step": 13700
    },
    {
      "epoch": 0.9201033522365021,
      "grad_norm": 0.603471577167511,
      "learning_rate": 0.00016247271235616276,
      "loss": 2.5097,
      "step": 13710
    },
    {
      "epoch": 0.9207744706553471,
      "grad_norm": 0.6489086747169495,
      "learning_rate": 0.0001624161222898139,
      "loss": 2.5823,
      "step": 13720
    },
    {
      "epoch": 0.9214455890741922,
      "grad_norm": 0.6842382550239563,
      "learning_rate": 0.0001623594994593886,
      "loss": 2.5041,
      "step": 13730
    },
    {
      "epoch": 0.9221167074930371,
      "grad_norm": 0.7338286638259888,
      "learning_rate": 0.00016230284389460976,
      "loss": 2.5336,
      "step": 13740
    },
    {
      "epoch": 0.9227878259118821,
      "grad_norm": 0.7427623271942139,
      "learning_rate": 0.00016224615562521763,
      "loss": 2.5082,
      "step": 13750
    },
    {
      "epoch": 0.9227878259118821,
      "eval_bleu": 20.752403822506825,
      "eval_gen_len": 28.739,
      "eval_loss": 2.9477312564849854,
      "eval_runtime": 58.9265,
      "eval_samples_per_second": 16.97,
      "eval_steps_per_second": 1.069,
      "step": 13750
    },
    {
      "epoch": 0.9234589443307272,
      "grad_norm": 0.7120288610458374,
      "learning_rate": 0.00016218943468096952,
      "loss": 2.5934,
      "step": 13760
    },
    {
      "epoch": 0.9241300627495722,
      "grad_norm": 0.6705505847930908,
      "learning_rate": 0.00016213268109163998,
      "loss": 2.5477,
      "step": 13770
    },
    {
      "epoch": 0.9248011811684171,
      "grad_norm": 0.6941132545471191,
      "learning_rate": 0.00016207589488702063,
      "loss": 2.506,
      "step": 13780
    },
    {
      "epoch": 0.9254722995872622,
      "grad_norm": 0.6958239674568176,
      "learning_rate": 0.00016201907609692022,
      "loss": 2.518,
      "step": 13790
    },
    {
      "epoch": 0.9261434180061072,
      "grad_norm": 0.6886225342750549,
      "learning_rate": 0.00016196222475116465,
      "loss": 2.5127,
      "step": 13800
    },
    {
      "epoch": 0.9261434180061072,
      "eval_bleu": 20.646689552082325,
      "eval_gen_len": 29.108,
      "eval_loss": 2.942197799682617,
      "eval_runtime": 63.0429,
      "eval_samples_per_second": 15.862,
      "eval_steps_per_second": 0.999,
      "step": 13800
    },
    {
      "epoch": 0.9268145364249522,
      "grad_norm": 0.7484258413314819,
      "learning_rate": 0.00016190534087959688,
      "loss": 2.502,
      "step": 13810
    },
    {
      "epoch": 0.9274856548437972,
      "grad_norm": 0.6462398767471313,
      "learning_rate": 0.00016184842451207697,
      "loss": 2.5255,
      "step": 13820
    },
    {
      "epoch": 0.9281567732626422,
      "grad_norm": 0.7071403861045837,
      "learning_rate": 0.00016179147567848192,
      "loss": 2.5921,
      "step": 13830
    },
    {
      "epoch": 0.9288278916814872,
      "grad_norm": 0.6976171135902405,
      "learning_rate": 0.00016173449440870594,
      "loss": 2.5612,
      "step": 13840
    },
    {
      "epoch": 0.9294990101003322,
      "grad_norm": 0.6550087332725525,
      "learning_rate": 0.00016167748073266016,
      "loss": 2.5124,
      "step": 13850
    },
    {
      "epoch": 0.9294990101003322,
      "eval_bleu": 20.92651891350053,
      "eval_gen_len": 28.832,
      "eval_loss": 2.9429919719696045,
      "eval_runtime": 58.9144,
      "eval_samples_per_second": 16.974,
      "eval_steps_per_second": 1.069,
      "step": 13850
    },
    {
      "epoch": 0.9301701285191772,
      "grad_norm": 0.6686171293258667,
      "learning_rate": 0.0001616204346802728,
      "loss": 2.5799,
      "step": 13860
    },
    {
      "epoch": 0.9308412469380222,
      "grad_norm": 0.716977059841156,
      "learning_rate": 0.00016156335628148897,
      "loss": 2.5193,
      "step": 13870
    },
    {
      "epoch": 0.9315123653568672,
      "grad_norm": 0.6733264923095703,
      "learning_rate": 0.00016150624556627086,
      "loss": 2.5422,
      "step": 13880
    },
    {
      "epoch": 0.9321834837757123,
      "grad_norm": 0.7445803284645081,
      "learning_rate": 0.00016144910256459753,
      "loss": 2.4953,
      "step": 13890
    },
    {
      "epoch": 0.9328546021945572,
      "grad_norm": 0.7183336615562439,
      "learning_rate": 0.00016139192730646508,
      "loss": 2.5112,
      "step": 13900
    },
    {
      "epoch": 0.9328546021945572,
      "eval_bleu": 20.959900710424762,
      "eval_gen_len": 28.863,
      "eval_loss": 2.946476459503174,
      "eval_runtime": 59.2512,
      "eval_samples_per_second": 16.877,
      "eval_steps_per_second": 1.063,
      "step": 13900
    },
    {
      "epoch": 0.9335257206134022,
      "grad_norm": 0.6693708896636963,
      "learning_rate": 0.0001613347198218865,
      "loss": 2.5366,
      "step": 13910
    },
    {
      "epoch": 0.9341968390322473,
      "grad_norm": 0.6933098435401917,
      "learning_rate": 0.00016127748014089165,
      "loss": 2.4992,
      "step": 13920
    },
    {
      "epoch": 0.9348679574510922,
      "grad_norm": 0.6480895280838013,
      "learning_rate": 0.00016122020829352742,
      "loss": 2.5855,
      "step": 13930
    },
    {
      "epoch": 0.9355390758699372,
      "grad_norm": 0.6557377576828003,
      "learning_rate": 0.00016116290430985742,
      "loss": 2.6109,
      "step": 13940
    },
    {
      "epoch": 0.9362101942887823,
      "grad_norm": 0.7280328869819641,
      "learning_rate": 0.0001611055682199623,
      "loss": 2.5145,
      "step": 13950
    },
    {
      "epoch": 0.9362101942887823,
      "eval_bleu": 21.329237353797602,
      "eval_gen_len": 29.013,
      "eval_loss": 2.9374032020568848,
      "eval_runtime": 59.6542,
      "eval_samples_per_second": 16.763,
      "eval_steps_per_second": 1.056,
      "step": 13950
    },
    {
      "epoch": 0.9368813127076273,
      "grad_norm": 0.639963686466217,
      "learning_rate": 0.0001610482000539394,
      "loss": 2.5428,
      "step": 13960
    },
    {
      "epoch": 0.9375524311264722,
      "grad_norm": 0.6599290370941162,
      "learning_rate": 0.00016099079984190298,
      "loss": 2.5559,
      "step": 13970
    },
    {
      "epoch": 0.9382235495453173,
      "grad_norm": 0.6446126699447632,
      "learning_rate": 0.00016093336761398421,
      "loss": 2.5891,
      "step": 13980
    },
    {
      "epoch": 0.9388946679641623,
      "grad_norm": 0.724144697189331,
      "learning_rate": 0.00016087590340033085,
      "loss": 2.5444,
      "step": 13990
    },
    {
      "epoch": 0.9395657863830073,
      "grad_norm": 0.7126310467720032,
      "learning_rate": 0.00016081840723110763,
      "loss": 2.5169,
      "step": 14000
    },
    {
      "epoch": 0.9395657863830073,
      "eval_bleu": 20.89633154918863,
      "eval_gen_len": 28.889,
      "eval_loss": 2.945608615875244,
      "eval_runtime": 59.4479,
      "eval_samples_per_second": 16.821,
      "eval_steps_per_second": 1.06,
      "step": 14000
    },
    {
      "epoch": 0.9402369048018523,
      "grad_norm": 0.6681027412414551,
      "learning_rate": 0.00016076087913649602,
      "loss": 2.5114,
      "step": 14010
    },
    {
      "epoch": 0.9409080232206973,
      "grad_norm": 0.6546433568000793,
      "learning_rate": 0.00016070331914669418,
      "loss": 2.5159,
      "step": 14020
    },
    {
      "epoch": 0.9415791416395423,
      "grad_norm": 0.6520863175392151,
      "learning_rate": 0.00016064572729191707,
      "loss": 2.5704,
      "step": 14030
    },
    {
      "epoch": 0.9422502600583873,
      "grad_norm": 0.691845178604126,
      "learning_rate": 0.00016058810360239638,
      "loss": 2.4985,
      "step": 14040
    },
    {
      "epoch": 0.9429213784772323,
      "grad_norm": 0.7555446028709412,
      "learning_rate": 0.00016053044810838046,
      "loss": 2.4868,
      "step": 14050
    },
    {
      "epoch": 0.9429213784772323,
      "eval_bleu": 21.304468434954835,
      "eval_gen_len": 29.314,
      "eval_loss": 2.9374356269836426,
      "eval_runtime": 63.2069,
      "eval_samples_per_second": 15.821,
      "eval_steps_per_second": 0.997,
      "step": 14050
    },
    {
      "epoch": 0.9435924968960773,
      "grad_norm": 0.6928693056106567,
      "learning_rate": 0.00016047276084013446,
      "loss": 2.4966,
      "step": 14060
    },
    {
      "epoch": 0.9442636153149223,
      "grad_norm": 0.6883327960968018,
      "learning_rate": 0.00016041504182794008,
      "loss": 2.5187,
      "step": 14070
    },
    {
      "epoch": 0.9449347337337674,
      "grad_norm": 0.6858718395233154,
      "learning_rate": 0.00016035729110209577,
      "loss": 2.5715,
      "step": 14080
    },
    {
      "epoch": 0.9456058521526123,
      "grad_norm": 0.7015407681465149,
      "learning_rate": 0.0001602995086929166,
      "loss": 2.4689,
      "step": 14090
    },
    {
      "epoch": 0.9462769705714573,
      "grad_norm": 0.7427716255187988,
      "learning_rate": 0.00016024169463073424,
      "loss": 2.5726,
      "step": 14100
    },
    {
      "epoch": 0.9462769705714573,
      "eval_bleu": 21.149927804480814,
      "eval_gen_len": 28.989,
      "eval_loss": 2.944912910461426,
      "eval_runtime": 59.3742,
      "eval_samples_per_second": 16.842,
      "eval_steps_per_second": 1.061,
      "step": 14100
    },
    {
      "epoch": 0.9469480889903024,
      "grad_norm": 0.6834174394607544,
      "learning_rate": 0.00016018384894589705,
      "loss": 2.5661,
      "step": 14110
    },
    {
      "epoch": 0.9476192074091473,
      "grad_norm": 0.6760646104812622,
      "learning_rate": 0.00016012597166876992,
      "loss": 2.5285,
      "step": 14120
    },
    {
      "epoch": 0.9482903258279923,
      "grad_norm": 0.6651780009269714,
      "learning_rate": 0.00016006806282973442,
      "loss": 2.5805,
      "step": 14130
    },
    {
      "epoch": 0.9489614442468374,
      "grad_norm": 0.7096386551856995,
      "learning_rate": 0.00016001012245918852,
      "loss": 2.537,
      "step": 14140
    },
    {
      "epoch": 0.9496325626656824,
      "grad_norm": 0.6510050296783447,
      "learning_rate": 0.0001599521505875469,
      "loss": 2.5253,
      "step": 14150
    },
    {
      "epoch": 0.9496325626656824,
      "eval_bleu": 21.27527491666986,
      "eval_gen_len": 28.97,
      "eval_loss": 2.940579652786255,
      "eval_runtime": 59.1673,
      "eval_samples_per_second": 16.901,
      "eval_steps_per_second": 1.065,
      "step": 14150
    },
    {
      "epoch": 0.9503036810845273,
      "grad_norm": 0.6779153347015381,
      "learning_rate": 0.0001598941472452407,
      "loss": 2.5375,
      "step": 14160
    },
    {
      "epoch": 0.9509747995033724,
      "grad_norm": 0.7978318929672241,
      "learning_rate": 0.00015983611246271758,
      "loss": 2.5744,
      "step": 14170
    },
    {
      "epoch": 0.9516459179222174,
      "grad_norm": 0.8340082764625549,
      "learning_rate": 0.00015977804627044178,
      "loss": 2.5728,
      "step": 14180
    },
    {
      "epoch": 0.9523170363410624,
      "grad_norm": 0.7508862614631653,
      "learning_rate": 0.00015971994869889392,
      "loss": 2.6149,
      "step": 14190
    },
    {
      "epoch": 0.9529881547599074,
      "grad_norm": 0.7346110939979553,
      "learning_rate": 0.00015966181977857119,
      "loss": 2.6123,
      "step": 14200
    },
    {
      "epoch": 0.9529881547599074,
      "eval_bleu": 20.927800919309053,
      "eval_gen_len": 28.951,
      "eval_loss": 2.9508700370788574,
      "eval_runtime": 59.1385,
      "eval_samples_per_second": 16.909,
      "eval_steps_per_second": 1.065,
      "step": 14200
    },
    {
      "epoch": 0.9536592731787524,
      "grad_norm": 0.6662420630455017,
      "learning_rate": 0.00015960365953998707,
      "loss": 2.5204,
      "step": 14210
    },
    {
      "epoch": 0.9543303915975974,
      "grad_norm": 0.6880415081977844,
      "learning_rate": 0.00015954546801367174,
      "loss": 2.5178,
      "step": 14220
    },
    {
      "epoch": 0.9550015100164424,
      "grad_norm": 0.7043453454971313,
      "learning_rate": 0.00015948724523017158,
      "loss": 2.5489,
      "step": 14230
    },
    {
      "epoch": 0.9556726284352874,
      "grad_norm": 0.7218138575553894,
      "learning_rate": 0.00015942899122004946,
      "loss": 2.5216,
      "step": 14240
    },
    {
      "epoch": 0.9563437468541324,
      "grad_norm": 0.7241318225860596,
      "learning_rate": 0.00015937070601388466,
      "loss": 2.5034,
      "step": 14250
    },
    {
      "epoch": 0.9563437468541324,
      "eval_bleu": 20.942517588186696,
      "eval_gen_len": 28.889,
      "eval_loss": 2.944413900375366,
      "eval_runtime": 59.699,
      "eval_samples_per_second": 16.751,
      "eval_steps_per_second": 1.055,
      "step": 14250
    },
    {
      "epoch": 0.9570148652729774,
      "grad_norm": 0.7304214239120483,
      "learning_rate": 0.0001593123896422728,
      "loss": 2.5173,
      "step": 14260
    },
    {
      "epoch": 0.9576859836918225,
      "grad_norm": 0.7082661390304565,
      "learning_rate": 0.00015925404213582592,
      "loss": 2.4829,
      "step": 14270
    },
    {
      "epoch": 0.9583571021106674,
      "grad_norm": 0.7001875638961792,
      "learning_rate": 0.0001591956635251723,
      "loss": 2.545,
      "step": 14280
    },
    {
      "epoch": 0.9590282205295124,
      "grad_norm": 0.6729068756103516,
      "learning_rate": 0.00015913725384095667,
      "loss": 2.5309,
      "step": 14290
    },
    {
      "epoch": 0.9596993389483575,
      "grad_norm": 0.6326051354408264,
      "learning_rate": 0.00015907881311383993,
      "loss": 2.5089,
      "step": 14300
    },
    {
      "epoch": 0.9596993389483575,
      "eval_bleu": 20.966865568662932,
      "eval_gen_len": 29.055,
      "eval_loss": 2.947230339050293,
      "eval_runtime": 62.5815,
      "eval_samples_per_second": 15.979,
      "eval_steps_per_second": 1.007,
      "step": 14300
    },
    {
      "epoch": 0.9603704573672024,
      "grad_norm": 0.6495118737220764,
      "learning_rate": 0.00015902034137449942,
      "loss": 2.5049,
      "step": 14310
    },
    {
      "epoch": 0.9610415757860474,
      "grad_norm": 0.6378480792045593,
      "learning_rate": 0.00015896183865362864,
      "loss": 2.4948,
      "step": 14320
    },
    {
      "epoch": 0.9617126942048925,
      "grad_norm": 0.676444947719574,
      "learning_rate": 0.00015890330498193747,
      "loss": 2.5302,
      "step": 14330
    },
    {
      "epoch": 0.9623838126237375,
      "grad_norm": 0.6859634518623352,
      "learning_rate": 0.00015884474039015188,
      "loss": 2.5315,
      "step": 14340
    },
    {
      "epoch": 0.9630549310425824,
      "grad_norm": 0.6957220435142517,
      "learning_rate": 0.00015878614490901427,
      "loss": 2.5302,
      "step": 14350
    },
    {
      "epoch": 0.9630549310425824,
      "eval_bleu": 20.91426429574328,
      "eval_gen_len": 28.832,
      "eval_loss": 2.9463353157043457,
      "eval_runtime": 58.9958,
      "eval_samples_per_second": 16.95,
      "eval_steps_per_second": 1.068,
      "step": 14350
    },
    {
      "epoch": 0.9637260494614275,
      "grad_norm": 0.6535253524780273,
      "learning_rate": 0.0001587275185692831,
      "loss": 2.5399,
      "step": 14360
    },
    {
      "epoch": 0.9643971678802725,
      "grad_norm": 0.757047176361084,
      "learning_rate": 0.00015866886140173306,
      "loss": 2.5714,
      "step": 14370
    },
    {
      "epoch": 0.9650682862991175,
      "grad_norm": 0.7148892283439636,
      "learning_rate": 0.00015861017343715505,
      "loss": 2.502,
      "step": 14380
    },
    {
      "epoch": 0.9657394047179625,
      "grad_norm": 0.7397422194480896,
      "learning_rate": 0.0001585514547063561,
      "loss": 2.5796,
      "step": 14390
    },
    {
      "epoch": 0.9664105231368075,
      "grad_norm": 0.6441233158111572,
      "learning_rate": 0.00015849270524015952,
      "loss": 2.505,
      "step": 14400
    },
    {
      "epoch": 0.9664105231368075,
      "eval_bleu": 20.747074396982402,
      "eval_gen_len": 28.846,
      "eval_loss": 2.946922779083252,
      "eval_runtime": 59.483,
      "eval_samples_per_second": 16.812,
      "eval_steps_per_second": 1.059,
      "step": 14400
    },
    {
      "epoch": 0.9670816415556525,
      "grad_norm": 0.682407796382904,
      "learning_rate": 0.00015843392506940452,
      "loss": 2.5811,
      "step": 14410
    },
    {
      "epoch": 0.9677527599744975,
      "grad_norm": 0.6817023754119873,
      "learning_rate": 0.00015837511422494665,
      "loss": 2.4925,
      "step": 14420
    },
    {
      "epoch": 0.9684238783933425,
      "grad_norm": 0.671531617641449,
      "learning_rate": 0.0001583162727376574,
      "loss": 2.5062,
      "step": 14430
    },
    {
      "epoch": 0.9690949968121875,
      "grad_norm": 0.7315244674682617,
      "learning_rate": 0.00015825740063842448,
      "loss": 2.5401,
      "step": 14440
    },
    {
      "epoch": 0.9697661152310325,
      "grad_norm": 0.7468874454498291,
      "learning_rate": 0.00015819849795815154,
      "loss": 2.5369,
      "step": 14450
    },
    {
      "epoch": 0.9697661152310325,
      "eval_bleu": 20.640604563817323,
      "eval_gen_len": 28.758,
      "eval_loss": 2.9550607204437256,
      "eval_runtime": 59.4831,
      "eval_samples_per_second": 16.811,
      "eval_steps_per_second": 1.059,
      "step": 14450
    },
    {
      "epoch": 0.9704372336498776,
      "grad_norm": 0.7090259790420532,
      "learning_rate": 0.0001581395647277584,
      "loss": 2.5037,
      "step": 14460
    },
    {
      "epoch": 0.9711083520687225,
      "grad_norm": 0.6305365562438965,
      "learning_rate": 0.00015808060097818083,
      "loss": 2.5297,
      "step": 14470
    },
    {
      "epoch": 0.9717794704875675,
      "grad_norm": 0.6901201605796814,
      "learning_rate": 0.00015802160674037067,
      "loss": 2.5411,
      "step": 14480
    },
    {
      "epoch": 0.9724505889064126,
      "grad_norm": 0.7114307880401611,
      "learning_rate": 0.00015796258204529577,
      "loss": 2.5366,
      "step": 14490
    },
    {
      "epoch": 0.9731217073252575,
      "grad_norm": 0.6456625461578369,
      "learning_rate": 0.00015790352692393985,
      "loss": 2.5719,
      "step": 14500
    },
    {
      "epoch": 0.9731217073252575,
      "eval_bleu": 20.362334001170968,
      "eval_gen_len": 28.704,
      "eval_loss": 2.9501938819885254,
      "eval_runtime": 58.5571,
      "eval_samples_per_second": 17.077,
      "eval_steps_per_second": 1.076,
      "step": 14500
    },
    {
      "epoch": 0.9737928257441025,
      "grad_norm": 0.6344281435012817,
      "learning_rate": 0.00015784444140730283,
      "loss": 2.5067,
      "step": 14510
    },
    {
      "epoch": 0.9744639441629476,
      "grad_norm": 0.6632516384124756,
      "learning_rate": 0.00015778532552640034,
      "loss": 2.4806,
      "step": 14520
    },
    {
      "epoch": 0.9751350625817926,
      "grad_norm": 0.6870660781860352,
      "learning_rate": 0.00015772617931226413,
      "loss": 2.5316,
      "step": 14530
    },
    {
      "epoch": 0.9758061810006375,
      "grad_norm": 0.6557849645614624,
      "learning_rate": 0.0001576670027959418,
      "loss": 2.5037,
      "step": 14540
    },
    {
      "epoch": 0.9764772994194826,
      "grad_norm": 0.6666812896728516,
      "learning_rate": 0.0001576077960084968,
      "loss": 2.5248,
      "step": 14550
    },
    {
      "epoch": 0.9764772994194826,
      "eval_bleu": 20.73415865104872,
      "eval_gen_len": 28.657,
      "eval_loss": 2.9446585178375244,
      "eval_runtime": 58.696,
      "eval_samples_per_second": 17.037,
      "eval_steps_per_second": 1.073,
      "step": 14550
    },
    {
      "epoch": 0.9771484178383276,
      "grad_norm": 0.6785593628883362,
      "learning_rate": 0.00015754855898100862,
      "loss": 2.5352,
      "step": 14560
    },
    {
      "epoch": 0.9778195362571726,
      "grad_norm": 0.7529326677322388,
      "learning_rate": 0.0001574892917445725,
      "loss": 2.5567,
      "step": 14570
    },
    {
      "epoch": 0.9784906546760176,
      "grad_norm": 0.6542777419090271,
      "learning_rate": 0.00015742999433029952,
      "loss": 2.5363,
      "step": 14580
    },
    {
      "epoch": 0.9791617730948626,
      "grad_norm": 0.6764351725578308,
      "learning_rate": 0.0001573706667693167,
      "loss": 2.5264,
      "step": 14590
    },
    {
      "epoch": 0.9798328915137076,
      "grad_norm": 0.6352410316467285,
      "learning_rate": 0.00015731130909276688,
      "loss": 2.507,
      "step": 14600
    },
    {
      "epoch": 0.9798328915137076,
      "eval_bleu": 20.774015150829136,
      "eval_gen_len": 28.849,
      "eval_loss": 2.9500515460968018,
      "eval_runtime": 58.5991,
      "eval_samples_per_second": 17.065,
      "eval_steps_per_second": 1.075,
      "step": 14600
    },
    {
      "epoch": 0.9805040099325526,
      "grad_norm": 0.6740983724594116,
      "learning_rate": 0.0001572519213318086,
      "loss": 2.5143,
      "step": 14610
    },
    {
      "epoch": 0.9811751283513976,
      "grad_norm": 0.7270071506500244,
      "learning_rate": 0.0001571925035176163,
      "loss": 2.4853,
      "step": 14620
    },
    {
      "epoch": 0.9818462467702426,
      "grad_norm": 0.7770673036575317,
      "learning_rate": 0.0001571330556813801,
      "loss": 2.4663,
      "step": 14630
    },
    {
      "epoch": 0.9825173651890876,
      "grad_norm": 0.671103298664093,
      "learning_rate": 0.00015707357785430602,
      "loss": 2.54,
      "step": 14640
    },
    {
      "epoch": 0.9831884836079327,
      "grad_norm": 0.6583108305931091,
      "learning_rate": 0.00015701407006761566,
      "loss": 2.5289,
      "step": 14650
    },
    {
      "epoch": 0.9831884836079327,
      "eval_bleu": 21.0459350819915,
      "eval_gen_len": 28.881,
      "eval_loss": 2.944413661956787,
      "eval_runtime": 59.5975,
      "eval_samples_per_second": 16.779,
      "eval_steps_per_second": 1.057,
      "step": 14650
    },
    {
      "epoch": 0.9838596020267776,
      "grad_norm": 0.6411632299423218,
      "learning_rate": 0.0001569545323525465,
      "loss": 2.5357,
      "step": 14660
    },
    {
      "epoch": 0.9845307204456226,
      "grad_norm": 0.7314491271972656,
      "learning_rate": 0.00015689496474035158,
      "loss": 2.5409,
      "step": 14670
    },
    {
      "epoch": 0.9852018388644677,
      "grad_norm": 0.6698452830314636,
      "learning_rate": 0.00015683536726229975,
      "loss": 2.5363,
      "step": 14680
    },
    {
      "epoch": 0.9858729572833126,
      "grad_norm": 0.6717334389686584,
      "learning_rate": 0.00015677573994967548,
      "loss": 2.5501,
      "step": 14690
    },
    {
      "epoch": 0.9865440757021576,
      "grad_norm": 0.7080692052841187,
      "learning_rate": 0.00015671608283377892,
      "loss": 2.5812,
      "step": 14700
    },
    {
      "epoch": 0.9865440757021576,
      "eval_bleu": 20.626875046650547,
      "eval_gen_len": 28.816,
      "eval_loss": 2.9494941234588623,
      "eval_runtime": 58.2819,
      "eval_samples_per_second": 17.158,
      "eval_steps_per_second": 1.081,
      "step": 14700
    },
    {
      "epoch": 0.9872151941210027,
      "grad_norm": 0.6277728080749512,
      "learning_rate": 0.00015665639594592587,
      "loss": 2.567,
      "step": 14710
    },
    {
      "epoch": 0.9878863125398477,
      "grad_norm": 0.6641985774040222,
      "learning_rate": 0.00015659667931744778,
      "loss": 2.4977,
      "step": 14720
    },
    {
      "epoch": 0.9885574309586926,
      "grad_norm": 0.7345382571220398,
      "learning_rate": 0.0001565369329796916,
      "loss": 2.5705,
      "step": 14730
    },
    {
      "epoch": 0.9892285493775377,
      "grad_norm": 0.7089883089065552,
      "learning_rate": 0.00015647715696402004,
      "loss": 2.5655,
      "step": 14740
    },
    {
      "epoch": 0.9898996677963827,
      "grad_norm": 0.6696327328681946,
      "learning_rate": 0.00015641735130181127,
      "loss": 2.5403,
      "step": 14750
    },
    {
      "epoch": 0.9898996677963827,
      "eval_bleu": 20.932495766848934,
      "eval_gen_len": 28.829,
      "eval_loss": 2.944972038269043,
      "eval_runtime": 58.6186,
      "eval_samples_per_second": 17.059,
      "eval_steps_per_second": 1.075,
      "step": 14750
    },
    {
      "epoch": 0.9905707862152276,
      "grad_norm": 0.6642028093338013,
      "learning_rate": 0.00015635751602445906,
      "loss": 2.5491,
      "step": 14760
    },
    {
      "epoch": 0.9912419046340727,
      "grad_norm": 0.7377517819404602,
      "learning_rate": 0.00015629765116337275,
      "loss": 2.5484,
      "step": 14770
    },
    {
      "epoch": 0.9919130230529177,
      "grad_norm": 0.6562085151672363,
      "learning_rate": 0.00015623775674997715,
      "loss": 2.5539,
      "step": 14780
    },
    {
      "epoch": 0.9925841414717627,
      "grad_norm": 0.6883463263511658,
      "learning_rate": 0.0001561778328157126,
      "loss": 2.4717,
      "step": 14790
    },
    {
      "epoch": 0.9932552598906077,
      "grad_norm": 0.7183317542076111,
      "learning_rate": 0.000156117879392035,
      "loss": 2.5751,
      "step": 14800
    },
    {
      "epoch": 0.9932552598906077,
      "eval_bleu": 20.91574732212503,
      "eval_gen_len": 28.824,
      "eval_loss": 2.945132255554199,
      "eval_runtime": 58.6555,
      "eval_samples_per_second": 17.049,
      "eval_steps_per_second": 1.074,
      "step": 14800
    },
    {
      "epoch": 0.9939263783094527,
      "grad_norm": 0.6588929891586304,
      "learning_rate": 0.00015605789651041568,
      "loss": 2.5336,
      "step": 14810
    },
    {
      "epoch": 0.9945974967282977,
      "grad_norm": 0.6938626170158386,
      "learning_rate": 0.0001559978842023414,
      "loss": 2.5122,
      "step": 14820
    },
    {
      "epoch": 0.9952686151471427,
      "grad_norm": 0.7154473662376404,
      "learning_rate": 0.0001559378424993144,
      "loss": 2.5741,
      "step": 14830
    },
    {
      "epoch": 0.9959397335659878,
      "grad_norm": 0.6790732145309448,
      "learning_rate": 0.00015587777143285237,
      "loss": 2.5127,
      "step": 14840
    },
    {
      "epoch": 0.9966108519848327,
      "grad_norm": 0.7033659815788269,
      "learning_rate": 0.00015581767103448844,
      "loss": 2.4968,
      "step": 14850
    },
    {
      "epoch": 0.9966108519848327,
      "eval_bleu": 20.986331803932373,
      "eval_gen_len": 28.998,
      "eval_loss": 2.9528024196624756,
      "eval_runtime": 63.3915,
      "eval_samples_per_second": 15.775,
      "eval_steps_per_second": 0.994,
      "step": 14850
    },
    {
      "epoch": 0.9972819704036777,
      "grad_norm": 0.7294611930847168,
      "learning_rate": 0.00015575754133577102,
      "loss": 2.5602,
      "step": 14860
    },
    {
      "epoch": 0.9979530888225228,
      "grad_norm": 0.6945741772651672,
      "learning_rate": 0.00015569738236826406,
      "loss": 2.5335,
      "step": 14870
    },
    {
      "epoch": 0.9986242072413677,
      "grad_norm": 0.718340277671814,
      "learning_rate": 0.0001556371941635467,
      "loss": 2.5348,
      "step": 14880
    },
    {
      "epoch": 0.9992953256602127,
      "grad_norm": 0.6908565163612366,
      "learning_rate": 0.0001555769767532136,
      "loss": 2.5498,
      "step": 14890
    },
    {
      "epoch": 0.9999664440790578,
      "grad_norm": 0.703282356262207,
      "learning_rate": 0.00015551673016887455,
      "loss": 2.5314,
      "step": 14900
    },
    {
      "epoch": 0.9999664440790578,
      "eval_bleu": 20.967481771757974,
      "eval_gen_len": 28.735,
      "eval_loss": 2.946622848510742,
      "eval_runtime": 58.6742,
      "eval_samples_per_second": 17.043,
      "eval_steps_per_second": 1.074,
      "step": 14900
    },
    {
      "epoch": 1.0006040065769606,
      "grad_norm": 0.668968141078949,
      "learning_rate": 0.00015545645444215494,
      "loss": 2.4561,
      "step": 14910
    },
    {
      "epoch": 1.0012751249958054,
      "grad_norm": 0.71026611328125,
      "learning_rate": 0.00015539614960469514,
      "loss": 2.4772,
      "step": 14920
    },
    {
      "epoch": 1.0019462434146504,
      "grad_norm": 0.7165964245796204,
      "learning_rate": 0.000155335815688151,
      "loss": 2.4744,
      "step": 14930
    },
    {
      "epoch": 1.0026173618334955,
      "grad_norm": 0.7321726679801941,
      "learning_rate": 0.00015527545272419358,
      "loss": 2.4928,
      "step": 14940
    },
    {
      "epoch": 1.0032884802523405,
      "grad_norm": 0.6865475177764893,
      "learning_rate": 0.00015521506074450922,
      "loss": 2.4761,
      "step": 14950
    },
    {
      "epoch": 1.0032884802523405,
      "eval_bleu": 21.214545190338928,
      "eval_gen_len": 29.044,
      "eval_loss": 2.9453279972076416,
      "eval_runtime": 64.4563,
      "eval_samples_per_second": 15.514,
      "eval_steps_per_second": 0.977,
      "step": 14950
    },
    {
      "epoch": 1.0039595986711856,
      "grad_norm": 0.6542257070541382,
      "learning_rate": 0.00015515463978079948,
      "loss": 2.4506,
      "step": 14960
    },
    {
      "epoch": 1.0046307170900306,
      "grad_norm": 0.723111629486084,
      "learning_rate": 0.00015509418986478103,
      "loss": 2.4903,
      "step": 14970
    },
    {
      "epoch": 1.0053018355088756,
      "grad_norm": 0.6576902270317078,
      "learning_rate": 0.0001550337110281859,
      "loss": 2.4726,
      "step": 14980
    },
    {
      "epoch": 1.0059729539277205,
      "grad_norm": 0.6714034080505371,
      "learning_rate": 0.00015497320330276122,
      "loss": 2.4597,
      "step": 14990
    },
    {
      "epoch": 1.0066440723465655,
      "grad_norm": 0.728983998298645,
      "learning_rate": 0.0001549126667202693,
      "loss": 2.4229,
      "step": 15000
    },
    {
      "epoch": 1.0066440723465655,
      "eval_bleu": 20.85479793982874,
      "eval_gen_len": 28.788,
      "eval_loss": 2.949490547180176,
      "eval_runtime": 58.7959,
      "eval_samples_per_second": 17.008,
      "eval_steps_per_second": 1.072,
      "step": 15000
    },
    {
      "epoch": 1.0073151907654105,
      "grad_norm": 0.7102435827255249,
      "learning_rate": 0.00015485210131248753,
      "loss": 2.4591,
      "step": 15010
    },
    {
      "epoch": 1.0079863091842556,
      "grad_norm": 0.6424479484558105,
      "learning_rate": 0.00015479150711120856,
      "loss": 2.4798,
      "step": 15020
    },
    {
      "epoch": 1.0086574276031006,
      "grad_norm": 0.6469324827194214,
      "learning_rate": 0.00015473088414824003,
      "loss": 2.4908,
      "step": 15030
    },
    {
      "epoch": 1.0093285460219457,
      "grad_norm": 0.6825933456420898,
      "learning_rate": 0.0001546702324554048,
      "loss": 2.5205,
      "step": 15040
    },
    {
      "epoch": 1.0099996644407905,
      "grad_norm": 0.6874158382415771,
      "learning_rate": 0.0001546095520645407,
      "loss": 2.4453,
      "step": 15050
    },
    {
      "epoch": 1.0099996644407905,
      "eval_bleu": 21.213689967527827,
      "eval_gen_len": 28.911,
      "eval_loss": 2.945402145385742,
      "eval_runtime": 59.4406,
      "eval_samples_per_second": 16.824,
      "eval_steps_per_second": 1.06,
      "step": 15050
    },
    {
      "epoch": 1.0106707828596355,
      "grad_norm": 0.7079926133155823,
      "learning_rate": 0.00015454884300750068,
      "loss": 2.5325,
      "step": 15060
    },
    {
      "epoch": 1.0113419012784806,
      "grad_norm": 0.6661635637283325,
      "learning_rate": 0.00015448810531615273,
      "loss": 2.4604,
      "step": 15070
    },
    {
      "epoch": 1.0120130196973256,
      "grad_norm": 0.7179942727088928,
      "learning_rate": 0.00015442733902237983,
      "loss": 2.5225,
      "step": 15080
    },
    {
      "epoch": 1.0126841381161706,
      "grad_norm": 0.6452792286872864,
      "learning_rate": 0.00015436654415808008,
      "loss": 2.4276,
      "step": 15090
    },
    {
      "epoch": 1.0133552565350157,
      "grad_norm": 0.70618736743927,
      "learning_rate": 0.00015430572075516644,
      "loss": 2.5035,
      "step": 15100
    },
    {
      "epoch": 1.0133552565350157,
      "eval_bleu": 20.972633640100916,
      "eval_gen_len": 29.193,
      "eval_loss": 2.9459712505340576,
      "eval_runtime": 62.9133,
      "eval_samples_per_second": 15.895,
      "eval_steps_per_second": 1.001,
      "step": 15100
    },
    {
      "epoch": 1.0140263749538605,
      "grad_norm": 0.6912446618080139,
      "learning_rate": 0.00015424486884556702,
      "loss": 2.456,
      "step": 15110
    },
    {
      "epoch": 1.0146974933727055,
      "grad_norm": 0.7131431102752686,
      "learning_rate": 0.0001541839884612247,
      "loss": 2.5187,
      "step": 15120
    },
    {
      "epoch": 1.0153686117915506,
      "grad_norm": 0.6291235089302063,
      "learning_rate": 0.00015412307963409743,
      "loss": 2.4581,
      "step": 15130
    },
    {
      "epoch": 1.0160397302103956,
      "grad_norm": 0.6790573000907898,
      "learning_rate": 0.00015406214239615805,
      "loss": 2.5103,
      "step": 15140
    },
    {
      "epoch": 1.0167108486292407,
      "grad_norm": 0.7074560523033142,
      "learning_rate": 0.00015400117677939434,
      "loss": 2.4467,
      "step": 15150
    },
    {
      "epoch": 1.0167108486292407,
      "eval_bleu": 20.961317762153005,
      "eval_gen_len": 28.94,
      "eval_loss": 2.9507997035980225,
      "eval_runtime": 59.6967,
      "eval_samples_per_second": 16.751,
      "eval_steps_per_second": 1.055,
      "step": 15150
    },
    {
      "epoch": 1.0173819670480857,
      "grad_norm": 0.7270566821098328,
      "learning_rate": 0.000153940182815809,
      "loss": 2.5088,
      "step": 15160
    },
    {
      "epoch": 1.0180530854669307,
      "grad_norm": 0.6738376617431641,
      "learning_rate": 0.0001538791605374195,
      "loss": 2.5096,
      "step": 15170
    },
    {
      "epoch": 1.0187242038857756,
      "grad_norm": 0.6371524930000305,
      "learning_rate": 0.0001538181099762583,
      "loss": 2.4991,
      "step": 15180
    },
    {
      "epoch": 1.0193953223046206,
      "grad_norm": 0.6886555552482605,
      "learning_rate": 0.00015375703116437265,
      "loss": 2.5276,
      "step": 15190
    },
    {
      "epoch": 1.0200664407234656,
      "grad_norm": 0.6917998194694519,
      "learning_rate": 0.0001536959241338246,
      "loss": 2.4736,
      "step": 15200
    },
    {
      "epoch": 1.0200664407234656,
      "eval_bleu": 20.893819008942422,
      "eval_gen_len": 29.15,
      "eval_loss": 2.947594165802002,
      "eval_runtime": 62.6263,
      "eval_samples_per_second": 15.968,
      "eval_steps_per_second": 1.006,
      "step": 15200
    },
    {
      "epoch": 1.0207375591423107,
      "grad_norm": 0.7069040536880493,
      "learning_rate": 0.0001536347889166911,
      "loss": 2.4706,
      "step": 15210
    },
    {
      "epoch": 1.0214086775611557,
      "grad_norm": 0.6643815636634827,
      "learning_rate": 0.00015357362554506375,
      "loss": 2.4711,
      "step": 15220
    },
    {
      "epoch": 1.0220797959800008,
      "grad_norm": 0.723992645740509,
      "learning_rate": 0.00015351243405104916,
      "loss": 2.4942,
      "step": 15230
    },
    {
      "epoch": 1.0227509143988456,
      "grad_norm": 0.6390525102615356,
      "learning_rate": 0.00015345121446676843,
      "loss": 2.5127,
      "step": 15240
    },
    {
      "epoch": 1.0234220328176906,
      "grad_norm": 0.6764763593673706,
      "learning_rate": 0.00015338996682435758,
      "loss": 2.4651,
      "step": 15250
    },
    {
      "epoch": 1.0234220328176906,
      "eval_bleu": 20.610190119950566,
      "eval_gen_len": 28.802,
      "eval_loss": 2.9540934562683105,
      "eval_runtime": 58.5828,
      "eval_samples_per_second": 17.07,
      "eval_steps_per_second": 1.075,
      "step": 15250
    },
    {
      "epoch": 1.0240931512365357,
      "grad_norm": 0.7294607162475586,
      "learning_rate": 0.00015332869115596733,
      "loss": 2.5493,
      "step": 15260
    },
    {
      "epoch": 1.0247642696553807,
      "grad_norm": 0.7060666084289551,
      "learning_rate": 0.00015326738749376313,
      "loss": 2.4548,
      "step": 15270
    },
    {
      "epoch": 1.0254353880742257,
      "grad_norm": 0.6846752166748047,
      "learning_rate": 0.000153206055869925,
      "loss": 2.4661,
      "step": 15280
    },
    {
      "epoch": 1.0261065064930708,
      "grad_norm": 0.6838732361793518,
      "learning_rate": 0.00015314469631664784,
      "loss": 2.4791,
      "step": 15290
    },
    {
      "epoch": 1.0267776249119156,
      "grad_norm": 0.6808617115020752,
      "learning_rate": 0.000153083308866141,
      "loss": 2.4752,
      "step": 15300
    },
    {
      "epoch": 1.0267776249119156,
      "eval_bleu": 20.985196165220014,
      "eval_gen_len": 28.841,
      "eval_loss": 2.947683095932007,
      "eval_runtime": 59.7568,
      "eval_samples_per_second": 16.734,
      "eval_steps_per_second": 1.054,
      "step": 15300
    },
    {
      "epoch": 1.0274487433307606,
      "grad_norm": 0.7121524214744568,
      "learning_rate": 0.00015302189355062866,
      "loss": 2.4537,
      "step": 15310
    },
    {
      "epoch": 1.0281198617496057,
      "grad_norm": 0.641249418258667,
      "learning_rate": 0.00015296045040234953,
      "loss": 2.5077,
      "step": 15320
    },
    {
      "epoch": 1.0287909801684507,
      "grad_norm": 0.6662874817848206,
      "learning_rate": 0.00015289897945355686,
      "loss": 2.4654,
      "step": 15330
    },
    {
      "epoch": 1.0294620985872958,
      "grad_norm": 0.7091264128684998,
      "learning_rate": 0.0001528374807365187,
      "loss": 2.4643,
      "step": 15340
    },
    {
      "epoch": 1.0301332170061408,
      "grad_norm": 0.6713157296180725,
      "learning_rate": 0.00015277595428351746,
      "loss": 2.5055,
      "step": 15350
    },
    {
      "epoch": 1.0301332170061408,
      "eval_bleu": 21.06364606024384,
      "eval_gen_len": 29.0,
      "eval_loss": 2.9432766437530518,
      "eval_runtime": 59.586,
      "eval_samples_per_second": 16.782,
      "eval_steps_per_second": 1.057,
      "step": 15350
    },
    {
      "epoch": 1.0308043354249858,
      "grad_norm": 0.6815207600593567,
      "learning_rate": 0.00015271440012685025,
      "loss": 2.5197,
      "step": 15360
    },
    {
      "epoch": 1.0314754538438307,
      "grad_norm": 0.6666781902313232,
      "learning_rate": 0.00015265281829882868,
      "loss": 2.532,
      "step": 15370
    },
    {
      "epoch": 1.0321465722626757,
      "grad_norm": 0.7621724009513855,
      "learning_rate": 0.00015259120883177882,
      "loss": 2.4827,
      "step": 15380
    },
    {
      "epoch": 1.0328176906815207,
      "grad_norm": 0.6672454476356506,
      "learning_rate": 0.00015252957175804137,
      "loss": 2.4718,
      "step": 15390
    },
    {
      "epoch": 1.0334888091003658,
      "grad_norm": 0.700088381767273,
      "learning_rate": 0.00015246790710997146,
      "loss": 2.4806,
      "step": 15400
    },
    {
      "epoch": 1.0334888091003658,
      "eval_bleu": 20.89190403522817,
      "eval_gen_len": 28.91,
      "eval_loss": 2.945004940032959,
      "eval_runtime": 59.784,
      "eval_samples_per_second": 16.727,
      "eval_steps_per_second": 1.054,
      "step": 15400
    },
    {
      "epoch": 1.0341599275192108,
      "grad_norm": 0.686689555644989,
      "learning_rate": 0.00015240621491993865,
      "loss": 2.4636,
      "step": 15410
    },
    {
      "epoch": 1.0348310459380559,
      "grad_norm": 0.6771154403686523,
      "learning_rate": 0.00015234449522032704,
      "loss": 2.509,
      "step": 15420
    },
    {
      "epoch": 1.0355021643569007,
      "grad_norm": 0.6622729897499084,
      "learning_rate": 0.0001522827480435351,
      "loss": 2.4955,
      "step": 15430
    },
    {
      "epoch": 1.0361732827757457,
      "grad_norm": 0.6795818209648132,
      "learning_rate": 0.0001522209734219758,
      "loss": 2.4394,
      "step": 15440
    },
    {
      "epoch": 1.0368444011945908,
      "grad_norm": 0.6752549409866333,
      "learning_rate": 0.00015215917138807647,
      "loss": 2.4498,
      "step": 15450
    },
    {
      "epoch": 1.0368444011945908,
      "eval_bleu": 21.356669932398834,
      "eval_gen_len": 28.907,
      "eval_loss": 2.9462454319000244,
      "eval_runtime": 59.2092,
      "eval_samples_per_second": 16.889,
      "eval_steps_per_second": 1.064,
      "step": 15450
    },
    {
      "epoch": 1.0375155196134358,
      "grad_norm": 0.6554104089736938,
      "learning_rate": 0.0001520973419742788,
      "loss": 2.4661,
      "step": 15460
    },
    {
      "epoch": 1.0381866380322808,
      "grad_norm": 0.6906429529190063,
      "learning_rate": 0.00015203548521303893,
      "loss": 2.4877,
      "step": 15470
    },
    {
      "epoch": 1.0388577564511259,
      "grad_norm": 0.7260097861289978,
      "learning_rate": 0.00015197360113682724,
      "loss": 2.4943,
      "step": 15480
    },
    {
      "epoch": 1.039528874869971,
      "grad_norm": 0.7005165815353394,
      "learning_rate": 0.00015191168977812857,
      "loss": 2.4999,
      "step": 15490
    },
    {
      "epoch": 1.0401999932888157,
      "grad_norm": 0.649124264717102,
      "learning_rate": 0.00015184975116944207,
      "loss": 2.4541,
      "step": 15500
    },
    {
      "epoch": 1.0401999932888157,
      "eval_bleu": 20.858919970699688,
      "eval_gen_len": 28.754,
      "eval_loss": 2.944782257080078,
      "eval_runtime": 58.6361,
      "eval_samples_per_second": 17.054,
      "eval_steps_per_second": 1.074,
      "step": 15500
    },
    {
      "epoch": 1.0408711117076608,
      "grad_norm": 0.7490870356559753,
      "learning_rate": 0.00015178778534328106,
      "loss": 2.5035,
      "step": 15510
    },
    {
      "epoch": 1.0415422301265058,
      "grad_norm": 0.6721712350845337,
      "learning_rate": 0.00015172579233217333,
      "loss": 2.4781,
      "step": 15520
    },
    {
      "epoch": 1.0422133485453509,
      "grad_norm": 0.6856083273887634,
      "learning_rate": 0.0001516637721686608,
      "loss": 2.4886,
      "step": 15530
    },
    {
      "epoch": 1.042884466964196,
      "grad_norm": 0.7117714881896973,
      "learning_rate": 0.00015160172488529972,
      "loss": 2.5191,
      "step": 15540
    },
    {
      "epoch": 1.043555585383041,
      "grad_norm": 0.6572927832603455,
      "learning_rate": 0.00015153965051466054,
      "loss": 2.4812,
      "step": 15550
    },
    {
      "epoch": 1.043555585383041,
      "eval_bleu": 20.884312955701347,
      "eval_gen_len": 28.818,
      "eval_loss": 2.9454402923583984,
      "eval_runtime": 58.8178,
      "eval_samples_per_second": 17.002,
      "eval_steps_per_second": 1.071,
      "step": 15550
    },
    {
      "epoch": 1.0442267038018858,
      "grad_norm": 0.6260728240013123,
      "learning_rate": 0.00015147754908932795,
      "loss": 2.5395,
      "step": 15560
    },
    {
      "epoch": 1.0448978222207308,
      "grad_norm": 0.6968162655830383,
      "learning_rate": 0.00015141542064190083,
      "loss": 2.4893,
      "step": 15570
    },
    {
      "epoch": 1.0455689406395758,
      "grad_norm": 0.5816336870193481,
      "learning_rate": 0.00015135326520499223,
      "loss": 2.4498,
      "step": 15580
    },
    {
      "epoch": 1.0462400590584209,
      "grad_norm": 0.714121401309967,
      "learning_rate": 0.0001512910828112294,
      "loss": 2.5262,
      "step": 15590
    },
    {
      "epoch": 1.046911177477266,
      "grad_norm": 0.7227197289466858,
      "learning_rate": 0.00015122887349325374,
      "loss": 2.4522,
      "step": 15600
    },
    {
      "epoch": 1.046911177477266,
      "eval_bleu": 21.1583928140561,
      "eval_gen_len": 28.899,
      "eval_loss": 2.9438424110412598,
      "eval_runtime": 59.4488,
      "eval_samples_per_second": 16.821,
      "eval_steps_per_second": 1.06,
      "step": 15600
    },
    {
      "epoch": 1.047582295896111,
      "grad_norm": 0.649194598197937,
      "learning_rate": 0.00015116663728372074,
      "loss": 2.4951,
      "step": 15610
    },
    {
      "epoch": 1.0482534143149558,
      "grad_norm": 0.7920651435852051,
      "learning_rate": 0.00015110437421530007,
      "loss": 2.5129,
      "step": 15620
    },
    {
      "epoch": 1.0489245327338008,
      "grad_norm": 0.6573473811149597,
      "learning_rate": 0.00015104208432067546,
      "loss": 2.464,
      "step": 15630
    },
    {
      "epoch": 1.0495956511526459,
      "grad_norm": 0.6608170866966248,
      "learning_rate": 0.00015097976763254467,
      "loss": 2.4737,
      "step": 15640
    },
    {
      "epoch": 1.050266769571491,
      "grad_norm": 0.6563783884048462,
      "learning_rate": 0.00015091742418361963,
      "loss": 2.4966,
      "step": 15650
    },
    {
      "epoch": 1.050266769571491,
      "eval_bleu": 20.699148165812765,
      "eval_gen_len": 28.831,
      "eval_loss": 2.948316812515259,
      "eval_runtime": 59.1667,
      "eval_samples_per_second": 16.901,
      "eval_steps_per_second": 1.065,
      "step": 15650
    },
    {
      "epoch": 1.050937887990336,
      "grad_norm": 0.6954197287559509,
      "learning_rate": 0.0001508550540066263,
      "loss": 2.4548,
      "step": 15660
    },
    {
      "epoch": 1.051609006409181,
      "grad_norm": 0.6616263389587402,
      "learning_rate": 0.00015079265713430453,
      "loss": 2.5698,
      "step": 15670
    },
    {
      "epoch": 1.0522801248280258,
      "grad_norm": 0.6452159881591797,
      "learning_rate": 0.00015073023359940841,
      "loss": 2.4448,
      "step": 15680
    },
    {
      "epoch": 1.0529512432468708,
      "grad_norm": 0.687284529209137,
      "learning_rate": 0.00015066778343470583,
      "loss": 2.493,
      "step": 15690
    },
    {
      "epoch": 1.0536223616657159,
      "grad_norm": 0.6247456073760986,
      "learning_rate": 0.00015060530667297876,
      "loss": 2.4845,
      "step": 15700
    },
    {
      "epoch": 1.0536223616657159,
      "eval_bleu": 21.110926367857243,
      "eval_gen_len": 28.939,
      "eval_loss": 2.943596363067627,
      "eval_runtime": 59.2328,
      "eval_samples_per_second": 16.883,
      "eval_steps_per_second": 1.064,
      "step": 15700
    },
    {
      "epoch": 1.054293480084561,
      "grad_norm": 0.705821692943573,
      "learning_rate": 0.00015054280334702314,
      "loss": 2.4787,
      "step": 15710
    },
    {
      "epoch": 1.054964598503406,
      "grad_norm": 0.6769447326660156,
      "learning_rate": 0.00015048027348964874,
      "loss": 2.4677,
      "step": 15720
    },
    {
      "epoch": 1.055635716922251,
      "grad_norm": 0.6749350428581238,
      "learning_rate": 0.00015041771713367945,
      "loss": 2.4847,
      "step": 15730
    },
    {
      "epoch": 1.056306835341096,
      "grad_norm": 0.75157630443573,
      "learning_rate": 0.00015035513431195288,
      "loss": 2.4989,
      "step": 15740
    },
    {
      "epoch": 1.0569779537599409,
      "grad_norm": 0.7122289538383484,
      "learning_rate": 0.00015029252505732062,
      "loss": 2.4905,
      "step": 15750
    },
    {
      "epoch": 1.0569779537599409,
      "eval_bleu": 20.659499976346794,
      "eval_gen_len": 28.808,
      "eval_loss": 2.9454853534698486,
      "eval_runtime": 58.6147,
      "eval_samples_per_second": 17.061,
      "eval_steps_per_second": 1.075,
      "step": 15750
    },
    {
      "epoch": 1.057649072178786,
      "grad_norm": 0.7371302843093872,
      "learning_rate": 0.00015022988940264812,
      "loss": 2.5052,
      "step": 15760
    },
    {
      "epoch": 1.058320190597631,
      "grad_norm": 0.6013870239257812,
      "learning_rate": 0.00015016722738081477,
      "loss": 2.4098,
      "step": 15770
    },
    {
      "epoch": 1.058991309016476,
      "grad_norm": 0.6764667630195618,
      "learning_rate": 0.00015010453902471364,
      "loss": 2.498,
      "step": 15780
    },
    {
      "epoch": 1.059662427435321,
      "grad_norm": 0.6409795880317688,
      "learning_rate": 0.00015004182436725177,
      "loss": 2.5004,
      "step": 15790
    },
    {
      "epoch": 1.060333545854166,
      "grad_norm": 0.6420424580574036,
      "learning_rate": 0.00014997908344134987,
      "loss": 2.505,
      "step": 15800
    },
    {
      "epoch": 1.060333545854166,
      "eval_bleu": 20.792757985820735,
      "eval_gen_len": 28.788,
      "eval_loss": 2.9444878101348877,
      "eval_runtime": 59.0819,
      "eval_samples_per_second": 16.926,
      "eval_steps_per_second": 1.066,
      "step": 15800
    },
    {
      "epoch": 1.0610046642730109,
      "grad_norm": 0.7454977035522461,
      "learning_rate": 0.00014991631627994263,
      "loss": 2.4908,
      "step": 15810
    },
    {
      "epoch": 1.061675782691856,
      "grad_norm": 0.6559080481529236,
      "learning_rate": 0.00014985352291597826,
      "loss": 2.504,
      "step": 15820
    },
    {
      "epoch": 1.062346901110701,
      "grad_norm": 0.6689931750297546,
      "learning_rate": 0.00014979070338241897,
      "loss": 2.5137,
      "step": 15830
    },
    {
      "epoch": 1.063018019529546,
      "grad_norm": 0.6645650863647461,
      "learning_rate": 0.00014972785771224059,
      "loss": 2.4606,
      "step": 15840
    },
    {
      "epoch": 1.063689137948391,
      "grad_norm": 0.6720103025436401,
      "learning_rate": 0.00014966498593843263,
      "loss": 2.5037,
      "step": 15850
    },
    {
      "epoch": 1.063689137948391,
      "eval_bleu": 20.788775318680404,
      "eval_gen_len": 28.847,
      "eval_loss": 2.9440433979034424,
      "eval_runtime": 59.4323,
      "eval_samples_per_second": 16.826,
      "eval_steps_per_second": 1.06,
      "step": 15850
    },
    {
      "epoch": 1.064360256367236,
      "grad_norm": 0.6442589163780212,
      "learning_rate": 0.00014960208809399839,
      "loss": 2.4644,
      "step": 15860
    },
    {
      "epoch": 1.0650313747860811,
      "grad_norm": 0.6721549034118652,
      "learning_rate": 0.00014953916421195476,
      "loss": 2.5416,
      "step": 15870
    },
    {
      "epoch": 1.065702493204926,
      "grad_norm": 0.7628542184829712,
      "learning_rate": 0.00014947621432533241,
      "loss": 2.4682,
      "step": 15880
    },
    {
      "epoch": 1.066373611623771,
      "grad_norm": 0.7235395908355713,
      "learning_rate": 0.0001494132384671756,
      "loss": 2.482,
      "step": 15890
    },
    {
      "epoch": 1.067044730042616,
      "grad_norm": 0.7132918238639832,
      "learning_rate": 0.0001493502366705422,
      "loss": 2.4833,
      "step": 15900
    },
    {
      "epoch": 1.067044730042616,
      "eval_bleu": 20.68520081249516,
      "eval_gen_len": 28.95,
      "eval_loss": 2.943362236022949,
      "eval_runtime": 61.4048,
      "eval_samples_per_second": 16.285,
      "eval_steps_per_second": 1.026,
      "step": 15900
    },
    {
      "epoch": 1.067715848461461,
      "grad_norm": 0.6829847693443298,
      "learning_rate": 0.00014928720896850378,
      "loss": 2.4662,
      "step": 15910
    },
    {
      "epoch": 1.068386966880306,
      "grad_norm": 0.6673076748847961,
      "learning_rate": 0.0001492241553941454,
      "loss": 2.4748,
      "step": 15920
    },
    {
      "epoch": 1.069058085299151,
      "grad_norm": 0.73346346616745,
      "learning_rate": 0.00014916107598056576,
      "loss": 2.5489,
      "step": 15930
    },
    {
      "epoch": 1.069729203717996,
      "grad_norm": 0.6878848671913147,
      "learning_rate": 0.00014909797076087715,
      "loss": 2.4916,
      "step": 15940
    },
    {
      "epoch": 1.070400322136841,
      "grad_norm": 0.7850983142852783,
      "learning_rate": 0.00014903483976820537,
      "loss": 2.4797,
      "step": 15950
    },
    {
      "epoch": 1.070400322136841,
      "eval_bleu": 20.66041239448662,
      "eval_gen_len": 28.812,
      "eval_loss": 2.951796293258667,
      "eval_runtime": 58.6546,
      "eval_samples_per_second": 17.049,
      "eval_steps_per_second": 1.074,
      "step": 15950
    },
    {
      "epoch": 1.071071440555686,
      "grad_norm": 0.6621320843696594,
      "learning_rate": 0.0001489716830356897,
      "loss": 2.4978,
      "step": 15960
    },
    {
      "epoch": 1.071742558974531,
      "grad_norm": 0.6714887022972107,
      "learning_rate": 0.000148908500596483,
      "loss": 2.483,
      "step": 15970
    },
    {
      "epoch": 1.0724136773933761,
      "grad_norm": 0.6456308364868164,
      "learning_rate": 0.00014884529248375164,
      "loss": 2.4334,
      "step": 15980
    },
    {
      "epoch": 1.0730847958122212,
      "grad_norm": 0.6888636350631714,
      "learning_rate": 0.0001487820587306755,
      "loss": 2.4676,
      "step": 15990
    },
    {
      "epoch": 1.073755914231066,
      "grad_norm": 0.6358798742294312,
      "learning_rate": 0.00014871879937044768,
      "loss": 2.4491,
      "step": 16000
    },
    {
      "epoch": 1.073755914231066,
      "eval_bleu": 21.04085327804912,
      "eval_gen_len": 28.913,
      "eval_loss": 2.944948196411133,
      "eval_runtime": 59.1075,
      "eval_samples_per_second": 16.918,
      "eval_steps_per_second": 1.066,
      "step": 16000
    },
    {
      "epoch": 1.074427032649911,
      "grad_norm": 0.7003697752952576,
      "learning_rate": 0.00014865551443627502,
      "loss": 2.4875,
      "step": 16010
    },
    {
      "epoch": 1.075098151068756,
      "grad_norm": 0.6661871075630188,
      "learning_rate": 0.00014859220396137767,
      "loss": 2.4834,
      "step": 16020
    },
    {
      "epoch": 1.075769269487601,
      "grad_norm": 0.7366531491279602,
      "learning_rate": 0.00014852886797898915,
      "loss": 2.4857,
      "step": 16030
    },
    {
      "epoch": 1.0764403879064461,
      "grad_norm": 0.6381445527076721,
      "learning_rate": 0.0001484655065223564,
      "loss": 2.4825,
      "step": 16040
    },
    {
      "epoch": 1.0771115063252912,
      "grad_norm": 0.6410722732543945,
      "learning_rate": 0.0001484021196247397,
      "loss": 2.492,
      "step": 16050
    },
    {
      "epoch": 1.0771115063252912,
      "eval_bleu": 20.729674277081322,
      "eval_gen_len": 28.739,
      "eval_loss": 2.945848226547241,
      "eval_runtime": 58.4655,
      "eval_samples_per_second": 17.104,
      "eval_steps_per_second": 1.078,
      "step": 16050
    },
    {
      "epoch": 1.077782624744136,
      "grad_norm": 0.7873066067695618,
      "learning_rate": 0.00014833870731941273,
      "loss": 2.5405,
      "step": 16060
    },
    {
      "epoch": 1.078453743162981,
      "grad_norm": 0.7338768243789673,
      "learning_rate": 0.00014827526963966253,
      "loss": 2.5033,
      "step": 16070
    },
    {
      "epoch": 1.079124861581826,
      "grad_norm": 0.7180230617523193,
      "learning_rate": 0.0001482118066187894,
      "loss": 2.4714,
      "step": 16080
    },
    {
      "epoch": 1.0797959800006711,
      "grad_norm": 0.66098952293396,
      "learning_rate": 0.00014814831829010694,
      "loss": 2.4912,
      "step": 16090
    },
    {
      "epoch": 1.0804670984195162,
      "grad_norm": 0.6916508674621582,
      "learning_rate": 0.0001480848046869421,
      "loss": 2.508,
      "step": 16100
    },
    {
      "epoch": 1.0804670984195162,
      "eval_bleu": 20.634647310021847,
      "eval_gen_len": 28.883,
      "eval_loss": 2.9458889961242676,
      "eval_runtime": 59.0249,
      "eval_samples_per_second": 16.942,
      "eval_steps_per_second": 1.067,
      "step": 16100
    },
    {
      "epoch": 1.0811382168383612,
      "grad_norm": 0.6843146085739136,
      "learning_rate": 0.00014802126584263504,
      "loss": 2.5279,
      "step": 16110
    },
    {
      "epoch": 1.0818093352572062,
      "grad_norm": 0.700120747089386,
      "learning_rate": 0.0001479577017905392,
      "loss": 2.4855,
      "step": 16120
    },
    {
      "epoch": 1.082480453676051,
      "grad_norm": 0.771038293838501,
      "learning_rate": 0.0001478941125640212,
      "loss": 2.4789,
      "step": 16130
    },
    {
      "epoch": 1.083151572094896,
      "grad_norm": 0.6771474480628967,
      "learning_rate": 0.00014783049819646092,
      "loss": 2.4681,
      "step": 16140
    },
    {
      "epoch": 1.0838226905137411,
      "grad_norm": 0.6825258731842041,
      "learning_rate": 0.00014776685872125146,
      "loss": 2.4778,
      "step": 16150
    },
    {
      "epoch": 1.0838226905137411,
      "eval_bleu": 20.694738931783913,
      "eval_gen_len": 29.086,
      "eval_loss": 2.9495317935943604,
      "eval_runtime": 62.036,
      "eval_samples_per_second": 16.12,
      "eval_steps_per_second": 1.016,
      "step": 16150
    },
    {
      "epoch": 1.0844938089325862,
      "grad_norm": 0.6593424081802368,
      "learning_rate": 0.0001477031941717991,
      "loss": 2.4536,
      "step": 16160
    },
    {
      "epoch": 1.0851649273514312,
      "grad_norm": 0.6572877168655396,
      "learning_rate": 0.00014763950458152316,
      "loss": 2.5114,
      "step": 16170
    },
    {
      "epoch": 1.0858360457702763,
      "grad_norm": 0.6637599468231201,
      "learning_rate": 0.00014757578998385627,
      "loss": 2.4834,
      "step": 16180
    },
    {
      "epoch": 1.086507164189121,
      "grad_norm": 0.7011615037918091,
      "learning_rate": 0.0001475120504122441,
      "loss": 2.5071,
      "step": 16190
    },
    {
      "epoch": 1.0871782826079661,
      "grad_norm": 0.7015179991722107,
      "learning_rate": 0.0001474482859001454,
      "loss": 2.4874,
      "step": 16200
    },
    {
      "epoch": 1.0871782826079661,
      "eval_bleu": 20.79339776488497,
      "eval_gen_len": 29.089,
      "eval_loss": 2.950812816619873,
      "eval_runtime": 61.6784,
      "eval_samples_per_second": 16.213,
      "eval_steps_per_second": 1.021,
      "step": 16200
    },
    {
      "epoch": 1.0878494010268112,
      "grad_norm": 0.8008754253387451,
      "learning_rate": 0.00014738449648103217,
      "loss": 2.4538,
      "step": 16210
    },
    {
      "epoch": 1.0885205194456562,
      "grad_norm": 0.6880461573600769,
      "learning_rate": 0.00014732068218838924,
      "loss": 2.4955,
      "step": 16220
    },
    {
      "epoch": 1.0891916378645012,
      "grad_norm": 0.6908367276191711,
      "learning_rate": 0.0001472568430557147,
      "loss": 2.4596,
      "step": 16230
    },
    {
      "epoch": 1.0898627562833463,
      "grad_norm": 0.6499083042144775,
      "learning_rate": 0.00014719297911651961,
      "loss": 2.4719,
      "step": 16240
    },
    {
      "epoch": 1.0905338747021913,
      "grad_norm": 0.7229087352752686,
      "learning_rate": 0.000147129090404328,
      "loss": 2.4912,
      "step": 16250
    },
    {
      "epoch": 1.0905338747021913,
      "eval_bleu": 20.590312944785435,
      "eval_gen_len": 28.944,
      "eval_loss": 2.948079824447632,
      "eval_runtime": 58.5605,
      "eval_samples_per_second": 17.076,
      "eval_steps_per_second": 1.076,
      "step": 16250
    },
    {
      "epoch": 1.0912049931210361,
      "grad_norm": 0.6720262765884399,
      "learning_rate": 0.000147065176952677,
      "loss": 2.476,
      "step": 16260
    },
    {
      "epoch": 1.0918761115398812,
      "grad_norm": 0.654985249042511,
      "learning_rate": 0.00014700123879511667,
      "loss": 2.5582,
      "step": 16270
    },
    {
      "epoch": 1.0925472299587262,
      "grad_norm": 0.6890849471092224,
      "learning_rate": 0.00014693727596521003,
      "loss": 2.5002,
      "step": 16280
    },
    {
      "epoch": 1.0932183483775713,
      "grad_norm": 0.5575107932090759,
      "learning_rate": 0.00014687328849653306,
      "loss": 2.4137,
      "step": 16290
    },
    {
      "epoch": 1.0938894667964163,
      "grad_norm": 0.6676480770111084,
      "learning_rate": 0.00014680927642267473,
      "loss": 2.4725,
      "step": 16300
    },
    {
      "epoch": 1.0938894667964163,
      "eval_bleu": 20.505169054565116,
      "eval_gen_len": 28.99,
      "eval_loss": 2.9550888538360596,
      "eval_runtime": 62.0611,
      "eval_samples_per_second": 16.113,
      "eval_steps_per_second": 1.015,
      "step": 16300
    },
    {
      "epoch": 1.0945605852152611,
      "grad_norm": 0.6931958794593811,
      "learning_rate": 0.00014674523977723685,
      "loss": 2.5402,
      "step": 16310
    },
    {
      "epoch": 1.0952317036341062,
      "grad_norm": 0.6738011837005615,
      "learning_rate": 0.00014668117859383413,
      "loss": 2.4374,
      "step": 16320
    },
    {
      "epoch": 1.0959028220529512,
      "grad_norm": 0.7127703428268433,
      "learning_rate": 0.00014661709290609423,
      "loss": 2.4777,
      "step": 16330
    },
    {
      "epoch": 1.0965739404717962,
      "grad_norm": 0.687296986579895,
      "learning_rate": 0.00014655298274765763,
      "loss": 2.4647,
      "step": 16340
    },
    {
      "epoch": 1.0972450588906413,
      "grad_norm": 0.722042977809906,
      "learning_rate": 0.0001464888481521776,
      "loss": 2.5212,
      "step": 16350
    },
    {
      "epoch": 1.0972450588906413,
      "eval_bleu": 20.820511009508948,
      "eval_gen_len": 28.815,
      "eval_loss": 2.948880672454834,
      "eval_runtime": 58.2502,
      "eval_samples_per_second": 17.167,
      "eval_steps_per_second": 1.082,
      "step": 16350
    },
    {
      "epoch": 1.0979161773094863,
      "grad_norm": 0.6890725493431091,
      "learning_rate": 0.00014642468915332038,
      "loss": 2.5023,
      "step": 16360
    },
    {
      "epoch": 1.0985872957283314,
      "grad_norm": 0.7126411199569702,
      "learning_rate": 0.00014636050578476487,
      "loss": 2.5037,
      "step": 16370
    },
    {
      "epoch": 1.0992584141471762,
      "grad_norm": 0.6752011179924011,
      "learning_rate": 0.00014629629808020288,
      "loss": 2.4423,
      "step": 16380
    },
    {
      "epoch": 1.0999295325660212,
      "grad_norm": 0.7253080010414124,
      "learning_rate": 0.00014623206607333888,
      "loss": 2.4831,
      "step": 16390
    },
    {
      "epoch": 1.1006006509848663,
      "grad_norm": 0.6812512874603271,
      "learning_rate": 0.0001461678097978902,
      "loss": 2.5283,
      "step": 16400
    },
    {
      "epoch": 1.1006006509848663,
      "eval_bleu": 21.12716857097503,
      "eval_gen_len": 28.8,
      "eval_loss": 2.946481227874756,
      "eval_runtime": 58.8669,
      "eval_samples_per_second": 16.987,
      "eval_steps_per_second": 1.07,
      "step": 16400
    },
    {
      "epoch": 1.1012717694037113,
      "grad_norm": 0.6686766147613525,
      "learning_rate": 0.00014610352928758684,
      "loss": 2.4798,
      "step": 16410
    },
    {
      "epoch": 1.1019428878225563,
      "grad_norm": 0.8120679259300232,
      "learning_rate": 0.00014603922457617156,
      "loss": 2.4773,
      "step": 16420
    },
    {
      "epoch": 1.1026140062414014,
      "grad_norm": 0.6462231874465942,
      "learning_rate": 0.00014597489569739987,
      "loss": 2.4886,
      "step": 16430
    },
    {
      "epoch": 1.1032851246602462,
      "grad_norm": 0.7068192958831787,
      "learning_rate": 0.00014591054268503977,
      "loss": 2.4912,
      "step": 16440
    },
    {
      "epoch": 1.1039562430790912,
      "grad_norm": 0.6350468397140503,
      "learning_rate": 0.00014584616557287224,
      "loss": 2.4949,
      "step": 16450
    },
    {
      "epoch": 1.1039562430790912,
      "eval_bleu": 20.5553337487087,
      "eval_gen_len": 28.968,
      "eval_loss": 2.9441683292388916,
      "eval_runtime": 59.6683,
      "eval_samples_per_second": 16.759,
      "eval_steps_per_second": 1.056,
      "step": 16450
    },
    {
      "epoch": 1.1046273614979363,
      "grad_norm": 0.6945935487747192,
      "learning_rate": 0.00014578176439469058,
      "loss": 2.4721,
      "step": 16460
    },
    {
      "epoch": 1.1052984799167813,
      "grad_norm": 0.6635533571243286,
      "learning_rate": 0.00014571733918430102,
      "loss": 2.432,
      "step": 16470
    },
    {
      "epoch": 1.1059695983356264,
      "grad_norm": 0.6755245327949524,
      "learning_rate": 0.00014565288997552215,
      "loss": 2.5345,
      "step": 16480
    },
    {
      "epoch": 1.1066407167544714,
      "grad_norm": 0.6608491539955139,
      "learning_rate": 0.00014558841680218534,
      "loss": 2.5017,
      "step": 16490
    },
    {
      "epoch": 1.1073118351733164,
      "grad_norm": 0.7012346386909485,
      "learning_rate": 0.00014552391969813446,
      "loss": 2.4647,
      "step": 16500
    },
    {
      "epoch": 1.1073118351733164,
      "eval_bleu": 20.69727766235481,
      "eval_gen_len": 28.805,
      "eval_loss": 2.95500111579895,
      "eval_runtime": 58.5486,
      "eval_samples_per_second": 17.08,
      "eval_steps_per_second": 1.076,
      "step": 16500
    },
    {
      "epoch": 1.1079829535921613,
      "grad_norm": 0.6364539861679077,
      "learning_rate": 0.00014545939869722597,
      "loss": 2.4792,
      "step": 16510
    },
    {
      "epoch": 1.1086540720110063,
      "grad_norm": 0.7052116394042969,
      "learning_rate": 0.00014539485383332883,
      "loss": 2.5328,
      "step": 16520
    },
    {
      "epoch": 1.1093251904298513,
      "grad_norm": 0.7047196626663208,
      "learning_rate": 0.00014533028514032457,
      "loss": 2.4736,
      "step": 16530
    },
    {
      "epoch": 1.1099963088486964,
      "grad_norm": 0.6660577058792114,
      "learning_rate": 0.00014526569265210722,
      "loss": 2.4605,
      "step": 16540
    },
    {
      "epoch": 1.1106674272675414,
      "grad_norm": 0.6507015228271484,
      "learning_rate": 0.00014520107640258326,
      "loss": 2.4548,
      "step": 16550
    },
    {
      "epoch": 1.1106674272675414,
      "eval_bleu": 21.01032747771377,
      "eval_gen_len": 28.737,
      "eval_loss": 2.9489173889160156,
      "eval_runtime": 58.461,
      "eval_samples_per_second": 17.105,
      "eval_steps_per_second": 1.078,
      "step": 16550
    },
    {
      "epoch": 1.1113385456863865,
      "grad_norm": 0.6820542812347412,
      "learning_rate": 0.00014513643642567173,
      "loss": 2.5207,
      "step": 16560
    },
    {
      "epoch": 1.1120096641052313,
      "grad_norm": 0.7468729615211487,
      "learning_rate": 0.00014507177275530406,
      "loss": 2.5352,
      "step": 16570
    },
    {
      "epoch": 1.1126807825240763,
      "grad_norm": 0.7015089988708496,
      "learning_rate": 0.00014500708542542412,
      "loss": 2.4863,
      "step": 16580
    },
    {
      "epoch": 1.1133519009429214,
      "grad_norm": 0.710846483707428,
      "learning_rate": 0.00014494237446998823,
      "loss": 2.4938,
      "step": 16590
    },
    {
      "epoch": 1.1140230193617664,
      "grad_norm": 0.7824732661247253,
      "learning_rate": 0.00014487763992296503,
      "loss": 2.4741,
      "step": 16600
    },
    {
      "epoch": 1.1140230193617664,
      "eval_bleu": 20.850784720786685,
      "eval_gen_len": 29.023,
      "eval_loss": 2.9501357078552246,
      "eval_runtime": 64.8994,
      "eval_samples_per_second": 15.408,
      "eval_steps_per_second": 0.971,
      "step": 16600
    },
    {
      "epoch": 1.1146941377806114,
      "grad_norm": 0.6792036294937134,
      "learning_rate": 0.00014481288181833569,
      "loss": 2.4702,
      "step": 16610
    },
    {
      "epoch": 1.1153652561994565,
      "grad_norm": 0.6775521636009216,
      "learning_rate": 0.00014474810019009363,
      "loss": 2.4639,
      "step": 16620
    },
    {
      "epoch": 1.1160363746183013,
      "grad_norm": 0.7598618865013123,
      "learning_rate": 0.00014468329507224463,
      "loss": 2.5397,
      "step": 16630
    },
    {
      "epoch": 1.1167074930371463,
      "grad_norm": 0.7200046181678772,
      "learning_rate": 0.00014461846649880685,
      "loss": 2.4757,
      "step": 16640
    },
    {
      "epoch": 1.1173786114559914,
      "grad_norm": 0.6411724090576172,
      "learning_rate": 0.00014455361450381072,
      "loss": 2.5014,
      "step": 16650
    },
    {
      "epoch": 1.1173786114559914,
      "eval_bleu": 20.852668376048996,
      "eval_gen_len": 29.31,
      "eval_loss": 2.947754383087158,
      "eval_runtime": 64.6398,
      "eval_samples_per_second": 15.47,
      "eval_steps_per_second": 0.975,
      "step": 16650
    },
    {
      "epoch": 1.1180497298748364,
      "grad_norm": 0.710764467716217,
      "learning_rate": 0.00014448873912129896,
      "loss": 2.4829,
      "step": 16660
    },
    {
      "epoch": 1.1187208482936815,
      "grad_norm": 0.724266529083252,
      "learning_rate": 0.00014442384038532665,
      "loss": 2.5047,
      "step": 16670
    },
    {
      "epoch": 1.1193919667125265,
      "grad_norm": 0.6869248747825623,
      "learning_rate": 0.000144358918329961,
      "loss": 2.5036,
      "step": 16680
    },
    {
      "epoch": 1.1200630851313713,
      "grad_norm": 0.756886899471283,
      "learning_rate": 0.00014429397298928152,
      "loss": 2.4813,
      "step": 16690
    },
    {
      "epoch": 1.1207342035502164,
      "grad_norm": 0.6542186737060547,
      "learning_rate": 0.00014422900439738,
      "loss": 2.415,
      "step": 16700
    },
    {
      "epoch": 1.1207342035502164,
      "eval_bleu": 21.139184472976307,
      "eval_gen_len": 28.982,
      "eval_loss": 2.9488887786865234,
      "eval_runtime": 61.8697,
      "eval_samples_per_second": 16.163,
      "eval_steps_per_second": 1.018,
      "step": 16700
    },
    {
      "epoch": 1.1214053219690614,
      "grad_norm": 0.7247728705406189,
      "learning_rate": 0.00014416401258836035,
      "loss": 2.5169,
      "step": 16710
    },
    {
      "epoch": 1.1220764403879064,
      "grad_norm": 0.6876682639122009,
      "learning_rate": 0.00014409899759633868,
      "loss": 2.4736,
      "step": 16720
    },
    {
      "epoch": 1.1227475588067515,
      "grad_norm": 0.7127254605293274,
      "learning_rate": 0.00014403395945544335,
      "loss": 2.512,
      "step": 16730
    },
    {
      "epoch": 1.1234186772255965,
      "grad_norm": 0.7007341384887695,
      "learning_rate": 0.0001439688981998148,
      "loss": 2.4914,
      "step": 16740
    },
    {
      "epoch": 1.1240897956444416,
      "grad_norm": 0.682981014251709,
      "learning_rate": 0.00014390381386360557,
      "loss": 2.4251,
      "step": 16750
    },
    {
      "epoch": 1.1240897956444416,
      "eval_bleu": 20.665306496120383,
      "eval_gen_len": 28.801,
      "eval_loss": 2.9518516063690186,
      "eval_runtime": 58.425,
      "eval_samples_per_second": 17.116,
      "eval_steps_per_second": 1.078,
      "step": 16750
    },
    {
      "epoch": 1.1247609140632864,
      "grad_norm": 0.6594414710998535,
      "learning_rate": 0.00014383870648098038,
      "loss": 2.4713,
      "step": 16760
    },
    {
      "epoch": 1.1254320324821314,
      "grad_norm": 0.6502173542976379,
      "learning_rate": 0.00014377357608611605,
      "loss": 2.4871,
      "step": 16770
    },
    {
      "epoch": 1.1261031509009765,
      "grad_norm": 0.7214707136154175,
      "learning_rate": 0.00014370842271320145,
      "loss": 2.4916,
      "step": 16780
    },
    {
      "epoch": 1.1267742693198215,
      "grad_norm": 0.6638190746307373,
      "learning_rate": 0.0001436432463964375,
      "loss": 2.4729,
      "step": 16790
    },
    {
      "epoch": 1.1274453877386665,
      "grad_norm": 0.7371633648872375,
      "learning_rate": 0.00014357804717003722,
      "loss": 2.5122,
      "step": 16800
    },
    {
      "epoch": 1.1274453877386665,
      "eval_bleu": 21.095201285759394,
      "eval_gen_len": 28.802,
      "eval_loss": 2.949337959289551,
      "eval_runtime": 58.38,
      "eval_samples_per_second": 17.129,
      "eval_steps_per_second": 1.079,
      "step": 16800
    },
    {
      "epoch": 1.1281165061575116,
      "grad_norm": 0.6403869390487671,
      "learning_rate": 0.00014351282506822562,
      "loss": 2.4725,
      "step": 16810
    },
    {
      "epoch": 1.1287876245763564,
      "grad_norm": 0.6623241901397705,
      "learning_rate": 0.00014344758012523965,
      "loss": 2.4761,
      "step": 16820
    },
    {
      "epoch": 1.1294587429952014,
      "grad_norm": 0.6779627799987793,
      "learning_rate": 0.0001433823123753284,
      "loss": 2.479,
      "step": 16830
    },
    {
      "epoch": 1.1301298614140465,
      "grad_norm": 0.6797533631324768,
      "learning_rate": 0.00014331702185275283,
      "loss": 2.4977,
      "step": 16840
    },
    {
      "epoch": 1.1308009798328915,
      "grad_norm": 0.7023646235466003,
      "learning_rate": 0.00014325170859178583,
      "loss": 2.4669,
      "step": 16850
    },
    {
      "epoch": 1.1308009798328915,
      "eval_bleu": 20.78076951410509,
      "eval_gen_len": 28.847,
      "eval_loss": 2.9518349170684814,
      "eval_runtime": 59.4966,
      "eval_samples_per_second": 16.808,
      "eval_steps_per_second": 1.059,
      "step": 16850
    },
    {
      "epoch": 1.1314720982517366,
      "grad_norm": 0.641703724861145,
      "learning_rate": 0.00014318637262671232,
      "loss": 2.5207,
      "step": 16860
    },
    {
      "epoch": 1.1321432166705816,
      "grad_norm": 0.6466153860092163,
      "learning_rate": 0.00014312101399182906,
      "loss": 2.4907,
      "step": 16870
    },
    {
      "epoch": 1.1328143350894266,
      "grad_norm": 0.7026315331459045,
      "learning_rate": 0.00014305563272144477,
      "loss": 2.5149,
      "step": 16880
    },
    {
      "epoch": 1.1334854535082715,
      "grad_norm": 0.7280604839324951,
      "learning_rate": 0.00014299022884987998,
      "loss": 2.5122,
      "step": 16890
    },
    {
      "epoch": 1.1341565719271165,
      "grad_norm": 0.679733157157898,
      "learning_rate": 0.00014292480241146716,
      "loss": 2.4581,
      "step": 16900
    },
    {
      "epoch": 1.1341565719271165,
      "eval_bleu": 20.887124129419323,
      "eval_gen_len": 28.843,
      "eval_loss": 2.9485342502593994,
      "eval_runtime": 58.6133,
      "eval_samples_per_second": 17.061,
      "eval_steps_per_second": 1.075,
      "step": 16900
    },
    {
      "epoch": 1.1348276903459615,
      "grad_norm": 0.707883358001709,
      "learning_rate": 0.00014285935344055057,
      "loss": 2.5067,
      "step": 16910
    },
    {
      "epoch": 1.1354988087648066,
      "grad_norm": 0.64115971326828,
      "learning_rate": 0.00014279388197148632,
      "loss": 2.4673,
      "step": 16920
    },
    {
      "epoch": 1.1361699271836516,
      "grad_norm": 0.6924756169319153,
      "learning_rate": 0.00014272838803864238,
      "loss": 2.4659,
      "step": 16930
    },
    {
      "epoch": 1.1368410456024964,
      "grad_norm": 0.6825474500656128,
      "learning_rate": 0.00014266287167639838,
      "loss": 2.4895,
      "step": 16940
    },
    {
      "epoch": 1.1375121640213415,
      "grad_norm": 0.748330295085907,
      "learning_rate": 0.00014259733291914584,
      "loss": 2.5396,
      "step": 16950
    },
    {
      "epoch": 1.1375121640213415,
      "eval_bleu": 20.999307558572813,
      "eval_gen_len": 29.058,
      "eval_loss": 2.944267749786377,
      "eval_runtime": 61.7087,
      "eval_samples_per_second": 16.205,
      "eval_steps_per_second": 1.021,
      "step": 16950
    },
    {
      "epoch": 1.1381832824401865,
      "grad_norm": 0.6706171035766602,
      "learning_rate": 0.000142531771801288,
      "loss": 2.4822,
      "step": 16960
    },
    {
      "epoch": 1.1388544008590316,
      "grad_norm": 0.6655285954475403,
      "learning_rate": 0.00014246618835723983,
      "loss": 2.493,
      "step": 16970
    },
    {
      "epoch": 1.1395255192778766,
      "grad_norm": 0.7488421201705933,
      "learning_rate": 0.0001424005826214281,
      "loss": 2.5817,
      "step": 16980
    },
    {
      "epoch": 1.1401966376967216,
      "grad_norm": 0.7142647504806519,
      "learning_rate": 0.00014233495462829106,
      "loss": 2.525,
      "step": 16990
    },
    {
      "epoch": 1.1408677561155667,
      "grad_norm": 0.6471628546714783,
      "learning_rate": 0.00014226930441227893,
      "loss": 2.4456,
      "step": 17000
    },
    {
      "epoch": 1.1408677561155667,
      "eval_bleu": 21.06217325063017,
      "eval_gen_len": 28.869,
      "eval_loss": 2.9433391094207764,
      "eval_runtime": 58.6989,
      "eval_samples_per_second": 17.036,
      "eval_steps_per_second": 1.073,
      "step": 17000
    },
    {
      "epoch": 1.1415388745344117,
      "grad_norm": 0.6525425910949707,
      "learning_rate": 0.0001422036320078534,
      "loss": 2.492,
      "step": 17010
    },
    {
      "epoch": 1.1422099929532565,
      "grad_norm": 0.6753433346748352,
      "learning_rate": 0.00014213793744948788,
      "loss": 2.4691,
      "step": 17020
    },
    {
      "epoch": 1.1428811113721016,
      "grad_norm": 0.6468095183372498,
      "learning_rate": 0.00014207222077166736,
      "loss": 2.4718,
      "step": 17030
    },
    {
      "epoch": 1.1435522297909466,
      "grad_norm": 0.6714679002761841,
      "learning_rate": 0.0001420064820088885,
      "loss": 2.4818,
      "step": 17040
    },
    {
      "epoch": 1.1442233482097917,
      "grad_norm": 0.6993090510368347,
      "learning_rate": 0.00014194072119565957,
      "loss": 2.5018,
      "step": 17050
    },
    {
      "epoch": 1.1442233482097917,
      "eval_bleu": 21.203679514643817,
      "eval_gen_len": 28.834,
      "eval_loss": 2.9425997734069824,
      "eval_runtime": 58.6125,
      "eval_samples_per_second": 17.061,
      "eval_steps_per_second": 1.075,
      "step": 17050
    },
    {
      "epoch": 1.1448944666286367,
      "grad_norm": 0.7182549834251404,
      "learning_rate": 0.00014187493836650034,
      "loss": 2.4761,
      "step": 17060
    },
    {
      "epoch": 1.1455655850474815,
      "grad_norm": 0.7046434879302979,
      "learning_rate": 0.00014180913355594214,
      "loss": 2.4578,
      "step": 17070
    },
    {
      "epoch": 1.1462367034663266,
      "grad_norm": 0.6559885740280151,
      "learning_rate": 0.0001417433067985279,
      "loss": 2.4761,
      "step": 17080
    },
    {
      "epoch": 1.1469078218851716,
      "grad_norm": 0.7445852160453796,
      "learning_rate": 0.00014167745812881206,
      "loss": 2.4901,
      "step": 17090
    },
    {
      "epoch": 1.1475789403040166,
      "grad_norm": 0.6962032914161682,
      "learning_rate": 0.0001416115875813605,
      "loss": 2.4188,
      "step": 17100
    },
    {
      "epoch": 1.1475789403040166,
      "eval_bleu": 20.400536431756866,
      "eval_gen_len": 28.74,
      "eval_loss": 2.9596290588378906,
      "eval_runtime": 58.6324,
      "eval_samples_per_second": 17.055,
      "eval_steps_per_second": 1.074,
      "step": 17100
    },
    {
      "epoch": 1.1482500587228617,
      "grad_norm": 0.7074404358863831,
      "learning_rate": 0.00014154569519075067,
      "loss": 2.5106,
      "step": 17110
    },
    {
      "epoch": 1.1489211771417067,
      "grad_norm": 0.7013163566589355,
      "learning_rate": 0.00014147978099157143,
      "loss": 2.538,
      "step": 17120
    },
    {
      "epoch": 1.1495922955605518,
      "grad_norm": 0.6977388858795166,
      "learning_rate": 0.00014141384501842306,
      "loss": 2.4124,
      "step": 17130
    },
    {
      "epoch": 1.1502634139793966,
      "grad_norm": 0.6722865104675293,
      "learning_rate": 0.00014134788730591735,
      "loss": 2.4742,
      "step": 17140
    },
    {
      "epoch": 1.1509345323982416,
      "grad_norm": 0.6909911036491394,
      "learning_rate": 0.00014128190788867748,
      "loss": 2.5365,
      "step": 17150
    },
    {
      "epoch": 1.1509345323982416,
      "eval_bleu": 20.77495817433579,
      "eval_gen_len": 28.873,
      "eval_loss": 2.947192430496216,
      "eval_runtime": 58.0463,
      "eval_samples_per_second": 17.228,
      "eval_steps_per_second": 1.085,
      "step": 17150
    },
    {
      "epoch": 1.1516056508170867,
      "grad_norm": 0.661784827709198,
      "learning_rate": 0.00014121590680133794,
      "loss": 2.4895,
      "step": 17160
    },
    {
      "epoch": 1.1522767692359317,
      "grad_norm": 0.6054470539093018,
      "learning_rate": 0.00014114988407854472,
      "loss": 2.4887,
      "step": 17170
    },
    {
      "epoch": 1.1529478876547767,
      "grad_norm": 0.7064305543899536,
      "learning_rate": 0.0001410838397549551,
      "loss": 2.5144,
      "step": 17180
    },
    {
      "epoch": 1.1536190060736218,
      "grad_norm": 0.7098108530044556,
      "learning_rate": 0.0001410177738652377,
      "loss": 2.5078,
      "step": 17190
    },
    {
      "epoch": 1.1542901244924666,
      "grad_norm": 0.6953929662704468,
      "learning_rate": 0.00014095168644407243,
      "loss": 2.4847,
      "step": 17200
    },
    {
      "epoch": 1.1542901244924666,
      "eval_bleu": 20.84680218217341,
      "eval_gen_len": 28.884,
      "eval_loss": 2.9419238567352295,
      "eval_runtime": 58.6774,
      "eval_samples_per_second": 17.042,
      "eval_steps_per_second": 1.074,
      "step": 17200
    },
    {
      "epoch": 1.1549612429113116,
      "grad_norm": 0.7830110788345337,
      "learning_rate": 0.00014088557752615062,
      "loss": 2.5124,
      "step": 17210
    },
    {
      "epoch": 1.1556323613301567,
      "grad_norm": 0.7106044888496399,
      "learning_rate": 0.00014081944714617475,
      "loss": 2.4624,
      "step": 17220
    },
    {
      "epoch": 1.1563034797490017,
      "grad_norm": 0.6818180680274963,
      "learning_rate": 0.00014075329533885862,
      "loss": 2.4753,
      "step": 17230
    },
    {
      "epoch": 1.1569745981678468,
      "grad_norm": 0.6612021327018738,
      "learning_rate": 0.0001406871221389273,
      "loss": 2.5039,
      "step": 17240
    },
    {
      "epoch": 1.1576457165866918,
      "grad_norm": 0.703123152256012,
      "learning_rate": 0.00014062092758111705,
      "loss": 2.5152,
      "step": 17250
    },
    {
      "epoch": 1.1576457165866918,
      "eval_bleu": 20.78548026606329,
      "eval_gen_len": 28.983,
      "eval_loss": 2.9454867839813232,
      "eval_runtime": 58.6309,
      "eval_samples_per_second": 17.056,
      "eval_steps_per_second": 1.075,
      "step": 17250
    },
    {
      "epoch": 1.1583168350055368,
      "grad_norm": 0.6671294569969177,
      "learning_rate": 0.00014055471170017537,
      "loss": 2.4677,
      "step": 17260
    },
    {
      "epoch": 1.1589879534243817,
      "grad_norm": 0.7000644207000732,
      "learning_rate": 0.00014048847453086095,
      "loss": 2.5089,
      "step": 17270
    },
    {
      "epoch": 1.1596590718432267,
      "grad_norm": 0.6573365330696106,
      "learning_rate": 0.0001404222161079436,
      "loss": 2.4703,
      "step": 17280
    },
    {
      "epoch": 1.1603301902620717,
      "grad_norm": 0.7069681882858276,
      "learning_rate": 0.0001403559364662044,
      "loss": 2.5386,
      "step": 17290
    },
    {
      "epoch": 1.1610013086809168,
      "grad_norm": 0.7493364810943604,
      "learning_rate": 0.00014028963564043548,
      "loss": 2.4676,
      "step": 17300
    },
    {
      "epoch": 1.1610013086809168,
      "eval_bleu": 20.907875686454926,
      "eval_gen_len": 28.759,
      "eval_loss": 2.947139024734497,
      "eval_runtime": 58.1221,
      "eval_samples_per_second": 17.205,
      "eval_steps_per_second": 1.084,
      "step": 17300
    },
    {
      "epoch": 1.1616724270997618,
      "grad_norm": 0.7440763115882874,
      "learning_rate": 0.00014022331366544006,
      "loss": 2.486,
      "step": 17310
    },
    {
      "epoch": 1.1623435455186066,
      "grad_norm": 0.6300789713859558,
      "learning_rate": 0.00014015697057603263,
      "loss": 2.518,
      "step": 17320
    },
    {
      "epoch": 1.1630146639374517,
      "grad_norm": 0.7068043351173401,
      "learning_rate": 0.00014009060640703854,
      "loss": 2.4604,
      "step": 17330
    },
    {
      "epoch": 1.1636857823562967,
      "grad_norm": 0.6835677027702332,
      "learning_rate": 0.00014002422119329438,
      "loss": 2.5063,
      "step": 17340
    },
    {
      "epoch": 1.1643569007751418,
      "grad_norm": 0.6761711835861206,
      "learning_rate": 0.00013995781496964766,
      "loss": 2.4921,
      "step": 17350
    },
    {
      "epoch": 1.1643569007751418,
      "eval_bleu": 20.7359589821031,
      "eval_gen_len": 28.8,
      "eval_loss": 2.9512076377868652,
      "eval_runtime": 58.6563,
      "eval_samples_per_second": 17.048,
      "eval_steps_per_second": 1.074,
      "step": 17350
    },
    {
      "epoch": 1.1650280191939868,
      "grad_norm": 0.7493313550949097,
      "learning_rate": 0.00013989138777095706,
      "loss": 2.4899,
      "step": 17360
    },
    {
      "epoch": 1.1656991376128318,
      "grad_norm": 0.6738379597663879,
      "learning_rate": 0.00013982493963209209,
      "loss": 2.5185,
      "step": 17370
    },
    {
      "epoch": 1.1663702560316769,
      "grad_norm": 0.648541271686554,
      "learning_rate": 0.00013975847058793342,
      "loss": 2.4862,
      "step": 17380
    },
    {
      "epoch": 1.167041374450522,
      "grad_norm": 0.6906835436820984,
      "learning_rate": 0.00013969198067337261,
      "loss": 2.4342,
      "step": 17390
    },
    {
      "epoch": 1.1677124928693667,
      "grad_norm": 0.6945260763168335,
      "learning_rate": 0.00013962546992331222,
      "loss": 2.4975,
      "step": 17400
    },
    {
      "epoch": 1.1677124928693667,
      "eval_bleu": 20.90916805027284,
      "eval_gen_len": 28.833,
      "eval_loss": 2.9482901096343994,
      "eval_runtime": 58.4569,
      "eval_samples_per_second": 17.107,
      "eval_steps_per_second": 1.078,
      "step": 17400
    },
    {
      "epoch": 1.1683836112882118,
      "grad_norm": 0.7073487639427185,
      "learning_rate": 0.0001395589383726657,
      "loss": 2.4264,
      "step": 17410
    },
    {
      "epoch": 1.1690547297070568,
      "grad_norm": 0.6067776679992676,
      "learning_rate": 0.00013949238605635736,
      "loss": 2.4191,
      "step": 17420
    },
    {
      "epoch": 1.1697258481259019,
      "grad_norm": 0.6527338624000549,
      "learning_rate": 0.0001394258130093226,
      "loss": 2.5126,
      "step": 17430
    },
    {
      "epoch": 1.170396966544747,
      "grad_norm": 0.6640025973320007,
      "learning_rate": 0.00013935921926650754,
      "loss": 2.5547,
      "step": 17440
    },
    {
      "epoch": 1.1710680849635917,
      "grad_norm": 0.7170712947845459,
      "learning_rate": 0.0001392926048628692,
      "loss": 2.5157,
      "step": 17450
    },
    {
      "epoch": 1.1710680849635917,
      "eval_bleu": 20.83515301109728,
      "eval_gen_len": 29.146,
      "eval_loss": 2.938824415206909,
      "eval_runtime": 62.0767,
      "eval_samples_per_second": 16.109,
      "eval_steps_per_second": 1.015,
      "step": 17450
    },
    {
      "epoch": 1.1717392033824368,
      "grad_norm": 0.626526951789856,
      "learning_rate": 0.0001392259698333755,
      "loss": 2.5006,
      "step": 17460
    },
    {
      "epoch": 1.1724103218012818,
      "grad_norm": 0.6794134378433228,
      "learning_rate": 0.00013915931421300512,
      "loss": 2.4809,
      "step": 17470
    },
    {
      "epoch": 1.1730814402201268,
      "grad_norm": 0.7304925918579102,
      "learning_rate": 0.00013909263803674757,
      "loss": 2.4616,
      "step": 17480
    },
    {
      "epoch": 1.1737525586389719,
      "grad_norm": 0.693101704120636,
      "learning_rate": 0.00013902594133960314,
      "loss": 2.4994,
      "step": 17490
    },
    {
      "epoch": 1.174423677057817,
      "grad_norm": 0.7210209965705872,
      "learning_rate": 0.00013895922415658297,
      "loss": 2.466,
      "step": 17500
    },
    {
      "epoch": 1.174423677057817,
      "eval_bleu": 20.779369140027356,
      "eval_gen_len": 28.919,
      "eval_loss": 2.946207284927368,
      "eval_runtime": 58.7574,
      "eval_samples_per_second": 17.019,
      "eval_steps_per_second": 1.072,
      "step": 17500
    },
    {
      "epoch": 1.175094795476662,
      "grad_norm": 0.7246314883232117,
      "learning_rate": 0.00013889248652270884,
      "loss": 2.4927,
      "step": 17510
    },
    {
      "epoch": 1.1757659138955068,
      "grad_norm": 0.6614384055137634,
      "learning_rate": 0.00013882572847301333,
      "loss": 2.4706,
      "step": 17520
    },
    {
      "epoch": 1.1764370323143518,
      "grad_norm": 0.6427684426307678,
      "learning_rate": 0.0001387589500425397,
      "loss": 2.4812,
      "step": 17530
    },
    {
      "epoch": 1.1771081507331969,
      "grad_norm": 0.6715339422225952,
      "learning_rate": 0.00013869215126634197,
      "loss": 2.4761,
      "step": 17540
    },
    {
      "epoch": 1.177779269152042,
      "grad_norm": 0.7081024050712585,
      "learning_rate": 0.00013862533217948476,
      "loss": 2.4782,
      "step": 17550
    },
    {
      "epoch": 1.177779269152042,
      "eval_bleu": 21.232425573540784,
      "eval_gen_len": 28.892,
      "eval_loss": 2.9392573833465576,
      "eval_runtime": 58.706,
      "eval_samples_per_second": 17.034,
      "eval_steps_per_second": 1.073,
      "step": 17550
    },
    {
      "epoch": 1.178450387570887,
      "grad_norm": 0.6911357641220093,
      "learning_rate": 0.00013855849281704344,
      "loss": 2.4921,
      "step": 17560
    },
    {
      "epoch": 1.179121505989732,
      "grad_norm": 0.6913990378379822,
      "learning_rate": 0.00013849163321410395,
      "loss": 2.5374,
      "step": 17570
    },
    {
      "epoch": 1.1797926244085768,
      "grad_norm": 0.661544680595398,
      "learning_rate": 0.0001384247534057629,
      "loss": 2.4975,
      "step": 17580
    },
    {
      "epoch": 1.1804637428274218,
      "grad_norm": 0.6887455582618713,
      "learning_rate": 0.00013835785342712747,
      "loss": 2.4482,
      "step": 17590
    },
    {
      "epoch": 1.1811348612462669,
      "grad_norm": 0.7038236260414124,
      "learning_rate": 0.00013829093331331545,
      "loss": 2.4729,
      "step": 17600
    },
    {
      "epoch": 1.1811348612462669,
      "eval_bleu": 21.03382597723626,
      "eval_gen_len": 29.053,
      "eval_loss": 2.942314863204956,
      "eval_runtime": 62.4874,
      "eval_samples_per_second": 16.003,
      "eval_steps_per_second": 1.008,
      "step": 17600
    },
    {
      "epoch": 1.181805979665112,
      "grad_norm": 0.7092055082321167,
      "learning_rate": 0.00013822399309945516,
      "loss": 2.5506,
      "step": 17610
    },
    {
      "epoch": 1.182477098083957,
      "grad_norm": 0.6490100026130676,
      "learning_rate": 0.0001381570328206856,
      "loss": 2.5037,
      "step": 17620
    },
    {
      "epoch": 1.183148216502802,
      "grad_norm": 0.6979042887687683,
      "learning_rate": 0.0001380900525121561,
      "loss": 2.4808,
      "step": 17630
    },
    {
      "epoch": 1.183819334921647,
      "grad_norm": 0.6031008362770081,
      "learning_rate": 0.0001380230522090267,
      "loss": 2.5044,
      "step": 17640
    },
    {
      "epoch": 1.1844904533404919,
      "grad_norm": 0.6038902401924133,
      "learning_rate": 0.0001379560319464678,
      "loss": 2.4633,
      "step": 17650
    },
    {
      "epoch": 1.1844904533404919,
      "eval_bleu": 20.851084789278488,
      "eval_gen_len": 29.027,
      "eval_loss": 2.9426796436309814,
      "eval_runtime": 62.6186,
      "eval_samples_per_second": 15.97,
      "eval_steps_per_second": 1.006,
      "step": 17650
    },
    {
      "epoch": 1.185161571759337,
      "grad_norm": 0.6552256345748901,
      "learning_rate": 0.00013788899175966034,
      "loss": 2.5268,
      "step": 17660
    },
    {
      "epoch": 1.185832690178182,
      "grad_norm": 0.7054794430732727,
      "learning_rate": 0.00013782193168379573,
      "loss": 2.4597,
      "step": 17670
    },
    {
      "epoch": 1.186503808597027,
      "grad_norm": 0.7279176712036133,
      "learning_rate": 0.0001377548517540757,
      "loss": 2.483,
      "step": 17680
    },
    {
      "epoch": 1.187174927015872,
      "grad_norm": 0.6601889133453369,
      "learning_rate": 0.00013768775200571264,
      "loss": 2.4733,
      "step": 17690
    },
    {
      "epoch": 1.1878460454347168,
      "grad_norm": 0.6807998418807983,
      "learning_rate": 0.00013762063247392908,
      "loss": 2.4383,
      "step": 17700
    },
    {
      "epoch": 1.1878460454347168,
      "eval_bleu": 20.753008069047485,
      "eval_gen_len": 28.978,
      "eval_loss": 2.943054437637329,
      "eval_runtime": 62.731,
      "eval_samples_per_second": 15.941,
      "eval_steps_per_second": 1.004,
      "step": 17700
    },
    {
      "epoch": 1.1885171638535619,
      "grad_norm": 0.7264143228530884,
      "learning_rate": 0.00013755349319395817,
      "loss": 2.4847,
      "step": 17710
    },
    {
      "epoch": 1.189188282272407,
      "grad_norm": 0.624824583530426,
      "learning_rate": 0.00013748633420104323,
      "loss": 2.4413,
      "step": 17720
    },
    {
      "epoch": 1.189859400691252,
      "grad_norm": 0.7815672159194946,
      "learning_rate": 0.00013741915553043798,
      "loss": 2.5128,
      "step": 17730
    },
    {
      "epoch": 1.190530519110097,
      "grad_norm": 0.7128347754478455,
      "learning_rate": 0.00013735195721740657,
      "loss": 2.4895,
      "step": 17740
    },
    {
      "epoch": 1.191201637528942,
      "grad_norm": 0.6761473417282104,
      "learning_rate": 0.00013728473929722337,
      "loss": 2.5013,
      "step": 17750
    },
    {
      "epoch": 1.191201637528942,
      "eval_bleu": 20.723456299512904,
      "eval_gen_len": 28.852,
      "eval_loss": 2.9449474811553955,
      "eval_runtime": 59.103,
      "eval_samples_per_second": 16.92,
      "eval_steps_per_second": 1.066,
      "step": 17750
    },
    {
      "epoch": 1.191872755947787,
      "grad_norm": 0.6366126537322998,
      "learning_rate": 0.00013721750180517304,
      "loss": 2.4686,
      "step": 17760
    },
    {
      "epoch": 1.192543874366632,
      "grad_norm": 0.7407619953155518,
      "learning_rate": 0.00013715024477655062,
      "loss": 2.4683,
      "step": 17770
    },
    {
      "epoch": 1.193214992785477,
      "grad_norm": 0.7167978882789612,
      "learning_rate": 0.0001370829682466612,
      "loss": 2.5237,
      "step": 17780
    },
    {
      "epoch": 1.193886111204322,
      "grad_norm": 0.634273886680603,
      "learning_rate": 0.00013701567225082032,
      "loss": 2.4605,
      "step": 17790
    },
    {
      "epoch": 1.194557229623167,
      "grad_norm": 0.7230899930000305,
      "learning_rate": 0.00013694835682435358,
      "loss": 2.4767,
      "step": 17800
    },
    {
      "epoch": 1.194557229623167,
      "eval_bleu": 21.144282737067627,
      "eval_gen_len": 28.862,
      "eval_loss": 2.9369113445281982,
      "eval_runtime": 59.8107,
      "eval_samples_per_second": 16.719,
      "eval_steps_per_second": 1.053,
      "step": 17800
    },
    {
      "epoch": 1.195228348042012,
      "grad_norm": 0.6746227145195007,
      "learning_rate": 0.00013688102200259695,
      "loss": 2.4915,
      "step": 17810
    },
    {
      "epoch": 1.195899466460857,
      "grad_norm": 0.7341448068618774,
      "learning_rate": 0.00013681366782089635,
      "loss": 2.4543,
      "step": 17820
    },
    {
      "epoch": 1.196570584879702,
      "grad_norm": 0.7114641666412354,
      "learning_rate": 0.00013674629431460807,
      "loss": 2.4978,
      "step": 17830
    },
    {
      "epoch": 1.197241703298547,
      "grad_norm": 0.6819760203361511,
      "learning_rate": 0.00013667890151909844,
      "loss": 2.5014,
      "step": 17840
    },
    {
      "epoch": 1.197912821717392,
      "grad_norm": 0.7409584522247314,
      "learning_rate": 0.00013661148946974395,
      "loss": 2.482,
      "step": 17850
    },
    {
      "epoch": 1.197912821717392,
      "eval_bleu": 21.088170650998876,
      "eval_gen_len": 29.153,
      "eval_loss": 2.936971426010132,
      "eval_runtime": 62.2246,
      "eval_samples_per_second": 16.071,
      "eval_steps_per_second": 1.012,
      "step": 17850
    },
    {
      "epoch": 1.198583940136237,
      "grad_norm": 0.730045735836029,
      "learning_rate": 0.00013654405820193118,
      "loss": 2.4545,
      "step": 17860
    },
    {
      "epoch": 1.199255058555082,
      "grad_norm": 0.665809690952301,
      "learning_rate": 0.0001364766077510568,
      "loss": 2.429,
      "step": 17870
    },
    {
      "epoch": 1.1999261769739271,
      "grad_norm": 0.7740731835365295,
      "learning_rate": 0.00013640913815252757,
      "loss": 2.4888,
      "step": 17880
    },
    {
      "epoch": 1.2005972953927722,
      "grad_norm": 0.6560474634170532,
      "learning_rate": 0.0001363416494417603,
      "loss": 2.5076,
      "step": 17890
    },
    {
      "epoch": 1.201268413811617,
      "grad_norm": 0.740407407283783,
      "learning_rate": 0.00013627414165418174,
      "loss": 2.4845,
      "step": 17900
    },
    {
      "epoch": 1.201268413811617,
      "eval_bleu": 20.8482704188699,
      "eval_gen_len": 28.757,
      "eval_loss": 2.9452106952667236,
      "eval_runtime": 58.7403,
      "eval_samples_per_second": 17.024,
      "eval_steps_per_second": 1.073,
      "step": 17900
    },
    {
      "epoch": 1.201939532230462,
      "grad_norm": 0.6520513296127319,
      "learning_rate": 0.00013620661482522883,
      "loss": 2.4753,
      "step": 17910
    },
    {
      "epoch": 1.202610650649307,
      "grad_norm": 0.6713753938674927,
      "learning_rate": 0.0001361390689903484,
      "loss": 2.473,
      "step": 17920
    },
    {
      "epoch": 1.203281769068152,
      "grad_norm": 0.6539899706840515,
      "learning_rate": 0.00013607150418499717,
      "loss": 2.4785,
      "step": 17930
    },
    {
      "epoch": 1.2039528874869971,
      "grad_norm": 0.6445999145507812,
      "learning_rate": 0.00013600392044464202,
      "loss": 2.4834,
      "step": 17940
    },
    {
      "epoch": 1.2046240059058422,
      "grad_norm": 0.6254945993423462,
      "learning_rate": 0.0001359363178047596,
      "loss": 2.4684,
      "step": 17950
    },
    {
      "epoch": 1.2046240059058422,
      "eval_bleu": 20.66303673258576,
      "eval_gen_len": 28.729,
      "eval_loss": 2.946936845779419,
      "eval_runtime": 58.8653,
      "eval_samples_per_second": 16.988,
      "eval_steps_per_second": 1.07,
      "step": 17950
    },
    {
      "epoch": 1.205295124324687,
      "grad_norm": 0.7343749403953552,
      "learning_rate": 0.00013586869630083658,
      "loss": 2.4771,
      "step": 17960
    },
    {
      "epoch": 1.205966242743532,
      "grad_norm": 0.6682496070861816,
      "learning_rate": 0.00013580105596836946,
      "loss": 2.4488,
      "step": 17970
    },
    {
      "epoch": 1.206637361162377,
      "grad_norm": 0.695009708404541,
      "learning_rate": 0.00013573339684286472,
      "loss": 2.528,
      "step": 17980
    },
    {
      "epoch": 1.2073084795812221,
      "grad_norm": 0.675614058971405,
      "learning_rate": 0.00013566571895983856,
      "loss": 2.5051,
      "step": 17990
    },
    {
      "epoch": 1.2079795980000672,
      "grad_norm": 0.6305761337280273,
      "learning_rate": 0.0001355980223548172,
      "loss": 2.499,
      "step": 18000
    },
    {
      "epoch": 1.2079795980000672,
      "eval_bleu": 21.243579646899565,
      "eval_gen_len": 28.836,
      "eval_loss": 2.9414613246917725,
      "eval_runtime": 59.3283,
      "eval_samples_per_second": 16.855,
      "eval_steps_per_second": 1.062,
      "step": 18000
    },
    {
      "epoch": 1.2086507164189122,
      "grad_norm": 0.6476386189460754,
      "learning_rate": 0.0001355303070633365,
      "loss": 2.492,
      "step": 18010
    },
    {
      "epoch": 1.2093218348377572,
      "grad_norm": 0.7314913272857666,
      "learning_rate": 0.00013546257312094232,
      "loss": 2.4501,
      "step": 18020
    },
    {
      "epoch": 1.209992953256602,
      "grad_norm": 0.743354320526123,
      "learning_rate": 0.0001353948205631902,
      "loss": 2.5037,
      "step": 18030
    },
    {
      "epoch": 1.210664071675447,
      "grad_norm": 0.704464316368103,
      "learning_rate": 0.0001353270494256454,
      "loss": 2.512,
      "step": 18040
    },
    {
      "epoch": 1.2113351900942921,
      "grad_norm": 0.7163812518119812,
      "learning_rate": 0.00013525925974388307,
      "loss": 2.4834,
      "step": 18050
    },
    {
      "epoch": 1.2113351900942921,
      "eval_bleu": 20.99592541189454,
      "eval_gen_len": 28.874,
      "eval_loss": 2.9410400390625,
      "eval_runtime": 58.782,
      "eval_samples_per_second": 17.012,
      "eval_steps_per_second": 1.072,
      "step": 18050
    },
    {
      "epoch": 1.2120063085131372,
      "grad_norm": 0.6399991512298584,
      "learning_rate": 0.00013519145155348802,
      "loss": 2.4658,
      "step": 18060
    },
    {
      "epoch": 1.2126774269319822,
      "grad_norm": 0.685876190662384,
      "learning_rate": 0.00013512362489005475,
      "loss": 2.4857,
      "step": 18070
    },
    {
      "epoch": 1.213348545350827,
      "grad_norm": 0.7167141437530518,
      "learning_rate": 0.00013505577978918754,
      "loss": 2.4732,
      "step": 18080
    },
    {
      "epoch": 1.214019663769672,
      "grad_norm": 0.627399742603302,
      "learning_rate": 0.00013498791628650025,
      "loss": 2.4317,
      "step": 18090
    },
    {
      "epoch": 1.2146907821885171,
      "grad_norm": 0.6911934614181519,
      "learning_rate": 0.00013492003441761648,
      "loss": 2.5115,
      "step": 18100
    },
    {
      "epoch": 1.2146907821885171,
      "eval_bleu": 20.656518863041004,
      "eval_gen_len": 28.98,
      "eval_loss": 2.9427192211151123,
      "eval_runtime": 60.039,
      "eval_samples_per_second": 16.656,
      "eval_steps_per_second": 1.049,
      "step": 18100
    },
    {
      "epoch": 1.2153619006073622,
      "grad_norm": 0.6926048994064331,
      "learning_rate": 0.00013485213421816943,
      "loss": 2.4345,
      "step": 18110
    },
    {
      "epoch": 1.2160330190262072,
      "grad_norm": 0.6640596985816956,
      "learning_rate": 0.00013478421572380193,
      "loss": 2.478,
      "step": 18120
    },
    {
      "epoch": 1.2167041374450522,
      "grad_norm": 0.719387948513031,
      "learning_rate": 0.00013471627897016641,
      "loss": 2.4673,
      "step": 18130
    },
    {
      "epoch": 1.2173752558638973,
      "grad_norm": 0.6997013688087463,
      "learning_rate": 0.0001346483239929249,
      "loss": 2.5243,
      "step": 18140
    },
    {
      "epoch": 1.218046374282742,
      "grad_norm": 0.6921172142028809,
      "learning_rate": 0.00013458035082774902,
      "loss": 2.4975,
      "step": 18150
    },
    {
      "epoch": 1.218046374282742,
      "eval_bleu": 21.148235944496665,
      "eval_gen_len": 28.86,
      "eval_loss": 2.9409003257751465,
      "eval_runtime": 59.6856,
      "eval_samples_per_second": 16.754,
      "eval_steps_per_second": 1.056,
      "step": 18150
    },
    {
      "epoch": 1.2187174927015871,
      "grad_norm": 0.7091541886329651,
      "learning_rate": 0.00013451235951031983,
      "loss": 2.4813,
      "step": 18160
    },
    {
      "epoch": 1.2193886111204322,
      "grad_norm": 0.6452171802520752,
      "learning_rate": 0.000134444350076328,
      "loss": 2.5031,
      "step": 18170
    },
    {
      "epoch": 1.2200597295392772,
      "grad_norm": 0.7050647735595703,
      "learning_rate": 0.00013437632256147378,
      "loss": 2.4566,
      "step": 18180
    },
    {
      "epoch": 1.2207308479581223,
      "grad_norm": 0.7088150978088379,
      "learning_rate": 0.00013430827700146674,
      "loss": 2.5137,
      "step": 18190
    },
    {
      "epoch": 1.2214019663769673,
      "grad_norm": 0.7238883376121521,
      "learning_rate": 0.0001342402134320261,
      "loss": 2.5137,
      "step": 18200
    },
    {
      "epoch": 1.2214019663769673,
      "eval_bleu": 21.035694641921438,
      "eval_gen_len": 28.993,
      "eval_loss": 2.9394774436950684,
      "eval_runtime": 59.3791,
      "eval_samples_per_second": 16.841,
      "eval_steps_per_second": 1.061,
      "step": 18200
    },
    {
      "epoch": 1.2220730847958121,
      "grad_norm": 0.6916296482086182,
      "learning_rate": 0.00013417213188888038,
      "loss": 2.4898,
      "step": 18210
    },
    {
      "epoch": 1.2227442032146572,
      "grad_norm": 0.7013218402862549,
      "learning_rate": 0.00013410403240776762,
      "loss": 2.4463,
      "step": 18220
    },
    {
      "epoch": 1.2234153216335022,
      "grad_norm": 0.7618667483329773,
      "learning_rate": 0.0001340359150244353,
      "loss": 2.5278,
      "step": 18230
    },
    {
      "epoch": 1.2240864400523472,
      "grad_norm": 0.736149787902832,
      "learning_rate": 0.00013396777977464023,
      "loss": 2.4886,
      "step": 18240
    },
    {
      "epoch": 1.2247575584711923,
      "grad_norm": 0.6825673580169678,
      "learning_rate": 0.00013389962669414863,
      "loss": 2.4602,
      "step": 18250
    },
    {
      "epoch": 1.2247575584711923,
      "eval_bleu": 21.144587918155093,
      "eval_gen_len": 28.844,
      "eval_loss": 2.940114736557007,
      "eval_runtime": 60.386,
      "eval_samples_per_second": 16.56,
      "eval_steps_per_second": 1.043,
      "step": 18250
    },
    {
      "epoch": 1.2254286768900373,
      "grad_norm": 0.6547885537147522,
      "learning_rate": 0.00013383145581873605,
      "loss": 2.4226,
      "step": 18260
    },
    {
      "epoch": 1.2260997953088824,
      "grad_norm": 0.6587986946105957,
      "learning_rate": 0.00013376326718418744,
      "loss": 2.4507,
      "step": 18270
    },
    {
      "epoch": 1.2267709137277272,
      "grad_norm": 0.7131261825561523,
      "learning_rate": 0.00013369506082629704,
      "loss": 2.5037,
      "step": 18280
    },
    {
      "epoch": 1.2274420321465722,
      "grad_norm": 0.6515269875526428,
      "learning_rate": 0.0001336268367808684,
      "loss": 2.5078,
      "step": 18290
    },
    {
      "epoch": 1.2281131505654173,
      "grad_norm": 0.736035168170929,
      "learning_rate": 0.0001335585950837143,
      "loss": 2.5155,
      "step": 18300
    },
    {
      "epoch": 1.2281131505654173,
      "eval_bleu": 21.057009275515515,
      "eval_gen_len": 28.845,
      "eval_loss": 2.9406304359436035,
      "eval_runtime": 61.5641,
      "eval_samples_per_second": 16.243,
      "eval_steps_per_second": 1.023,
      "step": 18300
    },
    {
      "epoch": 1.2287842689842623,
      "grad_norm": 0.661762535572052,
      "learning_rate": 0.00013349033577065685,
      "loss": 2.45,
      "step": 18310
    },
    {
      "epoch": 1.2294553874031073,
      "grad_norm": 0.6875168681144714,
      "learning_rate": 0.00013342205887752743,
      "loss": 2.5192,
      "step": 18320
    },
    {
      "epoch": 1.2301265058219524,
      "grad_norm": 0.6127507090568542,
      "learning_rate": 0.00013335376444016659,
      "loss": 2.4667,
      "step": 18330
    },
    {
      "epoch": 1.2307976242407972,
      "grad_norm": 0.6608520746231079,
      "learning_rate": 0.00013328545249442411,
      "loss": 2.4889,
      "step": 18340
    },
    {
      "epoch": 1.2314687426596422,
      "grad_norm": 0.6436412334442139,
      "learning_rate": 0.00013321712307615892,
      "loss": 2.5192,
      "step": 18350
    },
    {
      "epoch": 1.2314687426596422,
      "eval_bleu": 21.35105737219259,
      "eval_gen_len": 28.968,
      "eval_loss": 2.9392893314361572,
      "eval_runtime": 61.375,
      "eval_samples_per_second": 16.293,
      "eval_steps_per_second": 1.026,
      "step": 18350
    },
    {
      "epoch": 1.2321398610784873,
      "grad_norm": 0.6752676963806152,
      "learning_rate": 0.0001331487762212392,
      "loss": 2.478,
      "step": 18360
    },
    {
      "epoch": 1.2328109794973323,
      "grad_norm": 0.7156247496604919,
      "learning_rate": 0.00013308041196554227,
      "loss": 2.5524,
      "step": 18370
    },
    {
      "epoch": 1.2334820979161774,
      "grad_norm": 0.6837125420570374,
      "learning_rate": 0.00013301203034495447,
      "loss": 2.555,
      "step": 18380
    },
    {
      "epoch": 1.2341532163350224,
      "grad_norm": 0.7014709115028381,
      "learning_rate": 0.00013294363139537148,
      "loss": 2.4547,
      "step": 18390
    },
    {
      "epoch": 1.2348243347538674,
      "grad_norm": 0.6400542855262756,
      "learning_rate": 0.00013287521515269779,
      "loss": 2.4585,
      "step": 18400
    },
    {
      "epoch": 1.2348243347538674,
      "eval_bleu": 20.887014553206736,
      "eval_gen_len": 28.867,
      "eval_loss": 2.943476915359497,
      "eval_runtime": 62.0372,
      "eval_samples_per_second": 16.119,
      "eval_steps_per_second": 1.016,
      "step": 18400
    },
    {
      "epoch": 1.2354954531727123,
      "grad_norm": 0.749626874923706,
      "learning_rate": 0.0001328067816528472,
      "loss": 2.4931,
      "step": 18410
    },
    {
      "epoch": 1.2361665715915573,
      "grad_norm": 0.7251285910606384,
      "learning_rate": 0.0001327383309317425,
      "loss": 2.481,
      "step": 18420
    },
    {
      "epoch": 1.2368376900104023,
      "grad_norm": 0.6721609830856323,
      "learning_rate": 0.00013266986302531546,
      "loss": 2.4164,
      "step": 18430
    },
    {
      "epoch": 1.2375088084292474,
      "grad_norm": 0.6808569431304932,
      "learning_rate": 0.00013260137796950697,
      "loss": 2.489,
      "step": 18440
    },
    {
      "epoch": 1.2381799268480924,
      "grad_norm": 0.6873767375946045,
      "learning_rate": 0.00013253287580026682,
      "loss": 2.5041,
      "step": 18450
    },
    {
      "epoch": 1.2381799268480924,
      "eval_bleu": 21.44310443298556,
      "eval_gen_len": 28.881,
      "eval_loss": 2.9390506744384766,
      "eval_runtime": 61.3566,
      "eval_samples_per_second": 16.298,
      "eval_steps_per_second": 1.027,
      "step": 18450
    },
    {
      "epoch": 1.2388510452669372,
      "grad_norm": 0.6782805919647217,
      "learning_rate": 0.00013246435655355385,
      "loss": 2.4764,
      "step": 18460
    },
    {
      "epoch": 1.2395221636857823,
      "grad_norm": 0.6415431499481201,
      "learning_rate": 0.00013239582026533585,
      "loss": 2.4579,
      "step": 18470
    },
    {
      "epoch": 1.2401932821046273,
      "grad_norm": 0.6301953792572021,
      "learning_rate": 0.00013232726697158957,
      "loss": 2.4502,
      "step": 18480
    },
    {
      "epoch": 1.2408644005234724,
      "grad_norm": 0.6682009100914001,
      "learning_rate": 0.00013225869670830062,
      "loss": 2.5208,
      "step": 18490
    },
    {
      "epoch": 1.2415355189423174,
      "grad_norm": 0.706001341342926,
      "learning_rate": 0.0001321901095114636,
      "loss": 2.4863,
      "step": 18500
    },
    {
      "epoch": 1.2415355189423174,
      "eval_bleu": 21.17050616148561,
      "eval_gen_len": 28.851,
      "eval_loss": 2.940200090408325,
      "eval_runtime": 61.8374,
      "eval_samples_per_second": 16.171,
      "eval_steps_per_second": 1.019,
      "step": 18500
    },
    {
      "epoch": 1.2422066373611624,
      "grad_norm": 0.7018498778343201,
      "learning_rate": 0.000132121505417082,
      "loss": 2.4628,
      "step": 18510
    },
    {
      "epoch": 1.2428777557800075,
      "grad_norm": 0.710589587688446,
      "learning_rate": 0.00013205288446116814,
      "loss": 2.5016,
      "step": 18520
    },
    {
      "epoch": 1.2435488741988523,
      "grad_norm": 0.6834880709648132,
      "learning_rate": 0.00013198424667974315,
      "loss": 2.4343,
      "step": 18530
    },
    {
      "epoch": 1.2442199926176973,
      "grad_norm": 0.7009046673774719,
      "learning_rate": 0.00013191559210883703,
      "loss": 2.4527,
      "step": 18540
    },
    {
      "epoch": 1.2448911110365424,
      "grad_norm": 0.6859959363937378,
      "learning_rate": 0.00013184692078448867,
      "loss": 2.4985,
      "step": 18550
    },
    {
      "epoch": 1.2448911110365424,
      "eval_bleu": 21.030254927769796,
      "eval_gen_len": 28.883,
      "eval_loss": 2.9400014877319336,
      "eval_runtime": 61.3925,
      "eval_samples_per_second": 16.289,
      "eval_steps_per_second": 1.026,
      "step": 18550
    },
    {
      "epoch": 1.2455622294553874,
      "grad_norm": 0.7143781781196594,
      "learning_rate": 0.00013177823274274566,
      "loss": 2.5184,
      "step": 18560
    },
    {
      "epoch": 1.2462333478742325,
      "grad_norm": 0.6830200552940369,
      "learning_rate": 0.00013170952801966435,
      "loss": 2.4998,
      "step": 18570
    },
    {
      "epoch": 1.2469044662930775,
      "grad_norm": 0.6675519943237305,
      "learning_rate": 0.00013164080665131,
      "loss": 2.4294,
      "step": 18580
    },
    {
      "epoch": 1.2475755847119223,
      "grad_norm": 0.6989952921867371,
      "learning_rate": 0.00013157206867375637,
      "loss": 2.4545,
      "step": 18590
    },
    {
      "epoch": 1.2482467031307674,
      "grad_norm": 0.7112772464752197,
      "learning_rate": 0.00013150331412308615,
      "loss": 2.4503,
      "step": 18600
    },
    {
      "epoch": 1.2482467031307674,
      "eval_bleu": 21.55842853013049,
      "eval_gen_len": 28.924,
      "eval_loss": 2.9355216026306152,
      "eval_runtime": 61.5562,
      "eval_samples_per_second": 16.245,
      "eval_steps_per_second": 1.023,
      "step": 18600
    },
    {
      "epoch": 1.2489178215496124,
      "grad_norm": 0.7469514608383179,
      "learning_rate": 0.0001314345430353906,
      "loss": 2.4809,
      "step": 18610
    },
    {
      "epoch": 1.2495889399684574,
      "grad_norm": 0.7162307500839233,
      "learning_rate": 0.00013136575544676972,
      "loss": 2.4852,
      "step": 18620
    },
    {
      "epoch": 1.2502600583873025,
      "grad_norm": 0.7005938291549683,
      "learning_rate": 0.00013129695139333216,
      "loss": 2.5115,
      "step": 18630
    },
    {
      "epoch": 1.2509311768061475,
      "grad_norm": 0.6875452995300293,
      "learning_rate": 0.0001312281309111952,
      "loss": 2.4411,
      "step": 18640
    },
    {
      "epoch": 1.2516022952249926,
      "grad_norm": 0.7061406970024109,
      "learning_rate": 0.00013115929403648483,
      "loss": 2.461,
      "step": 18650
    },
    {
      "epoch": 1.2516022952249926,
      "eval_bleu": 20.98872268799113,
      "eval_gen_len": 29.112,
      "eval_loss": 2.9410667419433594,
      "eval_runtime": 64.5749,
      "eval_samples_per_second": 15.486,
      "eval_steps_per_second": 0.976,
      "step": 18650
    },
    {
      "epoch": 1.2522734136438374,
      "grad_norm": 0.6497896313667297,
      "learning_rate": 0.00013109044080533545,
      "loss": 2.4797,
      "step": 18660
    },
    {
      "epoch": 1.2529445320626824,
      "grad_norm": 0.6433113813400269,
      "learning_rate": 0.00013102157125389024,
      "loss": 2.5138,
      "step": 18670
    },
    {
      "epoch": 1.2536156504815275,
      "grad_norm": 0.6614446043968201,
      "learning_rate": 0.00013095268541830088,
      "loss": 2.4899,
      "step": 18680
    },
    {
      "epoch": 1.2542867689003725,
      "grad_norm": 0.6983668208122253,
      "learning_rate": 0.00013088378333472755,
      "loss": 2.4893,
      "step": 18690
    },
    {
      "epoch": 1.2549578873192175,
      "grad_norm": 0.7137289047241211,
      "learning_rate": 0.00013081486503933905,
      "loss": 2.4564,
      "step": 18700
    },
    {
      "epoch": 1.2549578873192175,
      "eval_bleu": 21.288133355634844,
      "eval_gen_len": 28.879,
      "eval_loss": 2.9369595050811768,
      "eval_runtime": 61.7195,
      "eval_samples_per_second": 16.202,
      "eval_steps_per_second": 1.021,
      "step": 18700
    },
    {
      "epoch": 1.2556290057380624,
      "grad_norm": 0.6983040571212769,
      "learning_rate": 0.00013074593056831257,
      "loss": 2.4698,
      "step": 18710
    },
    {
      "epoch": 1.2563001241569074,
      "grad_norm": 0.6830811500549316,
      "learning_rate": 0.00013067697995783394,
      "loss": 2.489,
      "step": 18720
    },
    {
      "epoch": 1.2569712425757524,
      "grad_norm": 0.7009085416793823,
      "learning_rate": 0.0001306080132440973,
      "loss": 2.4757,
      "step": 18730
    },
    {
      "epoch": 1.2576423609945975,
      "grad_norm": 0.7627017498016357,
      "learning_rate": 0.0001305390304633054,
      "loss": 2.4821,
      "step": 18740
    },
    {
      "epoch": 1.2583134794134425,
      "grad_norm": 0.7053970694541931,
      "learning_rate": 0.00013047003165166934,
      "loss": 2.5011,
      "step": 18750
    },
    {
      "epoch": 1.2583134794134425,
      "eval_bleu": 21.466787917791926,
      "eval_gen_len": 28.954,
      "eval_loss": 2.938364267349243,
      "eval_runtime": 62.0461,
      "eval_samples_per_second": 16.117,
      "eval_steps_per_second": 1.015,
      "step": 18750
    },
    {
      "epoch": 1.2589845978322876,
      "grad_norm": 0.6606994271278381,
      "learning_rate": 0.00013040101684540857,
      "loss": 2.4505,
      "step": 18760
    },
    {
      "epoch": 1.2596557162511326,
      "grad_norm": 0.6389548778533936,
      "learning_rate": 0.00013033198608075112,
      "loss": 2.5192,
      "step": 18770
    },
    {
      "epoch": 1.2603268346699776,
      "grad_norm": 0.6823866963386536,
      "learning_rate": 0.00013026293939393324,
      "loss": 2.4379,
      "step": 18780
    },
    {
      "epoch": 1.2609979530888225,
      "grad_norm": 0.6068135499954224,
      "learning_rate": 0.00013019387682119957,
      "loss": 2.4807,
      "step": 18790
    },
    {
      "epoch": 1.2616690715076675,
      "grad_norm": 0.7212008237838745,
      "learning_rate": 0.00013012479839880311,
      "loss": 2.4434,
      "step": 18800
    },
    {
      "epoch": 1.2616690715076675,
      "eval_bleu": 20.923354921148402,
      "eval_gen_len": 28.856,
      "eval_loss": 2.94073486328125,
      "eval_runtime": 61.7537,
      "eval_samples_per_second": 16.193,
      "eval_steps_per_second": 1.02,
      "step": 18800
    },
    {
      "epoch": 1.2623401899265125,
      "grad_norm": 0.7004701495170593,
      "learning_rate": 0.00013005570416300518,
      "loss": 2.5173,
      "step": 18810
    },
    {
      "epoch": 1.2630113083453576,
      "grad_norm": 0.6795243620872498,
      "learning_rate": 0.00012998659415007542,
      "loss": 2.5205,
      "step": 18820
    },
    {
      "epoch": 1.2636824267642026,
      "grad_norm": 0.6613855957984924,
      "learning_rate": 0.00012991746839629176,
      "loss": 2.5433,
      "step": 18830
    },
    {
      "epoch": 1.2643535451830474,
      "grad_norm": 0.641643226146698,
      "learning_rate": 0.00012984832693794024,
      "loss": 2.4704,
      "step": 18840
    },
    {
      "epoch": 1.2650246636018925,
      "grad_norm": 0.7110932469367981,
      "learning_rate": 0.00012977916981131538,
      "loss": 2.4804,
      "step": 18850
    },
    {
      "epoch": 1.2650246636018925,
      "eval_bleu": 21.224778852229107,
      "eval_gen_len": 28.808,
      "eval_loss": 2.9388434886932373,
      "eval_runtime": 62.374,
      "eval_samples_per_second": 16.032,
      "eval_steps_per_second": 1.01,
      "step": 18850
    },
    {
      "epoch": 1.2656957820207375,
      "grad_norm": 0.6232795119285583,
      "learning_rate": 0.00012970999705271975,
      "loss": 2.4451,
      "step": 18860
    },
    {
      "epoch": 1.2663669004395826,
      "grad_norm": 0.6701889038085938,
      "learning_rate": 0.00012964080869846422,
      "loss": 2.4853,
      "step": 18870
    },
    {
      "epoch": 1.2670380188584276,
      "grad_norm": 0.6777746081352234,
      "learning_rate": 0.0001295716047848678,
      "loss": 2.5254,
      "step": 18880
    },
    {
      "epoch": 1.2677091372772726,
      "grad_norm": 0.6314952373504639,
      "learning_rate": 0.00012950238534825768,
      "loss": 2.4663,
      "step": 18890
    },
    {
      "epoch": 1.2683802556961177,
      "grad_norm": 0.8208017349243164,
      "learning_rate": 0.00012943315042496914,
      "loss": 2.5037,
      "step": 18900
    },
    {
      "epoch": 1.2683802556961177,
      "eval_bleu": 20.77890435682645,
      "eval_gen_len": 28.872,
      "eval_loss": 2.9442317485809326,
      "eval_runtime": 61.7153,
      "eval_samples_per_second": 16.203,
      "eval_steps_per_second": 1.021,
      "step": 18900
    },
    {
      "epoch": 1.2690513741149627,
      "grad_norm": 0.7361288070678711,
      "learning_rate": 0.00012936390005134575,
      "loss": 2.4871,
      "step": 18910
    },
    {
      "epoch": 1.2697224925338075,
      "grad_norm": 0.6930681467056274,
      "learning_rate": 0.00012929463426373904,
      "loss": 2.5047,
      "step": 18920
    },
    {
      "epoch": 1.2703936109526526,
      "grad_norm": 0.6709476709365845,
      "learning_rate": 0.00012922535309850867,
      "loss": 2.4591,
      "step": 18930
    },
    {
      "epoch": 1.2710647293714976,
      "grad_norm": 0.6680697798728943,
      "learning_rate": 0.0001291560565920224,
      "loss": 2.461,
      "step": 18940
    },
    {
      "epoch": 1.2717358477903427,
      "grad_norm": 0.6595565676689148,
      "learning_rate": 0.00012908674478065597,
      "loss": 2.4232,
      "step": 18950
    },
    {
      "epoch": 1.2717358477903427,
      "eval_bleu": 21.436348050939007,
      "eval_gen_len": 28.871,
      "eval_loss": 2.9375786781311035,
      "eval_runtime": 62.2893,
      "eval_samples_per_second": 16.054,
      "eval_steps_per_second": 1.011,
      "step": 18950
    },
    {
      "epoch": 1.2724069662091875,
      "grad_norm": 0.6689265966415405,
      "learning_rate": 0.00012901741770079332,
      "loss": 2.4625,
      "step": 18960
    },
    {
      "epoch": 1.2730780846280325,
      "grad_norm": 0.8019791841506958,
      "learning_rate": 0.0001289480753888262,
      "loss": 2.4786,
      "step": 18970
    },
    {
      "epoch": 1.2737492030468776,
      "grad_norm": 0.688242495059967,
      "learning_rate": 0.00012887871788115447,
      "loss": 2.4741,
      "step": 18980
    },
    {
      "epoch": 1.2744203214657226,
      "grad_norm": 0.7141289114952087,
      "learning_rate": 0.00012880934521418595,
      "loss": 2.5069,
      "step": 18990
    },
    {
      "epoch": 1.2750914398845676,
      "grad_norm": 0.6343473196029663,
      "learning_rate": 0.00012873995742433643,
      "loss": 2.4712,
      "step": 19000
    },
    {
      "epoch": 1.2750914398845676,
      "eval_bleu": 20.879027854727088,
      "eval_gen_len": 28.782,
      "eval_loss": 2.9396212100982666,
      "eval_runtime": 63.1272,
      "eval_samples_per_second": 15.841,
      "eval_steps_per_second": 0.998,
      "step": 19000
    },
    {
      "epoch": 1.2757625583034127,
      "grad_norm": 0.6994655132293701,
      "learning_rate": 0.00012867055454802962,
      "loss": 2.4594,
      "step": 19010
    },
    {
      "epoch": 1.2764336767222577,
      "grad_norm": 0.7553746104240417,
      "learning_rate": 0.00012860113662169708,
      "loss": 2.5112,
      "step": 19020
    },
    {
      "epoch": 1.2771047951411028,
      "grad_norm": 0.7361690998077393,
      "learning_rate": 0.00012853170368177843,
      "loss": 2.5648,
      "step": 19030
    },
    {
      "epoch": 1.2777759135599476,
      "grad_norm": 0.7489808797836304,
      "learning_rate": 0.0001284622557647211,
      "loss": 2.4547,
      "step": 19040
    },
    {
      "epoch": 1.2784470319787926,
      "grad_norm": 0.6755473017692566,
      "learning_rate": 0.00012839279290698027,
      "loss": 2.4715,
      "step": 19050
    },
    {
      "epoch": 1.2784470319787926,
      "eval_bleu": 20.68313230262362,
      "eval_gen_len": 29.053,
      "eval_loss": 2.948162317276001,
      "eval_runtime": 67.0892,
      "eval_samples_per_second": 14.906,
      "eval_steps_per_second": 0.939,
      "step": 19050
    },
    {
      "epoch": 1.2791181503976377,
      "grad_norm": 0.7044779658317566,
      "learning_rate": 0.00012832331514501911,
      "loss": 2.4422,
      "step": 19060
    },
    {
      "epoch": 1.2797892688164827,
      "grad_norm": 0.6605504751205444,
      "learning_rate": 0.00012825382251530854,
      "loss": 2.4714,
      "step": 19070
    },
    {
      "epoch": 1.2804603872353277,
      "grad_norm": 0.7343862056732178,
      "learning_rate": 0.00012818431505432734,
      "loss": 2.4491,
      "step": 19080
    },
    {
      "epoch": 1.2811315056541726,
      "grad_norm": 0.742364227771759,
      "learning_rate": 0.00012811479279856204,
      "loss": 2.5147,
      "step": 19090
    },
    {
      "epoch": 1.2818026240730176,
      "grad_norm": 0.7271179556846619,
      "learning_rate": 0.0001280452557845069,
      "loss": 2.4841,
      "step": 19100
    },
    {
      "epoch": 1.2818026240730176,
      "eval_bleu": 20.68619743966708,
      "eval_gen_len": 28.862,
      "eval_loss": 2.94250750541687,
      "eval_runtime": 62.469,
      "eval_samples_per_second": 16.008,
      "eval_steps_per_second": 1.009,
      "step": 19100
    },
    {
      "epoch": 1.2824737424918626,
      "grad_norm": 0.7315837740898132,
      "learning_rate": 0.000127975704048664,
      "loss": 2.4224,
      "step": 19110
    },
    {
      "epoch": 1.2831448609107077,
      "grad_norm": 0.6854636073112488,
      "learning_rate": 0.00012790613762754305,
      "loss": 2.4879,
      "step": 19120
    },
    {
      "epoch": 1.2838159793295527,
      "grad_norm": 0.7484944462776184,
      "learning_rate": 0.0001278365565576616,
      "loss": 2.4865,
      "step": 19130
    },
    {
      "epoch": 1.2844870977483978,
      "grad_norm": 0.7001131176948547,
      "learning_rate": 0.00012776696087554482,
      "loss": 2.4817,
      "step": 19140
    },
    {
      "epoch": 1.2851582161672428,
      "grad_norm": 0.7013571262359619,
      "learning_rate": 0.0001276973506177255,
      "loss": 2.473,
      "step": 19150
    },
    {
      "epoch": 1.2851582161672428,
      "eval_bleu": 20.920724454478368,
      "eval_gen_len": 28.942,
      "eval_loss": 2.93882155418396,
      "eval_runtime": 62.2775,
      "eval_samples_per_second": 16.057,
      "eval_steps_per_second": 1.012,
      "step": 19150
    },
    {
      "epoch": 1.2858293345860878,
      "grad_norm": 0.7296960949897766,
      "learning_rate": 0.00012762772582074417,
      "loss": 2.5071,
      "step": 19160
    },
    {
      "epoch": 1.2865004530049327,
      "grad_norm": 0.7129086852073669,
      "learning_rate": 0.00012755808652114894,
      "loss": 2.5125,
      "step": 19170
    },
    {
      "epoch": 1.2871715714237777,
      "grad_norm": 0.7221249938011169,
      "learning_rate": 0.00012748843275549557,
      "loss": 2.5397,
      "step": 19180
    },
    {
      "epoch": 1.2878426898426227,
      "grad_norm": 0.702955961227417,
      "learning_rate": 0.00012741876456034734,
      "loss": 2.4838,
      "step": 19190
    },
    {
      "epoch": 1.2885138082614678,
      "grad_norm": 0.6620959639549255,
      "learning_rate": 0.0001273490819722752,
      "loss": 2.4368,
      "step": 19200
    },
    {
      "epoch": 1.2885138082614678,
      "eval_bleu": 21.149511432054936,
      "eval_gen_len": 28.893,
      "eval_loss": 2.941504955291748,
      "eval_runtime": 62.2975,
      "eval_samples_per_second": 16.052,
      "eval_steps_per_second": 1.011,
      "step": 19200
    },
    {
      "epoch": 1.2891849266803128,
      "grad_norm": 0.6689051985740662,
      "learning_rate": 0.00012727938502785758,
      "loss": 2.4979,
      "step": 19210
    },
    {
      "epoch": 1.2898560450991576,
      "grad_norm": 0.7612215280532837,
      "learning_rate": 0.0001272096737636805,
      "loss": 2.4811,
      "step": 19220
    },
    {
      "epoch": 1.2905271635180027,
      "grad_norm": 0.8091500401496887,
      "learning_rate": 0.00012713994821633747,
      "loss": 2.4889,
      "step": 19230
    },
    {
      "epoch": 1.2911982819368477,
      "grad_norm": 0.7060390114784241,
      "learning_rate": 0.0001270702084224295,
      "loss": 2.4819,
      "step": 19240
    },
    {
      "epoch": 1.2918694003556928,
      "grad_norm": 0.6584455966949463,
      "learning_rate": 0.00012700045441856506,
      "loss": 2.5328,
      "step": 19250
    },
    {
      "epoch": 1.2918694003556928,
      "eval_bleu": 21.479178261042932,
      "eval_gen_len": 28.968,
      "eval_loss": 2.9367835521698,
      "eval_runtime": 62.1632,
      "eval_samples_per_second": 16.087,
      "eval_steps_per_second": 1.013,
      "step": 19250
    },
    {
      "epoch": 1.2925405187745378,
      "grad_norm": 0.7238574624061584,
      "learning_rate": 0.00012693068624136008,
      "loss": 2.5201,
      "step": 19260
    },
    {
      "epoch": 1.2932116371933828,
      "grad_norm": 0.642641544342041,
      "learning_rate": 0.00012686090392743807,
      "loss": 2.4688,
      "step": 19270
    },
    {
      "epoch": 1.2938827556122279,
      "grad_norm": 0.7371601462364197,
      "learning_rate": 0.00012679110751342968,
      "loss": 2.4764,
      "step": 19280
    },
    {
      "epoch": 1.294553874031073,
      "grad_norm": 0.6630110144615173,
      "learning_rate": 0.0001267212970359732,
      "loss": 2.5256,
      "step": 19290
    },
    {
      "epoch": 1.2952249924499177,
      "grad_norm": 0.6392539143562317,
      "learning_rate": 0.00012665147253171423,
      "loss": 2.4302,
      "step": 19300
    },
    {
      "epoch": 1.2952249924499177,
      "eval_bleu": 21.071804307893185,
      "eval_gen_len": 28.879,
      "eval_loss": 2.939061164855957,
      "eval_runtime": 61.6487,
      "eval_samples_per_second": 16.221,
      "eval_steps_per_second": 1.022,
      "step": 19300
    },
    {
      "epoch": 1.2958961108687628,
      "grad_norm": 0.6476590633392334,
      "learning_rate": 0.0001265816340373057,
      "loss": 2.4727,
      "step": 19310
    },
    {
      "epoch": 1.2965672292876078,
      "grad_norm": 0.6665481328964233,
      "learning_rate": 0.00012651178158940796,
      "loss": 2.465,
      "step": 19320
    },
    {
      "epoch": 1.2972383477064529,
      "grad_norm": 0.7315478920936584,
      "learning_rate": 0.00012644191522468855,
      "loss": 2.4721,
      "step": 19330
    },
    {
      "epoch": 1.2979094661252977,
      "grad_norm": 0.6394508481025696,
      "learning_rate": 0.00012637203497982245,
      "loss": 2.4171,
      "step": 19340
    },
    {
      "epoch": 1.2985805845441427,
      "grad_norm": 0.7508349418640137,
      "learning_rate": 0.00012630214089149187,
      "loss": 2.5271,
      "step": 19350
    },
    {
      "epoch": 1.2985805845441427,
      "eval_bleu": 21.07352486471857,
      "eval_gen_len": 28.994,
      "eval_loss": 2.944276809692383,
      "eval_runtime": 63.2595,
      "eval_samples_per_second": 15.808,
      "eval_steps_per_second": 0.996,
      "step": 19350
    },
    {
      "epoch": 1.2992517029629878,
      "grad_norm": 0.690784752368927,
      "learning_rate": 0.00012623223299638634,
      "loss": 2.5162,
      "step": 19360
    },
    {
      "epoch": 1.2999228213818328,
      "grad_norm": 0.7403339147567749,
      "learning_rate": 0.00012616231133120252,
      "loss": 2.466,
      "step": 19370
    },
    {
      "epoch": 1.3005939398006778,
      "grad_norm": 0.6806496381759644,
      "learning_rate": 0.00012609237593264435,
      "loss": 2.4893,
      "step": 19380
    },
    {
      "epoch": 1.3012650582195229,
      "grad_norm": 0.7030185461044312,
      "learning_rate": 0.0001260224268374231,
      "loss": 2.5115,
      "step": 19390
    },
    {
      "epoch": 1.301936176638368,
      "grad_norm": 0.7263248562812805,
      "learning_rate": 0.00012595246408225708,
      "loss": 2.4831,
      "step": 19400
    },
    {
      "epoch": 1.301936176638368,
      "eval_bleu": 21.112541291335823,
      "eval_gen_len": 29.011,
      "eval_loss": 2.9384331703186035,
      "eval_runtime": 62.2883,
      "eval_samples_per_second": 16.054,
      "eval_steps_per_second": 1.011,
      "step": 19400
    },
    {
      "epoch": 1.302607295057213,
      "grad_norm": 0.6802673935890198,
      "learning_rate": 0.00012588248770387177,
      "loss": 2.4932,
      "step": 19410
    },
    {
      "epoch": 1.3032784134760578,
      "grad_norm": 0.6492636203765869,
      "learning_rate": 0.00012581249773899989,
      "loss": 2.5017,
      "step": 19420
    },
    {
      "epoch": 1.3039495318949028,
      "grad_norm": 0.7008742690086365,
      "learning_rate": 0.00012574249422438126,
      "loss": 2.5076,
      "step": 19430
    },
    {
      "epoch": 1.3046206503137479,
      "grad_norm": 0.6589850187301636,
      "learning_rate": 0.00012567247719676278,
      "loss": 2.4279,
      "step": 19440
    },
    {
      "epoch": 1.305291768732593,
      "grad_norm": 0.699774980545044,
      "learning_rate": 0.0001256024466928985,
      "loss": 2.4301,
      "step": 19450
    },
    {
      "epoch": 1.305291768732593,
      "eval_bleu": 21.199212325513244,
      "eval_gen_len": 28.955,
      "eval_loss": 2.939037322998047,
      "eval_runtime": 62.146,
      "eval_samples_per_second": 16.091,
      "eval_steps_per_second": 1.014,
      "step": 19450
    },
    {
      "epoch": 1.305962887151438,
      "grad_norm": 0.680243730545044,
      "learning_rate": 0.00012553240274954948,
      "loss": 2.4743,
      "step": 19460
    },
    {
      "epoch": 1.3066340055702828,
      "grad_norm": 0.6261840462684631,
      "learning_rate": 0.0001254623454034839,
      "loss": 2.4651,
      "step": 19470
    },
    {
      "epoch": 1.3073051239891278,
      "grad_norm": 0.6436797380447388,
      "learning_rate": 0.00012539227469147692,
      "loss": 2.4431,
      "step": 19480
    },
    {
      "epoch": 1.3079762424079728,
      "grad_norm": 0.7621766328811646,
      "learning_rate": 0.00012532219065031073,
      "loss": 2.5064,
      "step": 19490
    },
    {
      "epoch": 1.3086473608268179,
      "grad_norm": 0.7680556178092957,
      "learning_rate": 0.00012525209331677454,
      "loss": 2.5023,
      "step": 19500
    },
    {
      "epoch": 1.3086473608268179,
      "eval_bleu": 21.060406776777846,
      "eval_gen_len": 29.042,
      "eval_loss": 2.9369773864746094,
      "eval_runtime": 61.6574,
      "eval_samples_per_second": 16.219,
      "eval_steps_per_second": 1.022,
      "step": 19500
    },
    {
      "epoch": 1.309318479245663,
      "grad_norm": 0.7295153737068176,
      "learning_rate": 0.0001251819827276645,
      "loss": 2.4591,
      "step": 19510
    },
    {
      "epoch": 1.309989597664508,
      "grad_norm": 0.744732141494751,
      "learning_rate": 0.00012511185891978376,
      "loss": 2.4692,
      "step": 19520
    },
    {
      "epoch": 1.310660716083353,
      "grad_norm": 0.6694866418838501,
      "learning_rate": 0.00012504172192994237,
      "loss": 2.4618,
      "step": 19530
    },
    {
      "epoch": 1.311331834502198,
      "grad_norm": 0.6551846861839294,
      "learning_rate": 0.00012497157179495736,
      "loss": 2.5069,
      "step": 19540
    },
    {
      "epoch": 1.3120029529210429,
      "grad_norm": 0.6419070363044739,
      "learning_rate": 0.0001249014085516526,
      "loss": 2.4647,
      "step": 19550
    },
    {
      "epoch": 1.3120029529210429,
      "eval_bleu": 21.079266121036227,
      "eval_gen_len": 28.902,
      "eval_loss": 2.944422721862793,
      "eval_runtime": 62.1379,
      "eval_samples_per_second": 16.093,
      "eval_steps_per_second": 1.014,
      "step": 19550
    },
    {
      "epoch": 1.312674071339888,
      "grad_norm": 0.7108444571495056,
      "learning_rate": 0.00012483123223685884,
      "loss": 2.4869,
      "step": 19560
    },
    {
      "epoch": 1.313345189758733,
      "grad_norm": 0.6662734150886536,
      "learning_rate": 0.00012476104288741376,
      "loss": 2.5117,
      "step": 19570
    },
    {
      "epoch": 1.314016308177578,
      "grad_norm": 0.6795262098312378,
      "learning_rate": 0.00012469084054016178,
      "loss": 2.4758,
      "step": 19580
    },
    {
      "epoch": 1.314687426596423,
      "grad_norm": 0.7506099343299866,
      "learning_rate": 0.00012462062523195422,
      "loss": 2.4907,
      "step": 19590
    },
    {
      "epoch": 1.3153585450152678,
      "grad_norm": 0.760202169418335,
      "learning_rate": 0.00012455039699964916,
      "loss": 2.5016,
      "step": 19600
    },
    {
      "epoch": 1.3153585450152678,
      "eval_bleu": 21.068799422962027,
      "eval_gen_len": 28.931,
      "eval_loss": 2.937405824661255,
      "eval_runtime": 61.9185,
      "eval_samples_per_second": 16.15,
      "eval_steps_per_second": 1.017,
      "step": 19600
    },
    {
      "epoch": 1.3160296634341129,
      "grad_norm": 0.6852207183837891,
      "learning_rate": 0.0001244801558801115,
      "loss": 2.4964,
      "step": 19610
    },
    {
      "epoch": 1.316700781852958,
      "grad_norm": 0.7172830104827881,
      "learning_rate": 0.0001244099019102129,
      "loss": 2.4133,
      "step": 19620
    },
    {
      "epoch": 1.317371900271803,
      "grad_norm": 0.7323098182678223,
      "learning_rate": 0.0001243396351268318,
      "loss": 2.4962,
      "step": 19630
    },
    {
      "epoch": 1.318043018690648,
      "grad_norm": 0.6568121314048767,
      "learning_rate": 0.00012426935556685324,
      "loss": 2.4557,
      "step": 19640
    },
    {
      "epoch": 1.318714137109493,
      "grad_norm": 0.6505544185638428,
      "learning_rate": 0.00012419906326716909,
      "loss": 2.5148,
      "step": 19650
    },
    {
      "epoch": 1.318714137109493,
      "eval_bleu": 21.15104746991775,
      "eval_gen_len": 28.951,
      "eval_loss": 2.937894344329834,
      "eval_runtime": 61.1239,
      "eval_samples_per_second": 16.36,
      "eval_steps_per_second": 1.031,
      "step": 19650
    },
    {
      "epoch": 1.319385255528338,
      "grad_norm": 0.6380146741867065,
      "learning_rate": 0.00012412875826467781,
      "loss": 2.5042,
      "step": 19660
    },
    {
      "epoch": 1.3200563739471831,
      "grad_norm": 0.6575315594673157,
      "learning_rate": 0.00012405844059628471,
      "loss": 2.4658,
      "step": 19670
    },
    {
      "epoch": 1.320727492366028,
      "grad_norm": 0.694394052028656,
      "learning_rate": 0.0001239881102989015,
      "loss": 2.4496,
      "step": 19680
    },
    {
      "epoch": 1.321398610784873,
      "grad_norm": 0.6466131806373596,
      "learning_rate": 0.00012391776740944667,
      "loss": 2.4678,
      "step": 19690
    },
    {
      "epoch": 1.322069729203718,
      "grad_norm": 0.6917659640312195,
      "learning_rate": 0.00012384741196484533,
      "loss": 2.4775,
      "step": 19700
    },
    {
      "epoch": 1.322069729203718,
      "eval_bleu": 21.342173888016255,
      "eval_gen_len": 29.034,
      "eval_loss": 2.9360671043395996,
      "eval_runtime": 61.3381,
      "eval_samples_per_second": 16.303,
      "eval_steps_per_second": 1.027,
      "step": 19700
    },
    {
      "epoch": 1.322740847622563,
      "grad_norm": 0.7304964661598206,
      "learning_rate": 0.00012377704400202914,
      "loss": 2.4679,
      "step": 19710
    },
    {
      "epoch": 1.3234119660414079,
      "grad_norm": 0.7071089148521423,
      "learning_rate": 0.0001237066635579363,
      "loss": 2.4886,
      "step": 19720
    },
    {
      "epoch": 1.324083084460253,
      "grad_norm": 0.5973191857337952,
      "learning_rate": 0.0001236362706695116,
      "loss": 2.397,
      "step": 19730
    },
    {
      "epoch": 1.324754202879098,
      "grad_norm": 0.71586012840271,
      "learning_rate": 0.00012356586537370636,
      "loss": 2.5109,
      "step": 19740
    },
    {
      "epoch": 1.325425321297943,
      "grad_norm": 0.7255634069442749,
      "learning_rate": 0.0001234954477074784,
      "loss": 2.4661,
      "step": 19750
    },
    {
      "epoch": 1.325425321297943,
      "eval_bleu": 21.051444809271445,
      "eval_gen_len": 29.072,
      "eval_loss": 2.939331293106079,
      "eval_runtime": 62.692,
      "eval_samples_per_second": 15.951,
      "eval_steps_per_second": 1.005,
      "step": 19750
    },
    {
      "epoch": 1.326096439716788,
      "grad_norm": 0.7486515641212463,
      "learning_rate": 0.0001234250177077921,
      "loss": 2.5077,
      "step": 19760
    },
    {
      "epoch": 1.326767558135633,
      "grad_norm": 0.6735448837280273,
      "learning_rate": 0.00012335457541161825,
      "loss": 2.4687,
      "step": 19770
    },
    {
      "epoch": 1.3274386765544781,
      "grad_norm": 0.6267067790031433,
      "learning_rate": 0.00012328412085593405,
      "loss": 2.4606,
      "step": 19780
    },
    {
      "epoch": 1.3281097949733232,
      "grad_norm": 0.6864752769470215,
      "learning_rate": 0.0001232136540777232,
      "loss": 2.5107,
      "step": 19790
    },
    {
      "epoch": 1.328780913392168,
      "grad_norm": 0.6440294981002808,
      "learning_rate": 0.00012314317511397582,
      "loss": 2.4316,
      "step": 19800
    },
    {
      "epoch": 1.328780913392168,
      "eval_bleu": 21.37847744104243,
      "eval_gen_len": 28.733,
      "eval_loss": 2.9409308433532715,
      "eval_runtime": 60.4787,
      "eval_samples_per_second": 16.535,
      "eval_steps_per_second": 1.042,
      "step": 19800
    },
    {
      "epoch": 1.329452031811013,
      "grad_norm": 0.7111128568649292,
      "learning_rate": 0.00012307268400168844,
      "loss": 2.4788,
      "step": 19810
    },
    {
      "epoch": 1.330123150229858,
      "grad_norm": 0.6923819184303284,
      "learning_rate": 0.00012300218077786386,
      "loss": 2.4952,
      "step": 19820
    },
    {
      "epoch": 1.330794268648703,
      "grad_norm": 0.7400187849998474,
      "learning_rate": 0.00012293166547951137,
      "loss": 2.4272,
      "step": 19830
    },
    {
      "epoch": 1.3314653870675481,
      "grad_norm": 0.7158904671669006,
      "learning_rate": 0.00012286113814364658,
      "loss": 2.5051,
      "step": 19840
    },
    {
      "epoch": 1.332136505486393,
      "grad_norm": 0.7422758936882019,
      "learning_rate": 0.00012279059880729133,
      "loss": 2.4779,
      "step": 19850
    },
    {
      "epoch": 1.332136505486393,
      "eval_bleu": 21.158051010939953,
      "eval_gen_len": 29.157,
      "eval_loss": 2.937516927719116,
      "eval_runtime": 64.6834,
      "eval_samples_per_second": 15.46,
      "eval_steps_per_second": 0.974,
      "step": 19850
    },
    {
      "epoch": 1.332807623905238,
      "grad_norm": 0.6646651029586792,
      "learning_rate": 0.00012272004750747383,
      "loss": 2.5389,
      "step": 19860
    },
    {
      "epoch": 1.333478742324083,
      "grad_norm": 0.6579696536064148,
      "learning_rate": 0.00012264948428122852,
      "loss": 2.5249,
      "step": 19870
    },
    {
      "epoch": 1.334149860742928,
      "grad_norm": 0.6734135150909424,
      "learning_rate": 0.0001225789091655962,
      "loss": 2.4626,
      "step": 19880
    },
    {
      "epoch": 1.3348209791617731,
      "grad_norm": 0.6721006631851196,
      "learning_rate": 0.0001225083221976238,
      "loss": 2.4832,
      "step": 19890
    },
    {
      "epoch": 1.3354920975806182,
      "grad_norm": 0.7199180722236633,
      "learning_rate": 0.00012243772341436452,
      "loss": 2.4763,
      "step": 19900
    },
    {
      "epoch": 1.3354920975806182,
      "eval_bleu": 21.427298999598996,
      "eval_gen_len": 28.927,
      "eval_loss": 2.9437832832336426,
      "eval_runtime": 62.0543,
      "eval_samples_per_second": 16.115,
      "eval_steps_per_second": 1.015,
      "step": 19900
    },
    {
      "epoch": 1.3361632159994632,
      "grad_norm": 0.6630879640579224,
      "learning_rate": 0.00012236711285287778,
      "loss": 2.4811,
      "step": 19910
    },
    {
      "epoch": 1.3368343344183082,
      "grad_norm": 0.6491751670837402,
      "learning_rate": 0.0001222964905502291,
      "loss": 2.5337,
      "step": 19920
    },
    {
      "epoch": 1.337505452837153,
      "grad_norm": 0.719828724861145,
      "learning_rate": 0.00012222585654349027,
      "loss": 2.4661,
      "step": 19930
    },
    {
      "epoch": 1.338176571255998,
      "grad_norm": 0.7214331030845642,
      "learning_rate": 0.00012215521086973924,
      "loss": 2.4881,
      "step": 19940
    },
    {
      "epoch": 1.3388476896748431,
      "grad_norm": 0.7121843695640564,
      "learning_rate": 0.0001220845535660599,
      "loss": 2.4799,
      "step": 19950
    },
    {
      "epoch": 1.3388476896748431,
      "eval_bleu": 21.197812122328937,
      "eval_gen_len": 29.111,
      "eval_loss": 2.9360554218292236,
      "eval_runtime": 64.8773,
      "eval_samples_per_second": 15.414,
      "eval_steps_per_second": 0.971,
      "step": 19950
    },
    {
      "epoch": 1.3395188080936882,
      "grad_norm": 0.7237116098403931,
      "learning_rate": 0.00012201388466954244,
      "loss": 2.5376,
      "step": 19960
    },
    {
      "epoch": 1.3401899265125332,
      "grad_norm": 0.6852918267250061,
      "learning_rate": 0.00012194320421728305,
      "loss": 2.5054,
      "step": 19970
    },
    {
      "epoch": 1.340861044931378,
      "grad_norm": 0.6907331347465515,
      "learning_rate": 0.00012187251224638401,
      "loss": 2.5176,
      "step": 19980
    },
    {
      "epoch": 1.341532163350223,
      "grad_norm": 0.6836864948272705,
      "learning_rate": 0.0001218018087939536,
      "loss": 2.5024,
      "step": 19990
    },
    {
      "epoch": 1.3422032817690681,
      "grad_norm": 0.7710979580879211,
      "learning_rate": 0.00012173109389710617,
      "loss": 2.4926,
      "step": 20000
    },
    {
      "epoch": 1.3422032817690681,
      "eval_bleu": 21.390442095224454,
      "eval_gen_len": 28.83,
      "eval_loss": 2.9386372566223145,
      "eval_runtime": 61.3681,
      "eval_samples_per_second": 16.295,
      "eval_steps_per_second": 1.027,
      "step": 20000
    },
    {
      "epoch": 1.3428744001879132,
      "grad_norm": 0.7021924257278442,
      "learning_rate": 0.00012166036759296212,
      "loss": 2.4587,
      "step": 20010
    },
    {
      "epoch": 1.3435455186067582,
      "grad_norm": 0.6782358884811401,
      "learning_rate": 0.00012158962991864775,
      "loss": 2.4704,
      "step": 20020
    },
    {
      "epoch": 1.3442166370256032,
      "grad_norm": 0.7146028876304626,
      "learning_rate": 0.00012151888091129535,
      "loss": 2.4876,
      "step": 20030
    },
    {
      "epoch": 1.3448877554444483,
      "grad_norm": 0.6683083772659302,
      "learning_rate": 0.0001214481206080432,
      "loss": 2.4647,
      "step": 20040
    },
    {
      "epoch": 1.3455588738632933,
      "grad_norm": 0.6661957502365112,
      "learning_rate": 0.00012137734904603551,
      "loss": 2.4609,
      "step": 20050
    },
    {
      "epoch": 1.3455588738632933,
      "eval_bleu": 21.099655549698205,
      "eval_gen_len": 29.206,
      "eval_loss": 2.942060708999634,
      "eval_runtime": 65.2067,
      "eval_samples_per_second": 15.336,
      "eval_steps_per_second": 0.966,
      "step": 20050
    },
    {
      "epoch": 1.3462299922821381,
      "grad_norm": 0.7252253890037537,
      "learning_rate": 0.0001213065662624223,
      "loss": 2.5015,
      "step": 20060
    },
    {
      "epoch": 1.3469011107009832,
      "grad_norm": 0.649333119392395,
      "learning_rate": 0.00012123577229435961,
      "loss": 2.4919,
      "step": 20070
    },
    {
      "epoch": 1.3475722291198282,
      "grad_norm": 0.6948903799057007,
      "learning_rate": 0.00012116496717900932,
      "loss": 2.4603,
      "step": 20080
    },
    {
      "epoch": 1.3482433475386733,
      "grad_norm": 0.7375118136405945,
      "learning_rate": 0.00012109415095353906,
      "loss": 2.4518,
      "step": 20090
    },
    {
      "epoch": 1.348914465957518,
      "grad_norm": 0.7248646020889282,
      "learning_rate": 0.00012102332365512241,
      "loss": 2.5349,
      "step": 20100
    },
    {
      "epoch": 1.348914465957518,
      "eval_bleu": 21.34502817369558,
      "eval_gen_len": 29.17,
      "eval_loss": 2.93869948387146,
      "eval_runtime": 66.8123,
      "eval_samples_per_second": 14.967,
      "eval_steps_per_second": 0.943,
      "step": 20100
    },
    {
      "epoch": 1.3495855843763631,
      "grad_norm": 0.7296434640884399,
      "learning_rate": 0.00012095248532093874,
      "loss": 2.5265,
      "step": 20110
    },
    {
      "epoch": 1.3502567027952082,
      "grad_norm": 0.6457915902137756,
      "learning_rate": 0.00012088163598817321,
      "loss": 2.4995,
      "step": 20120
    },
    {
      "epoch": 1.3509278212140532,
      "grad_norm": 0.6313709616661072,
      "learning_rate": 0.00012081077569401669,
      "loss": 2.4761,
      "step": 20130
    },
    {
      "epoch": 1.3515989396328982,
      "grad_norm": 0.6404964923858643,
      "learning_rate": 0.00012073990447566588,
      "loss": 2.4865,
      "step": 20140
    },
    {
      "epoch": 1.3522700580517433,
      "grad_norm": 0.6374138593673706,
      "learning_rate": 0.00012066902237032316,
      "loss": 2.4795,
      "step": 20150
    },
    {
      "epoch": 1.3522700580517433,
      "eval_bleu": 21.2952673871172,
      "eval_gen_len": 29.156,
      "eval_loss": 2.938709020614624,
      "eval_runtime": 72.8957,
      "eval_samples_per_second": 13.718,
      "eval_steps_per_second": 0.864,
      "step": 20150
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 0.6880989074707031,
      "learning_rate": 0.0001205981294151967,
      "loss": 2.4639,
      "step": 20160
    },
    {
      "epoch": 1.3536122948894334,
      "grad_norm": 0.709098756313324,
      "learning_rate": 0.0001205272256475003,
      "loss": 2.4382,
      "step": 20170
    },
    {
      "epoch": 1.3542834133082782,
      "grad_norm": 0.7268784642219543,
      "learning_rate": 0.00012045631110445341,
      "loss": 2.4651,
      "step": 20180
    },
    {
      "epoch": 1.3549545317271232,
      "grad_norm": 0.7024850845336914,
      "learning_rate": 0.00012038538582328125,
      "loss": 2.4774,
      "step": 20190
    },
    {
      "epoch": 1.3556256501459683,
      "grad_norm": 0.6132150888442993,
      "learning_rate": 0.00012031444984121456,
      "loss": 2.4736,
      "step": 20200
    },
    {
      "epoch": 1.3556256501459683,
      "eval_bleu": 20.916903620028396,
      "eval_gen_len": 28.897,
      "eval_loss": 2.9363527297973633,
      "eval_runtime": 63.8131,
      "eval_samples_per_second": 15.671,
      "eval_steps_per_second": 0.987,
      "step": 20200
    },
    {
      "epoch": 1.3562967685648133,
      "grad_norm": 0.7121782302856445,
      "learning_rate": 0.00012024350319548976,
      "loss": 2.4869,
      "step": 20210
    },
    {
      "epoch": 1.3569678869836583,
      "grad_norm": 0.7377995848655701,
      "learning_rate": 0.00012017254592334883,
      "loss": 2.4571,
      "step": 20220
    },
    {
      "epoch": 1.3576390054025032,
      "grad_norm": 0.7046127319335938,
      "learning_rate": 0.00012010157806203939,
      "loss": 2.5073,
      "step": 20230
    },
    {
      "epoch": 1.3583101238213482,
      "grad_norm": 0.7329592108726501,
      "learning_rate": 0.00012003059964881456,
      "loss": 2.5355,
      "step": 20240
    },
    {
      "epoch": 1.3589812422401932,
      "grad_norm": 0.809904158115387,
      "learning_rate": 0.00011995961072093302,
      "loss": 2.5218,
      "step": 20250
    },
    {
      "epoch": 1.3589812422401932,
      "eval_bleu": 21.000874965416525,
      "eval_gen_len": 28.881,
      "eval_loss": 2.938685417175293,
      "eval_runtime": 69.0589,
      "eval_samples_per_second": 14.48,
      "eval_steps_per_second": 0.912,
      "step": 20250
    },
    {
      "epoch": 1.3596523606590383,
      "grad_norm": 0.748271644115448,
      "learning_rate": 0.00011988861131565894,
      "loss": 2.4409,
      "step": 20260
    },
    {
      "epoch": 1.3603234790778833,
      "grad_norm": 0.6480550169944763,
      "learning_rate": 0.00011981760147026205,
      "loss": 2.4722,
      "step": 20270
    },
    {
      "epoch": 1.3609945974967284,
      "grad_norm": 0.7285093665122986,
      "learning_rate": 0.0001197465812220175,
      "loss": 2.4335,
      "step": 20280
    },
    {
      "epoch": 1.3616657159155734,
      "grad_norm": 0.6657912135124207,
      "learning_rate": 0.00011967555060820597,
      "loss": 2.528,
      "step": 20290
    },
    {
      "epoch": 1.3623368343344184,
      "grad_norm": 0.6817167401313782,
      "learning_rate": 0.0001196045096661135,
      "loss": 2.5036,
      "step": 20300
    },
    {
      "epoch": 1.3623368343344184,
      "eval_bleu": 21.376537081023315,
      "eval_gen_len": 28.966,
      "eval_loss": 2.933825731277466,
      "eval_runtime": 69.4554,
      "eval_samples_per_second": 14.398,
      "eval_steps_per_second": 0.907,
      "step": 20300
    },
    {
      "epoch": 1.3630079527532633,
      "grad_norm": 0.725307822227478,
      "learning_rate": 0.00011953345843303159,
      "loss": 2.4704,
      "step": 20310
    },
    {
      "epoch": 1.3636790711721083,
      "grad_norm": 0.7079823613166809,
      "learning_rate": 0.00011946239694625716,
      "loss": 2.425,
      "step": 20320
    },
    {
      "epoch": 1.3643501895909533,
      "grad_norm": 0.6811646223068237,
      "learning_rate": 0.0001193913252430925,
      "loss": 2.5003,
      "step": 20330
    },
    {
      "epoch": 1.3650213080097984,
      "grad_norm": 0.7010288238525391,
      "learning_rate": 0.00011932024336084525,
      "loss": 2.4426,
      "step": 20340
    },
    {
      "epoch": 1.3656924264286434,
      "grad_norm": 0.6825384497642517,
      "learning_rate": 0.00011924915133682839,
      "loss": 2.469,
      "step": 20350
    },
    {
      "epoch": 1.3656924264286434,
      "eval_bleu": 21.3375823442043,
      "eval_gen_len": 28.946,
      "eval_loss": 2.938525438308716,
      "eval_runtime": 68.9526,
      "eval_samples_per_second": 14.503,
      "eval_steps_per_second": 0.914,
      "step": 20350
    },
    {
      "epoch": 1.3663635448474882,
      "grad_norm": 0.7449449300765991,
      "learning_rate": 0.00011917804920836025,
      "loss": 2.4884,
      "step": 20360
    },
    {
      "epoch": 1.3670346632663333,
      "grad_norm": 0.6295179128646851,
      "learning_rate": 0.00011910693701276442,
      "loss": 2.4976,
      "step": 20370
    },
    {
      "epoch": 1.3677057816851783,
      "grad_norm": 0.6968140602111816,
      "learning_rate": 0.00011903581478736985,
      "loss": 2.4872,
      "step": 20380
    },
    {
      "epoch": 1.3683769001040234,
      "grad_norm": 0.8096487522125244,
      "learning_rate": 0.0001189646825695107,
      "loss": 2.4596,
      "step": 20390
    },
    {
      "epoch": 1.3690480185228684,
      "grad_norm": 0.7496457099914551,
      "learning_rate": 0.00011889354039652634,
      "loss": 2.5412,
      "step": 20400
    },
    {
      "epoch": 1.3690480185228684,
      "eval_bleu": 21.16353544896768,
      "eval_gen_len": 28.855,
      "eval_loss": 2.935469388961792,
      "eval_runtime": 69.6426,
      "eval_samples_per_second": 14.359,
      "eval_steps_per_second": 0.905,
      "step": 20400
    },
    {
      "epoch": 1.3697191369417134,
      "grad_norm": 0.6440573334693909,
      "learning_rate": 0.00011882238830576144,
      "loss": 2.4776,
      "step": 20410
    },
    {
      "epoch": 1.3703902553605585,
      "grad_norm": 0.6855055093765259,
      "learning_rate": 0.00011875122633456585,
      "loss": 2.4735,
      "step": 20420
    },
    {
      "epoch": 1.3710613737794035,
      "grad_norm": 0.7315500378608704,
      "learning_rate": 0.00011868005452029462,
      "loss": 2.412,
      "step": 20430
    },
    {
      "epoch": 1.3717324921982483,
      "grad_norm": 0.7026481032371521,
      "learning_rate": 0.00011860887290030792,
      "loss": 2.4919,
      "step": 20440
    },
    {
      "epoch": 1.3724036106170934,
      "grad_norm": 0.6383965015411377,
      "learning_rate": 0.00011853768151197109,
      "loss": 2.4866,
      "step": 20450
    },
    {
      "epoch": 1.3724036106170934,
      "eval_bleu": 21.44225193858798,
      "eval_gen_len": 29.179,
      "eval_loss": 2.935864210128784,
      "eval_runtime": 72.1271,
      "eval_samples_per_second": 13.864,
      "eval_steps_per_second": 0.873,
      "step": 20450
    },
    {
      "epoch": 1.3730747290359384,
      "grad_norm": 0.6416980624198914,
      "learning_rate": 0.0001184664803926546,
      "loss": 2.4652,
      "step": 20460
    },
    {
      "epoch": 1.3737458474547835,
      "grad_norm": 0.7346127033233643,
      "learning_rate": 0.0001183952695797341,
      "loss": 2.4909,
      "step": 20470
    },
    {
      "epoch": 1.3744169658736283,
      "grad_norm": 0.7160449028015137,
      "learning_rate": 0.00011832404911059016,
      "loss": 2.4676,
      "step": 20480
    },
    {
      "epoch": 1.3750880842924733,
      "grad_norm": 0.658576488494873,
      "learning_rate": 0.00011825281902260861,
      "loss": 2.4659,
      "step": 20490
    },
    {
      "epoch": 1.3757592027113184,
      "grad_norm": 0.7196254730224609,
      "learning_rate": 0.00011818157935318018,
      "loss": 2.5076,
      "step": 20500
    },
    {
      "epoch": 1.3757592027113184,
      "eval_bleu": 21.246921018531815,
      "eval_gen_len": 29.383,
      "eval_loss": 2.934845447540283,
      "eval_runtime": 74.8381,
      "eval_samples_per_second": 13.362,
      "eval_steps_per_second": 0.842,
      "step": 20500
    },
    {
      "epoch": 1.3764303211301634,
      "grad_norm": 0.7472938299179077,
      "learning_rate": 0.00011811033013970073,
      "loss": 2.5159,
      "step": 20510
    },
    {
      "epoch": 1.3771014395490084,
      "grad_norm": 0.6593085527420044,
      "learning_rate": 0.00011803907141957102,
      "loss": 2.4492,
      "step": 20520
    },
    {
      "epoch": 1.3777725579678535,
      "grad_norm": 0.7085515856742859,
      "learning_rate": 0.00011796780323019693,
      "loss": 2.5201,
      "step": 20530
    },
    {
      "epoch": 1.3784436763866985,
      "grad_norm": 0.7107326984405518,
      "learning_rate": 0.00011789652560898925,
      "loss": 2.4984,
      "step": 20540
    },
    {
      "epoch": 1.3791147948055436,
      "grad_norm": 0.7257703542709351,
      "learning_rate": 0.0001178252385933637,
      "loss": 2.4906,
      "step": 20550
    },
    {
      "epoch": 1.3791147948055436,
      "eval_bleu": 21.187716097983046,
      "eval_gen_len": 29.041,
      "eval_loss": 2.940793991088867,
      "eval_runtime": 70.1037,
      "eval_samples_per_second": 14.265,
      "eval_steps_per_second": 0.899,
      "step": 20550
    },
    {
      "epoch": 1.3797859132243884,
      "grad_norm": 0.6840000748634338,
      "learning_rate": 0.00011775394222074099,
      "loss": 2.4811,
      "step": 20560
    },
    {
      "epoch": 1.3804570316432334,
      "grad_norm": 0.6661813855171204,
      "learning_rate": 0.00011768263652854663,
      "loss": 2.5112,
      "step": 20570
    },
    {
      "epoch": 1.3811281500620785,
      "grad_norm": 0.6488561630249023,
      "learning_rate": 0.00011761132155421112,
      "loss": 2.474,
      "step": 20580
    },
    {
      "epoch": 1.3817992684809235,
      "grad_norm": 0.6244407296180725,
      "learning_rate": 0.00011753999733516987,
      "loss": 2.4689,
      "step": 20590
    },
    {
      "epoch": 1.3824703868997685,
      "grad_norm": 0.6948173642158508,
      "learning_rate": 0.00011746866390886305,
      "loss": 2.4481,
      "step": 20600
    },
    {
      "epoch": 1.3824703868997685,
      "eval_bleu": 21.279105808697206,
      "eval_gen_len": 28.939,
      "eval_loss": 2.943425416946411,
      "eval_runtime": 63.8496,
      "eval_samples_per_second": 15.662,
      "eval_steps_per_second": 0.987,
      "step": 20600
    },
    {
      "epoch": 1.3831415053186134,
      "grad_norm": 0.6915603280067444,
      "learning_rate": 0.00011739732131273562,
      "loss": 2.4927,
      "step": 20610
    },
    {
      "epoch": 1.3838126237374584,
      "grad_norm": 0.727436900138855,
      "learning_rate": 0.00011732596958423752,
      "loss": 2.4694,
      "step": 20620
    },
    {
      "epoch": 1.3844837421563034,
      "grad_norm": 0.6744562983512878,
      "learning_rate": 0.00011725460876082335,
      "loss": 2.4889,
      "step": 20630
    },
    {
      "epoch": 1.3851548605751485,
      "grad_norm": 0.6138540506362915,
      "learning_rate": 0.00011718323887995255,
      "loss": 2.4992,
      "step": 20640
    },
    {
      "epoch": 1.3858259789939935,
      "grad_norm": 0.6534168124198914,
      "learning_rate": 0.0001171118599790893,
      "loss": 2.5232,
      "step": 20650
    },
    {
      "epoch": 1.3858259789939935,
      "eval_bleu": 21.563738721634667,
      "eval_gen_len": 28.883,
      "eval_loss": 2.9378809928894043,
      "eval_runtime": 63.8708,
      "eval_samples_per_second": 15.657,
      "eval_steps_per_second": 0.986,
      "step": 20650
    },
    {
      "epoch": 1.3864970974128386,
      "grad_norm": 0.7235645055770874,
      "learning_rate": 0.00011704047209570243,
      "loss": 2.4597,
      "step": 20660
    },
    {
      "epoch": 1.3871682158316836,
      "grad_norm": 0.6766744256019592,
      "learning_rate": 0.00011696907526726564,
      "loss": 2.5169,
      "step": 20670
    },
    {
      "epoch": 1.3878393342505286,
      "grad_norm": 0.6696385145187378,
      "learning_rate": 0.00011689766953125721,
      "loss": 2.4771,
      "step": 20680
    },
    {
      "epoch": 1.3885104526693735,
      "grad_norm": 0.6355229616165161,
      "learning_rate": 0.0001168262549251601,
      "loss": 2.4938,
      "step": 20690
    },
    {
      "epoch": 1.3891815710882185,
      "grad_norm": 0.6925520896911621,
      "learning_rate": 0.00011675483148646207,
      "loss": 2.4518,
      "step": 20700
    },
    {
      "epoch": 1.3891815710882185,
      "eval_bleu": 21.284281073642244,
      "eval_gen_len": 28.932,
      "eval_loss": 2.93752384185791,
      "eval_runtime": 64.4409,
      "eval_samples_per_second": 15.518,
      "eval_steps_per_second": 0.978,
      "step": 20700
    },
    {
      "epoch": 1.3898526895070635,
      "grad_norm": 0.6917905211448669,
      "learning_rate": 0.00011668339925265528,
      "loss": 2.462,
      "step": 20710
    },
    {
      "epoch": 1.3905238079259086,
      "grad_norm": 0.6439194083213806,
      "learning_rate": 0.0001166119582612367,
      "loss": 2.414,
      "step": 20720
    },
    {
      "epoch": 1.3911949263447536,
      "grad_norm": 0.6836743354797363,
      "learning_rate": 0.00011654050854970782,
      "loss": 2.4695,
      "step": 20730
    },
    {
      "epoch": 1.3918660447635984,
      "grad_norm": 0.6678350567817688,
      "learning_rate": 0.00011646905015557469,
      "loss": 2.5233,
      "step": 20740
    },
    {
      "epoch": 1.3925371631824435,
      "grad_norm": 0.7139343023300171,
      "learning_rate": 0.00011639758311634796,
      "loss": 2.5109,
      "step": 20750
    },
    {
      "epoch": 1.3925371631824435,
      "eval_bleu": 21.134535654482672,
      "eval_gen_len": 28.914,
      "eval_loss": 2.937145233154297,
      "eval_runtime": 64.0907,
      "eval_samples_per_second": 15.603,
      "eval_steps_per_second": 0.983,
      "step": 20750
    },
    {
      "epoch": 1.3932082816012885,
      "grad_norm": 0.6630216240882874,
      "learning_rate": 0.0001163261074695428,
      "loss": 2.5026,
      "step": 20760
    },
    {
      "epoch": 1.3938794000201336,
      "grad_norm": 0.6986448168754578,
      "learning_rate": 0.00011625462325267893,
      "loss": 2.4904,
      "step": 20770
    },
    {
      "epoch": 1.3945505184389786,
      "grad_norm": 0.7173417806625366,
      "learning_rate": 0.00011618313050328049,
      "loss": 2.4553,
      "step": 20780
    },
    {
      "epoch": 1.3952216368578236,
      "grad_norm": 0.7369820475578308,
      "learning_rate": 0.00011611162925887618,
      "loss": 2.5523,
      "step": 20790
    },
    {
      "epoch": 1.3958927552766687,
      "grad_norm": 0.6995398998260498,
      "learning_rate": 0.0001160401195569991,
      "loss": 2.4771,
      "step": 20800
    },
    {
      "epoch": 1.3958927552766687,
      "eval_bleu": 21.180055248063052,
      "eval_gen_len": 28.903,
      "eval_loss": 2.9405264854431152,
      "eval_runtime": 64.1156,
      "eval_samples_per_second": 15.597,
      "eval_steps_per_second": 0.983,
      "step": 20800
    },
    {
      "epoch": 1.3965638736955135,
      "grad_norm": 0.7069430351257324,
      "learning_rate": 0.00011596860143518682,
      "loss": 2.4893,
      "step": 20810
    },
    {
      "epoch": 1.3972349921143585,
      "grad_norm": 0.6399899125099182,
      "learning_rate": 0.00011589707493098139,
      "loss": 2.4033,
      "step": 20820
    },
    {
      "epoch": 1.3979061105332036,
      "grad_norm": 0.7353147268295288,
      "learning_rate": 0.0001158255400819291,
      "loss": 2.5417,
      "step": 20830
    },
    {
      "epoch": 1.3985772289520486,
      "grad_norm": 0.670066773891449,
      "learning_rate": 0.00011575399692558076,
      "loss": 2.5026,
      "step": 20840
    },
    {
      "epoch": 1.3992483473708937,
      "grad_norm": 0.6592165231704712,
      "learning_rate": 0.0001156824454994915,
      "loss": 2.4822,
      "step": 20850
    },
    {
      "epoch": 1.3992483473708937,
      "eval_bleu": 21.257638910525827,
      "eval_gen_len": 28.86,
      "eval_loss": 2.942230224609375,
      "eval_runtime": 64.2816,
      "eval_samples_per_second": 15.557,
      "eval_steps_per_second": 0.98,
      "step": 20850
    },
    {
      "epoch": 1.3999194657897385,
      "grad_norm": 0.7503591179847717,
      "learning_rate": 0.0001156108858412208,
      "loss": 2.4927,
      "step": 20860
    },
    {
      "epoch": 1.4005905842085835,
      "grad_norm": 0.680416464805603,
      "learning_rate": 0.00011553931798833246,
      "loss": 2.4607,
      "step": 20870
    },
    {
      "epoch": 1.4012617026274286,
      "grad_norm": 0.7126158475875854,
      "learning_rate": 0.00011546774197839452,
      "loss": 2.5111,
      "step": 20880
    },
    {
      "epoch": 1.4019328210462736,
      "grad_norm": 0.6769466400146484,
      "learning_rate": 0.00011539615784897939,
      "loss": 2.5186,
      "step": 20890
    },
    {
      "epoch": 1.4026039394651186,
      "grad_norm": 0.6892744302749634,
      "learning_rate": 0.0001153245656376637,
      "loss": 2.4985,
      "step": 20900
    },
    {
      "epoch": 1.4026039394651186,
      "eval_bleu": 20.947965209300865,
      "eval_gen_len": 28.961,
      "eval_loss": 2.9385526180267334,
      "eval_runtime": 64.0659,
      "eval_samples_per_second": 15.609,
      "eval_steps_per_second": 0.983,
      "step": 20900
    },
    {
      "epoch": 1.4032750578839637,
      "grad_norm": 0.7116913199424744,
      "learning_rate": 0.00011525296538202835,
      "loss": 2.5026,
      "step": 20910
    },
    {
      "epoch": 1.4039461763028087,
      "grad_norm": 0.7435107231140137,
      "learning_rate": 0.00011518135711965841,
      "loss": 2.469,
      "step": 20920
    },
    {
      "epoch": 1.4046172947216538,
      "grad_norm": 0.6763120889663696,
      "learning_rate": 0.00011510974088814319,
      "loss": 2.47,
      "step": 20930
    },
    {
      "epoch": 1.4052884131404986,
      "grad_norm": 0.7165138125419617,
      "learning_rate": 0.00011503811672507616,
      "loss": 2.4582,
      "step": 20940
    },
    {
      "epoch": 1.4059595315593436,
      "grad_norm": 0.7694848775863647,
      "learning_rate": 0.000114966484668055,
      "loss": 2.509,
      "step": 20950
    },
    {
      "epoch": 1.4059595315593436,
      "eval_bleu": 21.464863146337553,
      "eval_gen_len": 29.115,
      "eval_loss": 2.9364986419677734,
      "eval_runtime": 67.4463,
      "eval_samples_per_second": 14.827,
      "eval_steps_per_second": 0.934,
      "step": 20950
    },
    {
      "epoch": 1.4066306499781887,
      "grad_norm": 0.7097268104553223,
      "learning_rate": 0.0001148948447546815,
      "loss": 2.4892,
      "step": 20960
    },
    {
      "epoch": 1.4073017683970337,
      "grad_norm": 0.7087773084640503,
      "learning_rate": 0.00011482319702256159,
      "loss": 2.4804,
      "step": 20970
    },
    {
      "epoch": 1.4079728868158787,
      "grad_norm": 0.7210528254508972,
      "learning_rate": 0.00011475154150930525,
      "loss": 2.4418,
      "step": 20980
    },
    {
      "epoch": 1.4086440052347236,
      "grad_norm": 0.6797657012939453,
      "learning_rate": 0.00011467987825252662,
      "loss": 2.4659,
      "step": 20990
    },
    {
      "epoch": 1.4093151236535686,
      "grad_norm": 0.6860945224761963,
      "learning_rate": 0.00011460820728984384,
      "loss": 2.4355,
      "step": 21000
    },
    {
      "epoch": 1.4093151236535686,
      "eval_bleu": 21.143515408947902,
      "eval_gen_len": 29.05,
      "eval_loss": 2.9400906562805176,
      "eval_runtime": 67.5315,
      "eval_samples_per_second": 14.808,
      "eval_steps_per_second": 0.933,
      "step": 21000
    },
    {
      "epoch": 1.4099862420724136,
      "grad_norm": 0.6719287633895874,
      "learning_rate": 0.00011453652865887921,
      "loss": 2.4592,
      "step": 21010
    },
    {
      "epoch": 1.4106573604912587,
      "grad_norm": 0.7093518376350403,
      "learning_rate": 0.00011446484239725888,
      "loss": 2.5383,
      "step": 21020
    },
    {
      "epoch": 1.4113284789101037,
      "grad_norm": 0.7910131216049194,
      "learning_rate": 0.00011439314854261313,
      "loss": 2.5283,
      "step": 21030
    },
    {
      "epoch": 1.4119995973289488,
      "grad_norm": 0.7154982686042786,
      "learning_rate": 0.0001143214471325762,
      "loss": 2.5247,
      "step": 21040
    },
    {
      "epoch": 1.4126707157477938,
      "grad_norm": 0.6857572197914124,
      "learning_rate": 0.0001142497382047863,
      "loss": 2.5279,
      "step": 21050
    },
    {
      "epoch": 1.4126707157477938,
      "eval_bleu": 20.99023991854699,
      "eval_gen_len": 28.888,
      "eval_loss": 2.939486503601074,
      "eval_runtime": 64.0538,
      "eval_samples_per_second": 15.612,
      "eval_steps_per_second": 0.984,
      "step": 21050
    },
    {
      "epoch": 1.4133418341666388,
      "grad_norm": 0.6666979193687439,
      "learning_rate": 0.00011417802179688558,
      "loss": 2.5093,
      "step": 21060
    },
    {
      "epoch": 1.4140129525854837,
      "grad_norm": 0.6251600980758667,
      "learning_rate": 0.00011410629794652003,
      "loss": 2.4641,
      "step": 21070
    },
    {
      "epoch": 1.4146840710043287,
      "grad_norm": 0.6373838782310486,
      "learning_rate": 0.00011403456669133974,
      "loss": 2.46,
      "step": 21080
    },
    {
      "epoch": 1.4153551894231737,
      "grad_norm": 0.7748715281486511,
      "learning_rate": 0.00011396282806899853,
      "loss": 2.536,
      "step": 21090
    },
    {
      "epoch": 1.4160263078420188,
      "grad_norm": 0.6730486750602722,
      "learning_rate": 0.00011389108211715414,
      "loss": 2.5101,
      "step": 21100
    },
    {
      "epoch": 1.4160263078420188,
      "eval_bleu": 21.25675578838368,
      "eval_gen_len": 28.94,
      "eval_loss": 2.9401822090148926,
      "eval_runtime": 64.3031,
      "eval_samples_per_second": 15.551,
      "eval_steps_per_second": 0.98,
      "step": 21100
    },
    {
      "epoch": 1.4166974262608638,
      "grad_norm": 0.7355565428733826,
      "learning_rate": 0.00011381932887346813,
      "loss": 2.4809,
      "step": 21110
    },
    {
      "epoch": 1.4173685446797086,
      "grad_norm": 0.6833245158195496,
      "learning_rate": 0.00011374756837560592,
      "loss": 2.4879,
      "step": 21120
    },
    {
      "epoch": 1.4180396630985537,
      "grad_norm": 0.7189375162124634,
      "learning_rate": 0.00011367580066123673,
      "loss": 2.4514,
      "step": 21130
    },
    {
      "epoch": 1.4187107815173987,
      "grad_norm": 0.7449078559875488,
      "learning_rate": 0.0001136040257680336,
      "loss": 2.4367,
      "step": 21140
    },
    {
      "epoch": 1.4193818999362438,
      "grad_norm": 0.7376638054847717,
      "learning_rate": 0.00011353224373367324,
      "loss": 2.4426,
      "step": 21150
    },
    {
      "epoch": 1.4193818999362438,
      "eval_bleu": 21.144656330471676,
      "eval_gen_len": 28.928,
      "eval_loss": 2.941657066345215,
      "eval_runtime": 64.0168,
      "eval_samples_per_second": 15.621,
      "eval_steps_per_second": 0.984,
      "step": 21150
    },
    {
      "epoch": 1.4200530183550888,
      "grad_norm": 0.6608697772026062,
      "learning_rate": 0.00011346045459583621,
      "loss": 2.5211,
      "step": 21160
    },
    {
      "epoch": 1.4207241367739338,
      "grad_norm": 0.6845714449882507,
      "learning_rate": 0.00011338865839220675,
      "loss": 2.4799,
      "step": 21170
    },
    {
      "epoch": 1.4213952551927789,
      "grad_norm": 0.6608578562736511,
      "learning_rate": 0.00011331685516047284,
      "loss": 2.4852,
      "step": 21180
    },
    {
      "epoch": 1.4220663736116237,
      "grad_norm": 0.7424838542938232,
      "learning_rate": 0.00011324504493832608,
      "loss": 2.4531,
      "step": 21190
    },
    {
      "epoch": 1.4227374920304687,
      "grad_norm": 0.7538447976112366,
      "learning_rate": 0.00011317322776346184,
      "loss": 2.5554,
      "step": 21200
    },
    {
      "epoch": 1.4227374920304687,
      "eval_bleu": 21.24635519069445,
      "eval_gen_len": 28.904,
      "eval_loss": 2.9365670680999756,
      "eval_runtime": 63.8186,
      "eval_samples_per_second": 15.669,
      "eval_steps_per_second": 0.987,
      "step": 21200
    },
    {
      "epoch": 1.4234086104493138,
      "grad_norm": 0.7243637442588806,
      "learning_rate": 0.00011310140367357906,
      "loss": 2.5095,
      "step": 21210
    },
    {
      "epoch": 1.4240797288681588,
      "grad_norm": 0.6379173398017883,
      "learning_rate": 0.00011302957270638037,
      "loss": 2.4644,
      "step": 21220
    },
    {
      "epoch": 1.4247508472870039,
      "grad_norm": 0.7349067330360413,
      "learning_rate": 0.00011295773489957198,
      "loss": 2.5046,
      "step": 21230
    },
    {
      "epoch": 1.4254219657058487,
      "grad_norm": 0.7205206751823425,
      "learning_rate": 0.0001128858902908636,
      "loss": 2.4996,
      "step": 21240
    },
    {
      "epoch": 1.4260930841246937,
      "grad_norm": 0.7333466410636902,
      "learning_rate": 0.0001128140389179687,
      "loss": 2.4964,
      "step": 21250
    },
    {
      "epoch": 1.4260930841246937,
      "eval_bleu": 21.234447596377816,
      "eval_gen_len": 28.841,
      "eval_loss": 2.943188190460205,
      "eval_runtime": 63.7078,
      "eval_samples_per_second": 15.697,
      "eval_steps_per_second": 0.989,
      "step": 21250
    },
    {
      "epoch": 1.4267642025435388,
      "grad_norm": 0.685109555721283,
      "learning_rate": 0.00011274218081860412,
      "loss": 2.4639,
      "step": 21260
    },
    {
      "epoch": 1.4274353209623838,
      "grad_norm": 0.7352333068847656,
      "learning_rate": 0.00011267031603049038,
      "loss": 2.4835,
      "step": 21270
    },
    {
      "epoch": 1.4281064393812288,
      "grad_norm": 0.6800729632377625,
      "learning_rate": 0.00011259844459135143,
      "loss": 2.472,
      "step": 21280
    },
    {
      "epoch": 1.4287775578000739,
      "grad_norm": 0.6642618775367737,
      "learning_rate": 0.00011252656653891467,
      "loss": 2.4453,
      "step": 21290
    },
    {
      "epoch": 1.429448676218919,
      "grad_norm": 0.6531319618225098,
      "learning_rate": 0.00011245468191091108,
      "loss": 2.4665,
      "step": 21300
    },
    {
      "epoch": 1.429448676218919,
      "eval_bleu": 21.105810077133338,
      "eval_gen_len": 29.107,
      "eval_loss": 2.940128803253174,
      "eval_runtime": 67.6025,
      "eval_samples_per_second": 14.792,
      "eval_steps_per_second": 0.932,
      "step": 21300
    },
    {
      "epoch": 1.430119794637764,
      "grad_norm": 0.7466737627983093,
      "learning_rate": 0.00011238279074507503,
      "loss": 2.4771,
      "step": 21310
    },
    {
      "epoch": 1.4307909130566088,
      "grad_norm": 0.7071586847305298,
      "learning_rate": 0.00011231089307914433,
      "loss": 2.4471,
      "step": 21320
    },
    {
      "epoch": 1.4314620314754538,
      "grad_norm": 0.7878448367118835,
      "learning_rate": 0.00011223898895086016,
      "loss": 2.4865,
      "step": 21330
    },
    {
      "epoch": 1.4321331498942989,
      "grad_norm": 0.7398644685745239,
      "learning_rate": 0.00011216707839796717,
      "loss": 2.5084,
      "step": 21340
    },
    {
      "epoch": 1.432804268313144,
      "grad_norm": 0.7214520573616028,
      "learning_rate": 0.00011209516145821333,
      "loss": 2.447,
      "step": 21350
    },
    {
      "epoch": 1.432804268313144,
      "eval_bleu": 21.385000459624017,
      "eval_gen_len": 28.855,
      "eval_loss": 2.9407546520233154,
      "eval_runtime": 64.026,
      "eval_samples_per_second": 15.619,
      "eval_steps_per_second": 0.984,
      "step": 21350
    },
    {
      "epoch": 1.433475386731989,
      "grad_norm": 0.6500616669654846,
      "learning_rate": 0.00011202323816934999,
      "loss": 2.5337,
      "step": 21360
    },
    {
      "epoch": 1.4341465051508338,
      "grad_norm": 0.6491212844848633,
      "learning_rate": 0.00011195130856913181,
      "loss": 2.4715,
      "step": 21370
    },
    {
      "epoch": 1.4348176235696788,
      "grad_norm": 0.6932840943336487,
      "learning_rate": 0.00011187937269531676,
      "loss": 2.47,
      "step": 21380
    },
    {
      "epoch": 1.4354887419885238,
      "grad_norm": 0.7418805956840515,
      "learning_rate": 0.00011180743058566616,
      "loss": 2.473,
      "step": 21390
    },
    {
      "epoch": 1.4361598604073689,
      "grad_norm": 0.7420685887336731,
      "learning_rate": 0.00011173548227794455,
      "loss": 2.5045,
      "step": 21400
    },
    {
      "epoch": 1.4361598604073689,
      "eval_bleu": 21.467381476341213,
      "eval_gen_len": 28.844,
      "eval_loss": 2.9388155937194824,
      "eval_runtime": 64.3092,
      "eval_samples_per_second": 15.55,
      "eval_steps_per_second": 0.98,
      "step": 21400
    },
    {
      "epoch": 1.436830978826214,
      "grad_norm": 0.6394181251525879,
      "learning_rate": 0.00011166352780991969,
      "loss": 2.4857,
      "step": 21410
    },
    {
      "epoch": 1.437502097245059,
      "grad_norm": 0.6833469271659851,
      "learning_rate": 0.00011159156721936266,
      "loss": 2.4463,
      "step": 21420
    },
    {
      "epoch": 1.438173215663904,
      "grad_norm": 0.6610981822013855,
      "learning_rate": 0.00011151960054404766,
      "loss": 2.4667,
      "step": 21430
    },
    {
      "epoch": 1.438844334082749,
      "grad_norm": 0.6528098583221436,
      "learning_rate": 0.00011144762782175222,
      "loss": 2.5034,
      "step": 21440
    },
    {
      "epoch": 1.4395154525015939,
      "grad_norm": 0.7207186222076416,
      "learning_rate": 0.00011137564909025691,
      "loss": 2.4599,
      "step": 21450
    },
    {
      "epoch": 1.4395154525015939,
      "eval_bleu": 21.137882263762297,
      "eval_gen_len": 28.828,
      "eval_loss": 2.9418108463287354,
      "eval_runtime": 64.0008,
      "eval_samples_per_second": 15.625,
      "eval_steps_per_second": 0.984,
      "step": 21450
    },
    {
      "epoch": 1.440186570920439,
      "grad_norm": 0.6890172958374023,
      "learning_rate": 0.00011130366438734547,
      "loss": 2.4979,
      "step": 21460
    },
    {
      "epoch": 1.440857689339284,
      "grad_norm": 0.6732693314552307,
      "learning_rate": 0.00011123167375080488,
      "loss": 2.5092,
      "step": 21470
    },
    {
      "epoch": 1.441528807758129,
      "grad_norm": 0.6820975542068481,
      "learning_rate": 0.00011115967721842511,
      "loss": 2.4914,
      "step": 21480
    },
    {
      "epoch": 1.4421999261769738,
      "grad_norm": 0.7174848318099976,
      "learning_rate": 0.00011108767482799931,
      "loss": 2.4944,
      "step": 21490
    },
    {
      "epoch": 1.4428710445958188,
      "grad_norm": 0.7138962149620056,
      "learning_rate": 0.00011101566661732366,
      "loss": 2.4879,
      "step": 21500
    },
    {
      "epoch": 1.4428710445958188,
      "eval_bleu": 21.310891074104447,
      "eval_gen_len": 29.252,
      "eval_loss": 2.9346837997436523,
      "eval_runtime": 67.9003,
      "eval_samples_per_second": 14.727,
      "eval_steps_per_second": 0.928,
      "step": 21500
    },
    {
      "epoch": 1.4435421630146639,
      "grad_norm": 0.6691178679466248,
      "learning_rate": 0.0001109436526241974,
      "loss": 2.4448,
      "step": 21510
    },
    {
      "epoch": 1.444213281433509,
      "grad_norm": 0.6434569954872131,
      "learning_rate": 0.00011087163288642284,
      "loss": 2.4368,
      "step": 21520
    },
    {
      "epoch": 1.444884399852354,
      "grad_norm": 0.6888874769210815,
      "learning_rate": 0.00011079960744180524,
      "loss": 2.4906,
      "step": 21530
    },
    {
      "epoch": 1.445555518271199,
      "grad_norm": 0.7179876565933228,
      "learning_rate": 0.00011072757632815294,
      "loss": 2.4777,
      "step": 21540
    },
    {
      "epoch": 1.446226636690044,
      "grad_norm": 0.7311023473739624,
      "learning_rate": 0.00011065553958327716,
      "loss": 2.5387,
      "step": 21550
    },
    {
      "epoch": 1.446226636690044,
      "eval_bleu": 20.92167541987684,
      "eval_gen_len": 29.183,
      "eval_loss": 2.9414710998535156,
      "eval_runtime": 68.2734,
      "eval_samples_per_second": 14.647,
      "eval_steps_per_second": 0.923,
      "step": 21550
    },
    {
      "epoch": 1.446897755108889,
      "grad_norm": 0.6359661817550659,
      "learning_rate": 0.00011058349724499218,
      "loss": 2.4952,
      "step": 21560
    },
    {
      "epoch": 1.447568873527734,
      "grad_norm": 0.7021963596343994,
      "learning_rate": 0.00011051144935111513,
      "loss": 2.4751,
      "step": 21570
    },
    {
      "epoch": 1.448239991946579,
      "grad_norm": 0.6921625137329102,
      "learning_rate": 0.00011043939593946613,
      "loss": 2.4945,
      "step": 21580
    },
    {
      "epoch": 1.448911110365424,
      "grad_norm": 0.7570368647575378,
      "learning_rate": 0.00011036733704786809,
      "loss": 2.5062,
      "step": 21590
    },
    {
      "epoch": 1.449582228784269,
      "grad_norm": 0.7037112712860107,
      "learning_rate": 0.00011029527271414688,
      "loss": 2.5426,
      "step": 21600
    },
    {
      "epoch": 1.449582228784269,
      "eval_bleu": 20.67466475381278,
      "eval_gen_len": 28.894,
      "eval_loss": 2.9413156509399414,
      "eval_runtime": 64.1346,
      "eval_samples_per_second": 15.592,
      "eval_steps_per_second": 0.982,
      "step": 21600
    },
    {
      "epoch": 1.450253347203114,
      "grad_norm": 0.6940298676490784,
      "learning_rate": 0.00011022320297613124,
      "loss": 2.5103,
      "step": 21610
    },
    {
      "epoch": 1.4509244656219589,
      "grad_norm": 0.6548211574554443,
      "learning_rate": 0.00011015112787165272,
      "loss": 2.5115,
      "step": 21620
    },
    {
      "epoch": 1.451595584040804,
      "grad_norm": 0.6699470281600952,
      "learning_rate": 0.00011007904743854567,
      "loss": 2.4768,
      "step": 21630
    },
    {
      "epoch": 1.452266702459649,
      "grad_norm": 0.7126599550247192,
      "learning_rate": 0.00011000696171464721,
      "loss": 2.4343,
      "step": 21640
    },
    {
      "epoch": 1.452937820878494,
      "grad_norm": 0.7384676933288574,
      "learning_rate": 0.00010993487073779733,
      "loss": 2.4786,
      "step": 21650
    },
    {
      "epoch": 1.452937820878494,
      "eval_bleu": 20.883691737477818,
      "eval_gen_len": 29.264,
      "eval_loss": 2.9386982917785645,
      "eval_runtime": 67.7012,
      "eval_samples_per_second": 14.771,
      "eval_steps_per_second": 0.931,
      "step": 21650
    },
    {
      "epoch": 1.453608939297339,
      "grad_norm": 0.7245804071426392,
      "learning_rate": 0.00010986277454583873,
      "loss": 2.5361,
      "step": 21660
    },
    {
      "epoch": 1.454280057716184,
      "grad_norm": 0.7195674777030945,
      "learning_rate": 0.00010979067317661682,
      "loss": 2.4527,
      "step": 21670
    },
    {
      "epoch": 1.4549511761350291,
      "grad_norm": 0.6693668365478516,
      "learning_rate": 0.00010971856666797973,
      "loss": 2.5275,
      "step": 21680
    },
    {
      "epoch": 1.4556222945538742,
      "grad_norm": 0.7061782479286194,
      "learning_rate": 0.00010964645505777832,
      "loss": 2.4843,
      "step": 21690
    },
    {
      "epoch": 1.456293412972719,
      "grad_norm": 0.6387813091278076,
      "learning_rate": 0.00010957433838386615,
      "loss": 2.4307,
      "step": 21700
    },
    {
      "epoch": 1.456293412972719,
      "eval_bleu": 21.2649008891108,
      "eval_gen_len": 29.076,
      "eval_loss": 2.9401023387908936,
      "eval_runtime": 67.9418,
      "eval_samples_per_second": 14.718,
      "eval_steps_per_second": 0.927,
      "step": 21700
    },
    {
      "epoch": 1.456964531391564,
      "grad_norm": 0.7532282471656799,
      "learning_rate": 0.00010950221668409938,
      "loss": 2.5156,
      "step": 21710
    },
    {
      "epoch": 1.457635649810409,
      "grad_norm": 0.6630398631095886,
      "learning_rate": 0.00010943008999633684,
      "loss": 2.5013,
      "step": 21720
    },
    {
      "epoch": 1.458306768229254,
      "grad_norm": 0.7698704600334167,
      "learning_rate": 0.00010935795835843993,
      "loss": 2.4879,
      "step": 21730
    },
    {
      "epoch": 1.4589778866480991,
      "grad_norm": 0.6119897365570068,
      "learning_rate": 0.00010928582180827274,
      "loss": 2.4226,
      "step": 21740
    },
    {
      "epoch": 1.459649005066944,
      "grad_norm": 0.7465013265609741,
      "learning_rate": 0.00010921368038370185,
      "loss": 2.5284,
      "step": 21750
    },
    {
      "epoch": 1.459649005066944,
      "eval_bleu": 20.87954696740077,
      "eval_gen_len": 28.854,
      "eval_loss": 2.941291332244873,
      "eval_runtime": 63.6792,
      "eval_samples_per_second": 15.704,
      "eval_steps_per_second": 0.989,
      "step": 21750
    },
    {
      "epoch": 1.460320123485789,
      "grad_norm": 0.7461017966270447,
      "learning_rate": 0.00010914153412259651,
      "loss": 2.4705,
      "step": 21760
    },
    {
      "epoch": 1.460991241904634,
      "grad_norm": 0.6888421773910522,
      "learning_rate": 0.00010906938306282835,
      "loss": 2.4941,
      "step": 21770
    },
    {
      "epoch": 1.461662360323479,
      "grad_norm": 0.664662778377533,
      "learning_rate": 0.00010899722724227162,
      "loss": 2.4515,
      "step": 21780
    },
    {
      "epoch": 1.462333478742324,
      "grad_norm": 0.6559476852416992,
      "learning_rate": 0.00010892506669880309,
      "loss": 2.517,
      "step": 21790
    },
    {
      "epoch": 1.4630045971611692,
      "grad_norm": 0.6797605752944946,
      "learning_rate": 0.00010885290147030196,
      "loss": 2.5486,
      "step": 21800
    },
    {
      "epoch": 1.4630045971611692,
      "eval_bleu": 21.047140560746378,
      "eval_gen_len": 29.028,
      "eval_loss": 2.9367144107818604,
      "eval_runtime": 66.7236,
      "eval_samples_per_second": 14.987,
      "eval_steps_per_second": 0.944,
      "step": 21800
    },
    {
      "epoch": 1.4636757155800142,
      "grad_norm": 0.6725021004676819,
      "learning_rate": 0.0001087807315946499,
      "loss": 2.5476,
      "step": 21810
    },
    {
      "epoch": 1.4643468339988592,
      "grad_norm": 0.6689722537994385,
      "learning_rate": 0.000108708557109731,
      "loss": 2.4527,
      "step": 21820
    },
    {
      "epoch": 1.465017952417704,
      "grad_norm": 0.6801691055297852,
      "learning_rate": 0.00010863637805343179,
      "loss": 2.4631,
      "step": 21830
    },
    {
      "epoch": 1.465689070836549,
      "grad_norm": 0.7624870538711548,
      "learning_rate": 0.00010856419446364123,
      "loss": 2.5092,
      "step": 21840
    },
    {
      "epoch": 1.4663601892553941,
      "grad_norm": 0.6880831122398376,
      "learning_rate": 0.00010849200637825063,
      "loss": 2.4328,
      "step": 21850
    },
    {
      "epoch": 1.4663601892553941,
      "eval_bleu": 21.322612541309837,
      "eval_gen_len": 29.253,
      "eval_loss": 2.942354202270508,
      "eval_runtime": 70.1975,
      "eval_samples_per_second": 14.246,
      "eval_steps_per_second": 0.897,
      "step": 21850
    },
    {
      "epoch": 1.4670313076742392,
      "grad_norm": 0.753041684627533,
      "learning_rate": 0.00010841981383515365,
      "loss": 2.515,
      "step": 21860
    },
    {
      "epoch": 1.467702426093084,
      "grad_norm": 0.7518863081932068,
      "learning_rate": 0.00010834761687224629,
      "loss": 2.4844,
      "step": 21870
    },
    {
      "epoch": 1.468373544511929,
      "grad_norm": 0.71853107213974,
      "learning_rate": 0.00010827541552742685,
      "loss": 2.4412,
      "step": 21880
    },
    {
      "epoch": 1.469044662930774,
      "grad_norm": 0.7242953181266785,
      "learning_rate": 0.00010820320983859606,
      "loss": 2.4548,
      "step": 21890
    },
    {
      "epoch": 1.469715781349619,
      "grad_norm": 0.6686941981315613,
      "learning_rate": 0.00010813099984365673,
      "loss": 2.4286,
      "step": 21900
    },
    {
      "epoch": 1.469715781349619,
      "eval_bleu": 21.21312164641568,
      "eval_gen_len": 28.859,
      "eval_loss": 2.940476179122925,
      "eval_runtime": 63.9049,
      "eval_samples_per_second": 15.648,
      "eval_steps_per_second": 0.986,
      "step": 21900
    },
    {
      "epoch": 1.4703868997684642,
      "grad_norm": 0.702294647693634,
      "learning_rate": 0.0001080587855805141,
      "loss": 2.4535,
      "step": 21910
    },
    {
      "epoch": 1.4710580181873092,
      "grad_norm": 0.6985085606575012,
      "learning_rate": 0.00010798656708707553,
      "loss": 2.4938,
      "step": 21920
    },
    {
      "epoch": 1.4717291366061542,
      "grad_norm": 0.6793025732040405,
      "learning_rate": 0.00010791434440125065,
      "loss": 2.4804,
      "step": 21930
    },
    {
      "epoch": 1.4724002550249993,
      "grad_norm": 0.6791211366653442,
      "learning_rate": 0.00010784211756095137,
      "loss": 2.4472,
      "step": 21940
    },
    {
      "epoch": 1.473071373443844,
      "grad_norm": 0.7276175618171692,
      "learning_rate": 0.00010776988660409163,
      "loss": 2.4476,
      "step": 21950
    },
    {
      "epoch": 1.473071373443844,
      "eval_bleu": 21.21882835438228,
      "eval_gen_len": 28.794,
      "eval_loss": 2.937504768371582,
      "eval_runtime": 64.3635,
      "eval_samples_per_second": 15.537,
      "eval_steps_per_second": 0.979,
      "step": 21950
    },
    {
      "epoch": 1.4737424918626891,
      "grad_norm": 0.6169907450675964,
      "learning_rate": 0.00010769765156858763,
      "loss": 2.4184,
      "step": 21960
    },
    {
      "epoch": 1.4744136102815342,
      "grad_norm": 0.7014363408088684,
      "learning_rate": 0.00010762541249235767,
      "loss": 2.4873,
      "step": 21970
    },
    {
      "epoch": 1.4750847287003792,
      "grad_norm": 0.6638818383216858,
      "learning_rate": 0.0001075531694133222,
      "loss": 2.4827,
      "step": 21980
    },
    {
      "epoch": 1.4757558471192243,
      "grad_norm": 0.7294805645942688,
      "learning_rate": 0.00010748092236940376,
      "loss": 2.5129,
      "step": 21990
    },
    {
      "epoch": 1.476426965538069,
      "grad_norm": 0.7532600164413452,
      "learning_rate": 0.00010740867139852697,
      "loss": 2.4764,
      "step": 22000
    },
    {
      "epoch": 1.476426965538069,
      "eval_bleu": 21.460848622212705,
      "eval_gen_len": 28.928,
      "eval_loss": 2.936081647872925,
      "eval_runtime": 63.7805,
      "eval_samples_per_second": 15.679,
      "eval_steps_per_second": 0.988,
      "step": 22000
    },
    {
      "epoch": 1.477098083956914,
      "grad_norm": 0.6803361773490906,
      "learning_rate": 0.0001073364165386185,
      "loss": 2.4814,
      "step": 22010
    },
    {
      "epoch": 1.4777692023757591,
      "grad_norm": 0.6848105192184448,
      "learning_rate": 0.0001072641578276071,
      "loss": 2.4908,
      "step": 22020
    },
    {
      "epoch": 1.4784403207946042,
      "grad_norm": 0.6836701035499573,
      "learning_rate": 0.00010719189530342348,
      "loss": 2.4709,
      "step": 22030
    },
    {
      "epoch": 1.4791114392134492,
      "grad_norm": 0.7448415160179138,
      "learning_rate": 0.00010711962900400039,
      "loss": 2.4943,
      "step": 22040
    },
    {
      "epoch": 1.4797825576322943,
      "grad_norm": 0.6494995355606079,
      "learning_rate": 0.00010704735896727255,
      "loss": 2.4451,
      "step": 22050
    },
    {
      "epoch": 1.4797825576322943,
      "eval_bleu": 21.154539810914905,
      "eval_gen_len": 28.821,
      "eval_loss": 2.9401137828826904,
      "eval_runtime": 63.7015,
      "eval_samples_per_second": 15.698,
      "eval_steps_per_second": 0.989,
      "step": 22050
    },
    {
      "epoch": 1.4804536760511393,
      "grad_norm": 0.7065387964248657,
      "learning_rate": 0.00010697508523117667,
      "loss": 2.5,
      "step": 22060
    },
    {
      "epoch": 1.4811247944699844,
      "grad_norm": 0.682499885559082,
      "learning_rate": 0.00010690280783365141,
      "loss": 2.4275,
      "step": 22070
    },
    {
      "epoch": 1.4817959128888292,
      "grad_norm": 0.6251890659332275,
      "learning_rate": 0.00010683052681263726,
      "loss": 2.4831,
      "step": 22080
    },
    {
      "epoch": 1.4824670313076742,
      "grad_norm": 0.7165964245796204,
      "learning_rate": 0.00010675824220607668,
      "loss": 2.494,
      "step": 22090
    },
    {
      "epoch": 1.4831381497265193,
      "grad_norm": 0.7294588088989258,
      "learning_rate": 0.00010668595405191409,
      "loss": 2.5279,
      "step": 22100
    },
    {
      "epoch": 1.4831381497265193,
      "eval_bleu": 21.344561763698145,
      "eval_gen_len": 28.98,
      "eval_loss": 2.9360454082489014,
      "eval_runtime": 64.5162,
      "eval_samples_per_second": 15.5,
      "eval_steps_per_second": 0.976,
      "step": 22100
    },
    {
      "epoch": 1.4838092681453643,
      "grad_norm": 0.6797358989715576,
      "learning_rate": 0.00010661366238809558,
      "loss": 2.4704,
      "step": 22110
    },
    {
      "epoch": 1.4844803865642093,
      "grad_norm": 0.7529571652412415,
      "learning_rate": 0.00010654136725256927,
      "loss": 2.4722,
      "step": 22120
    },
    {
      "epoch": 1.4851515049830541,
      "grad_norm": 0.6520865559577942,
      "learning_rate": 0.00010646906868328497,
      "loss": 2.5415,
      "step": 22130
    },
    {
      "epoch": 1.4858226234018992,
      "grad_norm": 0.7253370881080627,
      "learning_rate": 0.00010639676671819436,
      "loss": 2.467,
      "step": 22140
    },
    {
      "epoch": 1.4864937418207442,
      "grad_norm": 0.7447059154510498,
      "learning_rate": 0.00010632446139525092,
      "loss": 2.514,
      "step": 22150
    },
    {
      "epoch": 1.4864937418207442,
      "eval_bleu": 21.17098372255205,
      "eval_gen_len": 28.835,
      "eval_loss": 2.938060998916626,
      "eval_runtime": 63.4051,
      "eval_samples_per_second": 15.772,
      "eval_steps_per_second": 0.994,
      "step": 22150
    },
    {
      "epoch": 1.4871648602395893,
      "grad_norm": 0.6495828628540039,
      "learning_rate": 0.00010625215275240985,
      "loss": 2.4654,
      "step": 22160
    },
    {
      "epoch": 1.4878359786584343,
      "grad_norm": 0.7344114184379578,
      "learning_rate": 0.00010617984082762806,
      "loss": 2.5455,
      "step": 22170
    },
    {
      "epoch": 1.4885070970772794,
      "grad_norm": 0.6816137433052063,
      "learning_rate": 0.00010610752565886429,
      "loss": 2.4358,
      "step": 22180
    },
    {
      "epoch": 1.4891782154961244,
      "grad_norm": 0.6359168291091919,
      "learning_rate": 0.00010603520728407887,
      "loss": 2.442,
      "step": 22190
    },
    {
      "epoch": 1.4898493339149694,
      "grad_norm": 0.6426284313201904,
      "learning_rate": 0.00010596288574123392,
      "loss": 2.4814,
      "step": 22200
    },
    {
      "epoch": 1.4898493339149694,
      "eval_bleu": 21.152376105404993,
      "eval_gen_len": 28.798,
      "eval_loss": 2.9393105506896973,
      "eval_runtime": 63.8284,
      "eval_samples_per_second": 15.667,
      "eval_steps_per_second": 0.987,
      "step": 22200
    },
    {
      "epoch": 1.4905204523338142,
      "grad_norm": 0.6792503595352173,
      "learning_rate": 0.00010589056106829312,
      "loss": 2.4984,
      "step": 22210
    },
    {
      "epoch": 1.4911915707526593,
      "grad_norm": 0.6653790473937988,
      "learning_rate": 0.00010581823330322183,
      "loss": 2.4767,
      "step": 22220
    },
    {
      "epoch": 1.4918626891715043,
      "grad_norm": 0.7071572542190552,
      "learning_rate": 0.00010574590248398708,
      "loss": 2.4687,
      "step": 22230
    },
    {
      "epoch": 1.4925338075903494,
      "grad_norm": 0.7386501431465149,
      "learning_rate": 0.00010567356864855744,
      "loss": 2.5538,
      "step": 22240
    },
    {
      "epoch": 1.4932049260091942,
      "grad_norm": 0.6950784921646118,
      "learning_rate": 0.00010560123183490312,
      "loss": 2.5379,
      "step": 22250
    },
    {
      "epoch": 1.4932049260091942,
      "eval_bleu": 21.02454047741344,
      "eval_gen_len": 28.685,
      "eval_loss": 2.9381539821624756,
      "eval_runtime": 63.7992,
      "eval_samples_per_second": 15.674,
      "eval_steps_per_second": 0.987,
      "step": 22250
    },
    {
      "epoch": 1.4938760444280392,
      "grad_norm": 0.6211643815040588,
      "learning_rate": 0.00010552889208099581,
      "loss": 2.4604,
      "step": 22260
    },
    {
      "epoch": 1.4945471628468843,
      "grad_norm": 0.7068456411361694,
      "learning_rate": 0.00010545654942480883,
      "loss": 2.4837,
      "step": 22270
    },
    {
      "epoch": 1.4952182812657293,
      "grad_norm": 0.6863744854927063,
      "learning_rate": 0.00010538420390431698,
      "loss": 2.47,
      "step": 22280
    },
    {
      "epoch": 1.4958893996845744,
      "grad_norm": 0.6451379656791687,
      "learning_rate": 0.00010531185555749659,
      "loss": 2.5051,
      "step": 22290
    },
    {
      "epoch": 1.4965605181034194,
      "grad_norm": 0.7359557151794434,
      "learning_rate": 0.00010523950442232544,
      "loss": 2.5148,
      "step": 22300
    },
    {
      "epoch": 1.4965605181034194,
      "eval_bleu": 21.193015915888207,
      "eval_gen_len": 28.744,
      "eval_loss": 2.94027042388916,
      "eval_runtime": 63.0034,
      "eval_samples_per_second": 15.872,
      "eval_steps_per_second": 1.0,
      "step": 22300
    },
    {
      "epoch": 1.4972316365222644,
      "grad_norm": 0.702271580696106,
      "learning_rate": 0.00010516715053678279,
      "loss": 2.465,
      "step": 22310
    },
    {
      "epoch": 1.4979027549411095,
      "grad_norm": 0.6829217076301575,
      "learning_rate": 0.00010509479393884934,
      "loss": 2.4826,
      "step": 22320
    },
    {
      "epoch": 1.4985738733599543,
      "grad_norm": 0.7226303219795227,
      "learning_rate": 0.00010502243466650723,
      "loss": 2.4975,
      "step": 22330
    },
    {
      "epoch": 1.4992449917787993,
      "grad_norm": 0.7188911437988281,
      "learning_rate": 0.00010495007275773998,
      "loss": 2.4429,
      "step": 22340
    },
    {
      "epoch": 1.4999161101976444,
      "grad_norm": 0.6669061183929443,
      "learning_rate": 0.00010487770825053249,
      "loss": 2.474,
      "step": 22350
    },
    {
      "epoch": 1.4999161101976444,
      "eval_bleu": 21.193199545966802,
      "eval_gen_len": 28.993,
      "eval_loss": 2.9380719661712646,
      "eval_runtime": 64.1747,
      "eval_samples_per_second": 15.582,
      "eval_steps_per_second": 0.982,
      "step": 22350
    },
    {
      "epoch": 1.5005872286164894,
      "grad_norm": 0.6626123189926147,
      "learning_rate": 0.00010480534118287108,
      "loss": 2.4529,
      "step": 22360
    },
    {
      "epoch": 1.5012583470353342,
      "grad_norm": 0.6446173787117004,
      "learning_rate": 0.00010473297159274335,
      "loss": 2.4769,
      "step": 22370
    },
    {
      "epoch": 1.5019294654541793,
      "grad_norm": 0.6544009447097778,
      "learning_rate": 0.00010466059951813826,
      "loss": 2.4229,
      "step": 22380
    },
    {
      "epoch": 1.5026005838730243,
      "grad_norm": 0.690457284450531,
      "learning_rate": 0.00010458822499704605,
      "loss": 2.4589,
      "step": 22390
    },
    {
      "epoch": 1.5032717022918693,
      "grad_norm": 0.6851180195808411,
      "learning_rate": 0.00010451584806745827,
      "loss": 2.4827,
      "step": 22400
    },
    {
      "epoch": 1.5032717022918693,
      "eval_bleu": 20.88831538095671,
      "eval_gen_len": 28.774,
      "eval_loss": 2.9399664402008057,
      "eval_runtime": 63.3239,
      "eval_samples_per_second": 15.792,
      "eval_steps_per_second": 0.995,
      "step": 22400
    },
    {
      "epoch": 1.5039428207107144,
      "grad_norm": 0.6981097459793091,
      "learning_rate": 0.00010444346876736769,
      "loss": 2.4519,
      "step": 22410
    },
    {
      "epoch": 1.5046139391295594,
      "grad_norm": 0.6826134324073792,
      "learning_rate": 0.00010437108713476835,
      "loss": 2.514,
      "step": 22420
    },
    {
      "epoch": 1.5052850575484045,
      "grad_norm": 0.7051617503166199,
      "learning_rate": 0.00010429870320765558,
      "loss": 2.4599,
      "step": 22430
    },
    {
      "epoch": 1.5059561759672495,
      "grad_norm": 0.6553483605384827,
      "learning_rate": 0.00010422631702402579,
      "loss": 2.4304,
      "step": 22440
    },
    {
      "epoch": 1.5066272943860946,
      "grad_norm": 0.6957069039344788,
      "learning_rate": 0.00010415392862187665,
      "loss": 2.5293,
      "step": 22450
    },
    {
      "epoch": 1.5066272943860946,
      "eval_bleu": 21.354680359995648,
      "eval_gen_len": 28.934,
      "eval_loss": 2.9322519302368164,
      "eval_runtime": 64.2698,
      "eval_samples_per_second": 15.559,
      "eval_steps_per_second": 0.98,
      "step": 22450
    },
    {
      "epoch": 1.5072984128049396,
      "grad_norm": 0.7883753776550293,
      "learning_rate": 0.000104081538039207,
      "loss": 2.5053,
      "step": 22460
    },
    {
      "epoch": 1.5079695312237844,
      "grad_norm": 0.725223183631897,
      "learning_rate": 0.00010400914531401681,
      "loss": 2.4909,
      "step": 22470
    },
    {
      "epoch": 1.5086406496426294,
      "grad_norm": 0.7057579159736633,
      "learning_rate": 0.00010393675048430718,
      "loss": 2.4777,
      "step": 22480
    },
    {
      "epoch": 1.5093117680614745,
      "grad_norm": 0.6279769539833069,
      "learning_rate": 0.00010386435358808026,
      "loss": 2.417,
      "step": 22490
    },
    {
      "epoch": 1.5099828864803193,
      "grad_norm": 0.6974954605102539,
      "learning_rate": 0.00010379195466333937,
      "loss": 2.4479,
      "step": 22500
    },
    {
      "epoch": 1.5099828864803193,
      "eval_bleu": 21.143249438117614,
      "eval_gen_len": 28.901,
      "eval_loss": 2.9391679763793945,
      "eval_runtime": 64.2863,
      "eval_samples_per_second": 15.555,
      "eval_steps_per_second": 0.98,
      "step": 22500
    },
    {
      "epoch": 1.5106540048991643,
      "grad_norm": 0.6686109900474548,
      "learning_rate": 0.00010371955374808886,
      "loss": 2.4718,
      "step": 22510
    },
    {
      "epoch": 1.5113251233180094,
      "grad_norm": 0.695893406867981,
      "learning_rate": 0.0001036471508803341,
      "loss": 2.4632,
      "step": 22520
    },
    {
      "epoch": 1.5119962417368544,
      "grad_norm": 0.6359604001045227,
      "learning_rate": 0.0001035747460980815,
      "loss": 2.5136,
      "step": 22530
    },
    {
      "epoch": 1.5126673601556995,
      "grad_norm": 0.6873396039009094,
      "learning_rate": 0.0001035023394393385,
      "loss": 2.4703,
      "step": 22540
    },
    {
      "epoch": 1.5133384785745445,
      "grad_norm": 0.6907935738563538,
      "learning_rate": 0.0001034299309421135,
      "loss": 2.4716,
      "step": 22550
    },
    {
      "epoch": 1.5133384785745445,
      "eval_bleu": 21.433867328375285,
      "eval_gen_len": 28.924,
      "eval_loss": 2.9348561763763428,
      "eval_runtime": 64.3155,
      "eval_samples_per_second": 15.548,
      "eval_steps_per_second": 0.98,
      "step": 22550
    },
    {
      "epoch": 1.5140095969933896,
      "grad_norm": 0.6944046020507812,
      "learning_rate": 0.00010335752064441588,
      "loss": 2.4627,
      "step": 22560
    },
    {
      "epoch": 1.5146807154122346,
      "grad_norm": 0.6870289444923401,
      "learning_rate": 0.00010328510858425595,
      "loss": 2.4651,
      "step": 22570
    },
    {
      "epoch": 1.5153518338310796,
      "grad_norm": 0.6538011431694031,
      "learning_rate": 0.00010321269479964493,
      "loss": 2.4902,
      "step": 22580
    },
    {
      "epoch": 1.5160229522499244,
      "grad_norm": 0.7021862864494324,
      "learning_rate": 0.00010314027932859498,
      "loss": 2.5314,
      "step": 22590
    },
    {
      "epoch": 1.5166940706687695,
      "grad_norm": 0.728201150894165,
      "learning_rate": 0.00010306786220911917,
      "loss": 2.4201,
      "step": 22600
    },
    {
      "epoch": 1.5166940706687695,
      "eval_bleu": 21.446532633292595,
      "eval_gen_len": 28.915,
      "eval_loss": 2.93705153465271,
      "eval_runtime": 64.3828,
      "eval_samples_per_second": 15.532,
      "eval_steps_per_second": 0.979,
      "step": 22600
    },
    {
      "epoch": 1.5173651890876145,
      "grad_norm": 0.7216376066207886,
      "learning_rate": 0.00010299544347923134,
      "loss": 2.5293,
      "step": 22610
    },
    {
      "epoch": 1.5180363075064596,
      "grad_norm": 0.6686733961105347,
      "learning_rate": 0.00010292302317694625,
      "loss": 2.4816,
      "step": 22620
    },
    {
      "epoch": 1.5187074259253044,
      "grad_norm": 0.7410642504692078,
      "learning_rate": 0.00010285060134027948,
      "loss": 2.4892,
      "step": 22630
    },
    {
      "epoch": 1.5193785443441494,
      "grad_norm": 0.7367489337921143,
      "learning_rate": 0.00010277817800724741,
      "loss": 2.4881,
      "step": 22640
    },
    {
      "epoch": 1.5200496627629945,
      "grad_norm": 0.6637278199195862,
      "learning_rate": 0.00010270575321586717,
      "loss": 2.464,
      "step": 22650
    },
    {
      "epoch": 1.5200496627629945,
      "eval_bleu": 21.168699007425534,
      "eval_gen_len": 28.852,
      "eval_loss": 2.934971332550049,
      "eval_runtime": 64.2362,
      "eval_samples_per_second": 15.568,
      "eval_steps_per_second": 0.981,
      "step": 22650
    },
    {
      "epoch": 1.5207207811818395,
      "grad_norm": 0.6869862675666809,
      "learning_rate": 0.00010263332700415668,
      "loss": 2.5367,
      "step": 22660
    },
    {
      "epoch": 1.5213918996006845,
      "grad_norm": 0.640654981136322,
      "learning_rate": 0.00010256089941013465,
      "loss": 2.5133,
      "step": 22670
    },
    {
      "epoch": 1.5220630180195296,
      "grad_norm": 0.6810671091079712,
      "learning_rate": 0.00010248847047182046,
      "loss": 2.4747,
      "step": 22680
    },
    {
      "epoch": 1.5227341364383746,
      "grad_norm": 0.678668737411499,
      "learning_rate": 0.00010241604022723421,
      "loss": 2.5052,
      "step": 22690
    },
    {
      "epoch": 1.5234052548572197,
      "grad_norm": 0.6890254020690918,
      "learning_rate": 0.0001023436087143967,
      "loss": 2.4818,
      "step": 22700
    },
    {
      "epoch": 1.5234052548572197,
      "eval_bleu": 21.37665509358682,
      "eval_gen_len": 28.878,
      "eval_loss": 2.9343321323394775,
      "eval_runtime": 64.6494,
      "eval_samples_per_second": 15.468,
      "eval_steps_per_second": 0.974,
      "step": 22700
    },
    {
      "epoch": 1.5240763732760647,
      "grad_norm": 0.6226195096969604,
      "learning_rate": 0.00010227117597132932,
      "loss": 2.4755,
      "step": 22710
    },
    {
      "epoch": 1.5247474916949095,
      "grad_norm": 0.8015268445014954,
      "learning_rate": 0.00010219874203605422,
      "loss": 2.514,
      "step": 22720
    },
    {
      "epoch": 1.5254186101137546,
      "grad_norm": 0.6999784111976624,
      "learning_rate": 0.00010212630694659414,
      "loss": 2.4814,
      "step": 22730
    },
    {
      "epoch": 1.5260897285325996,
      "grad_norm": 0.6949124336242676,
      "learning_rate": 0.00010205387074097239,
      "loss": 2.45,
      "step": 22740
    },
    {
      "epoch": 1.5267608469514444,
      "grad_norm": 0.7063080072402954,
      "learning_rate": 0.00010198143345721284,
      "loss": 2.458,
      "step": 22750
    },
    {
      "epoch": 1.5267608469514444,
      "eval_bleu": 21.06154878955467,
      "eval_gen_len": 28.861,
      "eval_loss": 2.938369035720825,
      "eval_runtime": 63.9053,
      "eval_samples_per_second": 15.648,
      "eval_steps_per_second": 0.986,
      "step": 22750
    },
    {
      "epoch": 1.5274319653702895,
      "grad_norm": 0.662561297416687,
      "learning_rate": 0.00010190899513334004,
      "loss": 2.4685,
      "step": 22760
    },
    {
      "epoch": 1.5281030837891345,
      "grad_norm": 0.661881148815155,
      "learning_rate": 0.00010183655580737901,
      "loss": 2.5064,
      "step": 22770
    },
    {
      "epoch": 1.5287742022079795,
      "grad_norm": 0.6815128922462463,
      "learning_rate": 0.00010176411551735527,
      "loss": 2.4535,
      "step": 22780
    },
    {
      "epoch": 1.5294453206268246,
      "grad_norm": 0.6606469750404358,
      "learning_rate": 0.0001016916743012949,
      "loss": 2.442,
      "step": 22790
    },
    {
      "epoch": 1.5301164390456696,
      "grad_norm": 0.675682544708252,
      "learning_rate": 0.00010161923219722442,
      "loss": 2.4752,
      "step": 22800
    },
    {
      "epoch": 1.5301164390456696,
      "eval_bleu": 21.25135175621009,
      "eval_gen_len": 28.877,
      "eval_loss": 2.9353342056274414,
      "eval_runtime": 64.1826,
      "eval_samples_per_second": 15.581,
      "eval_steps_per_second": 0.982,
      "step": 22800
    },
    {
      "epoch": 1.5307875574645147,
      "grad_norm": 0.6705961227416992,
      "learning_rate": 0.00010154678924317089,
      "loss": 2.448,
      "step": 22810
    },
    {
      "epoch": 1.5314586758833597,
      "grad_norm": 0.6667830944061279,
      "learning_rate": 0.00010147434547716174,
      "loss": 2.4967,
      "step": 22820
    },
    {
      "epoch": 1.5321297943022048,
      "grad_norm": 0.7447512149810791,
      "learning_rate": 0.00010140190093722486,
      "loss": 2.5147,
      "step": 22830
    },
    {
      "epoch": 1.5328009127210498,
      "grad_norm": 0.6896798014640808,
      "learning_rate": 0.00010132945566138852,
      "loss": 2.4587,
      "step": 22840
    },
    {
      "epoch": 1.5334720311398946,
      "grad_norm": 0.6327010989189148,
      "learning_rate": 0.00010125700968768141,
      "loss": 2.466,
      "step": 22850
    },
    {
      "epoch": 1.5334720311398946,
      "eval_bleu": 20.879664188025764,
      "eval_gen_len": 28.857,
      "eval_loss": 2.933290958404541,
      "eval_runtime": 63.9357,
      "eval_samples_per_second": 15.641,
      "eval_steps_per_second": 0.985,
      "step": 22850
    },
    {
      "epoch": 1.5341431495587396,
      "grad_norm": 0.7267377376556396,
      "learning_rate": 0.0001011845630541326,
      "loss": 2.471,
      "step": 22860
    },
    {
      "epoch": 1.5348142679775847,
      "grad_norm": 0.6734435558319092,
      "learning_rate": 0.00010111211579877147,
      "loss": 2.4565,
      "step": 22870
    },
    {
      "epoch": 1.5354853863964295,
      "grad_norm": 0.6998969316482544,
      "learning_rate": 0.00010103966795962769,
      "loss": 2.449,
      "step": 22880
    },
    {
      "epoch": 1.5361565048152745,
      "grad_norm": 0.6391187906265259,
      "learning_rate": 0.00010096721957473135,
      "loss": 2.4539,
      "step": 22890
    },
    {
      "epoch": 1.5368276232341196,
      "grad_norm": 0.7500869631767273,
      "learning_rate": 0.0001008947706821127,
      "loss": 2.5009,
      "step": 22900
    },
    {
      "epoch": 1.5368276232341196,
      "eval_bleu": 21.41548757369356,
      "eval_gen_len": 29.229,
      "eval_loss": 2.9353487491607666,
      "eval_runtime": 68.1171,
      "eval_samples_per_second": 14.681,
      "eval_steps_per_second": 0.925,
      "step": 22900
    },
    {
      "epoch": 1.5374987416529646,
      "grad_norm": 0.7953815460205078,
      "learning_rate": 0.00010082232131980235,
      "loss": 2.4889,
      "step": 22910
    },
    {
      "epoch": 1.5381698600718097,
      "grad_norm": 0.7656824588775635,
      "learning_rate": 0.00010074987152583112,
      "loss": 2.4786,
      "step": 22920
    },
    {
      "epoch": 1.5388409784906547,
      "grad_norm": 0.6808340549468994,
      "learning_rate": 0.00010067742133823006,
      "loss": 2.4818,
      "step": 22930
    },
    {
      "epoch": 1.5395120969094997,
      "grad_norm": 0.7135382294654846,
      "learning_rate": 0.0001006049707950304,
      "loss": 2.5373,
      "step": 22940
    },
    {
      "epoch": 1.5401832153283448,
      "grad_norm": 0.7241442203521729,
      "learning_rate": 0.00010053251993426363,
      "loss": 2.5028,
      "step": 22950
    },
    {
      "epoch": 1.5401832153283448,
      "eval_bleu": 20.96129332034943,
      "eval_gen_len": 28.823,
      "eval_loss": 2.934314250946045,
      "eval_runtime": 64.4172,
      "eval_samples_per_second": 15.524,
      "eval_steps_per_second": 0.978,
      "step": 22950
    },
    {
      "epoch": 1.5408543337471898,
      "grad_norm": 0.7349432110786438,
      "learning_rate": 0.0001004600687939613,
      "loss": 2.4828,
      "step": 22960
    },
    {
      "epoch": 1.5415254521660346,
      "grad_norm": 0.6778975129127502,
      "learning_rate": 0.00010038761741215519,
      "loss": 2.4809,
      "step": 22970
    },
    {
      "epoch": 1.5421965705848797,
      "grad_norm": 0.7301314473152161,
      "learning_rate": 0.0001003151658268772,
      "loss": 2.4595,
      "step": 22980
    },
    {
      "epoch": 1.5428676890037247,
      "grad_norm": 0.7077516913414001,
      "learning_rate": 0.00010024271407615933,
      "loss": 2.4982,
      "step": 22990
    },
    {
      "epoch": 1.5435388074225695,
      "grad_norm": 0.6707775592803955,
      "learning_rate": 0.0001001702621980336,
      "loss": 2.4659,
      "step": 23000
    },
    {
      "epoch": 1.5435388074225695,
      "eval_bleu": 21.169917338865808,
      "eval_gen_len": 28.818,
      "eval_loss": 2.9351141452789307,
      "eval_runtime": 64.0355,
      "eval_samples_per_second": 15.616,
      "eval_steps_per_second": 0.984,
      "step": 23000
    },
    {
      "epoch": 1.5442099258414146,
      "grad_norm": 0.7255467772483826,
      "learning_rate": 0.00010009781023053219,
      "loss": 2.4865,
      "step": 23010
    },
    {
      "epoch": 1.5448810442602596,
      "grad_norm": 0.6735039949417114,
      "learning_rate": 0.0001000253582116873,
      "loss": 2.5193,
      "step": 23020
    },
    {
      "epoch": 1.5455521626791047,
      "grad_norm": 0.6974849700927734,
      "learning_rate": 9.995290617953109e-05,
      "loss": 2.5129,
      "step": 23030
    },
    {
      "epoch": 1.5462232810979497,
      "grad_norm": 0.6760650873184204,
      "learning_rate": 9.988045417209587e-05,
      "loss": 2.4559,
      "step": 23040
    },
    {
      "epoch": 1.5468943995167947,
      "grad_norm": 0.6892862915992737,
      "learning_rate": 9.980800222741379e-05,
      "loss": 2.5015,
      "step": 23050
    },
    {
      "epoch": 1.5468943995167947,
      "eval_bleu": 21.22747289229243,
      "eval_gen_len": 28.926,
      "eval_loss": 2.935023784637451,
      "eval_runtime": 64.4963,
      "eval_samples_per_second": 15.505,
      "eval_steps_per_second": 0.977,
      "step": 23050
    },
    {
      "epoch": 1.5475655179356398,
      "grad_norm": 0.6812942624092102,
      "learning_rate": 9.973555038351706e-05,
      "loss": 2.4757,
      "step": 23060
    },
    {
      "epoch": 1.5482366363544848,
      "grad_norm": 0.6429543495178223,
      "learning_rate": 9.966309867843775e-05,
      "loss": 2.4339,
      "step": 23070
    },
    {
      "epoch": 1.5489077547733299,
      "grad_norm": 0.695295512676239,
      "learning_rate": 9.959064715020799e-05,
      "loss": 2.4623,
      "step": 23080
    },
    {
      "epoch": 1.549578873192175,
      "grad_norm": 0.6494927406311035,
      "learning_rate": 9.951819583685967e-05,
      "loss": 2.4434,
      "step": 23090
    },
    {
      "epoch": 1.5502499916110197,
      "grad_norm": 0.673440158367157,
      "learning_rate": 9.94457447764247e-05,
      "loss": 2.4771,
      "step": 23100
    },
    {
      "epoch": 1.5502499916110197,
      "eval_bleu": 21.072123337118807,
      "eval_gen_len": 28.735,
      "eval_loss": 2.941328287124634,
      "eval_runtime": 63.5024,
      "eval_samples_per_second": 15.747,
      "eval_steps_per_second": 0.992,
      "step": 23100
    },
    {
      "epoch": 1.5509211100298648,
      "grad_norm": 0.6974233388900757,
      "learning_rate": 9.937329400693471e-05,
      "loss": 2.4676,
      "step": 23110
    },
    {
      "epoch": 1.5515922284487098,
      "grad_norm": 0.6940101385116577,
      "learning_rate": 9.930084356642135e-05,
      "loss": 2.4123,
      "step": 23120
    },
    {
      "epoch": 1.5522633468675546,
      "grad_norm": 0.676962673664093,
      "learning_rate": 9.922839349291598e-05,
      "loss": 2.4903,
      "step": 23130
    },
    {
      "epoch": 1.5529344652863997,
      "grad_norm": 0.7210491299629211,
      "learning_rate": 9.915594382444976e-05,
      "loss": 2.4839,
      "step": 23140
    },
    {
      "epoch": 1.5536055837052447,
      "grad_norm": 0.6932413578033447,
      "learning_rate": 9.908349459905372e-05,
      "loss": 2.4936,
      "step": 23150
    },
    {
      "epoch": 1.5536055837052447,
      "eval_bleu": 21.320399759379708,
      "eval_gen_len": 29.004,
      "eval_loss": 2.939880132675171,
      "eval_runtime": 67.1615,
      "eval_samples_per_second": 14.889,
      "eval_steps_per_second": 0.938,
      "step": 23150
    },
    {
      "epoch": 1.5542767021240897,
      "grad_norm": 0.7196801900863647,
      "learning_rate": 9.901104585475854e-05,
      "loss": 2.4826,
      "step": 23160
    },
    {
      "epoch": 1.5549478205429348,
      "grad_norm": 0.648361086845398,
      "learning_rate": 9.893859762959481e-05,
      "loss": 2.4451,
      "step": 23170
    },
    {
      "epoch": 1.5556189389617798,
      "grad_norm": 0.7109432220458984,
      "learning_rate": 9.886614996159268e-05,
      "loss": 2.5056,
      "step": 23180
    },
    {
      "epoch": 1.5562900573806249,
      "grad_norm": 0.7124879956245422,
      "learning_rate": 9.879370288878215e-05,
      "loss": 2.4853,
      "step": 23190
    },
    {
      "epoch": 1.55696117579947,
      "grad_norm": 0.6792876720428467,
      "learning_rate": 9.872125644919274e-05,
      "loss": 2.4501,
      "step": 23200
    },
    {
      "epoch": 1.55696117579947,
      "eval_bleu": 21.429129546944864,
      "eval_gen_len": 28.781,
      "eval_loss": 2.937436819076538,
      "eval_runtime": 63.526,
      "eval_samples_per_second": 15.742,
      "eval_steps_per_second": 0.992,
      "step": 23200
    },
    {
      "epoch": 1.557632294218315,
      "grad_norm": 0.681442141532898,
      "learning_rate": 9.864881068085386e-05,
      "loss": 2.4815,
      "step": 23210
    },
    {
      "epoch": 1.55830341263716,
      "grad_norm": 0.6829758882522583,
      "learning_rate": 9.857636562179437e-05,
      "loss": 2.4493,
      "step": 23220
    },
    {
      "epoch": 1.5589745310560048,
      "grad_norm": 0.6718621850013733,
      "learning_rate": 9.850392131004287e-05,
      "loss": 2.5015,
      "step": 23230
    },
    {
      "epoch": 1.5596456494748498,
      "grad_norm": 0.6441452503204346,
      "learning_rate": 9.843147778362747e-05,
      "loss": 2.5414,
      "step": 23240
    },
    {
      "epoch": 1.560316767893695,
      "grad_norm": 0.6792532801628113,
      "learning_rate": 9.8359035080576e-05,
      "loss": 2.5332,
      "step": 23250
    },
    {
      "epoch": 1.560316767893695,
      "eval_bleu": 21.390710176920063,
      "eval_gen_len": 28.818,
      "eval_loss": 2.934896945953369,
      "eval_runtime": 64.0168,
      "eval_samples_per_second": 15.621,
      "eval_steps_per_second": 0.984,
      "step": 23250
    },
    {
      "epoch": 1.5609878863125397,
      "grad_norm": 0.6608927249908447,
      "learning_rate": 9.828659323891574e-05,
      "loss": 2.4727,
      "step": 23260
    },
    {
      "epoch": 1.5616590047313847,
      "grad_norm": 0.6813234686851501,
      "learning_rate": 9.821415229667361e-05,
      "loss": 2.458,
      "step": 23270
    },
    {
      "epoch": 1.5623301231502298,
      "grad_norm": 0.7007575631141663,
      "learning_rate": 9.814171229187595e-05,
      "loss": 2.5346,
      "step": 23280
    },
    {
      "epoch": 1.5630012415690748,
      "grad_norm": 0.6966183185577393,
      "learning_rate": 9.806927326254874e-05,
      "loss": 2.5519,
      "step": 23290
    },
    {
      "epoch": 1.5636723599879199,
      "grad_norm": 0.6957223415374756,
      "learning_rate": 9.799683524671728e-05,
      "loss": 2.4795,
      "step": 23300
    },
    {
      "epoch": 1.5636723599879199,
      "eval_bleu": 21.084330078066838,
      "eval_gen_len": 28.852,
      "eval_loss": 2.939565896987915,
      "eval_runtime": 64.2407,
      "eval_samples_per_second": 15.566,
      "eval_steps_per_second": 0.981,
      "step": 23300
    },
    {
      "epoch": 1.564343478406765,
      "grad_norm": 0.7361403107643127,
      "learning_rate": 9.792439828240656e-05,
      "loss": 2.5003,
      "step": 23310
    },
    {
      "epoch": 1.56501459682561,
      "grad_norm": 0.7026287913322449,
      "learning_rate": 9.785196240764081e-05,
      "loss": 2.4716,
      "step": 23320
    },
    {
      "epoch": 1.565685715244455,
      "grad_norm": 0.6595706939697266,
      "learning_rate": 9.777952766044381e-05,
      "loss": 2.4571,
      "step": 23330
    },
    {
      "epoch": 1.5663568336633,
      "grad_norm": 0.7621875405311584,
      "learning_rate": 9.770709407883865e-05,
      "loss": 2.4871,
      "step": 23340
    },
    {
      "epoch": 1.5670279520821448,
      "grad_norm": 0.7204223871231079,
      "learning_rate": 9.763466170084796e-05,
      "loss": 2.4899,
      "step": 23350
    },
    {
      "epoch": 1.5670279520821448,
      "eval_bleu": 21.380932767651537,
      "eval_gen_len": 29.128,
      "eval_loss": 2.9373958110809326,
      "eval_runtime": 67.4448,
      "eval_samples_per_second": 14.827,
      "eval_steps_per_second": 0.934,
      "step": 23350
    },
    {
      "epoch": 1.5676990705009899,
      "grad_norm": 0.7078704237937927,
      "learning_rate": 9.756223056449358e-05,
      "loss": 2.5043,
      "step": 23360
    },
    {
      "epoch": 1.568370188919835,
      "grad_norm": 0.6647331118583679,
      "learning_rate": 9.74898007077968e-05,
      "loss": 2.4591,
      "step": 23370
    },
    {
      "epoch": 1.5690413073386797,
      "grad_norm": 0.6682602167129517,
      "learning_rate": 9.741737216877814e-05,
      "loss": 2.4779,
      "step": 23380
    },
    {
      "epoch": 1.5697124257575248,
      "grad_norm": 0.7552537322044373,
      "learning_rate": 9.73449449854576e-05,
      "loss": 2.4521,
      "step": 23390
    },
    {
      "epoch": 1.5703835441763698,
      "grad_norm": 0.721149742603302,
      "learning_rate": 9.727251919585428e-05,
      "loss": 2.5226,
      "step": 23400
    },
    {
      "epoch": 1.5703835441763698,
      "eval_bleu": 21.537960703921144,
      "eval_gen_len": 28.847,
      "eval_loss": 2.9327824115753174,
      "eval_runtime": 64.2553,
      "eval_samples_per_second": 15.563,
      "eval_steps_per_second": 0.98,
      "step": 23400
    },
    {
      "epoch": 1.5710546625952149,
      "grad_norm": 0.6472881436347961,
      "learning_rate": 9.720009483798664e-05,
      "loss": 2.4739,
      "step": 23410
    },
    {
      "epoch": 1.57172578101406,
      "grad_norm": 0.6825973987579346,
      "learning_rate": 9.71276719498724e-05,
      "loss": 2.4773,
      "step": 23420
    },
    {
      "epoch": 1.572396899432905,
      "grad_norm": 0.6872347593307495,
      "learning_rate": 9.705525056952844e-05,
      "loss": 2.4369,
      "step": 23430
    },
    {
      "epoch": 1.57306801785175,
      "grad_norm": 0.6532321572303772,
      "learning_rate": 9.698283073497094e-05,
      "loss": 2.4665,
      "step": 23440
    },
    {
      "epoch": 1.573739136270595,
      "grad_norm": 0.6826910376548767,
      "learning_rate": 9.69104124842152e-05,
      "loss": 2.4446,
      "step": 23450
    },
    {
      "epoch": 1.573739136270595,
      "eval_bleu": 21.51084110941316,
      "eval_gen_len": 28.802,
      "eval_loss": 2.935102939605713,
      "eval_runtime": 63.772,
      "eval_samples_per_second": 15.681,
      "eval_steps_per_second": 0.988,
      "step": 23450
    },
    {
      "epoch": 1.57441025468944,
      "grad_norm": 0.6377067565917969,
      "learning_rate": 9.683799585527573e-05,
      "loss": 2.4434,
      "step": 23460
    },
    {
      "epoch": 1.575081373108285,
      "grad_norm": 0.6971690058708191,
      "learning_rate": 9.676558088616611e-05,
      "loss": 2.4922,
      "step": 23470
    },
    {
      "epoch": 1.57575249152713,
      "grad_norm": 0.7038491368293762,
      "learning_rate": 9.669316761489922e-05,
      "loss": 2.4763,
      "step": 23480
    },
    {
      "epoch": 1.576423609945975,
      "grad_norm": 0.7106030583381653,
      "learning_rate": 9.662075607948683e-05,
      "loss": 2.4427,
      "step": 23490
    },
    {
      "epoch": 1.57709472836482,
      "grad_norm": 0.6920204162597656,
      "learning_rate": 9.654834631793997e-05,
      "loss": 2.4749,
      "step": 23500
    },
    {
      "epoch": 1.57709472836482,
      "eval_bleu": 21.614111207209486,
      "eval_gen_len": 28.833,
      "eval_loss": 2.9324610233306885,
      "eval_runtime": 64.2396,
      "eval_samples_per_second": 15.567,
      "eval_steps_per_second": 0.981,
      "step": 23500
    },
    {
      "epoch": 1.5777658467836648,
      "grad_norm": 0.7286359667778015,
      "learning_rate": 9.64759383682686e-05,
      "loss": 2.4816,
      "step": 23510
    },
    {
      "epoch": 1.5784369652025099,
      "grad_norm": 0.7033409476280212,
      "learning_rate": 9.64035322684819e-05,
      "loss": 2.3984,
      "step": 23520
    },
    {
      "epoch": 1.579108083621355,
      "grad_norm": 0.6866241693496704,
      "learning_rate": 9.633112805658793e-05,
      "loss": 2.4511,
      "step": 23530
    },
    {
      "epoch": 1.5797792020402,
      "grad_norm": 0.7670127749443054,
      "learning_rate": 9.625872577059381e-05,
      "loss": 2.5545,
      "step": 23540
    },
    {
      "epoch": 1.580450320459045,
      "grad_norm": 0.7128111720085144,
      "learning_rate": 9.618632544850565e-05,
      "loss": 2.4502,
      "step": 23550
    },
    {
      "epoch": 1.580450320459045,
      "eval_bleu": 21.332463257342024,
      "eval_gen_len": 29.157,
      "eval_loss": 2.930784225463867,
      "eval_runtime": 67.6644,
      "eval_samples_per_second": 14.779,
      "eval_steps_per_second": 0.931,
      "step": 23550
    },
    {
      "epoch": 1.58112143887789,
      "grad_norm": 0.7824414372444153,
      "learning_rate": 9.611392712832856e-05,
      "loss": 2.5042,
      "step": 23560
    },
    {
      "epoch": 1.581792557296735,
      "grad_norm": 0.6589860320091248,
      "learning_rate": 9.604153084806652e-05,
      "loss": 2.4663,
      "step": 23570
    },
    {
      "epoch": 1.58246367571558,
      "grad_norm": 0.7010396718978882,
      "learning_rate": 9.596913664572254e-05,
      "loss": 2.5065,
      "step": 23580
    },
    {
      "epoch": 1.5831347941344251,
      "grad_norm": 0.693342387676239,
      "learning_rate": 9.589674455929843e-05,
      "loss": 2.4497,
      "step": 23590
    },
    {
      "epoch": 1.5838059125532702,
      "grad_norm": 0.6769909262657166,
      "learning_rate": 9.582435462679502e-05,
      "loss": 2.4783,
      "step": 23600
    },
    {
      "epoch": 1.5838059125532702,
      "eval_bleu": 21.471726715394453,
      "eval_gen_len": 28.865,
      "eval_loss": 2.932823896408081,
      "eval_runtime": 64.0589,
      "eval_samples_per_second": 15.611,
      "eval_steps_per_second": 0.983,
      "step": 23600
    },
    {
      "epoch": 1.584477030972115,
      "grad_norm": 0.6093313694000244,
      "learning_rate": 9.575196688621184e-05,
      "loss": 2.439,
      "step": 23610
    },
    {
      "epoch": 1.58514814939096,
      "grad_norm": 0.6994116902351379,
      "learning_rate": 9.567958137554747e-05,
      "loss": 2.4822,
      "step": 23620
    },
    {
      "epoch": 1.585819267809805,
      "grad_norm": 0.6604892015457153,
      "learning_rate": 9.560719813279913e-05,
      "loss": 2.4265,
      "step": 23630
    },
    {
      "epoch": 1.58649038622865,
      "grad_norm": 0.683363676071167,
      "learning_rate": 9.553481719596301e-05,
      "loss": 2.4529,
      "step": 23640
    },
    {
      "epoch": 1.587161504647495,
      "grad_norm": 0.6901679039001465,
      "learning_rate": 9.546243860303393e-05,
      "loss": 2.4972,
      "step": 23650
    },
    {
      "epoch": 1.587161504647495,
      "eval_bleu": 21.334150041613256,
      "eval_gen_len": 28.733,
      "eval_loss": 2.934736967086792,
      "eval_runtime": 63.3686,
      "eval_samples_per_second": 15.781,
      "eval_steps_per_second": 0.994,
      "step": 23650
    },
    {
      "epoch": 1.58783262306634,
      "grad_norm": 0.7221602201461792,
      "learning_rate": 9.539006239200562e-05,
      "loss": 2.5295,
      "step": 23660
    },
    {
      "epoch": 1.588503741485185,
      "grad_norm": 0.622031033039093,
      "learning_rate": 9.531768860087048e-05,
      "loss": 2.5002,
      "step": 23670
    },
    {
      "epoch": 1.58917485990403,
      "grad_norm": 0.7150212526321411,
      "learning_rate": 9.524531726761969e-05,
      "loss": 2.5008,
      "step": 23680
    },
    {
      "epoch": 1.589845978322875,
      "grad_norm": 0.6967072486877441,
      "learning_rate": 9.517294843024305e-05,
      "loss": 2.5059,
      "step": 23690
    },
    {
      "epoch": 1.5905170967417201,
      "grad_norm": 0.6809716820716858,
      "learning_rate": 9.510058212672919e-05,
      "loss": 2.5169,
      "step": 23700
    },
    {
      "epoch": 1.5905170967417201,
      "eval_bleu": 21.277968351029067,
      "eval_gen_len": 28.817,
      "eval_loss": 2.9361820220947266,
      "eval_runtime": 63.6737,
      "eval_samples_per_second": 15.705,
      "eval_steps_per_second": 0.989,
      "step": 23700
    },
    {
      "epoch": 1.5911882151605652,
      "grad_norm": 0.6971981525421143,
      "learning_rate": 9.50282183950653e-05,
      "loss": 2.4765,
      "step": 23710
    },
    {
      "epoch": 1.5918593335794102,
      "grad_norm": 0.7453851103782654,
      "learning_rate": 9.495585727323725e-05,
      "loss": 2.4991,
      "step": 23720
    },
    {
      "epoch": 1.592530451998255,
      "grad_norm": 0.6873395442962646,
      "learning_rate": 9.488349879922955e-05,
      "loss": 2.5324,
      "step": 23730
    },
    {
      "epoch": 1.5932015704171,
      "grad_norm": 0.6949912905693054,
      "learning_rate": 9.481114301102525e-05,
      "loss": 2.5255,
      "step": 23740
    },
    {
      "epoch": 1.5938726888359451,
      "grad_norm": 0.6768789887428284,
      "learning_rate": 9.473878994660616e-05,
      "loss": 2.4333,
      "step": 23750
    },
    {
      "epoch": 1.5938726888359451,
      "eval_bleu": 21.086678883171256,
      "eval_gen_len": 28.828,
      "eval_loss": 2.931816577911377,
      "eval_runtime": 63.6568,
      "eval_samples_per_second": 15.709,
      "eval_steps_per_second": 0.99,
      "step": 23750
    },
    {
      "epoch": 1.59454380725479,
      "grad_norm": 0.7060122489929199,
      "learning_rate": 9.466643964395246e-05,
      "loss": 2.5048,
      "step": 23760
    },
    {
      "epoch": 1.595214925673635,
      "grad_norm": 0.6187785267829895,
      "learning_rate": 9.459409214104306e-05,
      "loss": 2.4653,
      "step": 23770
    },
    {
      "epoch": 1.59588604409248,
      "grad_norm": 0.6054387092590332,
      "learning_rate": 9.45217474758552e-05,
      "loss": 2.4598,
      "step": 23780
    },
    {
      "epoch": 1.596557162511325,
      "grad_norm": 0.6748986840248108,
      "learning_rate": 9.444940568636486e-05,
      "loss": 2.5048,
      "step": 23790
    },
    {
      "epoch": 1.59722828093017,
      "grad_norm": 0.7526420950889587,
      "learning_rate": 9.437706681054631e-05,
      "loss": 2.4998,
      "step": 23800
    },
    {
      "epoch": 1.59722828093017,
      "eval_bleu": 21.024924788607528,
      "eval_gen_len": 28.902,
      "eval_loss": 2.934664249420166,
      "eval_runtime": 63.904,
      "eval_samples_per_second": 15.648,
      "eval_steps_per_second": 0.986,
      "step": 23800
    },
    {
      "epoch": 1.5978993993490151,
      "grad_norm": 0.6721999049186707,
      "learning_rate": 9.430473088637244e-05,
      "loss": 2.4663,
      "step": 23810
    },
    {
      "epoch": 1.5985705177678602,
      "grad_norm": 0.6367530822753906,
      "learning_rate": 9.423239795181445e-05,
      "loss": 2.4249,
      "step": 23820
    },
    {
      "epoch": 1.5992416361867052,
      "grad_norm": 0.6776880621910095,
      "learning_rate": 9.416006804484212e-05,
      "loss": 2.4696,
      "step": 23830
    },
    {
      "epoch": 1.5999127546055503,
      "grad_norm": 0.6802286505699158,
      "learning_rate": 9.408774120342352e-05,
      "loss": 2.5151,
      "step": 23840
    },
    {
      "epoch": 1.6005838730243953,
      "grad_norm": 0.6656255125999451,
      "learning_rate": 9.401541746552519e-05,
      "loss": 2.4855,
      "step": 23850
    },
    {
      "epoch": 1.6005838730243953,
      "eval_bleu": 20.996579394784284,
      "eval_gen_len": 28.815,
      "eval_loss": 2.9421939849853516,
      "eval_runtime": 63.0192,
      "eval_samples_per_second": 15.868,
      "eval_steps_per_second": 1.0,
      "step": 23850
    },
    {
      "epoch": 1.6012549914432401,
      "grad_norm": 0.7965330481529236,
      "learning_rate": 9.394309686911195e-05,
      "loss": 2.4821,
      "step": 23860
    },
    {
      "epoch": 1.6019261098620852,
      "grad_norm": 0.6118425130844116,
      "learning_rate": 9.387077945214711e-05,
      "loss": 2.516,
      "step": 23870
    },
    {
      "epoch": 1.6025972282809302,
      "grad_norm": 0.7136287093162537,
      "learning_rate": 9.379846525259216e-05,
      "loss": 2.4516,
      "step": 23880
    },
    {
      "epoch": 1.603268346699775,
      "grad_norm": 0.7128562331199646,
      "learning_rate": 9.372615430840704e-05,
      "loss": 2.5199,
      "step": 23890
    },
    {
      "epoch": 1.60393946511862,
      "grad_norm": 0.6604248285293579,
      "learning_rate": 9.365384665754982e-05,
      "loss": 2.4683,
      "step": 23900
    },
    {
      "epoch": 1.60393946511862,
      "eval_bleu": 20.962648653336103,
      "eval_gen_len": 28.781,
      "eval_loss": 2.9349796772003174,
      "eval_runtime": 63.7297,
      "eval_samples_per_second": 15.691,
      "eval_steps_per_second": 0.989,
      "step": 23900
    },
    {
      "epoch": 1.604610583537465,
      "grad_norm": 0.6855155825614929,
      "learning_rate": 9.358154233797703e-05,
      "loss": 2.4909,
      "step": 23910
    },
    {
      "epoch": 1.6052817019563101,
      "grad_norm": 0.652976930141449,
      "learning_rate": 9.350924138764325e-05,
      "loss": 2.5026,
      "step": 23920
    },
    {
      "epoch": 1.6059528203751552,
      "grad_norm": 0.6648015379905701,
      "learning_rate": 9.343694384450153e-05,
      "loss": 2.4945,
      "step": 23930
    },
    {
      "epoch": 1.6066239387940002,
      "grad_norm": 0.7235645055770874,
      "learning_rate": 9.336464974650288e-05,
      "loss": 2.5036,
      "step": 23940
    },
    {
      "epoch": 1.6072950572128453,
      "grad_norm": 0.6461437344551086,
      "learning_rate": 9.329235913159671e-05,
      "loss": 2.4721,
      "step": 23950
    },
    {
      "epoch": 1.6072950572128453,
      "eval_bleu": 20.92363717916514,
      "eval_gen_len": 28.823,
      "eval_loss": 2.936702251434326,
      "eval_runtime": 63.4872,
      "eval_samples_per_second": 15.751,
      "eval_steps_per_second": 0.992,
      "step": 23950
    },
    {
      "epoch": 1.6079661756316903,
      "grad_norm": 0.6936532258987427,
      "learning_rate": 9.32200720377304e-05,
      "loss": 2.5163,
      "step": 23960
    },
    {
      "epoch": 1.6086372940505353,
      "grad_norm": 0.6979628205299377,
      "learning_rate": 9.314778850284972e-05,
      "loss": 2.4878,
      "step": 23970
    },
    {
      "epoch": 1.6093084124693802,
      "grad_norm": 0.7165588140487671,
      "learning_rate": 9.307550856489835e-05,
      "loss": 2.4502,
      "step": 23980
    },
    {
      "epoch": 1.6099795308882252,
      "grad_norm": 0.651506245136261,
      "learning_rate": 9.300323226181823e-05,
      "loss": 2.497,
      "step": 23990
    },
    {
      "epoch": 1.6106506493070702,
      "grad_norm": 0.6683390736579895,
      "learning_rate": 9.293095963154928e-05,
      "loss": 2.427,
      "step": 24000
    },
    {
      "epoch": 1.6106506493070702,
      "eval_bleu": 21.169672307803747,
      "eval_gen_len": 28.812,
      "eval_loss": 2.932757616043091,
      "eval_runtime": 64.3326,
      "eval_samples_per_second": 15.544,
      "eval_steps_per_second": 0.979,
      "step": 24000
    },
    {
      "epoch": 1.6113217677259153,
      "grad_norm": 0.6174280047416687,
      "learning_rate": 9.285869071202964e-05,
      "loss": 2.4663,
      "step": 24010
    },
    {
      "epoch": 1.61199288614476,
      "grad_norm": 0.6999500393867493,
      "learning_rate": 9.278642554119534e-05,
      "loss": 2.4831,
      "step": 24020
    },
    {
      "epoch": 1.6126640045636051,
      "grad_norm": 0.677368700504303,
      "learning_rate": 9.271416415698054e-05,
      "loss": 2.4743,
      "step": 24030
    },
    {
      "epoch": 1.6133351229824502,
      "grad_norm": 0.7991608381271362,
      "learning_rate": 9.264190659731738e-05,
      "loss": 2.4544,
      "step": 24040
    },
    {
      "epoch": 1.6140062414012952,
      "grad_norm": 0.7908497452735901,
      "learning_rate": 9.256965290013596e-05,
      "loss": 2.5228,
      "step": 24050
    },
    {
      "epoch": 1.6140062414012952,
      "eval_bleu": 21.15103219996593,
      "eval_gen_len": 28.854,
      "eval_loss": 2.936065196990967,
      "eval_runtime": 64.0525,
      "eval_samples_per_second": 15.612,
      "eval_steps_per_second": 0.984,
      "step": 24050
    },
    {
      "epoch": 1.6146773598201403,
      "grad_norm": 0.7356370091438293,
      "learning_rate": 9.249740310336448e-05,
      "loss": 2.4976,
      "step": 24060
    },
    {
      "epoch": 1.6153484782389853,
      "grad_norm": 0.6662971377372742,
      "learning_rate": 9.242515724492895e-05,
      "loss": 2.4712,
      "step": 24070
    },
    {
      "epoch": 1.6160195966578303,
      "grad_norm": 0.7159417271614075,
      "learning_rate": 9.235291536275338e-05,
      "loss": 2.4782,
      "step": 24080
    },
    {
      "epoch": 1.6166907150766754,
      "grad_norm": 0.6603776812553406,
      "learning_rate": 9.228067749475964e-05,
      "loss": 2.4356,
      "step": 24090
    },
    {
      "epoch": 1.6173618334955204,
      "grad_norm": 0.6701921224594116,
      "learning_rate": 9.22084436788676e-05,
      "loss": 2.4857,
      "step": 24100
    },
    {
      "epoch": 1.6173618334955204,
      "eval_bleu": 21.35081991204656,
      "eval_gen_len": 28.827,
      "eval_loss": 2.936720848083496,
      "eval_runtime": 63.8503,
      "eval_samples_per_second": 15.662,
      "eval_steps_per_second": 0.987,
      "step": 24100
    },
    {
      "epoch": 1.6180329519143652,
      "grad_norm": 0.707048237323761,
      "learning_rate": 9.213621395299489e-05,
      "loss": 2.4684,
      "step": 24110
    },
    {
      "epoch": 1.6187040703332103,
      "grad_norm": 0.6675984263420105,
      "learning_rate": 9.206398835505706e-05,
      "loss": 2.4682,
      "step": 24120
    },
    {
      "epoch": 1.6193751887520553,
      "grad_norm": 0.7107369303703308,
      "learning_rate": 9.199176692296743e-05,
      "loss": 2.4562,
      "step": 24130
    },
    {
      "epoch": 1.6200463071709001,
      "grad_norm": 0.6833522915840149,
      "learning_rate": 9.191954969463725e-05,
      "loss": 2.5004,
      "step": 24140
    },
    {
      "epoch": 1.6207174255897452,
      "grad_norm": 0.6677337884902954,
      "learning_rate": 9.184733670797542e-05,
      "loss": 2.4737,
      "step": 24150
    },
    {
      "epoch": 1.6207174255897452,
      "eval_bleu": 20.903175959644518,
      "eval_gen_len": 28.77,
      "eval_loss": 2.941663980484009,
      "eval_runtime": 64.4789,
      "eval_samples_per_second": 15.509,
      "eval_steps_per_second": 0.977,
      "step": 24150
    },
    {
      "epoch": 1.6213885440085902,
      "grad_norm": 0.6889938116073608,
      "learning_rate": 9.177512800088872e-05,
      "loss": 2.4733,
      "step": 24160
    },
    {
      "epoch": 1.6220596624274353,
      "grad_norm": 0.6633656620979309,
      "learning_rate": 9.17029236112816e-05,
      "loss": 2.5175,
      "step": 24170
    },
    {
      "epoch": 1.6227307808462803,
      "grad_norm": 0.7568949460983276,
      "learning_rate": 9.163072357705636e-05,
      "loss": 2.4743,
      "step": 24180
    },
    {
      "epoch": 1.6234018992651253,
      "grad_norm": 0.655464768409729,
      "learning_rate": 9.155852793611288e-05,
      "loss": 2.4776,
      "step": 24190
    },
    {
      "epoch": 1.6240730176839704,
      "grad_norm": 0.6650352478027344,
      "learning_rate": 9.148633672634886e-05,
      "loss": 2.4709,
      "step": 24200
    },
    {
      "epoch": 1.6240730176839704,
      "eval_bleu": 21.139988292381926,
      "eval_gen_len": 28.864,
      "eval_loss": 2.9392566680908203,
      "eval_runtime": 64.4202,
      "eval_samples_per_second": 15.523,
      "eval_steps_per_second": 0.978,
      "step": 24200
    },
    {
      "epoch": 1.6247441361028154,
      "grad_norm": 0.6262476444244385,
      "learning_rate": 9.14141499856595e-05,
      "loss": 2.5321,
      "step": 24210
    },
    {
      "epoch": 1.6254152545216605,
      "grad_norm": 0.6976838707923889,
      "learning_rate": 9.134196775193789e-05,
      "loss": 2.4942,
      "step": 24220
    },
    {
      "epoch": 1.6260863729405055,
      "grad_norm": 0.6626493334770203,
      "learning_rate": 9.126979006307453e-05,
      "loss": 2.5044,
      "step": 24230
    },
    {
      "epoch": 1.6267574913593503,
      "grad_norm": 0.7344397902488708,
      "learning_rate": 9.119761695695772e-05,
      "loss": 2.5235,
      "step": 24240
    },
    {
      "epoch": 1.6274286097781954,
      "grad_norm": 0.685773491859436,
      "learning_rate": 9.11254484714732e-05,
      "loss": 2.5489,
      "step": 24250
    },
    {
      "epoch": 1.6274286097781954,
      "eval_bleu": 21.31558662006923,
      "eval_gen_len": 28.878,
      "eval_loss": 2.9348835945129395,
      "eval_runtime": 64.0625,
      "eval_samples_per_second": 15.61,
      "eval_steps_per_second": 0.983,
      "step": 24250
    },
    {
      "epoch": 1.6280997281970404,
      "grad_norm": 0.6096357107162476,
      "learning_rate": 9.105328464450439e-05,
      "loss": 2.5025,
      "step": 24260
    },
    {
      "epoch": 1.6287708466158852,
      "grad_norm": 0.7208538055419922,
      "learning_rate": 9.098112551393216e-05,
      "loss": 2.4281,
      "step": 24270
    },
    {
      "epoch": 1.6294419650347303,
      "grad_norm": 0.7077631950378418,
      "learning_rate": 9.090897111763508e-05,
      "loss": 2.5295,
      "step": 24280
    },
    {
      "epoch": 1.6301130834535753,
      "grad_norm": 0.6934918165206909,
      "learning_rate": 9.083682149348909e-05,
      "loss": 2.5091,
      "step": 24290
    },
    {
      "epoch": 1.6307842018724203,
      "grad_norm": 0.6657406687736511,
      "learning_rate": 9.076467667936766e-05,
      "loss": 2.4894,
      "step": 24300
    },
    {
      "epoch": 1.6307842018724203,
      "eval_bleu": 21.32983428968976,
      "eval_gen_len": 28.841,
      "eval_loss": 2.941331148147583,
      "eval_runtime": 63.7161,
      "eval_samples_per_second": 15.695,
      "eval_steps_per_second": 0.989,
      "step": 24300
    },
    {
      "epoch": 1.6314553202912654,
      "grad_norm": 0.749478816986084,
      "learning_rate": 9.069253671314178e-05,
      "loss": 2.4357,
      "step": 24310
    },
    {
      "epoch": 1.6321264387101104,
      "grad_norm": 0.6572912335395813,
      "learning_rate": 9.062040163267976e-05,
      "loss": 2.5078,
      "step": 24320
    },
    {
      "epoch": 1.6327975571289555,
      "grad_norm": 0.7266240119934082,
      "learning_rate": 9.05482714758476e-05,
      "loss": 2.468,
      "step": 24330
    },
    {
      "epoch": 1.6334686755478005,
      "grad_norm": 0.685070276260376,
      "learning_rate": 9.047614628050842e-05,
      "loss": 2.4402,
      "step": 24340
    },
    {
      "epoch": 1.6341397939666455,
      "grad_norm": 0.663284182548523,
      "learning_rate": 9.040402608452298e-05,
      "loss": 2.4768,
      "step": 24350
    },
    {
      "epoch": 1.6341397939666455,
      "eval_bleu": 21.42349785809649,
      "eval_gen_len": 29.171,
      "eval_loss": 2.935725688934326,
      "eval_runtime": 67.7481,
      "eval_samples_per_second": 14.761,
      "eval_steps_per_second": 0.93,
      "step": 24350
    },
    {
      "epoch": 1.6348109123854904,
      "grad_norm": 0.6824562549591064,
      "learning_rate": 9.033191092574925e-05,
      "loss": 2.488,
      "step": 24360
    },
    {
      "epoch": 1.6354820308043354,
      "grad_norm": 0.6820000410079956,
      "learning_rate": 9.025980084204267e-05,
      "loss": 2.4865,
      "step": 24370
    },
    {
      "epoch": 1.6361531492231804,
      "grad_norm": 0.6608879566192627,
      "learning_rate": 9.01876958712559e-05,
      "loss": 2.4591,
      "step": 24380
    },
    {
      "epoch": 1.6368242676420255,
      "grad_norm": 0.6802358031272888,
      "learning_rate": 9.011559605123906e-05,
      "loss": 2.481,
      "step": 24390
    },
    {
      "epoch": 1.6374953860608703,
      "grad_norm": 0.7294022440910339,
      "learning_rate": 9.00435014198394e-05,
      "loss": 2.4738,
      "step": 24400
    },
    {
      "epoch": 1.6374953860608703,
      "eval_bleu": 21.24038732450623,
      "eval_gen_len": 28.818,
      "eval_loss": 2.9353580474853516,
      "eval_runtime": 64.036,
      "eval_samples_per_second": 15.616,
      "eval_steps_per_second": 0.984,
      "step": 24400
    },
    {
      "epoch": 1.6381665044797153,
      "grad_norm": 0.7720341682434082,
      "learning_rate": 8.99714120149016e-05,
      "loss": 2.4488,
      "step": 24410
    },
    {
      "epoch": 1.6388376228985604,
      "grad_norm": 0.6949495077133179,
      "learning_rate": 8.989932787426752e-05,
      "loss": 2.4901,
      "step": 24420
    },
    {
      "epoch": 1.6395087413174054,
      "grad_norm": 0.691325306892395,
      "learning_rate": 8.982724903577625e-05,
      "loss": 2.4787,
      "step": 24430
    },
    {
      "epoch": 1.6401798597362505,
      "grad_norm": 0.681988537311554,
      "learning_rate": 8.975517553726408e-05,
      "loss": 2.4485,
      "step": 24440
    },
    {
      "epoch": 1.6408509781550955,
      "grad_norm": 0.696610152721405,
      "learning_rate": 8.968310741656462e-05,
      "loss": 2.4832,
      "step": 24450
    },
    {
      "epoch": 1.6408509781550955,
      "eval_bleu": 21.291574702782306,
      "eval_gen_len": 28.803,
      "eval_loss": 2.9357707500457764,
      "eval_runtime": 64.1817,
      "eval_samples_per_second": 15.581,
      "eval_steps_per_second": 0.982,
      "step": 24450
    },
    {
      "epoch": 1.6415220965739405,
      "grad_norm": 0.7498140931129456,
      "learning_rate": 8.961104471150848e-05,
      "loss": 2.47,
      "step": 24460
    },
    {
      "epoch": 1.6421932149927856,
      "grad_norm": 0.6260626316070557,
      "learning_rate": 8.953898745992359e-05,
      "loss": 2.4297,
      "step": 24470
    },
    {
      "epoch": 1.6428643334116306,
      "grad_norm": 0.7204983830451965,
      "learning_rate": 8.946693569963484e-05,
      "loss": 2.492,
      "step": 24480
    },
    {
      "epoch": 1.6435354518304754,
      "grad_norm": 0.6806362867355347,
      "learning_rate": 8.939488946846445e-05,
      "loss": 2.4252,
      "step": 24490
    },
    {
      "epoch": 1.6442065702493205,
      "grad_norm": 0.731514573097229,
      "learning_rate": 8.932284880423156e-05,
      "loss": 2.4763,
      "step": 24500
    },
    {
      "epoch": 1.6442065702493205,
      "eval_bleu": 21.301517961221485,
      "eval_gen_len": 28.834,
      "eval_loss": 2.9372501373291016,
      "eval_runtime": 63.694,
      "eval_samples_per_second": 15.7,
      "eval_steps_per_second": 0.989,
      "step": 24500
    },
    {
      "epoch": 1.6448776886681655,
      "grad_norm": 0.6632895469665527,
      "learning_rate": 8.925081374475248e-05,
      "loss": 2.4447,
      "step": 24510
    },
    {
      "epoch": 1.6455488070870103,
      "grad_norm": 0.6367316246032715,
      "learning_rate": 8.91787843278405e-05,
      "loss": 2.4576,
      "step": 24520
    },
    {
      "epoch": 1.6462199255058554,
      "grad_norm": 0.6928447484970093,
      "learning_rate": 8.910676059130611e-05,
      "loss": 2.4808,
      "step": 24530
    },
    {
      "epoch": 1.6468910439247004,
      "grad_norm": 0.6746357679367065,
      "learning_rate": 8.903474257295658e-05,
      "loss": 2.4721,
      "step": 24540
    },
    {
      "epoch": 1.6475621623435455,
      "grad_norm": 0.6235705614089966,
      "learning_rate": 8.896273031059641e-05,
      "loss": 2.4959,
      "step": 24550
    },
    {
      "epoch": 1.6475621623435455,
      "eval_bleu": 20.78238480804287,
      "eval_gen_len": 28.865,
      "eval_loss": 2.942600965499878,
      "eval_runtime": 65.2802,
      "eval_samples_per_second": 15.319,
      "eval_steps_per_second": 0.965,
      "step": 24550
    },
    {
      "epoch": 1.6482332807623905,
      "grad_norm": 0.6786211729049683,
      "learning_rate": 8.889072384202692e-05,
      "loss": 2.4796,
      "step": 24560
    },
    {
      "epoch": 1.6489043991812355,
      "grad_norm": 0.7393036484718323,
      "learning_rate": 8.88187232050465e-05,
      "loss": 2.4681,
      "step": 24570
    },
    {
      "epoch": 1.6495755176000806,
      "grad_norm": 0.7013221383094788,
      "learning_rate": 8.874672843745031e-05,
      "loss": 2.4682,
      "step": 24580
    },
    {
      "epoch": 1.6502466360189256,
      "grad_norm": 0.6997635364532471,
      "learning_rate": 8.867473957703068e-05,
      "loss": 2.4476,
      "step": 24590
    },
    {
      "epoch": 1.6509177544377707,
      "grad_norm": 0.7280358076095581,
      "learning_rate": 8.860275666157662e-05,
      "loss": 2.5081,
      "step": 24600
    },
    {
      "epoch": 1.6509177544377707,
      "eval_bleu": 21.35188701939718,
      "eval_gen_len": 28.827,
      "eval_loss": 2.936673164367676,
      "eval_runtime": 64.1776,
      "eval_samples_per_second": 15.582,
      "eval_steps_per_second": 0.982,
      "step": 24600
    },
    {
      "epoch": 1.6515888728566157,
      "grad_norm": 0.744970977306366,
      "learning_rate": 8.853077972887409e-05,
      "loss": 2.4985,
      "step": 24610
    },
    {
      "epoch": 1.6522599912754605,
      "grad_norm": 0.7335637807846069,
      "learning_rate": 8.845880881670598e-05,
      "loss": 2.4952,
      "step": 24620
    },
    {
      "epoch": 1.6529311096943056,
      "grad_norm": 0.7239775657653809,
      "learning_rate": 8.838684396285188e-05,
      "loss": 2.5108,
      "step": 24630
    },
    {
      "epoch": 1.6536022281131506,
      "grad_norm": 0.7291625738143921,
      "learning_rate": 8.831488520508836e-05,
      "loss": 2.4955,
      "step": 24640
    },
    {
      "epoch": 1.6542733465319954,
      "grad_norm": 0.7454876899719238,
      "learning_rate": 8.824293258118865e-05,
      "loss": 2.4687,
      "step": 24650
    },
    {
      "epoch": 1.6542733465319954,
      "eval_bleu": 21.28554191331271,
      "eval_gen_len": 28.78,
      "eval_loss": 2.9373257160186768,
      "eval_runtime": 63.6142,
      "eval_samples_per_second": 15.72,
      "eval_steps_per_second": 0.99,
      "step": 24650
    },
    {
      "epoch": 1.6549444649508405,
      "grad_norm": 0.6979126334190369,
      "learning_rate": 8.817098612892287e-05,
      "loss": 2.4271,
      "step": 24660
    },
    {
      "epoch": 1.6556155833696855,
      "grad_norm": 0.7437773942947388,
      "learning_rate": 8.809904588605778e-05,
      "loss": 2.449,
      "step": 24670
    },
    {
      "epoch": 1.6562867017885305,
      "grad_norm": 0.6613349318504333,
      "learning_rate": 8.802711189035704e-05,
      "loss": 2.4868,
      "step": 24680
    },
    {
      "epoch": 1.6569578202073756,
      "grad_norm": 0.6937224864959717,
      "learning_rate": 8.795518417958087e-05,
      "loss": 2.4466,
      "step": 24690
    },
    {
      "epoch": 1.6576289386262206,
      "grad_norm": 0.6453315019607544,
      "learning_rate": 8.788326279148631e-05,
      "loss": 2.4382,
      "step": 24700
    },
    {
      "epoch": 1.6576289386262206,
      "eval_bleu": 21.067734913057407,
      "eval_gen_len": 28.784,
      "eval_loss": 2.9403440952301025,
      "eval_runtime": 64.0461,
      "eval_samples_per_second": 15.614,
      "eval_steps_per_second": 0.984,
      "step": 24700
    },
    {
      "epoch": 1.6583000570450657,
      "grad_norm": 0.7228725552558899,
      "learning_rate": 8.781134776382696e-05,
      "loss": 2.4683,
      "step": 24710
    },
    {
      "epoch": 1.6589711754639107,
      "grad_norm": 0.6967063546180725,
      "learning_rate": 8.773943913435325e-05,
      "loss": 2.4655,
      "step": 24720
    },
    {
      "epoch": 1.6596422938827557,
      "grad_norm": 0.6696810722351074,
      "learning_rate": 8.766753694081208e-05,
      "loss": 2.4368,
      "step": 24730
    },
    {
      "epoch": 1.6603134123016006,
      "grad_norm": 0.6602157354354858,
      "learning_rate": 8.759564122094711e-05,
      "loss": 2.4512,
      "step": 24740
    },
    {
      "epoch": 1.6609845307204456,
      "grad_norm": 0.7443439960479736,
      "learning_rate": 8.752375201249845e-05,
      "loss": 2.4641,
      "step": 24750
    },
    {
      "epoch": 1.6609845307204456,
      "eval_bleu": 21.3899594342494,
      "eval_gen_len": 29.02,
      "eval_loss": 2.935561418533325,
      "eval_runtime": 64.3508,
      "eval_samples_per_second": 15.54,
      "eval_steps_per_second": 0.979,
      "step": 24750
    },
    {
      "epoch": 1.6616556491392906,
      "grad_norm": 0.6943922638893127,
      "learning_rate": 8.745186935320299e-05,
      "loss": 2.4818,
      "step": 24760
    },
    {
      "epoch": 1.6623267675581357,
      "grad_norm": 0.6941847205162048,
      "learning_rate": 8.737999328079398e-05,
      "loss": 2.4763,
      "step": 24770
    },
    {
      "epoch": 1.6629978859769805,
      "grad_norm": 0.6650645136833191,
      "learning_rate": 8.730812383300137e-05,
      "loss": 2.4593,
      "step": 24780
    },
    {
      "epoch": 1.6636690043958255,
      "grad_norm": 0.7300103306770325,
      "learning_rate": 8.723626104755151e-05,
      "loss": 2.4655,
      "step": 24790
    },
    {
      "epoch": 1.6643401228146706,
      "grad_norm": 0.6715070605278015,
      "learning_rate": 8.716440496216738e-05,
      "loss": 2.4772,
      "step": 24800
    },
    {
      "epoch": 1.6643401228146706,
      "eval_bleu": 21.391003518338202,
      "eval_gen_len": 28.865,
      "eval_loss": 2.9353697299957275,
      "eval_runtime": 64.3025,
      "eval_samples_per_second": 15.552,
      "eval_steps_per_second": 0.98,
      "step": 24800
    },
    {
      "epoch": 1.6650112412335156,
      "grad_norm": 0.6361643075942993,
      "learning_rate": 8.709255561456828e-05,
      "loss": 2.4701,
      "step": 24810
    },
    {
      "epoch": 1.6656823596523607,
      "grad_norm": 0.7156801819801331,
      "learning_rate": 8.70207130424702e-05,
      "loss": 2.5049,
      "step": 24820
    },
    {
      "epoch": 1.6663534780712057,
      "grad_norm": 0.6815605759620667,
      "learning_rate": 8.694887728358529e-05,
      "loss": 2.4886,
      "step": 24830
    },
    {
      "epoch": 1.6670245964900507,
      "grad_norm": 0.6426534056663513,
      "learning_rate": 8.68770483756224e-05,
      "loss": 2.4949,
      "step": 24840
    },
    {
      "epoch": 1.6676957149088958,
      "grad_norm": 0.658111572265625,
      "learning_rate": 8.680522635628655e-05,
      "loss": 2.5247,
      "step": 24850
    },
    {
      "epoch": 1.6676957149088958,
      "eval_bleu": 21.33447662766162,
      "eval_gen_len": 28.743,
      "eval_loss": 2.9381024837493896,
      "eval_runtime": 64.0905,
      "eval_samples_per_second": 15.603,
      "eval_steps_per_second": 0.983,
      "step": 24850
    },
    {
      "epoch": 1.6683668333277408,
      "grad_norm": 0.7311593890190125,
      "learning_rate": 8.673341126327934e-05,
      "loss": 2.5059,
      "step": 24860
    },
    {
      "epoch": 1.6690379517465856,
      "grad_norm": 0.7439601421356201,
      "learning_rate": 8.666160313429861e-05,
      "loss": 2.5258,
      "step": 24870
    },
    {
      "epoch": 1.6697090701654307,
      "grad_norm": 0.6355062127113342,
      "learning_rate": 8.658980200703857e-05,
      "loss": 2.4861,
      "step": 24880
    },
    {
      "epoch": 1.6703801885842757,
      "grad_norm": 0.6661731600761414,
      "learning_rate": 8.65180079191898e-05,
      "loss": 2.5089,
      "step": 24890
    },
    {
      "epoch": 1.6710513070031205,
      "grad_norm": 0.7257869839668274,
      "learning_rate": 8.644622090843906e-05,
      "loss": 2.4515,
      "step": 24900
    },
    {
      "epoch": 1.6710513070031205,
      "eval_bleu": 20.841312881318327,
      "eval_gen_len": 28.8,
      "eval_loss": 2.9397876262664795,
      "eval_runtime": 64.1161,
      "eval_samples_per_second": 15.597,
      "eval_steps_per_second": 0.983,
      "step": 24900
    },
    {
      "epoch": 1.6717224254219656,
      "grad_norm": 0.6830395460128784,
      "learning_rate": 8.637444101246961e-05,
      "loss": 2.4991,
      "step": 24910
    },
    {
      "epoch": 1.6723935438408106,
      "grad_norm": 0.769920289516449,
      "learning_rate": 8.630266826896076e-05,
      "loss": 2.465,
      "step": 24920
    },
    {
      "epoch": 1.6730646622596557,
      "grad_norm": 0.647774875164032,
      "learning_rate": 8.623090271558819e-05,
      "loss": 2.4471,
      "step": 24930
    },
    {
      "epoch": 1.6737357806785007,
      "grad_norm": 0.6904558539390564,
      "learning_rate": 8.615914439002373e-05,
      "loss": 2.4948,
      "step": 24940
    },
    {
      "epoch": 1.6744068990973457,
      "grad_norm": 0.7197750210762024,
      "learning_rate": 8.608739332993553e-05,
      "loss": 2.4741,
      "step": 24950
    },
    {
      "epoch": 1.6744068990973457,
      "eval_bleu": 21.122432820255,
      "eval_gen_len": 28.755,
      "eval_loss": 2.9364309310913086,
      "eval_runtime": 63.9135,
      "eval_samples_per_second": 15.646,
      "eval_steps_per_second": 0.986,
      "step": 24950
    },
    {
      "epoch": 1.6750780175161908,
      "grad_norm": 0.6817206740379333,
      "learning_rate": 8.601564957298779e-05,
      "loss": 2.4828,
      "step": 24960
    },
    {
      "epoch": 1.6757491359350358,
      "grad_norm": 0.6730782389640808,
      "learning_rate": 8.594391315684098e-05,
      "loss": 2.46,
      "step": 24970
    },
    {
      "epoch": 1.6764202543538809,
      "grad_norm": 0.714168906211853,
      "learning_rate": 8.587218411915161e-05,
      "loss": 2.513,
      "step": 24980
    },
    {
      "epoch": 1.677091372772726,
      "grad_norm": 0.6850817799568176,
      "learning_rate": 8.580046249757248e-05,
      "loss": 2.4589,
      "step": 24990
    },
    {
      "epoch": 1.6777624911915707,
      "grad_norm": 0.6613691449165344,
      "learning_rate": 8.572874832975232e-05,
      "loss": 2.4499,
      "step": 25000
    },
    {
      "epoch": 1.6777624911915707,
      "eval_bleu": 21.174063576855435,
      "eval_gen_len": 28.745,
      "eval_loss": 2.9363582134246826,
      "eval_runtime": 63.8621,
      "eval_samples_per_second": 15.659,
      "eval_steps_per_second": 0.987,
      "step": 25000
    },
    {
      "epoch": 1.6784336096104158,
      "grad_norm": 0.6811712980270386,
      "learning_rate": 8.565704165333608e-05,
      "loss": 2.4257,
      "step": 25010
    },
    {
      "epoch": 1.6791047280292608,
      "grad_norm": 0.6609974503517151,
      "learning_rate": 8.558534250596464e-05,
      "loss": 2.483,
      "step": 25020
    },
    {
      "epoch": 1.6797758464481056,
      "grad_norm": 0.6589393615722656,
      "learning_rate": 8.551365092527513e-05,
      "loss": 2.5218,
      "step": 25030
    },
    {
      "epoch": 1.6804469648669507,
      "grad_norm": 0.756920576095581,
      "learning_rate": 8.54419669489005e-05,
      "loss": 2.4935,
      "step": 25040
    },
    {
      "epoch": 1.6811180832857957,
      "grad_norm": 0.6767166256904602,
      "learning_rate": 8.537029061446986e-05,
      "loss": 2.4723,
      "step": 25050
    },
    {
      "epoch": 1.6811180832857957,
      "eval_bleu": 21.429943538723222,
      "eval_gen_len": 28.832,
      "eval_loss": 2.9369900226593018,
      "eval_runtime": 63.9904,
      "eval_samples_per_second": 15.627,
      "eval_steps_per_second": 0.985,
      "step": 25050
    },
    {
      "epoch": 1.6817892017046407,
      "grad_norm": 0.7550290822982788,
      "learning_rate": 8.529862195960817e-05,
      "loss": 2.4997,
      "step": 25060
    },
    {
      "epoch": 1.6824603201234858,
      "grad_norm": 0.6749101281166077,
      "learning_rate": 8.522696102193652e-05,
      "loss": 2.4649,
      "step": 25070
    },
    {
      "epoch": 1.6831314385423308,
      "grad_norm": 0.709786593914032,
      "learning_rate": 8.515530783907181e-05,
      "loss": 2.4802,
      "step": 25080
    },
    {
      "epoch": 1.6838025569611759,
      "grad_norm": 0.6283088326454163,
      "learning_rate": 8.508366244862696e-05,
      "loss": 2.4824,
      "step": 25090
    },
    {
      "epoch": 1.684473675380021,
      "grad_norm": 0.6752596497535706,
      "learning_rate": 8.50120248882107e-05,
      "loss": 2.456,
      "step": 25100
    },
    {
      "epoch": 1.684473675380021,
      "eval_bleu": 21.543292470835173,
      "eval_gen_len": 28.884,
      "eval_loss": 2.9328465461730957,
      "eval_runtime": 63.721,
      "eval_samples_per_second": 15.693,
      "eval_steps_per_second": 0.989,
      "step": 25100
    },
    {
      "epoch": 1.685144793798866,
      "grad_norm": 0.6688516736030579,
      "learning_rate": 8.49403951954278e-05,
      "loss": 2.4812,
      "step": 25110
    },
    {
      "epoch": 1.6858159122177108,
      "grad_norm": 0.7153778076171875,
      "learning_rate": 8.486877340787873e-05,
      "loss": 2.4681,
      "step": 25120
    },
    {
      "epoch": 1.6864870306365558,
      "grad_norm": 0.6485210657119751,
      "learning_rate": 8.479715956316e-05,
      "loss": 2.4638,
      "step": 25130
    },
    {
      "epoch": 1.6871581490554008,
      "grad_norm": 0.6727628111839294,
      "learning_rate": 8.472555369886371e-05,
      "loss": 2.4181,
      "step": 25140
    },
    {
      "epoch": 1.6878292674742457,
      "grad_norm": 0.7014368772506714,
      "learning_rate": 8.465395585257803e-05,
      "loss": 2.4432,
      "step": 25150
    },
    {
      "epoch": 1.6878292674742457,
      "eval_bleu": 21.672005846283053,
      "eval_gen_len": 28.876,
      "eval_loss": 2.9325435161590576,
      "eval_runtime": 63.9732,
      "eval_samples_per_second": 15.632,
      "eval_steps_per_second": 0.985,
      "step": 25150
    },
    {
      "epoch": 1.6885003858930907,
      "grad_norm": 0.6501568555831909,
      "learning_rate": 8.458236606188668e-05,
      "loss": 2.4271,
      "step": 25160
    },
    {
      "epoch": 1.6891715043119357,
      "grad_norm": 0.6749528050422668,
      "learning_rate": 8.451078436436938e-05,
      "loss": 2.4443,
      "step": 25170
    },
    {
      "epoch": 1.6898426227307808,
      "grad_norm": 0.8229576945304871,
      "learning_rate": 8.443921079760143e-05,
      "loss": 2.502,
      "step": 25180
    },
    {
      "epoch": 1.6905137411496258,
      "grad_norm": 0.711996853351593,
      "learning_rate": 8.436764539915392e-05,
      "loss": 2.4708,
      "step": 25190
    },
    {
      "epoch": 1.6911848595684709,
      "grad_norm": 0.6832741498947144,
      "learning_rate": 8.429608820659366e-05,
      "loss": 2.4832,
      "step": 25200
    },
    {
      "epoch": 1.6911848595684709,
      "eval_bleu": 21.224761144639803,
      "eval_gen_len": 28.896,
      "eval_loss": 2.931354284286499,
      "eval_runtime": 63.8445,
      "eval_samples_per_second": 15.663,
      "eval_steps_per_second": 0.987,
      "step": 25200
    },
    {
      "epoch": 1.691855977987316,
      "grad_norm": 0.7679474949836731,
      "learning_rate": 8.422453925748312e-05,
      "loss": 2.5477,
      "step": 25210
    },
    {
      "epoch": 1.692527096406161,
      "grad_norm": 0.6469824910163879,
      "learning_rate": 8.415299858938053e-05,
      "loss": 2.4912,
      "step": 25220
    },
    {
      "epoch": 1.693198214825006,
      "grad_norm": 0.7122019529342651,
      "learning_rate": 8.408146623983966e-05,
      "loss": 2.4519,
      "step": 25230
    },
    {
      "epoch": 1.693869333243851,
      "grad_norm": 0.828633725643158,
      "learning_rate": 8.400994224641e-05,
      "loss": 2.4682,
      "step": 25240
    },
    {
      "epoch": 1.6945404516626958,
      "grad_norm": 0.718437135219574,
      "learning_rate": 8.393842664663655e-05,
      "loss": 2.5022,
      "step": 25250
    },
    {
      "epoch": 1.6945404516626958,
      "eval_bleu": 21.23906547645184,
      "eval_gen_len": 28.905,
      "eval_loss": 2.9367594718933105,
      "eval_runtime": 63.9633,
      "eval_samples_per_second": 15.634,
      "eval_steps_per_second": 0.985,
      "step": 25250
    },
    {
      "epoch": 1.6952115700815409,
      "grad_norm": 0.6913001537322998,
      "learning_rate": 8.386691947806008e-05,
      "loss": 2.4271,
      "step": 25260
    },
    {
      "epoch": 1.695882688500386,
      "grad_norm": 0.6784201264381409,
      "learning_rate": 8.379542077821675e-05,
      "loss": 2.4587,
      "step": 25270
    },
    {
      "epoch": 1.6965538069192307,
      "grad_norm": 0.6294425129890442,
      "learning_rate": 8.372393058463838e-05,
      "loss": 2.4325,
      "step": 25280
    },
    {
      "epoch": 1.6972249253380758,
      "grad_norm": 0.7095068693161011,
      "learning_rate": 8.365244893485224e-05,
      "loss": 2.4926,
      "step": 25290
    },
    {
      "epoch": 1.6978960437569208,
      "grad_norm": 0.7066725492477417,
      "learning_rate": 8.358097586638128e-05,
      "loss": 2.4833,
      "step": 25300
    },
    {
      "epoch": 1.6978960437569208,
      "eval_bleu": 21.31296757116623,
      "eval_gen_len": 28.887,
      "eval_loss": 2.934776782989502,
      "eval_runtime": 64.4115,
      "eval_samples_per_second": 15.525,
      "eval_steps_per_second": 0.978,
      "step": 25300
    },
    {
      "epoch": 1.6985671621757659,
      "grad_norm": 0.7088422775268555,
      "learning_rate": 8.350951141674374e-05,
      "loss": 2.4833,
      "step": 25310
    },
    {
      "epoch": 1.699238280594611,
      "grad_norm": 0.6857017278671265,
      "learning_rate": 8.34380556234535e-05,
      "loss": 2.3924,
      "step": 25320
    },
    {
      "epoch": 1.699909399013456,
      "grad_norm": 0.676768958568573,
      "learning_rate": 8.336660852401974e-05,
      "loss": 2.4582,
      "step": 25330
    },
    {
      "epoch": 1.700580517432301,
      "grad_norm": 0.7435950040817261,
      "learning_rate": 8.329517015594728e-05,
      "loss": 2.5121,
      "step": 25340
    },
    {
      "epoch": 1.701251635851146,
      "grad_norm": 0.714613139629364,
      "learning_rate": 8.322374055673615e-05,
      "loss": 2.4681,
      "step": 25350
    },
    {
      "epoch": 1.701251635851146,
      "eval_bleu": 21.411622933346365,
      "eval_gen_len": 28.889,
      "eval_loss": 2.939373254776001,
      "eval_runtime": 64.5126,
      "eval_samples_per_second": 15.501,
      "eval_steps_per_second": 0.977,
      "step": 25350
    },
    {
      "epoch": 1.701922754269991,
      "grad_norm": 0.7407569885253906,
      "learning_rate": 8.315231976388191e-05,
      "loss": 2.4895,
      "step": 25360
    },
    {
      "epoch": 1.702593872688836,
      "grad_norm": 0.68173748254776,
      "learning_rate": 8.308090781487541e-05,
      "loss": 2.4915,
      "step": 25370
    },
    {
      "epoch": 1.703264991107681,
      "grad_norm": 0.7277919054031372,
      "learning_rate": 8.300950474720298e-05,
      "loss": 2.4469,
      "step": 25380
    },
    {
      "epoch": 1.703936109526526,
      "grad_norm": 0.7261453866958618,
      "learning_rate": 8.293811059834615e-05,
      "loss": 2.4882,
      "step": 25390
    },
    {
      "epoch": 1.704607227945371,
      "grad_norm": 0.614893913269043,
      "learning_rate": 8.286672540578187e-05,
      "loss": 2.4503,
      "step": 25400
    },
    {
      "epoch": 1.704607227945371,
      "eval_bleu": 21.63671640917798,
      "eval_gen_len": 28.951,
      "eval_loss": 2.9363389015197754,
      "eval_runtime": 63.8484,
      "eval_samples_per_second": 15.662,
      "eval_steps_per_second": 0.987,
      "step": 25400
    },
    {
      "epoch": 1.7052783463642158,
      "grad_norm": 0.7201805710792542,
      "learning_rate": 8.279534920698228e-05,
      "loss": 2.4801,
      "step": 25410
    },
    {
      "epoch": 1.7059494647830609,
      "grad_norm": 0.7119470238685608,
      "learning_rate": 8.272398203941496e-05,
      "loss": 2.4913,
      "step": 25420
    },
    {
      "epoch": 1.706620583201906,
      "grad_norm": 0.7491301894187927,
      "learning_rate": 8.265262394054258e-05,
      "loss": 2.4572,
      "step": 25430
    },
    {
      "epoch": 1.707291701620751,
      "grad_norm": 0.6898239850997925,
      "learning_rate": 8.258127494782319e-05,
      "loss": 2.4274,
      "step": 25440
    },
    {
      "epoch": 1.707962820039596,
      "grad_norm": 0.704541802406311,
      "learning_rate": 8.250993509870992e-05,
      "loss": 2.5022,
      "step": 25450
    },
    {
      "epoch": 1.707962820039596,
      "eval_bleu": 21.572913631948417,
      "eval_gen_len": 28.921,
      "eval_loss": 2.9366838932037354,
      "eval_runtime": 63.2936,
      "eval_samples_per_second": 15.799,
      "eval_steps_per_second": 0.995,
      "step": 25450
    },
    {
      "epoch": 1.708633938458441,
      "grad_norm": 0.7079902291297913,
      "learning_rate": 8.243860443065125e-05,
      "loss": 2.4911,
      "step": 25460
    },
    {
      "epoch": 1.709305056877286,
      "grad_norm": 0.7565146088600159,
      "learning_rate": 8.236728298109069e-05,
      "loss": 2.4534,
      "step": 25470
    },
    {
      "epoch": 1.709976175296131,
      "grad_norm": 0.6536447405815125,
      "learning_rate": 8.229597078746708e-05,
      "loss": 2.474,
      "step": 25480
    },
    {
      "epoch": 1.7106472937149761,
      "grad_norm": 0.6580840349197388,
      "learning_rate": 8.222466788721425e-05,
      "loss": 2.4584,
      "step": 25490
    },
    {
      "epoch": 1.711318412133821,
      "grad_norm": 0.6825116276741028,
      "learning_rate": 8.21533743177612e-05,
      "loss": 2.4739,
      "step": 25500
    },
    {
      "epoch": 1.711318412133821,
      "eval_bleu": 21.857035357064195,
      "eval_gen_len": 28.968,
      "eval_loss": 2.929563522338867,
      "eval_runtime": 63.8962,
      "eval_samples_per_second": 15.65,
      "eval_steps_per_second": 0.986,
      "step": 25500
    },
    {
      "epoch": 1.711989530552666,
      "grad_norm": 0.7032045722007751,
      "learning_rate": 8.208209011653208e-05,
      "loss": 2.4312,
      "step": 25510
    },
    {
      "epoch": 1.712660648971511,
      "grad_norm": 0.6883833408355713,
      "learning_rate": 8.201081532094603e-05,
      "loss": 2.4754,
      "step": 25520
    },
    {
      "epoch": 1.7133317673903559,
      "grad_norm": 0.6540526151657104,
      "learning_rate": 8.193954996841737e-05,
      "loss": 2.4818,
      "step": 25530
    },
    {
      "epoch": 1.714002885809201,
      "grad_norm": 0.7119835019111633,
      "learning_rate": 8.186829409635536e-05,
      "loss": 2.4837,
      "step": 25540
    },
    {
      "epoch": 1.714674004228046,
      "grad_norm": 0.719760537147522,
      "learning_rate": 8.179704774216436e-05,
      "loss": 2.4457,
      "step": 25550
    },
    {
      "epoch": 1.714674004228046,
      "eval_bleu": 21.562203185629816,
      "eval_gen_len": 28.884,
      "eval_loss": 2.931029796600342,
      "eval_runtime": 63.907,
      "eval_samples_per_second": 15.648,
      "eval_steps_per_second": 0.986,
      "step": 25550
    },
    {
      "epoch": 1.715345122646891,
      "grad_norm": 0.6565378308296204,
      "learning_rate": 8.172581094324364e-05,
      "loss": 2.4732,
      "step": 25560
    },
    {
      "epoch": 1.716016241065736,
      "grad_norm": 0.6453200578689575,
      "learning_rate": 8.165458373698758e-05,
      "loss": 2.4594,
      "step": 25570
    },
    {
      "epoch": 1.716687359484581,
      "grad_norm": 0.6931400895118713,
      "learning_rate": 8.15833661607854e-05,
      "loss": 2.4877,
      "step": 25580
    },
    {
      "epoch": 1.717358477903426,
      "grad_norm": 0.6475791931152344,
      "learning_rate": 8.151215825202138e-05,
      "loss": 2.5135,
      "step": 25590
    },
    {
      "epoch": 1.7180295963222711,
      "grad_norm": 0.7424793839454651,
      "learning_rate": 8.144096004807456e-05,
      "loss": 2.4827,
      "step": 25600
    },
    {
      "epoch": 1.7180295963222711,
      "eval_bleu": 21.335532910961593,
      "eval_gen_len": 28.858,
      "eval_loss": 2.9341065883636475,
      "eval_runtime": 63.893,
      "eval_samples_per_second": 15.651,
      "eval_steps_per_second": 0.986,
      "step": 25600
    },
    {
      "epoch": 1.7187007147411162,
      "grad_norm": 0.6753220558166504,
      "learning_rate": 8.136977158631912e-05,
      "loss": 2.5066,
      "step": 25610
    },
    {
      "epoch": 1.7193718331599612,
      "grad_norm": 0.7174993753433228,
      "learning_rate": 8.129859290412392e-05,
      "loss": 2.4416,
      "step": 25620
    },
    {
      "epoch": 1.720042951578806,
      "grad_norm": 0.7625526189804077,
      "learning_rate": 8.122742403885279e-05,
      "loss": 2.5084,
      "step": 25630
    },
    {
      "epoch": 1.720714069997651,
      "grad_norm": 0.6658177375793457,
      "learning_rate": 8.115626502786435e-05,
      "loss": 2.4421,
      "step": 25640
    },
    {
      "epoch": 1.7213851884164961,
      "grad_norm": 0.6109898686408997,
      "learning_rate": 8.108511590851215e-05,
      "loss": 2.4853,
      "step": 25650
    },
    {
      "epoch": 1.7213851884164961,
      "eval_bleu": 21.584705291007854,
      "eval_gen_len": 28.892,
      "eval_loss": 2.92777419090271,
      "eval_runtime": 63.7862,
      "eval_samples_per_second": 15.677,
      "eval_steps_per_second": 0.988,
      "step": 25650
    },
    {
      "epoch": 1.722056306835341,
      "grad_norm": 0.6839781999588013,
      "learning_rate": 8.10139767181444e-05,
      "loss": 2.4642,
      "step": 25660
    },
    {
      "epoch": 1.722727425254186,
      "grad_norm": 0.7776437997817993,
      "learning_rate": 8.094284749410422e-05,
      "loss": 2.5042,
      "step": 25670
    },
    {
      "epoch": 1.723398543673031,
      "grad_norm": 0.6752610206604004,
      "learning_rate": 8.08717282737294e-05,
      "loss": 2.4843,
      "step": 25680
    },
    {
      "epoch": 1.724069662091876,
      "grad_norm": 0.7050192356109619,
      "learning_rate": 8.080061909435262e-05,
      "loss": 2.501,
      "step": 25690
    },
    {
      "epoch": 1.724740780510721,
      "grad_norm": 0.6865827441215515,
      "learning_rate": 8.072951999330111e-05,
      "loss": 2.4431,
      "step": 25700
    },
    {
      "epoch": 1.724740780510721,
      "eval_bleu": 21.378823822997916,
      "eval_gen_len": 28.956,
      "eval_loss": 2.9311630725860596,
      "eval_runtime": 64.7128,
      "eval_samples_per_second": 15.453,
      "eval_steps_per_second": 0.974,
      "step": 25700
    },
    {
      "epoch": 1.7254118989295661,
      "grad_norm": 0.6434574723243713,
      "learning_rate": 8.065843100789696e-05,
      "loss": 2.4762,
      "step": 25710
    },
    {
      "epoch": 1.7260830173484112,
      "grad_norm": 0.8671664595603943,
      "learning_rate": 8.058735217545683e-05,
      "loss": 2.4886,
      "step": 25720
    },
    {
      "epoch": 1.7267541357672562,
      "grad_norm": 0.6696003675460815,
      "learning_rate": 8.05162835332922e-05,
      "loss": 2.4731,
      "step": 25730
    },
    {
      "epoch": 1.7274252541861013,
      "grad_norm": 0.7099536657333374,
      "learning_rate": 8.0445225118709e-05,
      "loss": 2.5181,
      "step": 25740
    },
    {
      "epoch": 1.7280963726049463,
      "grad_norm": 0.6875432729721069,
      "learning_rate": 8.037417696900802e-05,
      "loss": 2.4916,
      "step": 25750
    },
    {
      "epoch": 1.7280963726049463,
      "eval_bleu": 21.414092526791798,
      "eval_gen_len": 28.936,
      "eval_loss": 2.9297142028808594,
      "eval_runtime": 63.2158,
      "eval_samples_per_second": 15.819,
      "eval_steps_per_second": 0.997,
      "step": 25750
    },
    {
      "epoch": 1.7287674910237911,
      "grad_norm": 0.7341926693916321,
      "learning_rate": 8.030313912148447e-05,
      "loss": 2.4786,
      "step": 25760
    },
    {
      "epoch": 1.7294386094426362,
      "grad_norm": 0.627448320388794,
      "learning_rate": 8.023211161342823e-05,
      "loss": 2.4664,
      "step": 25770
    },
    {
      "epoch": 1.7301097278614812,
      "grad_norm": 0.6786414384841919,
      "learning_rate": 8.016109448212379e-05,
      "loss": 2.4733,
      "step": 25780
    },
    {
      "epoch": 1.730780846280326,
      "grad_norm": 0.691715657711029,
      "learning_rate": 8.009008776485008e-05,
      "loss": 2.4453,
      "step": 25790
    },
    {
      "epoch": 1.731451964699171,
      "grad_norm": 0.7110735774040222,
      "learning_rate": 8.00190914988807e-05,
      "loss": 2.4566,
      "step": 25800
    },
    {
      "epoch": 1.731451964699171,
      "eval_bleu": 21.395365482066193,
      "eval_gen_len": 29.018,
      "eval_loss": 2.931699752807617,
      "eval_runtime": 63.5484,
      "eval_samples_per_second": 15.736,
      "eval_steps_per_second": 0.991,
      "step": 25800
    },
    {
      "epoch": 1.732123083118016,
      "grad_norm": 0.7387024760246277,
      "learning_rate": 7.994810572148367e-05,
      "loss": 2.4761,
      "step": 25810
    },
    {
      "epoch": 1.7327942015368611,
      "grad_norm": 0.7354088425636292,
      "learning_rate": 7.987713046992156e-05,
      "loss": 2.4598,
      "step": 25820
    },
    {
      "epoch": 1.7334653199557062,
      "grad_norm": 0.6884924173355103,
      "learning_rate": 7.980616578145133e-05,
      "loss": 2.5447,
      "step": 25830
    },
    {
      "epoch": 1.7341364383745512,
      "grad_norm": 0.6535432934761047,
      "learning_rate": 7.973521169332451e-05,
      "loss": 2.4458,
      "step": 25840
    },
    {
      "epoch": 1.7348075567933963,
      "grad_norm": 0.6335003972053528,
      "learning_rate": 7.966426824278699e-05,
      "loss": 2.436,
      "step": 25850
    },
    {
      "epoch": 1.7348075567933963,
      "eval_bleu": 21.460106470396465,
      "eval_gen_len": 28.992,
      "eval_loss": 2.93232798576355,
      "eval_runtime": 63.9646,
      "eval_samples_per_second": 15.634,
      "eval_steps_per_second": 0.985,
      "step": 25850
    },
    {
      "epoch": 1.7354786752122413,
      "grad_norm": 0.6836902499198914,
      "learning_rate": 7.95933354670791e-05,
      "loss": 2.4838,
      "step": 25860
    },
    {
      "epoch": 1.7361497936310863,
      "grad_norm": 0.6691306233406067,
      "learning_rate": 7.952241340343552e-05,
      "loss": 2.4946,
      "step": 25870
    },
    {
      "epoch": 1.7368209120499312,
      "grad_norm": 0.7437146306037903,
      "learning_rate": 7.945150208908543e-05,
      "loss": 2.5499,
      "step": 25880
    },
    {
      "epoch": 1.7374920304687762,
      "grad_norm": 0.700419008731842,
      "learning_rate": 7.93806015612522e-05,
      "loss": 2.4323,
      "step": 25890
    },
    {
      "epoch": 1.7381631488876212,
      "grad_norm": 0.7175484299659729,
      "learning_rate": 7.930971185715368e-05,
      "loss": 2.4785,
      "step": 25900
    },
    {
      "epoch": 1.7381631488876212,
      "eval_bleu": 21.250667243851016,
      "eval_gen_len": 28.851,
      "eval_loss": 2.931133985519409,
      "eval_runtime": 63.7862,
      "eval_samples_per_second": 15.677,
      "eval_steps_per_second": 0.988,
      "step": 25900
    },
    {
      "epoch": 1.738834267306466,
      "grad_norm": 0.674450159072876,
      "learning_rate": 7.923883301400192e-05,
      "loss": 2.4945,
      "step": 25910
    },
    {
      "epoch": 1.739505385725311,
      "grad_norm": 0.6737545728683472,
      "learning_rate": 7.916796506900343e-05,
      "loss": 2.4497,
      "step": 25920
    },
    {
      "epoch": 1.7401765041441561,
      "grad_norm": 0.6514649391174316,
      "learning_rate": 7.90971080593588e-05,
      "loss": 2.4425,
      "step": 25930
    },
    {
      "epoch": 1.7408476225630012,
      "grad_norm": 0.638816773891449,
      "learning_rate": 7.902626202226304e-05,
      "loss": 2.4713,
      "step": 25940
    },
    {
      "epoch": 1.7415187409818462,
      "grad_norm": 0.6999550461769104,
      "learning_rate": 7.895542699490529e-05,
      "loss": 2.4714,
      "step": 25950
    },
    {
      "epoch": 1.7415187409818462,
      "eval_bleu": 21.353106143286546,
      "eval_gen_len": 28.898,
      "eval_loss": 2.932645559310913,
      "eval_runtime": 64.1511,
      "eval_samples_per_second": 15.588,
      "eval_steps_per_second": 0.982,
      "step": 25950
    },
    {
      "epoch": 1.7421898594006913,
      "grad_norm": 0.6624528169631958,
      "learning_rate": 7.888460301446903e-05,
      "loss": 2.5265,
      "step": 25960
    },
    {
      "epoch": 1.7428609778195363,
      "grad_norm": 0.753139853477478,
      "learning_rate": 7.881379011813179e-05,
      "loss": 2.4828,
      "step": 25970
    },
    {
      "epoch": 1.7435320962383813,
      "grad_norm": 0.7114614248275757,
      "learning_rate": 7.874298834306544e-05,
      "loss": 2.5026,
      "step": 25980
    },
    {
      "epoch": 1.7442032146572264,
      "grad_norm": 0.6460873484611511,
      "learning_rate": 7.867219772643583e-05,
      "loss": 2.4744,
      "step": 25990
    },
    {
      "epoch": 1.7448743330760714,
      "grad_norm": 0.7012046575546265,
      "learning_rate": 7.860141830540319e-05,
      "loss": 2.475,
      "step": 26000
    },
    {
      "epoch": 1.7448743330760714,
      "eval_bleu": 21.347490717450686,
      "eval_gen_len": 28.817,
      "eval_loss": 2.933586597442627,
      "eval_runtime": 63.3913,
      "eval_samples_per_second": 15.775,
      "eval_steps_per_second": 0.994,
      "step": 26000
    },
    {
      "epoch": 1.7455454514949162,
      "grad_norm": 0.6476933360099792,
      "learning_rate": 7.853065011712166e-05,
      "loss": 2.4878,
      "step": 26010
    },
    {
      "epoch": 1.7462165699137613,
      "grad_norm": 0.7818062901496887,
      "learning_rate": 7.845989319873957e-05,
      "loss": 2.456,
      "step": 26020
    },
    {
      "epoch": 1.7468876883326063,
      "grad_norm": 0.7699670195579529,
      "learning_rate": 7.838914758739932e-05,
      "loss": 2.4352,
      "step": 26030
    },
    {
      "epoch": 1.7475588067514511,
      "grad_norm": 0.655682384967804,
      "learning_rate": 7.831841332023743e-05,
      "loss": 2.4502,
      "step": 26040
    },
    {
      "epoch": 1.7482299251702962,
      "grad_norm": 0.6675354838371277,
      "learning_rate": 7.824769043438433e-05,
      "loss": 2.4529,
      "step": 26050
    },
    {
      "epoch": 1.7482299251702962,
      "eval_bleu": 20.95639880266586,
      "eval_gen_len": 28.986,
      "eval_loss": 2.934473752975464,
      "eval_runtime": 64.3844,
      "eval_samples_per_second": 15.532,
      "eval_steps_per_second": 0.978,
      "step": 26050
    },
    {
      "epoch": 1.7489010435891412,
      "grad_norm": 0.7466655373573303,
      "learning_rate": 7.817697896696468e-05,
      "loss": 2.5131,
      "step": 26060
    },
    {
      "epoch": 1.7495721620079863,
      "grad_norm": 0.6960691809654236,
      "learning_rate": 7.810627895509699e-05,
      "loss": 2.5153,
      "step": 26070
    },
    {
      "epoch": 1.7502432804268313,
      "grad_norm": 0.6538236141204834,
      "learning_rate": 7.80355904358937e-05,
      "loss": 2.4732,
      "step": 26080
    },
    {
      "epoch": 1.7509143988456763,
      "grad_norm": 0.6946508884429932,
      "learning_rate": 7.796491344646146e-05,
      "loss": 2.4778,
      "step": 26090
    },
    {
      "epoch": 1.7515855172645214,
      "grad_norm": 0.707431435585022,
      "learning_rate": 7.789424802390058e-05,
      "loss": 2.4479,
      "step": 26100
    },
    {
      "epoch": 1.7515855172645214,
      "eval_bleu": 20.788237746347807,
      "eval_gen_len": 29.097,
      "eval_loss": 2.9389758110046387,
      "eval_runtime": 67.1168,
      "eval_samples_per_second": 14.899,
      "eval_steps_per_second": 0.939,
      "step": 26100
    },
    {
      "epoch": 1.7522566356833664,
      "grad_norm": 0.6707834601402283,
      "learning_rate": 7.782359420530557e-05,
      "loss": 2.4864,
      "step": 26110
    },
    {
      "epoch": 1.7529277541022115,
      "grad_norm": 0.6698330640792847,
      "learning_rate": 7.775295202776463e-05,
      "loss": 2.4596,
      "step": 26120
    },
    {
      "epoch": 1.7535988725210565,
      "grad_norm": 0.6356778740882874,
      "learning_rate": 7.768232152835999e-05,
      "loss": 2.4631,
      "step": 26130
    },
    {
      "epoch": 1.7542699909399013,
      "grad_norm": 0.6736570000648499,
      "learning_rate": 7.761170274416761e-05,
      "loss": 2.4025,
      "step": 26140
    },
    {
      "epoch": 1.7549411093587464,
      "grad_norm": 0.7027248740196228,
      "learning_rate": 7.754109571225752e-05,
      "loss": 2.4888,
      "step": 26150
    },
    {
      "epoch": 1.7549411093587464,
      "eval_bleu": 21.301325962052626,
      "eval_gen_len": 28.937,
      "eval_loss": 2.929802656173706,
      "eval_runtime": 64.1669,
      "eval_samples_per_second": 15.584,
      "eval_steps_per_second": 0.982,
      "step": 26150
    },
    {
      "epoch": 1.7556122277775914,
      "grad_norm": 0.6919525265693665,
      "learning_rate": 7.747050046969333e-05,
      "loss": 2.5204,
      "step": 26160
    },
    {
      "epoch": 1.7562833461964362,
      "grad_norm": 0.6943140625953674,
      "learning_rate": 7.739991705353266e-05,
      "loss": 2.4419,
      "step": 26170
    },
    {
      "epoch": 1.7569544646152813,
      "grad_norm": 0.662183403968811,
      "learning_rate": 7.732934550082676e-05,
      "loss": 2.4556,
      "step": 26180
    },
    {
      "epoch": 1.7576255830341263,
      "grad_norm": 0.6278181672096252,
      "learning_rate": 7.725878584862083e-05,
      "loss": 2.4898,
      "step": 26190
    },
    {
      "epoch": 1.7582967014529713,
      "grad_norm": 0.7655845284461975,
      "learning_rate": 7.718823813395367e-05,
      "loss": 2.4629,
      "step": 26200
    },
    {
      "epoch": 1.7582967014529713,
      "eval_bleu": 21.081865282307533,
      "eval_gen_len": 28.803,
      "eval_loss": 2.9378254413604736,
      "eval_runtime": 63.5497,
      "eval_samples_per_second": 15.736,
      "eval_steps_per_second": 0.991,
      "step": 26200
    },
    {
      "epoch": 1.7589678198718164,
      "grad_norm": 0.6958760023117065,
      "learning_rate": 7.71177023938579e-05,
      "loss": 2.4512,
      "step": 26210
    },
    {
      "epoch": 1.7596389382906614,
      "grad_norm": 0.6543221473693848,
      "learning_rate": 7.704717866535975e-05,
      "loss": 2.5241,
      "step": 26220
    },
    {
      "epoch": 1.7603100567095065,
      "grad_norm": 0.7546828389167786,
      "learning_rate": 7.697666698547933e-05,
      "loss": 2.4499,
      "step": 26230
    },
    {
      "epoch": 1.7609811751283515,
      "grad_norm": 0.7136877179145813,
      "learning_rate": 7.690616739123023e-05,
      "loss": 2.4768,
      "step": 26240
    },
    {
      "epoch": 1.7616522935471965,
      "grad_norm": 0.696550190448761,
      "learning_rate": 7.683567991961984e-05,
      "loss": 2.4283,
      "step": 26250
    },
    {
      "epoch": 1.7616522935471965,
      "eval_bleu": 21.151219465499373,
      "eval_gen_len": 28.829,
      "eval_loss": 2.9369046688079834,
      "eval_runtime": 64.116,
      "eval_samples_per_second": 15.597,
      "eval_steps_per_second": 0.983,
      "step": 26250
    },
    {
      "epoch": 1.7623234119660414,
      "grad_norm": 0.6697522401809692,
      "learning_rate": 7.676520460764905e-05,
      "loss": 2.5128,
      "step": 26260
    },
    {
      "epoch": 1.7629945303848864,
      "grad_norm": 0.6285646557807922,
      "learning_rate": 7.669474149231255e-05,
      "loss": 2.4692,
      "step": 26270
    },
    {
      "epoch": 1.7636656488037314,
      "grad_norm": 0.749737560749054,
      "learning_rate": 7.662429061059844e-05,
      "loss": 2.5354,
      "step": 26280
    },
    {
      "epoch": 1.7643367672225763,
      "grad_norm": 0.6833251714706421,
      "learning_rate": 7.655385199948852e-05,
      "loss": 2.4111,
      "step": 26290
    },
    {
      "epoch": 1.7650078856414213,
      "grad_norm": 0.6492385268211365,
      "learning_rate": 7.648342569595806e-05,
      "loss": 2.4667,
      "step": 26300
    },
    {
      "epoch": 1.7650078856414213,
      "eval_bleu": 21.31771194137384,
      "eval_gen_len": 28.92,
      "eval_loss": 2.9329631328582764,
      "eval_runtime": 64.0458,
      "eval_samples_per_second": 15.614,
      "eval_steps_per_second": 0.984,
      "step": 26300
    },
    {
      "epoch": 1.7656790040602663,
      "grad_norm": 0.733248770236969,
      "learning_rate": 7.6413011736976e-05,
      "loss": 2.479,
      "step": 26310
    },
    {
      "epoch": 1.7663501224791114,
      "grad_norm": 0.7084337472915649,
      "learning_rate": 7.634261015950465e-05,
      "loss": 2.5028,
      "step": 26320
    },
    {
      "epoch": 1.7670212408979564,
      "grad_norm": 0.6469162702560425,
      "learning_rate": 7.627222100049993e-05,
      "loss": 2.4503,
      "step": 26330
    },
    {
      "epoch": 1.7676923593168015,
      "grad_norm": 0.7410047650337219,
      "learning_rate": 7.620184429691114e-05,
      "loss": 2.4811,
      "step": 26340
    },
    {
      "epoch": 1.7683634777356465,
      "grad_norm": 0.7590832114219666,
      "learning_rate": 7.613148008568119e-05,
      "loss": 2.4842,
      "step": 26350
    },
    {
      "epoch": 1.7683634777356465,
      "eval_bleu": 21.348807011267876,
      "eval_gen_len": 28.99,
      "eval_loss": 2.9326438903808594,
      "eval_runtime": 63.9663,
      "eval_samples_per_second": 15.633,
      "eval_steps_per_second": 0.985,
      "step": 26350
    },
    {
      "epoch": 1.7690345961544915,
      "grad_norm": 0.7340307235717773,
      "learning_rate": 7.606112840374631e-05,
      "loss": 2.4389,
      "step": 26360
    },
    {
      "epoch": 1.7697057145733366,
      "grad_norm": 0.6463502049446106,
      "learning_rate": 7.599078928803612e-05,
      "loss": 2.4905,
      "step": 26370
    },
    {
      "epoch": 1.7703768329921816,
      "grad_norm": 0.6814841032028198,
      "learning_rate": 7.592046277547382e-05,
      "loss": 2.4005,
      "step": 26380
    },
    {
      "epoch": 1.7710479514110264,
      "grad_norm": 0.683914303779602,
      "learning_rate": 7.585014890297579e-05,
      "loss": 2.4636,
      "step": 26390
    },
    {
      "epoch": 1.7717190698298715,
      "grad_norm": 0.7198473215103149,
      "learning_rate": 7.577984770745194e-05,
      "loss": 2.531,
      "step": 26400
    },
    {
      "epoch": 1.7717190698298715,
      "eval_bleu": 21.54236363768102,
      "eval_gen_len": 28.947,
      "eval_loss": 2.932142734527588,
      "eval_runtime": 63.8108,
      "eval_samples_per_second": 15.671,
      "eval_steps_per_second": 0.987,
      "step": 26400
    },
    {
      "epoch": 1.7723901882487165,
      "grad_norm": 0.7099300622940063,
      "learning_rate": 7.570955922580541e-05,
      "loss": 2.4686,
      "step": 26410
    },
    {
      "epoch": 1.7730613066675613,
      "grad_norm": 0.6788355708122253,
      "learning_rate": 7.563928349493274e-05,
      "loss": 2.4486,
      "step": 26420
    },
    {
      "epoch": 1.7737324250864064,
      "grad_norm": 0.7157973051071167,
      "learning_rate": 7.556902055172374e-05,
      "loss": 2.4627,
      "step": 26430
    },
    {
      "epoch": 1.7744035435052514,
      "grad_norm": 0.7463886141777039,
      "learning_rate": 7.549877043306153e-05,
      "loss": 2.4989,
      "step": 26440
    },
    {
      "epoch": 1.7750746619240965,
      "grad_norm": 0.724025547504425,
      "learning_rate": 7.542853317582243e-05,
      "loss": 2.5244,
      "step": 26450
    },
    {
      "epoch": 1.7750746619240965,
      "eval_bleu": 21.45777635318288,
      "eval_gen_len": 28.989,
      "eval_loss": 2.9321088790893555,
      "eval_runtime": 65.2151,
      "eval_samples_per_second": 15.334,
      "eval_steps_per_second": 0.966,
      "step": 26450
    },
    {
      "epoch": 1.7757457803429415,
      "grad_norm": 0.6665330529212952,
      "learning_rate": 7.535830881687614e-05,
      "loss": 2.4829,
      "step": 26460
    },
    {
      "epoch": 1.7764168987617865,
      "grad_norm": 0.6899041533470154,
      "learning_rate": 7.528809739308546e-05,
      "loss": 2.4426,
      "step": 26470
    },
    {
      "epoch": 1.7770880171806316,
      "grad_norm": 0.7267050743103027,
      "learning_rate": 7.521789894130649e-05,
      "loss": 2.4742,
      "step": 26480
    },
    {
      "epoch": 1.7777591355994766,
      "grad_norm": 0.6989633440971375,
      "learning_rate": 7.51477134983884e-05,
      "loss": 2.4458,
      "step": 26490
    },
    {
      "epoch": 1.7784302540183217,
      "grad_norm": 0.7122328877449036,
      "learning_rate": 7.507754110117371e-05,
      "loss": 2.4359,
      "step": 26500
    },
    {
      "epoch": 1.7784302540183217,
      "eval_bleu": 21.210440340598126,
      "eval_gen_len": 28.884,
      "eval_loss": 2.938936471939087,
      "eval_runtime": 64.0934,
      "eval_samples_per_second": 15.602,
      "eval_steps_per_second": 0.983,
      "step": 26500
    },
    {
      "epoch": 1.7791013724371665,
      "grad_norm": 0.733936607837677,
      "learning_rate": 7.500738178649796e-05,
      "loss": 2.4932,
      "step": 26510
    },
    {
      "epoch": 1.7797724908560115,
      "grad_norm": 0.675479531288147,
      "learning_rate": 7.493723559118986e-05,
      "loss": 2.4745,
      "step": 26520
    },
    {
      "epoch": 1.7804436092748566,
      "grad_norm": 0.6674222350120544,
      "learning_rate": 7.486710255207118e-05,
      "loss": 2.4845,
      "step": 26530
    },
    {
      "epoch": 1.7811147276937016,
      "grad_norm": 0.740755021572113,
      "learning_rate": 7.479698270595693e-05,
      "loss": 2.4732,
      "step": 26540
    },
    {
      "epoch": 1.7817858461125464,
      "grad_norm": 0.7136472463607788,
      "learning_rate": 7.472687608965503e-05,
      "loss": 2.5007,
      "step": 26550
    },
    {
      "epoch": 1.7817858461125464,
      "eval_bleu": 21.14854667562688,
      "eval_gen_len": 29.001,
      "eval_loss": 2.9339046478271484,
      "eval_runtime": 65.1383,
      "eval_samples_per_second": 15.352,
      "eval_steps_per_second": 0.967,
      "step": 26550
    },
    {
      "epoch": 1.7824569645313915,
      "grad_norm": 0.7935888767242432,
      "learning_rate": 7.465678273996656e-05,
      "loss": 2.4981,
      "step": 26560
    },
    {
      "epoch": 1.7831280829502365,
      "grad_norm": 0.6753661036491394,
      "learning_rate": 7.458670269368555e-05,
      "loss": 2.4473,
      "step": 26570
    },
    {
      "epoch": 1.7837992013690815,
      "grad_norm": 0.7044055461883545,
      "learning_rate": 7.451663598759918e-05,
      "loss": 2.4744,
      "step": 26580
    },
    {
      "epoch": 1.7844703197879266,
      "grad_norm": 0.675402820110321,
      "learning_rate": 7.444658265848748e-05,
      "loss": 2.5016,
      "step": 26590
    },
    {
      "epoch": 1.7851414382067716,
      "grad_norm": 0.7294562458992004,
      "learning_rate": 7.437654274312358e-05,
      "loss": 2.4486,
      "step": 26600
    },
    {
      "epoch": 1.7851414382067716,
      "eval_bleu": 20.998048505793435,
      "eval_gen_len": 29.119,
      "eval_loss": 2.934734344482422,
      "eval_runtime": 67.8474,
      "eval_samples_per_second": 14.739,
      "eval_steps_per_second": 0.929,
      "step": 26600
    },
    {
      "epoch": 1.7858125566256167,
      "grad_norm": 0.6759945154190063,
      "learning_rate": 7.43065162782734e-05,
      "loss": 2.5032,
      "step": 26610
    },
    {
      "epoch": 1.7864836750444617,
      "grad_norm": 0.6390016674995422,
      "learning_rate": 7.423650330069607e-05,
      "loss": 2.4423,
      "step": 26620
    },
    {
      "epoch": 1.7871547934633067,
      "grad_norm": 0.7333667874336243,
      "learning_rate": 7.416650384714335e-05,
      "loss": 2.4832,
      "step": 26630
    },
    {
      "epoch": 1.7878259118821516,
      "grad_norm": 0.7003100514411926,
      "learning_rate": 7.409651795436011e-05,
      "loss": 2.4892,
      "step": 26640
    },
    {
      "epoch": 1.7884970303009966,
      "grad_norm": 0.6405361890792847,
      "learning_rate": 7.4026545659084e-05,
      "loss": 2.5098,
      "step": 26650
    },
    {
      "epoch": 1.7884970303009966,
      "eval_bleu": 21.217845793788122,
      "eval_gen_len": 28.893,
      "eval_loss": 2.9310476779937744,
      "eval_runtime": 64.4753,
      "eval_samples_per_second": 15.51,
      "eval_steps_per_second": 0.977,
      "step": 26650
    },
    {
      "epoch": 1.7891681487198416,
      "grad_norm": 0.6328108310699463,
      "learning_rate": 7.39565869980455e-05,
      "loss": 2.4689,
      "step": 26660
    },
    {
      "epoch": 1.7898392671386865,
      "grad_norm": 0.7507703900337219,
      "learning_rate": 7.388664200796809e-05,
      "loss": 2.4785,
      "step": 26670
    },
    {
      "epoch": 1.7905103855575315,
      "grad_norm": 0.694450318813324,
      "learning_rate": 7.381671072556789e-05,
      "loss": 2.4985,
      "step": 26680
    },
    {
      "epoch": 1.7911815039763765,
      "grad_norm": 0.6693331599235535,
      "learning_rate": 7.374679318755398e-05,
      "loss": 2.4725,
      "step": 26690
    },
    {
      "epoch": 1.7918526223952216,
      "grad_norm": 0.7212451100349426,
      "learning_rate": 7.367688943062807e-05,
      "loss": 2.5131,
      "step": 26700
    },
    {
      "epoch": 1.7918526223952216,
      "eval_bleu": 21.58168413935102,
      "eval_gen_len": 28.888,
      "eval_loss": 2.928792953491211,
      "eval_runtime": 64.0227,
      "eval_samples_per_second": 15.619,
      "eval_steps_per_second": 0.984,
      "step": 26700
    },
    {
      "epoch": 1.7925237408140666,
      "grad_norm": 0.6973280310630798,
      "learning_rate": 7.36069994914848e-05,
      "loss": 2.4664,
      "step": 26710
    },
    {
      "epoch": 1.7931948592329117,
      "grad_norm": 0.7695528864860535,
      "learning_rate": 7.353712340681139e-05,
      "loss": 2.4454,
      "step": 26720
    },
    {
      "epoch": 1.7938659776517567,
      "grad_norm": 0.7119755744934082,
      "learning_rate": 7.346726121328796e-05,
      "loss": 2.4604,
      "step": 26730
    },
    {
      "epoch": 1.7945370960706017,
      "grad_norm": 0.6234990358352661,
      "learning_rate": 7.339741294758719e-05,
      "loss": 2.5178,
      "step": 26740
    },
    {
      "epoch": 1.7952082144894468,
      "grad_norm": 0.6950475573539734,
      "learning_rate": 7.332757864637456e-05,
      "loss": 2.4645,
      "step": 26750
    },
    {
      "epoch": 1.7952082144894468,
      "eval_bleu": 21.376566191843462,
      "eval_gen_len": 28.832,
      "eval_loss": 2.931373119354248,
      "eval_runtime": 63.948,
      "eval_samples_per_second": 15.638,
      "eval_steps_per_second": 0.985,
      "step": 26750
    },
    {
      "epoch": 1.7958793329082918,
      "grad_norm": 0.7477033138275146,
      "learning_rate": 7.325775834630808e-05,
      "loss": 2.4466,
      "step": 26760
    },
    {
      "epoch": 1.7965504513271366,
      "grad_norm": 0.7289373874664307,
      "learning_rate": 7.318795208403862e-05,
      "loss": 2.4977,
      "step": 26770
    },
    {
      "epoch": 1.7972215697459817,
      "grad_norm": 0.7414723038673401,
      "learning_rate": 7.311815989620945e-05,
      "loss": 2.4583,
      "step": 26780
    },
    {
      "epoch": 1.7978926881648267,
      "grad_norm": 0.7210781574249268,
      "learning_rate": 7.304838181945665e-05,
      "loss": 2.446,
      "step": 26790
    },
    {
      "epoch": 1.7985638065836715,
      "grad_norm": 0.6541656851768494,
      "learning_rate": 7.297861789040871e-05,
      "loss": 2.4969,
      "step": 26800
    },
    {
      "epoch": 1.7985638065836715,
      "eval_bleu": 21.190179326598457,
      "eval_gen_len": 28.814,
      "eval_loss": 2.9323198795318604,
      "eval_runtime": 63.9677,
      "eval_samples_per_second": 15.633,
      "eval_steps_per_second": 0.985,
      "step": 26800
    },
    {
      "epoch": 1.7992349250025166,
      "grad_norm": 0.6875797510147095,
      "learning_rate": 7.290886814568689e-05,
      "loss": 2.4544,
      "step": 26810
    },
    {
      "epoch": 1.7999060434213616,
      "grad_norm": 0.7024366855621338,
      "learning_rate": 7.283913262190484e-05,
      "loss": 2.4587,
      "step": 26820
    },
    {
      "epoch": 1.8005771618402067,
      "grad_norm": 0.6261032819747925,
      "learning_rate": 7.276941135566884e-05,
      "loss": 2.4754,
      "step": 26830
    },
    {
      "epoch": 1.8012482802590517,
      "grad_norm": 0.6540015339851379,
      "learning_rate": 7.269970438357759e-05,
      "loss": 2.483,
      "step": 26840
    },
    {
      "epoch": 1.8019193986778967,
      "grad_norm": 0.7204115986824036,
      "learning_rate": 7.263001174222246e-05,
      "loss": 2.5327,
      "step": 26850
    },
    {
      "epoch": 1.8019193986778967,
      "eval_bleu": 21.139223426298887,
      "eval_gen_len": 28.763,
      "eval_loss": 2.933607816696167,
      "eval_runtime": 63.3955,
      "eval_samples_per_second": 15.774,
      "eval_steps_per_second": 0.994,
      "step": 26850
    },
    {
      "epoch": 1.8025905170967418,
      "grad_norm": 0.6725149154663086,
      "learning_rate": 7.256033346818707e-05,
      "loss": 2.4402,
      "step": 26860
    },
    {
      "epoch": 1.8032616355155868,
      "grad_norm": 0.688804566860199,
      "learning_rate": 7.249066959804772e-05,
      "loss": 2.4764,
      "step": 26870
    },
    {
      "epoch": 1.8039327539344319,
      "grad_norm": 0.7242034673690796,
      "learning_rate": 7.242102016837296e-05,
      "loss": 2.5218,
      "step": 26880
    },
    {
      "epoch": 1.8046038723532767,
      "grad_norm": 0.6745007038116455,
      "learning_rate": 7.23513852157239e-05,
      "loss": 2.5075,
      "step": 26890
    },
    {
      "epoch": 1.8052749907721217,
      "grad_norm": 0.6930586695671082,
      "learning_rate": 7.228176477665396e-05,
      "loss": 2.4541,
      "step": 26900
    },
    {
      "epoch": 1.8052749907721217,
      "eval_bleu": 21.092383955654263,
      "eval_gen_len": 28.855,
      "eval_loss": 2.936347007751465,
      "eval_runtime": 63.4442,
      "eval_samples_per_second": 15.762,
      "eval_steps_per_second": 0.993,
      "step": 26900
    },
    {
      "epoch": 1.8059461091909668,
      "grad_norm": 0.7731930613517761,
      "learning_rate": 7.221215888770901e-05,
      "loss": 2.4832,
      "step": 26910
    },
    {
      "epoch": 1.8066172276098118,
      "grad_norm": 0.7247707843780518,
      "learning_rate": 7.214256758542719e-05,
      "loss": 2.4341,
      "step": 26920
    },
    {
      "epoch": 1.8072883460286566,
      "grad_norm": 0.6511143445968628,
      "learning_rate": 7.207299090633912e-05,
      "loss": 2.5147,
      "step": 26930
    },
    {
      "epoch": 1.8079594644475017,
      "grad_norm": 0.6654123067855835,
      "learning_rate": 7.200342888696764e-05,
      "loss": 2.4682,
      "step": 26940
    },
    {
      "epoch": 1.8086305828663467,
      "grad_norm": 0.6474376320838928,
      "learning_rate": 7.193388156382788e-05,
      "loss": 2.4779,
      "step": 26950
    },
    {
      "epoch": 1.8086305828663467,
      "eval_bleu": 21.120363951834015,
      "eval_gen_len": 28.758,
      "eval_loss": 2.9353671073913574,
      "eval_runtime": 63.9073,
      "eval_samples_per_second": 15.648,
      "eval_steps_per_second": 0.986,
      "step": 26950
    },
    {
      "epoch": 1.8093017012851917,
      "grad_norm": 0.6786275506019592,
      "learning_rate": 7.186434897342733e-05,
      "loss": 2.4456,
      "step": 26960
    },
    {
      "epoch": 1.8099728197040368,
      "grad_norm": 0.7131808400154114,
      "learning_rate": 7.179483115226569e-05,
      "loss": 2.4569,
      "step": 26970
    },
    {
      "epoch": 1.8106439381228818,
      "grad_norm": 0.6681491136550903,
      "learning_rate": 7.172532813683497e-05,
      "loss": 2.4854,
      "step": 26980
    },
    {
      "epoch": 1.8113150565417269,
      "grad_norm": 0.6333208084106445,
      "learning_rate": 7.16558399636193e-05,
      "loss": 2.4029,
      "step": 26990
    },
    {
      "epoch": 1.811986174960572,
      "grad_norm": 0.6820492148399353,
      "learning_rate": 7.158636666909515e-05,
      "loss": 2.4567,
      "step": 27000
    },
    {
      "epoch": 1.811986174960572,
      "eval_bleu": 21.100303785312374,
      "eval_gen_len": 28.819,
      "eval_loss": 2.9392738342285156,
      "eval_runtime": 63.7518,
      "eval_samples_per_second": 15.686,
      "eval_steps_per_second": 0.988,
      "step": 27000
    },
    {
      "epoch": 1.812657293379417,
      "grad_norm": 0.7307000160217285,
      "learning_rate": 7.15169082897311e-05,
      "loss": 2.4857,
      "step": 27010
    },
    {
      "epoch": 1.8133284117982618,
      "grad_norm": 0.7313342094421387,
      "learning_rate": 7.144746486198793e-05,
      "loss": 2.4819,
      "step": 27020
    },
    {
      "epoch": 1.8139995302171068,
      "grad_norm": 0.695830225944519,
      "learning_rate": 7.137803642231847e-05,
      "loss": 2.4857,
      "step": 27030
    },
    {
      "epoch": 1.8146706486359518,
      "grad_norm": 0.682339608669281,
      "learning_rate": 7.13086230071679e-05,
      "loss": 2.4256,
      "step": 27040
    },
    {
      "epoch": 1.8153417670547967,
      "grad_norm": 0.6962774991989136,
      "learning_rate": 7.12392246529733e-05,
      "loss": 2.5109,
      "step": 27050
    },
    {
      "epoch": 1.8153417670547967,
      "eval_bleu": 21.60860937829358,
      "eval_gen_len": 28.897,
      "eval_loss": 2.9320785999298096,
      "eval_runtime": 64.1068,
      "eval_samples_per_second": 15.599,
      "eval_steps_per_second": 0.983,
      "step": 27050
    },
    {
      "epoch": 1.8160128854736417,
      "grad_norm": 0.9409387111663818,
      "learning_rate": 7.116984139616395e-05,
      "loss": 2.48,
      "step": 27060
    },
    {
      "epoch": 1.8166840038924867,
      "grad_norm": 0.649280309677124,
      "learning_rate": 7.110047327316116e-05,
      "loss": 2.493,
      "step": 27070
    },
    {
      "epoch": 1.8173551223113318,
      "grad_norm": 0.7209627032279968,
      "learning_rate": 7.103112032037837e-05,
      "loss": 2.4713,
      "step": 27080
    },
    {
      "epoch": 1.8180262407301768,
      "grad_norm": 0.6328372955322266,
      "learning_rate": 7.096178257422095e-05,
      "loss": 2.4479,
      "step": 27090
    },
    {
      "epoch": 1.8186973591490219,
      "grad_norm": 0.7132936120033264,
      "learning_rate": 7.089246007108638e-05,
      "loss": 2.4175,
      "step": 27100
    },
    {
      "epoch": 1.8186973591490219,
      "eval_bleu": 21.532237939786295,
      "eval_gen_len": 28.867,
      "eval_loss": 2.932431221008301,
      "eval_runtime": 63.7247,
      "eval_samples_per_second": 15.692,
      "eval_steps_per_second": 0.989,
      "step": 27100
    },
    {
      "epoch": 1.819368477567867,
      "grad_norm": 0.6806367635726929,
      "learning_rate": 7.082315284736407e-05,
      "loss": 2.4845,
      "step": 27110
    },
    {
      "epoch": 1.820039595986712,
      "grad_norm": 0.7129708528518677,
      "learning_rate": 7.075386093943548e-05,
      "loss": 2.4555,
      "step": 27120
    },
    {
      "epoch": 1.820710714405557,
      "grad_norm": 0.7479646801948547,
      "learning_rate": 7.068458438367396e-05,
      "loss": 2.4578,
      "step": 27130
    },
    {
      "epoch": 1.821381832824402,
      "grad_norm": 0.6954881548881531,
      "learning_rate": 7.061532321644486e-05,
      "loss": 2.4739,
      "step": 27140
    },
    {
      "epoch": 1.8220529512432468,
      "grad_norm": 0.7184797525405884,
      "learning_rate": 7.054607747410535e-05,
      "loss": 2.4693,
      "step": 27150
    },
    {
      "epoch": 1.8220529512432468,
      "eval_bleu": 21.22045973429492,
      "eval_gen_len": 28.914,
      "eval_loss": 2.9339568614959717,
      "eval_runtime": 64.2537,
      "eval_samples_per_second": 15.563,
      "eval_steps_per_second": 0.98,
      "step": 27150
    },
    {
      "epoch": 1.8227240696620919,
      "grad_norm": 0.7196685671806335,
      "learning_rate": 7.047684719300468e-05,
      "loss": 2.4698,
      "step": 27160
    },
    {
      "epoch": 1.823395188080937,
      "grad_norm": 0.7236988544464111,
      "learning_rate": 7.040763240948381e-05,
      "loss": 2.4607,
      "step": 27170
    },
    {
      "epoch": 1.8240663064997817,
      "grad_norm": 0.673904299736023,
      "learning_rate": 7.033843315987567e-05,
      "loss": 2.4671,
      "step": 27180
    },
    {
      "epoch": 1.8247374249186268,
      "grad_norm": 0.663750410079956,
      "learning_rate": 7.026924948050497e-05,
      "loss": 2.4451,
      "step": 27190
    },
    {
      "epoch": 1.8254085433374718,
      "grad_norm": 0.7014834880828857,
      "learning_rate": 7.020008140768831e-05,
      "loss": 2.4583,
      "step": 27200
    },
    {
      "epoch": 1.8254085433374718,
      "eval_bleu": 20.998349092336348,
      "eval_gen_len": 28.753,
      "eval_loss": 2.937772274017334,
      "eval_runtime": 64.0542,
      "eval_samples_per_second": 15.612,
      "eval_steps_per_second": 0.984,
      "step": 27200
    },
    {
      "epoch": 1.8260796617563169,
      "grad_norm": 0.6360835433006287,
      "learning_rate": 7.013092897773406e-05,
      "loss": 2.4307,
      "step": 27210
    },
    {
      "epoch": 1.826750780175162,
      "grad_norm": 0.6650236248970032,
      "learning_rate": 7.006179222694236e-05,
      "loss": 2.492,
      "step": 27220
    },
    {
      "epoch": 1.827421898594007,
      "grad_norm": 0.70100337266922,
      "learning_rate": 6.999267119160515e-05,
      "loss": 2.491,
      "step": 27230
    },
    {
      "epoch": 1.828093017012852,
      "grad_norm": 0.7041260600090027,
      "learning_rate": 6.992356590800617e-05,
      "loss": 2.46,
      "step": 27240
    },
    {
      "epoch": 1.828764135431697,
      "grad_norm": 0.6810706257820129,
      "learning_rate": 6.985447641242078e-05,
      "loss": 2.4824,
      "step": 27250
    },
    {
      "epoch": 1.828764135431697,
      "eval_bleu": 21.20604402431163,
      "eval_gen_len": 28.874,
      "eval_loss": 2.9332807064056396,
      "eval_runtime": 63.9316,
      "eval_samples_per_second": 15.642,
      "eval_steps_per_second": 0.985,
      "step": 27250
    },
    {
      "epoch": 1.829435253850542,
      "grad_norm": 0.6885268092155457,
      "learning_rate": 6.978540274111609e-05,
      "loss": 2.4652,
      "step": 27260
    },
    {
      "epoch": 1.8301063722693869,
      "grad_norm": 0.6862356066703796,
      "learning_rate": 6.9716344930351e-05,
      "loss": 2.464,
      "step": 27270
    },
    {
      "epoch": 1.830777490688232,
      "grad_norm": 0.6512256860733032,
      "learning_rate": 6.96473030163759e-05,
      "loss": 2.4193,
      "step": 27280
    },
    {
      "epoch": 1.831448609107077,
      "grad_norm": 0.6856368184089661,
      "learning_rate": 6.957827703543304e-05,
      "loss": 2.452,
      "step": 27290
    },
    {
      "epoch": 1.832119727525922,
      "grad_norm": 0.7164016366004944,
      "learning_rate": 6.950926702375612e-05,
      "loss": 2.5046,
      "step": 27300
    },
    {
      "epoch": 1.832119727525922,
      "eval_bleu": 21.325827984715215,
      "eval_gen_len": 28.773,
      "eval_loss": 2.9305646419525146,
      "eval_runtime": 63.811,
      "eval_samples_per_second": 15.671,
      "eval_steps_per_second": 0.987,
      "step": 27300
    },
    {
      "epoch": 1.8327908459447668,
      "grad_norm": 0.6668058633804321,
      "learning_rate": 6.944027301757064e-05,
      "loss": 2.4643,
      "step": 27310
    },
    {
      "epoch": 1.8334619643636119,
      "grad_norm": 0.6755356192588806,
      "learning_rate": 6.937129505309354e-05,
      "loss": 2.4307,
      "step": 27320
    },
    {
      "epoch": 1.834133082782457,
      "grad_norm": 0.7468252778053284,
      "learning_rate": 6.930233316653343e-05,
      "loss": 2.4627,
      "step": 27330
    },
    {
      "epoch": 1.834804201201302,
      "grad_norm": 0.7273635268211365,
      "learning_rate": 6.92333873940904e-05,
      "loss": 2.4707,
      "step": 27340
    },
    {
      "epoch": 1.835475319620147,
      "grad_norm": 0.713455080986023,
      "learning_rate": 6.916445777195621e-05,
      "loss": 2.5042,
      "step": 27350
    },
    {
      "epoch": 1.835475319620147,
      "eval_bleu": 21.745138081485184,
      "eval_gen_len": 28.907,
      "eval_loss": 2.9281818866729736,
      "eval_runtime": 64.3121,
      "eval_samples_per_second": 15.549,
      "eval_steps_per_second": 0.98,
      "step": 27350
    },
    {
      "epoch": 1.836146438038992,
      "grad_norm": 0.7391186952590942,
      "learning_rate": 6.909554433631402e-05,
      "loss": 2.4725,
      "step": 27360
    },
    {
      "epoch": 1.836817556457837,
      "grad_norm": 0.6878005862236023,
      "learning_rate": 6.902664712333857e-05,
      "loss": 2.4978,
      "step": 27370
    },
    {
      "epoch": 1.837488674876682,
      "grad_norm": 0.6932539343833923,
      "learning_rate": 6.8957766169196e-05,
      "loss": 2.4771,
      "step": 27380
    },
    {
      "epoch": 1.8381597932955271,
      "grad_norm": 0.6761859655380249,
      "learning_rate": 6.8888901510044e-05,
      "loss": 2.4872,
      "step": 27390
    },
    {
      "epoch": 1.838830911714372,
      "grad_norm": 0.6994473338127136,
      "learning_rate": 6.88200531820317e-05,
      "loss": 2.4699,
      "step": 27400
    },
    {
      "epoch": 1.838830911714372,
      "eval_bleu": 21.116583262904008,
      "eval_gen_len": 28.877,
      "eval_loss": 2.9323813915252686,
      "eval_runtime": 64.57,
      "eval_samples_per_second": 15.487,
      "eval_steps_per_second": 0.976,
      "step": 27400
    },
    {
      "epoch": 1.839502030133217,
      "grad_norm": 0.6955807209014893,
      "learning_rate": 6.875122122129963e-05,
      "loss": 2.5075,
      "step": 27410
    },
    {
      "epoch": 1.840173148552062,
      "grad_norm": 0.6854736804962158,
      "learning_rate": 6.868240566397964e-05,
      "loss": 2.4641,
      "step": 27420
    },
    {
      "epoch": 1.8408442669709069,
      "grad_norm": 0.7539514303207397,
      "learning_rate": 6.86136065461952e-05,
      "loss": 2.5087,
      "step": 27430
    },
    {
      "epoch": 1.841515385389752,
      "grad_norm": 0.6592575311660767,
      "learning_rate": 6.85448239040609e-05,
      "loss": 2.4529,
      "step": 27440
    },
    {
      "epoch": 1.842186503808597,
      "grad_norm": 0.6084111928939819,
      "learning_rate": 6.847605777368285e-05,
      "loss": 2.4763,
      "step": 27450
    },
    {
      "epoch": 1.842186503808597,
      "eval_bleu": 21.383480296393625,
      "eval_gen_len": 28.805,
      "eval_loss": 2.9306583404541016,
      "eval_runtime": 63.732,
      "eval_samples_per_second": 15.691,
      "eval_steps_per_second": 0.989,
      "step": 27450
    },
    {
      "epoch": 1.842857622227442,
      "grad_norm": 0.6945417523384094,
      "learning_rate": 6.840730819115838e-05,
      "loss": 2.4646,
      "step": 27460
    },
    {
      "epoch": 1.843528740646287,
      "grad_norm": 0.7432854175567627,
      "learning_rate": 6.833857519257628e-05,
      "loss": 2.4991,
      "step": 27470
    },
    {
      "epoch": 1.844199859065132,
      "grad_norm": 0.7385415434837341,
      "learning_rate": 6.826985881401644e-05,
      "loss": 2.5007,
      "step": 27480
    },
    {
      "epoch": 1.844870977483977,
      "grad_norm": 0.6922296285629272,
      "learning_rate": 6.82011590915502e-05,
      "loss": 2.494,
      "step": 27490
    },
    {
      "epoch": 1.8455420959028221,
      "grad_norm": 0.6625102758407593,
      "learning_rate": 6.813247606124003e-05,
      "loss": 2.4681,
      "step": 27500
    },
    {
      "epoch": 1.8455420959028221,
      "eval_bleu": 21.383117394188357,
      "eval_gen_len": 28.913,
      "eval_loss": 2.929466724395752,
      "eval_runtime": 64.3951,
      "eval_samples_per_second": 15.529,
      "eval_steps_per_second": 0.978,
      "step": 27500
    },
    {
      "epoch": 1.8462132143216672,
      "grad_norm": 0.7195459604263306,
      "learning_rate": 6.806380975913978e-05,
      "loss": 2.452,
      "step": 27510
    },
    {
      "epoch": 1.8468843327405122,
      "grad_norm": 0.6630353927612305,
      "learning_rate": 6.799516022129432e-05,
      "loss": 2.4748,
      "step": 27520
    },
    {
      "epoch": 1.847555451159357,
      "grad_norm": 0.6664546132087708,
      "learning_rate": 6.792652748373991e-05,
      "loss": 2.4702,
      "step": 27530
    },
    {
      "epoch": 1.848226569578202,
      "grad_norm": 0.6110401749610901,
      "learning_rate": 6.785791158250392e-05,
      "loss": 2.471,
      "step": 27540
    },
    {
      "epoch": 1.8488976879970471,
      "grad_norm": 0.7215887308120728,
      "learning_rate": 6.778931255360477e-05,
      "loss": 2.47,
      "step": 27550
    },
    {
      "epoch": 1.8488976879970471,
      "eval_bleu": 21.315496375684855,
      "eval_gen_len": 28.91,
      "eval_loss": 2.9363362789154053,
      "eval_runtime": 63.0397,
      "eval_samples_per_second": 15.863,
      "eval_steps_per_second": 0.999,
      "step": 27550
    },
    {
      "epoch": 1.849568806415892,
      "grad_norm": 0.6080816388130188,
      "learning_rate": 6.772073043305225e-05,
      "loss": 2.4517,
      "step": 27560
    },
    {
      "epoch": 1.850239924834737,
      "grad_norm": 0.6730591654777527,
      "learning_rate": 6.765216525684707e-05,
      "loss": 2.4274,
      "step": 27570
    },
    {
      "epoch": 1.850911043253582,
      "grad_norm": 0.7084345817565918,
      "learning_rate": 6.75836170609812e-05,
      "loss": 2.4899,
      "step": 27580
    },
    {
      "epoch": 1.851582161672427,
      "grad_norm": 0.6559385657310486,
      "learning_rate": 6.751508588143755e-05,
      "loss": 2.5143,
      "step": 27590
    },
    {
      "epoch": 1.852253280091272,
      "grad_norm": 0.7097812294960022,
      "learning_rate": 6.744657175419022e-05,
      "loss": 2.4683,
      "step": 27600
    },
    {
      "epoch": 1.852253280091272,
      "eval_bleu": 21.316166052839442,
      "eval_gen_len": 28.902,
      "eval_loss": 2.9310476779937744,
      "eval_runtime": 64.0715,
      "eval_samples_per_second": 15.608,
      "eval_steps_per_second": 0.983,
      "step": 27600
    },
    {
      "epoch": 1.8529243985101171,
      "grad_norm": 0.6488180160522461,
      "learning_rate": 6.737807471520427e-05,
      "loss": 2.4555,
      "step": 27610
    },
    {
      "epoch": 1.8535955169289622,
      "grad_norm": 0.6492964029312134,
      "learning_rate": 6.73095948004359e-05,
      "loss": 2.4618,
      "step": 27620
    },
    {
      "epoch": 1.8542666353478072,
      "grad_norm": 0.6962411999702454,
      "learning_rate": 6.724113204583218e-05,
      "loss": 2.4713,
      "step": 27630
    },
    {
      "epoch": 1.8549377537666523,
      "grad_norm": 0.6740655303001404,
      "learning_rate": 6.717268648733131e-05,
      "loss": 2.4441,
      "step": 27640
    },
    {
      "epoch": 1.855608872185497,
      "grad_norm": 0.6970049738883972,
      "learning_rate": 6.710425816086229e-05,
      "loss": 2.4895,
      "step": 27650
    },
    {
      "epoch": 1.855608872185497,
      "eval_bleu": 21.39690400397745,
      "eval_gen_len": 28.924,
      "eval_loss": 2.930394411087036,
      "eval_runtime": 64.2222,
      "eval_samples_per_second": 15.571,
      "eval_steps_per_second": 0.981,
      "step": 27650
    },
    {
      "epoch": 1.8562799906043421,
      "grad_norm": 0.7442229390144348,
      "learning_rate": 6.70358471023453e-05,
      "loss": 2.4557,
      "step": 27660
    },
    {
      "epoch": 1.8569511090231872,
      "grad_norm": 0.8277245759963989,
      "learning_rate": 6.696745334769127e-05,
      "loss": 2.5146,
      "step": 27670
    },
    {
      "epoch": 1.857622227442032,
      "grad_norm": 0.6572778820991516,
      "learning_rate": 6.689907693280215e-05,
      "loss": 2.4765,
      "step": 27680
    },
    {
      "epoch": 1.858293345860877,
      "grad_norm": 0.7040741443634033,
      "learning_rate": 6.683071789357068e-05,
      "loss": 2.466,
      "step": 27690
    },
    {
      "epoch": 1.858964464279722,
      "grad_norm": 0.6709333658218384,
      "learning_rate": 6.676237626588064e-05,
      "loss": 2.4464,
      "step": 27700
    },
    {
      "epoch": 1.858964464279722,
      "eval_bleu": 21.100316607030233,
      "eval_gen_len": 28.91,
      "eval_loss": 2.927959680557251,
      "eval_runtime": 64.0533,
      "eval_samples_per_second": 15.612,
      "eval_steps_per_second": 0.984,
      "step": 27700
    },
    {
      "epoch": 1.859635582698567,
      "grad_norm": 0.6321325302124023,
      "learning_rate": 6.669405208560653e-05,
      "loss": 2.4764,
      "step": 27710
    },
    {
      "epoch": 1.8603067011174121,
      "grad_norm": 0.7100211977958679,
      "learning_rate": 6.662574538861377e-05,
      "loss": 2.4908,
      "step": 27720
    },
    {
      "epoch": 1.8609778195362572,
      "grad_norm": 0.6715836524963379,
      "learning_rate": 6.655745621075852e-05,
      "loss": 2.4352,
      "step": 27730
    },
    {
      "epoch": 1.8616489379551022,
      "grad_norm": 0.7486264109611511,
      "learning_rate": 6.648918458788787e-05,
      "loss": 2.4689,
      "step": 27740
    },
    {
      "epoch": 1.8623200563739473,
      "grad_norm": 0.7044920921325684,
      "learning_rate": 6.642093055583956e-05,
      "loss": 2.4606,
      "step": 27750
    },
    {
      "epoch": 1.8623200563739473,
      "eval_bleu": 21.16922474331774,
      "eval_gen_len": 28.906,
      "eval_loss": 2.9320108890533447,
      "eval_runtime": 63.5796,
      "eval_samples_per_second": 15.728,
      "eval_steps_per_second": 0.991,
      "step": 27750
    },
    {
      "epoch": 1.8629911747927923,
      "grad_norm": 0.7359158396720886,
      "learning_rate": 6.635269415044221e-05,
      "loss": 2.5521,
      "step": 27760
    },
    {
      "epoch": 1.8636622932116373,
      "grad_norm": 0.6883350610733032,
      "learning_rate": 6.628447540751508e-05,
      "loss": 2.4507,
      "step": 27770
    },
    {
      "epoch": 1.8643334116304822,
      "grad_norm": 0.6486707329750061,
      "learning_rate": 6.621627436286828e-05,
      "loss": 2.4502,
      "step": 27780
    },
    {
      "epoch": 1.8650045300493272,
      "grad_norm": 0.6897543668746948,
      "learning_rate": 6.61480910523025e-05,
      "loss": 2.455,
      "step": 27790
    },
    {
      "epoch": 1.8656756484681722,
      "grad_norm": 0.6671929955482483,
      "learning_rate": 6.607992551160925e-05,
      "loss": 2.4935,
      "step": 27800
    },
    {
      "epoch": 1.8656756484681722,
      "eval_bleu": 21.300571642809235,
      "eval_gen_len": 28.86,
      "eval_loss": 2.9273037910461426,
      "eval_runtime": 63.5364,
      "eval_samples_per_second": 15.739,
      "eval_steps_per_second": 0.992,
      "step": 27800
    },
    {
      "epoch": 1.866346766887017,
      "grad_norm": 0.6596150994300842,
      "learning_rate": 6.601177777657055e-05,
      "loss": 2.4309,
      "step": 27810
    },
    {
      "epoch": 1.867017885305862,
      "grad_norm": 0.6632000207901001,
      "learning_rate": 6.594364788295929e-05,
      "loss": 2.4717,
      "step": 27820
    },
    {
      "epoch": 1.8676890037247071,
      "grad_norm": 0.7135553359985352,
      "learning_rate": 6.587553586653882e-05,
      "loss": 2.477,
      "step": 27830
    },
    {
      "epoch": 1.8683601221435522,
      "grad_norm": 0.669089138507843,
      "learning_rate": 6.580744176306313e-05,
      "loss": 2.5234,
      "step": 27840
    },
    {
      "epoch": 1.8690312405623972,
      "grad_norm": 0.6881637573242188,
      "learning_rate": 6.573936560827689e-05,
      "loss": 2.4996,
      "step": 27850
    },
    {
      "epoch": 1.8690312405623972,
      "eval_bleu": 21.068062874083857,
      "eval_gen_len": 28.801,
      "eval_loss": 2.9312288761138916,
      "eval_runtime": 64.3754,
      "eval_samples_per_second": 15.534,
      "eval_steps_per_second": 0.979,
      "step": 27850
    },
    {
      "epoch": 1.8697023589812423,
      "grad_norm": 0.6612346172332764,
      "learning_rate": 6.567130743791523e-05,
      "loss": 2.5009,
      "step": 27860
    },
    {
      "epoch": 1.8703734774000873,
      "grad_norm": 0.829195499420166,
      "learning_rate": 6.560326728770398e-05,
      "loss": 2.4943,
      "step": 27870
    },
    {
      "epoch": 1.8710445958189323,
      "grad_norm": 0.7019984126091003,
      "learning_rate": 6.553524519335938e-05,
      "loss": 2.4946,
      "step": 27880
    },
    {
      "epoch": 1.8717157142377774,
      "grad_norm": 0.5824173092842102,
      "learning_rate": 6.54672411905883e-05,
      "loss": 2.4217,
      "step": 27890
    },
    {
      "epoch": 1.8723868326566224,
      "grad_norm": 0.698588490486145,
      "learning_rate": 6.539925531508798e-05,
      "loss": 2.4741,
      "step": 27900
    },
    {
      "epoch": 1.8723868326566224,
      "eval_bleu": 21.224751461504155,
      "eval_gen_len": 29.101,
      "eval_loss": 2.9298877716064453,
      "eval_runtime": 66.4804,
      "eval_samples_per_second": 15.042,
      "eval_steps_per_second": 0.948,
      "step": 27900
    },
    {
      "epoch": 1.8730579510754672,
      "grad_norm": 0.6748378276824951,
      "learning_rate": 6.533128760254633e-05,
      "loss": 2.4452,
      "step": 27910
    },
    {
      "epoch": 1.8737290694943123,
      "grad_norm": 0.7402843832969666,
      "learning_rate": 6.52633380886415e-05,
      "loss": 2.5089,
      "step": 27920
    },
    {
      "epoch": 1.8744001879131573,
      "grad_norm": 0.6785075664520264,
      "learning_rate": 6.519540680904232e-05,
      "loss": 2.4474,
      "step": 27930
    },
    {
      "epoch": 1.8750713063320021,
      "grad_norm": 0.6856110692024231,
      "learning_rate": 6.51274937994079e-05,
      "loss": 2.4916,
      "step": 27940
    },
    {
      "epoch": 1.8757424247508472,
      "grad_norm": 0.6997240781784058,
      "learning_rate": 6.505959909538779e-05,
      "loss": 2.459,
      "step": 27950
    },
    {
      "epoch": 1.8757424247508472,
      "eval_bleu": 21.552926226284438,
      "eval_gen_len": 28.904,
      "eval_loss": 2.9252002239227295,
      "eval_runtime": 63.709,
      "eval_samples_per_second": 15.696,
      "eval_steps_per_second": 0.989,
      "step": 27950
    },
    {
      "epoch": 1.8764135431696922,
      "grad_norm": 0.7372959852218628,
      "learning_rate": 6.499172273262188e-05,
      "loss": 2.5241,
      "step": 27960
    },
    {
      "epoch": 1.8770846615885373,
      "grad_norm": 0.6604711413383484,
      "learning_rate": 6.49238647467406e-05,
      "loss": 2.4391,
      "step": 27970
    },
    {
      "epoch": 1.8777557800073823,
      "grad_norm": 0.626518964767456,
      "learning_rate": 6.485602517336455e-05,
      "loss": 2.4449,
      "step": 27980
    },
    {
      "epoch": 1.8784268984262273,
      "grad_norm": 0.7119892239570618,
      "learning_rate": 6.478820404810476e-05,
      "loss": 2.4848,
      "step": 27990
    },
    {
      "epoch": 1.8790980168450724,
      "grad_norm": 0.7177548408508301,
      "learning_rate": 6.47204014065625e-05,
      "loss": 2.4913,
      "step": 28000
    },
    {
      "epoch": 1.8790980168450724,
      "eval_bleu": 21.377474487563692,
      "eval_gen_len": 28.956,
      "eval_loss": 2.926943778991699,
      "eval_runtime": 65.0748,
      "eval_samples_per_second": 15.367,
      "eval_steps_per_second": 0.968,
      "step": 28000
    },
    {
      "epoch": 1.8797691352639174,
      "grad_norm": 0.6520158052444458,
      "learning_rate": 6.46526172843295e-05,
      "loss": 2.4343,
      "step": 28010
    },
    {
      "epoch": 1.8804402536827625,
      "grad_norm": 0.7549976706504822,
      "learning_rate": 6.458485171698756e-05,
      "loss": 2.5134,
      "step": 28020
    },
    {
      "epoch": 1.8811113721016073,
      "grad_norm": 0.6772090196609497,
      "learning_rate": 6.451710474010889e-05,
      "loss": 2.4845,
      "step": 28030
    },
    {
      "epoch": 1.8817824905204523,
      "grad_norm": 0.6597155332565308,
      "learning_rate": 6.444937638925584e-05,
      "loss": 2.4809,
      "step": 28040
    },
    {
      "epoch": 1.8824536089392974,
      "grad_norm": 0.7225301265716553,
      "learning_rate": 6.438166669998112e-05,
      "loss": 2.4618,
      "step": 28050
    },
    {
      "epoch": 1.8824536089392974,
      "eval_bleu": 21.148087501014402,
      "eval_gen_len": 28.712,
      "eval_loss": 2.9307057857513428,
      "eval_runtime": 63.0062,
      "eval_samples_per_second": 15.871,
      "eval_steps_per_second": 1.0,
      "step": 28050
    },
    {
      "epoch": 1.8831247273581422,
      "grad_norm": 0.7174270153045654,
      "learning_rate": 6.431397570782747e-05,
      "loss": 2.4282,
      "step": 28060
    },
    {
      "epoch": 1.8837958457769872,
      "grad_norm": 0.7162426710128784,
      "learning_rate": 6.424630344832796e-05,
      "loss": 2.479,
      "step": 28070
    },
    {
      "epoch": 1.8844669641958323,
      "grad_norm": 0.726667582988739,
      "learning_rate": 6.417864995700569e-05,
      "loss": 2.4462,
      "step": 28080
    },
    {
      "epoch": 1.8851380826146773,
      "grad_norm": 0.6768860220909119,
      "learning_rate": 6.411101526937411e-05,
      "loss": 2.4338,
      "step": 28090
    },
    {
      "epoch": 1.8858092010335223,
      "grad_norm": 0.6095996499061584,
      "learning_rate": 6.404339942093658e-05,
      "loss": 2.4701,
      "step": 28100
    },
    {
      "epoch": 1.8858092010335223,
      "eval_bleu": 21.51245804854933,
      "eval_gen_len": 28.954,
      "eval_loss": 2.925835132598877,
      "eval_runtime": 63.7769,
      "eval_samples_per_second": 15.68,
      "eval_steps_per_second": 0.988,
      "step": 28100
    },
    {
      "epoch": 1.8864803194523674,
      "grad_norm": 0.7005290985107422,
      "learning_rate": 6.397580244718671e-05,
      "loss": 2.4396,
      "step": 28110
    },
    {
      "epoch": 1.8871514378712124,
      "grad_norm": 0.721383273601532,
      "learning_rate": 6.390822438360816e-05,
      "loss": 2.4311,
      "step": 28120
    },
    {
      "epoch": 1.8878225562900575,
      "grad_norm": 0.7173702120780945,
      "learning_rate": 6.384066526567458e-05,
      "loss": 2.4987,
      "step": 28130
    },
    {
      "epoch": 1.8884936747089025,
      "grad_norm": 0.733305037021637,
      "learning_rate": 6.37731251288499e-05,
      "loss": 2.4635,
      "step": 28140
    },
    {
      "epoch": 1.8891647931277475,
      "grad_norm": 0.6660200953483582,
      "learning_rate": 6.370560400858783e-05,
      "loss": 2.4776,
      "step": 28150
    },
    {
      "epoch": 1.8891647931277475,
      "eval_bleu": 21.391307832731403,
      "eval_gen_len": 28.94,
      "eval_loss": 2.925762176513672,
      "eval_runtime": 64.1059,
      "eval_samples_per_second": 15.599,
      "eval_steps_per_second": 0.983,
      "step": 28150
    },
    {
      "epoch": 1.8898359115465924,
      "grad_norm": 0.6665467619895935,
      "learning_rate": 6.363810194033229e-05,
      "loss": 2.5003,
      "step": 28160
    },
    {
      "epoch": 1.8905070299654374,
      "grad_norm": 0.6596987247467041,
      "learning_rate": 6.357061895951703e-05,
      "loss": 2.5106,
      "step": 28170
    },
    {
      "epoch": 1.8911781483842824,
      "grad_norm": 0.7005465626716614,
      "learning_rate": 6.350315510156597e-05,
      "loss": 2.4863,
      "step": 28180
    },
    {
      "epoch": 1.8918492668031273,
      "grad_norm": 0.6458737254142761,
      "learning_rate": 6.343571040189282e-05,
      "loss": 2.4561,
      "step": 28190
    },
    {
      "epoch": 1.8925203852219723,
      "grad_norm": 0.6786613464355469,
      "learning_rate": 6.336828489590135e-05,
      "loss": 2.4629,
      "step": 28200
    },
    {
      "epoch": 1.8925203852219723,
      "eval_bleu": 21.372546044804537,
      "eval_gen_len": 28.937,
      "eval_loss": 2.927931308746338,
      "eval_runtime": 64.5935,
      "eval_samples_per_second": 15.481,
      "eval_steps_per_second": 0.975,
      "step": 28200
    },
    {
      "epoch": 1.8931915036408173,
      "grad_norm": 0.7018064260482788,
      "learning_rate": 6.330087861898516e-05,
      "loss": 2.4614,
      "step": 28210
    },
    {
      "epoch": 1.8938626220596624,
      "grad_norm": 0.6726198792457581,
      "learning_rate": 6.323349160652789e-05,
      "loss": 2.495,
      "step": 28220
    },
    {
      "epoch": 1.8945337404785074,
      "grad_norm": 0.6693222522735596,
      "learning_rate": 6.316612389390288e-05,
      "loss": 2.4867,
      "step": 28230
    },
    {
      "epoch": 1.8952048588973525,
      "grad_norm": 0.6449986100196838,
      "learning_rate": 6.309877551647355e-05,
      "loss": 2.4684,
      "step": 28240
    },
    {
      "epoch": 1.8958759773161975,
      "grad_norm": 0.6563401222229004,
      "learning_rate": 6.303144650959299e-05,
      "loss": 2.5049,
      "step": 28250
    },
    {
      "epoch": 1.8958759773161975,
      "eval_bleu": 21.234803907303398,
      "eval_gen_len": 28.918,
      "eval_loss": 2.934704065322876,
      "eval_runtime": 64.1125,
      "eval_samples_per_second": 15.598,
      "eval_steps_per_second": 0.983,
      "step": 28250
    },
    {
      "epoch": 1.8965470957350425,
      "grad_norm": 0.6423114538192749,
      "learning_rate": 6.296413690860422e-05,
      "loss": 2.4568,
      "step": 28260
    },
    {
      "epoch": 1.8972182141538876,
      "grad_norm": 0.6690889000892639,
      "learning_rate": 6.289684674884002e-05,
      "loss": 2.4555,
      "step": 28270
    },
    {
      "epoch": 1.8978893325727326,
      "grad_norm": 0.6261641979217529,
      "learning_rate": 6.282957606562306e-05,
      "loss": 2.4532,
      "step": 28280
    },
    {
      "epoch": 1.8985604509915774,
      "grad_norm": 0.67451012134552,
      "learning_rate": 6.276232489426566e-05,
      "loss": 2.4553,
      "step": 28290
    },
    {
      "epoch": 1.8992315694104225,
      "grad_norm": 0.6089219450950623,
      "learning_rate": 6.269509327007e-05,
      "loss": 2.4507,
      "step": 28300
    },
    {
      "epoch": 1.8992315694104225,
      "eval_bleu": 21.222306880825492,
      "eval_gen_len": 28.918,
      "eval_loss": 2.9312021732330322,
      "eval_runtime": 64.0861,
      "eval_samples_per_second": 15.604,
      "eval_steps_per_second": 0.983,
      "step": 28300
    },
    {
      "epoch": 1.8999026878292675,
      "grad_norm": 0.7109554409980774,
      "learning_rate": 6.26278812283279e-05,
      "loss": 2.4575,
      "step": 28310
    },
    {
      "epoch": 1.9005738062481123,
      "grad_norm": 0.6625460982322693,
      "learning_rate": 6.2560688804321e-05,
      "loss": 2.5054,
      "step": 28320
    },
    {
      "epoch": 1.9012449246669574,
      "grad_norm": 0.7337138056755066,
      "learning_rate": 6.249351603332061e-05,
      "loss": 2.4491,
      "step": 28330
    },
    {
      "epoch": 1.9019160430858024,
      "grad_norm": 0.6561562418937683,
      "learning_rate": 6.242636295058768e-05,
      "loss": 2.4589,
      "step": 28340
    },
    {
      "epoch": 1.9025871615046475,
      "grad_norm": 0.6962432265281677,
      "learning_rate": 6.235922959137285e-05,
      "loss": 2.475,
      "step": 28350
    },
    {
      "epoch": 1.9025871615046475,
      "eval_bleu": 21.183320147953683,
      "eval_gen_len": 28.939,
      "eval_loss": 2.930231809616089,
      "eval_runtime": 64.4607,
      "eval_samples_per_second": 15.513,
      "eval_steps_per_second": 0.977,
      "step": 28350
    },
    {
      "epoch": 1.9032582799234925,
      "grad_norm": 0.6024413704872131,
      "learning_rate": 6.229211599091646e-05,
      "loss": 2.4641,
      "step": 28360
    },
    {
      "epoch": 1.9039293983423375,
      "grad_norm": 0.6635923385620117,
      "learning_rate": 6.22250221844484e-05,
      "loss": 2.4438,
      "step": 28370
    },
    {
      "epoch": 1.9046005167611826,
      "grad_norm": 0.7047592401504517,
      "learning_rate": 6.215794820718823e-05,
      "loss": 2.4868,
      "step": 28380
    },
    {
      "epoch": 1.9052716351800276,
      "grad_norm": 0.7292352318763733,
      "learning_rate": 6.209089409434501e-05,
      "loss": 2.4773,
      "step": 28390
    },
    {
      "epoch": 1.9059427535988727,
      "grad_norm": 0.7036888003349304,
      "learning_rate": 6.202385988111751e-05,
      "loss": 2.4374,
      "step": 28400
    },
    {
      "epoch": 1.9059427535988727,
      "eval_bleu": 21.085416005829817,
      "eval_gen_len": 28.904,
      "eval_loss": 2.930750846862793,
      "eval_runtime": 64.5087,
      "eval_samples_per_second": 15.502,
      "eval_steps_per_second": 0.977,
      "step": 28400
    },
    {
      "epoch": 1.9066138720177175,
      "grad_norm": 0.7101089954376221,
      "learning_rate": 6.195684560269395e-05,
      "loss": 2.4616,
      "step": 28410
    },
    {
      "epoch": 1.9072849904365625,
      "grad_norm": 0.7283008694648743,
      "learning_rate": 6.18898512942521e-05,
      "loss": 2.4818,
      "step": 28420
    },
    {
      "epoch": 1.9079561088554076,
      "grad_norm": 0.6995818018913269,
      "learning_rate": 6.182287699095928e-05,
      "loss": 2.4954,
      "step": 28430
    },
    {
      "epoch": 1.9086272272742524,
      "grad_norm": 0.7073152661323547,
      "learning_rate": 6.175592272797224e-05,
      "loss": 2.5014,
      "step": 28440
    },
    {
      "epoch": 1.9092983456930974,
      "grad_norm": 0.7039936184883118,
      "learning_rate": 6.168898854043737e-05,
      "loss": 2.4357,
      "step": 28450
    },
    {
      "epoch": 1.9092983456930974,
      "eval_bleu": 21.07557862951354,
      "eval_gen_len": 28.926,
      "eval_loss": 2.9328768253326416,
      "eval_runtime": 64.1582,
      "eval_samples_per_second": 15.586,
      "eval_steps_per_second": 0.982,
      "step": 28450
    },
    {
      "epoch": 1.9099694641119425,
      "grad_norm": 0.677088737487793,
      "learning_rate": 6.16220744634903e-05,
      "loss": 2.4781,
      "step": 28460
    },
    {
      "epoch": 1.9106405825307875,
      "grad_norm": 0.6481784582138062,
      "learning_rate": 6.155518053225633e-05,
      "loss": 2.444,
      "step": 28470
    },
    {
      "epoch": 1.9113117009496325,
      "grad_norm": 0.7134476900100708,
      "learning_rate": 6.148830678184994e-05,
      "loss": 2.4802,
      "step": 28480
    },
    {
      "epoch": 1.9119828193684776,
      "grad_norm": 0.7038148641586304,
      "learning_rate": 6.142145324737525e-05,
      "loss": 2.4945,
      "step": 28490
    },
    {
      "epoch": 1.9126539377873226,
      "grad_norm": 0.6764240860939026,
      "learning_rate": 6.135461996392562e-05,
      "loss": 2.4667,
      "step": 28500
    },
    {
      "epoch": 1.9126539377873226,
      "eval_bleu": 20.945087240285957,
      "eval_gen_len": 28.831,
      "eval_loss": 2.9343862533569336,
      "eval_runtime": 63.0226,
      "eval_samples_per_second": 15.867,
      "eval_steps_per_second": 1.0,
      "step": 28500
    },
    {
      "epoch": 1.9133250562061677,
      "grad_norm": 0.6303516626358032,
      "learning_rate": 6.128780696658387e-05,
      "loss": 2.4941,
      "step": 28510
    },
    {
      "epoch": 1.9139961746250127,
      "grad_norm": 0.6705747842788696,
      "learning_rate": 6.122101429042204e-05,
      "loss": 2.4941,
      "step": 28520
    },
    {
      "epoch": 1.9146672930438577,
      "grad_norm": 0.7409944534301758,
      "learning_rate": 6.115424197050168e-05,
      "loss": 2.462,
      "step": 28530
    },
    {
      "epoch": 1.9153384114627026,
      "grad_norm": 0.6924105882644653,
      "learning_rate": 6.10874900418735e-05,
      "loss": 2.4413,
      "step": 28540
    },
    {
      "epoch": 1.9160095298815476,
      "grad_norm": 0.708736002445221,
      "learning_rate": 6.102075853957763e-05,
      "loss": 2.4807,
      "step": 28550
    },
    {
      "epoch": 1.9160095298815476,
      "eval_bleu": 21.24894920231926,
      "eval_gen_len": 28.992,
      "eval_loss": 2.9303908348083496,
      "eval_runtime": 64.019,
      "eval_samples_per_second": 15.62,
      "eval_steps_per_second": 0.984,
      "step": 28550
    },
    {
      "epoch": 1.9166806483003926,
      "grad_norm": 0.7025416493415833,
      "learning_rate": 6.095404749864337e-05,
      "loss": 2.4636,
      "step": 28560
    },
    {
      "epoch": 1.9173517667192375,
      "grad_norm": 0.6678074598312378,
      "learning_rate": 6.0887356954089356e-05,
      "loss": 2.5023,
      "step": 28570
    },
    {
      "epoch": 1.9180228851380825,
      "grad_norm": 0.7127639651298523,
      "learning_rate": 6.08206869409234e-05,
      "loss": 2.4741,
      "step": 28580
    },
    {
      "epoch": 1.9186940035569275,
      "grad_norm": 0.7479299902915955,
      "learning_rate": 6.075403749414261e-05,
      "loss": 2.5239,
      "step": 28590
    },
    {
      "epoch": 1.9193651219757726,
      "grad_norm": 0.7609955668449402,
      "learning_rate": 6.0687408648733244e-05,
      "loss": 2.4658,
      "step": 28600
    },
    {
      "epoch": 1.9193651219757726,
      "eval_bleu": 21.23798328024279,
      "eval_gen_len": 28.984,
      "eval_loss": 2.9288735389709473,
      "eval_runtime": 63.9756,
      "eval_samples_per_second": 15.631,
      "eval_steps_per_second": 0.985,
      "step": 28600
    },
    {
      "epoch": 1.9200362403946176,
      "grad_norm": 0.727409839630127,
      "learning_rate": 6.0620800439670775e-05,
      "loss": 2.5254,
      "step": 28610
    },
    {
      "epoch": 1.9207073588134627,
      "grad_norm": 0.6545154452323914,
      "learning_rate": 6.0554212901919784e-05,
      "loss": 2.4138,
      "step": 28620
    },
    {
      "epoch": 1.9213784772323077,
      "grad_norm": 0.7069727182388306,
      "learning_rate": 6.048764607043411e-05,
      "loss": 2.4868,
      "step": 28630
    },
    {
      "epoch": 1.9220495956511527,
      "grad_norm": 0.6565433740615845,
      "learning_rate": 6.042109998015662e-05,
      "loss": 2.4179,
      "step": 28640
    },
    {
      "epoch": 1.9227207140699978,
      "grad_norm": 0.6679753661155701,
      "learning_rate": 6.035457466601937e-05,
      "loss": 2.448,
      "step": 28650
    },
    {
      "epoch": 1.9227207140699978,
      "eval_bleu": 21.121145469917163,
      "eval_gen_len": 28.921,
      "eval_loss": 2.9291326999664307,
      "eval_runtime": 63.539,
      "eval_samples_per_second": 15.738,
      "eval_steps_per_second": 0.992,
      "step": 28650
    },
    {
      "epoch": 1.9233918324888426,
      "grad_norm": 0.7142819166183472,
      "learning_rate": 6.02880701629434e-05,
      "loss": 2.5095,
      "step": 28660
    },
    {
      "epoch": 1.9240629509076876,
      "grad_norm": 0.6821807026863098,
      "learning_rate": 6.022158650583898e-05,
      "loss": 2.4528,
      "step": 28670
    },
    {
      "epoch": 1.9247340693265327,
      "grad_norm": 0.6421986222267151,
      "learning_rate": 6.015512372960532e-05,
      "loss": 2.4525,
      "step": 28680
    },
    {
      "epoch": 1.9254051877453777,
      "grad_norm": 0.6550021171569824,
      "learning_rate": 6.0088681869130716e-05,
      "loss": 2.4983,
      "step": 28690
    },
    {
      "epoch": 1.9260763061642225,
      "grad_norm": 0.6296828389167786,
      "learning_rate": 6.002226095929247e-05,
      "loss": 2.4236,
      "step": 28700
    },
    {
      "epoch": 1.9260763061642225,
      "eval_bleu": 21.349254257866654,
      "eval_gen_len": 28.96,
      "eval_loss": 2.927715539932251,
      "eval_runtime": 64.5816,
      "eval_samples_per_second": 15.484,
      "eval_steps_per_second": 0.976,
      "step": 28700
    },
    {
      "epoch": 1.9267474245830676,
      "grad_norm": 0.6402326822280884,
      "learning_rate": 5.995586103495685e-05,
      "loss": 2.4496,
      "step": 28710
    },
    {
      "epoch": 1.9274185430019126,
      "grad_norm": 0.7631080150604248,
      "learning_rate": 5.9889482130979226e-05,
      "loss": 2.4715,
      "step": 28720
    },
    {
      "epoch": 1.9280896614207577,
      "grad_norm": 0.6436675190925598,
      "learning_rate": 5.9823124282203804e-05,
      "loss": 2.396,
      "step": 28730
    },
    {
      "epoch": 1.9287607798396027,
      "grad_norm": 0.7457842230796814,
      "learning_rate": 5.975678752346381e-05,
      "loss": 2.4859,
      "step": 28740
    },
    {
      "epoch": 1.9294318982584477,
      "grad_norm": 0.7633200883865356,
      "learning_rate": 5.9690471889581324e-05,
      "loss": 2.514,
      "step": 28750
    },
    {
      "epoch": 1.9294318982584477,
      "eval_bleu": 21.129791420996828,
      "eval_gen_len": 28.877,
      "eval_loss": 2.9278664588928223,
      "eval_runtime": 64.5648,
      "eval_samples_per_second": 15.488,
      "eval_steps_per_second": 0.976,
      "step": 28750
    },
    {
      "epoch": 1.9301030166772928,
      "grad_norm": 0.7252821922302246,
      "learning_rate": 5.9624177415367496e-05,
      "loss": 2.4901,
      "step": 28760
    },
    {
      "epoch": 1.9307741350961378,
      "grad_norm": 0.7610417008399963,
      "learning_rate": 5.955790413562219e-05,
      "loss": 2.5029,
      "step": 28770
    },
    {
      "epoch": 1.9314452535149829,
      "grad_norm": 0.7114486694335938,
      "learning_rate": 5.9491652085134245e-05,
      "loss": 2.5283,
      "step": 28780
    },
    {
      "epoch": 1.9321163719338277,
      "grad_norm": 0.7616063952445984,
      "learning_rate": 5.9425421298681286e-05,
      "loss": 2.5184,
      "step": 28790
    },
    {
      "epoch": 1.9327874903526727,
      "grad_norm": 0.707020103931427,
      "learning_rate": 5.935921181102989e-05,
      "loss": 2.4905,
      "step": 28800
    },
    {
      "epoch": 1.9327874903526727,
      "eval_bleu": 20.978084776979802,
      "eval_gen_len": 29.098,
      "eval_loss": 2.931042432785034,
      "eval_runtime": 67.9971,
      "eval_samples_per_second": 14.707,
      "eval_steps_per_second": 0.927,
      "step": 28800
    },
    {
      "epoch": 1.9334586087715178,
      "grad_norm": 0.7379425764083862,
      "learning_rate": 5.929302365693534e-05,
      "loss": 2.5058,
      "step": 28810
    },
    {
      "epoch": 1.9341297271903626,
      "grad_norm": 0.7091187834739685,
      "learning_rate": 5.922685687114179e-05,
      "loss": 2.4936,
      "step": 28820
    },
    {
      "epoch": 1.9348008456092076,
      "grad_norm": 0.6173368096351624,
      "learning_rate": 5.9160711488382095e-05,
      "loss": 2.4447,
      "step": 28830
    },
    {
      "epoch": 1.9354719640280527,
      "grad_norm": 0.80564284324646,
      "learning_rate": 5.909458754337801e-05,
      "loss": 2.473,
      "step": 28840
    },
    {
      "epoch": 1.9361430824468977,
      "grad_norm": 0.6684594750404358,
      "learning_rate": 5.902848507083988e-05,
      "loss": 2.5044,
      "step": 28850
    },
    {
      "epoch": 1.9361430824468977,
      "eval_bleu": 20.988927705580235,
      "eval_gen_len": 29.101,
      "eval_loss": 2.9301114082336426,
      "eval_runtime": 67.5551,
      "eval_samples_per_second": 14.803,
      "eval_steps_per_second": 0.933,
      "step": 28850
    },
    {
      "epoch": 1.9368142008657427,
      "grad_norm": 0.7286438345909119,
      "learning_rate": 5.8962404105466926e-05,
      "loss": 2.443,
      "step": 28860
    },
    {
      "epoch": 1.9374853192845878,
      "grad_norm": 0.7006790637969971,
      "learning_rate": 5.889634468194697e-05,
      "loss": 2.4641,
      "step": 28870
    },
    {
      "epoch": 1.9381564377034328,
      "grad_norm": 0.7036927938461304,
      "learning_rate": 5.8830306834956597e-05,
      "loss": 2.4647,
      "step": 28880
    },
    {
      "epoch": 1.9388275561222779,
      "grad_norm": 0.6939504146575928,
      "learning_rate": 5.8764290599160954e-05,
      "loss": 2.4798,
      "step": 28890
    },
    {
      "epoch": 1.939498674541123,
      "grad_norm": 0.6457309722900391,
      "learning_rate": 5.869829600921404e-05,
      "loss": 2.4463,
      "step": 28900
    },
    {
      "epoch": 1.939498674541123,
      "eval_bleu": 21.064345671429834,
      "eval_gen_len": 28.837,
      "eval_loss": 2.932219982147217,
      "eval_runtime": 63.9816,
      "eval_samples_per_second": 15.629,
      "eval_steps_per_second": 0.985,
      "step": 28900
    },
    {
      "epoch": 1.940169792959968,
      "grad_norm": 0.6973554491996765,
      "learning_rate": 5.863232309975829e-05,
      "loss": 2.441,
      "step": 28910
    },
    {
      "epoch": 1.9408409113788128,
      "grad_norm": 0.6928982734680176,
      "learning_rate": 5.856637190542489e-05,
      "loss": 2.4337,
      "step": 28920
    },
    {
      "epoch": 1.9415120297976578,
      "grad_norm": 0.7025235891342163,
      "learning_rate": 5.850044246083353e-05,
      "loss": 2.498,
      "step": 28930
    },
    {
      "epoch": 1.9421831482165028,
      "grad_norm": 0.6682766079902649,
      "learning_rate": 5.843453480059259e-05,
      "loss": 2.4308,
      "step": 28940
    },
    {
      "epoch": 1.9428542666353477,
      "grad_norm": 0.6659695506095886,
      "learning_rate": 5.8368648959298925e-05,
      "loss": 2.4684,
      "step": 28950
    },
    {
      "epoch": 1.9428542666353477,
      "eval_bleu": 21.20386811711198,
      "eval_gen_len": 28.997,
      "eval_loss": 2.929189443588257,
      "eval_runtime": 64.3285,
      "eval_samples_per_second": 15.545,
      "eval_steps_per_second": 0.979,
      "step": 28950
    },
    {
      "epoch": 1.9435253850541927,
      "grad_norm": 0.7306572794914246,
      "learning_rate": 5.8302784971537985e-05,
      "loss": 2.4554,
      "step": 28960
    },
    {
      "epoch": 1.9441965034730377,
      "grad_norm": 0.7356363534927368,
      "learning_rate": 5.82369428718837e-05,
      "loss": 2.4759,
      "step": 28970
    },
    {
      "epoch": 1.9448676218918828,
      "grad_norm": 0.670929491519928,
      "learning_rate": 5.81711226948986e-05,
      "loss": 2.427,
      "step": 28980
    },
    {
      "epoch": 1.9455387403107278,
      "grad_norm": 0.6874676942825317,
      "learning_rate": 5.810532447513364e-05,
      "loss": 2.4504,
      "step": 28990
    },
    {
      "epoch": 1.9462098587295729,
      "grad_norm": 0.702318012714386,
      "learning_rate": 5.803954824712818e-05,
      "loss": 2.4278,
      "step": 29000
    },
    {
      "epoch": 1.9462098587295729,
      "eval_bleu": 21.263739935544717,
      "eval_gen_len": 29.011,
      "eval_loss": 2.931304454803467,
      "eval_runtime": 64.8145,
      "eval_samples_per_second": 15.429,
      "eval_steps_per_second": 0.972,
      "step": 29000
    },
    {
      "epoch": 1.946880977148418,
      "grad_norm": 0.7229705452919006,
      "learning_rate": 5.797379404541024e-05,
      "loss": 2.4995,
      "step": 29010
    },
    {
      "epoch": 1.947552095567263,
      "grad_norm": 0.6563547253608704,
      "learning_rate": 5.790806190449608e-05,
      "loss": 2.4615,
      "step": 29020
    },
    {
      "epoch": 1.948223213986108,
      "grad_norm": 0.6555082201957703,
      "learning_rate": 5.7842351858890466e-05,
      "loss": 2.482,
      "step": 29030
    },
    {
      "epoch": 1.9488943324049528,
      "grad_norm": 0.6869472861289978,
      "learning_rate": 5.777666394308651e-05,
      "loss": 2.4469,
      "step": 29040
    },
    {
      "epoch": 1.9495654508237978,
      "grad_norm": 0.6097231507301331,
      "learning_rate": 5.771099819156582e-05,
      "loss": 2.4701,
      "step": 29050
    },
    {
      "epoch": 1.9495654508237978,
      "eval_bleu": 21.036793963902223,
      "eval_gen_len": 28.904,
      "eval_loss": 2.929003953933716,
      "eval_runtime": 63.9184,
      "eval_samples_per_second": 15.645,
      "eval_steps_per_second": 0.986,
      "step": 29050
    },
    {
      "epoch": 1.9502365692426429,
      "grad_norm": 0.6572467088699341,
      "learning_rate": 5.7645354638798255e-05,
      "loss": 2.4643,
      "step": 29060
    },
    {
      "epoch": 1.950907687661488,
      "grad_norm": 0.6866119503974915,
      "learning_rate": 5.7579733319242114e-05,
      "loss": 2.4973,
      "step": 29070
    },
    {
      "epoch": 1.9515788060803327,
      "grad_norm": 0.6937236785888672,
      "learning_rate": 5.751413426734389e-05,
      "loss": 2.4955,
      "step": 29080
    },
    {
      "epoch": 1.9522499244991778,
      "grad_norm": 0.7409166693687439,
      "learning_rate": 5.744855751753857e-05,
      "loss": 2.4636,
      "step": 29090
    },
    {
      "epoch": 1.9529210429180228,
      "grad_norm": 0.7045537829399109,
      "learning_rate": 5.738300310424931e-05,
      "loss": 2.4588,
      "step": 29100
    },
    {
      "epoch": 1.9529210429180228,
      "eval_bleu": 21.13782067504851,
      "eval_gen_len": 28.802,
      "eval_loss": 2.93229079246521,
      "eval_runtime": 64.1756,
      "eval_samples_per_second": 15.582,
      "eval_steps_per_second": 0.982,
      "step": 29100
    },
    {
      "epoch": 1.9535921613368679,
      "grad_norm": 0.7739102244377136,
      "learning_rate": 5.731747106188754e-05,
      "loss": 2.4871,
      "step": 29110
    },
    {
      "epoch": 1.954263279755713,
      "grad_norm": 0.6736669540405273,
      "learning_rate": 5.725196142485296e-05,
      "loss": 2.4456,
      "step": 29120
    },
    {
      "epoch": 1.954934398174558,
      "grad_norm": 0.6718979477882385,
      "learning_rate": 5.7186474227533596e-05,
      "loss": 2.492,
      "step": 29130
    },
    {
      "epoch": 1.955605516593403,
      "grad_norm": 0.6661742329597473,
      "learning_rate": 5.7121009504305536e-05,
      "loss": 2.4509,
      "step": 29140
    },
    {
      "epoch": 1.956276635012248,
      "grad_norm": 0.7609086036682129,
      "learning_rate": 5.705556728953324e-05,
      "loss": 2.4976,
      "step": 29150
    },
    {
      "epoch": 1.956276635012248,
      "eval_bleu": 21.271697157186733,
      "eval_gen_len": 28.843,
      "eval_loss": 2.930482864379883,
      "eval_runtime": 64.6033,
      "eval_samples_per_second": 15.479,
      "eval_steps_per_second": 0.975,
      "step": 29150
    },
    {
      "epoch": 1.956947753431093,
      "grad_norm": 0.6325085759162903,
      "learning_rate": 5.69901476175692e-05,
      "loss": 2.4675,
      "step": 29160
    },
    {
      "epoch": 1.9576188718499379,
      "grad_norm": 0.6650046706199646,
      "learning_rate": 5.6924750522754214e-05,
      "loss": 2.4589,
      "step": 29170
    },
    {
      "epoch": 1.958289990268783,
      "grad_norm": 0.7685168981552124,
      "learning_rate": 5.685937603941708e-05,
      "loss": 2.4692,
      "step": 29180
    },
    {
      "epoch": 1.958961108687628,
      "grad_norm": 0.6534852385520935,
      "learning_rate": 5.67940242018749e-05,
      "loss": 2.4748,
      "step": 29190
    },
    {
      "epoch": 1.9596322271064728,
      "grad_norm": 0.6940051913261414,
      "learning_rate": 5.6728695044432723e-05,
      "loss": 2.4992,
      "step": 29200
    },
    {
      "epoch": 1.9596322271064728,
      "eval_bleu": 21.241061230433868,
      "eval_gen_len": 28.906,
      "eval_loss": 2.9289543628692627,
      "eval_runtime": 64.0706,
      "eval_samples_per_second": 15.608,
      "eval_steps_per_second": 0.983,
      "step": 29200
    },
    {
      "epoch": 1.9603033455253178,
      "grad_norm": 0.6591780185699463,
      "learning_rate": 5.66633886013838e-05,
      "loss": 2.5025,
      "step": 29210
    },
    {
      "epoch": 1.9609744639441629,
      "grad_norm": 0.6695594191551208,
      "learning_rate": 5.659810490700937e-05,
      "loss": 2.4833,
      "step": 29220
    },
    {
      "epoch": 1.961645582363008,
      "grad_norm": 0.6267428994178772,
      "learning_rate": 5.653284399557886e-05,
      "loss": 2.4678,
      "step": 29230
    },
    {
      "epoch": 1.962316700781853,
      "grad_norm": 0.6728302836418152,
      "learning_rate": 5.646760590134959e-05,
      "loss": 2.4473,
      "step": 29240
    },
    {
      "epoch": 1.962987819200698,
      "grad_norm": 0.6969948410987854,
      "learning_rate": 5.6402390658567025e-05,
      "loss": 2.467,
      "step": 29250
    },
    {
      "epoch": 1.962987819200698,
      "eval_bleu": 21.297336235682106,
      "eval_gen_len": 28.827,
      "eval_loss": 2.9324867725372314,
      "eval_runtime": 63.9373,
      "eval_samples_per_second": 15.64,
      "eval_steps_per_second": 0.985,
      "step": 29250
    },
    {
      "epoch": 1.963658937619543,
      "grad_norm": 0.6864530444145203,
      "learning_rate": 5.633719830146454e-05,
      "loss": 2.4802,
      "step": 29260
    },
    {
      "epoch": 1.964330056038388,
      "grad_norm": 0.7008470892906189,
      "learning_rate": 5.6272028864263606e-05,
      "loss": 2.4442,
      "step": 29270
    },
    {
      "epoch": 1.965001174457233,
      "grad_norm": 0.7148599624633789,
      "learning_rate": 5.620688238117355e-05,
      "loss": 2.4959,
      "step": 29280
    },
    {
      "epoch": 1.9656722928760781,
      "grad_norm": 0.7153266072273254,
      "learning_rate": 5.614175888639169e-05,
      "loss": 2.5125,
      "step": 29290
    },
    {
      "epoch": 1.966343411294923,
      "grad_norm": 0.7078018188476562,
      "learning_rate": 5.60766584141033e-05,
      "loss": 2.4434,
      "step": 29300
    },
    {
      "epoch": 1.966343411294923,
      "eval_bleu": 21.014308204405516,
      "eval_gen_len": 29.087,
      "eval_loss": 2.930813789367676,
      "eval_runtime": 67.5195,
      "eval_samples_per_second": 14.811,
      "eval_steps_per_second": 0.933,
      "step": 29300
    },
    {
      "epoch": 1.967014529713768,
      "grad_norm": 0.6321645379066467,
      "learning_rate": 5.6011580998481506e-05,
      "loss": 2.4375,
      "step": 29310
    },
    {
      "epoch": 1.967685648132613,
      "grad_norm": 0.6357446312904358,
      "learning_rate": 5.5946526673687446e-05,
      "loss": 2.4625,
      "step": 29320
    },
    {
      "epoch": 1.9683567665514579,
      "grad_norm": 0.6124964952468872,
      "learning_rate": 5.5881495473870004e-05,
      "loss": 2.4616,
      "step": 29330
    },
    {
      "epoch": 1.969027884970303,
      "grad_norm": 0.633380651473999,
      "learning_rate": 5.581648743316606e-05,
      "loss": 2.4597,
      "step": 29340
    },
    {
      "epoch": 1.969699003389148,
      "grad_norm": 0.697349488735199,
      "learning_rate": 5.575150258570019e-05,
      "loss": 2.5082,
      "step": 29350
    },
    {
      "epoch": 1.969699003389148,
      "eval_bleu": 21.232066981503422,
      "eval_gen_len": 28.905,
      "eval_loss": 2.9322636127471924,
      "eval_runtime": 64.1145,
      "eval_samples_per_second": 15.597,
      "eval_steps_per_second": 0.983,
      "step": 29350
    },
    {
      "epoch": 1.970370121807993,
      "grad_norm": 0.6104112267494202,
      "learning_rate": 5.568654096558493e-05,
      "loss": 2.3977,
      "step": 29360
    },
    {
      "epoch": 1.971041240226838,
      "grad_norm": 0.6879054307937622,
      "learning_rate": 5.5621602606920555e-05,
      "loss": 2.4921,
      "step": 29370
    },
    {
      "epoch": 1.971712358645683,
      "grad_norm": 0.6942605376243591,
      "learning_rate": 5.555668754379512e-05,
      "loss": 2.4584,
      "step": 29380
    },
    {
      "epoch": 1.972383477064528,
      "grad_norm": 0.6413564085960388,
      "learning_rate": 5.549179581028443e-05,
      "loss": 2.489,
      "step": 29390
    },
    {
      "epoch": 1.9730545954833731,
      "grad_norm": 0.6883301734924316,
      "learning_rate": 5.542692744045217e-05,
      "loss": 2.5355,
      "step": 29400
    },
    {
      "epoch": 1.9730545954833731,
      "eval_bleu": 21.28053341058474,
      "eval_gen_len": 28.986,
      "eval_loss": 2.9278481006622314,
      "eval_runtime": 63.7168,
      "eval_samples_per_second": 15.694,
      "eval_steps_per_second": 0.989,
      "step": 29400
    },
    {
      "epoch": 1.9737257139022182,
      "grad_norm": 0.7144761681556702,
      "learning_rate": 5.536208246834958e-05,
      "loss": 2.4814,
      "step": 29410
    },
    {
      "epoch": 1.974396832321063,
      "grad_norm": 0.6639181971549988,
      "learning_rate": 5.5297260928015816e-05,
      "loss": 2.4742,
      "step": 29420
    },
    {
      "epoch": 1.975067950739908,
      "grad_norm": 0.7076355814933777,
      "learning_rate": 5.523246285347754e-05,
      "loss": 2.5147,
      "step": 29430
    },
    {
      "epoch": 1.975739069158753,
      "grad_norm": 0.7029792070388794,
      "learning_rate": 5.516768827874925e-05,
      "loss": 2.4699,
      "step": 29440
    },
    {
      "epoch": 1.9764101875775981,
      "grad_norm": 0.789186418056488,
      "learning_rate": 5.510293723783297e-05,
      "loss": 2.5203,
      "step": 29450
    },
    {
      "epoch": 1.9764101875775981,
      "eval_bleu": 21.275835172311634,
      "eval_gen_len": 29.016,
      "eval_loss": 2.927448034286499,
      "eval_runtime": 64.5118,
      "eval_samples_per_second": 15.501,
      "eval_steps_per_second": 0.977,
      "step": 29450
    },
    {
      "epoch": 1.977081305996443,
      "grad_norm": 0.7509266138076782,
      "learning_rate": 5.503820976471855e-05,
      "loss": 2.4425,
      "step": 29460
    },
    {
      "epoch": 1.977752424415288,
      "grad_norm": 0.647311806678772,
      "learning_rate": 5.497350589338331e-05,
      "loss": 2.3999,
      "step": 29470
    },
    {
      "epoch": 1.978423542834133,
      "grad_norm": 0.6851335167884827,
      "learning_rate": 5.490882565779221e-05,
      "loss": 2.5467,
      "step": 29480
    },
    {
      "epoch": 1.979094661252978,
      "grad_norm": 0.6487478613853455,
      "learning_rate": 5.4844169091897804e-05,
      "loss": 2.4362,
      "step": 29490
    },
    {
      "epoch": 1.979765779671823,
      "grad_norm": 0.7587623596191406,
      "learning_rate": 5.477953622964034e-05,
      "loss": 2.4116,
      "step": 29500
    },
    {
      "epoch": 1.979765779671823,
      "eval_bleu": 21.252634921527,
      "eval_gen_len": 28.895,
      "eval_loss": 2.9296023845672607,
      "eval_runtime": 64.1739,
      "eval_samples_per_second": 15.583,
      "eval_steps_per_second": 0.982,
      "step": 29500
    },
    {
      "epoch": 1.9804368980906681,
      "grad_norm": 0.7014994025230408,
      "learning_rate": 5.471492710494741e-05,
      "loss": 2.4474,
      "step": 29510
    },
    {
      "epoch": 1.9811080165095132,
      "grad_norm": 0.7160327434539795,
      "learning_rate": 5.465034175173438e-05,
      "loss": 2.4952,
      "step": 29520
    },
    {
      "epoch": 1.9817791349283582,
      "grad_norm": 0.7374669313430786,
      "learning_rate": 5.4585780203903924e-05,
      "loss": 2.4967,
      "step": 29530
    },
    {
      "epoch": 1.9824502533472033,
      "grad_norm": 0.6043703556060791,
      "learning_rate": 5.45212424953464e-05,
      "loss": 2.4264,
      "step": 29540
    },
    {
      "epoch": 1.983121371766048,
      "grad_norm": 0.6774285435676575,
      "learning_rate": 5.4456728659939524e-05,
      "loss": 2.4096,
      "step": 29550
    },
    {
      "epoch": 1.983121371766048,
      "eval_bleu": 21.437209545301627,
      "eval_gen_len": 28.86,
      "eval_loss": 2.929797410964966,
      "eval_runtime": 64.4697,
      "eval_samples_per_second": 15.511,
      "eval_steps_per_second": 0.977,
      "step": 29550
    },
    {
      "epoch": 1.9837924901848931,
      "grad_norm": 0.6792200207710266,
      "learning_rate": 5.439223873154853e-05,
      "loss": 2.4798,
      "step": 29560
    },
    {
      "epoch": 1.9844636086037382,
      "grad_norm": 0.7379559278488159,
      "learning_rate": 5.432777274402605e-05,
      "loss": 2.4848,
      "step": 29570
    },
    {
      "epoch": 1.985134727022583,
      "grad_norm": 0.7032138705253601,
      "learning_rate": 5.426333073121228e-05,
      "loss": 2.4319,
      "step": 29580
    },
    {
      "epoch": 1.985805845441428,
      "grad_norm": 0.680637776851654,
      "learning_rate": 5.4198912726934693e-05,
      "loss": 2.4578,
      "step": 29590
    },
    {
      "epoch": 1.986476963860273,
      "grad_norm": 0.6816632747650146,
      "learning_rate": 5.4134518765008205e-05,
      "loss": 2.4694,
      "step": 29600
    },
    {
      "epoch": 1.986476963860273,
      "eval_bleu": 21.284928932665874,
      "eval_gen_len": 28.865,
      "eval_loss": 2.92915678024292,
      "eval_runtime": 64.1771,
      "eval_samples_per_second": 15.582,
      "eval_steps_per_second": 0.982,
      "step": 29600
    },
    {
      "epoch": 1.987148082279118,
      "grad_norm": 0.7218299508094788,
      "learning_rate": 5.407014887923516e-05,
      "loss": 2.5211,
      "step": 29610
    },
    {
      "epoch": 1.9878192006979631,
      "grad_norm": 0.6417099237442017,
      "learning_rate": 5.400580310340517e-05,
      "loss": 2.4658,
      "step": 29620
    },
    {
      "epoch": 1.9884903191168082,
      "grad_norm": 0.662162721157074,
      "learning_rate": 5.394148147129532e-05,
      "loss": 2.4452,
      "step": 29630
    },
    {
      "epoch": 1.9891614375356532,
      "grad_norm": 0.6897631883621216,
      "learning_rate": 5.38771840166699e-05,
      "loss": 2.4273,
      "step": 29640
    },
    {
      "epoch": 1.9898325559544983,
      "grad_norm": 0.6100298762321472,
      "learning_rate": 5.3812910773280543e-05,
      "loss": 2.441,
      "step": 29650
    },
    {
      "epoch": 1.9898325559544983,
      "eval_bleu": 21.423684332758782,
      "eval_gen_len": 28.923,
      "eval_loss": 2.926267147064209,
      "eval_runtime": 64.412,
      "eval_samples_per_second": 15.525,
      "eval_steps_per_second": 0.978,
      "step": 29650
    },
    {
      "epoch": 1.9905036743733433,
      "grad_norm": 0.7150505185127258,
      "learning_rate": 5.374866177486617e-05,
      "loss": 2.4688,
      "step": 29660
    },
    {
      "epoch": 1.9911747927921883,
      "grad_norm": 0.6901890635490417,
      "learning_rate": 5.368443705515306e-05,
      "loss": 2.4798,
      "step": 29670
    },
    {
      "epoch": 1.9918459112110332,
      "grad_norm": 0.6043037176132202,
      "learning_rate": 5.3620236647854583e-05,
      "loss": 2.4669,
      "step": 29680
    },
    {
      "epoch": 1.9925170296298782,
      "grad_norm": 0.7027308940887451,
      "learning_rate": 5.355606058667152e-05,
      "loss": 2.5554,
      "step": 29690
    },
    {
      "epoch": 1.9931881480487232,
      "grad_norm": 0.7432153820991516,
      "learning_rate": 5.349190890529172e-05,
      "loss": 2.4488,
      "step": 29700
    },
    {
      "epoch": 1.9931881480487232,
      "eval_bleu": 21.526286842521497,
      "eval_gen_len": 29.008,
      "eval_loss": 2.927277088165283,
      "eval_runtime": 63.8828,
      "eval_samples_per_second": 15.654,
      "eval_steps_per_second": 0.986,
      "step": 29700
    },
    {
      "epoch": 1.993859266467568,
      "grad_norm": 0.7171278595924377,
      "learning_rate": 5.3427781637390394e-05,
      "loss": 2.5113,
      "step": 29710
    },
    {
      "epoch": 1.994530384886413,
      "grad_norm": 0.6077909469604492,
      "learning_rate": 5.336367881662979e-05,
      "loss": 2.4176,
      "step": 29720
    },
    {
      "epoch": 1.9952015033052581,
      "grad_norm": 0.6400649547576904,
      "learning_rate": 5.329960047665941e-05,
      "loss": 2.4548,
      "step": 29730
    },
    {
      "epoch": 1.9958726217241032,
      "grad_norm": 0.7036420702934265,
      "learning_rate": 5.323554665111581e-05,
      "loss": 2.4677,
      "step": 29740
    },
    {
      "epoch": 1.9965437401429482,
      "grad_norm": 0.6958271265029907,
      "learning_rate": 5.317151737362283e-05,
      "loss": 2.4827,
      "step": 29750
    },
    {
      "epoch": 1.9965437401429482,
      "eval_bleu": 21.159863906305088,
      "eval_gen_len": 28.893,
      "eval_loss": 2.9283030033111572,
      "eval_runtime": 63.6987,
      "eval_samples_per_second": 15.699,
      "eval_steps_per_second": 0.989,
      "step": 29750
    },
    {
      "epoch": 1.9972148585617933,
      "grad_norm": 0.7140100598335266,
      "learning_rate": 5.310751267779127e-05,
      "loss": 2.4516,
      "step": 29760
    },
    {
      "epoch": 1.9978859769806383,
      "grad_norm": 0.6165951490402222,
      "learning_rate": 5.304353259721917e-05,
      "loss": 2.4624,
      "step": 29770
    },
    {
      "epoch": 1.9985570953994833,
      "grad_norm": 0.6300039291381836,
      "learning_rate": 5.297957716549151e-05,
      "loss": 2.4999,
      "step": 29780
    },
    {
      "epoch": 1.9992282138183284,
      "grad_norm": 0.6815632581710815,
      "learning_rate": 5.2915646416180455e-05,
      "loss": 2.4594,
      "step": 29790
    },
    {
      "epoch": 1.9998993322371732,
      "grad_norm": 0.6552728414535522,
      "learning_rate": 5.285174038284507e-05,
      "loss": 2.4417,
      "step": 29800
    },
    {
      "epoch": 1.9998993322371732,
      "eval_bleu": 21.226239800865695,
      "eval_gen_len": 28.839,
      "eval_loss": 2.9282398223876953,
      "eval_runtime": 64.1145,
      "eval_samples_per_second": 15.597,
      "eval_steps_per_second": 0.983,
      "step": 29800
    },
    {
      "epoch": 2.000536894735076,
      "grad_norm": 0.7618942856788635,
      "learning_rate": 5.2787859099031634e-05,
      "loss": 2.5347,
      "step": 29810
    },
    {
      "epoch": 2.001208013153921,
      "grad_norm": 0.6690100431442261,
      "learning_rate": 5.272400259827328e-05,
      "loss": 2.4479,
      "step": 29820
    },
    {
      "epoch": 2.001879131572766,
      "grad_norm": 0.7053123116493225,
      "learning_rate": 5.2660170914090166e-05,
      "loss": 2.4229,
      "step": 29830
    },
    {
      "epoch": 2.002550249991611,
      "grad_norm": 0.6690265536308289,
      "learning_rate": 5.2596364079989426e-05,
      "loss": 2.4942,
      "step": 29840
    },
    {
      "epoch": 2.003221368410456,
      "grad_norm": 0.6161752939224243,
      "learning_rate": 5.2532582129465235e-05,
      "loss": 2.4906,
      "step": 29850
    },
    {
      "epoch": 2.003221368410456,
      "eval_bleu": 21.27077324544001,
      "eval_gen_len": 28.885,
      "eval_loss": 2.9286978244781494,
      "eval_runtime": 64.0169,
      "eval_samples_per_second": 15.621,
      "eval_steps_per_second": 0.984,
      "step": 29850
    },
    {
      "epoch": 2.003892486829301,
      "grad_norm": 0.695215106010437,
      "learning_rate": 5.246882509599853e-05,
      "loss": 2.4534,
      "step": 29860
    },
    {
      "epoch": 2.004563605248146,
      "grad_norm": 0.6988332867622375,
      "learning_rate": 5.2405093013057384e-05,
      "loss": 2.4367,
      "step": 29870
    },
    {
      "epoch": 2.005234723666991,
      "grad_norm": 0.7383856177330017,
      "learning_rate": 5.234138591409661e-05,
      "loss": 2.453,
      "step": 29880
    },
    {
      "epoch": 2.005905842085836,
      "grad_norm": 0.6640016436576843,
      "learning_rate": 5.2277703832557904e-05,
      "loss": 2.4258,
      "step": 29890
    },
    {
      "epoch": 2.006576960504681,
      "grad_norm": 0.6837713718414307,
      "learning_rate": 5.221404680186996e-05,
      "loss": 2.4336,
      "step": 29900
    },
    {
      "epoch": 2.006576960504681,
      "eval_bleu": 21.291020240226146,
      "eval_gen_len": 28.916,
      "eval_loss": 2.9297008514404297,
      "eval_runtime": 64.2753,
      "eval_samples_per_second": 15.558,
      "eval_steps_per_second": 0.98,
      "step": 29900
    },
    {
      "epoch": 2.007248078923526,
      "grad_norm": 0.628025233745575,
      "learning_rate": 5.2150414855448226e-05,
      "loss": 2.4224,
      "step": 29910
    },
    {
      "epoch": 2.007919197342371,
      "grad_norm": 0.7170009016990662,
      "learning_rate": 5.208680802669499e-05,
      "loss": 2.4525,
      "step": 29920
    },
    {
      "epoch": 2.008590315761216,
      "grad_norm": 0.6901500225067139,
      "learning_rate": 5.2023226348999324e-05,
      "loss": 2.4533,
      "step": 29930
    },
    {
      "epoch": 2.009261434180061,
      "grad_norm": 0.699007511138916,
      "learning_rate": 5.195966985573721e-05,
      "loss": 2.4185,
      "step": 29940
    },
    {
      "epoch": 2.0099325525989062,
      "grad_norm": 0.6882306337356567,
      "learning_rate": 5.1896138580271294e-05,
      "loss": 2.4571,
      "step": 29950
    },
    {
      "epoch": 2.0099325525989062,
      "eval_bleu": 21.26036231301454,
      "eval_gen_len": 28.86,
      "eval_loss": 2.930021286010742,
      "eval_runtime": 64.2093,
      "eval_samples_per_second": 15.574,
      "eval_steps_per_second": 0.981,
      "step": 29950
    },
    {
      "epoch": 2.0106036710177513,
      "grad_norm": 0.6822152137756348,
      "learning_rate": 5.183263255595107e-05,
      "loss": 2.4632,
      "step": 29960
    },
    {
      "epoch": 2.011274789436596,
      "grad_norm": 0.7046100497245789,
      "learning_rate": 5.176915181611266e-05,
      "loss": 2.4173,
      "step": 29970
    },
    {
      "epoch": 2.011945907855441,
      "grad_norm": 0.6843554973602295,
      "learning_rate": 5.1705696394079095e-05,
      "loss": 2.4462,
      "step": 29980
    },
    {
      "epoch": 2.012617026274286,
      "grad_norm": 0.6861951351165771,
      "learning_rate": 5.164226632315996e-05,
      "loss": 2.4569,
      "step": 29990
    },
    {
      "epoch": 2.013288144693131,
      "grad_norm": 0.7269421219825745,
      "learning_rate": 5.1578861636651574e-05,
      "loss": 2.4568,
      "step": 30000
    },
    {
      "epoch": 2.013288144693131,
      "eval_bleu": 21.22430866886125,
      "eval_gen_len": 28.87,
      "eval_loss": 2.931122303009033,
      "eval_runtime": 64.3444,
      "eval_samples_per_second": 15.541,
      "eval_steps_per_second": 0.979,
      "step": 30000
    },
    {
      "epoch": 2.013959263111976,
      "grad_norm": 0.6967037320137024,
      "learning_rate": 5.15154823678369e-05,
      "loss": 2.4203,
      "step": 30010
    },
    {
      "epoch": 2.014630381530821,
      "grad_norm": 0.684959352016449,
      "learning_rate": 5.145212854998569e-05,
      "loss": 2.4622,
      "step": 30020
    },
    {
      "epoch": 2.015301499949666,
      "grad_norm": 0.6740511655807495,
      "learning_rate": 5.138880021635417e-05,
      "loss": 2.3969,
      "step": 30030
    },
    {
      "epoch": 2.015972618368511,
      "grad_norm": 0.6996030807495117,
      "learning_rate": 5.132549740018533e-05,
      "loss": 2.4072,
      "step": 30040
    },
    {
      "epoch": 2.016643736787356,
      "grad_norm": 0.6721303462982178,
      "learning_rate": 5.12622201347086e-05,
      "loss": 2.4434,
      "step": 30050
    },
    {
      "epoch": 2.016643736787356,
      "eval_bleu": 21.312630603758496,
      "eval_gen_len": 28.864,
      "eval_loss": 2.9310996532440186,
      "eval_runtime": 63.977,
      "eval_samples_per_second": 15.631,
      "eval_steps_per_second": 0.985,
      "step": 30050
    },
    {
      "epoch": 2.0173148552062012,
      "grad_norm": 0.6188123822212219,
      "learning_rate": 5.1198968453140226e-05,
      "loss": 2.4432,
      "step": 30060
    },
    {
      "epoch": 2.0179859736250463,
      "grad_norm": 0.6640698313713074,
      "learning_rate": 5.113574238868277e-05,
      "loss": 2.4224,
      "step": 30070
    },
    {
      "epoch": 2.0186570920438913,
      "grad_norm": 0.7265568375587463,
      "learning_rate": 5.1072541974525577e-05,
      "loss": 2.4536,
      "step": 30080
    },
    {
      "epoch": 2.0193282104627364,
      "grad_norm": 0.7084583044052124,
      "learning_rate": 5.1009367243844376e-05,
      "loss": 2.4174,
      "step": 30090
    },
    {
      "epoch": 2.019999328881581,
      "grad_norm": 0.7365621328353882,
      "learning_rate": 5.0946218229801434e-05,
      "loss": 2.4455,
      "step": 30100
    },
    {
      "epoch": 2.019999328881581,
      "eval_bleu": 21.503163891952187,
      "eval_gen_len": 28.887,
      "eval_loss": 2.9331703186035156,
      "eval_runtime": 64.2423,
      "eval_samples_per_second": 15.566,
      "eval_steps_per_second": 0.981,
      "step": 30100
    },
    {
      "epoch": 2.020670447300426,
      "grad_norm": 0.7310879826545715,
      "learning_rate": 5.088309496554555e-05,
      "loss": 2.4378,
      "step": 30110
    },
    {
      "epoch": 2.021341565719271,
      "grad_norm": 0.663285493850708,
      "learning_rate": 5.0819997484212046e-05,
      "loss": 2.4796,
      "step": 30120
    },
    {
      "epoch": 2.022012684138116,
      "grad_norm": 0.663111686706543,
      "learning_rate": 5.07569258189226e-05,
      "loss": 2.4248,
      "step": 30130
    },
    {
      "epoch": 2.022683802556961,
      "grad_norm": 0.7030788660049438,
      "learning_rate": 5.0693880002785456e-05,
      "loss": 2.4169,
      "step": 30140
    },
    {
      "epoch": 2.023354920975806,
      "grad_norm": 0.6662903428077698,
      "learning_rate": 5.0630860068895194e-05,
      "loss": 2.4708,
      "step": 30150
    },
    {
      "epoch": 2.023354920975806,
      "eval_bleu": 21.226051247951183,
      "eval_gen_len": 28.943,
      "eval_loss": 2.932798147201538,
      "eval_runtime": 64.1891,
      "eval_samples_per_second": 15.579,
      "eval_steps_per_second": 0.981,
      "step": 30150
    },
    {
      "epoch": 2.024026039394651,
      "grad_norm": 0.6680098176002502,
      "learning_rate": 5.0567866050332915e-05,
      "loss": 2.4718,
      "step": 30160
    },
    {
      "epoch": 2.0246971578134962,
      "grad_norm": 0.6964249610900879,
      "learning_rate": 5.0504897980166e-05,
      "loss": 2.5015,
      "step": 30170
    },
    {
      "epoch": 2.0253682762323413,
      "grad_norm": 0.6798425912857056,
      "learning_rate": 5.0441955891448264e-05,
      "loss": 2.4221,
      "step": 30180
    },
    {
      "epoch": 2.0260393946511863,
      "grad_norm": 0.6698659658432007,
      "learning_rate": 5.037903981721989e-05,
      "loss": 2.4035,
      "step": 30190
    },
    {
      "epoch": 2.0267105130700314,
      "grad_norm": 0.6609922051429749,
      "learning_rate": 5.031614979050734e-05,
      "loss": 2.4266,
      "step": 30200
    },
    {
      "epoch": 2.0267105130700314,
      "eval_bleu": 21.349483025981385,
      "eval_gen_len": 28.911,
      "eval_loss": 2.9302453994750977,
      "eval_runtime": 64.009,
      "eval_samples_per_second": 15.623,
      "eval_steps_per_second": 0.984,
      "step": 30200
    },
    {
      "epoch": 2.0273816314888764,
      "grad_norm": 0.7551152110099792,
      "learning_rate": 5.025328584432354e-05,
      "loss": 2.4575,
      "step": 30210
    },
    {
      "epoch": 2.028052749907721,
      "grad_norm": 0.7085496187210083,
      "learning_rate": 5.0190448011667565e-05,
      "loss": 2.4088,
      "step": 30220
    },
    {
      "epoch": 2.028723868326566,
      "grad_norm": 0.6887832283973694,
      "learning_rate": 5.012763632552494e-05,
      "loss": 2.5237,
      "step": 30230
    },
    {
      "epoch": 2.029394986745411,
      "grad_norm": 0.6398585438728333,
      "learning_rate": 5.0064850818867305e-05,
      "loss": 2.4594,
      "step": 30240
    },
    {
      "epoch": 2.030066105164256,
      "grad_norm": 0.6692217588424683,
      "learning_rate": 5.000209152465272e-05,
      "loss": 2.4538,
      "step": 30250
    },
    {
      "epoch": 2.030066105164256,
      "eval_bleu": 21.201100973428883,
      "eval_gen_len": 29.146,
      "eval_loss": 2.9314894676208496,
      "eval_runtime": 67.0742,
      "eval_samples_per_second": 14.909,
      "eval_steps_per_second": 0.939,
      "step": 30250
    },
    {
      "epoch": 2.030737223583101,
      "grad_norm": 0.6861236691474915,
      "learning_rate": 4.993935847582535e-05,
      "loss": 2.4158,
      "step": 30260
    },
    {
      "epoch": 2.031408342001946,
      "grad_norm": 0.6898226141929626,
      "learning_rate": 4.987665170531566e-05,
      "loss": 2.4328,
      "step": 30270
    },
    {
      "epoch": 2.0320794604207912,
      "grad_norm": 0.6677325367927551,
      "learning_rate": 4.9813971246040223e-05,
      "loss": 2.435,
      "step": 30280
    },
    {
      "epoch": 2.0327505788396363,
      "grad_norm": 0.7342432737350464,
      "learning_rate": 4.975131713090199e-05,
      "loss": 2.4309,
      "step": 30290
    },
    {
      "epoch": 2.0334216972584813,
      "grad_norm": 0.6196765899658203,
      "learning_rate": 4.968868939278985e-05,
      "loss": 2.4632,
      "step": 30300
    },
    {
      "epoch": 2.0334216972584813,
      "eval_bleu": 21.165283882119997,
      "eval_gen_len": 29.108,
      "eval_loss": 2.932401657104492,
      "eval_runtime": 66.9042,
      "eval_samples_per_second": 14.947,
      "eval_steps_per_second": 0.942,
      "step": 30300
    },
    {
      "epoch": 2.0340928156773264,
      "grad_norm": 0.6456702351570129,
      "learning_rate": 4.962608806457908e-05,
      "loss": 2.4822,
      "step": 30310
    },
    {
      "epoch": 2.0347639340961714,
      "grad_norm": 0.6821365356445312,
      "learning_rate": 4.956351317913088e-05,
      "loss": 2.4768,
      "step": 30320
    },
    {
      "epoch": 2.0354350525150164,
      "grad_norm": 0.7833166718482971,
      "learning_rate": 4.950096476929273e-05,
      "loss": 2.4855,
      "step": 30330
    },
    {
      "epoch": 2.0361061709338615,
      "grad_norm": 0.7448034286499023,
      "learning_rate": 4.943844286789814e-05,
      "loss": 2.4169,
      "step": 30340
    },
    {
      "epoch": 2.036777289352706,
      "grad_norm": 0.7157983183860779,
      "learning_rate": 4.9375947507766685e-05,
      "loss": 2.4422,
      "step": 30350
    },
    {
      "epoch": 2.036777289352706,
      "eval_bleu": 21.242557526863376,
      "eval_gen_len": 28.959,
      "eval_loss": 2.935295820236206,
      "eval_runtime": 63.9759,
      "eval_samples_per_second": 15.631,
      "eval_steps_per_second": 0.985,
      "step": 30350
    },
    {
      "epoch": 2.037448407771551,
      "grad_norm": 0.68874591588974,
      "learning_rate": 4.931347872170401e-05,
      "loss": 2.4544,
      "step": 30360
    },
    {
      "epoch": 2.038119526190396,
      "grad_norm": 0.660094678401947,
      "learning_rate": 4.925103654250191e-05,
      "loss": 2.4157,
      "step": 30370
    },
    {
      "epoch": 2.038790644609241,
      "grad_norm": 0.7487196922302246,
      "learning_rate": 4.918862100293806e-05,
      "loss": 2.4376,
      "step": 30380
    },
    {
      "epoch": 2.0394617630280862,
      "grad_norm": 0.6409587860107422,
      "learning_rate": 4.912623213577632e-05,
      "loss": 2.4186,
      "step": 30390
    },
    {
      "epoch": 2.0401328814469313,
      "grad_norm": 0.6945110559463501,
      "learning_rate": 4.9063869973766374e-05,
      "loss": 2.4241,
      "step": 30400
    },
    {
      "epoch": 2.0401328814469313,
      "eval_bleu": 21.360754135145122,
      "eval_gen_len": 28.981,
      "eval_loss": 2.9314870834350586,
      "eval_runtime": 64.0887,
      "eval_samples_per_second": 15.603,
      "eval_steps_per_second": 0.983,
      "step": 30400
    },
    {
      "epoch": 2.0408039998657763,
      "grad_norm": 0.669226884841919,
      "learning_rate": 4.9001534549644045e-05,
      "loss": 2.4597,
      "step": 30410
    },
    {
      "epoch": 2.0414751182846214,
      "grad_norm": 0.7202720046043396,
      "learning_rate": 4.893922589613098e-05,
      "loss": 2.4913,
      "step": 30420
    },
    {
      "epoch": 2.0421462367034664,
      "grad_norm": 0.6403849124908447,
      "learning_rate": 4.8876944045934915e-05,
      "loss": 2.4344,
      "step": 30430
    },
    {
      "epoch": 2.0428173551223114,
      "grad_norm": 0.6883182525634766,
      "learning_rate": 4.881468903174942e-05,
      "loss": 2.4444,
      "step": 30440
    },
    {
      "epoch": 2.0434884735411565,
      "grad_norm": 0.6680882573127747,
      "learning_rate": 4.875246088625397e-05,
      "loss": 2.4412,
      "step": 30450
    },
    {
      "epoch": 2.0434884735411565,
      "eval_bleu": 21.325015221322367,
      "eval_gen_len": 28.908,
      "eval_loss": 2.931460380554199,
      "eval_runtime": 63.2371,
      "eval_samples_per_second": 15.814,
      "eval_steps_per_second": 0.996,
      "step": 30450
    },
    {
      "epoch": 2.0441595919600015,
      "grad_norm": 0.6915388703346252,
      "learning_rate": 4.869025964211398e-05,
      "loss": 2.4437,
      "step": 30460
    },
    {
      "epoch": 2.0448307103788466,
      "grad_norm": 0.7131237983703613,
      "learning_rate": 4.862808533198071e-05,
      "loss": 2.4323,
      "step": 30470
    },
    {
      "epoch": 2.045501828797691,
      "grad_norm": 0.7040827870368958,
      "learning_rate": 4.856593798849136e-05,
      "loss": 2.4174,
      "step": 30480
    },
    {
      "epoch": 2.046172947216536,
      "grad_norm": 0.6370938420295715,
      "learning_rate": 4.850381764426883e-05,
      "loss": 2.4074,
      "step": 30490
    },
    {
      "epoch": 2.0468440656353812,
      "grad_norm": 0.7230808734893799,
      "learning_rate": 4.8441724331922044e-05,
      "loss": 2.429,
      "step": 30500
    },
    {
      "epoch": 2.0468440656353812,
      "eval_bleu": 21.27582235088369,
      "eval_gen_len": 28.869,
      "eval_loss": 2.9320011138916016,
      "eval_runtime": 64.1211,
      "eval_samples_per_second": 15.596,
      "eval_steps_per_second": 0.983,
      "step": 30500
    },
    {
      "epoch": 2.0475151840542263,
      "grad_norm": 0.6589428782463074,
      "learning_rate": 4.837965808404553e-05,
      "loss": 2.453,
      "step": 30510
    },
    {
      "epoch": 2.0481863024730713,
      "grad_norm": 0.7033931016921997,
      "learning_rate": 4.831761893321978e-05,
      "loss": 2.445,
      "step": 30520
    },
    {
      "epoch": 2.0488574208919164,
      "grad_norm": 0.6057621836662292,
      "learning_rate": 4.825560691201094e-05,
      "loss": 2.4309,
      "step": 30530
    },
    {
      "epoch": 2.0495285393107614,
      "grad_norm": 0.7132351994514465,
      "learning_rate": 4.819362205297098e-05,
      "loss": 2.454,
      "step": 30540
    },
    {
      "epoch": 2.0501996577296064,
      "grad_norm": 0.7212188243865967,
      "learning_rate": 4.8131664388637554e-05,
      "loss": 2.3955,
      "step": 30550
    },
    {
      "epoch": 2.0501996577296064,
      "eval_bleu": 21.666637985320317,
      "eval_gen_len": 28.951,
      "eval_loss": 2.930753231048584,
      "eval_runtime": 64.2264,
      "eval_samples_per_second": 15.57,
      "eval_steps_per_second": 0.981,
      "step": 30550
    },
    {
      "epoch": 2.0508707761484515,
      "grad_norm": 0.6673244833946228,
      "learning_rate": 4.806973395153415e-05,
      "loss": 2.451,
      "step": 30560
    },
    {
      "epoch": 2.0515418945672965,
      "grad_norm": 0.6346376538276672,
      "learning_rate": 4.8007830774169804e-05,
      "loss": 2.4152,
      "step": 30570
    },
    {
      "epoch": 2.0522130129861416,
      "grad_norm": 0.6911000609397888,
      "learning_rate": 4.794595488903944e-05,
      "loss": 2.4809,
      "step": 30580
    },
    {
      "epoch": 2.0528841314049866,
      "grad_norm": 0.692207932472229,
      "learning_rate": 4.7884106328623434e-05,
      "loss": 2.4388,
      "step": 30590
    },
    {
      "epoch": 2.053555249823831,
      "grad_norm": 0.7243069410324097,
      "learning_rate": 4.7822285125388046e-05,
      "loss": 2.456,
      "step": 30600
    },
    {
      "epoch": 2.053555249823831,
      "eval_bleu": 21.574002562723827,
      "eval_gen_len": 29.06,
      "eval_loss": 2.9290945529937744,
      "eval_runtime": 64.2922,
      "eval_samples_per_second": 15.554,
      "eval_steps_per_second": 0.98,
      "step": 30600
    },
    {
      "epoch": 2.0542263682426762,
      "grad_norm": 0.6864482164382935,
      "learning_rate": 4.776049131178501e-05,
      "loss": 2.4817,
      "step": 30610
    },
    {
      "epoch": 2.0548974866615213,
      "grad_norm": 0.6098374724388123,
      "learning_rate": 4.7698724920251726e-05,
      "loss": 2.4257,
      "step": 30620
    },
    {
      "epoch": 2.0555686050803663,
      "grad_norm": 0.6950147747993469,
      "learning_rate": 4.763698598321117e-05,
      "loss": 2.4411,
      "step": 30630
    },
    {
      "epoch": 2.0562397234992114,
      "grad_norm": 0.7017108201980591,
      "learning_rate": 4.757527453307202e-05,
      "loss": 2.4413,
      "step": 30640
    },
    {
      "epoch": 2.0569108419180564,
      "grad_norm": 0.6634621620178223,
      "learning_rate": 4.7513590602228395e-05,
      "loss": 2.4645,
      "step": 30650
    },
    {
      "epoch": 2.0569108419180564,
      "eval_bleu": 21.261571842108008,
      "eval_gen_len": 28.901,
      "eval_loss": 2.9320120811462402,
      "eval_runtime": 63.4282,
      "eval_samples_per_second": 15.766,
      "eval_steps_per_second": 0.993,
      "step": 30650
    },
    {
      "epoch": 2.0575819603369014,
      "grad_norm": 0.6615058183670044,
      "learning_rate": 4.745193422306007e-05,
      "loss": 2.4635,
      "step": 30660
    },
    {
      "epoch": 2.0582530787557465,
      "grad_norm": 0.7093840837478638,
      "learning_rate": 4.7390305427932246e-05,
      "loss": 2.4258,
      "step": 30670
    },
    {
      "epoch": 2.0589241971745915,
      "grad_norm": 0.7305189967155457,
      "learning_rate": 4.732870424919579e-05,
      "loss": 2.4962,
      "step": 30680
    },
    {
      "epoch": 2.0595953155934366,
      "grad_norm": 0.6334673762321472,
      "learning_rate": 4.7267130719186906e-05,
      "loss": 2.4295,
      "step": 30690
    },
    {
      "epoch": 2.0602664340122816,
      "grad_norm": 0.6333949565887451,
      "learning_rate": 4.720558487022744e-05,
      "loss": 2.4253,
      "step": 30700
    },
    {
      "epoch": 2.0602664340122816,
      "eval_bleu": 21.47366637193026,
      "eval_gen_len": 28.921,
      "eval_loss": 2.9327237606048584,
      "eval_runtime": 64.409,
      "eval_samples_per_second": 15.526,
      "eval_steps_per_second": 0.978,
      "step": 30700
    },
    {
      "epoch": 2.0609375524311266,
      "grad_norm": 0.710871696472168,
      "learning_rate": 4.7144066734624616e-05,
      "loss": 2.4758,
      "step": 30710
    },
    {
      "epoch": 2.0616086708499717,
      "grad_norm": 0.6663573384284973,
      "learning_rate": 4.7082576344671106e-05,
      "loss": 2.4574,
      "step": 30720
    },
    {
      "epoch": 2.0622797892688163,
      "grad_norm": 0.6923354268074036,
      "learning_rate": 4.702111373264503e-05,
      "loss": 2.4135,
      "step": 30730
    },
    {
      "epoch": 2.0629509076876613,
      "grad_norm": 0.6845311522483826,
      "learning_rate": 4.695967893080999e-05,
      "loss": 2.4279,
      "step": 30740
    },
    {
      "epoch": 2.0636220261065064,
      "grad_norm": 0.7252792716026306,
      "learning_rate": 4.689827197141492e-05,
      "loss": 2.4894,
      "step": 30750
    },
    {
      "epoch": 2.0636220261065064,
      "eval_bleu": 21.48018356362656,
      "eval_gen_len": 28.963,
      "eval_loss": 2.93119740486145,
      "eval_runtime": 63.8518,
      "eval_samples_per_second": 15.661,
      "eval_steps_per_second": 0.987,
      "step": 30750
    },
    {
      "epoch": 2.0642931445253514,
      "grad_norm": 0.6610584259033203,
      "learning_rate": 4.68368928866941e-05,
      "loss": 2.4615,
      "step": 30760
    },
    {
      "epoch": 2.0649642629441964,
      "grad_norm": 0.6340013742446899,
      "learning_rate": 4.677554170886733e-05,
      "loss": 2.4558,
      "step": 30770
    },
    {
      "epoch": 2.0656353813630415,
      "grad_norm": 0.635384202003479,
      "learning_rate": 4.671421847013959e-05,
      "loss": 2.4454,
      "step": 30780
    },
    {
      "epoch": 2.0663064997818865,
      "grad_norm": 0.698637068271637,
      "learning_rate": 4.6652923202701325e-05,
      "loss": 2.4554,
      "step": 30790
    },
    {
      "epoch": 2.0669776182007316,
      "grad_norm": 0.6429011225700378,
      "learning_rate": 4.659165593872822e-05,
      "loss": 2.4242,
      "step": 30800
    },
    {
      "epoch": 2.0669776182007316,
      "eval_bleu": 21.23695762258658,
      "eval_gen_len": 28.8,
      "eval_loss": 2.930607318878174,
      "eval_runtime": 63.2499,
      "eval_samples_per_second": 15.81,
      "eval_steps_per_second": 0.996,
      "step": 30800
    },
    {
      "epoch": 2.0676487366195766,
      "grad_norm": 0.6853945851325989,
      "learning_rate": 4.653041671038127e-05,
      "loss": 2.4327,
      "step": 30810
    },
    {
      "epoch": 2.0683198550384216,
      "grad_norm": 0.6932280659675598,
      "learning_rate": 4.646920554980675e-05,
      "loss": 2.4112,
      "step": 30820
    },
    {
      "epoch": 2.0689909734572667,
      "grad_norm": 0.6658597588539124,
      "learning_rate": 4.640802248913626e-05,
      "loss": 2.4587,
      "step": 30830
    },
    {
      "epoch": 2.0696620918761117,
      "grad_norm": 0.6803735494613647,
      "learning_rate": 4.6346867560486565e-05,
      "loss": 2.4524,
      "step": 30840
    },
    {
      "epoch": 2.0703332102949563,
      "grad_norm": 0.6484602093696594,
      "learning_rate": 4.628574079595974e-05,
      "loss": 2.4532,
      "step": 30850
    },
    {
      "epoch": 2.0703332102949563,
      "eval_bleu": 21.44603904863644,
      "eval_gen_len": 28.891,
      "eval_loss": 2.9290049076080322,
      "eval_runtime": 63.5382,
      "eval_samples_per_second": 15.739,
      "eval_steps_per_second": 0.992,
      "step": 30850
    },
    {
      "epoch": 2.0710043287138014,
      "grad_norm": 0.7323427796363831,
      "learning_rate": 4.6224642227643e-05,
      "loss": 2.423,
      "step": 30860
    },
    {
      "epoch": 2.0716754471326464,
      "grad_norm": 0.6935702562332153,
      "learning_rate": 4.616357188760885e-05,
      "loss": 2.4591,
      "step": 30870
    },
    {
      "epoch": 2.0723465655514914,
      "grad_norm": 0.7162789106369019,
      "learning_rate": 4.610252980791489e-05,
      "loss": 2.4577,
      "step": 30880
    },
    {
      "epoch": 2.0730176839703365,
      "grad_norm": 0.6814895868301392,
      "learning_rate": 4.6041516020603934e-05,
      "loss": 2.4355,
      "step": 30890
    },
    {
      "epoch": 2.0736888023891815,
      "grad_norm": 0.7075066566467285,
      "learning_rate": 4.598053055770388e-05,
      "loss": 2.453,
      "step": 30900
    },
    {
      "epoch": 2.0736888023891815,
      "eval_bleu": 21.398408937759935,
      "eval_gen_len": 29.02,
      "eval_loss": 2.931403636932373,
      "eval_runtime": 65.2595,
      "eval_samples_per_second": 15.323,
      "eval_steps_per_second": 0.965,
      "step": 30900
    },
    {
      "epoch": 2.0743599208080266,
      "grad_norm": 0.613200843334198,
      "learning_rate": 4.59195734512279e-05,
      "loss": 2.4611,
      "step": 30910
    },
    {
      "epoch": 2.0750310392268716,
      "grad_norm": 0.6911987662315369,
      "learning_rate": 4.58586447331741e-05,
      "loss": 2.4195,
      "step": 30920
    },
    {
      "epoch": 2.0757021576457166,
      "grad_norm": 0.6227709054946899,
      "learning_rate": 4.579774443552586e-05,
      "loss": 2.4062,
      "step": 30930
    },
    {
      "epoch": 2.0763732760645617,
      "grad_norm": 0.6757786870002747,
      "learning_rate": 4.573687259025147e-05,
      "loss": 2.4795,
      "step": 30940
    },
    {
      "epoch": 2.0770443944834067,
      "grad_norm": 0.6243372559547424,
      "learning_rate": 4.5676029229304443e-05,
      "loss": 2.4881,
      "step": 30950
    },
    {
      "epoch": 2.0770443944834067,
      "eval_bleu": 21.473832699058825,
      "eval_gen_len": 28.86,
      "eval_loss": 2.9338538646698,
      "eval_runtime": 63.8596,
      "eval_samples_per_second": 15.659,
      "eval_steps_per_second": 0.987,
      "step": 30950
    },
    {
      "epoch": 2.0777155129022518,
      "grad_norm": 0.6994609832763672,
      "learning_rate": 4.5615214384623236e-05,
      "loss": 2.4751,
      "step": 30960
    },
    {
      "epoch": 2.078386631321097,
      "grad_norm": 0.6362417340278625,
      "learning_rate": 4.555442808813136e-05,
      "loss": 2.4168,
      "step": 30970
    },
    {
      "epoch": 2.079057749739942,
      "grad_norm": 0.6767745018005371,
      "learning_rate": 4.549367037173733e-05,
      "loss": 2.4603,
      "step": 30980
    },
    {
      "epoch": 2.0797288681587864,
      "grad_norm": 0.6780481934547424,
      "learning_rate": 4.543294126733473e-05,
      "loss": 2.4105,
      "step": 30990
    },
    {
      "epoch": 2.0803999865776315,
      "grad_norm": 0.7281222939491272,
      "learning_rate": 4.5372240806802e-05,
      "loss": 2.4651,
      "step": 31000
    },
    {
      "epoch": 2.0803999865776315,
      "eval_bleu": 21.255173857593146,
      "eval_gen_len": 28.909,
      "eval_loss": 2.9333536624908447,
      "eval_runtime": 64.2301,
      "eval_samples_per_second": 15.569,
      "eval_steps_per_second": 0.981,
      "step": 31000
    },
    {
      "epoch": 2.0810711049964765,
      "grad_norm": 0.710312008857727,
      "learning_rate": 4.53115690220027e-05,
      "loss": 2.4347,
      "step": 31010
    },
    {
      "epoch": 2.0817422234153216,
      "grad_norm": 0.6964601874351501,
      "learning_rate": 4.525092594478516e-05,
      "loss": 2.426,
      "step": 31020
    },
    {
      "epoch": 2.0824133418341666,
      "grad_norm": 0.7295168042182922,
      "learning_rate": 4.519031160698282e-05,
      "loss": 2.4501,
      "step": 31030
    },
    {
      "epoch": 2.0830844602530116,
      "grad_norm": 0.6837360262870789,
      "learning_rate": 4.512972604041387e-05,
      "loss": 2.4778,
      "step": 31040
    },
    {
      "epoch": 2.0837555786718567,
      "grad_norm": 0.7071671485900879,
      "learning_rate": 4.506916927688154e-05,
      "loss": 2.4384,
      "step": 31050
    },
    {
      "epoch": 2.0837555786718567,
      "eval_bleu": 21.260180672266895,
      "eval_gen_len": 28.92,
      "eval_loss": 2.9315571784973145,
      "eval_runtime": 64.0021,
      "eval_samples_per_second": 15.624,
      "eval_steps_per_second": 0.984,
      "step": 31050
    },
    {
      "epoch": 2.0844266970907017,
      "grad_norm": 0.711134135723114,
      "learning_rate": 4.500864134817384e-05,
      "loss": 2.4482,
      "step": 31060
    },
    {
      "epoch": 2.0850978155095468,
      "grad_norm": 0.6839324235916138,
      "learning_rate": 4.4948142286063686e-05,
      "loss": 2.404,
      "step": 31070
    },
    {
      "epoch": 2.085768933928392,
      "grad_norm": 0.6976897120475769,
      "learning_rate": 4.488767212230883e-05,
      "loss": 2.431,
      "step": 31080
    },
    {
      "epoch": 2.086440052347237,
      "grad_norm": 0.6271694302558899,
      "learning_rate": 4.4827230888651815e-05,
      "loss": 2.4418,
      "step": 31090
    },
    {
      "epoch": 2.087111170766082,
      "grad_norm": 0.7318156957626343,
      "learning_rate": 4.4766818616820115e-05,
      "loss": 2.5081,
      "step": 31100
    },
    {
      "epoch": 2.087111170766082,
      "eval_bleu": 21.256211145780163,
      "eval_gen_len": 28.811,
      "eval_loss": 2.930175304412842,
      "eval_runtime": 64.7067,
      "eval_samples_per_second": 15.454,
      "eval_steps_per_second": 0.974,
      "step": 31100
    },
    {
      "epoch": 2.0877822891849265,
      "grad_norm": 0.735933780670166,
      "learning_rate": 4.470643533852586e-05,
      "loss": 2.4312,
      "step": 31110
    },
    {
      "epoch": 2.0884534076037715,
      "grad_norm": 0.7783334255218506,
      "learning_rate": 4.464608108546607e-05,
      "loss": 2.5041,
      "step": 31120
    },
    {
      "epoch": 2.0891245260226166,
      "grad_norm": 0.7403676509857178,
      "learning_rate": 4.4585755889322456e-05,
      "loss": 2.4928,
      "step": 31130
    },
    {
      "epoch": 2.0897956444414616,
      "grad_norm": 0.6822941303253174,
      "learning_rate": 4.4525459781761544e-05,
      "loss": 2.484,
      "step": 31140
    },
    {
      "epoch": 2.0904667628603066,
      "grad_norm": 0.7053359746932983,
      "learning_rate": 4.446519279443454e-05,
      "loss": 2.4397,
      "step": 31150
    },
    {
      "epoch": 2.0904667628603066,
      "eval_bleu": 21.31638632737603,
      "eval_gen_len": 28.91,
      "eval_loss": 2.93161940574646,
      "eval_runtime": 64.0941,
      "eval_samples_per_second": 15.602,
      "eval_steps_per_second": 0.983,
      "step": 31150
    },
    {
      "epoch": 2.0911378812791517,
      "grad_norm": 0.6926044225692749,
      "learning_rate": 4.4404954958977364e-05,
      "loss": 2.4852,
      "step": 31160
    },
    {
      "epoch": 2.0918089996979967,
      "grad_norm": 0.7022639513015747,
      "learning_rate": 4.43447463070106e-05,
      "loss": 2.4623,
      "step": 31170
    },
    {
      "epoch": 2.0924801181168418,
      "grad_norm": 0.6760777235031128,
      "learning_rate": 4.428456687013964e-05,
      "loss": 2.4383,
      "step": 31180
    },
    {
      "epoch": 2.093151236535687,
      "grad_norm": 0.6955991983413696,
      "learning_rate": 4.42244166799544e-05,
      "loss": 2.4567,
      "step": 31190
    },
    {
      "epoch": 2.093822354954532,
      "grad_norm": 0.6598815321922302,
      "learning_rate": 4.416429576802954e-05,
      "loss": 2.4267,
      "step": 31200
    },
    {
      "epoch": 2.093822354954532,
      "eval_bleu": 21.145021976138423,
      "eval_gen_len": 28.89,
      "eval_loss": 2.930769920349121,
      "eval_runtime": 64.1095,
      "eval_samples_per_second": 15.598,
      "eval_steps_per_second": 0.983,
      "step": 31200
    },
    {
      "epoch": 2.094493473373377,
      "grad_norm": 0.6924058198928833,
      "learning_rate": 4.4104204165924255e-05,
      "loss": 2.4147,
      "step": 31210
    },
    {
      "epoch": 2.095164591792222,
      "grad_norm": 0.7000871300697327,
      "learning_rate": 4.4044141905182504e-05,
      "loss": 2.4544,
      "step": 31220
    },
    {
      "epoch": 2.095835710211067,
      "grad_norm": 0.7283041477203369,
      "learning_rate": 4.398410901733269e-05,
      "loss": 2.3991,
      "step": 31230
    },
    {
      "epoch": 2.0965068286299116,
      "grad_norm": 0.6898726224899292,
      "learning_rate": 4.392410553388787e-05,
      "loss": 2.4439,
      "step": 31240
    },
    {
      "epoch": 2.0971779470487566,
      "grad_norm": 0.7426155805587769,
      "learning_rate": 4.3864131486345614e-05,
      "loss": 2.4738,
      "step": 31250
    },
    {
      "epoch": 2.0971779470487566,
      "eval_bleu": 20.99379743588171,
      "eval_gen_len": 28.877,
      "eval_loss": 2.931454658508301,
      "eval_runtime": 64.1535,
      "eval_samples_per_second": 15.588,
      "eval_steps_per_second": 0.982,
      "step": 31250
    },
    {
      "epoch": 2.0978490654676016,
      "grad_norm": 0.7077264785766602,
      "learning_rate": 4.380418690618816e-05,
      "loss": 2.4423,
      "step": 31260
    },
    {
      "epoch": 2.0985201838864467,
      "grad_norm": 0.7224109768867493,
      "learning_rate": 4.374427182488212e-05,
      "loss": 2.459,
      "step": 31270
    },
    {
      "epoch": 2.0991913023052917,
      "grad_norm": 0.6456772089004517,
      "learning_rate": 4.368438627387877e-05,
      "loss": 2.4752,
      "step": 31280
    },
    {
      "epoch": 2.0998624207241368,
      "grad_norm": 0.7400429248809814,
      "learning_rate": 4.3624530284613754e-05,
      "loss": 2.4305,
      "step": 31290
    },
    {
      "epoch": 2.100533539142982,
      "grad_norm": 0.6309852004051208,
      "learning_rate": 4.356470388850732e-05,
      "loss": 2.4566,
      "step": 31300
    },
    {
      "epoch": 2.100533539142982,
      "eval_bleu": 21.228464304873043,
      "eval_gen_len": 28.927,
      "eval_loss": 2.931352138519287,
      "eval_runtime": 64.1508,
      "eval_samples_per_second": 15.588,
      "eval_steps_per_second": 0.982,
      "step": 31300
    },
    {
      "epoch": 2.101204657561827,
      "grad_norm": 0.6915062069892883,
      "learning_rate": 4.3504907116964045e-05,
      "loss": 2.4864,
      "step": 31310
    },
    {
      "epoch": 2.101875775980672,
      "grad_norm": 0.6719847917556763,
      "learning_rate": 4.344514000137312e-05,
      "loss": 2.4158,
      "step": 31320
    },
    {
      "epoch": 2.102546894399517,
      "grad_norm": 0.6786186099052429,
      "learning_rate": 4.338540257310803e-05,
      "loss": 2.4606,
      "step": 31330
    },
    {
      "epoch": 2.103218012818362,
      "grad_norm": 0.6851091980934143,
      "learning_rate": 4.332569486352671e-05,
      "loss": 2.4222,
      "step": 31340
    },
    {
      "epoch": 2.103889131237207,
      "grad_norm": 0.729886531829834,
      "learning_rate": 4.326601690397155e-05,
      "loss": 2.4466,
      "step": 31350
    },
    {
      "epoch": 2.103889131237207,
      "eval_bleu": 21.023883760765703,
      "eval_gen_len": 28.848,
      "eval_loss": 2.9341092109680176,
      "eval_runtime": 64.3878,
      "eval_samples_per_second": 15.531,
      "eval_steps_per_second": 0.978,
      "step": 31350
    },
    {
      "epoch": 2.1045602496560516,
      "grad_norm": 0.7147221565246582,
      "learning_rate": 4.3206368725769216e-05,
      "loss": 2.4025,
      "step": 31360
    },
    {
      "epoch": 2.1052313680748966,
      "grad_norm": 0.7586347460746765,
      "learning_rate": 4.314675036023089e-05,
      "loss": 2.4222,
      "step": 31370
    },
    {
      "epoch": 2.1059024864937417,
      "grad_norm": 0.6879964470863342,
      "learning_rate": 4.308716183865196e-05,
      "loss": 2.4418,
      "step": 31380
    },
    {
      "epoch": 2.1065736049125867,
      "grad_norm": 0.662347137928009,
      "learning_rate": 4.302760319231226e-05,
      "loss": 2.4538,
      "step": 31390
    },
    {
      "epoch": 2.1072447233314318,
      "grad_norm": 0.6784504652023315,
      "learning_rate": 4.2968074452475834e-05,
      "loss": 2.449,
      "step": 31400
    },
    {
      "epoch": 2.1072447233314318,
      "eval_bleu": 20.78018858993453,
      "eval_gen_len": 28.845,
      "eval_loss": 2.9344735145568848,
      "eval_runtime": 64.4934,
      "eval_samples_per_second": 15.505,
      "eval_steps_per_second": 0.977,
      "step": 31400
    },
    {
      "epoch": 2.107915841750277,
      "grad_norm": 0.6731408834457397,
      "learning_rate": 4.290857565039117e-05,
      "loss": 2.4512,
      "step": 31410
    },
    {
      "epoch": 2.108586960169122,
      "grad_norm": 0.7450464367866516,
      "learning_rate": 4.2849106817290896e-05,
      "loss": 2.4117,
      "step": 31420
    },
    {
      "epoch": 2.109258078587967,
      "grad_norm": 0.6756004095077515,
      "learning_rate": 4.278966798439199e-05,
      "loss": 2.421,
      "step": 31430
    },
    {
      "epoch": 2.109929197006812,
      "grad_norm": 0.6366719007492065,
      "learning_rate": 4.273025918289562e-05,
      "loss": 2.4316,
      "step": 31440
    },
    {
      "epoch": 2.110600315425657,
      "grad_norm": 0.6958860754966736,
      "learning_rate": 4.267088044398729e-05,
      "loss": 2.4829,
      "step": 31450
    },
    {
      "epoch": 2.110600315425657,
      "eval_bleu": 21.318749371351338,
      "eval_gen_len": 28.961,
      "eval_loss": 2.9308278560638428,
      "eval_runtime": 65.3142,
      "eval_samples_per_second": 15.311,
      "eval_steps_per_second": 0.965,
      "step": 31450
    },
    {
      "epoch": 2.111271433844502,
      "grad_norm": 0.6264051795005798,
      "learning_rate": 4.26115317988366e-05,
      "loss": 2.4556,
      "step": 31460
    },
    {
      "epoch": 2.111942552263347,
      "grad_norm": 0.702157735824585,
      "learning_rate": 4.2552213278597496e-05,
      "loss": 2.4661,
      "step": 31470
    },
    {
      "epoch": 2.112613670682192,
      "grad_norm": 0.699770450592041,
      "learning_rate": 4.249292491440794e-05,
      "loss": 2.452,
      "step": 31480
    },
    {
      "epoch": 2.1132847891010367,
      "grad_norm": 0.7038381695747375,
      "learning_rate": 4.243366673739025e-05,
      "loss": 2.4118,
      "step": 31490
    },
    {
      "epoch": 2.1139559075198817,
      "grad_norm": 0.6314322352409363,
      "learning_rate": 4.237443877865075e-05,
      "loss": 2.3971,
      "step": 31500
    },
    {
      "epoch": 2.1139559075198817,
      "eval_bleu": 20.98571891759671,
      "eval_gen_len": 28.829,
      "eval_loss": 2.9317309856414795,
      "eval_runtime": 63.7259,
      "eval_samples_per_second": 15.692,
      "eval_steps_per_second": 0.989,
      "step": 31500
    },
    {
      "epoch": 2.1146270259387268,
      "grad_norm": 0.6301871538162231,
      "learning_rate": 4.2315241069279966e-05,
      "loss": 2.4638,
      "step": 31510
    },
    {
      "epoch": 2.115298144357572,
      "grad_norm": 0.6885620355606079,
      "learning_rate": 4.22560736403525e-05,
      "loss": 2.4422,
      "step": 31520
    },
    {
      "epoch": 2.115969262776417,
      "grad_norm": 0.6761425137519836,
      "learning_rate": 4.219693652292714e-05,
      "loss": 2.4571,
      "step": 31530
    },
    {
      "epoch": 2.116640381195262,
      "grad_norm": 0.7231841087341309,
      "learning_rate": 4.213782974804667e-05,
      "loss": 2.4427,
      "step": 31540
    },
    {
      "epoch": 2.117311499614107,
      "grad_norm": 0.6761470437049866,
      "learning_rate": 4.2078753346738066e-05,
      "loss": 2.4465,
      "step": 31550
    },
    {
      "epoch": 2.117311499614107,
      "eval_bleu": 21.310616303983643,
      "eval_gen_len": 28.932,
      "eval_loss": 2.9301326274871826,
      "eval_runtime": 64.373,
      "eval_samples_per_second": 15.534,
      "eval_steps_per_second": 0.979,
      "step": 31550
    },
    {
      "epoch": 2.117982618032952,
      "grad_norm": 0.7030905485153198,
      "learning_rate": 4.201970735001221e-05,
      "loss": 2.4289,
      "step": 31560
    },
    {
      "epoch": 2.118653736451797,
      "grad_norm": 0.6787284016609192,
      "learning_rate": 4.196069178886414e-05,
      "loss": 2.4766,
      "step": 31570
    },
    {
      "epoch": 2.119324854870642,
      "grad_norm": 0.7357391715049744,
      "learning_rate": 4.190170669427285e-05,
      "loss": 2.4288,
      "step": 31580
    },
    {
      "epoch": 2.119995973289487,
      "grad_norm": 0.7612387537956238,
      "learning_rate": 4.184275209720144e-05,
      "loss": 2.4435,
      "step": 31590
    },
    {
      "epoch": 2.120667091708332,
      "grad_norm": 0.7044357657432556,
      "learning_rate": 4.17838280285968e-05,
      "loss": 2.4279,
      "step": 31600
    },
    {
      "epoch": 2.120667091708332,
      "eval_bleu": 21.05282120784223,
      "eval_gen_len": 28.917,
      "eval_loss": 2.931710720062256,
      "eval_runtime": 63.6221,
      "eval_samples_per_second": 15.718,
      "eval_steps_per_second": 0.99,
      "step": 31600
    },
    {
      "epoch": 2.1213382101271767,
      "grad_norm": 0.7192184925079346,
      "learning_rate": 4.172493451939005e-05,
      "loss": 2.4303,
      "step": 31610
    },
    {
      "epoch": 2.1220093285460218,
      "grad_norm": 0.6446118354797363,
      "learning_rate": 4.166607160049604e-05,
      "loss": 2.4106,
      "step": 31620
    },
    {
      "epoch": 2.122680446964867,
      "grad_norm": 0.6953124403953552,
      "learning_rate": 4.160723930281375e-05,
      "loss": 2.4756,
      "step": 31630
    },
    {
      "epoch": 2.123351565383712,
      "grad_norm": 0.7171499729156494,
      "learning_rate": 4.154843765722597e-05,
      "loss": 2.4601,
      "step": 31640
    },
    {
      "epoch": 2.124022683802557,
      "grad_norm": 0.6698951125144958,
      "learning_rate": 4.1489666694599384e-05,
      "loss": 2.4388,
      "step": 31650
    },
    {
      "epoch": 2.124022683802557,
      "eval_bleu": 20.92929897165536,
      "eval_gen_len": 28.824,
      "eval_loss": 2.9336771965026855,
      "eval_runtime": 63.7686,
      "eval_samples_per_second": 15.682,
      "eval_steps_per_second": 0.988,
      "step": 31650
    },
    {
      "epoch": 2.124693802221402,
      "grad_norm": 0.6876211762428284,
      "learning_rate": 4.14309264457847e-05,
      "loss": 2.4525,
      "step": 31660
    },
    {
      "epoch": 2.125364920640247,
      "grad_norm": 0.765747606754303,
      "learning_rate": 4.137221694161634e-05,
      "loss": 2.4511,
      "step": 31670
    },
    {
      "epoch": 2.126036039059092,
      "grad_norm": 0.6788392066955566,
      "learning_rate": 4.131353821291273e-05,
      "loss": 2.3956,
      "step": 31680
    },
    {
      "epoch": 2.126707157477937,
      "grad_norm": 0.7079627513885498,
      "learning_rate": 4.125489029047605e-05,
      "loss": 2.4504,
      "step": 31690
    },
    {
      "epoch": 2.127378275896782,
      "grad_norm": 0.6657134294509888,
      "learning_rate": 4.119627320509234e-05,
      "loss": 2.3918,
      "step": 31700
    },
    {
      "epoch": 2.127378275896782,
      "eval_bleu": 21.201194256944223,
      "eval_gen_len": 28.89,
      "eval_loss": 2.9303462505340576,
      "eval_runtime": 64.4428,
      "eval_samples_per_second": 15.518,
      "eval_steps_per_second": 0.978,
      "step": 31700
    },
    {
      "epoch": 2.128049394315627,
      "grad_norm": 0.6483839750289917,
      "learning_rate": 4.113768698753141e-05,
      "loss": 2.4239,
      "step": 31710
    },
    {
      "epoch": 2.128720512734472,
      "grad_norm": 0.7414226531982422,
      "learning_rate": 4.107913166854698e-05,
      "loss": 2.4193,
      "step": 31720
    },
    {
      "epoch": 2.129391631153317,
      "grad_norm": 0.6368052363395691,
      "learning_rate": 4.1020607278876386e-05,
      "loss": 2.4413,
      "step": 31730
    },
    {
      "epoch": 2.1300627495721622,
      "grad_norm": 0.7042990922927856,
      "learning_rate": 4.0962113849240926e-05,
      "loss": 2.4935,
      "step": 31740
    },
    {
      "epoch": 2.130733867991007,
      "grad_norm": 0.7552844285964966,
      "learning_rate": 4.0903651410345435e-05,
      "loss": 2.4311,
      "step": 31750
    },
    {
      "epoch": 2.130733867991007,
      "eval_bleu": 21.236315452137163,
      "eval_gen_len": 28.959,
      "eval_loss": 2.929675579071045,
      "eval_runtime": 64.1628,
      "eval_samples_per_second": 15.585,
      "eval_steps_per_second": 0.982,
      "step": 31750
    },
    {
      "epoch": 2.131404986409852,
      "grad_norm": 0.7018269896507263,
      "learning_rate": 4.084521999287867e-05,
      "loss": 2.4683,
      "step": 31760
    },
    {
      "epoch": 2.132076104828697,
      "grad_norm": 0.7574427127838135,
      "learning_rate": 4.078681962751299e-05,
      "loss": 2.4772,
      "step": 31770
    },
    {
      "epoch": 2.132747223247542,
      "grad_norm": 0.7195383310317993,
      "learning_rate": 4.0728450344904455e-05,
      "loss": 2.4345,
      "step": 31780
    },
    {
      "epoch": 2.133418341666387,
      "grad_norm": 0.667176365852356,
      "learning_rate": 4.067011217569282e-05,
      "loss": 2.4435,
      "step": 31790
    },
    {
      "epoch": 2.134089460085232,
      "grad_norm": 0.721644937992096,
      "learning_rate": 4.061180515050158e-05,
      "loss": 2.4482,
      "step": 31800
    },
    {
      "epoch": 2.134089460085232,
      "eval_bleu": 21.151726272356512,
      "eval_gen_len": 28.912,
      "eval_loss": 2.932323694229126,
      "eval_runtime": 63.8564,
      "eval_samples_per_second": 15.66,
      "eval_steps_per_second": 0.987,
      "step": 31800
    },
    {
      "epoch": 2.134760578504077,
      "grad_norm": 0.6701828241348267,
      "learning_rate": 4.055352929993778e-05,
      "loss": 2.4255,
      "step": 31810
    },
    {
      "epoch": 2.135431696922922,
      "grad_norm": 0.6497284173965454,
      "learning_rate": 4.049528465459218e-05,
      "loss": 2.4608,
      "step": 31820
    },
    {
      "epoch": 2.136102815341767,
      "grad_norm": 0.6837084889411926,
      "learning_rate": 4.043707124503908e-05,
      "loss": 2.4267,
      "step": 31830
    },
    {
      "epoch": 2.136773933760612,
      "grad_norm": 0.6960716843605042,
      "learning_rate": 4.037888910183649e-05,
      "loss": 2.4183,
      "step": 31840
    },
    {
      "epoch": 2.1374450521794572,
      "grad_norm": 0.7089048624038696,
      "learning_rate": 4.032073825552591e-05,
      "loss": 2.4221,
      "step": 31850
    },
    {
      "epoch": 2.1374450521794572,
      "eval_bleu": 21.175800648164742,
      "eval_gen_len": 28.888,
      "eval_loss": 2.931487798690796,
      "eval_runtime": 64.0815,
      "eval_samples_per_second": 15.605,
      "eval_steps_per_second": 0.983,
      "step": 31850
    },
    {
      "epoch": 2.138116170598302,
      "grad_norm": 0.7272605299949646,
      "learning_rate": 4.0262618736632454e-05,
      "loss": 2.4335,
      "step": 31860
    },
    {
      "epoch": 2.138787289017147,
      "grad_norm": 0.6458904147148132,
      "learning_rate": 4.020453057566473e-05,
      "loss": 2.4377,
      "step": 31870
    },
    {
      "epoch": 2.139458407435992,
      "grad_norm": 0.7716952562332153,
      "learning_rate": 4.0146473803115026e-05,
      "loss": 2.4525,
      "step": 31880
    },
    {
      "epoch": 2.140129525854837,
      "grad_norm": 0.6992404460906982,
      "learning_rate": 4.0088448449458984e-05,
      "loss": 2.4421,
      "step": 31890
    },
    {
      "epoch": 2.140800644273682,
      "grad_norm": 0.7332804799079895,
      "learning_rate": 4.003045454515592e-05,
      "loss": 2.4389,
      "step": 31900
    },
    {
      "epoch": 2.140800644273682,
      "eval_bleu": 21.22126283606922,
      "eval_gen_len": 28.948,
      "eval_loss": 2.9317989349365234,
      "eval_runtime": 64.0878,
      "eval_samples_per_second": 15.604,
      "eval_steps_per_second": 0.983,
      "step": 31900
    },
    {
      "epoch": 2.141471762692527,
      "grad_norm": 0.7468602657318115,
      "learning_rate": 3.9972492120648475e-05,
      "loss": 2.4209,
      "step": 31910
    },
    {
      "epoch": 2.142142881111372,
      "grad_norm": 0.7144397497177124,
      "learning_rate": 3.991456120636292e-05,
      "loss": 2.4259,
      "step": 31920
    },
    {
      "epoch": 2.142813999530217,
      "grad_norm": 0.8089730143547058,
      "learning_rate": 3.985666183270889e-05,
      "loss": 2.4288,
      "step": 31930
    },
    {
      "epoch": 2.143485117949062,
      "grad_norm": 0.6890618801116943,
      "learning_rate": 3.979879403007942e-05,
      "loss": 2.4429,
      "step": 31940
    },
    {
      "epoch": 2.144156236367907,
      "grad_norm": 0.6781716346740723,
      "learning_rate": 3.974095782885114e-05,
      "loss": 2.4214,
      "step": 31950
    },
    {
      "epoch": 2.144156236367907,
      "eval_bleu": 21.05945919053602,
      "eval_gen_len": 28.791,
      "eval_loss": 2.9337222576141357,
      "eval_runtime": 63.7474,
      "eval_samples_per_second": 15.687,
      "eval_steps_per_second": 0.988,
      "step": 31950
    },
    {
      "epoch": 2.1448273547867522,
      "grad_norm": 0.7730809450149536,
      "learning_rate": 3.968315325938394e-05,
      "loss": 2.4731,
      "step": 31960
    },
    {
      "epoch": 2.1454984732055973,
      "grad_norm": 0.698976457118988,
      "learning_rate": 3.962538035202116e-05,
      "loss": 2.3898,
      "step": 31970
    },
    {
      "epoch": 2.1461695916244423,
      "grad_norm": 0.7072219252586365,
      "learning_rate": 3.956763913708949e-05,
      "loss": 2.4111,
      "step": 31980
    },
    {
      "epoch": 2.1468407100432874,
      "grad_norm": 0.6961854100227356,
      "learning_rate": 3.950992964489905e-05,
      "loss": 2.4549,
      "step": 31990
    },
    {
      "epoch": 2.147511828462132,
      "grad_norm": 0.7278463840484619,
      "learning_rate": 3.945225190574322e-05,
      "loss": 2.4505,
      "step": 32000
    },
    {
      "epoch": 2.147511828462132,
      "eval_bleu": 20.96274422450587,
      "eval_gen_len": 28.826,
      "eval_loss": 2.9347290992736816,
      "eval_runtime": 63.4095,
      "eval_samples_per_second": 15.77,
      "eval_steps_per_second": 0.994,
      "step": 32000
    },
    {
      "epoch": 2.148182946880977,
      "grad_norm": 0.6761138439178467,
      "learning_rate": 3.939460594989882e-05,
      "loss": 2.419,
      "step": 32010
    },
    {
      "epoch": 2.148854065299822,
      "grad_norm": 0.6490866541862488,
      "learning_rate": 3.933699180762586e-05,
      "loss": 2.5232,
      "step": 32020
    },
    {
      "epoch": 2.149525183718667,
      "grad_norm": 0.7487520575523376,
      "learning_rate": 3.927940950916779e-05,
      "loss": 2.4289,
      "step": 32030
    },
    {
      "epoch": 2.150196302137512,
      "grad_norm": 0.6664422154426575,
      "learning_rate": 3.922185908475121e-05,
      "loss": 2.4706,
      "step": 32040
    },
    {
      "epoch": 2.150867420556357,
      "grad_norm": 0.7271520495414734,
      "learning_rate": 3.916434056458607e-05,
      "loss": 2.4307,
      "step": 32050
    },
    {
      "epoch": 2.150867420556357,
      "eval_bleu": 21.12515691003824,
      "eval_gen_len": 28.835,
      "eval_loss": 2.9347996711730957,
      "eval_runtime": 64.4025,
      "eval_samples_per_second": 15.527,
      "eval_steps_per_second": 0.978,
      "step": 32050
    },
    {
      "epoch": 2.151538538975202,
      "grad_norm": 0.6588574051856995,
      "learning_rate": 3.910685397886551e-05,
      "loss": 2.3898,
      "step": 32060
    },
    {
      "epoch": 2.1522096573940472,
      "grad_norm": 0.6555877923965454,
      "learning_rate": 3.9049399357766005e-05,
      "loss": 2.4371,
      "step": 32070
    },
    {
      "epoch": 2.1528807758128923,
      "grad_norm": 0.7123640775680542,
      "learning_rate": 3.899197673144713e-05,
      "loss": 2.4192,
      "step": 32080
    },
    {
      "epoch": 2.1535518942317373,
      "grad_norm": 0.7051085829734802,
      "learning_rate": 3.8934586130051806e-05,
      "loss": 2.4711,
      "step": 32090
    },
    {
      "epoch": 2.1542230126505824,
      "grad_norm": 0.7341833710670471,
      "learning_rate": 3.887722758370599e-05,
      "loss": 2.4481,
      "step": 32100
    },
    {
      "epoch": 2.1542230126505824,
      "eval_bleu": 21.123911784213952,
      "eval_gen_len": 28.887,
      "eval_loss": 2.932537794113159,
      "eval_runtime": 64.54,
      "eval_samples_per_second": 15.494,
      "eval_steps_per_second": 0.976,
      "step": 32100
    },
    {
      "epoch": 2.1548941310694274,
      "grad_norm": 0.6061317324638367,
      "learning_rate": 3.881990112251895e-05,
      "loss": 2.4287,
      "step": 32110
    },
    {
      "epoch": 2.155565249488272,
      "grad_norm": 0.7020626664161682,
      "learning_rate": 3.876260677658301e-05,
      "loss": 2.4482,
      "step": 32120
    },
    {
      "epoch": 2.156236367907117,
      "grad_norm": 0.6858350038528442,
      "learning_rate": 3.870534457597369e-05,
      "loss": 2.4839,
      "step": 32130
    },
    {
      "epoch": 2.156907486325962,
      "grad_norm": 0.6664507985115051,
      "learning_rate": 3.864811455074956e-05,
      "loss": 2.4737,
      "step": 32140
    },
    {
      "epoch": 2.157578604744807,
      "grad_norm": 0.690798282623291,
      "learning_rate": 3.8590916730952456e-05,
      "loss": 2.4661,
      "step": 32150
    },
    {
      "epoch": 2.157578604744807,
      "eval_bleu": 21.146810732941482,
      "eval_gen_len": 29.132,
      "eval_loss": 2.9324207305908203,
      "eval_runtime": 67.8305,
      "eval_samples_per_second": 14.743,
      "eval_steps_per_second": 0.929,
      "step": 32150
    },
    {
      "epoch": 2.158249723163652,
      "grad_norm": 0.6958008408546448,
      "learning_rate": 3.853375114660713e-05,
      "loss": 2.4475,
      "step": 32160
    },
    {
      "epoch": 2.158920841582497,
      "grad_norm": 0.654941737651825,
      "learning_rate": 3.847661782772156e-05,
      "loss": 2.4984,
      "step": 32170
    },
    {
      "epoch": 2.1595919600013422,
      "grad_norm": 0.6754765510559082,
      "learning_rate": 3.841951680428667e-05,
      "loss": 2.4303,
      "step": 32180
    },
    {
      "epoch": 2.1602630784201873,
      "grad_norm": 0.709986686706543,
      "learning_rate": 3.836244810627654e-05,
      "loss": 2.4001,
      "step": 32190
    },
    {
      "epoch": 2.1609341968390323,
      "grad_norm": 0.6716405749320984,
      "learning_rate": 3.830541176364815e-05,
      "loss": 2.4377,
      "step": 32200
    },
    {
      "epoch": 2.1609341968390323,
      "eval_bleu": 21.142234616025544,
      "eval_gen_len": 28.9,
      "eval_loss": 2.931442975997925,
      "eval_runtime": 64.1014,
      "eval_samples_per_second": 15.6,
      "eval_steps_per_second": 0.983,
      "step": 32200
    },
    {
      "epoch": 2.1616053152578774,
      "grad_norm": 0.754020094871521,
      "learning_rate": 3.824840780634166e-05,
      "loss": 2.5045,
      "step": 32210
    },
    {
      "epoch": 2.1622764336767224,
      "grad_norm": 0.6709893345832825,
      "learning_rate": 3.8191436264280114e-05,
      "loss": 2.3907,
      "step": 32220
    },
    {
      "epoch": 2.1629475520955674,
      "grad_norm": 0.7246510982513428,
      "learning_rate": 3.813449716736948e-05,
      "loss": 2.4468,
      "step": 32230
    },
    {
      "epoch": 2.1636186705144125,
      "grad_norm": 0.6424129009246826,
      "learning_rate": 3.8077590545498876e-05,
      "loss": 2.4044,
      "step": 32240
    },
    {
      "epoch": 2.164289788933257,
      "grad_norm": 0.7986452579498291,
      "learning_rate": 3.802071642854022e-05,
      "loss": 2.4385,
      "step": 32250
    },
    {
      "epoch": 2.164289788933257,
      "eval_bleu": 21.34966335799865,
      "eval_gen_len": 29.143,
      "eval_loss": 2.9311697483062744,
      "eval_runtime": 66.9048,
      "eval_samples_per_second": 14.947,
      "eval_steps_per_second": 0.942,
      "step": 32250
    },
    {
      "epoch": 2.164960907352102,
      "grad_norm": 0.745965301990509,
      "learning_rate": 3.796387484634849e-05,
      "loss": 2.4404,
      "step": 32260
    },
    {
      "epoch": 2.165632025770947,
      "grad_norm": 0.6881246566772461,
      "learning_rate": 3.790706582876144e-05,
      "loss": 2.4741,
      "step": 32270
    },
    {
      "epoch": 2.166303144189792,
      "grad_norm": 0.6120772957801819,
      "learning_rate": 3.7850289405599906e-05,
      "loss": 2.4688,
      "step": 32280
    },
    {
      "epoch": 2.1669742626086372,
      "grad_norm": 0.6917293667793274,
      "learning_rate": 3.7793545606667426e-05,
      "loss": 2.4305,
      "step": 32290
    },
    {
      "epoch": 2.1676453810274823,
      "grad_norm": 0.6652305126190186,
      "learning_rate": 3.773683446175058e-05,
      "loss": 2.4707,
      "step": 32300
    },
    {
      "epoch": 2.1676453810274823,
      "eval_bleu": 21.258520421328836,
      "eval_gen_len": 28.903,
      "eval_loss": 2.9305922985076904,
      "eval_runtime": 64.4605,
      "eval_samples_per_second": 15.513,
      "eval_steps_per_second": 0.977,
      "step": 32300
    },
    {
      "epoch": 2.1683164994463273,
      "grad_norm": 0.6789869666099548,
      "learning_rate": 3.7680156000618705e-05,
      "loss": 2.3989,
      "step": 32310
    },
    {
      "epoch": 2.1689876178651724,
      "grad_norm": 0.6986899971961975,
      "learning_rate": 3.7623510253024e-05,
      "loss": 2.4631,
      "step": 32320
    },
    {
      "epoch": 2.1696587362840174,
      "grad_norm": 0.6483280062675476,
      "learning_rate": 3.756689724870147e-05,
      "loss": 2.4112,
      "step": 32330
    },
    {
      "epoch": 2.1703298547028624,
      "grad_norm": 0.7187609076499939,
      "learning_rate": 3.7510317017369026e-05,
      "loss": 2.4636,
      "step": 32340
    },
    {
      "epoch": 2.1710009731217075,
      "grad_norm": 0.6646939516067505,
      "learning_rate": 3.745376958872726e-05,
      "loss": 2.4435,
      "step": 32350
    },
    {
      "epoch": 2.1710009731217075,
      "eval_bleu": 21.41536368131661,
      "eval_gen_len": 28.918,
      "eval_loss": 2.9330341815948486,
      "eval_runtime": 64.1894,
      "eval_samples_per_second": 15.579,
      "eval_steps_per_second": 0.981,
      "step": 32350
    },
    {
      "epoch": 2.1716720915405525,
      "grad_norm": 0.7146920561790466,
      "learning_rate": 3.7397254992459644e-05,
      "loss": 2.4434,
      "step": 32360
    },
    {
      "epoch": 2.172343209959397,
      "grad_norm": 0.7621011734008789,
      "learning_rate": 3.734077325823232e-05,
      "loss": 2.4939,
      "step": 32370
    },
    {
      "epoch": 2.173014328378242,
      "grad_norm": 0.7445323467254639,
      "learning_rate": 3.728432441569427e-05,
      "loss": 2.4871,
      "step": 32380
    },
    {
      "epoch": 2.173685446797087,
      "grad_norm": 0.6448677778244019,
      "learning_rate": 3.722790849447717e-05,
      "loss": 2.3814,
      "step": 32390
    },
    {
      "epoch": 2.1743565652159322,
      "grad_norm": 0.6819872260093689,
      "learning_rate": 3.717152552419538e-05,
      "loss": 2.3941,
      "step": 32400
    },
    {
      "epoch": 2.1743565652159322,
      "eval_bleu": 21.39971633951239,
      "eval_gen_len": 29.031,
      "eval_loss": 2.9318630695343018,
      "eval_runtime": 63.7515,
      "eval_samples_per_second": 15.686,
      "eval_steps_per_second": 0.988,
      "step": 32400
    },
    {
      "epoch": 2.1750276836347773,
      "grad_norm": 0.664607048034668,
      "learning_rate": 3.711517553444598e-05,
      "loss": 2.3994,
      "step": 32410
    },
    {
      "epoch": 2.1756988020536223,
      "grad_norm": 0.7335203886032104,
      "learning_rate": 3.705885855480881e-05,
      "loss": 2.4323,
      "step": 32420
    },
    {
      "epoch": 2.1763699204724674,
      "grad_norm": 0.6607348322868347,
      "learning_rate": 3.700257461484626e-05,
      "loss": 2.4142,
      "step": 32430
    },
    {
      "epoch": 2.1770410388913124,
      "grad_norm": 0.7237557172775269,
      "learning_rate": 3.694632374410353e-05,
      "loss": 2.4653,
      "step": 32440
    },
    {
      "epoch": 2.1777121573101574,
      "grad_norm": 0.6845245361328125,
      "learning_rate": 3.689010597210828e-05,
      "loss": 2.4155,
      "step": 32450
    },
    {
      "epoch": 2.1777121573101574,
      "eval_bleu": 21.083462860724637,
      "eval_gen_len": 28.917,
      "eval_loss": 2.932363510131836,
      "eval_runtime": 63.9676,
      "eval_samples_per_second": 15.633,
      "eval_steps_per_second": 0.985,
      "step": 32450
    },
    {
      "epoch": 2.1783832757290025,
      "grad_norm": 0.6635822653770447,
      "learning_rate": 3.6833921328370954e-05,
      "loss": 2.4382,
      "step": 32460
    },
    {
      "epoch": 2.1790543941478475,
      "grad_norm": 0.6439915299415588,
      "learning_rate": 3.677776984238453e-05,
      "loss": 2.4488,
      "step": 32470
    },
    {
      "epoch": 2.1797255125666926,
      "grad_norm": 0.6422902345657349,
      "learning_rate": 3.672165154362457e-05,
      "loss": 2.4202,
      "step": 32480
    },
    {
      "epoch": 2.1803966309855376,
      "grad_norm": 0.6714360117912292,
      "learning_rate": 3.666556646154922e-05,
      "loss": 2.4569,
      "step": 32490
    },
    {
      "epoch": 2.1810677494043826,
      "grad_norm": 0.712356686592102,
      "learning_rate": 3.660951462559925e-05,
      "loss": 2.4326,
      "step": 32500
    },
    {
      "epoch": 2.1810677494043826,
      "eval_bleu": 21.227575755505168,
      "eval_gen_len": 28.955,
      "eval_loss": 2.9318959712982178,
      "eval_runtime": 64.5699,
      "eval_samples_per_second": 15.487,
      "eval_steps_per_second": 0.976,
      "step": 32500
    },
    {
      "epoch": 2.1817388678232272,
      "grad_norm": 0.6915162801742554,
      "learning_rate": 3.6553496065197926e-05,
      "loss": 2.4676,
      "step": 32510
    },
    {
      "epoch": 2.1824099862420723,
      "grad_norm": 0.6767362356185913,
      "learning_rate": 3.649751080975099e-05,
      "loss": 2.4126,
      "step": 32520
    },
    {
      "epoch": 2.1830811046609173,
      "grad_norm": 0.6438050270080566,
      "learning_rate": 3.644155888864687e-05,
      "loss": 2.4574,
      "step": 32530
    },
    {
      "epoch": 2.1837522230797624,
      "grad_norm": 0.6612013578414917,
      "learning_rate": 3.638564033125628e-05,
      "loss": 2.4189,
      "step": 32540
    },
    {
      "epoch": 2.1844233414986074,
      "grad_norm": 0.7217411398887634,
      "learning_rate": 3.632975516693263e-05,
      "loss": 2.4324,
      "step": 32550
    },
    {
      "epoch": 2.1844233414986074,
      "eval_bleu": 21.323537233026286,
      "eval_gen_len": 28.886,
      "eval_loss": 2.932265520095825,
      "eval_runtime": 63.9422,
      "eval_samples_per_second": 15.639,
      "eval_steps_per_second": 0.985,
      "step": 32550
    },
    {
      "epoch": 2.1850944599174524,
      "grad_norm": 0.7412288188934326,
      "learning_rate": 3.6273903425011636e-05,
      "loss": 2.4617,
      "step": 32560
    },
    {
      "epoch": 2.1857655783362975,
      "grad_norm": 0.686820387840271,
      "learning_rate": 3.62180851348116e-05,
      "loss": 2.4307,
      "step": 32570
    },
    {
      "epoch": 2.1864366967551425,
      "grad_norm": 0.6542909741401672,
      "learning_rate": 3.616230032563316e-05,
      "loss": 2.4341,
      "step": 32580
    },
    {
      "epoch": 2.1871078151739876,
      "grad_norm": 0.691109836101532,
      "learning_rate": 3.610654902675941e-05,
      "loss": 2.4863,
      "step": 32590
    },
    {
      "epoch": 2.1877789335928326,
      "grad_norm": 0.6907585859298706,
      "learning_rate": 3.605083126745585e-05,
      "loss": 2.4022,
      "step": 32600
    },
    {
      "epoch": 2.1877789335928326,
      "eval_bleu": 21.458184755910136,
      "eval_gen_len": 28.931,
      "eval_loss": 2.930896043777466,
      "eval_runtime": 64.2164,
      "eval_samples_per_second": 15.572,
      "eval_steps_per_second": 0.981,
      "step": 32600
    },
    {
      "epoch": 2.1884500520116776,
      "grad_norm": 0.7215980291366577,
      "learning_rate": 3.5995147076970445e-05,
      "loss": 2.4358,
      "step": 32610
    },
    {
      "epoch": 2.1891211704305222,
      "grad_norm": 0.723257839679718,
      "learning_rate": 3.5939496484533406e-05,
      "loss": 2.3805,
      "step": 32620
    },
    {
      "epoch": 2.1897922888493673,
      "grad_norm": 0.703915536403656,
      "learning_rate": 3.5883879519357465e-05,
      "loss": 2.4025,
      "step": 32630
    },
    {
      "epoch": 2.1904634072682123,
      "grad_norm": 0.7151232957839966,
      "learning_rate": 3.5828296210637544e-05,
      "loss": 2.4102,
      "step": 32640
    },
    {
      "epoch": 2.1911345256870574,
      "grad_norm": 0.7097988724708557,
      "learning_rate": 3.577274658755104e-05,
      "loss": 2.436,
      "step": 32650
    },
    {
      "epoch": 2.1911345256870574,
      "eval_bleu": 21.643920832588755,
      "eval_gen_len": 28.993,
      "eval_loss": 2.930492639541626,
      "eval_runtime": 64.1118,
      "eval_samples_per_second": 15.598,
      "eval_steps_per_second": 0.983,
      "step": 32650
    },
    {
      "epoch": 2.1918056441059024,
      "grad_norm": 0.695121705532074,
      "learning_rate": 3.571723067925756e-05,
      "loss": 2.4514,
      "step": 32660
    },
    {
      "epoch": 2.1924767625247474,
      "grad_norm": 0.7042976021766663,
      "learning_rate": 3.5661748514899066e-05,
      "loss": 2.4481,
      "step": 32670
    },
    {
      "epoch": 2.1931478809435925,
      "grad_norm": 0.6667795777320862,
      "learning_rate": 3.5606300123599744e-05,
      "loss": 2.4216,
      "step": 32680
    },
    {
      "epoch": 2.1938189993624375,
      "grad_norm": 0.6308409571647644,
      "learning_rate": 3.555088553446618e-05,
      "loss": 2.5042,
      "step": 32690
    },
    {
      "epoch": 2.1944901177812826,
      "grad_norm": 0.7057774066925049,
      "learning_rate": 3.549550477658708e-05,
      "loss": 2.4124,
      "step": 32700
    },
    {
      "epoch": 2.1944901177812826,
      "eval_bleu": 21.55195323955888,
      "eval_gen_len": 29.016,
      "eval_loss": 2.9299612045288086,
      "eval_runtime": 64.0511,
      "eval_samples_per_second": 15.613,
      "eval_steps_per_second": 0.984,
      "step": 32700
    },
    {
      "epoch": 2.1951612362001276,
      "grad_norm": 0.6740210056304932,
      "learning_rate": 3.544015787903349e-05,
      "loss": 2.4107,
      "step": 32710
    },
    {
      "epoch": 2.1958323546189726,
      "grad_norm": 0.719890296459198,
      "learning_rate": 3.538484487085859e-05,
      "loss": 2.4166,
      "step": 32720
    },
    {
      "epoch": 2.1965034730378177,
      "grad_norm": 0.6651098728179932,
      "learning_rate": 3.5329565781097896e-05,
      "loss": 2.4563,
      "step": 32730
    },
    {
      "epoch": 2.1971745914566627,
      "grad_norm": 0.6743899583816528,
      "learning_rate": 3.5274320638768996e-05,
      "loss": 2.4768,
      "step": 32740
    },
    {
      "epoch": 2.1978457098755078,
      "grad_norm": 0.7131415605545044,
      "learning_rate": 3.5219109472871716e-05,
      "loss": 2.4308,
      "step": 32750
    },
    {
      "epoch": 2.1978457098755078,
      "eval_bleu": 21.396868540372687,
      "eval_gen_len": 29.278,
      "eval_loss": 2.9315688610076904,
      "eval_runtime": 67.8397,
      "eval_samples_per_second": 14.741,
      "eval_steps_per_second": 0.929,
      "step": 32750
    },
    {
      "epoch": 2.1985168282943524,
      "grad_norm": 0.7247098684310913,
      "learning_rate": 3.516393231238798e-05,
      "loss": 2.4002,
      "step": 32760
    },
    {
      "epoch": 2.1991879467131974,
      "grad_norm": 0.6129968762397766,
      "learning_rate": 3.510878918628202e-05,
      "loss": 2.4989,
      "step": 32770
    },
    {
      "epoch": 2.1998590651320424,
      "grad_norm": 0.7315562963485718,
      "learning_rate": 3.505368012350001e-05,
      "loss": 2.4672,
      "step": 32780
    },
    {
      "epoch": 2.2005301835508875,
      "grad_norm": 0.7114312052726746,
      "learning_rate": 3.499860515297042e-05,
      "loss": 2.4906,
      "step": 32790
    },
    {
      "epoch": 2.2012013019697325,
      "grad_norm": 0.7577443718910217,
      "learning_rate": 3.494356430360365e-05,
      "loss": 2.4369,
      "step": 32800
    },
    {
      "epoch": 2.2012013019697325,
      "eval_bleu": 21.11477750181751,
      "eval_gen_len": 28.816,
      "eval_loss": 2.9334006309509277,
      "eval_runtime": 63.4498,
      "eval_samples_per_second": 15.76,
      "eval_steps_per_second": 0.993,
      "step": 32800
    },
    {
      "epoch": 2.2018724203885776,
      "grad_norm": 0.644677460193634,
      "learning_rate": 3.488855760429235e-05,
      "loss": 2.426,
      "step": 32810
    },
    {
      "epoch": 2.2025435388074226,
      "grad_norm": 0.697016716003418,
      "learning_rate": 3.4833585083911146e-05,
      "loss": 2.4409,
      "step": 32820
    },
    {
      "epoch": 2.2032146572262676,
      "grad_norm": 0.6857650279998779,
      "learning_rate": 3.4778646771316704e-05,
      "loss": 2.3974,
      "step": 32830
    },
    {
      "epoch": 2.2038857756451127,
      "grad_norm": 0.7371774911880493,
      "learning_rate": 3.472374269534788e-05,
      "loss": 2.4224,
      "step": 32840
    },
    {
      "epoch": 2.2045568940639577,
      "grad_norm": 0.7214370965957642,
      "learning_rate": 3.466887288482532e-05,
      "loss": 2.4356,
      "step": 32850
    },
    {
      "epoch": 2.2045568940639577,
      "eval_bleu": 21.47476336381391,
      "eval_gen_len": 28.986,
      "eval_loss": 2.931433916091919,
      "eval_runtime": 63.7499,
      "eval_samples_per_second": 15.686,
      "eval_steps_per_second": 0.988,
      "step": 32850
    },
    {
      "epoch": 2.2052280124828028,
      "grad_norm": 0.7047337293624878,
      "learning_rate": 3.461403736855192e-05,
      "loss": 2.4343,
      "step": 32860
    },
    {
      "epoch": 2.205899130901648,
      "grad_norm": 0.6943791508674622,
      "learning_rate": 3.4559236175312406e-05,
      "loss": 2.4285,
      "step": 32870
    },
    {
      "epoch": 2.2065702493204924,
      "grad_norm": 0.6492379903793335,
      "learning_rate": 3.4504469333873605e-05,
      "loss": 2.4564,
      "step": 32880
    },
    {
      "epoch": 2.2072413677393374,
      "grad_norm": 0.657139003276825,
      "learning_rate": 3.444973687298421e-05,
      "loss": 2.4523,
      "step": 32890
    },
    {
      "epoch": 2.2079124861581825,
      "grad_norm": 0.7773995399475098,
      "learning_rate": 3.439503882137496e-05,
      "loss": 2.4958,
      "step": 32900
    },
    {
      "epoch": 2.2079124861581825,
      "eval_bleu": 21.378983703113757,
      "eval_gen_len": 29.199,
      "eval_loss": 2.930692434310913,
      "eval_runtime": 68.0105,
      "eval_samples_per_second": 14.704,
      "eval_steps_per_second": 0.926,
      "step": 32900
    },
    {
      "epoch": 2.2085836045770275,
      "grad_norm": 0.7585265040397644,
      "learning_rate": 3.4340375207758445e-05,
      "loss": 2.4261,
      "step": 32910
    },
    {
      "epoch": 2.2092547229958726,
      "grad_norm": 0.7017887830734253,
      "learning_rate": 3.428574606082928e-05,
      "loss": 2.4654,
      "step": 32920
    },
    {
      "epoch": 2.2099258414147176,
      "grad_norm": 0.6854797601699829,
      "learning_rate": 3.423115140926388e-05,
      "loss": 2.453,
      "step": 32930
    },
    {
      "epoch": 2.2105969598335626,
      "grad_norm": 0.6790810227394104,
      "learning_rate": 3.417659128172061e-05,
      "loss": 2.4695,
      "step": 32940
    },
    {
      "epoch": 2.2112680782524077,
      "grad_norm": 0.710692286491394,
      "learning_rate": 3.4122065706839664e-05,
      "loss": 2.4336,
      "step": 32950
    },
    {
      "epoch": 2.2112680782524077,
      "eval_bleu": 21.10073603838315,
      "eval_gen_len": 29.098,
      "eval_loss": 2.9306459426879883,
      "eval_runtime": 67.9848,
      "eval_samples_per_second": 14.709,
      "eval_steps_per_second": 0.927,
      "step": 32950
    },
    {
      "epoch": 2.2119391966712527,
      "grad_norm": 0.6483650803565979,
      "learning_rate": 3.4067574713243213e-05,
      "loss": 2.4399,
      "step": 32960
    },
    {
      "epoch": 2.2126103150900978,
      "grad_norm": 0.7196774482727051,
      "learning_rate": 3.401311832953512e-05,
      "loss": 2.4829,
      "step": 32970
    },
    {
      "epoch": 2.213281433508943,
      "grad_norm": 0.6756604909896851,
      "learning_rate": 3.395869658430123e-05,
      "loss": 2.4434,
      "step": 32980
    },
    {
      "epoch": 2.213952551927788,
      "grad_norm": 0.6625339388847351,
      "learning_rate": 3.390430950610907e-05,
      "loss": 2.4329,
      "step": 32990
    },
    {
      "epoch": 2.214623670346633,
      "grad_norm": 0.6124247908592224,
      "learning_rate": 3.384995712350808e-05,
      "loss": 2.4298,
      "step": 33000
    },
    {
      "epoch": 2.214623670346633,
      "eval_bleu": 21.095737775571497,
      "eval_gen_len": 29.152,
      "eval_loss": 2.932328462600708,
      "eval_runtime": 67.9826,
      "eval_samples_per_second": 14.71,
      "eval_steps_per_second": 0.927,
      "step": 33000
    },
    {
      "epoch": 2.2152947887654775,
      "grad_norm": 0.6869403719902039,
      "learning_rate": 3.379563946502943e-05,
      "loss": 2.456,
      "step": 33010
    },
    {
      "epoch": 2.2159659071843225,
      "grad_norm": 0.7937828898429871,
      "learning_rate": 3.374135655918607e-05,
      "loss": 2.4712,
      "step": 33020
    },
    {
      "epoch": 2.2166370256031676,
      "grad_norm": 0.7109319567680359,
      "learning_rate": 3.368710843447265e-05,
      "loss": 2.4823,
      "step": 33030
    },
    {
      "epoch": 2.2173081440220126,
      "grad_norm": 0.6892654895782471,
      "learning_rate": 3.363289511936573e-05,
      "loss": 2.43,
      "step": 33040
    },
    {
      "epoch": 2.2179792624408576,
      "grad_norm": 0.6644615530967712,
      "learning_rate": 3.357871664232338e-05,
      "loss": 2.4421,
      "step": 33050
    },
    {
      "epoch": 2.2179792624408576,
      "eval_bleu": 21.166119366624198,
      "eval_gen_len": 29.174,
      "eval_loss": 2.9313766956329346,
      "eval_runtime": 67.6138,
      "eval_samples_per_second": 14.79,
      "eval_steps_per_second": 0.932,
      "step": 33050
    },
    {
      "epoch": 2.2186503808597027,
      "grad_norm": 0.7926619052886963,
      "learning_rate": 3.35245730317856e-05,
      "loss": 2.4856,
      "step": 33060
    },
    {
      "epoch": 2.2193214992785477,
      "grad_norm": 0.5937198400497437,
      "learning_rate": 3.347046431617388e-05,
      "loss": 2.4259,
      "step": 33070
    },
    {
      "epoch": 2.2199926176973928,
      "grad_norm": 0.706166684627533,
      "learning_rate": 3.341639052389157e-05,
      "loss": 2.4473,
      "step": 33080
    },
    {
      "epoch": 2.220663736116238,
      "grad_norm": 0.7151874899864197,
      "learning_rate": 3.3362351683323586e-05,
      "loss": 2.4497,
      "step": 33090
    },
    {
      "epoch": 2.221334854535083,
      "grad_norm": 0.7320242524147034,
      "learning_rate": 3.3308347822836505e-05,
      "loss": 2.475,
      "step": 33100
    },
    {
      "epoch": 2.221334854535083,
      "eval_bleu": 21.277176010968375,
      "eval_gen_len": 28.927,
      "eval_loss": 2.929807662963867,
      "eval_runtime": 64.0741,
      "eval_samples_per_second": 15.607,
      "eval_steps_per_second": 0.983,
      "step": 33100
    },
    {
      "epoch": 2.222005972953928,
      "grad_norm": 0.696441113948822,
      "learning_rate": 3.325437897077856e-05,
      "loss": 2.4509,
      "step": 33110
    },
    {
      "epoch": 2.222677091372773,
      "grad_norm": 0.6679279208183289,
      "learning_rate": 3.320044515547959e-05,
      "loss": 2.4578,
      "step": 33120
    },
    {
      "epoch": 2.2233482097916175,
      "grad_norm": 0.7381585240364075,
      "learning_rate": 3.31465464052511e-05,
      "loss": 2.4259,
      "step": 33130
    },
    {
      "epoch": 2.2240193282104626,
      "grad_norm": 0.716361939907074,
      "learning_rate": 3.3092682748386094e-05,
      "loss": 2.4264,
      "step": 33140
    },
    {
      "epoch": 2.2246904466293076,
      "grad_norm": 0.7139317393302917,
      "learning_rate": 3.303885421315926e-05,
      "loss": 2.4761,
      "step": 33150
    },
    {
      "epoch": 2.2246904466293076,
      "eval_bleu": 21.330993681503635,
      "eval_gen_len": 28.898,
      "eval_loss": 2.9317376613616943,
      "eval_runtime": 65.0346,
      "eval_samples_per_second": 15.376,
      "eval_steps_per_second": 0.969,
      "step": 33150
    },
    {
      "epoch": 2.2253615650481526,
      "grad_norm": 0.6830072402954102,
      "learning_rate": 3.2985060827826734e-05,
      "loss": 2.4402,
      "step": 33160
    },
    {
      "epoch": 2.2260326834669977,
      "grad_norm": 0.6073911190032959,
      "learning_rate": 3.2931302620626326e-05,
      "loss": 2.4455,
      "step": 33170
    },
    {
      "epoch": 2.2267038018858427,
      "grad_norm": 0.7199468016624451,
      "learning_rate": 3.287757961977724e-05,
      "loss": 2.4613,
      "step": 33180
    },
    {
      "epoch": 2.2273749203046878,
      "grad_norm": 0.6543352603912354,
      "learning_rate": 3.282389185348037e-05,
      "loss": 2.5109,
      "step": 33190
    },
    {
      "epoch": 2.228046038723533,
      "grad_norm": 0.6906141042709351,
      "learning_rate": 3.2770239349917964e-05,
      "loss": 2.4012,
      "step": 33200
    },
    {
      "epoch": 2.228046038723533,
      "eval_bleu": 21.37482727152463,
      "eval_gen_len": 29.169,
      "eval_loss": 2.9293620586395264,
      "eval_runtime": 67.6048,
      "eval_samples_per_second": 14.792,
      "eval_steps_per_second": 0.932,
      "step": 33200
    },
    {
      "epoch": 2.228717157142378,
      "grad_norm": 0.7368719577789307,
      "learning_rate": 3.271662213725381e-05,
      "loss": 2.4732,
      "step": 33210
    },
    {
      "epoch": 2.229388275561223,
      "grad_norm": 0.6818774342536926,
      "learning_rate": 3.2663040243633155e-05,
      "loss": 2.4445,
      "step": 33220
    },
    {
      "epoch": 2.230059393980068,
      "grad_norm": 0.7329450249671936,
      "learning_rate": 3.2609493697182805e-05,
      "loss": 2.476,
      "step": 33230
    },
    {
      "epoch": 2.230730512398913,
      "grad_norm": 0.6858996748924255,
      "learning_rate": 3.255598252601083e-05,
      "loss": 2.462,
      "step": 33240
    },
    {
      "epoch": 2.231401630817758,
      "grad_norm": 0.7817628383636475,
      "learning_rate": 3.250250675820693e-05,
      "loss": 2.5082,
      "step": 33250
    },
    {
      "epoch": 2.231401630817758,
      "eval_bleu": 21.324995693731857,
      "eval_gen_len": 29.233,
      "eval_loss": 2.930952310562134,
      "eval_runtime": 68.1389,
      "eval_samples_per_second": 14.676,
      "eval_steps_per_second": 0.925,
      "step": 33250
    },
    {
      "epoch": 2.2320727492366026,
      "grad_norm": 0.7091489434242249,
      "learning_rate": 3.2449066421842046e-05,
      "loss": 2.416,
      "step": 33260
    },
    {
      "epoch": 2.2327438676554476,
      "grad_norm": 0.6687909960746765,
      "learning_rate": 3.239566154496866e-05,
      "loss": 2.4535,
      "step": 33270
    },
    {
      "epoch": 2.2334149860742927,
      "grad_norm": 0.7099888920783997,
      "learning_rate": 3.2342292155620554e-05,
      "loss": 2.4791,
      "step": 33280
    },
    {
      "epoch": 2.2340861044931377,
      "grad_norm": 0.7049360275268555,
      "learning_rate": 3.228895828181291e-05,
      "loss": 2.4551,
      "step": 33290
    },
    {
      "epoch": 2.2347572229119828,
      "grad_norm": 0.6951775550842285,
      "learning_rate": 3.2235659951542205e-05,
      "loss": 2.4287,
      "step": 33300
    },
    {
      "epoch": 2.2347572229119828,
      "eval_bleu": 21.190496110003362,
      "eval_gen_len": 28.87,
      "eval_loss": 2.9313998222351074,
      "eval_runtime": 64.8817,
      "eval_samples_per_second": 15.413,
      "eval_steps_per_second": 0.971,
      "step": 33300
    },
    {
      "epoch": 2.235428341330828,
      "grad_norm": 0.7340843677520752,
      "learning_rate": 3.218239719278642e-05,
      "loss": 2.4498,
      "step": 33310
    },
    {
      "epoch": 2.236099459749673,
      "grad_norm": 0.6507246494293213,
      "learning_rate": 3.212917003350466e-05,
      "loss": 2.4746,
      "step": 33320
    },
    {
      "epoch": 2.236770578168518,
      "grad_norm": 0.6749406456947327,
      "learning_rate": 3.207597850163752e-05,
      "loss": 2.4593,
      "step": 33330
    },
    {
      "epoch": 2.237441696587363,
      "grad_norm": 0.6932870149612427,
      "learning_rate": 3.202282262510675e-05,
      "loss": 2.4614,
      "step": 33340
    },
    {
      "epoch": 2.238112815006208,
      "grad_norm": 0.6514204144477844,
      "learning_rate": 3.1969702431815505e-05,
      "loss": 2.4689,
      "step": 33350
    },
    {
      "epoch": 2.238112815006208,
      "eval_bleu": 21.389772843093397,
      "eval_gen_len": 28.927,
      "eval_loss": 2.9309473037719727,
      "eval_runtime": 64.6873,
      "eval_samples_per_second": 15.459,
      "eval_steps_per_second": 0.974,
      "step": 33350
    },
    {
      "epoch": 2.238783933425053,
      "grad_norm": 0.8103521466255188,
      "learning_rate": 3.191661794964814e-05,
      "loss": 2.4334,
      "step": 33360
    },
    {
      "epoch": 2.239455051843898,
      "grad_norm": 0.7919438481330872,
      "learning_rate": 3.186356920647026e-05,
      "loss": 2.4379,
      "step": 33370
    },
    {
      "epoch": 2.2401261702627426,
      "grad_norm": 0.7122364640235901,
      "learning_rate": 3.1810556230128684e-05,
      "loss": 2.4443,
      "step": 33380
    },
    {
      "epoch": 2.2407972886815877,
      "grad_norm": 0.6959605813026428,
      "learning_rate": 3.175757904845159e-05,
      "loss": 2.4571,
      "step": 33390
    },
    {
      "epoch": 2.2414684071004327,
      "grad_norm": 0.6638178825378418,
      "learning_rate": 3.170463768924823e-05,
      "loss": 2.4118,
      "step": 33400
    },
    {
      "epoch": 2.2414684071004327,
      "eval_bleu": 21.152639687192774,
      "eval_gen_len": 29.162,
      "eval_loss": 2.9320766925811768,
      "eval_runtime": 68.3285,
      "eval_samples_per_second": 14.635,
      "eval_steps_per_second": 0.922,
      "step": 33400
    },
    {
      "epoch": 2.2421395255192778,
      "grad_norm": 0.6941050887107849,
      "learning_rate": 3.165173218030906e-05,
      "loss": 2.4231,
      "step": 33410
    },
    {
      "epoch": 2.242810643938123,
      "grad_norm": 0.7055560350418091,
      "learning_rate": 3.1598862549405806e-05,
      "loss": 2.4674,
      "step": 33420
    },
    {
      "epoch": 2.243481762356968,
      "grad_norm": 0.6920546889305115,
      "learning_rate": 3.154602882429126e-05,
      "loss": 2.4609,
      "step": 33430
    },
    {
      "epoch": 2.244152880775813,
      "grad_norm": 0.7272902727127075,
      "learning_rate": 3.149323103269949e-05,
      "loss": 2.4642,
      "step": 33440
    },
    {
      "epoch": 2.244823999194658,
      "grad_norm": 0.7460217475891113,
      "learning_rate": 3.144046920234553e-05,
      "loss": 2.4165,
      "step": 33450
    },
    {
      "epoch": 2.244823999194658,
      "eval_bleu": 21.273445953482472,
      "eval_gen_len": 29.12,
      "eval_loss": 2.9326796531677246,
      "eval_runtime": 68.1736,
      "eval_samples_per_second": 14.668,
      "eval_steps_per_second": 0.924,
      "step": 33450
    },
    {
      "epoch": 2.245495117613503,
      "grad_norm": 0.8127124309539795,
      "learning_rate": 3.1387743360925715e-05,
      "loss": 2.4581,
      "step": 33460
    },
    {
      "epoch": 2.246166236032348,
      "grad_norm": 0.7451339364051819,
      "learning_rate": 3.133505353611738e-05,
      "loss": 2.4888,
      "step": 33470
    },
    {
      "epoch": 2.246837354451193,
      "grad_norm": 0.6838193535804749,
      "learning_rate": 3.128239975557895e-05,
      "loss": 2.4341,
      "step": 33480
    },
    {
      "epoch": 2.247508472870038,
      "grad_norm": 0.7159562706947327,
      "learning_rate": 3.122978204694995e-05,
      "loss": 2.4141,
      "step": 33490
    },
    {
      "epoch": 2.248179591288883,
      "grad_norm": 0.7407636642456055,
      "learning_rate": 3.117720043785104e-05,
      "loss": 2.4547,
      "step": 33500
    },
    {
      "epoch": 2.248179591288883,
      "eval_bleu": 21.360001931202465,
      "eval_gen_len": 29.205,
      "eval_loss": 2.930967330932617,
      "eval_runtime": 68.3191,
      "eval_samples_per_second": 14.637,
      "eval_steps_per_second": 0.922,
      "step": 33500
    },
    {
      "epoch": 2.248850709707728,
      "grad_norm": 0.7308133244514465,
      "learning_rate": 3.11246549558838e-05,
      "loss": 2.435,
      "step": 33510
    },
    {
      "epoch": 2.2495218281265728,
      "grad_norm": 0.7524656653404236,
      "learning_rate": 3.107214562863098e-05,
      "loss": 2.4522,
      "step": 33520
    },
    {
      "epoch": 2.250192946545418,
      "grad_norm": 0.8128286600112915,
      "learning_rate": 3.101967248365623e-05,
      "loss": 2.4695,
      "step": 33530
    },
    {
      "epoch": 2.250864064964263,
      "grad_norm": 0.7378252744674683,
      "learning_rate": 3.09672355485043e-05,
      "loss": 2.4173,
      "step": 33540
    },
    {
      "epoch": 2.251535183383108,
      "grad_norm": 0.6743544340133667,
      "learning_rate": 3.091483485070089e-05,
      "loss": 2.4156,
      "step": 33550
    },
    {
      "epoch": 2.251535183383108,
      "eval_bleu": 21.37221865377062,
      "eval_gen_len": 29.2,
      "eval_loss": 2.9302892684936523,
      "eval_runtime": 67.6091,
      "eval_samples_per_second": 14.791,
      "eval_steps_per_second": 0.932,
      "step": 33550
    },
    {
      "epoch": 2.252206301801953,
      "grad_norm": 0.7306864261627197,
      "learning_rate": 3.0862470417752675e-05,
      "loss": 2.4766,
      "step": 33560
    },
    {
      "epoch": 2.252877420220798,
      "grad_norm": 0.7013547420501709,
      "learning_rate": 3.0810142277147256e-05,
      "loss": 2.467,
      "step": 33570
    },
    {
      "epoch": 2.253548538639643,
      "grad_norm": 0.6670886278152466,
      "learning_rate": 3.075785045635332e-05,
      "loss": 2.4216,
      "step": 33580
    },
    {
      "epoch": 2.254219657058488,
      "grad_norm": 0.7436209321022034,
      "learning_rate": 3.070559498282031e-05,
      "loss": 2.4474,
      "step": 33590
    },
    {
      "epoch": 2.254890775477333,
      "grad_norm": 0.7307539582252502,
      "learning_rate": 3.065337588397874e-05,
      "loss": 2.4556,
      "step": 33600
    },
    {
      "epoch": 2.254890775477333,
      "eval_bleu": 21.29453932842761,
      "eval_gen_len": 29.374,
      "eval_loss": 2.9296066761016846,
      "eval_runtime": 71.2819,
      "eval_samples_per_second": 14.029,
      "eval_steps_per_second": 0.884,
      "step": 33600
    },
    {
      "epoch": 2.255561893896178,
      "grad_norm": 0.7172887921333313,
      "learning_rate": 3.060119318723991e-05,
      "loss": 2.4429,
      "step": 33610
    },
    {
      "epoch": 2.256233012315023,
      "grad_norm": 0.6733478307723999,
      "learning_rate": 3.054904691999613e-05,
      "loss": 2.435,
      "step": 33620
    },
    {
      "epoch": 2.2569041307338678,
      "grad_norm": 0.7233177423477173,
      "learning_rate": 3.0496937109620494e-05,
      "loss": 2.4478,
      "step": 33630
    },
    {
      "epoch": 2.257575249152713,
      "grad_norm": 0.6763055920600891,
      "learning_rate": 3.0444863783466993e-05,
      "loss": 2.4003,
      "step": 33640
    },
    {
      "epoch": 2.258246367571558,
      "grad_norm": 0.7400891184806824,
      "learning_rate": 3.0392826968870413e-05,
      "loss": 2.4213,
      "step": 33650
    },
    {
      "epoch": 2.258246367571558,
      "eval_bleu": 21.460769792091288,
      "eval_gen_len": 29.157,
      "eval_loss": 2.931175708770752,
      "eval_runtime": 67.3246,
      "eval_samples_per_second": 14.853,
      "eval_steps_per_second": 0.936,
      "step": 33650
    },
    {
      "epoch": 2.258917485990403,
      "grad_norm": 0.7240860462188721,
      "learning_rate": 3.0340826693146506e-05,
      "loss": 2.4327,
      "step": 33660
    },
    {
      "epoch": 2.259588604409248,
      "grad_norm": 0.7251627445220947,
      "learning_rate": 3.0288862983591704e-05,
      "loss": 2.4468,
      "step": 33670
    },
    {
      "epoch": 2.260259722828093,
      "grad_norm": 0.7112652659416199,
      "learning_rate": 3.023693586748334e-05,
      "loss": 2.4485,
      "step": 33680
    },
    {
      "epoch": 2.260930841246938,
      "grad_norm": 0.6242761015892029,
      "learning_rate": 3.018504537207948e-05,
      "loss": 2.4232,
      "step": 33690
    },
    {
      "epoch": 2.261601959665783,
      "grad_norm": 0.7129383087158203,
      "learning_rate": 3.0133191524618953e-05,
      "loss": 2.4595,
      "step": 33700
    },
    {
      "epoch": 2.261601959665783,
      "eval_bleu": 21.26157438525946,
      "eval_gen_len": 29.175,
      "eval_loss": 2.930250883102417,
      "eval_runtime": 67.775,
      "eval_samples_per_second": 14.755,
      "eval_steps_per_second": 0.93,
      "step": 33700
    },
    {
      "epoch": 2.262273078084628,
      "grad_norm": 0.7149289846420288,
      "learning_rate": 3.0081374352321456e-05,
      "loss": 2.4684,
      "step": 33710
    },
    {
      "epoch": 2.262944196503473,
      "grad_norm": 0.6807952523231506,
      "learning_rate": 3.002959388238732e-05,
      "loss": 2.4789,
      "step": 33720
    },
    {
      "epoch": 2.263615314922318,
      "grad_norm": 0.6954324245452881,
      "learning_rate": 2.9977850141997653e-05,
      "loss": 2.471,
      "step": 33730
    },
    {
      "epoch": 2.264286433341163,
      "grad_norm": 0.7354006767272949,
      "learning_rate": 2.9926143158314258e-05,
      "loss": 2.4309,
      "step": 33740
    },
    {
      "epoch": 2.2649575517600082,
      "grad_norm": 0.8042973875999451,
      "learning_rate": 2.9874472958479725e-05,
      "loss": 2.471,
      "step": 33750
    },
    {
      "epoch": 2.2649575517600082,
      "eval_bleu": 21.280747609896917,
      "eval_gen_len": 29.323,
      "eval_loss": 2.931190252304077,
      "eval_runtime": 71.2329,
      "eval_samples_per_second": 14.038,
      "eval_steps_per_second": 0.884,
      "step": 33750
    },
    {
      "epoch": 2.2656286701788533,
      "grad_norm": 0.7344042062759399,
      "learning_rate": 2.98228395696172e-05,
      "loss": 2.4478,
      "step": 33760
    },
    {
      "epoch": 2.266299788597698,
      "grad_norm": 0.6582738757133484,
      "learning_rate": 2.9771243018830662e-05,
      "loss": 2.4829,
      "step": 33770
    },
    {
      "epoch": 2.266970907016543,
      "grad_norm": 0.7039203643798828,
      "learning_rate": 2.9719683333204618e-05,
      "loss": 2.4577,
      "step": 33780
    },
    {
      "epoch": 2.267642025435388,
      "grad_norm": 0.8093167543411255,
      "learning_rate": 2.966816053980431e-05,
      "loss": 2.4823,
      "step": 33790
    },
    {
      "epoch": 2.268313143854233,
      "grad_norm": 0.702655017375946,
      "learning_rate": 2.961667466567555e-05,
      "loss": 2.435,
      "step": 33800
    },
    {
      "epoch": 2.268313143854233,
      "eval_bleu": 21.240632922043996,
      "eval_gen_len": 29.136,
      "eval_loss": 2.9310996532440186,
      "eval_runtime": 67.4659,
      "eval_samples_per_second": 14.822,
      "eval_steps_per_second": 0.934,
      "step": 33800
    },
    {
      "epoch": 2.268984262273078,
      "grad_norm": 0.7202050089836121,
      "learning_rate": 2.956522573784485e-05,
      "loss": 2.4933,
      "step": 33810
    },
    {
      "epoch": 2.269655380691923,
      "grad_norm": 0.6970870494842529,
      "learning_rate": 2.9513813783319255e-05,
      "loss": 2.4465,
      "step": 33820
    },
    {
      "epoch": 2.270326499110768,
      "grad_norm": 0.6482617259025574,
      "learning_rate": 2.9462438829086425e-05,
      "loss": 2.469,
      "step": 33830
    },
    {
      "epoch": 2.270997617529613,
      "grad_norm": 0.6885179877281189,
      "learning_rate": 2.9411100902114575e-05,
      "loss": 2.4469,
      "step": 33840
    },
    {
      "epoch": 2.271668735948458,
      "grad_norm": 0.671535313129425,
      "learning_rate": 2.9359800029352547e-05,
      "loss": 2.4458,
      "step": 33850
    },
    {
      "epoch": 2.271668735948458,
      "eval_bleu": 21.28116849847251,
      "eval_gen_len": 29.11,
      "eval_loss": 2.93169903755188,
      "eval_runtime": 66.7857,
      "eval_samples_per_second": 14.973,
      "eval_steps_per_second": 0.943,
      "step": 33850
    },
    {
      "epoch": 2.2723398543673032,
      "grad_norm": 0.6962795853614807,
      "learning_rate": 2.9308536237729657e-05,
      "loss": 2.479,
      "step": 33860
    },
    {
      "epoch": 2.2730109727861483,
      "grad_norm": 0.6381344795227051,
      "learning_rate": 2.9257309554155842e-05,
      "loss": 2.4244,
      "step": 33870
    },
    {
      "epoch": 2.273682091204993,
      "grad_norm": 0.7586033344268799,
      "learning_rate": 2.9206120005521455e-05,
      "loss": 2.5253,
      "step": 33880
    },
    {
      "epoch": 2.274353209623838,
      "grad_norm": 0.7210220694541931,
      "learning_rate": 2.915496761869746e-05,
      "loss": 2.5127,
      "step": 33890
    },
    {
      "epoch": 2.275024328042683,
      "grad_norm": 0.6328504681587219,
      "learning_rate": 2.910385242053525e-05,
      "loss": 2.4254,
      "step": 33900
    },
    {
      "epoch": 2.275024328042683,
      "eval_bleu": 21.10986241816467,
      "eval_gen_len": 28.83,
      "eval_loss": 2.932314395904541,
      "eval_runtime": 63.8994,
      "eval_samples_per_second": 15.65,
      "eval_steps_per_second": 0.986,
      "step": 33900
    },
    {
      "epoch": 2.275695446461528,
      "grad_norm": 0.6628249287605286,
      "learning_rate": 2.9052774437866692e-05,
      "loss": 2.4982,
      "step": 33910
    },
    {
      "epoch": 2.276366564880373,
      "grad_norm": 0.6291636824607849,
      "learning_rate": 2.9001733697504118e-05,
      "loss": 2.431,
      "step": 33920
    },
    {
      "epoch": 2.277037683299218,
      "grad_norm": 0.7047992944717407,
      "learning_rate": 2.8950730226240385e-05,
      "loss": 2.4161,
      "step": 33930
    },
    {
      "epoch": 2.277708801718063,
      "grad_norm": 0.7030499577522278,
      "learning_rate": 2.8899764050848678e-05,
      "loss": 2.402,
      "step": 33940
    },
    {
      "epoch": 2.278379920136908,
      "grad_norm": 0.7654651403427124,
      "learning_rate": 2.8848835198082703e-05,
      "loss": 2.4499,
      "step": 33950
    },
    {
      "epoch": 2.278379920136908,
      "eval_bleu": 21.287545510148853,
      "eval_gen_len": 28.84,
      "eval_loss": 2.9320826530456543,
      "eval_runtime": 67.9041,
      "eval_samples_per_second": 14.727,
      "eval_steps_per_second": 0.928,
      "step": 33950
    },
    {
      "epoch": 2.279051038555753,
      "grad_norm": 0.6936466097831726,
      "learning_rate": 2.8797943694676465e-05,
      "loss": 2.4256,
      "step": 33960
    },
    {
      "epoch": 2.2797221569745982,
      "grad_norm": 0.6814256906509399,
      "learning_rate": 2.874708956734451e-05,
      "loss": 2.4467,
      "step": 33970
    },
    {
      "epoch": 2.2803932753934433,
      "grad_norm": 0.695547342300415,
      "learning_rate": 2.8696272842781623e-05,
      "loss": 2.4599,
      "step": 33980
    },
    {
      "epoch": 2.2810643938122883,
      "grad_norm": 0.7090088129043579,
      "learning_rate": 2.864549354766304e-05,
      "loss": 2.4718,
      "step": 33990
    },
    {
      "epoch": 2.2817355122311334,
      "grad_norm": 0.7039464116096497,
      "learning_rate": 2.8594751708644286e-05,
      "loss": 2.4336,
      "step": 34000
    },
    {
      "epoch": 2.2817355122311334,
      "eval_bleu": 21.04291566764953,
      "eval_gen_len": 28.847,
      "eval_loss": 2.9293229579925537,
      "eval_runtime": 68.4319,
      "eval_samples_per_second": 14.613,
      "eval_steps_per_second": 0.921,
      "step": 34000
    },
    {
      "epoch": 2.2824066306499784,
      "grad_norm": 0.656240701675415,
      "learning_rate": 2.854404735236126e-05,
      "loss": 2.4591,
      "step": 34010
    },
    {
      "epoch": 2.2830777490688234,
      "grad_norm": 0.6743491291999817,
      "learning_rate": 2.8493380505430234e-05,
      "loss": 2.4071,
      "step": 34020
    },
    {
      "epoch": 2.283748867487668,
      "grad_norm": 0.6840914487838745,
      "learning_rate": 2.844275119444767e-05,
      "loss": 2.4494,
      "step": 34030
    },
    {
      "epoch": 2.284419985906513,
      "grad_norm": 0.6521002650260925,
      "learning_rate": 2.8392159445990474e-05,
      "loss": 2.428,
      "step": 34040
    },
    {
      "epoch": 2.285091104325358,
      "grad_norm": 0.6724609136581421,
      "learning_rate": 2.8341605286615692e-05,
      "loss": 2.4215,
      "step": 34050
    },
    {
      "epoch": 2.285091104325358,
      "eval_bleu": 21.320476859705938,
      "eval_gen_len": 29.117,
      "eval_loss": 2.930265426635742,
      "eval_runtime": 72.278,
      "eval_samples_per_second": 13.835,
      "eval_steps_per_second": 0.872,
      "step": 34050
    },
    {
      "epoch": 2.285762222744203,
      "grad_norm": 0.7197442650794983,
      "learning_rate": 2.829108874286076e-05,
      "loss": 2.4153,
      "step": 34060
    },
    {
      "epoch": 2.286433341163048,
      "grad_norm": 0.7155792713165283,
      "learning_rate": 2.824060984124326e-05,
      "loss": 2.3836,
      "step": 34070
    },
    {
      "epoch": 2.2871044595818932,
      "grad_norm": 0.7119261026382446,
      "learning_rate": 2.8190168608261114e-05,
      "loss": 2.4442,
      "step": 34080
    },
    {
      "epoch": 2.2877755780007383,
      "grad_norm": 0.6435372829437256,
      "learning_rate": 2.813976507039241e-05,
      "loss": 2.4484,
      "step": 34090
    },
    {
      "epoch": 2.2884466964195833,
      "grad_norm": 0.6437956690788269,
      "learning_rate": 2.808939925409545e-05,
      "loss": 2.4571,
      "step": 34100
    },
    {
      "epoch": 2.2884466964195833,
      "eval_bleu": 21.26792869189814,
      "eval_gen_len": 29.164,
      "eval_loss": 2.930908203125,
      "eval_runtime": 73.3259,
      "eval_samples_per_second": 13.638,
      "eval_steps_per_second": 0.859,
      "step": 34100
    },
    {
      "epoch": 2.2891178148384284,
      "grad_norm": 0.6715742349624634,
      "learning_rate": 2.803907118580872e-05,
      "loss": 2.4196,
      "step": 34110
    },
    {
      "epoch": 2.2897889332572734,
      "grad_norm": 0.6579887866973877,
      "learning_rate": 2.7988780891950973e-05,
      "loss": 2.4441,
      "step": 34120
    },
    {
      "epoch": 2.2904600516761184,
      "grad_norm": 0.6396710276603699,
      "learning_rate": 2.7938528398921026e-05,
      "loss": 2.4294,
      "step": 34130
    },
    {
      "epoch": 2.291131170094963,
      "grad_norm": 0.731181800365448,
      "learning_rate": 2.788831373309796e-05,
      "loss": 2.4218,
      "step": 34140
    },
    {
      "epoch": 2.291802288513808,
      "grad_norm": 0.64980149269104,
      "learning_rate": 2.7838136920840886e-05,
      "loss": 2.4241,
      "step": 34150
    },
    {
      "epoch": 2.291802288513808,
      "eval_bleu": 21.1930257935866,
      "eval_gen_len": 29.151,
      "eval_loss": 2.9323575496673584,
      "eval_runtime": 72.0189,
      "eval_samples_per_second": 13.885,
      "eval_steps_per_second": 0.875,
      "step": 34150
    },
    {
      "epoch": 2.292473406932653,
      "grad_norm": 0.6441541314125061,
      "learning_rate": 2.7787997988489168e-05,
      "loss": 2.4189,
      "step": 34160
    },
    {
      "epoch": 2.293144525351498,
      "grad_norm": 0.7322695255279541,
      "learning_rate": 2.7737896962362185e-05,
      "loss": 2.4339,
      "step": 34170
    },
    {
      "epoch": 2.293815643770343,
      "grad_norm": 0.6642662286758423,
      "learning_rate": 2.768783386875946e-05,
      "loss": 2.4536,
      "step": 34180
    },
    {
      "epoch": 2.2944867621891882,
      "grad_norm": 0.6902521848678589,
      "learning_rate": 2.7637808733960558e-05,
      "loss": 2.3972,
      "step": 34190
    },
    {
      "epoch": 2.2951578806080333,
      "grad_norm": 0.7644615173339844,
      "learning_rate": 2.7587821584225225e-05,
      "loss": 2.4013,
      "step": 34200
    },
    {
      "epoch": 2.2951578806080333,
      "eval_bleu": 21.47597172900525,
      "eval_gen_len": 28.953,
      "eval_loss": 2.9327895641326904,
      "eval_runtime": 68.1601,
      "eval_samples_per_second": 14.671,
      "eval_steps_per_second": 0.924,
      "step": 34200
    },
    {
      "epoch": 2.2958289990268783,
      "grad_norm": 0.6617493033409119,
      "learning_rate": 2.7537872445793145e-05,
      "loss": 2.4583,
      "step": 34210
    },
    {
      "epoch": 2.2965001174457234,
      "grad_norm": 0.6206237077713013,
      "learning_rate": 2.748796134488415e-05,
      "loss": 2.4438,
      "step": 34220
    },
    {
      "epoch": 2.2971712358645684,
      "grad_norm": 0.7311623096466064,
      "learning_rate": 2.7438088307698008e-05,
      "loss": 2.4856,
      "step": 34230
    },
    {
      "epoch": 2.2978423542834134,
      "grad_norm": 0.6848400235176086,
      "learning_rate": 2.7388253360414628e-05,
      "loss": 2.4335,
      "step": 34240
    },
    {
      "epoch": 2.2985134727022585,
      "grad_norm": 0.7267000675201416,
      "learning_rate": 2.73384565291938e-05,
      "loss": 2.4809,
      "step": 34250
    },
    {
      "epoch": 2.2985134727022585,
      "eval_bleu": 21.270559893779808,
      "eval_gen_len": 28.895,
      "eval_loss": 2.932143211364746,
      "eval_runtime": 64.4115,
      "eval_samples_per_second": 15.525,
      "eval_steps_per_second": 0.978,
      "step": 34250
    },
    {
      "epoch": 2.2991845911211035,
      "grad_norm": 0.7024320960044861,
      "learning_rate": 2.7288697840175382e-05,
      "loss": 2.4665,
      "step": 34260
    },
    {
      "epoch": 2.2998557095399486,
      "grad_norm": 0.730959951877594,
      "learning_rate": 2.7238977319479176e-05,
      "loss": 2.4443,
      "step": 34270
    },
    {
      "epoch": 2.300526827958793,
      "grad_norm": 0.6612404584884644,
      "learning_rate": 2.718929499320494e-05,
      "loss": 2.4685,
      "step": 34280
    },
    {
      "epoch": 2.301197946377638,
      "grad_norm": 0.696216881275177,
      "learning_rate": 2.7139650887432445e-05,
      "loss": 2.4376,
      "step": 34290
    },
    {
      "epoch": 2.3018690647964832,
      "grad_norm": 0.7363804578781128,
      "learning_rate": 2.709004502822132e-05,
      "loss": 2.448,
      "step": 34300
    },
    {
      "epoch": 2.3018690647964832,
      "eval_bleu": 21.282824358906836,
      "eval_gen_len": 29.174,
      "eval_loss": 2.9312686920166016,
      "eval_runtime": 73.3031,
      "eval_samples_per_second": 13.642,
      "eval_steps_per_second": 0.859,
      "step": 34300
    },
    {
      "epoch": 2.3025401832153283,
      "grad_norm": 0.709907054901123,
      "learning_rate": 2.7040477441611188e-05,
      "loss": 2.4453,
      "step": 34310
    },
    {
      "epoch": 2.3032113016341733,
      "grad_norm": 0.7190361022949219,
      "learning_rate": 2.6990948153621508e-05,
      "loss": 2.435,
      "step": 34320
    },
    {
      "epoch": 2.3038824200530184,
      "grad_norm": 0.714058518409729,
      "learning_rate": 2.694145719025173e-05,
      "loss": 2.4959,
      "step": 34330
    },
    {
      "epoch": 2.3045535384718634,
      "grad_norm": 0.6253154277801514,
      "learning_rate": 2.68920045774811e-05,
      "loss": 2.4309,
      "step": 34340
    },
    {
      "epoch": 2.3052246568907084,
      "grad_norm": 0.7944878935813904,
      "learning_rate": 2.684259034126876e-05,
      "loss": 2.4449,
      "step": 34350
    },
    {
      "epoch": 2.3052246568907084,
      "eval_bleu": 21.46218377817621,
      "eval_gen_len": 28.932,
      "eval_loss": 2.930168867111206,
      "eval_runtime": 69.241,
      "eval_samples_per_second": 14.442,
      "eval_steps_per_second": 0.91,
      "step": 34350
    },
    {
      "epoch": 2.3058957753095535,
      "grad_norm": 0.6882295608520508,
      "learning_rate": 2.6793214507553676e-05,
      "loss": 2.4273,
      "step": 34360
    },
    {
      "epoch": 2.3065668937283985,
      "grad_norm": 0.7166227102279663,
      "learning_rate": 2.6743877102254756e-05,
      "loss": 2.44,
      "step": 34370
    },
    {
      "epoch": 2.3072380121472436,
      "grad_norm": 0.7093867063522339,
      "learning_rate": 2.669457815127062e-05,
      "loss": 2.4502,
      "step": 34380
    },
    {
      "epoch": 2.307909130566088,
      "grad_norm": 0.6513352394104004,
      "learning_rate": 2.6645317680479785e-05,
      "loss": 2.5102,
      "step": 34390
    },
    {
      "epoch": 2.308580248984933,
      "grad_norm": 0.7063480019569397,
      "learning_rate": 2.659609571574051e-05,
      "loss": 2.4588,
      "step": 34400
    },
    {
      "epoch": 2.308580248984933,
      "eval_bleu": 21.28924245456738,
      "eval_gen_len": 29.159,
      "eval_loss": 2.929513692855835,
      "eval_runtime": 72.5617,
      "eval_samples_per_second": 13.781,
      "eval_steps_per_second": 0.868,
      "step": 34400
    },
    {
      "epoch": 2.3092513674037782,
      "grad_norm": 0.6574294567108154,
      "learning_rate": 2.654691228289089e-05,
      "loss": 2.4634,
      "step": 34410
    },
    {
      "epoch": 2.3099224858226233,
      "grad_norm": 0.7518566250801086,
      "learning_rate": 2.649776740774873e-05,
      "loss": 2.4545,
      "step": 34420
    },
    {
      "epoch": 2.3105936042414683,
      "grad_norm": 0.6460427045822144,
      "learning_rate": 2.6448661116111706e-05,
      "loss": 2.4363,
      "step": 34430
    },
    {
      "epoch": 2.3112647226603134,
      "grad_norm": 0.6036006212234497,
      "learning_rate": 2.6399593433757107e-05,
      "loss": 2.4301,
      "step": 34440
    },
    {
      "epoch": 2.3119358410791584,
      "grad_norm": 0.6704810857772827,
      "learning_rate": 2.6350564386442044e-05,
      "loss": 2.4436,
      "step": 34450
    },
    {
      "epoch": 2.3119358410791584,
      "eval_bleu": 21.468959310278482,
      "eval_gen_len": 29.147,
      "eval_loss": 2.929185628890991,
      "eval_runtime": 73.5171,
      "eval_samples_per_second": 13.602,
      "eval_steps_per_second": 0.857,
      "step": 34450
    },
    {
      "epoch": 2.3126069594980034,
      "grad_norm": 0.661824107170105,
      "learning_rate": 2.6301573999903284e-05,
      "loss": 2.4158,
      "step": 34460
    },
    {
      "epoch": 2.3132780779168485,
      "grad_norm": 0.7158746719360352,
      "learning_rate": 2.625262229985739e-05,
      "loss": 2.4553,
      "step": 34470
    },
    {
      "epoch": 2.3139491963356935,
      "grad_norm": 0.7700923085212708,
      "learning_rate": 2.6203709312000503e-05,
      "loss": 2.448,
      "step": 34480
    },
    {
      "epoch": 2.3146203147545386,
      "grad_norm": 0.7180299758911133,
      "learning_rate": 2.6154835062008566e-05,
      "loss": 2.4399,
      "step": 34490
    },
    {
      "epoch": 2.3152914331733836,
      "grad_norm": 0.6993648409843445,
      "learning_rate": 2.6105999575537066e-05,
      "loss": 2.4256,
      "step": 34500
    },
    {
      "epoch": 2.3152914331733836,
      "eval_bleu": 21.441056171924906,
      "eval_gen_len": 28.962,
      "eval_loss": 2.9301254749298096,
      "eval_runtime": 69.6112,
      "eval_samples_per_second": 14.366,
      "eval_steps_per_second": 0.905,
      "step": 34500
    },
    {
      "epoch": 2.3159625515922286,
      "grad_norm": 0.6819596886634827,
      "learning_rate": 2.6057202878221267e-05,
      "loss": 2.4292,
      "step": 34510
    },
    {
      "epoch": 2.3166336700110737,
      "grad_norm": 0.6689509749412537,
      "learning_rate": 2.600844499567596e-05,
      "loss": 2.4025,
      "step": 34520
    },
    {
      "epoch": 2.3173047884299183,
      "grad_norm": 0.6965222954750061,
      "learning_rate": 2.5959725953495617e-05,
      "loss": 2.424,
      "step": 34530
    },
    {
      "epoch": 2.3179759068487633,
      "grad_norm": 0.7181912660598755,
      "learning_rate": 2.591104577725427e-05,
      "loss": 2.453,
      "step": 34540
    },
    {
      "epoch": 2.3186470252676084,
      "grad_norm": 0.6166336536407471,
      "learning_rate": 2.5862404492505653e-05,
      "loss": 2.4044,
      "step": 34550
    },
    {
      "epoch": 2.3186470252676084,
      "eval_bleu": 21.419276177071687,
      "eval_gen_len": 29.163,
      "eval_loss": 2.928802490234375,
      "eval_runtime": 73.3978,
      "eval_samples_per_second": 13.624,
      "eval_steps_per_second": 0.858,
      "step": 34550
    },
    {
      "epoch": 2.3193181436864534,
      "grad_norm": 0.736436128616333,
      "learning_rate": 2.5813802124782982e-05,
      "loss": 2.4652,
      "step": 34560
    },
    {
      "epoch": 2.3199892621052984,
      "grad_norm": 0.7405996322631836,
      "learning_rate": 2.5765238699599103e-05,
      "loss": 2.4312,
      "step": 34570
    },
    {
      "epoch": 2.3206603805241435,
      "grad_norm": 0.7428023815155029,
      "learning_rate": 2.5716714242446405e-05,
      "loss": 2.4653,
      "step": 34580
    },
    {
      "epoch": 2.3213314989429885,
      "grad_norm": 0.7240723371505737,
      "learning_rate": 2.5668228778796775e-05,
      "loss": 2.4064,
      "step": 34590
    },
    {
      "epoch": 2.3220026173618336,
      "grad_norm": 0.7185367941856384,
      "learning_rate": 2.561978233410174e-05,
      "loss": 2.4425,
      "step": 34600
    },
    {
      "epoch": 2.3220026173618336,
      "eval_bleu": 21.403292365471852,
      "eval_gen_len": 29.155,
      "eval_loss": 2.9296724796295166,
      "eval_runtime": 70.6825,
      "eval_samples_per_second": 14.148,
      "eval_steps_per_second": 0.891,
      "step": 34600
    },
    {
      "epoch": 2.3226737357806786,
      "grad_norm": 0.6531509757041931,
      "learning_rate": 2.5571374933792224e-05,
      "loss": 2.4024,
      "step": 34610
    },
    {
      "epoch": 2.3233448541995236,
      "grad_norm": 0.6271724700927734,
      "learning_rate": 2.552300660327873e-05,
      "loss": 2.4237,
      "step": 34620
    },
    {
      "epoch": 2.3240159726183687,
      "grad_norm": 0.6782857775688171,
      "learning_rate": 2.5474677367951206e-05,
      "loss": 2.4145,
      "step": 34630
    },
    {
      "epoch": 2.3246870910372133,
      "grad_norm": 0.707597017288208,
      "learning_rate": 2.5426387253179153e-05,
      "loss": 2.4459,
      "step": 34640
    },
    {
      "epoch": 2.3253582094560583,
      "grad_norm": 0.6649537682533264,
      "learning_rate": 2.5378136284311415e-05,
      "loss": 2.4183,
      "step": 34650
    },
    {
      "epoch": 2.3253582094560583,
      "eval_bleu": 21.46606183951162,
      "eval_gen_len": 29.118,
      "eval_loss": 2.9299094676971436,
      "eval_runtime": 72.8937,
      "eval_samples_per_second": 13.719,
      "eval_steps_per_second": 0.864,
      "step": 34650
    },
    {
      "epoch": 2.3260293278749034,
      "grad_norm": 0.672204315662384,
      "learning_rate": 2.5329924486676436e-05,
      "loss": 2.4733,
      "step": 34660
    },
    {
      "epoch": 2.3267004462937484,
      "grad_norm": 0.8243322968482971,
      "learning_rate": 2.528175188558196e-05,
      "loss": 2.4717,
      "step": 34670
    },
    {
      "epoch": 2.3273715647125934,
      "grad_norm": 0.6765751242637634,
      "learning_rate": 2.523361850631527e-05,
      "loss": 2.3932,
      "step": 34680
    },
    {
      "epoch": 2.3280426831314385,
      "grad_norm": 0.6664586067199707,
      "learning_rate": 2.5185524374142954e-05,
      "loss": 2.439,
      "step": 34690
    },
    {
      "epoch": 2.3287138015502835,
      "grad_norm": 0.6977366805076599,
      "learning_rate": 2.5137469514311107e-05,
      "loss": 2.3765,
      "step": 34700
    },
    {
      "epoch": 2.3287138015502835,
      "eval_bleu": 21.271068982753373,
      "eval_gen_len": 29.011,
      "eval_loss": 2.9301016330718994,
      "eval_runtime": 71.5369,
      "eval_samples_per_second": 13.979,
      "eval_steps_per_second": 0.881,
      "step": 34700
    },
    {
      "epoch": 2.3293849199691286,
      "grad_norm": 0.6682369112968445,
      "learning_rate": 2.5089453952045116e-05,
      "loss": 2.4232,
      "step": 34710
    },
    {
      "epoch": 2.3300560383879736,
      "grad_norm": 0.6186383962631226,
      "learning_rate": 2.5041477712549778e-05,
      "loss": 2.4236,
      "step": 34720
    },
    {
      "epoch": 2.3307271568068186,
      "grad_norm": 0.6555604934692383,
      "learning_rate": 2.4993540821009222e-05,
      "loss": 2.4397,
      "step": 34730
    },
    {
      "epoch": 2.3313982752256637,
      "grad_norm": 0.7779223918914795,
      "learning_rate": 2.4945643302586997e-05,
      "loss": 2.4419,
      "step": 34740
    },
    {
      "epoch": 2.3320693936445087,
      "grad_norm": 0.6798796653747559,
      "learning_rate": 2.4897785182425882e-05,
      "loss": 2.4187,
      "step": 34750
    },
    {
      "epoch": 2.3320693936445087,
      "eval_bleu": 21.096852019024585,
      "eval_gen_len": 28.85,
      "eval_loss": 2.929283857345581,
      "eval_runtime": 69.4251,
      "eval_samples_per_second": 14.404,
      "eval_steps_per_second": 0.907,
      "step": 34750
    },
    {
      "epoch": 2.3327405120633538,
      "grad_norm": 0.6683928966522217,
      "learning_rate": 2.484996648564808e-05,
      "loss": 2.4339,
      "step": 34760
    },
    {
      "epoch": 2.333411630482199,
      "grad_norm": 0.6900820136070251,
      "learning_rate": 2.480218723735499e-05,
      "loss": 2.464,
      "step": 34770
    },
    {
      "epoch": 2.334082748901044,
      "grad_norm": 0.6800915598869324,
      "learning_rate": 2.4754447462627417e-05,
      "loss": 2.4433,
      "step": 34780
    },
    {
      "epoch": 2.3347538673198884,
      "grad_norm": 0.6296880841255188,
      "learning_rate": 2.470674718652536e-05,
      "loss": 2.4812,
      "step": 34790
    },
    {
      "epoch": 2.3354249857387335,
      "grad_norm": 0.6520412564277649,
      "learning_rate": 2.4659086434088096e-05,
      "loss": 2.4911,
      "step": 34800
    },
    {
      "epoch": 2.3354249857387335,
      "eval_bleu": 21.31560057276106,
      "eval_gen_len": 28.9,
      "eval_loss": 2.9300572872161865,
      "eval_runtime": 69.4843,
      "eval_samples_per_second": 14.392,
      "eval_steps_per_second": 0.907,
      "step": 34800
    },
    {
      "epoch": 2.3360961041575785,
      "grad_norm": 0.6883223056793213,
      "learning_rate": 2.461146523033415e-05,
      "loss": 2.4008,
      "step": 34810
    },
    {
      "epoch": 2.3367672225764236,
      "grad_norm": 0.6545445322990417,
      "learning_rate": 2.4563883600261384e-05,
      "loss": 2.4135,
      "step": 34820
    },
    {
      "epoch": 2.3374383409952686,
      "grad_norm": 0.6854256391525269,
      "learning_rate": 2.4516341568846724e-05,
      "loss": 2.4114,
      "step": 34830
    },
    {
      "epoch": 2.3381094594141136,
      "grad_norm": 0.6923611164093018,
      "learning_rate": 2.4468839161046454e-05,
      "loss": 2.4118,
      "step": 34840
    },
    {
      "epoch": 2.3387805778329587,
      "grad_norm": 0.6836633682250977,
      "learning_rate": 2.4421376401795947e-05,
      "loss": 2.4769,
      "step": 34850
    },
    {
      "epoch": 2.3387805778329587,
      "eval_bleu": 21.16586199833884,
      "eval_gen_len": 29.049,
      "eval_loss": 2.931499719619751,
      "eval_runtime": 72.8517,
      "eval_samples_per_second": 13.727,
      "eval_steps_per_second": 0.865,
      "step": 34850
    },
    {
      "epoch": 2.3394516962518037,
      "grad_norm": 0.6670316457748413,
      "learning_rate": 2.437395331600989e-05,
      "loss": 2.4337,
      "step": 34860
    },
    {
      "epoch": 2.3401228146706488,
      "grad_norm": 0.6497420072555542,
      "learning_rate": 2.432656992858201e-05,
      "loss": 2.4753,
      "step": 34870
    },
    {
      "epoch": 2.340793933089494,
      "grad_norm": 0.7260967493057251,
      "learning_rate": 2.427922626438527e-05,
      "loss": 2.4534,
      "step": 34880
    },
    {
      "epoch": 2.341465051508339,
      "grad_norm": 0.6851215362548828,
      "learning_rate": 2.4231922348271773e-05,
      "loss": 2.422,
      "step": 34890
    },
    {
      "epoch": 2.3421361699271834,
      "grad_norm": 0.6971785426139832,
      "learning_rate": 2.4184658205072708e-05,
      "loss": 2.4278,
      "step": 34900
    },
    {
      "epoch": 2.3421361699271834,
      "eval_bleu": 21.18682311399004,
      "eval_gen_len": 29.026,
      "eval_loss": 2.9326424598693848,
      "eval_runtime": 73.2812,
      "eval_samples_per_second": 13.646,
      "eval_steps_per_second": 0.86,
      "step": 34900
    },
    {
      "epoch": 2.3428072883460285,
      "grad_norm": 0.7062201499938965,
      "learning_rate": 2.413743385959848e-05,
      "loss": 2.4615,
      "step": 34910
    },
    {
      "epoch": 2.3434784067648735,
      "grad_norm": 0.6811846494674683,
      "learning_rate": 2.4090249336638516e-05,
      "loss": 2.4082,
      "step": 34920
    },
    {
      "epoch": 2.3441495251837186,
      "grad_norm": 0.7413541674613953,
      "learning_rate": 2.4043104660961413e-05,
      "loss": 2.5051,
      "step": 34930
    },
    {
      "epoch": 2.3448206436025636,
      "grad_norm": 0.6867007613182068,
      "learning_rate": 2.3995999857314754e-05,
      "loss": 2.4684,
      "step": 34940
    },
    {
      "epoch": 2.3454917620214086,
      "grad_norm": 0.6589657664299011,
      "learning_rate": 2.3948934950425316e-05,
      "loss": 2.4597,
      "step": 34950
    },
    {
      "epoch": 2.3454917620214086,
      "eval_bleu": 21.20239091904824,
      "eval_gen_len": 29.142,
      "eval_loss": 2.9296677112579346,
      "eval_runtime": 73.5499,
      "eval_samples_per_second": 13.596,
      "eval_steps_per_second": 0.857,
      "step": 34950
    },
    {
      "epoch": 2.3461628804402537,
      "grad_norm": 0.668146014213562,
      "learning_rate": 2.3901909964998826e-05,
      "loss": 2.4455,
      "step": 34960
    },
    {
      "epoch": 2.3468339988590987,
      "grad_norm": 0.7413845062255859,
      "learning_rate": 2.3854924925720112e-05,
      "loss": 2.4574,
      "step": 34970
    },
    {
      "epoch": 2.3475051172779438,
      "grad_norm": 0.721237301826477,
      "learning_rate": 2.380797985725298e-05,
      "loss": 2.5167,
      "step": 34980
    },
    {
      "epoch": 2.348176235696789,
      "grad_norm": 0.6957077383995056,
      "learning_rate": 2.3761074784240346e-05,
      "loss": 2.4403,
      "step": 34990
    },
    {
      "epoch": 2.348847354115634,
      "grad_norm": 0.740015983581543,
      "learning_rate": 2.3714209731304017e-05,
      "loss": 2.465,
      "step": 35000
    },
    {
      "epoch": 2.348847354115634,
      "eval_bleu": 21.398473565394195,
      "eval_gen_len": 29.321,
      "eval_loss": 2.9310736656188965,
      "eval_runtime": 77.0736,
      "eval_samples_per_second": 12.975,
      "eval_steps_per_second": 0.817,
      "step": 35000
    },
    {
      "epoch": 2.349518472534479,
      "grad_norm": 0.7168538570404053,
      "learning_rate": 2.3667384723044918e-05,
      "loss": 2.4895,
      "step": 35010
    },
    {
      "epoch": 2.350189590953324,
      "grad_norm": 0.7966297268867493,
      "learning_rate": 2.3620599784042806e-05,
      "loss": 2.428,
      "step": 35020
    },
    {
      "epoch": 2.350860709372169,
      "grad_norm": 0.6286543607711792,
      "learning_rate": 2.3573854938856576e-05,
      "loss": 2.517,
      "step": 35030
    },
    {
      "epoch": 2.3515318277910136,
      "grad_norm": 0.6948621869087219,
      "learning_rate": 2.3527150212023908e-05,
      "loss": 2.4089,
      "step": 35040
    },
    {
      "epoch": 2.3522029462098586,
      "grad_norm": 0.6727299690246582,
      "learning_rate": 2.3480485628061556e-05,
      "loss": 2.441,
      "step": 35050
    },
    {
      "epoch": 2.3522029462098586,
      "eval_bleu": 21.193666980644142,
      "eval_gen_len": 29.083,
      "eval_loss": 2.9333817958831787,
      "eval_runtime": 73.3756,
      "eval_samples_per_second": 13.629,
      "eval_steps_per_second": 0.859,
      "step": 35050
    },
    {
      "epoch": 2.3528740646287036,
      "grad_norm": 0.7227990031242371,
      "learning_rate": 2.3433861211465136e-05,
      "loss": 2.4962,
      "step": 35060
    },
    {
      "epoch": 2.3535451830475487,
      "grad_norm": 0.7122873067855835,
      "learning_rate": 2.338727698670916e-05,
      "loss": 2.4937,
      "step": 35070
    },
    {
      "epoch": 2.3542163014663937,
      "grad_norm": 0.7401787042617798,
      "learning_rate": 2.334073297824707e-05,
      "loss": 2.4565,
      "step": 35080
    },
    {
      "epoch": 2.3548874198852388,
      "grad_norm": 0.7234501838684082,
      "learning_rate": 2.3294229210511242e-05,
      "loss": 2.4479,
      "step": 35090
    },
    {
      "epoch": 2.355558538304084,
      "grad_norm": 0.7083902359008789,
      "learning_rate": 2.3247765707912826e-05,
      "loss": 2.4634,
      "step": 35100
    },
    {
      "epoch": 2.355558538304084,
      "eval_bleu": 20.99401732499606,
      "eval_gen_len": 29.301,
      "eval_loss": 2.933026075363159,
      "eval_runtime": 77.08,
      "eval_samples_per_second": 12.974,
      "eval_steps_per_second": 0.817,
      "step": 35100
    },
    {
      "epoch": 2.356229656722929,
      "grad_norm": 0.7478655576705933,
      "learning_rate": 2.320134249484196e-05,
      "loss": 2.4414,
      "step": 35110
    },
    {
      "epoch": 2.356900775141774,
      "grad_norm": 0.6967155337333679,
      "learning_rate": 2.3154959595667503e-05,
      "loss": 2.4648,
      "step": 35120
    },
    {
      "epoch": 2.357571893560619,
      "grad_norm": 0.7517736554145813,
      "learning_rate": 2.310861703473728e-05,
      "loss": 2.4446,
      "step": 35130
    },
    {
      "epoch": 2.358243011979464,
      "grad_norm": 0.6459024548530579,
      "learning_rate": 2.306231483637785e-05,
      "loss": 2.52,
      "step": 35140
    },
    {
      "epoch": 2.3589141303983086,
      "grad_norm": 0.7358768582344055,
      "learning_rate": 2.3016053024894603e-05,
      "loss": 2.4266,
      "step": 35150
    },
    {
      "epoch": 2.3589141303983086,
      "eval_bleu": 21.083273546175725,
      "eval_gen_len": 29.351,
      "eval_loss": 2.9333226680755615,
      "eval_runtime": 77.3029,
      "eval_samples_per_second": 12.936,
      "eval_steps_per_second": 0.815,
      "step": 35150
    },
    {
      "epoch": 2.3595852488171536,
      "grad_norm": 0.6569255590438843,
      "learning_rate": 2.2969831624571747e-05,
      "loss": 2.4265,
      "step": 35160
    },
    {
      "epoch": 2.3602563672359986,
      "grad_norm": 0.7013373970985413,
      "learning_rate": 2.2923650659672226e-05,
      "loss": 2.4196,
      "step": 35170
    },
    {
      "epoch": 2.3609274856548437,
      "grad_norm": 0.729375422000885,
      "learning_rate": 2.2877510154437877e-05,
      "loss": 2.4822,
      "step": 35180
    },
    {
      "epoch": 2.3615986040736887,
      "grad_norm": 0.7738170027732849,
      "learning_rate": 2.2831410133089148e-05,
      "loss": 2.4856,
      "step": 35190
    },
    {
      "epoch": 2.3622697224925338,
      "grad_norm": 0.6526656150817871,
      "learning_rate": 2.2785350619825375e-05,
      "loss": 2.4735,
      "step": 35200
    },
    {
      "epoch": 2.3622697224925338,
      "eval_bleu": 21.274280079313716,
      "eval_gen_len": 29.153,
      "eval_loss": 2.9314050674438477,
      "eval_runtime": 73.3016,
      "eval_samples_per_second": 13.642,
      "eval_steps_per_second": 0.859,
      "step": 35200
    },
    {
      "epoch": 2.362940840911379,
      "grad_norm": 0.6830101609230042,
      "learning_rate": 2.2739331638824513e-05,
      "loss": 2.4213,
      "step": 35210
    },
    {
      "epoch": 2.363611959330224,
      "grad_norm": 0.6907545924186707,
      "learning_rate": 2.269335321424333e-05,
      "loss": 2.476,
      "step": 35220
    },
    {
      "epoch": 2.364283077749069,
      "grad_norm": 0.709386944770813,
      "learning_rate": 2.264741537021725e-05,
      "loss": 2.469,
      "step": 35230
    },
    {
      "epoch": 2.364954196167914,
      "grad_norm": 0.6738553047180176,
      "learning_rate": 2.260151813086042e-05,
      "loss": 2.4179,
      "step": 35240
    },
    {
      "epoch": 2.365625314586759,
      "grad_norm": 0.6576862335205078,
      "learning_rate": 2.2555661520265625e-05,
      "loss": 2.4811,
      "step": 35250
    },
    {
      "epoch": 2.365625314586759,
      "eval_bleu": 21.37931024296869,
      "eval_gen_len": 28.908,
      "eval_loss": 2.9308505058288574,
      "eval_runtime": 69.2946,
      "eval_samples_per_second": 14.431,
      "eval_steps_per_second": 0.909,
      "step": 35250
    },
    {
      "epoch": 2.366296433005604,
      "grad_norm": 0.6485421657562256,
      "learning_rate": 2.2509845562504418e-05,
      "loss": 2.4983,
      "step": 35260
    },
    {
      "epoch": 2.366967551424449,
      "grad_norm": 0.7042198181152344,
      "learning_rate": 2.2464070281626903e-05,
      "loss": 2.4365,
      "step": 35270
    },
    {
      "epoch": 2.367638669843294,
      "grad_norm": 0.6875240206718445,
      "learning_rate": 2.2418335701661952e-05,
      "loss": 2.4459,
      "step": 35280
    },
    {
      "epoch": 2.3683097882621387,
      "grad_norm": 0.6517501473426819,
      "learning_rate": 2.2372641846616927e-05,
      "loss": 2.4289,
      "step": 35290
    },
    {
      "epoch": 2.3689809066809837,
      "grad_norm": 0.6796724796295166,
      "learning_rate": 2.232698874047795e-05,
      "loss": 2.4437,
      "step": 35300
    },
    {
      "epoch": 2.3689809066809837,
      "eval_bleu": 21.256803820289612,
      "eval_gen_len": 29.37,
      "eval_loss": 2.932208776473999,
      "eval_runtime": 77.0168,
      "eval_samples_per_second": 12.984,
      "eval_steps_per_second": 0.818,
      "step": 35300
    },
    {
      "epoch": 2.3696520250998288,
      "grad_norm": 0.6877707242965698,
      "learning_rate": 2.2281376407209654e-05,
      "loss": 2.4477,
      "step": 35310
    },
    {
      "epoch": 2.370323143518674,
      "grad_norm": 0.7741708755493164,
      "learning_rate": 2.223580487075534e-05,
      "loss": 2.4379,
      "step": 35320
    },
    {
      "epoch": 2.370994261937519,
      "grad_norm": 0.6185450553894043,
      "learning_rate": 2.219027415503685e-05,
      "loss": 2.4417,
      "step": 35330
    },
    {
      "epoch": 2.371665380356364,
      "grad_norm": 0.6702655553817749,
      "learning_rate": 2.21447842839546e-05,
      "loss": 2.4342,
      "step": 35340
    },
    {
      "epoch": 2.372336498775209,
      "grad_norm": 0.644495964050293,
      "learning_rate": 2.2099335281387556e-05,
      "loss": 2.4738,
      "step": 35350
    },
    {
      "epoch": 2.372336498775209,
      "eval_bleu": 21.32394792923585,
      "eval_gen_len": 29.106,
      "eval_loss": 2.9317421913146973,
      "eval_runtime": 72.6027,
      "eval_samples_per_second": 13.774,
      "eval_steps_per_second": 0.868,
      "step": 35350
    },
    {
      "epoch": 2.373007617194054,
      "grad_norm": 0.6521387100219727,
      "learning_rate": 2.20539271711933e-05,
      "loss": 2.4187,
      "step": 35360
    },
    {
      "epoch": 2.373678735612899,
      "grad_norm": 0.7205896377563477,
      "learning_rate": 2.2008559977207843e-05,
      "loss": 2.4074,
      "step": 35370
    },
    {
      "epoch": 2.374349854031744,
      "grad_norm": 0.6794240474700928,
      "learning_rate": 2.1963233723245825e-05,
      "loss": 2.4439,
      "step": 35380
    },
    {
      "epoch": 2.375020972450589,
      "grad_norm": 0.6784235835075378,
      "learning_rate": 2.191794843310029e-05,
      "loss": 2.4421,
      "step": 35390
    },
    {
      "epoch": 2.3756920908694337,
      "grad_norm": 0.6953433156013489,
      "learning_rate": 2.1872704130542877e-05,
      "loss": 2.4938,
      "step": 35400
    },
    {
      "epoch": 2.3756920908694337,
      "eval_bleu": 21.306943518317826,
      "eval_gen_len": 29.065,
      "eval_loss": 2.931492567062378,
      "eval_runtime": 72.7743,
      "eval_samples_per_second": 13.741,
      "eval_steps_per_second": 0.866,
      "step": 35400
    },
    {
      "epoch": 2.3763632092882787,
      "grad_norm": 0.6766547560691833,
      "learning_rate": 2.1827500839323657e-05,
      "loss": 2.4356,
      "step": 35410
    },
    {
      "epoch": 2.3770343277071238,
      "grad_norm": 0.7015840411186218,
      "learning_rate": 2.178233858317117e-05,
      "loss": 2.4622,
      "step": 35420
    },
    {
      "epoch": 2.377705446125969,
      "grad_norm": 0.7133052945137024,
      "learning_rate": 2.1737217385792386e-05,
      "loss": 2.4628,
      "step": 35430
    },
    {
      "epoch": 2.378376564544814,
      "grad_norm": 0.6648500561714172,
      "learning_rate": 2.1692137270872835e-05,
      "loss": 2.4502,
      "step": 35440
    },
    {
      "epoch": 2.379047682963659,
      "grad_norm": 0.6654039621353149,
      "learning_rate": 2.164709826207638e-05,
      "loss": 2.504,
      "step": 35450
    },
    {
      "epoch": 2.379047682963659,
      "eval_bleu": 21.31281677661816,
      "eval_gen_len": 28.966,
      "eval_loss": 2.929720401763916,
      "eval_runtime": 69.7636,
      "eval_samples_per_second": 14.334,
      "eval_steps_per_second": 0.903,
      "step": 35450
    },
    {
      "epoch": 2.379718801382504,
      "grad_norm": 0.661738395690918,
      "learning_rate": 2.1602100383045298e-05,
      "loss": 2.4443,
      "step": 35460
    },
    {
      "epoch": 2.380389919801349,
      "grad_norm": 0.6919012069702148,
      "learning_rate": 2.1557143657400368e-05,
      "loss": 2.4872,
      "step": 35470
    },
    {
      "epoch": 2.381061038220194,
      "grad_norm": 0.6557552814483643,
      "learning_rate": 2.151222810874066e-05,
      "loss": 2.4025,
      "step": 35480
    },
    {
      "epoch": 2.381732156639039,
      "grad_norm": 0.6817867755889893,
      "learning_rate": 2.1467353760643727e-05,
      "loss": 2.3889,
      "step": 35490
    },
    {
      "epoch": 2.382403275057884,
      "grad_norm": 0.6646910309791565,
      "learning_rate": 2.1422520636665432e-05,
      "loss": 2.4163,
      "step": 35500
    },
    {
      "epoch": 2.382403275057884,
      "eval_bleu": 21.176564557695993,
      "eval_gen_len": 29.121,
      "eval_loss": 2.9312264919281006,
      "eval_runtime": 73.7816,
      "eval_samples_per_second": 13.554,
      "eval_steps_per_second": 0.854,
      "step": 35500
    },
    {
      "epoch": 2.383074393476729,
      "grad_norm": 0.6683037877082825,
      "learning_rate": 2.137772876034001e-05,
      "loss": 2.4205,
      "step": 35510
    },
    {
      "epoch": 2.383745511895574,
      "grad_norm": 0.7108265161514282,
      "learning_rate": 2.1332978155180004e-05,
      "loss": 2.4766,
      "step": 35520
    },
    {
      "epoch": 2.384416630314419,
      "grad_norm": 0.7013335824012756,
      "learning_rate": 2.1288268844676417e-05,
      "loss": 2.4338,
      "step": 35530
    },
    {
      "epoch": 2.385087748733264,
      "grad_norm": 0.6648284196853638,
      "learning_rate": 2.1243600852298417e-05,
      "loss": 2.4139,
      "step": 35540
    },
    {
      "epoch": 2.385758867152109,
      "grad_norm": 0.693146288394928,
      "learning_rate": 2.1198974201493628e-05,
      "loss": 2.452,
      "step": 35550
    },
    {
      "epoch": 2.385758867152109,
      "eval_bleu": 21.221828031863435,
      "eval_gen_len": 29.112,
      "eval_loss": 2.9315993785858154,
      "eval_runtime": 72.5289,
      "eval_samples_per_second": 13.788,
      "eval_steps_per_second": 0.869,
      "step": 35550
    },
    {
      "epoch": 2.386429985570954,
      "grad_norm": 0.6622843742370605,
      "learning_rate": 2.115438891568784e-05,
      "loss": 2.4535,
      "step": 35560
    },
    {
      "epoch": 2.387101103989799,
      "grad_norm": 0.7569458484649658,
      "learning_rate": 2.1109845018285258e-05,
      "loss": 2.408,
      "step": 35570
    },
    {
      "epoch": 2.387772222408644,
      "grad_norm": 0.5707969665527344,
      "learning_rate": 2.1065342532668264e-05,
      "loss": 2.4738,
      "step": 35580
    },
    {
      "epoch": 2.388443340827489,
      "grad_norm": 0.6700210571289062,
      "learning_rate": 2.102088148219753e-05,
      "loss": 2.4095,
      "step": 35590
    },
    {
      "epoch": 2.389114459246334,
      "grad_norm": 0.7226678133010864,
      "learning_rate": 2.0976461890211975e-05,
      "loss": 2.4093,
      "step": 35600
    },
    {
      "epoch": 2.389114459246334,
      "eval_bleu": 21.41775875945134,
      "eval_gen_len": 29.117,
      "eval_loss": 2.93180775642395,
      "eval_runtime": 73.525,
      "eval_samples_per_second": 13.601,
      "eval_steps_per_second": 0.857,
      "step": 35600
    },
    {
      "epoch": 2.389785577665179,
      "grad_norm": 0.7218711972236633,
      "learning_rate": 2.0932083780028788e-05,
      "loss": 2.4188,
      "step": 35610
    },
    {
      "epoch": 2.390456696084024,
      "grad_norm": 0.6773787140846252,
      "learning_rate": 2.0887747174943317e-05,
      "loss": 2.4552,
      "step": 35620
    },
    {
      "epoch": 2.391127814502869,
      "grad_norm": 0.721875786781311,
      "learning_rate": 2.084345209822922e-05,
      "loss": 2.4284,
      "step": 35630
    },
    {
      "epoch": 2.391798932921714,
      "grad_norm": 0.7471599578857422,
      "learning_rate": 2.0799198573138244e-05,
      "loss": 2.4498,
      "step": 35640
    },
    {
      "epoch": 2.3924700513405592,
      "grad_norm": 0.7191222310066223,
      "learning_rate": 2.075498662290043e-05,
      "loss": 2.4754,
      "step": 35650
    },
    {
      "epoch": 2.3924700513405592,
      "eval_bleu": 21.369653714935726,
      "eval_gen_len": 28.878,
      "eval_loss": 2.929949998855591,
      "eval_runtime": 69.0117,
      "eval_samples_per_second": 14.49,
      "eval_steps_per_second": 0.913,
      "step": 35650
    },
    {
      "epoch": 2.393141169759404,
      "grad_norm": 0.6968061923980713,
      "learning_rate": 2.07108162707239e-05,
      "loss": 2.402,
      "step": 35660
    },
    {
      "epoch": 2.393812288178249,
      "grad_norm": 0.6790728569030762,
      "learning_rate": 2.0666687539795016e-05,
      "loss": 2.4716,
      "step": 35670
    },
    {
      "epoch": 2.394483406597094,
      "grad_norm": 0.728781521320343,
      "learning_rate": 2.062260045327824e-05,
      "loss": 2.4144,
      "step": 35680
    },
    {
      "epoch": 2.395154525015939,
      "grad_norm": 0.6313742399215698,
      "learning_rate": 2.0578555034316205e-05,
      "loss": 2.4629,
      "step": 35690
    },
    {
      "epoch": 2.395825643434784,
      "grad_norm": 0.7234644293785095,
      "learning_rate": 2.0534551306029627e-05,
      "loss": 2.4632,
      "step": 35700
    },
    {
      "epoch": 2.395825643434784,
      "eval_bleu": 21.07902755922958,
      "eval_gen_len": 29.106,
      "eval_loss": 2.930323362350464,
      "eval_runtime": 73.2524,
      "eval_samples_per_second": 13.651,
      "eval_steps_per_second": 0.86,
      "step": 35700
    },
    {
      "epoch": 2.396496761853629,
      "grad_norm": 0.6635869145393372,
      "learning_rate": 2.0490589291517414e-05,
      "loss": 2.4139,
      "step": 35710
    },
    {
      "epoch": 2.397167880272474,
      "grad_norm": 0.7917539477348328,
      "learning_rate": 2.04466690138565e-05,
      "loss": 2.4792,
      "step": 35720
    },
    {
      "epoch": 2.397838998691319,
      "grad_norm": 0.7142826914787292,
      "learning_rate": 2.0402790496101976e-05,
      "loss": 2.4398,
      "step": 35730
    },
    {
      "epoch": 2.398510117110164,
      "grad_norm": 0.7376859188079834,
      "learning_rate": 2.035895376128696e-05,
      "loss": 2.4581,
      "step": 35740
    },
    {
      "epoch": 2.399181235529009,
      "grad_norm": 0.6682792901992798,
      "learning_rate": 2.0315158832422632e-05,
      "loss": 2.4528,
      "step": 35750
    },
    {
      "epoch": 2.399181235529009,
      "eval_bleu": 21.231713361565838,
      "eval_gen_len": 28.856,
      "eval_loss": 2.929548501968384,
      "eval_runtime": 69.739,
      "eval_samples_per_second": 14.339,
      "eval_steps_per_second": 0.903,
      "step": 35750
    },
    {
      "epoch": 2.3998523539478542,
      "grad_norm": 0.7601816058158875,
      "learning_rate": 2.0271405732498305e-05,
      "loss": 2.4416,
      "step": 35760
    },
    {
      "epoch": 2.4005234723666993,
      "grad_norm": 0.6856357455253601,
      "learning_rate": 2.0227694484481253e-05,
      "loss": 2.4233,
      "step": 35770
    },
    {
      "epoch": 2.4011945907855443,
      "grad_norm": 0.6603485345840454,
      "learning_rate": 2.0184025111316806e-05,
      "loss": 2.4276,
      "step": 35780
    },
    {
      "epoch": 2.4018657092043894,
      "grad_norm": 0.7046803832054138,
      "learning_rate": 2.0140397635928287e-05,
      "loss": 2.4608,
      "step": 35790
    },
    {
      "epoch": 2.402536827623234,
      "grad_norm": 0.6649038195610046,
      "learning_rate": 2.009681208121712e-05,
      "loss": 2.4486,
      "step": 35800
    },
    {
      "epoch": 2.402536827623234,
      "eval_bleu": 21.29105209293189,
      "eval_gen_len": 28.839,
      "eval_loss": 2.9283368587493896,
      "eval_runtime": 69.8581,
      "eval_samples_per_second": 14.315,
      "eval_steps_per_second": 0.902,
      "step": 35800
    },
    {
      "epoch": 2.403207946042079,
      "grad_norm": 0.658591091632843,
      "learning_rate": 2.005326847006258e-05,
      "loss": 2.4355,
      "step": 35810
    },
    {
      "epoch": 2.403879064460924,
      "grad_norm": 0.6839622259140015,
      "learning_rate": 2.0009766825322086e-05,
      "loss": 2.3973,
      "step": 35820
    },
    {
      "epoch": 2.404550182879769,
      "grad_norm": 0.7044127583503723,
      "learning_rate": 1.9966307169830856e-05,
      "loss": 2.4844,
      "step": 35830
    },
    {
      "epoch": 2.405221301298614,
      "grad_norm": 0.6461421847343445,
      "learning_rate": 1.9922889526402234e-05,
      "loss": 2.4172,
      "step": 35840
    },
    {
      "epoch": 2.405892419717459,
      "grad_norm": 0.6683996915817261,
      "learning_rate": 1.9879513917827386e-05,
      "loss": 2.4478,
      "step": 35850
    },
    {
      "epoch": 2.405892419717459,
      "eval_bleu": 21.361193121500456,
      "eval_gen_len": 28.843,
      "eval_loss": 2.929128885269165,
      "eval_runtime": 69.415,
      "eval_samples_per_second": 14.406,
      "eval_steps_per_second": 0.908,
      "step": 35850
    },
    {
      "epoch": 2.406563538136304,
      "grad_norm": 0.7446038126945496,
      "learning_rate": 1.983618036687548e-05,
      "loss": 2.4298,
      "step": 35860
    },
    {
      "epoch": 2.4072346565551492,
      "grad_norm": 0.7349064946174622,
      "learning_rate": 1.9792888896293526e-05,
      "loss": 2.4216,
      "step": 35870
    },
    {
      "epoch": 2.4079057749739943,
      "grad_norm": 0.672600269317627,
      "learning_rate": 1.9749639528806584e-05,
      "loss": 2.3974,
      "step": 35880
    },
    {
      "epoch": 2.4085768933928393,
      "grad_norm": 0.7278895974159241,
      "learning_rate": 1.970643228711747e-05,
      "loss": 2.4525,
      "step": 35890
    },
    {
      "epoch": 2.4092480118116844,
      "grad_norm": 0.7256627678871155,
      "learning_rate": 1.9663267193907e-05,
      "loss": 2.4201,
      "step": 35900
    },
    {
      "epoch": 2.4092480118116844,
      "eval_bleu": 21.289300273590488,
      "eval_gen_len": 28.858,
      "eval_loss": 2.930769920349121,
      "eval_runtime": 61.335,
      "eval_samples_per_second": 16.304,
      "eval_steps_per_second": 1.027,
      "step": 35900
    },
    {
      "epoch": 2.409919130230529,
      "grad_norm": 0.7482240200042725,
      "learning_rate": 1.9620144271833753e-05,
      "loss": 2.4344,
      "step": 35910
    },
    {
      "epoch": 2.410590248649374,
      "grad_norm": 0.7437270879745483,
      "learning_rate": 1.957706354353429e-05,
      "loss": 2.446,
      "step": 35920
    },
    {
      "epoch": 2.411261367068219,
      "grad_norm": 0.6943086981773376,
      "learning_rate": 1.9534025031622916e-05,
      "loss": 2.3645,
      "step": 35930
    },
    {
      "epoch": 2.411932485487064,
      "grad_norm": 0.7567818760871887,
      "learning_rate": 1.9491028758691877e-05,
      "loss": 2.462,
      "step": 35940
    },
    {
      "epoch": 2.412603603905909,
      "grad_norm": 0.7070913910865784,
      "learning_rate": 1.9448074747311152e-05,
      "loss": 2.4781,
      "step": 35950
    },
    {
      "epoch": 2.412603603905909,
      "eval_bleu": 21.324160977445906,
      "eval_gen_len": 28.82,
      "eval_loss": 2.930718183517456,
      "eval_runtime": 60.532,
      "eval_samples_per_second": 16.52,
      "eval_steps_per_second": 1.041,
      "step": 35950
    },
    {
      "epoch": 2.413274722324754,
      "grad_norm": 0.707100510597229,
      "learning_rate": 1.9405163020028606e-05,
      "loss": 2.4092,
      "step": 35960
    },
    {
      "epoch": 2.413945840743599,
      "grad_norm": 0.7310556769371033,
      "learning_rate": 1.936229359936983e-05,
      "loss": 2.4722,
      "step": 35970
    },
    {
      "epoch": 2.4146169591624442,
      "grad_norm": 0.7997409105300903,
      "learning_rate": 1.9319466507838313e-05,
      "loss": 2.4617,
      "step": 35980
    },
    {
      "epoch": 2.4152880775812893,
      "grad_norm": 0.7144412994384766,
      "learning_rate": 1.9276681767915228e-05,
      "loss": 2.4511,
      "step": 35990
    },
    {
      "epoch": 2.4159591960001343,
      "grad_norm": 0.7201640009880066,
      "learning_rate": 1.9233939402059586e-05,
      "loss": 2.4422,
      "step": 36000
    },
    {
      "epoch": 2.4159591960001343,
      "eval_bleu": 21.19815938924047,
      "eval_gen_len": 28.864,
      "eval_loss": 2.93107533454895,
      "eval_runtime": 69.5779,
      "eval_samples_per_second": 14.372,
      "eval_steps_per_second": 0.905,
      "step": 36000
    },
    {
      "epoch": 2.4166303144189794,
      "grad_norm": 0.701807975769043,
      "learning_rate": 1.9191239432708096e-05,
      "loss": 2.4285,
      "step": 36010
    },
    {
      "epoch": 2.4173014328378244,
      "grad_norm": 0.6865429878234863,
      "learning_rate": 1.9148581882275274e-05,
      "loss": 2.4447,
      "step": 36020
    },
    {
      "epoch": 2.4179725512566694,
      "grad_norm": 0.6634252667427063,
      "learning_rate": 1.9105966773153317e-05,
      "loss": 2.4444,
      "step": 36030
    },
    {
      "epoch": 2.4186436696755145,
      "grad_norm": 0.7057253122329712,
      "learning_rate": 1.9063394127712163e-05,
      "loss": 2.4176,
      "step": 36040
    },
    {
      "epoch": 2.419314788094359,
      "grad_norm": 0.7257744669914246,
      "learning_rate": 1.902086396829945e-05,
      "loss": 2.4417,
      "step": 36050
    },
    {
      "epoch": 2.419314788094359,
      "eval_bleu": 21.268873085563268,
      "eval_gen_len": 28.863,
      "eval_loss": 2.9311397075653076,
      "eval_runtime": 63.7013,
      "eval_samples_per_second": 15.698,
      "eval_steps_per_second": 0.989,
      "step": 36050
    },
    {
      "epoch": 2.419985906513204,
      "grad_norm": 0.6136959791183472,
      "learning_rate": 1.897837631724051e-05,
      "loss": 2.4201,
      "step": 36060
    },
    {
      "epoch": 2.420657024932049,
      "grad_norm": 0.6683425903320312,
      "learning_rate": 1.8935931196838406e-05,
      "loss": 2.4352,
      "step": 36070
    },
    {
      "epoch": 2.421328143350894,
      "grad_norm": 0.7336126565933228,
      "learning_rate": 1.8893528629373802e-05,
      "loss": 2.4294,
      "step": 36080
    },
    {
      "epoch": 2.4219992617697392,
      "grad_norm": 0.6827456951141357,
      "learning_rate": 1.885116863710512e-05,
      "loss": 2.4324,
      "step": 36090
    },
    {
      "epoch": 2.4226703801885843,
      "grad_norm": 0.6554723978042603,
      "learning_rate": 1.880885124226832e-05,
      "loss": 2.4224,
      "step": 36100
    },
    {
      "epoch": 2.4226703801885843,
      "eval_bleu": 21.21967244540268,
      "eval_gen_len": 28.787,
      "eval_loss": 2.9309942722320557,
      "eval_runtime": 64.9393,
      "eval_samples_per_second": 15.399,
      "eval_steps_per_second": 0.97,
      "step": 36100
    },
    {
      "epoch": 2.4233414986074293,
      "grad_norm": 0.7379826903343201,
      "learning_rate": 1.8766576467077113e-05,
      "loss": 2.4719,
      "step": 36110
    },
    {
      "epoch": 2.4240126170262744,
      "grad_norm": 0.6888565421104431,
      "learning_rate": 1.8724344333722765e-05,
      "loss": 2.4715,
      "step": 36120
    },
    {
      "epoch": 2.4246837354451194,
      "grad_norm": 0.7602015137672424,
      "learning_rate": 1.8682154864374168e-05,
      "loss": 2.4744,
      "step": 36130
    },
    {
      "epoch": 2.4253548538639644,
      "grad_norm": 0.7090102434158325,
      "learning_rate": 1.8640008081177808e-05,
      "loss": 2.3971,
      "step": 36140
    },
    {
      "epoch": 2.4260259722828095,
      "grad_norm": 0.69320148229599,
      "learning_rate": 1.8597904006257816e-05,
      "loss": 2.4067,
      "step": 36150
    },
    {
      "epoch": 2.4260259722828095,
      "eval_bleu": 21.030742128256232,
      "eval_gen_len": 29.272,
      "eval_loss": 2.9315738677978516,
      "eval_runtime": 78.0295,
      "eval_samples_per_second": 12.816,
      "eval_steps_per_second": 0.807,
      "step": 36150
    },
    {
      "epoch": 2.426697090701654,
      "grad_norm": 0.6703991889953613,
      "learning_rate": 1.855584266171585e-05,
      "loss": 2.4108,
      "step": 36160
    },
    {
      "epoch": 2.427368209120499,
      "grad_norm": 0.7061601877212524,
      "learning_rate": 1.851382406963119e-05,
      "loss": 2.4188,
      "step": 36170
    },
    {
      "epoch": 2.428039327539344,
      "grad_norm": 0.7199222445487976,
      "learning_rate": 1.847184825206061e-05,
      "loss": 2.5088,
      "step": 36180
    },
    {
      "epoch": 2.428710445958189,
      "grad_norm": 0.6494497656822205,
      "learning_rate": 1.8429915231038484e-05,
      "loss": 2.368,
      "step": 36190
    },
    {
      "epoch": 2.4293815643770342,
      "grad_norm": 0.6833360195159912,
      "learning_rate": 1.8388025028576682e-05,
      "loss": 2.3904,
      "step": 36200
    },
    {
      "epoch": 2.4293815643770342,
      "eval_bleu": 21.159611382992793,
      "eval_gen_len": 28.877,
      "eval_loss": 2.9311225414276123,
      "eval_runtime": 60.9406,
      "eval_samples_per_second": 16.409,
      "eval_steps_per_second": 1.034,
      "step": 36200
    },
    {
      "epoch": 2.4300526827958793,
      "grad_norm": 0.7478559613227844,
      "learning_rate": 1.8346177666664675e-05,
      "loss": 2.4113,
      "step": 36210
    },
    {
      "epoch": 2.4307238012147243,
      "grad_norm": 0.7353180646896362,
      "learning_rate": 1.8304373167269285e-05,
      "loss": 2.485,
      "step": 36220
    },
    {
      "epoch": 2.4313949196335694,
      "grad_norm": 0.7209128141403198,
      "learning_rate": 1.8262611552335006e-05,
      "loss": 2.4312,
      "step": 36230
    },
    {
      "epoch": 2.4320660380524144,
      "grad_norm": 0.7256283164024353,
      "learning_rate": 1.822089284378372e-05,
      "loss": 2.4238,
      "step": 36240
    },
    {
      "epoch": 2.4327371564712594,
      "grad_norm": 0.7047744989395142,
      "learning_rate": 1.817921706351484e-05,
      "loss": 2.4689,
      "step": 36250
    },
    {
      "epoch": 2.4327371564712594,
      "eval_bleu": 21.079229776185056,
      "eval_gen_len": 28.909,
      "eval_loss": 2.929949998855591,
      "eval_runtime": 60.7364,
      "eval_samples_per_second": 16.465,
      "eval_steps_per_second": 1.037,
      "step": 36250
    },
    {
      "epoch": 2.4334082748901045,
      "grad_norm": 0.6963364481925964,
      "learning_rate": 1.8137584233405204e-05,
      "loss": 2.4372,
      "step": 36260
    },
    {
      "epoch": 2.4340793933089495,
      "grad_norm": 0.7362966537475586,
      "learning_rate": 1.8095994375309133e-05,
      "loss": 2.4677,
      "step": 36270
    },
    {
      "epoch": 2.4347505117277946,
      "grad_norm": 0.7143102288246155,
      "learning_rate": 1.805444751105836e-05,
      "loss": 2.4529,
      "step": 36280
    },
    {
      "epoch": 2.4354216301466396,
      "grad_norm": 0.6376672387123108,
      "learning_rate": 1.80129436624621e-05,
      "loss": 2.4416,
      "step": 36290
    },
    {
      "epoch": 2.436092748565484,
      "grad_norm": 0.696419358253479,
      "learning_rate": 1.7971482851306943e-05,
      "loss": 2.4828,
      "step": 36300
    },
    {
      "epoch": 2.436092748565484,
      "eval_bleu": 21.373956242281015,
      "eval_gen_len": 28.867,
      "eval_loss": 2.929506301879883,
      "eval_runtime": 60.8778,
      "eval_samples_per_second": 16.426,
      "eval_steps_per_second": 1.035,
      "step": 36300
    },
    {
      "epoch": 2.4367638669843292,
      "grad_norm": 0.6852590441703796,
      "learning_rate": 1.7930065099356884e-05,
      "loss": 2.4341,
      "step": 36310
    },
    {
      "epoch": 2.4374349854031743,
      "grad_norm": 0.6951406002044678,
      "learning_rate": 1.788869042835335e-05,
      "loss": 2.4842,
      "step": 36320
    },
    {
      "epoch": 2.4381061038220193,
      "grad_norm": 0.6647288203239441,
      "learning_rate": 1.7847358860015096e-05,
      "loss": 2.3925,
      "step": 36330
    },
    {
      "epoch": 2.4387772222408644,
      "grad_norm": 0.6575034260749817,
      "learning_rate": 1.7806070416038345e-05,
      "loss": 2.4336,
      "step": 36340
    },
    {
      "epoch": 2.4394483406597094,
      "grad_norm": 0.6617684364318848,
      "learning_rate": 1.7764825118096584e-05,
      "loss": 2.4191,
      "step": 36350
    },
    {
      "epoch": 2.4394483406597094,
      "eval_bleu": 21.118196609447295,
      "eval_gen_len": 28.869,
      "eval_loss": 2.9305782318115234,
      "eval_runtime": 61.4295,
      "eval_samples_per_second": 16.279,
      "eval_steps_per_second": 1.026,
      "step": 36350
    },
    {
      "epoch": 2.4401194590785544,
      "grad_norm": 0.760052502155304,
      "learning_rate": 1.7723622987840727e-05,
      "loss": 2.4818,
      "step": 36360
    },
    {
      "epoch": 2.4407905774973995,
      "grad_norm": 0.6339651346206665,
      "learning_rate": 1.768246404689897e-05,
      "loss": 2.4689,
      "step": 36370
    },
    {
      "epoch": 2.4414616959162445,
      "grad_norm": 0.6903544664382935,
      "learning_rate": 1.7641348316876894e-05,
      "loss": 2.3862,
      "step": 36380
    },
    {
      "epoch": 2.4421328143350896,
      "grad_norm": 0.644828736782074,
      "learning_rate": 1.7600275819357348e-05,
      "loss": 2.428,
      "step": 36390
    },
    {
      "epoch": 2.4428039327539346,
      "grad_norm": 0.6745765209197998,
      "learning_rate": 1.755924657590051e-05,
      "loss": 2.4774,
      "step": 36400
    },
    {
      "epoch": 2.4428039327539346,
      "eval_bleu": 21.00306434766839,
      "eval_gen_len": 28.825,
      "eval_loss": 2.9306347370147705,
      "eval_runtime": 61.8149,
      "eval_samples_per_second": 16.177,
      "eval_steps_per_second": 1.019,
      "step": 36400
    },
    {
      "epoch": 2.443475051172779,
      "grad_norm": 0.6330332159996033,
      "learning_rate": 1.7518260608043813e-05,
      "loss": 2.4026,
      "step": 36410
    },
    {
      "epoch": 2.4441461695916242,
      "grad_norm": 0.647361695766449,
      "learning_rate": 1.7477317937302074e-05,
      "loss": 2.4547,
      "step": 36420
    },
    {
      "epoch": 2.4448172880104693,
      "grad_norm": 0.6381979584693909,
      "learning_rate": 1.7436418585167257e-05,
      "loss": 2.4322,
      "step": 36430
    },
    {
      "epoch": 2.4454884064293143,
      "grad_norm": 0.6660972237586975,
      "learning_rate": 1.7395562573108702e-05,
      "loss": 2.4963,
      "step": 36440
    },
    {
      "epoch": 2.4461595248481594,
      "grad_norm": 0.7104693055152893,
      "learning_rate": 1.735474992257289e-05,
      "loss": 2.4714,
      "step": 36450
    },
    {
      "epoch": 2.4461595248481594,
      "eval_bleu": 21.451140585247533,
      "eval_gen_len": 28.851,
      "eval_loss": 2.9300193786621094,
      "eval_runtime": 62.1318,
      "eval_samples_per_second": 16.095,
      "eval_steps_per_second": 1.014,
      "step": 36450
    },
    {
      "epoch": 2.4468306432670044,
      "grad_norm": 0.6387708187103271,
      "learning_rate": 1.731398065498364e-05,
      "loss": 2.4391,
      "step": 36460
    },
    {
      "epoch": 2.4475017616858494,
      "grad_norm": 0.6263041496276855,
      "learning_rate": 1.7273254791741933e-05,
      "loss": 2.455,
      "step": 36470
    },
    {
      "epoch": 2.4481728801046945,
      "grad_norm": 0.6850650906562805,
      "learning_rate": 1.7232572354225972e-05,
      "loss": 2.4209,
      "step": 36480
    },
    {
      "epoch": 2.4488439985235395,
      "grad_norm": 0.6782364249229431,
      "learning_rate": 1.719193336379118e-05,
      "loss": 2.4838,
      "step": 36490
    },
    {
      "epoch": 2.4495151169423846,
      "grad_norm": 0.6853739023208618,
      "learning_rate": 1.7151337841770187e-05,
      "loss": 2.448,
      "step": 36500
    },
    {
      "epoch": 2.4495151169423846,
      "eval_bleu": 21.385500568179914,
      "eval_gen_len": 28.852,
      "eval_loss": 2.92972469329834,
      "eval_runtime": 62.1937,
      "eval_samples_per_second": 16.079,
      "eval_steps_per_second": 1.013,
      "step": 36500
    },
    {
      "epoch": 2.4501862353612296,
      "grad_norm": 0.729756236076355,
      "learning_rate": 1.7110785809472763e-05,
      "loss": 2.4155,
      "step": 36510
    },
    {
      "epoch": 2.4508573537800746,
      "grad_norm": 0.7207997441291809,
      "learning_rate": 1.70702772881859e-05,
      "loss": 2.4119,
      "step": 36520
    },
    {
      "epoch": 2.4515284721989197,
      "grad_norm": 0.7688745856285095,
      "learning_rate": 1.7029812299173697e-05,
      "loss": 2.4495,
      "step": 36530
    },
    {
      "epoch": 2.4521995906177647,
      "grad_norm": 0.6354061961174011,
      "learning_rate": 1.698939086367747e-05,
      "loss": 2.4383,
      "step": 36540
    },
    {
      "epoch": 2.4528707090366098,
      "grad_norm": 0.6834101676940918,
      "learning_rate": 1.694901300291558e-05,
      "loss": 2.5004,
      "step": 36550
    },
    {
      "epoch": 2.4528707090366098,
      "eval_bleu": 21.31430136500382,
      "eval_gen_len": 28.888,
      "eval_loss": 2.9309539794921875,
      "eval_runtime": 61.9036,
      "eval_samples_per_second": 16.154,
      "eval_steps_per_second": 1.018,
      "step": 36550
    },
    {
      "epoch": 2.4535418274554543,
      "grad_norm": 0.6505139470100403,
      "learning_rate": 1.6908678738083615e-05,
      "loss": 2.4182,
      "step": 36560
    },
    {
      "epoch": 2.4542129458742994,
      "grad_norm": 0.7010418176651001,
      "learning_rate": 1.6868388090354214e-05,
      "loss": 2.4528,
      "step": 36570
    },
    {
      "epoch": 2.4548840642931444,
      "grad_norm": 0.6997284293174744,
      "learning_rate": 1.6828141080877113e-05,
      "loss": 2.4403,
      "step": 36580
    },
    {
      "epoch": 2.4555551827119895,
      "grad_norm": 0.6752982139587402,
      "learning_rate": 1.6787937730779156e-05,
      "loss": 2.3693,
      "step": 36590
    },
    {
      "epoch": 2.4562263011308345,
      "grad_norm": 0.7651993632316589,
      "learning_rate": 1.674777806116432e-05,
      "loss": 2.4917,
      "step": 36600
    },
    {
      "epoch": 2.4562263011308345,
      "eval_bleu": 21.335126813045466,
      "eval_gen_len": 28.908,
      "eval_loss": 2.9304592609405518,
      "eval_runtime": 60.6265,
      "eval_samples_per_second": 16.494,
      "eval_steps_per_second": 1.039,
      "step": 36600
    },
    {
      "epoch": 2.4568974195496796,
      "grad_norm": 0.6908884644508362,
      "learning_rate": 1.670766209311356e-05,
      "loss": 2.474,
      "step": 36610
    },
    {
      "epoch": 2.4575685379685246,
      "grad_norm": 0.7626205086708069,
      "learning_rate": 1.6667589847684982e-05,
      "loss": 2.437,
      "step": 36620
    },
    {
      "epoch": 2.4582396563873696,
      "grad_norm": 0.6508867144584656,
      "learning_rate": 1.662756134591369e-05,
      "loss": 2.4355,
      "step": 36630
    },
    {
      "epoch": 2.4589107748062147,
      "grad_norm": 0.7635390758514404,
      "learning_rate": 1.6587576608811783e-05,
      "loss": 2.4494,
      "step": 36640
    },
    {
      "epoch": 2.4595818932250597,
      "grad_norm": 0.7088620662689209,
      "learning_rate": 1.654763565736851e-05,
      "loss": 2.4494,
      "step": 36650
    },
    {
      "epoch": 2.4595818932250597,
      "eval_bleu": 21.277594822327853,
      "eval_gen_len": 28.917,
      "eval_loss": 2.9304165840148926,
      "eval_runtime": 62.5582,
      "eval_samples_per_second": 15.985,
      "eval_steps_per_second": 1.007,
      "step": 36650
    },
    {
      "epoch": 2.4602530116439048,
      "grad_norm": 0.6527653932571411,
      "learning_rate": 1.650773851255003e-05,
      "loss": 2.4259,
      "step": 36660
    },
    {
      "epoch": 2.4609241300627493,
      "grad_norm": 0.7291170954704285,
      "learning_rate": 1.6467885195299527e-05,
      "loss": 2.4946,
      "step": 36670
    },
    {
      "epoch": 2.4615952484815944,
      "grad_norm": 0.7227396965026855,
      "learning_rate": 1.6428075726537185e-05,
      "loss": 2.3976,
      "step": 36680
    },
    {
      "epoch": 2.4622663669004394,
      "grad_norm": 0.7317695021629333,
      "learning_rate": 1.6388310127160222e-05,
      "loss": 2.4689,
      "step": 36690
    },
    {
      "epoch": 2.4629374853192845,
      "grad_norm": 0.6390218138694763,
      "learning_rate": 1.6348588418042732e-05,
      "loss": 2.4533,
      "step": 36700
    },
    {
      "epoch": 2.4629374853192845,
      "eval_bleu": 21.417745496770614,
      "eval_gen_len": 28.823,
      "eval_loss": 2.9297597408294678,
      "eval_runtime": 61.8275,
      "eval_samples_per_second": 16.174,
      "eval_steps_per_second": 1.019,
      "step": 36700
    },
    {
      "epoch": 2.4636086037381295,
      "grad_norm": 0.7258818745613098,
      "learning_rate": 1.6308910620035856e-05,
      "loss": 2.4363,
      "step": 36710
    },
    {
      "epoch": 2.4642797221569746,
      "grad_norm": 0.6317455768585205,
      "learning_rate": 1.6269276753967623e-05,
      "loss": 2.4103,
      "step": 36720
    },
    {
      "epoch": 2.4649508405758196,
      "grad_norm": 0.691118597984314,
      "learning_rate": 1.6229686840643042e-05,
      "loss": 2.4667,
      "step": 36730
    },
    {
      "epoch": 2.4656219589946646,
      "grad_norm": 0.6920799612998962,
      "learning_rate": 1.619014090084405e-05,
      "loss": 2.4805,
      "step": 36740
    },
    {
      "epoch": 2.4662930774135097,
      "grad_norm": 0.6648871898651123,
      "learning_rate": 1.6150638955329455e-05,
      "loss": 2.4228,
      "step": 36750
    },
    {
      "epoch": 2.4662930774135097,
      "eval_bleu": 21.332669305931034,
      "eval_gen_len": 28.858,
      "eval_loss": 2.928941249847412,
      "eval_runtime": 61.4991,
      "eval_samples_per_second": 16.26,
      "eval_steps_per_second": 1.024,
      "step": 36750
    },
    {
      "epoch": 2.4669641958323547,
      "grad_norm": 0.7353601455688477,
      "learning_rate": 1.6111181024835e-05,
      "loss": 2.4138,
      "step": 36760
    },
    {
      "epoch": 2.4676353142511998,
      "grad_norm": 0.671181321144104,
      "learning_rate": 1.6071767130073355e-05,
      "loss": 2.4765,
      "step": 36770
    },
    {
      "epoch": 2.468306432670045,
      "grad_norm": 0.694229006767273,
      "learning_rate": 1.6032397291734e-05,
      "loss": 2.4459,
      "step": 36780
    },
    {
      "epoch": 2.46897755108889,
      "grad_norm": 0.6587046980857849,
      "learning_rate": 1.5993071530483384e-05,
      "loss": 2.5186,
      "step": 36790
    },
    {
      "epoch": 2.469648669507735,
      "grad_norm": 0.6951884031295776,
      "learning_rate": 1.595378986696472e-05,
      "loss": 2.4776,
      "step": 36800
    },
    {
      "epoch": 2.469648669507735,
      "eval_bleu": 21.197704057129883,
      "eval_gen_len": 28.821,
      "eval_loss": 2.929781436920166,
      "eval_runtime": 61.4321,
      "eval_samples_per_second": 16.278,
      "eval_steps_per_second": 1.026,
      "step": 36800
    },
    {
      "epoch": 2.4703197879265795,
      "grad_norm": 0.6601654291152954,
      "learning_rate": 1.591455232179817e-05,
      "loss": 2.4678,
      "step": 36810
    },
    {
      "epoch": 2.4709909063454245,
      "grad_norm": 0.6409987807273865,
      "learning_rate": 1.587535891558063e-05,
      "loss": 2.4294,
      "step": 36820
    },
    {
      "epoch": 2.4716620247642695,
      "grad_norm": 0.7103090882301331,
      "learning_rate": 1.583620966888596e-05,
      "loss": 2.4637,
      "step": 36830
    },
    {
      "epoch": 2.4723331431831146,
      "grad_norm": 0.6902619004249573,
      "learning_rate": 1.5797104602264667e-05,
      "loss": 2.4272,
      "step": 36840
    },
    {
      "epoch": 2.4730042616019596,
      "grad_norm": 0.7485389709472656,
      "learning_rate": 1.575804373624423e-05,
      "loss": 2.418,
      "step": 36850
    },
    {
      "epoch": 2.4730042616019596,
      "eval_bleu": 21.28966774602647,
      "eval_gen_len": 28.832,
      "eval_loss": 2.9300858974456787,
      "eval_runtime": 61.5668,
      "eval_samples_per_second": 16.243,
      "eval_steps_per_second": 1.023,
      "step": 36850
    },
    {
      "epoch": 2.4736753800208047,
      "grad_norm": 0.7378165125846863,
      "learning_rate": 1.571902709132882e-05,
      "loss": 2.4825,
      "step": 36860
    },
    {
      "epoch": 2.4743464984396497,
      "grad_norm": 0.6561658978462219,
      "learning_rate": 1.568005468799948e-05,
      "loss": 2.4386,
      "step": 36870
    },
    {
      "epoch": 2.4750176168584948,
      "grad_norm": 0.6970435380935669,
      "learning_rate": 1.5641126546713912e-05,
      "loss": 2.4556,
      "step": 36880
    },
    {
      "epoch": 2.47568873527734,
      "grad_norm": 0.7046569585800171,
      "learning_rate": 1.560224268790673e-05,
      "loss": 2.4095,
      "step": 36890
    },
    {
      "epoch": 2.476359853696185,
      "grad_norm": 0.7285084128379822,
      "learning_rate": 1.5563403131989162e-05,
      "loss": 2.452,
      "step": 36900
    },
    {
      "epoch": 2.476359853696185,
      "eval_bleu": 21.252984940827474,
      "eval_gen_len": 28.893,
      "eval_loss": 2.929957866668701,
      "eval_runtime": 62.1404,
      "eval_samples_per_second": 16.093,
      "eval_steps_per_second": 1.014,
      "step": 36900
    },
    {
      "epoch": 2.47703097211503,
      "grad_norm": 0.7175841331481934,
      "learning_rate": 1.5524607899349296e-05,
      "loss": 2.4437,
      "step": 36910
    },
    {
      "epoch": 2.4777020905338745,
      "grad_norm": 0.7250161170959473,
      "learning_rate": 1.5485857010351877e-05,
      "loss": 2.3969,
      "step": 36920
    },
    {
      "epoch": 2.4783732089527195,
      "grad_norm": 0.725624680519104,
      "learning_rate": 1.5447150485338403e-05,
      "loss": 2.4528,
      "step": 36930
    },
    {
      "epoch": 2.4790443273715645,
      "grad_norm": 0.7685171365737915,
      "learning_rate": 1.540848834462707e-05,
      "loss": 2.5002,
      "step": 36940
    },
    {
      "epoch": 2.4797154457904096,
      "grad_norm": 0.7928272485733032,
      "learning_rate": 1.536987060851277e-05,
      "loss": 2.4154,
      "step": 36950
    },
    {
      "epoch": 2.4797154457904096,
      "eval_bleu": 21.196781350476012,
      "eval_gen_len": 28.841,
      "eval_loss": 2.929478406906128,
      "eval_runtime": 61.9951,
      "eval_samples_per_second": 16.13,
      "eval_steps_per_second": 1.016,
      "step": 36950
    },
    {
      "epoch": 2.4803865642092546,
      "grad_norm": 0.670981228351593,
      "learning_rate": 1.5331297297267133e-05,
      "loss": 2.4673,
      "step": 36960
    },
    {
      "epoch": 2.4810576826280997,
      "grad_norm": 0.7149240970611572,
      "learning_rate": 1.5292768431138414e-05,
      "loss": 2.4267,
      "step": 36970
    },
    {
      "epoch": 2.4817288010469447,
      "grad_norm": 0.723396360874176,
      "learning_rate": 1.5254284030351584e-05,
      "loss": 2.5171,
      "step": 36980
    },
    {
      "epoch": 2.4823999194657898,
      "grad_norm": 0.7114524245262146,
      "learning_rate": 1.5215844115108203e-05,
      "loss": 2.429,
      "step": 36990
    },
    {
      "epoch": 2.483071037884635,
      "grad_norm": 0.7173856496810913,
      "learning_rate": 1.5177448705586573e-05,
      "loss": 2.4087,
      "step": 37000
    },
    {
      "epoch": 2.483071037884635,
      "eval_bleu": 21.35399600474287,
      "eval_gen_len": 28.89,
      "eval_loss": 2.927591562271118,
      "eval_runtime": 62.289,
      "eval_samples_per_second": 16.054,
      "eval_steps_per_second": 1.011,
      "step": 37000
    },
    {
      "epoch": 2.48374215630348,
      "grad_norm": 0.7470251321792603,
      "learning_rate": 1.5139097821941572e-05,
      "loss": 2.4246,
      "step": 37010
    },
    {
      "epoch": 2.484413274722325,
      "grad_norm": 0.6909670829772949,
      "learning_rate": 1.5100791484304711e-05,
      "loss": 2.4499,
      "step": 37020
    },
    {
      "epoch": 2.48508439314117,
      "grad_norm": 0.7697925567626953,
      "learning_rate": 1.506252971278409e-05,
      "loss": 2.4868,
      "step": 37030
    },
    {
      "epoch": 2.485755511560015,
      "grad_norm": 0.6594308018684387,
      "learning_rate": 1.5024312527464512e-05,
      "loss": 2.4463,
      "step": 37040
    },
    {
      "epoch": 2.48642662997886,
      "grad_norm": 0.6612483263015747,
      "learning_rate": 1.4986139948407264e-05,
      "loss": 2.5212,
      "step": 37050
    },
    {
      "epoch": 2.48642662997886,
      "eval_bleu": 21.176581653601115,
      "eval_gen_len": 28.918,
      "eval_loss": 2.928043842315674,
      "eval_runtime": 62.5312,
      "eval_samples_per_second": 15.992,
      "eval_steps_per_second": 1.007,
      "step": 37050
    },
    {
      "epoch": 2.4870977483977046,
      "grad_norm": 0.7283557653427124,
      "learning_rate": 1.4948011995650302e-05,
      "loss": 2.4738,
      "step": 37060
    },
    {
      "epoch": 2.4877688668165496,
      "grad_norm": 0.6792126893997192,
      "learning_rate": 1.4909928689208086e-05,
      "loss": 2.459,
      "step": 37070
    },
    {
      "epoch": 2.4884399852353947,
      "grad_norm": 0.6403059959411621,
      "learning_rate": 1.4871890049071712e-05,
      "loss": 2.4312,
      "step": 37080
    },
    {
      "epoch": 2.4891111036542397,
      "grad_norm": 0.7732172608375549,
      "learning_rate": 1.4833896095208776e-05,
      "loss": 2.4895,
      "step": 37090
    },
    {
      "epoch": 2.4897822220730847,
      "grad_norm": 0.6626701951026917,
      "learning_rate": 1.4795946847563435e-05,
      "loss": 2.4264,
      "step": 37100
    },
    {
      "epoch": 2.4897822220730847,
      "eval_bleu": 21.146451313271786,
      "eval_gen_len": 28.859,
      "eval_loss": 2.9287328720092773,
      "eval_runtime": 61.6167,
      "eval_samples_per_second": 16.229,
      "eval_steps_per_second": 1.022,
      "step": 37100
    },
    {
      "epoch": 2.49045334049193,
      "grad_norm": 0.6753174662590027,
      "learning_rate": 1.4758042326056343e-05,
      "loss": 2.4097,
      "step": 37110
    },
    {
      "epoch": 2.491124458910775,
      "grad_norm": 0.6785200238227844,
      "learning_rate": 1.4720182550584771e-05,
      "loss": 2.3939,
      "step": 37120
    },
    {
      "epoch": 2.49179557732962,
      "grad_norm": 0.6344762444496155,
      "learning_rate": 1.468236754102238e-05,
      "loss": 2.4176,
      "step": 37130
    },
    {
      "epoch": 2.492466695748465,
      "grad_norm": 0.680328369140625,
      "learning_rate": 1.4644597317219433e-05,
      "loss": 2.4873,
      "step": 37140
    },
    {
      "epoch": 2.49313781416731,
      "grad_norm": 0.7063261866569519,
      "learning_rate": 1.4606871899002606e-05,
      "loss": 2.4337,
      "step": 37150
    },
    {
      "epoch": 2.49313781416731,
      "eval_bleu": 21.239549293514244,
      "eval_gen_len": 28.857,
      "eval_loss": 2.929269552230835,
      "eval_runtime": 61.906,
      "eval_samples_per_second": 16.154,
      "eval_steps_per_second": 1.018,
      "step": 37150
    },
    {
      "epoch": 2.493808932586155,
      "grad_norm": 0.6295379400253296,
      "learning_rate": 1.4569191306175146e-05,
      "loss": 2.4754,
      "step": 37160
    },
    {
      "epoch": 2.4944800510049996,
      "grad_norm": 0.6818698048591614,
      "learning_rate": 1.4531555558516653e-05,
      "loss": 2.4498,
      "step": 37170
    },
    {
      "epoch": 2.4951511694238446,
      "grad_norm": 0.6829149723052979,
      "learning_rate": 1.44939646757833e-05,
      "loss": 2.4683,
      "step": 37180
    },
    {
      "epoch": 2.4958222878426897,
      "grad_norm": 0.7075473666191101,
      "learning_rate": 1.445641867770764e-05,
      "loss": 2.443,
      "step": 37190
    },
    {
      "epoch": 2.4964934062615347,
      "grad_norm": 0.6892135739326477,
      "learning_rate": 1.4418917583998682e-05,
      "loss": 2.4286,
      "step": 37200
    },
    {
      "epoch": 2.4964934062615347,
      "eval_bleu": 21.308894524794848,
      "eval_gen_len": 28.917,
      "eval_loss": 2.9288907051086426,
      "eval_runtime": 62.6427,
      "eval_samples_per_second": 15.964,
      "eval_steps_per_second": 1.006,
      "step": 37200
    },
    {
      "epoch": 2.4971645246803797,
      "grad_norm": 0.6566426753997803,
      "learning_rate": 1.4381461414341858e-05,
      "loss": 2.4548,
      "step": 37210
    },
    {
      "epoch": 2.497835643099225,
      "grad_norm": 0.6938344836235046,
      "learning_rate": 1.4344050188399005e-05,
      "loss": 2.4665,
      "step": 37220
    },
    {
      "epoch": 2.49850676151807,
      "grad_norm": 0.7542232275009155,
      "learning_rate": 1.430668392580843e-05,
      "loss": 2.4719,
      "step": 37230
    },
    {
      "epoch": 2.499177879936915,
      "grad_norm": 0.6403700113296509,
      "learning_rate": 1.4269362646184748e-05,
      "loss": 2.4705,
      "step": 37240
    },
    {
      "epoch": 2.49984899835576,
      "grad_norm": 0.7127434015274048,
      "learning_rate": 1.4232086369119058e-05,
      "loss": 2.4302,
      "step": 37250
    },
    {
      "epoch": 2.49984899835576,
      "eval_bleu": 21.47967443074914,
      "eval_gen_len": 28.891,
      "eval_loss": 2.928453207015991,
      "eval_runtime": 62.7587,
      "eval_samples_per_second": 15.934,
      "eval_steps_per_second": 1.004,
      "step": 37250
    },
    {
      "epoch": 2.500520116774605,
      "grad_norm": 0.718277096748352,
      "learning_rate": 1.4194855114178729e-05,
      "loss": 2.41,
      "step": 37260
    },
    {
      "epoch": 2.50119123519345,
      "grad_norm": 0.6829052567481995,
      "learning_rate": 1.4157668900907616e-05,
      "loss": 2.4074,
      "step": 37270
    },
    {
      "epoch": 2.501862353612295,
      "grad_norm": 0.6586408019065857,
      "learning_rate": 1.4120527748825828e-05,
      "loss": 2.4665,
      "step": 37280
    },
    {
      "epoch": 2.50253347203114,
      "grad_norm": 0.6513800024986267,
      "learning_rate": 1.4083431677429871e-05,
      "loss": 2.4989,
      "step": 37290
    },
    {
      "epoch": 2.503204590449985,
      "grad_norm": 0.7225505709648132,
      "learning_rate": 1.404638070619254e-05,
      "loss": 2.4782,
      "step": 37300
    },
    {
      "epoch": 2.503204590449985,
      "eval_bleu": 21.33687647544692,
      "eval_gen_len": 28.934,
      "eval_loss": 2.9299569129943848,
      "eval_runtime": 61.9537,
      "eval_samples_per_second": 16.141,
      "eval_steps_per_second": 1.017,
      "step": 37300
    },
    {
      "epoch": 2.50387570886883,
      "grad_norm": 0.7196034789085388,
      "learning_rate": 1.400937485456304e-05,
      "loss": 2.4021,
      "step": 37310
    },
    {
      "epoch": 2.5045468272876747,
      "grad_norm": 0.7357395887374878,
      "learning_rate": 1.3972414141966795e-05,
      "loss": 2.4761,
      "step": 37320
    },
    {
      "epoch": 2.50521794570652,
      "grad_norm": 0.6819724440574646,
      "learning_rate": 1.3935498587805629e-05,
      "loss": 2.4145,
      "step": 37330
    },
    {
      "epoch": 2.505889064125365,
      "grad_norm": 0.6440200209617615,
      "learning_rate": 1.3898628211457577e-05,
      "loss": 2.4604,
      "step": 37340
    },
    {
      "epoch": 2.50656018254421,
      "grad_norm": 0.6619740724563599,
      "learning_rate": 1.386180303227702e-05,
      "loss": 2.4386,
      "step": 37350
    },
    {
      "epoch": 2.50656018254421,
      "eval_bleu": 21.191191212993733,
      "eval_gen_len": 28.912,
      "eval_loss": 2.9300217628479004,
      "eval_runtime": 62.7826,
      "eval_samples_per_second": 15.928,
      "eval_steps_per_second": 1.003,
      "step": 37350
    },
    {
      "epoch": 2.507231300963055,
      "grad_norm": 0.7012616395950317,
      "learning_rate": 1.3825023069594579e-05,
      "loss": 2.4409,
      "step": 37360
    },
    {
      "epoch": 2.5079024193819,
      "grad_norm": 0.6698811054229736,
      "learning_rate": 1.3788288342717149e-05,
      "loss": 2.4419,
      "step": 37370
    },
    {
      "epoch": 2.508573537800745,
      "grad_norm": 0.6640018820762634,
      "learning_rate": 1.375159887092785e-05,
      "loss": 2.4351,
      "step": 37380
    },
    {
      "epoch": 2.50924465621959,
      "grad_norm": 0.6710303425788879,
      "learning_rate": 1.3714954673486124e-05,
      "loss": 2.4423,
      "step": 37390
    },
    {
      "epoch": 2.509915774638435,
      "grad_norm": 0.696443498134613,
      "learning_rate": 1.367835576962756e-05,
      "loss": 2.4324,
      "step": 37400
    },
    {
      "epoch": 2.509915774638435,
      "eval_bleu": 21.375782983857807,
      "eval_gen_len": 28.907,
      "eval_loss": 2.930577516555786,
      "eval_runtime": 62.9835,
      "eval_samples_per_second": 15.877,
      "eval_steps_per_second": 1.0,
      "step": 37400
    },
    {
      "epoch": 2.51058689305728,
      "grad_norm": 0.6914416551589966,
      "learning_rate": 1.3641802178564045e-05,
      "loss": 2.4799,
      "step": 37410
    },
    {
      "epoch": 2.5112580114761247,
      "grad_norm": 0.6592274308204651,
      "learning_rate": 1.3605293919483598e-05,
      "loss": 2.3932,
      "step": 37420
    },
    {
      "epoch": 2.5119291298949697,
      "grad_norm": 0.757896900177002,
      "learning_rate": 1.3568831011550542e-05,
      "loss": 2.4498,
      "step": 37430
    },
    {
      "epoch": 2.512600248313815,
      "grad_norm": 0.7009953260421753,
      "learning_rate": 1.3532413473905303e-05,
      "loss": 2.4896,
      "step": 37440
    },
    {
      "epoch": 2.51327136673266,
      "grad_norm": 0.7366501688957214,
      "learning_rate": 1.3496041325664544e-05,
      "loss": 2.4382,
      "step": 37450
    },
    {
      "epoch": 2.51327136673266,
      "eval_bleu": 21.270468250246076,
      "eval_gen_len": 28.921,
      "eval_loss": 2.9308969974517822,
      "eval_runtime": 62.6009,
      "eval_samples_per_second": 15.974,
      "eval_steps_per_second": 1.006,
      "step": 37450
    },
    {
      "epoch": 2.513942485151505,
      "grad_norm": 0.7323673963546753,
      "learning_rate": 1.345971458592109e-05,
      "loss": 2.4421,
      "step": 37460
    },
    {
      "epoch": 2.51461360357035,
      "grad_norm": 0.7726581692695618,
      "learning_rate": 1.3423433273743924e-05,
      "loss": 2.4399,
      "step": 37470
    },
    {
      "epoch": 2.515284721989195,
      "grad_norm": 0.7239581942558289,
      "learning_rate": 1.3387197408178143e-05,
      "loss": 2.4613,
      "step": 37480
    },
    {
      "epoch": 2.51595584040804,
      "grad_norm": 0.7118232846260071,
      "learning_rate": 1.3351007008245097e-05,
      "loss": 2.4304,
      "step": 37490
    },
    {
      "epoch": 2.516626958826885,
      "grad_norm": 0.657956600189209,
      "learning_rate": 1.331486209294216e-05,
      "loss": 2.4351,
      "step": 37500
    },
    {
      "epoch": 2.516626958826885,
      "eval_bleu": 21.304457908452836,
      "eval_gen_len": 28.898,
      "eval_loss": 2.93009352684021,
      "eval_runtime": 62.8004,
      "eval_samples_per_second": 15.923,
      "eval_steps_per_second": 1.003,
      "step": 37500
    },
    {
      "epoch": 2.51729807724573,
      "grad_norm": 0.6435385942459106,
      "learning_rate": 1.3278762681242862e-05,
      "loss": 2.4655,
      "step": 37510
    },
    {
      "epoch": 2.517969195664575,
      "grad_norm": 0.7581698298454285,
      "learning_rate": 1.3242708792096902e-05,
      "loss": 2.5001,
      "step": 37520
    },
    {
      "epoch": 2.51864031408342,
      "grad_norm": 0.6796805262565613,
      "learning_rate": 1.3206700444429987e-05,
      "loss": 2.4374,
      "step": 37530
    },
    {
      "epoch": 2.519311432502265,
      "grad_norm": 0.6943947076797485,
      "learning_rate": 1.3170737657144005e-05,
      "loss": 2.4505,
      "step": 37540
    },
    {
      "epoch": 2.5199825509211102,
      "grad_norm": 0.654524564743042,
      "learning_rate": 1.313482044911689e-05,
      "loss": 2.4597,
      "step": 37550
    },
    {
      "epoch": 2.5199825509211102,
      "eval_bleu": 21.334578143280865,
      "eval_gen_len": 28.902,
      "eval_loss": 2.929800271987915,
      "eval_runtime": 62.5839,
      "eval_samples_per_second": 15.979,
      "eval_steps_per_second": 1.007,
      "step": 37550
    },
    {
      "epoch": 2.5206536693399553,
      "grad_norm": 0.6901010274887085,
      "learning_rate": 1.309894883920263e-05,
      "loss": 2.4382,
      "step": 37560
    },
    {
      "epoch": 2.5213247877588003,
      "grad_norm": 0.693253219127655,
      "learning_rate": 1.306312284623129e-05,
      "loss": 2.3798,
      "step": 37570
    },
    {
      "epoch": 2.521995906177645,
      "grad_norm": 0.7223265171051025,
      "learning_rate": 1.3027342489009032e-05,
      "loss": 2.4647,
      "step": 37580
    },
    {
      "epoch": 2.52266702459649,
      "grad_norm": 0.6436089873313904,
      "learning_rate": 1.2991607786317993e-05,
      "loss": 2.4823,
      "step": 37590
    },
    {
      "epoch": 2.523338143015335,
      "grad_norm": 0.6942927837371826,
      "learning_rate": 1.295591875691643e-05,
      "loss": 2.4253,
      "step": 37600
    },
    {
      "epoch": 2.523338143015335,
      "eval_bleu": 21.214457101372133,
      "eval_gen_len": 28.897,
      "eval_loss": 2.9303829669952393,
      "eval_runtime": 62.0481,
      "eval_samples_per_second": 16.117,
      "eval_steps_per_second": 1.015,
      "step": 37600
    },
    {
      "epoch": 2.52400926143418,
      "grad_norm": 0.6465134024620056,
      "learning_rate": 1.2920275419538508e-05,
      "loss": 2.4241,
      "step": 37610
    },
    {
      "epoch": 2.524680379853025,
      "grad_norm": 0.7777251601219177,
      "learning_rate": 1.288467779289454e-05,
      "loss": 2.4475,
      "step": 37620
    },
    {
      "epoch": 2.52535149827187,
      "grad_norm": 0.7179768085479736,
      "learning_rate": 1.2849125895670733e-05,
      "loss": 2.4137,
      "step": 37630
    },
    {
      "epoch": 2.526022616690715,
      "grad_norm": 0.7501316070556641,
      "learning_rate": 1.281361974652936e-05,
      "loss": 2.4271,
      "step": 37640
    },
    {
      "epoch": 2.52669373510956,
      "grad_norm": 0.7169223427772522,
      "learning_rate": 1.277815936410861e-05,
      "loss": 2.4549,
      "step": 37650
    },
    {
      "epoch": 2.52669373510956,
      "eval_bleu": 21.35025576654948,
      "eval_gen_len": 28.923,
      "eval_loss": 2.929276943206787,
      "eval_runtime": 62.8672,
      "eval_samples_per_second": 15.907,
      "eval_steps_per_second": 1.002,
      "step": 37650
    },
    {
      "epoch": 2.5273648535284052,
      "grad_norm": 0.6806924939155579,
      "learning_rate": 1.2742744767022752e-05,
      "loss": 2.4922,
      "step": 37660
    },
    {
      "epoch": 2.52803597194725,
      "grad_norm": 0.7664763331413269,
      "learning_rate": 1.27073759738619e-05,
      "loss": 2.4822,
      "step": 37670
    },
    {
      "epoch": 2.528707090366095,
      "grad_norm": 0.6779250502586365,
      "learning_rate": 1.2672053003192242e-05,
      "loss": 2.4209,
      "step": 37680
    },
    {
      "epoch": 2.52937820878494,
      "grad_norm": 0.6498667597770691,
      "learning_rate": 1.2636775873555796e-05,
      "loss": 2.437,
      "step": 37690
    },
    {
      "epoch": 2.530049327203785,
      "grad_norm": 0.7107642292976379,
      "learning_rate": 1.2601544603470627e-05,
      "loss": 2.4874,
      "step": 37700
    },
    {
      "epoch": 2.530049327203785,
      "eval_bleu": 21.42201074813193,
      "eval_gen_len": 28.874,
      "eval_loss": 2.9300193786621094,
      "eval_runtime": 62.1977,
      "eval_samples_per_second": 16.078,
      "eval_steps_per_second": 1.013,
      "step": 37700
    },
    {
      "epoch": 2.53072044562263,
      "grad_norm": 0.7613043189048767,
      "learning_rate": 1.2566359211430655e-05,
      "loss": 2.4277,
      "step": 37710
    },
    {
      "epoch": 2.531391564041475,
      "grad_norm": 0.6951901912689209,
      "learning_rate": 1.253121971590574e-05,
      "loss": 2.4176,
      "step": 37720
    },
    {
      "epoch": 2.53206268246032,
      "grad_norm": 0.7423685193061829,
      "learning_rate": 1.2496126135341623e-05,
      "loss": 2.4707,
      "step": 37730
    },
    {
      "epoch": 2.532733800879165,
      "grad_norm": 0.700775682926178,
      "learning_rate": 1.2461078488160005e-05,
      "loss": 2.4511,
      "step": 37740
    },
    {
      "epoch": 2.53340491929801,
      "grad_norm": 0.5978920459747314,
      "learning_rate": 1.242607679275839e-05,
      "loss": 2.4287,
      "step": 37750
    },
    {
      "epoch": 2.53340491929801,
      "eval_bleu": 21.350960742666665,
      "eval_gen_len": 28.896,
      "eval_loss": 2.930172920227051,
      "eval_runtime": 62.3143,
      "eval_samples_per_second": 16.048,
      "eval_steps_per_second": 1.011,
      "step": 37750
    },
    {
      "epoch": 2.534076037716855,
      "grad_norm": 0.698677659034729,
      "learning_rate": 1.2391121067510259e-05,
      "loss": 2.4371,
      "step": 37760
    },
    {
      "epoch": 2.5347471561357002,
      "grad_norm": 0.6636260747909546,
      "learning_rate": 1.2356211330764877e-05,
      "loss": 2.455,
      "step": 37770
    },
    {
      "epoch": 2.5354182745545453,
      "grad_norm": 0.7347394227981567,
      "learning_rate": 1.2321347600847421e-05,
      "loss": 2.4116,
      "step": 37780
    },
    {
      "epoch": 2.5360893929733903,
      "grad_norm": 0.7301972508430481,
      "learning_rate": 1.2286529896058895e-05,
      "loss": 2.4351,
      "step": 37790
    },
    {
      "epoch": 2.5367605113922354,
      "grad_norm": 0.6253966093063354,
      "learning_rate": 1.2251758234676114e-05,
      "loss": 2.4336,
      "step": 37800
    },
    {
      "epoch": 2.5367605113922354,
      "eval_bleu": 21.391904231458458,
      "eval_gen_len": 28.917,
      "eval_loss": 2.9297730922698975,
      "eval_runtime": 65.553,
      "eval_samples_per_second": 15.255,
      "eval_steps_per_second": 0.961,
      "step": 37800
    },
    {
      "epoch": 2.5374316298110804,
      "grad_norm": 0.6298636794090271,
      "learning_rate": 1.2217032634951809e-05,
      "loss": 2.4606,
      "step": 37810
    },
    {
      "epoch": 2.5381027482299254,
      "grad_norm": 0.7088522911071777,
      "learning_rate": 1.2182353115114453e-05,
      "loss": 2.4837,
      "step": 37820
    },
    {
      "epoch": 2.53877386664877,
      "grad_norm": 0.6912952661514282,
      "learning_rate": 1.2147719693368354e-05,
      "loss": 2.4345,
      "step": 37830
    },
    {
      "epoch": 2.539444985067615,
      "grad_norm": 0.6426169276237488,
      "learning_rate": 1.21131323878936e-05,
      "loss": 2.4286,
      "step": 37840
    },
    {
      "epoch": 2.54011610348646,
      "grad_norm": 0.7128536105155945,
      "learning_rate": 1.2078591216846147e-05,
      "loss": 2.4807,
      "step": 37850
    },
    {
      "epoch": 2.54011610348646,
      "eval_bleu": 21.204992378436952,
      "eval_gen_len": 28.896,
      "eval_loss": 2.9298179149627686,
      "eval_runtime": 59.6405,
      "eval_samples_per_second": 16.767,
      "eval_steps_per_second": 1.056,
      "step": 37850
    },
    {
      "epoch": 2.540787221905305,
      "grad_norm": 0.6995025873184204,
      "learning_rate": 1.2044096198357635e-05,
      "loss": 2.4579,
      "step": 37860
    },
    {
      "epoch": 2.54145834032415,
      "grad_norm": 0.6676446199417114,
      "learning_rate": 1.2009647350535557e-05,
      "loss": 2.464,
      "step": 37870
    },
    {
      "epoch": 2.5421294587429952,
      "grad_norm": 0.7538518309593201,
      "learning_rate": 1.1975244691463116e-05,
      "loss": 2.4391,
      "step": 37880
    },
    {
      "epoch": 2.5428005771618403,
      "grad_norm": 0.6293389201164246,
      "learning_rate": 1.1940888239199299e-05,
      "loss": 2.4652,
      "step": 37890
    },
    {
      "epoch": 2.5434716955806853,
      "grad_norm": 0.6686940789222717,
      "learning_rate": 1.1906578011778846e-05,
      "loss": 2.438,
      "step": 37900
    },
    {
      "epoch": 2.5434716955806853,
      "eval_bleu": 21.33193905601206,
      "eval_gen_len": 28.918,
      "eval_loss": 2.9290883541107178,
      "eval_runtime": 62.4721,
      "eval_samples_per_second": 16.007,
      "eval_steps_per_second": 1.008,
      "step": 37900
    },
    {
      "epoch": 2.5441428139995304,
      "grad_norm": 0.6669315099716187,
      "learning_rate": 1.1872314027212183e-05,
      "loss": 2.4738,
      "step": 37910
    },
    {
      "epoch": 2.544813932418375,
      "grad_norm": 0.6802195906639099,
      "learning_rate": 1.183809630348548e-05,
      "loss": 2.4466,
      "step": 37920
    },
    {
      "epoch": 2.54548505083722,
      "grad_norm": 0.7068142890930176,
      "learning_rate": 1.180392485856069e-05,
      "loss": 2.4704,
      "step": 37930
    },
    {
      "epoch": 2.546156169256065,
      "grad_norm": 0.7283141613006592,
      "learning_rate": 1.1769799710375361e-05,
      "loss": 2.4183,
      "step": 37940
    },
    {
      "epoch": 2.54682728767491,
      "grad_norm": 0.7617648839950562,
      "learning_rate": 1.1735720876842859e-05,
      "loss": 2.4593,
      "step": 37950
    },
    {
      "epoch": 2.54682728767491,
      "eval_bleu": 21.286590187593013,
      "eval_gen_len": 28.896,
      "eval_loss": 2.930643320083618,
      "eval_runtime": 62.4907,
      "eval_samples_per_second": 16.002,
      "eval_steps_per_second": 1.008,
      "step": 37950
    },
    {
      "epoch": 2.547498406093755,
      "grad_norm": 0.7212075591087341,
      "learning_rate": 1.1701688375852116e-05,
      "loss": 2.4199,
      "step": 37960
    },
    {
      "epoch": 2.5481695245126,
      "grad_norm": 0.7276904582977295,
      "learning_rate": 1.1667702225267852e-05,
      "loss": 2.4191,
      "step": 37970
    },
    {
      "epoch": 2.548840642931445,
      "grad_norm": 0.7196483612060547,
      "learning_rate": 1.1633762442930385e-05,
      "loss": 2.4014,
      "step": 37980
    },
    {
      "epoch": 2.5495117613502902,
      "grad_norm": 0.6365430355072021,
      "learning_rate": 1.1599869046655709e-05,
      "loss": 2.457,
      "step": 37990
    },
    {
      "epoch": 2.5501828797691353,
      "grad_norm": 0.7034174203872681,
      "learning_rate": 1.156602205423546e-05,
      "loss": 2.4577,
      "step": 38000
    },
    {
      "epoch": 2.5501828797691353,
      "eval_bleu": 21.268248295765193,
      "eval_gen_len": 28.926,
      "eval_loss": 2.930485248565674,
      "eval_runtime": 62.1821,
      "eval_samples_per_second": 16.082,
      "eval_steps_per_second": 1.013,
      "step": 38000
    },
    {
      "epoch": 2.5508539981879803,
      "grad_norm": 0.6852154731750488,
      "learning_rate": 1.1532221483436979e-05,
      "loss": 2.4241,
      "step": 38010
    },
    {
      "epoch": 2.5515251166068253,
      "grad_norm": 0.6555209755897522,
      "learning_rate": 1.149846735200314e-05,
      "loss": 2.4449,
      "step": 38020
    },
    {
      "epoch": 2.5521962350256704,
      "grad_norm": 0.6856525540351868,
      "learning_rate": 1.1464759677652526e-05,
      "loss": 2.4305,
      "step": 38030
    },
    {
      "epoch": 2.5528673534445154,
      "grad_norm": 0.7772460579872131,
      "learning_rate": 1.143109847807926e-05,
      "loss": 2.4233,
      "step": 38040
    },
    {
      "epoch": 2.5535384718633605,
      "grad_norm": 0.6762080192565918,
      "learning_rate": 1.1397483770953143e-05,
      "loss": 2.426,
      "step": 38050
    },
    {
      "epoch": 2.5535384718633605,
      "eval_bleu": 21.46927609663642,
      "eval_gen_len": 28.988,
      "eval_loss": 2.929306745529175,
      "eval_runtime": 61.986,
      "eval_samples_per_second": 16.133,
      "eval_steps_per_second": 1.016,
      "step": 38050
    },
    {
      "epoch": 2.5542095902822055,
      "grad_norm": 0.6676470637321472,
      "learning_rate": 1.1363915573919492e-05,
      "loss": 2.421,
      "step": 38060
    },
    {
      "epoch": 2.5548807087010506,
      "grad_norm": 0.736235499382019,
      "learning_rate": 1.1330393904599302e-05,
      "loss": 2.4343,
      "step": 38070
    },
    {
      "epoch": 2.555551827119895,
      "grad_norm": 0.6470876336097717,
      "learning_rate": 1.1296918780589072e-05,
      "loss": 2.44,
      "step": 38080
    },
    {
      "epoch": 2.55622294553874,
      "grad_norm": 0.7191897630691528,
      "learning_rate": 1.126349021946087e-05,
      "loss": 2.4076,
      "step": 38090
    },
    {
      "epoch": 2.5568940639575852,
      "grad_norm": 0.740905225276947,
      "learning_rate": 1.123010823876236e-05,
      "loss": 2.4414,
      "step": 38100
    },
    {
      "epoch": 2.5568940639575852,
      "eval_bleu": 21.458900283115668,
      "eval_gen_len": 28.945,
      "eval_loss": 2.9296438694000244,
      "eval_runtime": 62.4852,
      "eval_samples_per_second": 16.004,
      "eval_steps_per_second": 1.008,
      "step": 38100
    },
    {
      "epoch": 2.5575651823764303,
      "grad_norm": 0.6700144410133362,
      "learning_rate": 1.1196772856016702e-05,
      "loss": 2.4772,
      "step": 38110
    },
    {
      "epoch": 2.5582363007952753,
      "grad_norm": 0.712673544883728,
      "learning_rate": 1.1163484088722687e-05,
      "loss": 2.4631,
      "step": 38120
    },
    {
      "epoch": 2.5589074192141203,
      "grad_norm": 0.6581456065177917,
      "learning_rate": 1.1130241954354515e-05,
      "loss": 2.4224,
      "step": 38130
    },
    {
      "epoch": 2.5595785376329654,
      "grad_norm": 0.6844078302383423,
      "learning_rate": 1.1097046470362015e-05,
      "loss": 2.4119,
      "step": 38140
    },
    {
      "epoch": 2.5602496560518104,
      "grad_norm": 0.7085586786270142,
      "learning_rate": 1.1063897654170463e-05,
      "loss": 2.4598,
      "step": 38150
    },
    {
      "epoch": 2.5602496560518104,
      "eval_bleu": 21.413702332195573,
      "eval_gen_len": 28.904,
      "eval_loss": 2.9294145107269287,
      "eval_runtime": 62.1692,
      "eval_samples_per_second": 16.085,
      "eval_steps_per_second": 1.013,
      "step": 38150
    },
    {
      "epoch": 2.5609207744706555,
      "grad_norm": 0.6588835716247559,
      "learning_rate": 1.103079552318067e-05,
      "loss": 2.4467,
      "step": 38160
    },
    {
      "epoch": 2.5615918928895005,
      "grad_norm": 0.6149278283119202,
      "learning_rate": 1.0997740094768927e-05,
      "loss": 2.4382,
      "step": 38170
    },
    {
      "epoch": 2.562263011308345,
      "grad_norm": 0.6530442833900452,
      "learning_rate": 1.0964731386286997e-05,
      "loss": 2.3705,
      "step": 38180
    },
    {
      "epoch": 2.56293412972719,
      "grad_norm": 0.6953337788581848,
      "learning_rate": 1.093176941506212e-05,
      "loss": 2.4015,
      "step": 38190
    },
    {
      "epoch": 2.563605248146035,
      "grad_norm": 0.6972770094871521,
      "learning_rate": 1.0898854198397047e-05,
      "loss": 2.472,
      "step": 38200
    },
    {
      "epoch": 2.563605248146035,
      "eval_bleu": 21.44337719869037,
      "eval_gen_len": 28.913,
      "eval_loss": 2.927830457687378,
      "eval_runtime": 60.734,
      "eval_samples_per_second": 16.465,
      "eval_steps_per_second": 1.037,
      "step": 38200
    },
    {
      "epoch": 2.5642763665648802,
      "grad_norm": 0.6258125901222229,
      "learning_rate": 1.0865985753569919e-05,
      "loss": 2.4402,
      "step": 38210
    },
    {
      "epoch": 2.5649474849837253,
      "grad_norm": 0.6900846362113953,
      "learning_rate": 1.0833164097834402e-05,
      "loss": 2.4063,
      "step": 38220
    },
    {
      "epoch": 2.5656186034025703,
      "grad_norm": 0.6831771731376648,
      "learning_rate": 1.0800389248419507e-05,
      "loss": 2.4622,
      "step": 38230
    },
    {
      "epoch": 2.5662897218214153,
      "grad_norm": 0.6789222359657288,
      "learning_rate": 1.0767661222529779e-05,
      "loss": 2.4633,
      "step": 38240
    },
    {
      "epoch": 2.5669608402402604,
      "grad_norm": 0.8320031762123108,
      "learning_rate": 1.07349800373451e-05,
      "loss": 2.442,
      "step": 38250
    },
    {
      "epoch": 2.5669608402402604,
      "eval_bleu": 21.53414318005508,
      "eval_gen_len": 28.95,
      "eval_loss": 2.9283275604248047,
      "eval_runtime": 61.6036,
      "eval_samples_per_second": 16.233,
      "eval_steps_per_second": 1.023,
      "step": 38250
    },
    {
      "epoch": 2.5676319586591054,
      "grad_norm": 0.7174336314201355,
      "learning_rate": 1.070234571002079e-05,
      "loss": 2.4266,
      "step": 38260
    },
    {
      "epoch": 2.5683030770779505,
      "grad_norm": 0.6748952269554138,
      "learning_rate": 1.066975825768758e-05,
      "loss": 2.4609,
      "step": 38270
    },
    {
      "epoch": 2.5689741954967955,
      "grad_norm": 0.6971542835235596,
      "learning_rate": 1.0637217697451606e-05,
      "loss": 2.4803,
      "step": 38280
    },
    {
      "epoch": 2.5696453139156405,
      "grad_norm": 0.655101478099823,
      "learning_rate": 1.0604724046394354e-05,
      "loss": 2.4586,
      "step": 38290
    },
    {
      "epoch": 2.5703164323344856,
      "grad_norm": 0.6574916839599609,
      "learning_rate": 1.0572277321572732e-05,
      "loss": 2.4483,
      "step": 38300
    },
    {
      "epoch": 2.5703164323344856,
      "eval_bleu": 21.449349882657355,
      "eval_gen_len": 28.932,
      "eval_loss": 2.927689790725708,
      "eval_runtime": 59.7475,
      "eval_samples_per_second": 16.737,
      "eval_steps_per_second": 1.054,
      "step": 38300
    },
    {
      "epoch": 2.5709875507533306,
      "grad_norm": 0.7201338410377502,
      "learning_rate": 1.0539877540018962e-05,
      "loss": 2.4489,
      "step": 38310
    },
    {
      "epoch": 2.5716586691721757,
      "grad_norm": 0.6963521242141724,
      "learning_rate": 1.050752471874068e-05,
      "loss": 2.4481,
      "step": 38320
    },
    {
      "epoch": 2.5723297875910207,
      "grad_norm": 0.5964968800544739,
      "learning_rate": 1.0475218874720826e-05,
      "loss": 2.3999,
      "step": 38330
    },
    {
      "epoch": 2.5730009060098653,
      "grad_norm": 0.6879717111587524,
      "learning_rate": 1.0442960024917702e-05,
      "loss": 2.407,
      "step": 38340
    },
    {
      "epoch": 2.5736720244287103,
      "grad_norm": 0.6586381793022156,
      "learning_rate": 1.0410748186264918e-05,
      "loss": 2.4819,
      "step": 38350
    },
    {
      "epoch": 2.5736720244287103,
      "eval_bleu": 21.449081657581676,
      "eval_gen_len": 28.942,
      "eval_loss": 2.9284610748291016,
      "eval_runtime": 60.0979,
      "eval_samples_per_second": 16.64,
      "eval_steps_per_second": 1.048,
      "step": 38350
    },
    {
      "epoch": 2.5743431428475554,
      "grad_norm": 0.8054484128952026,
      "learning_rate": 1.0378583375671458e-05,
      "loss": 2.4801,
      "step": 38360
    },
    {
      "epoch": 2.5750142612664004,
      "grad_norm": 0.6770293712615967,
      "learning_rate": 1.0346465610021549e-05,
      "loss": 2.4889,
      "step": 38370
    },
    {
      "epoch": 2.5756853796852455,
      "grad_norm": 0.7713652849197388,
      "learning_rate": 1.0314394906174806e-05,
      "loss": 2.4628,
      "step": 38380
    },
    {
      "epoch": 2.5763564981040905,
      "grad_norm": 0.7673043012619019,
      "learning_rate": 1.0282371280966064e-05,
      "loss": 2.4609,
      "step": 38390
    },
    {
      "epoch": 2.5770276165229355,
      "grad_norm": 0.6988875865936279,
      "learning_rate": 1.025039475120545e-05,
      "loss": 2.431,
      "step": 38400
    },
    {
      "epoch": 2.5770276165229355,
      "eval_bleu": 21.51110654392135,
      "eval_gen_len": 28.958,
      "eval_loss": 2.928494453430176,
      "eval_runtime": 60.7309,
      "eval_samples_per_second": 16.466,
      "eval_steps_per_second": 1.037,
      "step": 38400
    },
    {
      "epoch": 2.5776987349417806,
      "grad_norm": 0.7706995606422424,
      "learning_rate": 1.0218465333678462e-05,
      "loss": 2.4505,
      "step": 38410
    },
    {
      "epoch": 2.5783698533606256,
      "grad_norm": 0.6474012136459351,
      "learning_rate": 1.0186583045145726e-05,
      "loss": 2.4641,
      "step": 38420
    },
    {
      "epoch": 2.5790409717794702,
      "grad_norm": 0.8193068504333496,
      "learning_rate": 1.0154747902343265e-05,
      "loss": 2.4109,
      "step": 38430
    },
    {
      "epoch": 2.5797120901983153,
      "grad_norm": 0.7536265254020691,
      "learning_rate": 1.0122959921982267e-05,
      "loss": 2.4559,
      "step": 38440
    },
    {
      "epoch": 2.5803832086171603,
      "grad_norm": 0.6871200799942017,
      "learning_rate": 1.0091219120749174e-05,
      "loss": 2.4436,
      "step": 38450
    },
    {
      "epoch": 2.5803832086171603,
      "eval_bleu": 21.52399383774813,
      "eval_gen_len": 28.968,
      "eval_loss": 2.9276010990142822,
      "eval_runtime": 60.631,
      "eval_samples_per_second": 16.493,
      "eval_steps_per_second": 1.039,
      "step": 38450
    },
    {
      "epoch": 2.5810543270360053,
      "grad_norm": 0.6446864008903503,
      "learning_rate": 1.0059525515305667e-05,
      "loss": 2.4302,
      "step": 38460
    },
    {
      "epoch": 2.5817254454548504,
      "grad_norm": 0.7423918843269348,
      "learning_rate": 1.0027879122288708e-05,
      "loss": 2.4345,
      "step": 38470
    },
    {
      "epoch": 2.5823965638736954,
      "grad_norm": 0.6905559301376343,
      "learning_rate": 9.996279958310373e-06,
      "loss": 2.4013,
      "step": 38480
    },
    {
      "epoch": 2.5830676822925405,
      "grad_norm": 0.6594971418380737,
      "learning_rate": 9.964728039958049e-06,
      "loss": 2.3978,
      "step": 38490
    },
    {
      "epoch": 2.5837388007113855,
      "grad_norm": 0.7239681482315063,
      "learning_rate": 9.933223383794233e-06,
      "loss": 2.4917,
      "step": 38500
    },
    {
      "epoch": 2.5837388007113855,
      "eval_bleu": 21.407714235556583,
      "eval_gen_len": 28.926,
      "eval_loss": 2.9292845726013184,
      "eval_runtime": 60.91,
      "eval_samples_per_second": 16.418,
      "eval_steps_per_second": 1.034,
      "step": 38500
    },
    {
      "epoch": 2.5844099191302305,
      "grad_norm": 0.7397067546844482,
      "learning_rate": 9.901766006356694e-06,
      "loss": 2.4854,
      "step": 38510
    },
    {
      "epoch": 2.5850810375490756,
      "grad_norm": 0.7027060389518738,
      "learning_rate": 9.870355924158336e-06,
      "loss": 2.4063,
      "step": 38520
    },
    {
      "epoch": 2.5857521559679206,
      "grad_norm": 0.7133927941322327,
      "learning_rate": 9.838993153687226e-06,
      "loss": 2.4345,
      "step": 38530
    },
    {
      "epoch": 2.5864232743867657,
      "grad_norm": 0.7334662675857544,
      "learning_rate": 9.807677711406604e-06,
      "loss": 2.4531,
      "step": 38540
    },
    {
      "epoch": 2.5870943928056107,
      "grad_norm": 0.679154098033905,
      "learning_rate": 9.776409613754911e-06,
      "loss": 2.4628,
      "step": 38550
    },
    {
      "epoch": 2.5870943928056107,
      "eval_bleu": 21.43074264779133,
      "eval_gen_len": 28.922,
      "eval_loss": 2.929168701171875,
      "eval_runtime": 60.4836,
      "eval_samples_per_second": 16.533,
      "eval_steps_per_second": 1.042,
      "step": 38550
    },
    {
      "epoch": 2.5877655112244558,
      "grad_norm": 0.7329323291778564,
      "learning_rate": 9.745188877145672e-06,
      "loss": 2.4148,
      "step": 38560
    },
    {
      "epoch": 2.588436629643301,
      "grad_norm": 0.7540370225906372,
      "learning_rate": 9.714015517967601e-06,
      "loss": 2.477,
      "step": 38570
    },
    {
      "epoch": 2.589107748062146,
      "grad_norm": 0.6383531093597412,
      "learning_rate": 9.682889552584495e-06,
      "loss": 2.4685,
      "step": 38580
    },
    {
      "epoch": 2.5897788664809904,
      "grad_norm": 0.7574290633201599,
      "learning_rate": 9.65181099733533e-06,
      "loss": 2.4648,
      "step": 38590
    },
    {
      "epoch": 2.5904499848998355,
      "grad_norm": 0.6768796443939209,
      "learning_rate": 9.620779868534147e-06,
      "loss": 2.4516,
      "step": 38600
    },
    {
      "epoch": 2.5904499848998355,
      "eval_bleu": 21.4554597678545,
      "eval_gen_len": 28.901,
      "eval_loss": 2.9291913509368896,
      "eval_runtime": 60.8153,
      "eval_samples_per_second": 16.443,
      "eval_steps_per_second": 1.036,
      "step": 38600
    },
    {
      "epoch": 2.5911211033186805,
      "grad_norm": 0.6759964227676392,
      "learning_rate": 9.58979618247009e-06,
      "loss": 2.4821,
      "step": 38610
    },
    {
      "epoch": 2.5917922217375255,
      "grad_norm": 0.7310450673103333,
      "learning_rate": 9.558859955407429e-06,
      "loss": 2.4264,
      "step": 38620
    },
    {
      "epoch": 2.5924633401563706,
      "grad_norm": 0.7263676524162292,
      "learning_rate": 9.52797120358553e-06,
      "loss": 2.4214,
      "step": 38630
    },
    {
      "epoch": 2.5931344585752156,
      "grad_norm": 0.6727131605148315,
      "learning_rate": 9.497129943218763e-06,
      "loss": 2.4348,
      "step": 38640
    },
    {
      "epoch": 2.5938055769940607,
      "grad_norm": 0.6572316288948059,
      "learning_rate": 9.466336190496683e-06,
      "loss": 2.4027,
      "step": 38650
    },
    {
      "epoch": 2.5938055769940607,
      "eval_bleu": 21.362178080422613,
      "eval_gen_len": 28.96,
      "eval_loss": 2.9294626712799072,
      "eval_runtime": 63.5765,
      "eval_samples_per_second": 15.729,
      "eval_steps_per_second": 0.991,
      "step": 38650
    },
    {
      "epoch": 2.5944766954129057,
      "grad_norm": 0.6610795259475708,
      "learning_rate": 9.435589961583802e-06,
      "loss": 2.473,
      "step": 38660
    },
    {
      "epoch": 2.5951478138317507,
      "grad_norm": 0.6886206865310669,
      "learning_rate": 9.404891272619754e-06,
      "loss": 2.4674,
      "step": 38670
    },
    {
      "epoch": 2.5958189322505953,
      "grad_norm": 0.6954948306083679,
      "learning_rate": 9.374240139719193e-06,
      "loss": 2.4309,
      "step": 38680
    },
    {
      "epoch": 2.5964900506694404,
      "grad_norm": 0.6564046144485474,
      "learning_rate": 9.343636578971782e-06,
      "loss": 2.4431,
      "step": 38690
    },
    {
      "epoch": 2.5971611690882854,
      "grad_norm": 0.6427921652793884,
      "learning_rate": 9.31308060644227e-06,
      "loss": 2.4564,
      "step": 38700
    },
    {
      "epoch": 2.5971611690882854,
      "eval_bleu": 21.322711633377697,
      "eval_gen_len": 28.929,
      "eval_loss": 2.9294700622558594,
      "eval_runtime": 63.1285,
      "eval_samples_per_second": 15.841,
      "eval_steps_per_second": 0.998,
      "step": 38700
    },
    {
      "epoch": 2.5978322875071305,
      "grad_norm": 0.7492997050285339,
      "learning_rate": 9.282572238170372e-06,
      "loss": 2.486,
      "step": 38710
    },
    {
      "epoch": 2.5985034059259755,
      "grad_norm": 0.6357654333114624,
      "learning_rate": 9.252111490170856e-06,
      "loss": 2.3758,
      "step": 38720
    },
    {
      "epoch": 2.5991745243448205,
      "grad_norm": 0.6963996887207031,
      "learning_rate": 9.221698378433441e-06,
      "loss": 2.4302,
      "step": 38730
    },
    {
      "epoch": 2.5998456427636656,
      "grad_norm": 0.7168443202972412,
      "learning_rate": 9.191332918922924e-06,
      "loss": 2.4197,
      "step": 38740
    },
    {
      "epoch": 2.6005167611825106,
      "grad_norm": 0.6747257113456726,
      "learning_rate": 9.161015127578976e-06,
      "loss": 2.5132,
      "step": 38750
    },
    {
      "epoch": 2.6005167611825106,
      "eval_bleu": 21.315095674210063,
      "eval_gen_len": 28.973,
      "eval_loss": 2.9297914505004883,
      "eval_runtime": 63.1021,
      "eval_samples_per_second": 15.847,
      "eval_steps_per_second": 0.998,
      "step": 38750
    },
    {
      "epoch": 2.6011878796013557,
      "grad_norm": 0.6867169141769409,
      "learning_rate": 9.130745020316357e-06,
      "loss": 2.418,
      "step": 38760
    },
    {
      "epoch": 2.6018589980202007,
      "grad_norm": 0.7013352513313293,
      "learning_rate": 9.100522613024709e-06,
      "loss": 2.5216,
      "step": 38770
    },
    {
      "epoch": 2.6025301164390457,
      "grad_norm": 0.6956695318222046,
      "learning_rate": 9.070347921568711e-06,
      "loss": 2.4383,
      "step": 38780
    },
    {
      "epoch": 2.603201234857891,
      "grad_norm": 0.7218545079231262,
      "learning_rate": 9.040220961787938e-06,
      "loss": 2.4444,
      "step": 38790
    },
    {
      "epoch": 2.603872353276736,
      "grad_norm": 0.7288905382156372,
      "learning_rate": 9.010141749496903e-06,
      "loss": 2.4184,
      "step": 38800
    },
    {
      "epoch": 2.603872353276736,
      "eval_bleu": 21.373199714106306,
      "eval_gen_len": 28.934,
      "eval_loss": 2.929877996444702,
      "eval_runtime": 63.8428,
      "eval_samples_per_second": 15.663,
      "eval_steps_per_second": 0.987,
      "step": 38800
    },
    {
      "epoch": 2.604543471695581,
      "grad_norm": 0.6894221901893616,
      "learning_rate": 8.98011030048509e-06,
      "loss": 2.4271,
      "step": 38810
    },
    {
      "epoch": 2.605214590114426,
      "grad_norm": 0.670212984085083,
      "learning_rate": 8.95012663051692e-06,
      "loss": 2.4144,
      "step": 38820
    },
    {
      "epoch": 2.605885708533271,
      "grad_norm": 0.6916242837905884,
      "learning_rate": 8.92019075533167e-06,
      "loss": 2.4187,
      "step": 38830
    },
    {
      "epoch": 2.6065568269521155,
      "grad_norm": 0.6048805117607117,
      "learning_rate": 8.890302690643615e-06,
      "loss": 2.4532,
      "step": 38840
    },
    {
      "epoch": 2.6072279453709606,
      "grad_norm": 0.7045865654945374,
      "learning_rate": 8.86046245214186e-06,
      "loss": 2.4334,
      "step": 38850
    },
    {
      "epoch": 2.6072279453709606,
      "eval_bleu": 21.353614029264033,
      "eval_gen_len": 28.9,
      "eval_loss": 2.930346727371216,
      "eval_runtime": 63.3436,
      "eval_samples_per_second": 15.787,
      "eval_steps_per_second": 0.995,
      "step": 38850
    },
    {
      "epoch": 2.6078990637898056,
      "grad_norm": 0.6989448070526123,
      "learning_rate": 8.830670055490453e-06,
      "loss": 2.3963,
      "step": 38860
    },
    {
      "epoch": 2.6085701822086507,
      "grad_norm": 0.7008482217788696,
      "learning_rate": 8.800925516328295e-06,
      "loss": 2.4666,
      "step": 38870
    },
    {
      "epoch": 2.6092413006274957,
      "grad_norm": 0.673590362071991,
      "learning_rate": 8.771228850269175e-06,
      "loss": 2.4741,
      "step": 38880
    },
    {
      "epoch": 2.6099124190463407,
      "grad_norm": 0.6943625807762146,
      "learning_rate": 8.741580072901745e-06,
      "loss": 2.4601,
      "step": 38890
    },
    {
      "epoch": 2.610583537465186,
      "grad_norm": 0.6834686994552612,
      "learning_rate": 8.711979199789566e-06,
      "loss": 2.4659,
      "step": 38900
    },
    {
      "epoch": 2.610583537465186,
      "eval_bleu": 21.365044432714278,
      "eval_gen_len": 28.925,
      "eval_loss": 2.929995059967041,
      "eval_runtime": 63.7107,
      "eval_samples_per_second": 15.696,
      "eval_steps_per_second": 0.989,
      "step": 38900
    },
    {
      "epoch": 2.611254655884031,
      "grad_norm": 0.6570680737495422,
      "learning_rate": 8.682426246470976e-06,
      "loss": 2.4523,
      "step": 38910
    },
    {
      "epoch": 2.611925774302876,
      "grad_norm": 0.6919511556625366,
      "learning_rate": 8.652921228459222e-06,
      "loss": 2.3958,
      "step": 38920
    },
    {
      "epoch": 2.612596892721721,
      "grad_norm": 0.7277765870094299,
      "learning_rate": 8.623464161242345e-06,
      "loss": 2.4028,
      "step": 38930
    },
    {
      "epoch": 2.6132680111405655,
      "grad_norm": 0.7083015441894531,
      "learning_rate": 8.594055060283269e-06,
      "loss": 2.4261,
      "step": 38940
    },
    {
      "epoch": 2.6139391295594105,
      "grad_norm": 0.7266965508460999,
      "learning_rate": 8.564693941019674e-06,
      "loss": 2.4435,
      "step": 38950
    },
    {
      "epoch": 2.6139391295594105,
      "eval_bleu": 21.34751132370199,
      "eval_gen_len": 28.941,
      "eval_loss": 2.9308714866638184,
      "eval_runtime": 62.5436,
      "eval_samples_per_second": 15.989,
      "eval_steps_per_second": 1.007,
      "step": 38950
    },
    {
      "epoch": 2.6146102479782556,
      "grad_norm": 0.6928240656852722,
      "learning_rate": 8.535380818864092e-06,
      "loss": 2.4192,
      "step": 38960
    },
    {
      "epoch": 2.6152813663971006,
      "grad_norm": 0.7488678097724915,
      "learning_rate": 8.506115709203855e-06,
      "loss": 2.4945,
      "step": 38970
    },
    {
      "epoch": 2.6159524848159457,
      "grad_norm": 0.6665090918540955,
      "learning_rate": 8.476898627401064e-06,
      "loss": 2.458,
      "step": 38980
    },
    {
      "epoch": 2.6166236032347907,
      "grad_norm": 0.7008997797966003,
      "learning_rate": 8.447729588792674e-06,
      "loss": 2.4796,
      "step": 38990
    },
    {
      "epoch": 2.6172947216536357,
      "grad_norm": 0.7305965423583984,
      "learning_rate": 8.418608608690337e-06,
      "loss": 2.4826,
      "step": 39000
    },
    {
      "epoch": 2.6172947216536357,
      "eval_bleu": 21.239879437678635,
      "eval_gen_len": 28.937,
      "eval_loss": 2.9291913509368896,
      "eval_runtime": 62.7453,
      "eval_samples_per_second": 15.937,
      "eval_steps_per_second": 1.004,
      "step": 39000
    },
    {
      "epoch": 2.617965840072481,
      "grad_norm": 0.7124020457267761,
      "learning_rate": 8.38953570238057e-06,
      "loss": 2.4548,
      "step": 39010
    },
    {
      "epoch": 2.618636958491326,
      "grad_norm": 0.6876892447471619,
      "learning_rate": 8.36051088512455e-06,
      "loss": 2.4708,
      "step": 39020
    },
    {
      "epoch": 2.619308076910171,
      "grad_norm": 0.698013961315155,
      "learning_rate": 8.331534172158318e-06,
      "loss": 2.4696,
      "step": 39030
    },
    {
      "epoch": 2.619979195329016,
      "grad_norm": 0.6644233465194702,
      "learning_rate": 8.302605578692557e-06,
      "loss": 2.4698,
      "step": 39040
    },
    {
      "epoch": 2.620650313747861,
      "grad_norm": 0.7654697299003601,
      "learning_rate": 8.273725119912801e-06,
      "loss": 2.467,
      "step": 39050
    },
    {
      "epoch": 2.620650313747861,
      "eval_bleu": 21.486100069215304,
      "eval_gen_len": 28.903,
      "eval_loss": 2.928632974624634,
      "eval_runtime": 63.099,
      "eval_samples_per_second": 15.848,
      "eval_steps_per_second": 0.998,
      "step": 39050
    },
    {
      "epoch": 2.621321432166706,
      "grad_norm": 0.6643859148025513,
      "learning_rate": 8.244892810979243e-06,
      "loss": 2.4593,
      "step": 39060
    },
    {
      "epoch": 2.621992550585551,
      "grad_norm": 0.6360477805137634,
      "learning_rate": 8.2161086670268e-06,
      "loss": 2.4252,
      "step": 39070
    },
    {
      "epoch": 2.622663669004396,
      "grad_norm": 0.6659080982208252,
      "learning_rate": 8.187372703165108e-06,
      "loss": 2.4432,
      "step": 39080
    },
    {
      "epoch": 2.6233347874232407,
      "grad_norm": 0.6506701707839966,
      "learning_rate": 8.158684934478589e-06,
      "loss": 2.4377,
      "step": 39090
    },
    {
      "epoch": 2.6240059058420857,
      "grad_norm": 0.6810197234153748,
      "learning_rate": 8.130045376026241e-06,
      "loss": 2.4952,
      "step": 39100
    },
    {
      "epoch": 2.6240059058420857,
      "eval_bleu": 21.435944673498682,
      "eval_gen_len": 28.879,
      "eval_loss": 2.9284555912017822,
      "eval_runtime": 62.7724,
      "eval_samples_per_second": 15.931,
      "eval_steps_per_second": 1.004,
      "step": 39100
    },
    {
      "epoch": 2.6246770242609307,
      "grad_norm": 0.6785624027252197,
      "learning_rate": 8.101454042841872e-06,
      "loss": 2.4178,
      "step": 39110
    },
    {
      "epoch": 2.625348142679776,
      "grad_norm": 0.7420127391815186,
      "learning_rate": 8.072910949933877e-06,
      "loss": 2.432,
      "step": 39120
    },
    {
      "epoch": 2.626019261098621,
      "grad_norm": 0.6885497570037842,
      "learning_rate": 8.044416112285402e-06,
      "loss": 2.4043,
      "step": 39130
    },
    {
      "epoch": 2.626690379517466,
      "grad_norm": 0.6941139101982117,
      "learning_rate": 8.01596954485424e-06,
      "loss": 2.4773,
      "step": 39140
    },
    {
      "epoch": 2.627361497936311,
      "grad_norm": 0.6555272340774536,
      "learning_rate": 7.987571262572813e-06,
      "loss": 2.4509,
      "step": 39150
    },
    {
      "epoch": 2.627361497936311,
      "eval_bleu": 21.42324528939735,
      "eval_gen_len": 28.859,
      "eval_loss": 2.928884983062744,
      "eval_runtime": 62.3808,
      "eval_samples_per_second": 16.031,
      "eval_steps_per_second": 1.01,
      "step": 39150
    },
    {
      "epoch": 2.628032616355156,
      "grad_norm": 0.6340063810348511,
      "learning_rate": 7.959221280348228e-06,
      "loss": 2.4576,
      "step": 39160
    },
    {
      "epoch": 2.628703734774001,
      "grad_norm": 0.6725606918334961,
      "learning_rate": 7.930919613062248e-06,
      "loss": 2.4875,
      "step": 39170
    },
    {
      "epoch": 2.629374853192846,
      "grad_norm": 0.6982182860374451,
      "learning_rate": 7.902666275571236e-06,
      "loss": 2.4257,
      "step": 39180
    },
    {
      "epoch": 2.6300459716116906,
      "grad_norm": 0.7090672850608826,
      "learning_rate": 7.874461282706247e-06,
      "loss": 2.4561,
      "step": 39190
    },
    {
      "epoch": 2.6307170900305357,
      "grad_norm": 0.6537835001945496,
      "learning_rate": 7.846304649272862e-06,
      "loss": 2.4445,
      "step": 39200
    },
    {
      "epoch": 2.6307170900305357,
      "eval_bleu": 21.33511212042064,
      "eval_gen_len": 28.927,
      "eval_loss": 2.929097890853882,
      "eval_runtime": 62.812,
      "eval_samples_per_second": 15.921,
      "eval_steps_per_second": 1.003,
      "step": 39200
    },
    {
      "epoch": 2.6313882084493807,
      "grad_norm": 0.725202202796936,
      "learning_rate": 7.818196390051403e-06,
      "loss": 2.4823,
      "step": 39210
    },
    {
      "epoch": 2.6320593268682257,
      "grad_norm": 0.7121752500534058,
      "learning_rate": 7.790136519796676e-06,
      "loss": 2.4297,
      "step": 39220
    },
    {
      "epoch": 2.632730445287071,
      "grad_norm": 0.7416442632675171,
      "learning_rate": 7.762125053238167e-06,
      "loss": 2.4438,
      "step": 39230
    },
    {
      "epoch": 2.633401563705916,
      "grad_norm": 0.6737182140350342,
      "learning_rate": 7.734162005079903e-06,
      "loss": 2.4877,
      "step": 39240
    },
    {
      "epoch": 2.634072682124761,
      "grad_norm": 0.6894651055335999,
      "learning_rate": 7.706247390000543e-06,
      "loss": 2.404,
      "step": 39250
    },
    {
      "epoch": 2.634072682124761,
      "eval_bleu": 21.47026050239735,
      "eval_gen_len": 28.893,
      "eval_loss": 2.929553270339966,
      "eval_runtime": 62.5219,
      "eval_samples_per_second": 15.994,
      "eval_steps_per_second": 1.008,
      "step": 39250
    },
    {
      "epoch": 2.634743800543606,
      "grad_norm": 0.717669665813446,
      "learning_rate": 7.678381222653297e-06,
      "loss": 2.4646,
      "step": 39260
    },
    {
      "epoch": 2.635414918962451,
      "grad_norm": 0.6867770552635193,
      "learning_rate": 7.65056351766591e-06,
      "loss": 2.4294,
      "step": 39270
    },
    {
      "epoch": 2.636086037381296,
      "grad_norm": 0.6879098415374756,
      "learning_rate": 7.622794289640767e-06,
      "loss": 2.496,
      "step": 39280
    },
    {
      "epoch": 2.636757155800141,
      "grad_norm": 0.6739255785942078,
      "learning_rate": 7.5950735531547305e-06,
      "loss": 2.4223,
      "step": 39290
    },
    {
      "epoch": 2.637428274218986,
      "grad_norm": 0.6429449915885925,
      "learning_rate": 7.56740132275926e-06,
      "loss": 2.4391,
      "step": 39300
    },
    {
      "epoch": 2.637428274218986,
      "eval_bleu": 21.270114977368276,
      "eval_gen_len": 28.868,
      "eval_loss": 2.9300966262817383,
      "eval_runtime": 63.1152,
      "eval_samples_per_second": 15.844,
      "eval_steps_per_second": 0.998,
      "step": 39300
    },
    {
      "epoch": 2.638099392637831,
      "grad_norm": 0.7121011018753052,
      "learning_rate": 7.539777612980303e-06,
      "loss": 2.4615,
      "step": 39310
    },
    {
      "epoch": 2.638770511056676,
      "grad_norm": 0.7146340012550354,
      "learning_rate": 7.512202438318394e-06,
      "loss": 2.4795,
      "step": 39320
    },
    {
      "epoch": 2.639441629475521,
      "grad_norm": 0.6808161735534668,
      "learning_rate": 7.484675813248554e-06,
      "loss": 2.4012,
      "step": 39330
    },
    {
      "epoch": 2.6401127478943662,
      "grad_norm": 0.7010529041290283,
      "learning_rate": 7.457197752220324e-06,
      "loss": 2.4429,
      "step": 39340
    },
    {
      "epoch": 2.640783866313211,
      "grad_norm": 0.6979915499687195,
      "learning_rate": 7.429768269657722e-06,
      "loss": 2.4437,
      "step": 39350
    },
    {
      "epoch": 2.640783866313211,
      "eval_bleu": 21.304561404618962,
      "eval_gen_len": 28.902,
      "eval_loss": 2.9294660091400146,
      "eval_runtime": 63.1428,
      "eval_samples_per_second": 15.837,
      "eval_steps_per_second": 0.998,
      "step": 39350
    },
    {
      "epoch": 2.641454984732056,
      "grad_norm": 0.6859778165817261,
      "learning_rate": 7.402387379959364e-06,
      "loss": 2.496,
      "step": 39360
    },
    {
      "epoch": 2.642126103150901,
      "grad_norm": 0.6874977350234985,
      "learning_rate": 7.375055097498218e-06,
      "loss": 2.453,
      "step": 39370
    },
    {
      "epoch": 2.642797221569746,
      "grad_norm": 0.6999813318252563,
      "learning_rate": 7.347771436621886e-06,
      "loss": 2.4381,
      "step": 39380
    },
    {
      "epoch": 2.643468339988591,
      "grad_norm": 0.6937896609306335,
      "learning_rate": 7.3205364116523014e-06,
      "loss": 2.4404,
      "step": 39390
    },
    {
      "epoch": 2.644139458407436,
      "grad_norm": 0.6861050128936768,
      "learning_rate": 7.293350036886004e-06,
      "loss": 2.4433,
      "step": 39400
    },
    {
      "epoch": 2.644139458407436,
      "eval_bleu": 21.357030452453927,
      "eval_gen_len": 28.857,
      "eval_loss": 2.9295308589935303,
      "eval_runtime": 62.7358,
      "eval_samples_per_second": 15.94,
      "eval_steps_per_second": 1.004,
      "step": 39400
    },
    {
      "epoch": 2.644810576826281,
      "grad_norm": 0.6647627353668213,
      "learning_rate": 7.266212326593879e-06,
      "loss": 2.4314,
      "step": 39410
    },
    {
      "epoch": 2.645481695245126,
      "grad_norm": 0.7899226546287537,
      "learning_rate": 7.239123295021344e-06,
      "loss": 2.4828,
      "step": 39420
    },
    {
      "epoch": 2.646152813663971,
      "grad_norm": 0.6294859051704407,
      "learning_rate": 7.212082956388211e-06,
      "loss": 2.46,
      "step": 39430
    },
    {
      "epoch": 2.6468239320828157,
      "grad_norm": 0.7277528047561646,
      "learning_rate": 7.185091324888793e-06,
      "loss": 2.4714,
      "step": 39440
    },
    {
      "epoch": 2.647495050501661,
      "grad_norm": 0.664584219455719,
      "learning_rate": 7.158148414691756e-06,
      "loss": 2.3923,
      "step": 39450
    },
    {
      "epoch": 2.647495050501661,
      "eval_bleu": 21.25597898214255,
      "eval_gen_len": 28.886,
      "eval_loss": 2.9298224449157715,
      "eval_runtime": 62.6597,
      "eval_samples_per_second": 15.959,
      "eval_steps_per_second": 1.005,
      "step": 39450
    },
    {
      "epoch": 2.648166168920506,
      "grad_norm": 0.7007673382759094,
      "learning_rate": 7.131254239940266e-06,
      "loss": 2.4251,
      "step": 39460
    },
    {
      "epoch": 2.648837287339351,
      "grad_norm": 0.7459716796875,
      "learning_rate": 7.104408814751861e-06,
      "loss": 2.4395,
      "step": 39470
    },
    {
      "epoch": 2.649508405758196,
      "grad_norm": 0.6480270624160767,
      "learning_rate": 7.077612153218516e-06,
      "loss": 2.4162,
      "step": 39480
    },
    {
      "epoch": 2.650179524177041,
      "grad_norm": 0.6443595886230469,
      "learning_rate": 7.050864269406587e-06,
      "loss": 2.3826,
      "step": 39490
    },
    {
      "epoch": 2.650850642595886,
      "grad_norm": 0.6215705871582031,
      "learning_rate": 7.024165177356823e-06,
      "loss": 2.4562,
      "step": 39500
    },
    {
      "epoch": 2.650850642595886,
      "eval_bleu": 21.162569489046078,
      "eval_gen_len": 28.866,
      "eval_loss": 2.930328845977783,
      "eval_runtime": 61.1034,
      "eval_samples_per_second": 16.366,
      "eval_steps_per_second": 1.031,
      "step": 39500
    },
    {
      "epoch": 2.651521761014731,
      "grad_norm": 0.7851402163505554,
      "learning_rate": 6.997514891084367e-06,
      "loss": 2.4778,
      "step": 39510
    },
    {
      "epoch": 2.652192879433576,
      "grad_norm": 0.6798501014709473,
      "learning_rate": 6.970913424578773e-06,
      "loss": 2.407,
      "step": 39520
    },
    {
      "epoch": 2.652863997852421,
      "grad_norm": 0.7287153005599976,
      "learning_rate": 6.944360791803905e-06,
      "loss": 2.483,
      "step": 39530
    },
    {
      "epoch": 2.653535116271266,
      "grad_norm": 0.6875565648078918,
      "learning_rate": 6.917857006698059e-06,
      "loss": 2.4582,
      "step": 39540
    },
    {
      "epoch": 2.654206234690111,
      "grad_norm": 0.7695615291595459,
      "learning_rate": 6.891402083173859e-06,
      "loss": 2.4845,
      "step": 39550
    },
    {
      "epoch": 2.654206234690111,
      "eval_bleu": 21.34310302848868,
      "eval_gen_len": 28.875,
      "eval_loss": 2.9305331707000732,
      "eval_runtime": 62.2242,
      "eval_samples_per_second": 16.071,
      "eval_steps_per_second": 1.012,
      "step": 39550
    },
    {
      "epoch": 2.6548773531089562,
      "grad_norm": 0.6659904718399048,
      "learning_rate": 6.864996035118243e-06,
      "loss": 2.4112,
      "step": 39560
    },
    {
      "epoch": 2.6555484715278013,
      "grad_norm": 0.7428607940673828,
      "learning_rate": 6.838638876392578e-06,
      "loss": 2.4325,
      "step": 39570
    },
    {
      "epoch": 2.6562195899466463,
      "grad_norm": 0.7469227910041809,
      "learning_rate": 6.812330620832497e-06,
      "loss": 2.4443,
      "step": 39580
    },
    {
      "epoch": 2.6568907083654913,
      "grad_norm": 0.6734305024147034,
      "learning_rate": 6.786071282247986e-06,
      "loss": 2.4411,
      "step": 39590
    },
    {
      "epoch": 2.657561826784336,
      "grad_norm": 0.6285580396652222,
      "learning_rate": 6.75986087442333e-06,
      "loss": 2.4469,
      "step": 39600
    },
    {
      "epoch": 2.657561826784336,
      "eval_bleu": 21.295526730966028,
      "eval_gen_len": 28.891,
      "eval_loss": 2.9299349784851074,
      "eval_runtime": 62.0653,
      "eval_samples_per_second": 16.112,
      "eval_steps_per_second": 1.015,
      "step": 39600
    },
    {
      "epoch": 2.658232945203181,
      "grad_norm": 0.6892824172973633,
      "learning_rate": 6.733699411117189e-06,
      "loss": 2.438,
      "step": 39610
    },
    {
      "epoch": 2.658904063622026,
      "grad_norm": 0.695919394493103,
      "learning_rate": 6.707586906062457e-06,
      "loss": 2.3639,
      "step": 39620
    },
    {
      "epoch": 2.659575182040871,
      "grad_norm": 0.6705270409584045,
      "learning_rate": 6.681523372966403e-06,
      "loss": 2.4667,
      "step": 39630
    },
    {
      "epoch": 2.660246300459716,
      "grad_norm": 0.695980966091156,
      "learning_rate": 6.655508825510515e-06,
      "loss": 2.4207,
      "step": 39640
    },
    {
      "epoch": 2.660917418878561,
      "grad_norm": 0.663031816482544,
      "learning_rate": 6.629543277350614e-06,
      "loss": 2.4008,
      "step": 39650
    },
    {
      "epoch": 2.660917418878561,
      "eval_bleu": 21.375499873347174,
      "eval_gen_len": 28.881,
      "eval_loss": 2.930063009262085,
      "eval_runtime": 62.1979,
      "eval_samples_per_second": 16.078,
      "eval_steps_per_second": 1.013,
      "step": 39650
    },
    {
      "epoch": 2.661588537297406,
      "grad_norm": 0.7493535876274109,
      "learning_rate": 6.603626742116786e-06,
      "loss": 2.4853,
      "step": 39660
    },
    {
      "epoch": 2.6622596557162512,
      "grad_norm": 0.6687027215957642,
      "learning_rate": 6.577759233413405e-06,
      "loss": 2.434,
      "step": 39670
    },
    {
      "epoch": 2.6629307741350963,
      "grad_norm": 0.6439782977104187,
      "learning_rate": 6.551940764819076e-06,
      "loss": 2.4894,
      "step": 39680
    },
    {
      "epoch": 2.6636018925539413,
      "grad_norm": 0.7292796969413757,
      "learning_rate": 6.52617134988669e-06,
      "loss": 2.4827,
      "step": 39690
    },
    {
      "epoch": 2.664273010972786,
      "grad_norm": 0.7372629046440125,
      "learning_rate": 6.500451002143359e-06,
      "loss": 2.4342,
      "step": 39700
    },
    {
      "epoch": 2.664273010972786,
      "eval_bleu": 21.253348822254388,
      "eval_gen_len": 28.865,
      "eval_loss": 2.929332733154297,
      "eval_runtime": 62.5229,
      "eval_samples_per_second": 15.994,
      "eval_steps_per_second": 1.008,
      "step": 39700
    },
    {
      "epoch": 2.664944129391631,
      "grad_norm": 0.7055501937866211,
      "learning_rate": 6.474779735090497e-06,
      "loss": 2.4372,
      "step": 39710
    },
    {
      "epoch": 2.665615247810476,
      "grad_norm": 0.6640725135803223,
      "learning_rate": 6.449157562203656e-06,
      "loss": 2.4558,
      "step": 39720
    },
    {
      "epoch": 2.666286366229321,
      "grad_norm": 0.7202579379081726,
      "learning_rate": 6.4235844969327445e-06,
      "loss": 2.4559,
      "step": 39730
    },
    {
      "epoch": 2.666957484648166,
      "grad_norm": 0.7001341581344604,
      "learning_rate": 6.3980605527017565e-06,
      "loss": 2.4346,
      "step": 39740
    },
    {
      "epoch": 2.667628603067011,
      "grad_norm": 0.7370558381080627,
      "learning_rate": 6.3725857429090204e-06,
      "loss": 2.4886,
      "step": 39750
    },
    {
      "epoch": 2.667628603067011,
      "eval_bleu": 21.325563201160815,
      "eval_gen_len": 28.894,
      "eval_loss": 2.9290554523468018,
      "eval_runtime": 62.3658,
      "eval_samples_per_second": 16.034,
      "eval_steps_per_second": 1.01,
      "step": 39750
    },
    {
      "epoch": 2.668299721485856,
      "grad_norm": 0.72318035364151,
      "learning_rate": 6.3471600809270056e-06,
      "loss": 2.4481,
      "step": 39760
    },
    {
      "epoch": 2.668970839904701,
      "grad_norm": 0.7412200570106506,
      "learning_rate": 6.321783580102402e-06,
      "loss": 2.4949,
      "step": 39770
    },
    {
      "epoch": 2.6696419583235462,
      "grad_norm": 0.7063453793525696,
      "learning_rate": 6.296456253756056e-06,
      "loss": 2.4347,
      "step": 39780
    },
    {
      "epoch": 2.6703130767423913,
      "grad_norm": 0.6912809014320374,
      "learning_rate": 6.271178115183063e-06,
      "loss": 2.4884,
      "step": 39790
    },
    {
      "epoch": 2.6709841951612363,
      "grad_norm": 0.7464077472686768,
      "learning_rate": 6.245949177652655e-06,
      "loss": 2.4664,
      "step": 39800
    },
    {
      "epoch": 2.6709841951612363,
      "eval_bleu": 21.349570193293232,
      "eval_gen_len": 28.898,
      "eval_loss": 2.9287967681884766,
      "eval_runtime": 61.5566,
      "eval_samples_per_second": 16.245,
      "eval_steps_per_second": 1.023,
      "step": 39800
    },
    {
      "epoch": 2.6716553135800813,
      "grad_norm": 0.6929463148117065,
      "learning_rate": 6.220769454408282e-06,
      "loss": 2.4281,
      "step": 39810
    },
    {
      "epoch": 2.6723264319989264,
      "grad_norm": 0.6904255151748657,
      "learning_rate": 6.195638958667482e-06,
      "loss": 2.4296,
      "step": 39820
    },
    {
      "epoch": 2.6729975504177714,
      "grad_norm": 0.6796767115592957,
      "learning_rate": 6.1705577036220375e-06,
      "loss": 2.4813,
      "step": 39830
    },
    {
      "epoch": 2.6736686688366165,
      "grad_norm": 0.708336591720581,
      "learning_rate": 6.145525702437826e-06,
      "loss": 2.4294,
      "step": 39840
    },
    {
      "epoch": 2.674339787255461,
      "grad_norm": 0.6821491718292236,
      "learning_rate": 6.120542968254894e-06,
      "loss": 2.4377,
      "step": 39850
    },
    {
      "epoch": 2.674339787255461,
      "eval_bleu": 21.224917994425212,
      "eval_gen_len": 28.844,
      "eval_loss": 2.93001651763916,
      "eval_runtime": 62.3284,
      "eval_samples_per_second": 16.044,
      "eval_steps_per_second": 1.011,
      "step": 39850
    },
    {
      "epoch": 2.675010905674306,
      "grad_norm": 0.7070227861404419,
      "learning_rate": 6.095609514187417e-06,
      "loss": 2.3964,
      "step": 39860
    },
    {
      "epoch": 2.675682024093151,
      "grad_norm": 0.6660284399986267,
      "learning_rate": 6.070725353323692e-06,
      "loss": 2.461,
      "step": 39870
    },
    {
      "epoch": 2.676353142511996,
      "grad_norm": 0.6644681692123413,
      "learning_rate": 6.045890498726181e-06,
      "loss": 2.4333,
      "step": 39880
    },
    {
      "epoch": 2.6770242609308412,
      "grad_norm": 0.7173115015029907,
      "learning_rate": 6.021104963431412e-06,
      "loss": 2.3918,
      "step": 39890
    },
    {
      "epoch": 2.6776953793496863,
      "grad_norm": 0.6701093912124634,
      "learning_rate": 5.996368760450077e-06,
      "loss": 2.4274,
      "step": 39900
    },
    {
      "epoch": 2.6776953793496863,
      "eval_bleu": 21.173457679940597,
      "eval_gen_len": 28.848,
      "eval_loss": 2.929910182952881,
      "eval_runtime": 62.2665,
      "eval_samples_per_second": 16.06,
      "eval_steps_per_second": 1.012,
      "step": 39900
    },
    {
      "epoch": 2.6783664977685313,
      "grad_norm": 0.6733250021934509,
      "learning_rate": 5.971681902766913e-06,
      "loss": 2.4307,
      "step": 39910
    },
    {
      "epoch": 2.6790376161873763,
      "grad_norm": 0.6577919125556946,
      "learning_rate": 5.947044403340818e-06,
      "loss": 2.472,
      "step": 39920
    },
    {
      "epoch": 2.6797087346062214,
      "grad_norm": 0.7980261445045471,
      "learning_rate": 5.922456275104704e-06,
      "loss": 2.4586,
      "step": 39930
    },
    {
      "epoch": 2.6803798530250664,
      "grad_norm": 0.6852180361747742,
      "learning_rate": 5.897917530965658e-06,
      "loss": 2.4471,
      "step": 39940
    },
    {
      "epoch": 2.681050971443911,
      "grad_norm": 0.6605219841003418,
      "learning_rate": 5.873428183804774e-06,
      "loss": 2.4439,
      "step": 39950
    },
    {
      "epoch": 2.681050971443911,
      "eval_bleu": 21.244282112623168,
      "eval_gen_len": 28.9,
      "eval_loss": 2.929499626159668,
      "eval_runtime": 62.1564,
      "eval_samples_per_second": 16.088,
      "eval_steps_per_second": 1.014,
      "step": 39950
    },
    {
      "epoch": 2.681722089862756,
      "grad_norm": 0.6860839128494263,
      "learning_rate": 5.848988246477227e-06,
      "loss": 2.4494,
      "step": 39960
    },
    {
      "epoch": 2.682393208281601,
      "grad_norm": 0.6492411494255066,
      "learning_rate": 5.824597731812264e-06,
      "loss": 2.3665,
      "step": 39970
    },
    {
      "epoch": 2.683064326700446,
      "grad_norm": 0.6513429880142212,
      "learning_rate": 5.800256652613223e-06,
      "loss": 2.3839,
      "step": 39980
    },
    {
      "epoch": 2.683735445119291,
      "grad_norm": 0.6722218990325928,
      "learning_rate": 5.775965021657415e-06,
      "loss": 2.403,
      "step": 39990
    },
    {
      "epoch": 2.6844065635381362,
      "grad_norm": 0.7262657284736633,
      "learning_rate": 5.751722851696284e-06,
      "loss": 2.4438,
      "step": 40000
    },
    {
      "epoch": 2.6844065635381362,
      "eval_bleu": 21.249602631074463,
      "eval_gen_len": 28.848,
      "eval_loss": 2.929967164993286,
      "eval_runtime": 61.9249,
      "eval_samples_per_second": 16.149,
      "eval_steps_per_second": 1.017,
      "step": 40000
    },
    {
      "epoch": 2.6850776819569813,
      "grad_norm": 0.6754244565963745,
      "learning_rate": 5.727530155455218e-06,
      "loss": 2.4165,
      "step": 40010
    },
    {
      "epoch": 2.6857488003758263,
      "grad_norm": 0.6459627151489258,
      "learning_rate": 5.703386945633726e-06,
      "loss": 2.4089,
      "step": 40020
    },
    {
      "epoch": 2.6864199187946713,
      "grad_norm": 0.7043597102165222,
      "learning_rate": 5.679293234905281e-06,
      "loss": 2.4551,
      "step": 40030
    },
    {
      "epoch": 2.6870910372135164,
      "grad_norm": 0.6856844425201416,
      "learning_rate": 5.655249035917376e-06,
      "loss": 2.4116,
      "step": 40040
    },
    {
      "epoch": 2.6877621556323614,
      "grad_norm": 0.6962969899177551,
      "learning_rate": 5.631254361291527e-06,
      "loss": 2.5009,
      "step": 40050
    },
    {
      "epoch": 2.6877621556323614,
      "eval_bleu": 21.214098485542387,
      "eval_gen_len": 28.898,
      "eval_loss": 2.9294185638427734,
      "eval_runtime": 62.2687,
      "eval_samples_per_second": 16.059,
      "eval_steps_per_second": 1.012,
      "step": 40050
    },
    {
      "epoch": 2.6884332740512065,
      "grad_norm": 0.7411274909973145,
      "learning_rate": 5.6073092236232585e-06,
      "loss": 2.4353,
      "step": 40060
    },
    {
      "epoch": 2.6891043924700515,
      "grad_norm": 0.6542401909828186,
      "learning_rate": 5.583413635482082e-06,
      "loss": 2.427,
      "step": 40070
    },
    {
      "epoch": 2.6897755108888965,
      "grad_norm": 0.7284162640571594,
      "learning_rate": 5.559567609411509e-06,
      "loss": 2.4893,
      "step": 40080
    },
    {
      "epoch": 2.6904466293077416,
      "grad_norm": 0.7248842120170593,
      "learning_rate": 5.535771157929004e-06,
      "loss": 2.3977,
      "step": 40090
    },
    {
      "epoch": 2.6911177477265866,
      "grad_norm": 0.7292407155036926,
      "learning_rate": 5.512024293526063e-06,
      "loss": 2.4301,
      "step": 40100
    },
    {
      "epoch": 2.6911177477265866,
      "eval_bleu": 21.503794424858704,
      "eval_gen_len": 28.913,
      "eval_loss": 2.92897629737854,
      "eval_runtime": 62.0803,
      "eval_samples_per_second": 16.108,
      "eval_steps_per_second": 1.015,
      "step": 40100
    },
    {
      "epoch": 2.6917888661454312,
      "grad_norm": 0.6459742784500122,
      "learning_rate": 5.4883270286681055e-06,
      "loss": 2.3956,
      "step": 40110
    },
    {
      "epoch": 2.6924599845642763,
      "grad_norm": 0.6425291895866394,
      "learning_rate": 5.4646793757945345e-06,
      "loss": 2.503,
      "step": 40120
    },
    {
      "epoch": 2.6931311029831213,
      "grad_norm": 0.6669746041297913,
      "learning_rate": 5.441081347318677e-06,
      "loss": 2.4623,
      "step": 40130
    },
    {
      "epoch": 2.6938022214019663,
      "grad_norm": 0.6454920768737793,
      "learning_rate": 5.41753295562788e-06,
      "loss": 2.3979,
      "step": 40140
    },
    {
      "epoch": 2.6944733398208114,
      "grad_norm": 0.6842097640037537,
      "learning_rate": 5.394034213083377e-06,
      "loss": 2.4135,
      "step": 40150
    },
    {
      "epoch": 2.6944733398208114,
      "eval_bleu": 21.383896046019416,
      "eval_gen_len": 28.887,
      "eval_loss": 2.9291529655456543,
      "eval_runtime": 60.9308,
      "eval_samples_per_second": 16.412,
      "eval_steps_per_second": 1.034,
      "step": 40150
    },
    {
      "epoch": 2.6951444582396564,
      "grad_norm": 0.7433153986930847,
      "learning_rate": 5.370585132020334e-06,
      "loss": 2.4247,
      "step": 40160
    },
    {
      "epoch": 2.6958155766585015,
      "grad_norm": 0.6608502268791199,
      "learning_rate": 5.347185724747905e-06,
      "loss": 2.4322,
      "step": 40170
    },
    {
      "epoch": 2.6964866950773465,
      "grad_norm": 0.7170001268386841,
      "learning_rate": 5.3238360035491094e-06,
      "loss": 2.4198,
      "step": 40180
    },
    {
      "epoch": 2.6971578134961915,
      "grad_norm": 0.6582309603691101,
      "learning_rate": 5.300535980680943e-06,
      "loss": 2.4195,
      "step": 40190
    },
    {
      "epoch": 2.697828931915036,
      "grad_norm": 0.6968815922737122,
      "learning_rate": 5.277285668374243e-06,
      "loss": 2.4833,
      "step": 40200
    },
    {
      "epoch": 2.697828931915036,
      "eval_bleu": 21.37781906118038,
      "eval_gen_len": 28.874,
      "eval_loss": 2.928957939147949,
      "eval_runtime": 60.7822,
      "eval_samples_per_second": 16.452,
      "eval_steps_per_second": 1.036,
      "step": 40200
    },
    {
      "epoch": 2.698500050333881,
      "grad_norm": 0.6177372932434082,
      "learning_rate": 5.254085078833804e-06,
      "loss": 2.4505,
      "step": 40210
    },
    {
      "epoch": 2.6991711687527262,
      "grad_norm": 0.7125768661499023,
      "learning_rate": 5.230934224238293e-06,
      "loss": 2.4459,
      "step": 40220
    },
    {
      "epoch": 2.6998422871715713,
      "grad_norm": 0.6690816283226013,
      "learning_rate": 5.2078331167403015e-06,
      "loss": 2.4341,
      "step": 40230
    },
    {
      "epoch": 2.7005134055904163,
      "grad_norm": 0.6976492404937744,
      "learning_rate": 5.184781768466274e-06,
      "loss": 2.4377,
      "step": 40240
    },
    {
      "epoch": 2.7011845240092613,
      "grad_norm": 0.6701393127441406,
      "learning_rate": 5.161780191516552e-06,
      "loss": 2.4434,
      "step": 40250
    },
    {
      "epoch": 2.7011845240092613,
      "eval_bleu": 21.350617452991436,
      "eval_gen_len": 28.918,
      "eval_loss": 2.9294049739837646,
      "eval_runtime": 60.9373,
      "eval_samples_per_second": 16.41,
      "eval_steps_per_second": 1.034,
      "step": 40250
    },
    {
      "epoch": 2.7018556424281064,
      "grad_norm": 0.7506797909736633,
      "learning_rate": 5.138828397965334e-06,
      "loss": 2.4648,
      "step": 40260
    },
    {
      "epoch": 2.7025267608469514,
      "grad_norm": 0.6852640509605408,
      "learning_rate": 5.115926399860726e-06,
      "loss": 2.3876,
      "step": 40270
    },
    {
      "epoch": 2.7031978792657965,
      "grad_norm": 0.7278387546539307,
      "learning_rate": 5.093074209224635e-06,
      "loss": 2.5074,
      "step": 40280
    },
    {
      "epoch": 2.7038689976846415,
      "grad_norm": 0.6731342077255249,
      "learning_rate": 5.070271838052876e-06,
      "loss": 2.3688,
      "step": 40290
    },
    {
      "epoch": 2.7045401161034865,
      "grad_norm": 0.6941795945167542,
      "learning_rate": 5.047519298315095e-06,
      "loss": 2.4149,
      "step": 40300
    },
    {
      "epoch": 2.7045401161034865,
      "eval_bleu": 21.2628114258726,
      "eval_gen_len": 28.871,
      "eval_loss": 2.9292893409729004,
      "eval_runtime": 60.7891,
      "eval_samples_per_second": 16.45,
      "eval_steps_per_second": 1.036,
      "step": 40300
    },
    {
      "epoch": 2.7052112345223316,
      "grad_norm": 0.7053247690200806,
      "learning_rate": 5.024816601954763e-06,
      "loss": 2.4682,
      "step": 40310
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 0.7078310251235962,
      "learning_rate": 5.002163760889189e-06,
      "loss": 2.5049,
      "step": 40320
    },
    {
      "epoch": 2.7065534713600217,
      "grad_norm": 0.7001372575759888,
      "learning_rate": 4.979560787009541e-06,
      "loss": 2.4348,
      "step": 40330
    },
    {
      "epoch": 2.7072245897788667,
      "grad_norm": 0.6604986190795898,
      "learning_rate": 4.957007692180782e-06,
      "loss": 2.4638,
      "step": 40340
    },
    {
      "epoch": 2.7078957081977117,
      "grad_norm": 0.7115070819854736,
      "learning_rate": 4.9345044882417205e-06,
      "loss": 2.4705,
      "step": 40350
    },
    {
      "epoch": 2.7078957081977117,
      "eval_bleu": 21.358770393651323,
      "eval_gen_len": 28.929,
      "eval_loss": 2.9288220405578613,
      "eval_runtime": 62.2333,
      "eval_samples_per_second": 16.069,
      "eval_steps_per_second": 1.012,
      "step": 40350
    },
    {
      "epoch": 2.7085668266165563,
      "grad_norm": 0.6962560415267944,
      "learning_rate": 4.912051187004918e-06,
      "loss": 2.4225,
      "step": 40360
    },
    {
      "epoch": 2.7092379450354014,
      "grad_norm": 0.6617625951766968,
      "learning_rate": 4.889647800256825e-06,
      "loss": 2.428,
      "step": 40370
    },
    {
      "epoch": 2.7099090634542464,
      "grad_norm": 0.7139581441879272,
      "learning_rate": 4.867294339757622e-06,
      "loss": 2.4766,
      "step": 40380
    },
    {
      "epoch": 2.7105801818730915,
      "grad_norm": 0.6967187523841858,
      "learning_rate": 4.84499081724129e-06,
      "loss": 2.4034,
      "step": 40390
    },
    {
      "epoch": 2.7112513002919365,
      "grad_norm": 0.7276742458343506,
      "learning_rate": 4.822737244415632e-06,
      "loss": 2.4541,
      "step": 40400
    },
    {
      "epoch": 2.7112513002919365,
      "eval_bleu": 21.392437385519404,
      "eval_gen_len": 28.89,
      "eval_loss": 2.929201364517212,
      "eval_runtime": 61.9022,
      "eval_samples_per_second": 16.155,
      "eval_steps_per_second": 1.018,
      "step": 40400
    },
    {
      "epoch": 2.7119224187107815,
      "grad_norm": 0.7202193737030029,
      "learning_rate": 4.800533632962201e-06,
      "loss": 2.4038,
      "step": 40410
    },
    {
      "epoch": 2.7125935371296266,
      "grad_norm": 0.7044960856437683,
      "learning_rate": 4.77837999453633e-06,
      "loss": 2.37,
      "step": 40420
    },
    {
      "epoch": 2.7132646555484716,
      "grad_norm": 0.6217913627624512,
      "learning_rate": 4.75627634076713e-06,
      "loss": 2.4374,
      "step": 40430
    },
    {
      "epoch": 2.7139357739673167,
      "grad_norm": 0.7050182223320007,
      "learning_rate": 4.734222683257461e-06,
      "loss": 2.4744,
      "step": 40440
    },
    {
      "epoch": 2.7146068923861613,
      "grad_norm": 0.7004997730255127,
      "learning_rate": 4.712219033583942e-06,
      "loss": 2.4075,
      "step": 40450
    },
    {
      "epoch": 2.7146068923861613,
      "eval_bleu": 21.271727598003377,
      "eval_gen_len": 28.891,
      "eval_loss": 2.9293251037597656,
      "eval_runtime": 61.6147,
      "eval_samples_per_second": 16.23,
      "eval_steps_per_second": 1.022,
      "step": 40450
    },
    {
      "epoch": 2.7152780108050063,
      "grad_norm": 0.6605388522148132,
      "learning_rate": 4.690265403296945e-06,
      "loss": 2.4341,
      "step": 40460
    },
    {
      "epoch": 2.7159491292238513,
      "grad_norm": 0.672776997089386,
      "learning_rate": 4.668361803920585e-06,
      "loss": 2.4177,
      "step": 40470
    },
    {
      "epoch": 2.7166202476426964,
      "grad_norm": 0.7648991346359253,
      "learning_rate": 4.646508246952708e-06,
      "loss": 2.4169,
      "step": 40480
    },
    {
      "epoch": 2.7172913660615414,
      "grad_norm": 0.6849274039268494,
      "learning_rate": 4.624704743864871e-06,
      "loss": 2.4591,
      "step": 40490
    },
    {
      "epoch": 2.7179624844803865,
      "grad_norm": 0.6720925569534302,
      "learning_rate": 4.602951306102432e-06,
      "loss": 2.4384,
      "step": 40500
    },
    {
      "epoch": 2.7179624844803865,
      "eval_bleu": 21.354317139501106,
      "eval_gen_len": 28.924,
      "eval_loss": 2.930074453353882,
      "eval_runtime": 62.3793,
      "eval_samples_per_second": 16.031,
      "eval_steps_per_second": 1.01,
      "step": 40500
    },
    {
      "epoch": 2.7186336028992315,
      "grad_norm": 0.7764781713485718,
      "learning_rate": 4.581247945084366e-06,
      "loss": 2.4363,
      "step": 40510
    },
    {
      "epoch": 2.7193047213180765,
      "grad_norm": 0.7327041029930115,
      "learning_rate": 4.5595946722034485e-06,
      "loss": 2.4212,
      "step": 40520
    },
    {
      "epoch": 2.7199758397369216,
      "grad_norm": 0.7221027612686157,
      "learning_rate": 4.537991498826099e-06,
      "loss": 2.4693,
      "step": 40530
    },
    {
      "epoch": 2.7206469581557666,
      "grad_norm": 0.6389591097831726,
      "learning_rate": 4.516438436292491e-06,
      "loss": 2.4782,
      "step": 40540
    },
    {
      "epoch": 2.7213180765746117,
      "grad_norm": 0.6718280911445618,
      "learning_rate": 4.494935495916441e-06,
      "loss": 2.48,
      "step": 40550
    },
    {
      "epoch": 2.7213180765746117,
      "eval_bleu": 21.421164299874263,
      "eval_gen_len": 28.854,
      "eval_loss": 2.9298269748687744,
      "eval_runtime": 62.3791,
      "eval_samples_per_second": 16.031,
      "eval_steps_per_second": 1.01,
      "step": 40550
    },
    {
      "epoch": 2.7219891949934567,
      "grad_norm": 0.6425983309745789,
      "learning_rate": 4.473482688985509e-06,
      "loss": 2.4853,
      "step": 40560
    },
    {
      "epoch": 2.7226603134123017,
      "grad_norm": 0.6525430083274841,
      "learning_rate": 4.452080026760897e-06,
      "loss": 2.4171,
      "step": 40570
    },
    {
      "epoch": 2.723331431831147,
      "grad_norm": 0.6770895719528198,
      "learning_rate": 4.430727520477485e-06,
      "loss": 2.4541,
      "step": 40580
    },
    {
      "epoch": 2.724002550249992,
      "grad_norm": 0.7056712508201599,
      "learning_rate": 4.409425181343841e-06,
      "loss": 2.4386,
      "step": 40590
    },
    {
      "epoch": 2.724673668668837,
      "grad_norm": 0.7237230539321899,
      "learning_rate": 4.3881730205422185e-06,
      "loss": 2.4109,
      "step": 40600
    },
    {
      "epoch": 2.724673668668837,
      "eval_bleu": 21.285432903996046,
      "eval_gen_len": 28.86,
      "eval_loss": 2.9299330711364746,
      "eval_runtime": 61.3615,
      "eval_samples_per_second": 16.297,
      "eval_steps_per_second": 1.027,
      "step": 40600
    },
    {
      "epoch": 2.7253447870876815,
      "grad_norm": 0.6609437465667725,
      "learning_rate": 4.366971049228486e-06,
      "loss": 2.4088,
      "step": 40610
    },
    {
      "epoch": 2.7260159055065265,
      "grad_norm": 0.7013397216796875,
      "learning_rate": 4.345819278532204e-06,
      "loss": 2.4427,
      "step": 40620
    },
    {
      "epoch": 2.7266870239253715,
      "grad_norm": 0.7671183347702026,
      "learning_rate": 4.324717719556537e-06,
      "loss": 2.3923,
      "step": 40630
    },
    {
      "epoch": 2.7273581423442166,
      "grad_norm": 0.7277572751045227,
      "learning_rate": 4.3036663833783574e-06,
      "loss": 2.5377,
      "step": 40640
    },
    {
      "epoch": 2.7280292607630616,
      "grad_norm": 0.6347764730453491,
      "learning_rate": 4.282665281048126e-06,
      "loss": 2.3986,
      "step": 40650
    },
    {
      "epoch": 2.7280292607630616,
      "eval_bleu": 21.496709534718264,
      "eval_gen_len": 28.888,
      "eval_loss": 2.929758071899414,
      "eval_runtime": 61.5798,
      "eval_samples_per_second": 16.239,
      "eval_steps_per_second": 1.023,
      "step": 40650
    },
    {
      "epoch": 2.7287003791819067,
      "grad_norm": 0.629660964012146,
      "learning_rate": 4.261714423589924e-06,
      "loss": 2.4015,
      "step": 40660
    },
    {
      "epoch": 2.7293714976007517,
      "grad_norm": 0.6682655215263367,
      "learning_rate": 4.240813822001488e-06,
      "loss": 2.4632,
      "step": 40670
    },
    {
      "epoch": 2.7300426160195967,
      "grad_norm": 0.6839831471443176,
      "learning_rate": 4.219963487254186e-06,
      "loss": 2.4176,
      "step": 40680
    },
    {
      "epoch": 2.730713734438442,
      "grad_norm": 0.7662822008132935,
      "learning_rate": 4.1991634302929405e-06,
      "loss": 2.4463,
      "step": 40690
    },
    {
      "epoch": 2.731384852857287,
      "grad_norm": 0.7478718161582947,
      "learning_rate": 4.178413662036363e-06,
      "loss": 2.4842,
      "step": 40700
    },
    {
      "epoch": 2.731384852857287,
      "eval_bleu": 21.29633964834698,
      "eval_gen_len": 28.895,
      "eval_loss": 2.929837942123413,
      "eval_runtime": 61.9576,
      "eval_samples_per_second": 16.14,
      "eval_steps_per_second": 1.017,
      "step": 40700
    },
    {
      "epoch": 2.7320559712761314,
      "grad_norm": 0.6904086470603943,
      "learning_rate": 4.1577141933765825e-06,
      "loss": 2.4924,
      "step": 40710
    },
    {
      "epoch": 2.7327270896949765,
      "grad_norm": 0.717873752117157,
      "learning_rate": 4.137065035179388e-06,
      "loss": 2.4862,
      "step": 40720
    },
    {
      "epoch": 2.7333982081138215,
      "grad_norm": 0.6325381398200989,
      "learning_rate": 4.116466198284141e-06,
      "loss": 2.4707,
      "step": 40730
    },
    {
      "epoch": 2.7340693265326665,
      "grad_norm": 0.6539475321769714,
      "learning_rate": 4.09591769350377e-06,
      "loss": 2.5038,
      "step": 40740
    },
    {
      "epoch": 2.7347404449515116,
      "grad_norm": 0.7215002179145813,
      "learning_rate": 4.075419531624791e-06,
      "loss": 2.4951,
      "step": 40750
    },
    {
      "epoch": 2.7347404449515116,
      "eval_bleu": 21.38755471607862,
      "eval_gen_len": 28.867,
      "eval_loss": 2.929938793182373,
      "eval_runtime": 62.247,
      "eval_samples_per_second": 16.065,
      "eval_steps_per_second": 1.012,
      "step": 40750
    },
    {
      "epoch": 2.7354115633703566,
      "grad_norm": 0.784778892993927,
      "learning_rate": 4.054971723407297e-06,
      "loss": 2.4009,
      "step": 40760
    },
    {
      "epoch": 2.7360826817892017,
      "grad_norm": 0.7314497828483582,
      "learning_rate": 4.0345742795849794e-06,
      "loss": 2.4712,
      "step": 40770
    },
    {
      "epoch": 2.7367538002080467,
      "grad_norm": 0.7348960041999817,
      "learning_rate": 4.014227210865018e-06,
      "loss": 2.4386,
      "step": 40780
    },
    {
      "epoch": 2.7374249186268917,
      "grad_norm": 0.7734733819961548,
      "learning_rate": 3.993930527928225e-06,
      "loss": 2.3914,
      "step": 40790
    },
    {
      "epoch": 2.738096037045737,
      "grad_norm": 0.6672506332397461,
      "learning_rate": 3.973684241428921e-06,
      "loss": 2.4861,
      "step": 40800
    },
    {
      "epoch": 2.738096037045737,
      "eval_bleu": 21.42721742443063,
      "eval_gen_len": 28.908,
      "eval_loss": 2.929628610610962,
      "eval_runtime": 61.8194,
      "eval_samples_per_second": 16.176,
      "eval_steps_per_second": 1.019,
      "step": 40800
    },
    {
      "epoch": 2.738767155464582,
      "grad_norm": 0.7605141401290894,
      "learning_rate": 3.953488361994994e-06,
      "loss": 2.4877,
      "step": 40810
    },
    {
      "epoch": 2.739438273883427,
      "grad_norm": 0.7595989108085632,
      "learning_rate": 3.933342900227843e-06,
      "loss": 2.5168,
      "step": 40820
    },
    {
      "epoch": 2.740109392302272,
      "grad_norm": 0.6422581672668457,
      "learning_rate": 3.913247866702452e-06,
      "loss": 2.4024,
      "step": 40830
    },
    {
      "epoch": 2.740780510721117,
      "grad_norm": 0.6855875849723816,
      "learning_rate": 3.89320327196725e-06,
      "loss": 2.4696,
      "step": 40840
    },
    {
      "epoch": 2.741451629139962,
      "grad_norm": 0.6439711451530457,
      "learning_rate": 3.873209126544286e-06,
      "loss": 2.4197,
      "step": 40850
    },
    {
      "epoch": 2.741451629139962,
      "eval_bleu": 21.408819245442974,
      "eval_gen_len": 28.866,
      "eval_loss": 2.92969012260437,
      "eval_runtime": 61.9244,
      "eval_samples_per_second": 16.149,
      "eval_steps_per_second": 1.017,
      "step": 40850
    },
    {
      "epoch": 2.742122747558807,
      "grad_norm": 0.6885123252868652,
      "learning_rate": 3.8532654409290435e-06,
      "loss": 2.4633,
      "step": 40860
    },
    {
      "epoch": 2.7427938659776516,
      "grad_norm": 0.7099656462669373,
      "learning_rate": 3.833372225590592e-06,
      "loss": 2.4777,
      "step": 40870
    },
    {
      "epoch": 2.7434649843964967,
      "grad_norm": 0.7006723880767822,
      "learning_rate": 3.813529490971446e-06,
      "loss": 2.4691,
      "step": 40880
    },
    {
      "epoch": 2.7441361028153417,
      "grad_norm": 0.6898350119590759,
      "learning_rate": 3.793737247487661e-06,
      "loss": 2.379,
      "step": 40890
    },
    {
      "epoch": 2.7448072212341867,
      "grad_norm": 0.6751227974891663,
      "learning_rate": 3.773995505528749e-06,
      "loss": 2.4355,
      "step": 40900
    },
    {
      "epoch": 2.7448072212341867,
      "eval_bleu": 21.446572793553017,
      "eval_gen_len": 28.891,
      "eval_loss": 2.9295992851257324,
      "eval_runtime": 61.3474,
      "eval_samples_per_second": 16.301,
      "eval_steps_per_second": 1.027,
      "step": 40900
    },
    {
      "epoch": 2.745478339653032,
      "grad_norm": 0.7384781241416931,
      "learning_rate": 3.754304275457776e-06,
      "loss": 2.425,
      "step": 40910
    },
    {
      "epoch": 2.746149458071877,
      "grad_norm": 0.6801409125328064,
      "learning_rate": 3.7346635676112296e-06,
      "loss": 2.4552,
      "step": 40920
    },
    {
      "epoch": 2.746820576490722,
      "grad_norm": 0.7483236789703369,
      "learning_rate": 3.7150733922990956e-06,
      "loss": 2.4144,
      "step": 40930
    },
    {
      "epoch": 2.747491694909567,
      "grad_norm": 0.7079375982284546,
      "learning_rate": 3.695533759804848e-06,
      "loss": 2.4268,
      "step": 40940
    },
    {
      "epoch": 2.748162813328412,
      "grad_norm": 0.6750970482826233,
      "learning_rate": 3.6760446803854156e-06,
      "loss": 2.4811,
      "step": 40950
    },
    {
      "epoch": 2.748162813328412,
      "eval_bleu": 21.364549386025857,
      "eval_gen_len": 28.857,
      "eval_loss": 2.9292352199554443,
      "eval_runtime": 61.9112,
      "eval_samples_per_second": 16.152,
      "eval_steps_per_second": 1.018,
      "step": 40950
    },
    {
      "epoch": 2.7488339317472565,
      "grad_norm": 0.6622827649116516,
      "learning_rate": 3.6566061642711926e-06,
      "loss": 2.426,
      "step": 40960
    },
    {
      "epoch": 2.7495050501661016,
      "grad_norm": 0.6259996294975281,
      "learning_rate": 3.637218221666061e-06,
      "loss": 2.4602,
      "step": 40970
    },
    {
      "epoch": 2.7501761685849466,
      "grad_norm": 0.6814723610877991,
      "learning_rate": 3.6178808627472804e-06,
      "loss": 2.4295,
      "step": 40980
    },
    {
      "epoch": 2.7508472870037917,
      "grad_norm": 0.669295608997345,
      "learning_rate": 3.598594097665642e-06,
      "loss": 2.4485,
      "step": 40990
    },
    {
      "epoch": 2.7515184054226367,
      "grad_norm": 0.6716978549957275,
      "learning_rate": 3.5793579365453358e-06,
      "loss": 2.4304,
      "step": 41000
    },
    {
      "epoch": 2.7515184054226367,
      "eval_bleu": 21.420083116597308,
      "eval_gen_len": 28.869,
      "eval_loss": 2.929476022720337,
      "eval_runtime": 62.7797,
      "eval_samples_per_second": 15.929,
      "eval_steps_per_second": 1.004,
      "step": 41000
    },
    {
      "epoch": 2.7521895238414817,
      "grad_norm": 0.7291555404663086,
      "learning_rate": 3.5601723894839954e-06,
      "loss": 2.4328,
      "step": 41010
    },
    {
      "epoch": 2.752860642260327,
      "grad_norm": 0.6801812648773193,
      "learning_rate": 3.541037466552666e-06,
      "loss": 2.4309,
      "step": 41020
    },
    {
      "epoch": 2.753531760679172,
      "grad_norm": 0.7303134202957153,
      "learning_rate": 3.521953177795834e-06,
      "loss": 2.4834,
      "step": 41030
    },
    {
      "epoch": 2.754202879098017,
      "grad_norm": 0.6909818053245544,
      "learning_rate": 3.502919533231441e-06,
      "loss": 2.4122,
      "step": 41040
    },
    {
      "epoch": 2.754873997516862,
      "grad_norm": 0.6933927536010742,
      "learning_rate": 3.4839365428507853e-06,
      "loss": 2.4143,
      "step": 41050
    },
    {
      "epoch": 2.754873997516862,
      "eval_bleu": 21.284780574225813,
      "eval_gen_len": 28.867,
      "eval_loss": 2.9295198917388916,
      "eval_runtime": 61.5877,
      "eval_samples_per_second": 16.237,
      "eval_steps_per_second": 1.023,
      "step": 41050
    },
    {
      "epoch": 2.755545115935707,
      "grad_norm": 0.7123530507087708,
      "learning_rate": 3.465004216618617e-06,
      "loss": 2.4442,
      "step": 41060
    },
    {
      "epoch": 2.756216234354552,
      "grad_norm": 0.697566568851471,
      "learning_rate": 3.4461225644730645e-06,
      "loss": 2.4555,
      "step": 41070
    },
    {
      "epoch": 2.756887352773397,
      "grad_norm": 0.7149439454078674,
      "learning_rate": 3.4272915963256878e-06,
      "loss": 2.4753,
      "step": 41080
    },
    {
      "epoch": 2.757558471192242,
      "grad_norm": 0.7217497825622559,
      "learning_rate": 3.408511322061403e-06,
      "loss": 2.4677,
      "step": 41090
    },
    {
      "epoch": 2.758229589611087,
      "grad_norm": 0.6668905019760132,
      "learning_rate": 3.3897817515385454e-06,
      "loss": 2.4508,
      "step": 41100
    },
    {
      "epoch": 2.758229589611087,
      "eval_bleu": 21.374959477779875,
      "eval_gen_len": 28.907,
      "eval_loss": 2.9296317100524902,
      "eval_runtime": 61.4813,
      "eval_samples_per_second": 16.265,
      "eval_steps_per_second": 1.025,
      "step": 41100
    },
    {
      "epoch": 2.758900708029932,
      "grad_norm": 0.6867163777351379,
      "learning_rate": 3.371102894588807e-06,
      "loss": 2.4688,
      "step": 41110
    },
    {
      "epoch": 2.7595718264487767,
      "grad_norm": 0.7476164698600769,
      "learning_rate": 3.352474761017288e-06,
      "loss": 2.4456,
      "step": 41120
    },
    {
      "epoch": 2.760242944867622,
      "grad_norm": 0.7061030864715576,
      "learning_rate": 3.3338973606024337e-06,
      "loss": 2.4857,
      "step": 41130
    },
    {
      "epoch": 2.760914063286467,
      "grad_norm": 0.7562124729156494,
      "learning_rate": 3.31537070309611e-06,
      "loss": 2.4383,
      "step": 41140
    },
    {
      "epoch": 2.761585181705312,
      "grad_norm": 0.6862273812294006,
      "learning_rate": 3.29689479822346e-06,
      "loss": 2.4041,
      "step": 41150
    },
    {
      "epoch": 2.761585181705312,
      "eval_bleu": 21.376312625837453,
      "eval_gen_len": 28.899,
      "eval_loss": 2.929574728012085,
      "eval_runtime": 61.7055,
      "eval_samples_per_second": 16.206,
      "eval_steps_per_second": 1.021,
      "step": 41150
    },
    {
      "epoch": 2.762256300124157,
      "grad_norm": 0.5982752442359924,
      "learning_rate": 3.2784696556830696e-06,
      "loss": 2.4522,
      "step": 41160
    },
    {
      "epoch": 2.762927418543002,
      "grad_norm": 0.6378833651542664,
      "learning_rate": 3.2600952851468358e-06,
      "loss": 2.3948,
      "step": 41170
    },
    {
      "epoch": 2.763598536961847,
      "grad_norm": 0.6475922465324402,
      "learning_rate": 3.2417716962600097e-06,
      "loss": 2.4272,
      "step": 41180
    },
    {
      "epoch": 2.764269655380692,
      "grad_norm": 0.6833893060684204,
      "learning_rate": 3.2234988986411863e-06,
      "loss": 2.4278,
      "step": 41190
    },
    {
      "epoch": 2.764940773799537,
      "grad_norm": 0.762606143951416,
      "learning_rate": 3.205276901882304e-06,
      "loss": 2.4232,
      "step": 41200
    },
    {
      "epoch": 2.764940773799537,
      "eval_bleu": 21.4064821018992,
      "eval_gen_len": 28.879,
      "eval_loss": 2.930161476135254,
      "eval_runtime": 60.6931,
      "eval_samples_per_second": 16.476,
      "eval_steps_per_second": 1.038,
      "step": 41200
    },
    {
      "epoch": 2.7656118922183817,
      "grad_norm": 0.6592836380004883,
      "learning_rate": 3.1871057155486216e-06,
      "loss": 2.3893,
      "step": 41210
    },
    {
      "epoch": 2.7662830106372267,
      "grad_norm": 0.7193222641944885,
      "learning_rate": 3.1689853491787436e-06,
      "loss": 2.4353,
      "step": 41220
    },
    {
      "epoch": 2.7669541290560717,
      "grad_norm": 0.6816486716270447,
      "learning_rate": 3.1509158122845717e-06,
      "loss": 2.4972,
      "step": 41230
    },
    {
      "epoch": 2.767625247474917,
      "grad_norm": 0.658758819103241,
      "learning_rate": 3.1328971143513743e-06,
      "loss": 2.4101,
      "step": 41240
    },
    {
      "epoch": 2.768296365893762,
      "grad_norm": 0.721520185470581,
      "learning_rate": 3.1149292648376625e-06,
      "loss": 2.4784,
      "step": 41250
    },
    {
      "epoch": 2.768296365893762,
      "eval_bleu": 21.3815926886502,
      "eval_gen_len": 28.885,
      "eval_loss": 2.9301042556762695,
      "eval_runtime": 61.8721,
      "eval_samples_per_second": 16.162,
      "eval_steps_per_second": 1.018,
      "step": 41250
    },
    {
      "epoch": 2.768967484312607,
      "grad_norm": 0.6836608648300171,
      "learning_rate": 3.0970122731753258e-06,
      "loss": 2.4064,
      "step": 41260
    },
    {
      "epoch": 2.769638602731452,
      "grad_norm": 0.6933313012123108,
      "learning_rate": 3.0791461487695184e-06,
      "loss": 2.4213,
      "step": 41270
    },
    {
      "epoch": 2.770309721150297,
      "grad_norm": 0.6845683455467224,
      "learning_rate": 3.0613309009986934e-06,
      "loss": 2.4229,
      "step": 41280
    },
    {
      "epoch": 2.770980839569142,
      "grad_norm": 0.6511437296867371,
      "learning_rate": 3.043566539214593e-06,
      "loss": 2.5055,
      "step": 41290
    },
    {
      "epoch": 2.771651957987987,
      "grad_norm": 0.6595249772071838,
      "learning_rate": 3.0258530727422797e-06,
      "loss": 2.4343,
      "step": 41300
    },
    {
      "epoch": 2.771651957987987,
      "eval_bleu": 21.476942921043456,
      "eval_gen_len": 28.877,
      "eval_loss": 2.9304702281951904,
      "eval_runtime": 61.3775,
      "eval_samples_per_second": 16.293,
      "eval_steps_per_second": 1.026,
      "step": 41300
    },
    {
      "epoch": 2.772323076406832,
      "grad_norm": 0.7020085453987122,
      "learning_rate": 3.00819051088006e-06,
      "loss": 2.4965,
      "step": 41310
    },
    {
      "epoch": 2.772994194825677,
      "grad_norm": 0.6945056915283203,
      "learning_rate": 2.990578862899551e-06,
      "loss": 2.4463,
      "step": 41320
    },
    {
      "epoch": 2.773665313244522,
      "grad_norm": 0.6850169897079468,
      "learning_rate": 2.9730181380456247e-06,
      "loss": 2.4184,
      "step": 41330
    },
    {
      "epoch": 2.774336431663367,
      "grad_norm": 0.669357419013977,
      "learning_rate": 2.9555083455364175e-06,
      "loss": 2.418,
      "step": 41340
    },
    {
      "epoch": 2.7750075500822122,
      "grad_norm": 0.6997342705726624,
      "learning_rate": 2.938049494563366e-06,
      "loss": 2.4537,
      "step": 41350
    },
    {
      "epoch": 2.7750075500822122,
      "eval_bleu": 21.351571816625267,
      "eval_gen_len": 28.881,
      "eval_loss": 2.92999005317688,
      "eval_runtime": 61.2025,
      "eval_samples_per_second": 16.339,
      "eval_steps_per_second": 1.029,
      "step": 41350
    },
    {
      "epoch": 2.7756786685010573,
      "grad_norm": 0.6921997666358948,
      "learning_rate": 2.920641594291118e-06,
      "loss": 2.4634,
      "step": 41360
    },
    {
      "epoch": 2.776349786919902,
      "grad_norm": 0.681654691696167,
      "learning_rate": 2.9032846538576077e-06,
      "loss": 2.4388,
      "step": 41370
    },
    {
      "epoch": 2.777020905338747,
      "grad_norm": 0.6933202743530273,
      "learning_rate": 2.88597868237398e-06,
      "loss": 2.415,
      "step": 41380
    },
    {
      "epoch": 2.777692023757592,
      "grad_norm": 0.6949529051780701,
      "learning_rate": 2.8687236889247018e-06,
      "loss": 2.4304,
      "step": 41390
    },
    {
      "epoch": 2.778363142176437,
      "grad_norm": 0.7095119953155518,
      "learning_rate": 2.851519682567383e-06,
      "loss": 2.4671,
      "step": 41400
    },
    {
      "epoch": 2.778363142176437,
      "eval_bleu": 21.38525280748062,
      "eval_gen_len": 28.885,
      "eval_loss": 2.9295780658721924,
      "eval_runtime": 60.0915,
      "eval_samples_per_second": 16.641,
      "eval_steps_per_second": 1.048,
      "step": 41400
    },
    {
      "epoch": 2.779034260595282,
      "grad_norm": 0.6718694567680359,
      "learning_rate": 2.8343666723329552e-06,
      "loss": 2.4094,
      "step": 41410
    },
    {
      "epoch": 2.779705379014127,
      "grad_norm": 0.6405760049819946,
      "learning_rate": 2.8172646672255276e-06,
      "loss": 2.4087,
      "step": 41420
    },
    {
      "epoch": 2.780376497432972,
      "grad_norm": 0.7185603380203247,
      "learning_rate": 2.800213676222452e-06,
      "loss": 2.4633,
      "step": 41430
    },
    {
      "epoch": 2.781047615851817,
      "grad_norm": 0.6432769894599915,
      "learning_rate": 2.7832137082742905e-06,
      "loss": 2.4138,
      "step": 41440
    },
    {
      "epoch": 2.781718734270662,
      "grad_norm": 0.6102232933044434,
      "learning_rate": 2.766264772304872e-06,
      "loss": 2.4417,
      "step": 41450
    },
    {
      "epoch": 2.781718734270662,
      "eval_bleu": 21.305738735350243,
      "eval_gen_len": 28.888,
      "eval_loss": 2.9298856258392334,
      "eval_runtime": 59.9134,
      "eval_samples_per_second": 16.691,
      "eval_steps_per_second": 1.052,
      "step": 41450
    },
    {
      "epoch": 2.7823898526895072,
      "grad_norm": 0.7653405666351318,
      "learning_rate": 2.7493668772111347e-06,
      "loss": 2.4687,
      "step": 41460
    },
    {
      "epoch": 2.783060971108352,
      "grad_norm": 0.69413161277771,
      "learning_rate": 2.732520031863328e-06,
      "loss": 2.4812,
      "step": 41470
    },
    {
      "epoch": 2.783732089527197,
      "grad_norm": 0.6867746114730835,
      "learning_rate": 2.7157242451048337e-06,
      "loss": 2.4589,
      "step": 41480
    },
    {
      "epoch": 2.784403207946042,
      "grad_norm": 0.6638272404670715,
      "learning_rate": 2.6989795257522877e-06,
      "loss": 2.4619,
      "step": 41490
    },
    {
      "epoch": 2.785074326364887,
      "grad_norm": 0.6698318719863892,
      "learning_rate": 2.68228588259547e-06,
      "loss": 2.4363,
      "step": 41500
    },
    {
      "epoch": 2.785074326364887,
      "eval_bleu": 21.325903542957352,
      "eval_gen_len": 28.886,
      "eval_loss": 2.929719924926758,
      "eval_runtime": 61.1467,
      "eval_samples_per_second": 16.354,
      "eval_steps_per_second": 1.03,
      "step": 41500
    },
    {
      "epoch": 2.785745444783732,
      "grad_norm": 0.7190846800804138,
      "learning_rate": 2.665643324397393e-06,
      "loss": 2.4414,
      "step": 41510
    },
    {
      "epoch": 2.786416563202577,
      "grad_norm": 0.7858973741531372,
      "learning_rate": 2.6490518598942027e-06,
      "loss": 2.4075,
      "step": 41520
    },
    {
      "epoch": 2.787087681621422,
      "grad_norm": 0.8606404662132263,
      "learning_rate": 2.6325114977952647e-06,
      "loss": 2.4283,
      "step": 41530
    },
    {
      "epoch": 2.787758800040267,
      "grad_norm": 0.6504903435707092,
      "learning_rate": 2.616022246783112e-06,
      "loss": 2.4401,
      "step": 41540
    },
    {
      "epoch": 2.788429918459112,
      "grad_norm": 0.6385326981544495,
      "learning_rate": 2.5995841155134317e-06,
      "loss": 2.4436,
      "step": 41550
    },
    {
      "epoch": 2.788429918459112,
      "eval_bleu": 21.33416218858329,
      "eval_gen_len": 28.873,
      "eval_loss": 2.929560422897339,
      "eval_runtime": 61.1929,
      "eval_samples_per_second": 16.342,
      "eval_steps_per_second": 1.03,
      "step": 41550
    },
    {
      "epoch": 2.789101036877957,
      "grad_norm": 0.6971826553344727,
      "learning_rate": 2.5831971126150766e-06,
      "loss": 2.4256,
      "step": 41560
    },
    {
      "epoch": 2.7897721552968022,
      "grad_norm": 0.6570979952812195,
      "learning_rate": 2.5668612466901e-06,
      "loss": 2.4163,
      "step": 41570
    },
    {
      "epoch": 2.7904432737156473,
      "grad_norm": 0.6684661507606506,
      "learning_rate": 2.550576526313653e-06,
      "loss": 2.4006,
      "step": 41580
    },
    {
      "epoch": 2.7911143921344923,
      "grad_norm": 0.7398122549057007,
      "learning_rate": 2.5343429600340973e-06,
      "loss": 2.4336,
      "step": 41590
    },
    {
      "epoch": 2.7917855105533373,
      "grad_norm": 0.6870149970054626,
      "learning_rate": 2.518160556372906e-06,
      "loss": 2.4095,
      "step": 41600
    },
    {
      "epoch": 2.7917855105533373,
      "eval_bleu": 21.477618261273847,
      "eval_gen_len": 28.899,
      "eval_loss": 2.9295215606689453,
      "eval_runtime": 61.27,
      "eval_samples_per_second": 16.321,
      "eval_steps_per_second": 1.028,
      "step": 41600
    },
    {
      "epoch": 2.7924566289721824,
      "grad_norm": 0.639903724193573,
      "learning_rate": 2.502029323824684e-06,
      "loss": 2.4352,
      "step": 41610
    },
    {
      "epoch": 2.793127747391027,
      "grad_norm": 0.6807253360748291,
      "learning_rate": 2.485949270857224e-06,
      "loss": 2.4429,
      "step": 41620
    },
    {
      "epoch": 2.793798865809872,
      "grad_norm": 0.7403257489204407,
      "learning_rate": 2.469920405911408e-06,
      "loss": 2.4547,
      "step": 41630
    },
    {
      "epoch": 2.794469984228717,
      "grad_norm": 0.6989291906356812,
      "learning_rate": 2.453942737401249e-06,
      "loss": 2.4382,
      "step": 41640
    },
    {
      "epoch": 2.795141102647562,
      "grad_norm": 0.6720687747001648,
      "learning_rate": 2.438016273713917e-06,
      "loss": 2.4277,
      "step": 41650
    },
    {
      "epoch": 2.795141102647562,
      "eval_bleu": 21.39388953640493,
      "eval_gen_len": 28.919,
      "eval_loss": 2.9294943809509277,
      "eval_runtime": 60.8496,
      "eval_samples_per_second": 16.434,
      "eval_steps_per_second": 1.035,
      "step": 41650
    },
    {
      "epoch": 2.795812221066407,
      "grad_norm": 0.6643349528312683,
      "learning_rate": 2.4221410232096897e-06,
      "loss": 2.4569,
      "step": 41660
    },
    {
      "epoch": 2.796483339485252,
      "grad_norm": 0.6854714751243591,
      "learning_rate": 2.4063169942219465e-06,
      "loss": 2.4575,
      "step": 41670
    },
    {
      "epoch": 2.7971544579040972,
      "grad_norm": 0.6504641175270081,
      "learning_rate": 2.390544195057198e-06,
      "loss": 2.4625,
      "step": 41680
    },
    {
      "epoch": 2.7978255763229423,
      "grad_norm": 0.6904076337814331,
      "learning_rate": 2.3748226339950443e-06,
      "loss": 2.423,
      "step": 41690
    },
    {
      "epoch": 2.7984966947417873,
      "grad_norm": 0.6755260825157166,
      "learning_rate": 2.359152319288227e-06,
      "loss": 2.4164,
      "step": 41700
    },
    {
      "epoch": 2.7984966947417873,
      "eval_bleu": 21.465568497986446,
      "eval_gen_len": 28.919,
      "eval_loss": 2.929265260696411,
      "eval_runtime": 60.921,
      "eval_samples_per_second": 16.415,
      "eval_steps_per_second": 1.034,
      "step": 41700
    },
    {
      "epoch": 2.7991678131606323,
      "grad_norm": 0.7061607241630554,
      "learning_rate": 2.3435332591625225e-06,
      "loss": 2.4507,
      "step": 41710
    },
    {
      "epoch": 2.799838931579477,
      "grad_norm": 0.6921944618225098,
      "learning_rate": 2.327965461816872e-06,
      "loss": 2.4262,
      "step": 41720
    },
    {
      "epoch": 2.800510049998322,
      "grad_norm": 0.7361603379249573,
      "learning_rate": 2.3124489354232393e-06,
      "loss": 2.4784,
      "step": 41730
    },
    {
      "epoch": 2.801181168417167,
      "grad_norm": 0.7355163097381592,
      "learning_rate": 2.2969836881267414e-06,
      "loss": 2.4547,
      "step": 41740
    },
    {
      "epoch": 2.801852286836012,
      "grad_norm": 0.813297688961029,
      "learning_rate": 2.2815697280455295e-06,
      "loss": 2.4843,
      "step": 41750
    },
    {
      "epoch": 2.801852286836012,
      "eval_bleu": 21.158645073685896,
      "eval_gen_len": 28.903,
      "eval_loss": 2.9292521476745605,
      "eval_runtime": 60.9116,
      "eval_samples_per_second": 16.417,
      "eval_steps_per_second": 1.034,
      "step": 41750
    },
    {
      "epoch": 2.802523405254857,
      "grad_norm": 0.7164745926856995,
      "learning_rate": 2.266207063270864e-06,
      "loss": 2.4239,
      "step": 41760
    },
    {
      "epoch": 2.803194523673702,
      "grad_norm": 0.7012599110603333,
      "learning_rate": 2.2508957018670397e-06,
      "loss": 2.4332,
      "step": 41770
    },
    {
      "epoch": 2.803865642092547,
      "grad_norm": 0.6749821901321411,
      "learning_rate": 2.2356356518714704e-06,
      "loss": 2.3909,
      "step": 41780
    },
    {
      "epoch": 2.8045367605113922,
      "grad_norm": 0.721913754940033,
      "learning_rate": 2.220426921294594e-06,
      "loss": 2.4846,
      "step": 41790
    },
    {
      "epoch": 2.8052078789302373,
      "grad_norm": 0.7104518413543701,
      "learning_rate": 2.205269518119946e-06,
      "loss": 2.4635,
      "step": 41800
    },
    {
      "epoch": 2.8052078789302373,
      "eval_bleu": 21.229319546237164,
      "eval_gen_len": 28.905,
      "eval_loss": 2.9294612407684326,
      "eval_runtime": 61.9423,
      "eval_samples_per_second": 16.144,
      "eval_steps_per_second": 1.017,
      "step": 41800
    },
    {
      "epoch": 2.8058789973490823,
      "grad_norm": 0.735832929611206,
      "learning_rate": 2.1901634503040725e-06,
      "loss": 2.4241,
      "step": 41810
    },
    {
      "epoch": 2.8065501157679273,
      "grad_norm": 0.6633870601654053,
      "learning_rate": 2.175108725776598e-06,
      "loss": 2.4813,
      "step": 41820
    },
    {
      "epoch": 2.8072212341867724,
      "grad_norm": 0.6781332492828369,
      "learning_rate": 2.1601053524402003e-06,
      "loss": 2.4481,
      "step": 41830
    },
    {
      "epoch": 2.8078923526056174,
      "grad_norm": 0.701529324054718,
      "learning_rate": 2.1451533381706133e-06,
      "loss": 2.4684,
      "step": 41840
    },
    {
      "epoch": 2.8085634710244625,
      "grad_norm": 0.7238788604736328,
      "learning_rate": 2.1302526908165587e-06,
      "loss": 2.3879,
      "step": 41850
    },
    {
      "epoch": 2.8085634710244625,
      "eval_bleu": 21.288210564653856,
      "eval_gen_len": 28.905,
      "eval_loss": 2.929361581802368,
      "eval_runtime": 61.1732,
      "eval_samples_per_second": 16.347,
      "eval_steps_per_second": 1.03,
      "step": 41850
    },
    {
      "epoch": 2.8092345894433075,
      "grad_norm": 0.6919412016868591,
      "learning_rate": 2.1154034181998684e-06,
      "loss": 2.4252,
      "step": 41860
    },
    {
      "epoch": 2.8099057078621525,
      "grad_norm": 0.7703564763069153,
      "learning_rate": 2.100605528115329e-06,
      "loss": 2.4922,
      "step": 41870
    },
    {
      "epoch": 2.810576826280997,
      "grad_norm": 0.6755103468894958,
      "learning_rate": 2.0858590283308276e-06,
      "loss": 2.4567,
      "step": 41880
    },
    {
      "epoch": 2.811247944699842,
      "grad_norm": 0.611706554889679,
      "learning_rate": 2.071163926587216e-06,
      "loss": 2.4746,
      "step": 41890
    },
    {
      "epoch": 2.8119190631186872,
      "grad_norm": 0.6886367797851562,
      "learning_rate": 2.056520230598391e-06,
      "loss": 2.4593,
      "step": 41900
    },
    {
      "epoch": 2.8119190631186872,
      "eval_bleu": 21.410462905795093,
      "eval_gen_len": 28.881,
      "eval_loss": 2.9294347763061523,
      "eval_runtime": 61.4344,
      "eval_samples_per_second": 16.278,
      "eval_steps_per_second": 1.025,
      "step": 41900
    },
    {
      "epoch": 2.8125901815375323,
      "grad_norm": 0.6755106449127197,
      "learning_rate": 2.041927948051281e-06,
      "loss": 2.3999,
      "step": 41910
    },
    {
      "epoch": 2.8132612999563773,
      "grad_norm": 0.7128056287765503,
      "learning_rate": 2.027387086605781e-06,
      "loss": 2.3983,
      "step": 41920
    },
    {
      "epoch": 2.8139324183752223,
      "grad_norm": 0.6441894769668579,
      "learning_rate": 2.012897653894841e-06,
      "loss": 2.4206,
      "step": 41930
    },
    {
      "epoch": 2.8146035367940674,
      "grad_norm": 0.7418689131736755,
      "learning_rate": 1.9984596575243876e-06,
      "loss": 2.43,
      "step": 41940
    },
    {
      "epoch": 2.8152746552129124,
      "grad_norm": 0.7029356360435486,
      "learning_rate": 1.9840731050733585e-06,
      "loss": 2.4861,
      "step": 41950
    },
    {
      "epoch": 2.8152746552129124,
      "eval_bleu": 21.402101601235707,
      "eval_gen_len": 28.891,
      "eval_loss": 2.929661273956299,
      "eval_runtime": 61.6653,
      "eval_samples_per_second": 16.217,
      "eval_steps_per_second": 1.022,
      "step": 41950
    },
    {
      "epoch": 2.8159457736317575,
      "grad_norm": 0.7275124192237854,
      "learning_rate": 1.96973800409368e-06,
      "loss": 2.4781,
      "step": 41960
    },
    {
      "epoch": 2.816616892050602,
      "grad_norm": 0.6915429830551147,
      "learning_rate": 1.955454362110276e-06,
      "loss": 2.4218,
      "step": 41970
    },
    {
      "epoch": 2.817288010469447,
      "grad_norm": 0.7137858867645264,
      "learning_rate": 1.94122218662105e-06,
      "loss": 2.4265,
      "step": 41980
    },
    {
      "epoch": 2.817959128888292,
      "grad_norm": 0.7115549445152283,
      "learning_rate": 1.927041485096892e-06,
      "loss": 2.4914,
      "step": 41990
    },
    {
      "epoch": 2.818630247307137,
      "grad_norm": 0.6672629117965698,
      "learning_rate": 1.91291226498167e-06,
      "loss": 2.434,
      "step": 42000
    },
    {
      "epoch": 2.818630247307137,
      "eval_bleu": 21.24573937093883,
      "eval_gen_len": 28.945,
      "eval_loss": 2.9300875663757324,
      "eval_runtime": 62.0558,
      "eval_samples_per_second": 16.115,
      "eval_steps_per_second": 1.015,
      "step": 42000
    },
    {
      "epoch": 2.8193013657259822,
      "grad_norm": 0.6975756883621216,
      "learning_rate": 1.8988345336922507e-06,
      "loss": 2.4054,
      "step": 42010
    },
    {
      "epoch": 2.8199724841448273,
      "grad_norm": 0.698674738407135,
      "learning_rate": 1.8848082986184346e-06,
      "loss": 2.4237,
      "step": 42020
    },
    {
      "epoch": 2.8206436025636723,
      "grad_norm": 0.6941028833389282,
      "learning_rate": 1.8708335671230094e-06,
      "loss": 2.44,
      "step": 42030
    },
    {
      "epoch": 2.8213147209825173,
      "grad_norm": 0.6486998200416565,
      "learning_rate": 1.8569103465417292e-06,
      "loss": 2.4555,
      "step": 42040
    },
    {
      "epoch": 2.8219858394013624,
      "grad_norm": 0.7256139516830444,
      "learning_rate": 1.8430386441833259e-06,
      "loss": 2.418,
      "step": 42050
    },
    {
      "epoch": 2.8219858394013624,
      "eval_bleu": 21.42948250199791,
      "eval_gen_len": 28.9,
      "eval_loss": 2.9299869537353516,
      "eval_runtime": 61.7236,
      "eval_samples_per_second": 16.201,
      "eval_steps_per_second": 1.021,
      "step": 42050
    },
    {
      "epoch": 2.8226569578202074,
      "grad_norm": 0.7067945599555969,
      "learning_rate": 1.82921846732943e-06,
      "loss": 2.5127,
      "step": 42060
    },
    {
      "epoch": 2.8233280762390525,
      "grad_norm": 0.6617441177368164,
      "learning_rate": 1.815449823234694e-06,
      "loss": 2.4185,
      "step": 42070
    },
    {
      "epoch": 2.8239991946578975,
      "grad_norm": 0.6478785872459412,
      "learning_rate": 1.8017327191266808e-06,
      "loss": 2.4584,
      "step": 42080
    },
    {
      "epoch": 2.8246703130767425,
      "grad_norm": 0.6836657524108887,
      "learning_rate": 1.7880671622059086e-06,
      "loss": 2.4201,
      "step": 42090
    },
    {
      "epoch": 2.8253414314955876,
      "grad_norm": 0.665552020072937,
      "learning_rate": 1.774453159645817e-06,
      "loss": 2.3927,
      "step": 42100
    },
    {
      "epoch": 2.8253414314955876,
      "eval_bleu": 21.324797213925148,
      "eval_gen_len": 28.846,
      "eval_loss": 2.9300715923309326,
      "eval_runtime": 61.6635,
      "eval_samples_per_second": 16.217,
      "eval_steps_per_second": 1.022,
      "step": 42100
    },
    {
      "epoch": 2.8260125499144326,
      "grad_norm": 0.7092716693878174,
      "learning_rate": 1.7608907185928114e-06,
      "loss": 2.4581,
      "step": 42110
    },
    {
      "epoch": 2.8266836683332777,
      "grad_norm": 0.6202828288078308,
      "learning_rate": 1.7473798461662194e-06,
      "loss": 2.4547,
      "step": 42120
    },
    {
      "epoch": 2.8273547867521223,
      "grad_norm": 0.800791323184967,
      "learning_rate": 1.733920549458312e-06,
      "loss": 2.5069,
      "step": 42130
    },
    {
      "epoch": 2.8280259051709673,
      "grad_norm": 0.7180521488189697,
      "learning_rate": 1.7205128355342493e-06,
      "loss": 2.4516,
      "step": 42140
    },
    {
      "epoch": 2.8286970235898123,
      "grad_norm": 0.6818280816078186,
      "learning_rate": 1.7071567114321563e-06,
      "loss": 2.4668,
      "step": 42150
    },
    {
      "epoch": 2.8286970235898123,
      "eval_bleu": 21.44346828109748,
      "eval_gen_len": 28.878,
      "eval_loss": 2.929868459701538,
      "eval_runtime": 59.7059,
      "eval_samples_per_second": 16.749,
      "eval_steps_per_second": 1.055,
      "step": 42150
    },
    {
      "epoch": 2.8293681420086574,
      "grad_norm": 0.7395986318588257,
      "learning_rate": 1.6938521841630583e-06,
      "loss": 2.4445,
      "step": 42160
    },
    {
      "epoch": 2.8300392604275024,
      "grad_norm": 0.6210753917694092,
      "learning_rate": 1.6805992607108912e-06,
      "loss": 2.4434,
      "step": 42170
    },
    {
      "epoch": 2.8307103788463475,
      "grad_norm": 0.6876033544540405,
      "learning_rate": 1.6673979480325007e-06,
      "loss": 2.499,
      "step": 42180
    },
    {
      "epoch": 2.8313814972651925,
      "grad_norm": 0.7176679372787476,
      "learning_rate": 1.6542482530576664e-06,
      "loss": 2.456,
      "step": 42190
    },
    {
      "epoch": 2.8320526156840375,
      "grad_norm": 0.7186050415039062,
      "learning_rate": 1.6411501826890441e-06,
      "loss": 2.4282,
      "step": 42200
    },
    {
      "epoch": 2.8320526156840375,
      "eval_bleu": 21.25195137531554,
      "eval_gen_len": 28.917,
      "eval_loss": 2.929986000061035,
      "eval_runtime": 62.8386,
      "eval_samples_per_second": 15.914,
      "eval_steps_per_second": 1.003,
      "step": 42200
    },
    {
      "epoch": 2.8327237341028826,
      "grad_norm": 0.7122898697853088,
      "learning_rate": 1.6281037438021896e-06,
      "loss": 2.4273,
      "step": 42210
    },
    {
      "epoch": 2.8333948525217276,
      "grad_norm": 0.6751649975776672,
      "learning_rate": 1.6151089432455802e-06,
      "loss": 2.3967,
      "step": 42220
    },
    {
      "epoch": 2.834065970940572,
      "grad_norm": 0.696079432964325,
      "learning_rate": 1.6021657878405705e-06,
      "loss": 2.4209,
      "step": 42230
    },
    {
      "epoch": 2.8347370893594173,
      "grad_norm": 0.6999086141586304,
      "learning_rate": 1.5892742843814146e-06,
      "loss": 2.4509,
      "step": 42240
    },
    {
      "epoch": 2.8354082077782623,
      "grad_norm": 0.688946008682251,
      "learning_rate": 1.5764344396352327e-06,
      "loss": 2.4266,
      "step": 42250
    },
    {
      "epoch": 2.8354082077782623,
      "eval_bleu": 21.284423450317313,
      "eval_gen_len": 28.88,
      "eval_loss": 2.929898262023926,
      "eval_runtime": 62.8848,
      "eval_samples_per_second": 15.902,
      "eval_steps_per_second": 1.002,
      "step": 42250
    },
    {
      "epoch": 2.8360793261971073,
      "grad_norm": 0.7040532827377319,
      "learning_rate": 1.5636462603420442e-06,
      "loss": 2.4134,
      "step": 42260
    },
    {
      "epoch": 2.8367504446159524,
      "grad_norm": 0.7088704109191895,
      "learning_rate": 1.5509097532147355e-06,
      "loss": 2.4425,
      "step": 42270
    },
    {
      "epoch": 2.8374215630347974,
      "grad_norm": 0.7020125985145569,
      "learning_rate": 1.5382249249391024e-06,
      "loss": 2.4585,
      "step": 42280
    },
    {
      "epoch": 2.8380926814536425,
      "grad_norm": 0.7389054894447327,
      "learning_rate": 1.525591782173763e-06,
      "loss": 2.4746,
      "step": 42290
    },
    {
      "epoch": 2.8387637998724875,
      "grad_norm": 0.7060653567314148,
      "learning_rate": 1.5130103315502352e-06,
      "loss": 2.4426,
      "step": 42300
    },
    {
      "epoch": 2.8387637998724875,
      "eval_bleu": 21.25346357324023,
      "eval_gen_len": 28.912,
      "eval_loss": 2.929851770401001,
      "eval_runtime": 62.7613,
      "eval_samples_per_second": 15.933,
      "eval_steps_per_second": 1.004,
      "step": 42300
    },
    {
      "epoch": 2.8394349182913325,
      "grad_norm": 0.708771824836731,
      "learning_rate": 1.5004805796729027e-06,
      "loss": 2.4865,
      "step": 42310
    },
    {
      "epoch": 2.8401060367101776,
      "grad_norm": 0.7537514567375183,
      "learning_rate": 1.488002533119015e-06,
      "loss": 2.4327,
      "step": 42320
    },
    {
      "epoch": 2.8407771551290226,
      "grad_norm": 0.680620014667511,
      "learning_rate": 1.475576198438644e-06,
      "loss": 2.4488,
      "step": 42330
    },
    {
      "epoch": 2.8414482735478677,
      "grad_norm": 0.6874950528144836,
      "learning_rate": 1.4632015821547606e-06,
      "loss": 2.4025,
      "step": 42340
    },
    {
      "epoch": 2.8421193919667127,
      "grad_norm": 0.5794357061386108,
      "learning_rate": 1.4508786907631466e-06,
      "loss": 2.445,
      "step": 42350
    },
    {
      "epoch": 2.8421193919667127,
      "eval_bleu": 21.38971076467496,
      "eval_gen_len": 28.893,
      "eval_loss": 2.92966628074646,
      "eval_runtime": 62.8851,
      "eval_samples_per_second": 15.902,
      "eval_steps_per_second": 1.002,
      "step": 42350
    },
    {
      "epoch": 2.8427905103855577,
      "grad_norm": 0.6850842833518982,
      "learning_rate": 1.438607530732483e-06,
      "loss": 2.416,
      "step": 42360
    },
    {
      "epoch": 2.843461628804403,
      "grad_norm": 0.6344260573387146,
      "learning_rate": 1.4263881085042396e-06,
      "loss": 2.4087,
      "step": 42370
    },
    {
      "epoch": 2.8441327472232474,
      "grad_norm": 0.6972166895866394,
      "learning_rate": 1.4142204304927743e-06,
      "loss": 2.4354,
      "step": 42380
    },
    {
      "epoch": 2.8448038656420924,
      "grad_norm": 0.7249413728713989,
      "learning_rate": 1.4021045030852441e-06,
      "loss": 2.425,
      "step": 42390
    },
    {
      "epoch": 2.8454749840609375,
      "grad_norm": 0.6818867325782776,
      "learning_rate": 1.3900403326416844e-06,
      "loss": 2.467,
      "step": 42400
    },
    {
      "epoch": 2.8454749840609375,
      "eval_bleu": 21.441131833550404,
      "eval_gen_len": 28.889,
      "eval_loss": 2.929611921310425,
      "eval_runtime": 63.9437,
      "eval_samples_per_second": 15.639,
      "eval_steps_per_second": 0.985,
      "step": 42400
    },
    {
      "epoch": 2.8461461024797825,
      "grad_norm": 0.674278736114502,
      "learning_rate": 1.378027925494918e-06,
      "loss": 2.409,
      "step": 42410
    },
    {
      "epoch": 2.8468172208986275,
      "grad_norm": 0.6991996169090271,
      "learning_rate": 1.366067287950612e-06,
      "loss": 2.4436,
      "step": 42420
    },
    {
      "epoch": 2.8474883393174726,
      "grad_norm": 0.6368017792701721,
      "learning_rate": 1.3541584262872774e-06,
      "loss": 2.4443,
      "step": 42430
    },
    {
      "epoch": 2.8481594577363176,
      "grad_norm": 0.6682446599006653,
      "learning_rate": 1.342301346756214e-06,
      "loss": 2.4429,
      "step": 42440
    },
    {
      "epoch": 2.8488305761551627,
      "grad_norm": 0.6910144090652466,
      "learning_rate": 1.3304960555815538e-06,
      "loss": 2.4071,
      "step": 42450
    },
    {
      "epoch": 2.8488305761551627,
      "eval_bleu": 21.494484668457353,
      "eval_gen_len": 28.891,
      "eval_loss": 2.929365873336792,
      "eval_runtime": 62.2034,
      "eval_samples_per_second": 16.076,
      "eval_steps_per_second": 1.013,
      "step": 42450
    },
    {
      "epoch": 2.8495016945740077,
      "grad_norm": 0.6802722811698914,
      "learning_rate": 1.318742558960251e-06,
      "loss": 2.4977,
      "step": 42460
    },
    {
      "epoch": 2.8501728129928527,
      "grad_norm": 0.7476226687431335,
      "learning_rate": 1.30704086306207e-06,
      "loss": 2.473,
      "step": 42470
    },
    {
      "epoch": 2.8508439314116973,
      "grad_norm": 0.7101794481277466,
      "learning_rate": 1.2953909740295756e-06,
      "loss": 2.4767,
      "step": 42480
    },
    {
      "epoch": 2.8515150498305424,
      "grad_norm": 0.7340958118438721,
      "learning_rate": 1.283792897978131e-06,
      "loss": 2.436,
      "step": 42490
    },
    {
      "epoch": 2.8521861682493874,
      "grad_norm": 0.6498696208000183,
      "learning_rate": 1.2722466409959111e-06,
      "loss": 2.4504,
      "step": 42500
    },
    {
      "epoch": 2.8521861682493874,
      "eval_bleu": 21.29178105432782,
      "eval_gen_len": 28.915,
      "eval_loss": 2.929257392883301,
      "eval_runtime": 63.4952,
      "eval_samples_per_second": 15.749,
      "eval_steps_per_second": 0.992,
      "step": 42500
    },
    {
      "epoch": 2.8528572866682325,
      "grad_norm": 0.6891051530838013,
      "learning_rate": 1.2607522091439118e-06,
      "loss": 2.4359,
      "step": 42510
    },
    {
      "epoch": 2.8535284050870775,
      "grad_norm": 0.6912283897399902,
      "learning_rate": 1.2493096084558841e-06,
      "loss": 2.4813,
      "step": 42520
    },
    {
      "epoch": 2.8541995235059225,
      "grad_norm": 0.7682204246520996,
      "learning_rate": 1.2379188449383905e-06,
      "loss": 2.4519,
      "step": 42530
    },
    {
      "epoch": 2.8548706419247676,
      "grad_norm": 0.6815598011016846,
      "learning_rate": 1.2265799245707698e-06,
      "loss": 2.4562,
      "step": 42540
    },
    {
      "epoch": 2.8555417603436126,
      "grad_norm": 0.6744992136955261,
      "learning_rate": 1.2152928533051833e-06,
      "loss": 2.4257,
      "step": 42550
    },
    {
      "epoch": 2.8555417603436126,
      "eval_bleu": 21.41176056867958,
      "eval_gen_len": 28.932,
      "eval_loss": 2.9289603233337402,
      "eval_runtime": 63.5024,
      "eval_samples_per_second": 15.747,
      "eval_steps_per_second": 0.992,
      "step": 42550
    },
    {
      "epoch": 2.8562128787624577,
      "grad_norm": 0.7009308338165283,
      "learning_rate": 1.2040576370665247e-06,
      "loss": 2.4822,
      "step": 42560
    },
    {
      "epoch": 2.8568839971813027,
      "grad_norm": 0.7440459728240967,
      "learning_rate": 1.1928742817525096e-06,
      "loss": 2.4541,
      "step": 42570
    },
    {
      "epoch": 2.8575551156001477,
      "grad_norm": 0.6103371381759644,
      "learning_rate": 1.1817427932335979e-06,
      "loss": 2.4534,
      "step": 42580
    },
    {
      "epoch": 2.858226234018993,
      "grad_norm": 0.7289717197418213,
      "learning_rate": 1.1706631773530707e-06,
      "loss": 2.4432,
      "step": 42590
    },
    {
      "epoch": 2.858897352437838,
      "grad_norm": 0.6834262609481812,
      "learning_rate": 1.1596354399269094e-06,
      "loss": 2.4258,
      "step": 42600
    },
    {
      "epoch": 2.858897352437838,
      "eval_bleu": 21.308047511187056,
      "eval_gen_len": 28.915,
      "eval_loss": 2.9290146827697754,
      "eval_runtime": 62.8566,
      "eval_samples_per_second": 15.909,
      "eval_steps_per_second": 1.002,
      "step": 42600
    },
    {
      "epoch": 2.859568470856683,
      "grad_norm": 0.6815330386161804,
      "learning_rate": 1.1486595867439277e-06,
      "loss": 2.4779,
      "step": 42610
    },
    {
      "epoch": 2.860239589275528,
      "grad_norm": 0.6667132377624512,
      "learning_rate": 1.1377356235656612e-06,
      "loss": 2.4819,
      "step": 42620
    },
    {
      "epoch": 2.860910707694373,
      "grad_norm": 0.6691915988922119,
      "learning_rate": 1.126863556126423e-06,
      "loss": 2.4549,
      "step": 42630
    },
    {
      "epoch": 2.8615818261132175,
      "grad_norm": 0.6600823402404785,
      "learning_rate": 1.1160433901332923e-06,
      "loss": 2.4173,
      "step": 42640
    },
    {
      "epoch": 2.8622529445320626,
      "grad_norm": 0.6796316504478455,
      "learning_rate": 1.1052751312660926e-06,
      "loss": 2.4805,
      "step": 42650
    },
    {
      "epoch": 2.8622529445320626,
      "eval_bleu": 21.464767216975844,
      "eval_gen_len": 28.904,
      "eval_loss": 2.9289710521698,
      "eval_runtime": 62.7029,
      "eval_samples_per_second": 15.948,
      "eval_steps_per_second": 1.005,
      "step": 42650
    },
    {
      "epoch": 2.8629240629509076,
      "grad_norm": 0.6952703595161438,
      "learning_rate": 1.094558785177402e-06,
      "loss": 2.4321,
      "step": 42660
    },
    {
      "epoch": 2.8635951813697527,
      "grad_norm": 0.6185373067855835,
      "learning_rate": 1.0838943574925542e-06,
      "loss": 2.4846,
      "step": 42670
    },
    {
      "epoch": 2.8642662997885977,
      "grad_norm": 0.744574785232544,
      "learning_rate": 1.0732818538096046e-06,
      "loss": 2.438,
      "step": 42680
    },
    {
      "epoch": 2.8649374182074427,
      "grad_norm": 0.6710283160209656,
      "learning_rate": 1.062721279699408e-06,
      "loss": 2.4673,
      "step": 42690
    },
    {
      "epoch": 2.865608536626288,
      "grad_norm": 0.6718384623527527,
      "learning_rate": 1.0522126407054854e-06,
      "loss": 2.4133,
      "step": 42700
    },
    {
      "epoch": 2.865608536626288,
      "eval_bleu": 21.31178492168211,
      "eval_gen_len": 28.922,
      "eval_loss": 2.929133176803589,
      "eval_runtime": 63.1858,
      "eval_samples_per_second": 15.826,
      "eval_steps_per_second": 0.997,
      "step": 42700
    },
    {
      "epoch": 2.866279655045133,
      "grad_norm": 0.6976726651191711,
      "learning_rate": 1.0417559423441581e-06,
      "loss": 2.4565,
      "step": 42710
    },
    {
      "epoch": 2.866950773463978,
      "grad_norm": 0.6958750486373901,
      "learning_rate": 1.031351190104446e-06,
      "loss": 2.411,
      "step": 42720
    },
    {
      "epoch": 2.8676218918828225,
      "grad_norm": 0.7068229913711548,
      "learning_rate": 1.0209983894481245e-06,
      "loss": 2.4389,
      "step": 42730
    },
    {
      "epoch": 2.8682930103016675,
      "grad_norm": 0.6223976612091064,
      "learning_rate": 1.0106975458096578e-06,
      "loss": 2.3838,
      "step": 42740
    },
    {
      "epoch": 2.8689641287205125,
      "grad_norm": 0.6760984063148499,
      "learning_rate": 1.0004486645963096e-06,
      "loss": 2.4251,
      "step": 42750
    },
    {
      "epoch": 2.8689641287205125,
      "eval_bleu": 21.39986812416763,
      "eval_gen_len": 28.886,
      "eval_loss": 2.929332733154297,
      "eval_runtime": 62.9703,
      "eval_samples_per_second": 15.881,
      "eval_steps_per_second": 1.0,
      "step": 42750
    },
    {
      "epoch": 2.8696352471393576,
      "grad_norm": 0.6692909002304077,
      "learning_rate": 9.902517511879762e-07,
      "loss": 2.4465,
      "step": 42760
    },
    {
      "epoch": 2.8703063655582026,
      "grad_norm": 0.6279687285423279,
      "learning_rate": 9.801068109373534e-07,
      "loss": 2.4638,
      "step": 42770
    },
    {
      "epoch": 2.8709774839770477,
      "grad_norm": 0.7054781913757324,
      "learning_rate": 9.70013849169804e-07,
      "loss": 2.4439,
      "step": 42780
    },
    {
      "epoch": 2.8716486023958927,
      "grad_norm": 0.7020426392555237,
      "learning_rate": 9.599728711834344e-07,
      "loss": 2.4515,
      "step": 42790
    },
    {
      "epoch": 2.8723197208147377,
      "grad_norm": 0.7349759340286255,
      "learning_rate": 9.499838822490503e-07,
      "loss": 2.5097,
      "step": 42800
    },
    {
      "epoch": 2.8723197208147377,
      "eval_bleu": 21.492712754394415,
      "eval_gen_len": 28.917,
      "eval_loss": 2.9291820526123047,
      "eval_runtime": 62.6913,
      "eval_samples_per_second": 15.951,
      "eval_steps_per_second": 1.005,
      "step": 42800
    },
    {
      "epoch": 2.872990839233583,
      "grad_norm": 0.7100144624710083,
      "learning_rate": 9.400468876101465e-07,
      "loss": 2.4338,
      "step": 42810
    },
    {
      "epoch": 2.873661957652428,
      "grad_norm": 0.6609154939651489,
      "learning_rate": 9.301618924829835e-07,
      "loss": 2.465,
      "step": 42820
    },
    {
      "epoch": 2.874333076071273,
      "grad_norm": 0.7037328481674194,
      "learning_rate": 9.203289020564554e-07,
      "loss": 2.4717,
      "step": 42830
    },
    {
      "epoch": 2.875004194490118,
      "grad_norm": 0.7021756768226624,
      "learning_rate": 9.10547921492222e-07,
      "loss": 2.4325,
      "step": 42840
    },
    {
      "epoch": 2.875675312908963,
      "grad_norm": 0.7047225832939148,
      "learning_rate": 9.008189559245761e-07,
      "loss": 2.4361,
      "step": 42850
    },
    {
      "epoch": 2.875675312908963,
      "eval_bleu": 21.329393788937555,
      "eval_gen_len": 28.899,
      "eval_loss": 2.9292800426483154,
      "eval_runtime": 62.5083,
      "eval_samples_per_second": 15.998,
      "eval_steps_per_second": 1.008,
      "step": 42850
    },
    {
      "epoch": 2.876346431327808,
      "grad_norm": 0.7154741287231445,
      "learning_rate": 8.911420104605772e-07,
      "loss": 2.4327,
      "step": 42860
    },
    {
      "epoch": 2.877017549746653,
      "grad_norm": 0.6753492951393127,
      "learning_rate": 8.815170901799174e-07,
      "loss": 2.4466,
      "step": 42870
    },
    {
      "epoch": 2.877688668165498,
      "grad_norm": 0.7526668310165405,
      "learning_rate": 8.719442001350109e-07,
      "loss": 2.4309,
      "step": 42880
    },
    {
      "epoch": 2.8783597865843427,
      "grad_norm": 0.669527530670166,
      "learning_rate": 8.624233453509378e-07,
      "loss": 2.4112,
      "step": 42890
    },
    {
      "epoch": 2.8790309050031877,
      "grad_norm": 0.738974928855896,
      "learning_rate": 8.529545308255005e-07,
      "loss": 2.4255,
      "step": 42900
    },
    {
      "epoch": 2.8790309050031877,
      "eval_bleu": 21.32667330954883,
      "eval_gen_len": 28.927,
      "eval_loss": 2.929218053817749,
      "eval_runtime": 62.7213,
      "eval_samples_per_second": 15.944,
      "eval_steps_per_second": 1.004,
      "step": 42900
    },
    {
      "epoch": 2.8797020234220327,
      "grad_norm": 0.665951669216156,
      "learning_rate": 8.435377615291451e-07,
      "loss": 2.4597,
      "step": 42910
    },
    {
      "epoch": 2.880373141840878,
      "grad_norm": 0.7174164652824402,
      "learning_rate": 8.341730424050287e-07,
      "loss": 2.4293,
      "step": 42920
    },
    {
      "epoch": 2.881044260259723,
      "grad_norm": 0.6756194829940796,
      "learning_rate": 8.248603783689524e-07,
      "loss": 2.4274,
      "step": 42930
    },
    {
      "epoch": 2.881715378678568,
      "grad_norm": 0.6613634824752808,
      "learning_rate": 8.155997743094279e-07,
      "loss": 2.4316,
      "step": 42940
    },
    {
      "epoch": 2.882386497097413,
      "grad_norm": 0.6827900409698486,
      "learning_rate": 8.063912350876001e-07,
      "loss": 2.4597,
      "step": 42950
    },
    {
      "epoch": 2.882386497097413,
      "eval_bleu": 21.50925343789755,
      "eval_gen_len": 28.914,
      "eval_loss": 2.9291179180145264,
      "eval_runtime": 62.3217,
      "eval_samples_per_second": 16.046,
      "eval_steps_per_second": 1.011,
      "step": 42950
    },
    {
      "epoch": 2.883057615516258,
      "grad_norm": 0.6884108185768127,
      "learning_rate": 7.972347655373246e-07,
      "loss": 2.4642,
      "step": 42960
    },
    {
      "epoch": 2.883728733935103,
      "grad_norm": 0.6690897345542908,
      "learning_rate": 7.881303704651011e-07,
      "loss": 2.4459,
      "step": 42970
    },
    {
      "epoch": 2.8843998523539476,
      "grad_norm": 0.7222947478294373,
      "learning_rate": 7.790780546500842e-07,
      "loss": 2.4593,
      "step": 42980
    },
    {
      "epoch": 2.8850709707727926,
      "grad_norm": 0.750697672367096,
      "learning_rate": 7.700778228441063e-07,
      "loss": 2.4385,
      "step": 42990
    },
    {
      "epoch": 2.8857420891916377,
      "grad_norm": 0.6918298602104187,
      "learning_rate": 7.611296797716772e-07,
      "loss": 2.4756,
      "step": 43000
    },
    {
      "epoch": 2.8857420891916377,
      "eval_bleu": 21.363977689667504,
      "eval_gen_len": 28.901,
      "eval_loss": 2.9289894104003906,
      "eval_runtime": 62.0178,
      "eval_samples_per_second": 16.124,
      "eval_steps_per_second": 1.016,
      "step": 43000
    },
    {
      "epoch": 2.8864132076104827,
      "grad_norm": 0.7260149121284485,
      "learning_rate": 7.52233630129906e-07,
      "loss": 2.4596,
      "step": 43010
    },
    {
      "epoch": 2.8870843260293277,
      "grad_norm": 0.6973267197608948,
      "learning_rate": 7.433896785886352e-07,
      "loss": 2.4352,
      "step": 43020
    },
    {
      "epoch": 2.887755444448173,
      "grad_norm": 0.6690244674682617,
      "learning_rate": 7.345978297902845e-07,
      "loss": 2.4518,
      "step": 43030
    },
    {
      "epoch": 2.888426562867018,
      "grad_norm": 0.7402001619338989,
      "learning_rate": 7.258580883499733e-07,
      "loss": 2.4558,
      "step": 43040
    },
    {
      "epoch": 2.889097681285863,
      "grad_norm": 0.6385761499404907,
      "learning_rate": 7.17170458855454e-07,
      "loss": 2.4527,
      "step": 43050
    },
    {
      "epoch": 2.889097681285863,
      "eval_bleu": 21.463851957633302,
      "eval_gen_len": 28.901,
      "eval_loss": 2.929133653640747,
      "eval_runtime": 62.7678,
      "eval_samples_per_second": 15.932,
      "eval_steps_per_second": 1.004,
      "step": 43050
    },
    {
      "epoch": 2.889768799704708,
      "grad_norm": 0.6562456488609314,
      "learning_rate": 7.085349458671008e-07,
      "loss": 2.4684,
      "step": 43060
    },
    {
      "epoch": 2.890439918123553,
      "grad_norm": 0.6317511796951294,
      "learning_rate": 6.999515539179768e-07,
      "loss": 2.4582,
      "step": 43070
    },
    {
      "epoch": 2.891111036542398,
      "grad_norm": 0.6884501576423645,
      "learning_rate": 6.914202875137443e-07,
      "loss": 2.4702,
      "step": 43080
    },
    {
      "epoch": 2.891782154961243,
      "grad_norm": 0.7422194480895996,
      "learning_rate": 6.829411511327211e-07,
      "loss": 2.4618,
      "step": 43090
    },
    {
      "epoch": 2.892453273380088,
      "grad_norm": 0.6943605542182922,
      "learning_rate": 6.745141492258467e-07,
      "loss": 2.457,
      "step": 43100
    },
    {
      "epoch": 2.892453273380088,
      "eval_bleu": 21.53461293464718,
      "eval_gen_len": 28.903,
      "eval_loss": 2.929136276245117,
      "eval_runtime": 62.6381,
      "eval_samples_per_second": 15.965,
      "eval_steps_per_second": 1.006,
      "step": 43100
    },
    {
      "epoch": 2.893124391798933,
      "grad_norm": 0.6606643199920654,
      "learning_rate": 6.661392862167271e-07,
      "loss": 2.4699,
      "step": 43110
    },
    {
      "epoch": 2.893795510217778,
      "grad_norm": 0.6889480352401733,
      "learning_rate": 6.578165665015678e-07,
      "loss": 2.5028,
      "step": 43120
    },
    {
      "epoch": 2.894466628636623,
      "grad_norm": 0.7135506868362427,
      "learning_rate": 6.495459944492077e-07,
      "loss": 2.4224,
      "step": 43130
    },
    {
      "epoch": 2.895137747055468,
      "grad_norm": 0.6559046506881714,
      "learning_rate": 6.413275744011182e-07,
      "loss": 2.4165,
      "step": 43140
    },
    {
      "epoch": 2.895808865474313,
      "grad_norm": 0.7295761108398438,
      "learning_rate": 6.331613106713929e-07,
      "loss": 2.487,
      "step": 43150
    },
    {
      "epoch": 2.895808865474313,
      "eval_bleu": 21.357866073423242,
      "eval_gen_len": 28.881,
      "eval_loss": 2.929030418395996,
      "eval_runtime": 63.1817,
      "eval_samples_per_second": 15.827,
      "eval_steps_per_second": 0.997,
      "step": 43150
    },
    {
      "epoch": 2.896479983893158,
      "grad_norm": 0.7678261995315552,
      "learning_rate": 6.250472075467361e-07,
      "loss": 2.5053,
      "step": 43160
    },
    {
      "epoch": 2.897151102312003,
      "grad_norm": 0.6894831657409668,
      "learning_rate": 6.169852692864963e-07,
      "loss": 2.4541,
      "step": 43170
    },
    {
      "epoch": 2.897822220730848,
      "grad_norm": 0.6535950303077698,
      "learning_rate": 6.089755001226105e-07,
      "loss": 2.4526,
      "step": 43180
    },
    {
      "epoch": 2.898493339149693,
      "grad_norm": 0.6727045774459839,
      "learning_rate": 6.010179042596709e-07,
      "loss": 2.4386,
      "step": 43190
    },
    {
      "epoch": 2.899164457568538,
      "grad_norm": 0.70469731092453,
      "learning_rate": 5.931124858748138e-07,
      "loss": 2.4815,
      "step": 43200
    },
    {
      "epoch": 2.899164457568538,
      "eval_bleu": 21.45689387568316,
      "eval_gen_len": 28.875,
      "eval_loss": 2.929086208343506,
      "eval_runtime": 63.1506,
      "eval_samples_per_second": 15.835,
      "eval_steps_per_second": 0.998,
      "step": 43200
    },
    {
      "epoch": 2.899835575987383,
      "grad_norm": 0.5990979075431824,
      "learning_rate": 5.852592491178643e-07,
      "loss": 2.4074,
      "step": 43210
    },
    {
      "epoch": 2.900506694406228,
      "grad_norm": 0.7057520747184753,
      "learning_rate": 5.774581981112137e-07,
      "loss": 2.4394,
      "step": 43220
    },
    {
      "epoch": 2.901177812825073,
      "grad_norm": 0.721258819103241,
      "learning_rate": 5.697093369498529e-07,
      "loss": 2.414,
      "step": 43230
    },
    {
      "epoch": 2.9018489312439177,
      "grad_norm": 0.706938624382019,
      "learning_rate": 5.620126697013839e-07,
      "loss": 2.4601,
      "step": 43240
    },
    {
      "epoch": 2.902520049662763,
      "grad_norm": 0.6407327055931091,
      "learning_rate": 5.543682004060413e-07,
      "loss": 2.4538,
      "step": 43250
    },
    {
      "epoch": 2.902520049662763,
      "eval_bleu": 21.349348723863876,
      "eval_gen_len": 28.917,
      "eval_loss": 2.9290716648101807,
      "eval_runtime": 62.9998,
      "eval_samples_per_second": 15.873,
      "eval_steps_per_second": 1.0,
      "step": 43250
    },
    {
      "epoch": 2.903191168081608,
      "grad_norm": 0.7604641318321228,
      "learning_rate": 5.467759330766042e-07,
      "loss": 2.4326,
      "step": 43260
    },
    {
      "epoch": 2.903862286500453,
      "grad_norm": 0.7021493911743164,
      "learning_rate": 5.392358716985068e-07,
      "loss": 2.4153,
      "step": 43270
    },
    {
      "epoch": 2.904533404919298,
      "grad_norm": 0.6568261981010437,
      "learning_rate": 5.317480202297387e-07,
      "loss": 2.4592,
      "step": 43280
    },
    {
      "epoch": 2.905204523338143,
      "grad_norm": 0.6763070821762085,
      "learning_rate": 5.243123826009e-07,
      "loss": 2.4749,
      "step": 43290
    },
    {
      "epoch": 2.905875641756988,
      "grad_norm": 0.5980404615402222,
      "learning_rate": 5.169289627151574e-07,
      "loss": 2.3981,
      "step": 43300
    },
    {
      "epoch": 2.905875641756988,
      "eval_bleu": 21.447487624954558,
      "eval_gen_len": 28.88,
      "eval_loss": 2.9289677143096924,
      "eval_runtime": 62.895,
      "eval_samples_per_second": 15.9,
      "eval_steps_per_second": 1.002,
      "step": 43300
    },
    {
      "epoch": 2.906546760175833,
      "grad_norm": 0.6254076361656189,
      "learning_rate": 5.095977644483218e-07,
      "loss": 2.4409,
      "step": 43310
    },
    {
      "epoch": 2.907217878594678,
      "grad_norm": 0.6935065388679504,
      "learning_rate": 5.023187916487259e-07,
      "loss": 2.4369,
      "step": 43320
    },
    {
      "epoch": 2.907888997013523,
      "grad_norm": 0.7010626196861267,
      "learning_rate": 4.950920481373467e-07,
      "loss": 2.3808,
      "step": 43330
    },
    {
      "epoch": 2.908560115432368,
      "grad_norm": 0.7159996628761292,
      "learning_rate": 4.879175377076828e-07,
      "loss": 2.4892,
      "step": 43340
    },
    {
      "epoch": 2.909231233851213,
      "grad_norm": 0.7228105664253235,
      "learning_rate": 4.807952641258772e-07,
      "loss": 2.4559,
      "step": 43350
    },
    {
      "epoch": 2.909231233851213,
      "eval_bleu": 21.45923382857714,
      "eval_gen_len": 28.903,
      "eval_loss": 2.928942918777466,
      "eval_runtime": 63.3339,
      "eval_samples_per_second": 15.789,
      "eval_steps_per_second": 0.995,
      "step": 43350
    },
    {
      "epoch": 2.9099023522700582,
      "grad_norm": 0.6386802196502686,
      "learning_rate": 4.737252311306173e-07,
      "loss": 2.4666,
      "step": 43360
    },
    {
      "epoch": 2.9105734706889033,
      "grad_norm": 0.6808273792266846,
      "learning_rate": 4.6670744243315636e-07,
      "loss": 2.4779,
      "step": 43370
    },
    {
      "epoch": 2.9112445891077483,
      "grad_norm": 0.6949639320373535,
      "learning_rate": 4.5974190171735874e-07,
      "loss": 2.4115,
      "step": 43380
    },
    {
      "epoch": 2.9119157075265933,
      "grad_norm": 0.7574481964111328,
      "learning_rate": 4.5282861263963307e-07,
      "loss": 2.4352,
      "step": 43390
    },
    {
      "epoch": 2.912586825945438,
      "grad_norm": 0.6453413963317871,
      "learning_rate": 4.4596757882897634e-07,
      "loss": 2.4828,
      "step": 43400
    },
    {
      "epoch": 2.912586825945438,
      "eval_bleu": 21.405630426389823,
      "eval_gen_len": 28.909,
      "eval_loss": 2.9290146827697754,
      "eval_runtime": 63.0805,
      "eval_samples_per_second": 15.853,
      "eval_steps_per_second": 0.999,
      "step": 43400
    },
    {
      "epoch": 2.913257944364283,
      "grad_norm": 0.7416922450065613,
      "learning_rate": 4.391588038869521e-07,
      "loss": 2.4799,
      "step": 43410
    },
    {
      "epoch": 2.913929062783128,
      "grad_norm": 0.7525109052658081,
      "learning_rate": 4.3240229138767907e-07,
      "loss": 2.4772,
      "step": 43420
    },
    {
      "epoch": 2.914600181201973,
      "grad_norm": 0.6786022186279297,
      "learning_rate": 4.2569804487785357e-07,
      "loss": 2.4523,
      "step": 43430
    },
    {
      "epoch": 2.915271299620818,
      "grad_norm": 0.7582712769508362,
      "learning_rate": 4.190460678767383e-07,
      "loss": 2.4294,
      "step": 43440
    },
    {
      "epoch": 2.915942418039663,
      "grad_norm": 0.6730267405509949,
      "learning_rate": 4.124463638761511e-07,
      "loss": 2.4613,
      "step": 43450
    },
    {
      "epoch": 2.915942418039663,
      "eval_bleu": 21.447309712929247,
      "eval_gen_len": 28.9,
      "eval_loss": 2.9289395809173584,
      "eval_runtime": 62.8014,
      "eval_samples_per_second": 15.923,
      "eval_steps_per_second": 1.003,
      "step": 43450
    },
    {
      "epoch": 2.916613536458508,
      "grad_norm": 0.7250659465789795,
      "learning_rate": 4.0589893634046527e-07,
      "loss": 2.4667,
      "step": 43460
    },
    {
      "epoch": 2.9172846548773532,
      "grad_norm": 0.6984114646911621,
      "learning_rate": 3.9940378870663154e-07,
      "loss": 2.4688,
      "step": 43470
    },
    {
      "epoch": 2.9179557732961983,
      "grad_norm": 0.6959298849105835,
      "learning_rate": 3.929609243841448e-07,
      "loss": 2.4639,
      "step": 43480
    },
    {
      "epoch": 2.918626891715043,
      "grad_norm": 0.6820372939109802,
      "learning_rate": 3.865703467550552e-07,
      "loss": 2.4765,
      "step": 43490
    },
    {
      "epoch": 2.919298010133888,
      "grad_norm": 0.7603977918624878,
      "learning_rate": 3.8023205917395724e-07,
      "loss": 2.4246,
      "step": 43500
    },
    {
      "epoch": 2.919298010133888,
      "eval_bleu": 21.45211500627016,
      "eval_gen_len": 28.92,
      "eval_loss": 2.929109811782837,
      "eval_runtime": 63.0554,
      "eval_samples_per_second": 15.859,
      "eval_steps_per_second": 0.999,
      "step": 43500
    },
    {
      "epoch": 2.919969128552733,
      "grad_norm": 0.7406647801399231,
      "learning_rate": 3.7394606496801154e-07,
      "loss": 2.4582,
      "step": 43510
    },
    {
      "epoch": 2.920640246971578,
      "grad_norm": 0.6645559668540955,
      "learning_rate": 3.677123674369343e-07,
      "loss": 2.4298,
      "step": 43520
    },
    {
      "epoch": 2.921311365390423,
      "grad_norm": 0.6807926893234253,
      "learning_rate": 3.6153096985295233e-07,
      "loss": 2.4281,
      "step": 43530
    },
    {
      "epoch": 2.921982483809268,
      "grad_norm": 0.6893950700759888,
      "learning_rate": 3.554018754608923e-07,
      "loss": 2.4475,
      "step": 43540
    },
    {
      "epoch": 2.922653602228113,
      "grad_norm": 0.6667992472648621,
      "learning_rate": 3.493250874780918e-07,
      "loss": 2.474,
      "step": 43550
    },
    {
      "epoch": 2.922653602228113,
      "eval_bleu": 21.45146300960709,
      "eval_gen_len": 28.868,
      "eval_loss": 2.9289443492889404,
      "eval_runtime": 64.2966,
      "eval_samples_per_second": 15.553,
      "eval_steps_per_second": 0.98,
      "step": 43550
    },
    {
      "epoch": 2.923324720646958,
      "grad_norm": 0.7137494683265686,
      "learning_rate": 3.433006090944213e-07,
      "loss": 2.4665,
      "step": 43560
    },
    {
      "epoch": 2.923995839065803,
      "grad_norm": 0.6399151682853699,
      "learning_rate": 3.3732844347232895e-07,
      "loss": 2.449,
      "step": 43570
    },
    {
      "epoch": 2.924666957484648,
      "grad_norm": 0.6240555047988892,
      "learning_rate": 3.314085937467737e-07,
      "loss": 2.4494,
      "step": 43580
    },
    {
      "epoch": 2.9253380759034933,
      "grad_norm": 0.7187246084213257,
      "learning_rate": 3.2554106302524754e-07,
      "loss": 2.3969,
      "step": 43590
    },
    {
      "epoch": 2.9260091943223383,
      "grad_norm": 0.6072964668273926,
      "learning_rate": 3.197258543878201e-07,
      "loss": 2.4575,
      "step": 43600
    },
    {
      "epoch": 2.9260091943223383,
      "eval_bleu": 21.53092087717307,
      "eval_gen_len": 28.876,
      "eval_loss": 2.9289841651916504,
      "eval_runtime": 63.0182,
      "eval_samples_per_second": 15.868,
      "eval_steps_per_second": 1.0,
      "step": 43600
    },
    {
      "epoch": 2.9266803127411833,
      "grad_norm": 0.7562080025672913,
      "learning_rate": 3.1396297088703843e-07,
      "loss": 2.4253,
      "step": 43610
    },
    {
      "epoch": 2.9273514311600284,
      "grad_norm": 0.6793140172958374,
      "learning_rate": 3.082524155480271e-07,
      "loss": 2.4461,
      "step": 43620
    },
    {
      "epoch": 2.9280225495788734,
      "grad_norm": 0.7107927799224854,
      "learning_rate": 3.025941913684216e-07,
      "loss": 2.4162,
      "step": 43630
    },
    {
      "epoch": 2.9286936679977185,
      "grad_norm": 0.7090970873832703,
      "learning_rate": 2.969883013183905e-07,
      "loss": 2.4388,
      "step": 43640
    },
    {
      "epoch": 2.929364786416563,
      "grad_norm": 0.593892514705658,
      "learning_rate": 2.9143474834064656e-07,
      "loss": 2.4197,
      "step": 43650
    },
    {
      "epoch": 2.929364786416563,
      "eval_bleu": 21.555865752931105,
      "eval_gen_len": 28.881,
      "eval_loss": 2.928997278213501,
      "eval_runtime": 62.8983,
      "eval_samples_per_second": 15.899,
      "eval_steps_per_second": 1.002,
      "step": 43650
    },
    {
      "epoch": 2.930035904835408,
      "grad_norm": 0.6902714967727661,
      "learning_rate": 2.8593353535039115e-07,
      "loss": 2.4521,
      "step": 43660
    },
    {
      "epoch": 2.930707023254253,
      "grad_norm": 0.6397459506988525,
      "learning_rate": 2.80484665235381e-07,
      "loss": 2.4038,
      "step": 43670
    },
    {
      "epoch": 2.931378141673098,
      "grad_norm": 0.6597493290901184,
      "learning_rate": 2.750881408559058e-07,
      "loss": 2.4214,
      "step": 43680
    },
    {
      "epoch": 2.932049260091943,
      "grad_norm": 0.6873359084129333,
      "learning_rate": 2.697439650447442e-07,
      "loss": 2.4526,
      "step": 43690
    },
    {
      "epoch": 2.9327203785107883,
      "grad_norm": 0.7000911831855774,
      "learning_rate": 2.644521406072187e-07,
      "loss": 2.4348,
      "step": 43700
    },
    {
      "epoch": 2.9327203785107883,
      "eval_bleu": 21.41406124594898,
      "eval_gen_len": 28.927,
      "eval_loss": 2.929025411605835,
      "eval_runtime": 69.6103,
      "eval_samples_per_second": 14.366,
      "eval_steps_per_second": 0.905,
      "step": 43700
    },
    {
      "epoch": 2.9333914969296333,
      "grad_norm": 0.7283982634544373,
      "learning_rate": 2.5921267032117393e-07,
      "loss": 2.4649,
      "step": 43710
    },
    {
      "epoch": 2.9340626153484783,
      "grad_norm": 0.6598497629165649,
      "learning_rate": 2.540255569369432e-07,
      "loss": 2.392,
      "step": 43720
    },
    {
      "epoch": 2.9347337337673234,
      "grad_norm": 0.6184890866279602,
      "learning_rate": 2.488908031774151e-07,
      "loss": 2.4098,
      "step": 43730
    },
    {
      "epoch": 2.935404852186168,
      "grad_norm": 0.7328009009361267,
      "learning_rate": 2.438084117379669e-07,
      "loss": 2.4404,
      "step": 43740
    },
    {
      "epoch": 2.936075970605013,
      "grad_norm": 0.7483182549476624,
      "learning_rate": 2.3877838528648665e-07,
      "loss": 2.4309,
      "step": 43750
    },
    {
      "epoch": 2.936075970605013,
      "eval_bleu": 21.4885210868156,
      "eval_gen_len": 28.905,
      "eval_loss": 2.929086685180664,
      "eval_runtime": 69.5011,
      "eval_samples_per_second": 14.388,
      "eval_steps_per_second": 0.906,
      "step": 43750
    },
    {
      "epoch": 2.936747089023858,
      "grad_norm": 0.6712866425514221,
      "learning_rate": 2.3380072646340678e-07,
      "loss": 2.4108,
      "step": 43760
    },
    {
      "epoch": 2.937418207442703,
      "grad_norm": 0.6852242946624756,
      "learning_rate": 2.2887543788163712e-07,
      "loss": 2.4437,
      "step": 43770
    },
    {
      "epoch": 2.938089325861548,
      "grad_norm": 0.7614747881889343,
      "learning_rate": 2.2400252212659845e-07,
      "loss": 2.4748,
      "step": 43780
    },
    {
      "epoch": 2.938760444280393,
      "grad_norm": 0.7158709168434143,
      "learning_rate": 2.1918198175624461e-07,
      "loss": 2.4619,
      "step": 43790
    },
    {
      "epoch": 2.939431562699238,
      "grad_norm": 0.7247635722160339,
      "learning_rate": 2.1441381930101813e-07,
      "loss": 2.4371,
      "step": 43800
    },
    {
      "epoch": 2.939431562699238,
      "eval_bleu": 21.354565822664362,
      "eval_gen_len": 28.911,
      "eval_loss": 2.9288485050201416,
      "eval_runtime": 70.528,
      "eval_samples_per_second": 14.179,
      "eval_steps_per_second": 0.893,
      "step": 43800
    },
    {
      "epoch": 2.9401026811180833,
      "grad_norm": 0.7160381078720093,
      "learning_rate": 2.0969803726386128e-07,
      "loss": 2.4045,
      "step": 43810
    },
    {
      "epoch": 2.9407737995369283,
      "grad_norm": 0.7831162214279175,
      "learning_rate": 2.0503463812022727e-07,
      "loss": 2.4762,
      "step": 43820
    },
    {
      "epoch": 2.9414449179557733,
      "grad_norm": 0.7557960152626038,
      "learning_rate": 2.0042362431808015e-07,
      "loss": 2.4796,
      "step": 43830
    },
    {
      "epoch": 2.9421160363746184,
      "grad_norm": 0.7275826334953308,
      "learning_rate": 1.9586499827787263e-07,
      "loss": 2.4469,
      "step": 43840
    },
    {
      "epoch": 2.9427871547934634,
      "grad_norm": 0.7231757640838623,
      "learning_rate": 1.9135876239256835e-07,
      "loss": 2.4196,
      "step": 43850
    },
    {
      "epoch": 2.9427871547934634,
      "eval_bleu": 21.303026824570154,
      "eval_gen_len": 28.911,
      "eval_loss": 2.9290318489074707,
      "eval_runtime": 69.6875,
      "eval_samples_per_second": 14.35,
      "eval_steps_per_second": 0.904,
      "step": 43850
    },
    {
      "epoch": 2.9434582732123085,
      "grad_norm": 0.6874683499336243,
      "learning_rate": 1.8690491902761954e-07,
      "loss": 2.4245,
      "step": 43860
    },
    {
      "epoch": 2.9441293916311535,
      "grad_norm": 0.6472946405410767,
      "learning_rate": 1.8250347052098936e-07,
      "loss": 2.4338,
      "step": 43870
    },
    {
      "epoch": 2.9448005100499985,
      "grad_norm": 0.721766471862793,
      "learning_rate": 1.781544191831186e-07,
      "loss": 2.414,
      "step": 43880
    },
    {
      "epoch": 2.9454716284688436,
      "grad_norm": 0.7405696511268616,
      "learning_rate": 1.738577672969477e-07,
      "loss": 2.4486,
      "step": 43890
    },
    {
      "epoch": 2.946142746887688,
      "grad_norm": 0.6628459095954895,
      "learning_rate": 1.6961351711793917e-07,
      "loss": 2.4018,
      "step": 43900
    },
    {
      "epoch": 2.946142746887688,
      "eval_bleu": 21.38666503735986,
      "eval_gen_len": 28.897,
      "eval_loss": 2.9290544986724854,
      "eval_runtime": 69.0913,
      "eval_samples_per_second": 14.474,
      "eval_steps_per_second": 0.912,
      "step": 43900
    },
    {
      "epoch": 2.946813865306533,
      "grad_norm": 0.6574194431304932,
      "learning_rate": 1.6542167087401085e-07,
      "loss": 2.4519,
      "step": 43910
    },
    {
      "epoch": 2.9474849837253783,
      "grad_norm": 0.6804894804954529,
      "learning_rate": 1.6128223076558037e-07,
      "loss": 2.4482,
      "step": 43920
    },
    {
      "epoch": 2.9481561021442233,
      "grad_norm": 0.7260220050811768,
      "learning_rate": 1.571951989655873e-07,
      "loss": 2.4885,
      "step": 43930
    },
    {
      "epoch": 2.9488272205630683,
      "grad_norm": 0.6825752258300781,
      "learning_rate": 1.531605776194045e-07,
      "loss": 2.5088,
      "step": 43940
    },
    {
      "epoch": 2.9494983389819134,
      "grad_norm": 0.7342392206192017,
      "learning_rate": 1.4917836884494885e-07,
      "loss": 2.4458,
      "step": 43950
    },
    {
      "epoch": 2.9494983389819134,
      "eval_bleu": 21.3489693575605,
      "eval_gen_len": 28.901,
      "eval_loss": 2.929069757461548,
      "eval_runtime": 68.5601,
      "eval_samples_per_second": 14.586,
      "eval_steps_per_second": 0.919,
      "step": 43950
    },
    {
      "epoch": 2.9501694574007584,
      "grad_norm": 0.678397536277771,
      "learning_rate": 1.4524857473259268e-07,
      "loss": 2.4753,
      "step": 43960
    },
    {
      "epoch": 2.9508405758196035,
      "grad_norm": 0.6731348633766174,
      "learning_rate": 1.413711973452081e-07,
      "loss": 2.4372,
      "step": 43970
    },
    {
      "epoch": 2.9515116942384485,
      "grad_norm": 0.7160924673080444,
      "learning_rate": 1.3754623871812255e-07,
      "loss": 2.43,
      "step": 43980
    },
    {
      "epoch": 2.9521828126572935,
      "grad_norm": 0.6310005784034729,
      "learning_rate": 1.337737008591966e-07,
      "loss": 2.45,
      "step": 43990
    },
    {
      "epoch": 2.952853931076138,
      "grad_norm": 0.6956864595413208,
      "learning_rate": 1.3005358574873505e-07,
      "loss": 2.4418,
      "step": 44000
    },
    {
      "epoch": 2.952853931076138,
      "eval_bleu": 21.3208917954668,
      "eval_gen_len": 28.925,
      "eval_loss": 2.929096221923828,
      "eval_runtime": 69.1941,
      "eval_samples_per_second": 14.452,
      "eval_steps_per_second": 0.91,
      "step": 44000
    },
    {
      "epoch": 2.953525049494983,
      "grad_norm": 0.6518875956535339,
      "learning_rate": 1.263858953395425e-07,
      "loss": 2.4452,
      "step": 44010
    },
    {
      "epoch": 2.954196167913828,
      "grad_norm": 0.7039341330528259,
      "learning_rate": 1.2277063155688996e-07,
      "loss": 2.452,
      "step": 44020
    },
    {
      "epoch": 2.9548672863326733,
      "grad_norm": 0.654620349407196,
      "learning_rate": 1.1920779629854828e-07,
      "loss": 2.4667,
      "step": 44030
    },
    {
      "epoch": 2.9555384047515183,
      "grad_norm": 0.7558196187019348,
      "learning_rate": 1.1569739143474368e-07,
      "loss": 2.4525,
      "step": 44040
    },
    {
      "epoch": 2.9562095231703633,
      "grad_norm": 0.6536557078361511,
      "learning_rate": 1.12239418808191e-07,
      "loss": 2.4074,
      "step": 44050
    },
    {
      "epoch": 2.9562095231703633,
      "eval_bleu": 21.342188188594402,
      "eval_gen_len": 28.883,
      "eval_loss": 2.929006338119507,
      "eval_runtime": 69.2189,
      "eval_samples_per_second": 14.447,
      "eval_steps_per_second": 0.91,
      "step": 44050
    },
    {
      "epoch": 2.9568806415892084,
      "grad_norm": 0.6134118437767029,
      "learning_rate": 1.088338802340938e-07,
      "loss": 2.4171,
      "step": 44060
    },
    {
      "epoch": 2.9575517600080534,
      "grad_norm": 0.7172659039497375,
      "learning_rate": 1.0548077750012208e-07,
      "loss": 2.4039,
      "step": 44070
    },
    {
      "epoch": 2.9582228784268985,
      "grad_norm": 0.723743736743927,
      "learning_rate": 1.0218011236641233e-07,
      "loss": 2.5059,
      "step": 44080
    },
    {
      "epoch": 2.9588939968457435,
      "grad_norm": 0.6455081105232239,
      "learning_rate": 9.893188656557861e-08,
      "loss": 2.495,
      "step": 44090
    },
    {
      "epoch": 2.9595651152645885,
      "grad_norm": 0.7051267027854919,
      "learning_rate": 9.573610180271253e-08,
      "loss": 2.4527,
      "step": 44100
    },
    {
      "epoch": 2.9595651152645885,
      "eval_bleu": 21.40078921373342,
      "eval_gen_len": 28.884,
      "eval_loss": 2.9289817810058594,
      "eval_runtime": 69.5953,
      "eval_samples_per_second": 14.369,
      "eval_steps_per_second": 0.905,
      "step": 44100
    },
    {
      "epoch": 2.9602362336834336,
      "grad_norm": 0.7006094455718994,
      "learning_rate": 9.259275975538328e-08,
      "loss": 2.4506,
      "step": 44110
    },
    {
      "epoch": 2.9609073521022786,
      "grad_norm": 0.6768382787704468,
      "learning_rate": 8.950186207361544e-08,
      "loss": 2.493,
      "step": 44120
    },
    {
      "epoch": 2.9615784705211237,
      "grad_norm": 0.7361558675765991,
      "learning_rate": 8.646341037992223e-08,
      "loss": 2.4331,
      "step": 44130
    },
    {
      "epoch": 2.9622495889399687,
      "grad_norm": 0.664418637752533,
      "learning_rate": 8.347740626927225e-08,
      "loss": 2.4158,
      "step": 44140
    },
    {
      "epoch": 2.9629207073588133,
      "grad_norm": 0.6417472958564758,
      "learning_rate": 8.054385130910059e-08,
      "loss": 2.416,
      "step": 44150
    },
    {
      "epoch": 2.9629207073588133,
      "eval_bleu": 21.406700596022073,
      "eval_gen_len": 28.912,
      "eval_loss": 2.9289345741271973,
      "eval_runtime": 68.8747,
      "eval_samples_per_second": 14.519,
      "eval_steps_per_second": 0.915,
      "step": 44150
    },
    {
      "epoch": 2.9635918257776583,
      "grad_norm": 0.7161716818809509,
      "learning_rate": 7.766274703933096e-08,
      "loss": 2.4465,
      "step": 44160
    },
    {
      "epoch": 2.9642629441965034,
      "grad_norm": 0.69998699426651,
      "learning_rate": 7.48340949723314e-08,
      "loss": 2.4428,
      "step": 44170
    },
    {
      "epoch": 2.9649340626153484,
      "grad_norm": 0.7231576442718506,
      "learning_rate": 7.205789659294748e-08,
      "loss": 2.4625,
      "step": 44180
    },
    {
      "epoch": 2.9656051810341935,
      "grad_norm": 0.7024601101875305,
      "learning_rate": 6.933415335849125e-08,
      "loss": 2.4597,
      "step": 44190
    },
    {
      "epoch": 2.9662762994530385,
      "grad_norm": 0.7055964469909668,
      "learning_rate": 6.666286669873011e-08,
      "loss": 2.4621,
      "step": 44200
    },
    {
      "epoch": 2.9662762994530385,
      "eval_bleu": 21.404482401276535,
      "eval_gen_len": 28.883,
      "eval_loss": 2.9291343688964844,
      "eval_runtime": 67.8392,
      "eval_samples_per_second": 14.741,
      "eval_steps_per_second": 0.929,
      "step": 44200
    },
    {
      "epoch": 2.9669474178718835,
      "grad_norm": 0.6534683108329773,
      "learning_rate": 6.404403801590909e-08,
      "loss": 2.4362,
      "step": 44210
    },
    {
      "epoch": 2.9676185362907286,
      "grad_norm": 0.7177969813346863,
      "learning_rate": 6.147766868472848e-08,
      "loss": 2.4559,
      "step": 44220
    },
    {
      "epoch": 2.9682896547095736,
      "grad_norm": 0.6646554470062256,
      "learning_rate": 5.896376005234405e-08,
      "loss": 2.4456,
      "step": 44230
    },
    {
      "epoch": 2.9689607731284187,
      "grad_norm": 0.6667842268943787,
      "learning_rate": 5.650231343838908e-08,
      "loss": 2.4174,
      "step": 44240
    },
    {
      "epoch": 2.9696318915472633,
      "grad_norm": 0.701981246471405,
      "learning_rate": 5.4093330134952213e-08,
      "loss": 2.4531,
      "step": 44250
    },
    {
      "epoch": 2.9696318915472633,
      "eval_bleu": 21.467183082963444,
      "eval_gen_len": 28.913,
      "eval_loss": 2.929168701171875,
      "eval_runtime": 69.1223,
      "eval_samples_per_second": 14.467,
      "eval_steps_per_second": 0.911,
      "step": 44250
    },
    {
      "epoch": 2.9703030099661083,
      "grad_norm": 0.6958836317062378,
      "learning_rate": 5.173681140656639e-08,
      "loss": 2.4547,
      "step": 44260
    },
    {
      "epoch": 2.9709741283849533,
      "grad_norm": 0.732908308506012,
      "learning_rate": 4.943275849025319e-08,
      "loss": 2.4527,
      "step": 44270
    },
    {
      "epoch": 2.9716452468037984,
      "grad_norm": 0.7149907350540161,
      "learning_rate": 4.718117259546739e-08,
      "loss": 2.4417,
      "step": 44280
    },
    {
      "epoch": 2.9723163652226434,
      "grad_norm": 0.6901302933692932,
      "learning_rate": 4.4982054904141314e-08,
      "loss": 2.4803,
      "step": 44290
    },
    {
      "epoch": 2.9729874836414885,
      "grad_norm": 0.6608431935310364,
      "learning_rate": 4.2835406570651546e-08,
      "loss": 2.4903,
      "step": 44300
    },
    {
      "epoch": 2.9729874836414885,
      "eval_bleu": 21.41539010092705,
      "eval_gen_len": 28.894,
      "eval_loss": 2.9291672706604004,
      "eval_runtime": 68.3647,
      "eval_samples_per_second": 14.627,
      "eval_steps_per_second": 0.922,
      "step": 44300
    },
    {
      "epoch": 2.9736586020603335,
      "grad_norm": 0.6628420352935791,
      "learning_rate": 4.074122872184116e-08,
      "loss": 2.4009,
      "step": 44310
    },
    {
      "epoch": 2.9743297204791785,
      "grad_norm": 0.7514714002609253,
      "learning_rate": 3.869952245700859e-08,
      "loss": 2.4547,
      "step": 44320
    },
    {
      "epoch": 2.9750008388980236,
      "grad_norm": 0.7104407548904419,
      "learning_rate": 3.671028884789651e-08,
      "loss": 2.4573,
      "step": 44330
    },
    {
      "epoch": 2.9756719573168686,
      "grad_norm": 0.7689525485038757,
      "learning_rate": 3.477352893872521e-08,
      "loss": 2.4555,
      "step": 44340
    },
    {
      "epoch": 2.9763430757357137,
      "grad_norm": 0.7066618204116821,
      "learning_rate": 3.28892437461481e-08,
      "loss": 2.4564,
      "step": 44350
    },
    {
      "epoch": 2.9763430757357137,
      "eval_bleu": 21.459590199074775,
      "eval_gen_len": 28.926,
      "eval_loss": 2.9291603565216064,
      "eval_runtime": 68.3389,
      "eval_samples_per_second": 14.633,
      "eval_steps_per_second": 0.922,
      "step": 44350
    },
    {
      "epoch": 2.9770141941545587,
      "grad_norm": 0.7027040123939514,
      "learning_rate": 3.105743425928509e-08,
      "loss": 2.4919,
      "step": 44360
    },
    {
      "epoch": 2.9776853125734037,
      "grad_norm": 0.6934829950332642,
      "learning_rate": 2.9278101439711437e-08,
      "loss": 2.4179,
      "step": 44370
    },
    {
      "epoch": 2.978356430992249,
      "grad_norm": 0.7307124137878418,
      "learning_rate": 2.7551246221446668e-08,
      "loss": 2.398,
      "step": 44380
    },
    {
      "epoch": 2.979027549411094,
      "grad_norm": 0.7041597962379456,
      "learning_rate": 2.5876869510965686e-08,
      "loss": 2.4568,
      "step": 44390
    },
    {
      "epoch": 2.979698667829939,
      "grad_norm": 0.7904657125473022,
      "learning_rate": 2.4254972187209844e-08,
      "loss": 2.4121,
      "step": 44400
    },
    {
      "epoch": 2.979698667829939,
      "eval_bleu": 21.36623641779956,
      "eval_gen_len": 28.912,
      "eval_loss": 2.929094076156616,
      "eval_runtime": 69.2061,
      "eval_samples_per_second": 14.45,
      "eval_steps_per_second": 0.91,
      "step": 44400
    },
    {
      "epoch": 2.9803697862487835,
      "grad_norm": 0.6871273517608643,
      "learning_rate": 2.2685555101553678e-08,
      "loss": 2.4789,
      "step": 44410
    },
    {
      "epoch": 2.9810409046676285,
      "grad_norm": 0.6748914122581482,
      "learning_rate": 2.1168619077827078e-08,
      "loss": 2.4562,
      "step": 44420
    },
    {
      "epoch": 2.9817120230864735,
      "grad_norm": 0.7526386976242065,
      "learning_rate": 1.9704164912315303e-08,
      "loss": 2.4238,
      "step": 44430
    },
    {
      "epoch": 2.9823831415053186,
      "grad_norm": 0.7330055236816406,
      "learning_rate": 1.8292193373770084e-08,
      "loss": 2.4481,
      "step": 44440
    },
    {
      "epoch": 2.9830542599241636,
      "grad_norm": 0.6775246858596802,
      "learning_rate": 1.6932705203354104e-08,
      "loss": 2.4036,
      "step": 44450
    },
    {
      "epoch": 2.9830542599241636,
      "eval_bleu": 21.442008051345447,
      "eval_gen_len": 28.904,
      "eval_loss": 2.92905330657959,
      "eval_runtime": 67.8615,
      "eval_samples_per_second": 14.736,
      "eval_steps_per_second": 0.928,
      "step": 44450
    },
    {
      "epoch": 2.9837253783430087,
      "grad_norm": 0.7286775708198547,
      "learning_rate": 1.5625701114718726e-08,
      "loss": 2.4815,
      "step": 44460
    },
    {
      "epoch": 2.9843964967618537,
      "grad_norm": 0.6495869159698486,
      "learning_rate": 1.4371181793948474e-08,
      "loss": 2.4412,
      "step": 44470
    },
    {
      "epoch": 2.9850676151806987,
      "grad_norm": 0.7064517736434937,
      "learning_rate": 1.316914789956103e-08,
      "loss": 2.411,
      "step": 44480
    },
    {
      "epoch": 2.985738733599544,
      "grad_norm": 0.6910910606384277,
      "learning_rate": 1.2019600062562753e-08,
      "loss": 2.3956,
      "step": 44490
    },
    {
      "epoch": 2.9864098520183884,
      "grad_norm": 0.689272940158844,
      "learning_rate": 1.0922538886370958e-08,
      "loss": 2.4666,
      "step": 44500
    },
    {
      "epoch": 2.9864098520183884,
      "eval_bleu": 21.523208198276468,
      "eval_gen_len": 28.865,
      "eval_loss": 2.9291064739227295,
      "eval_runtime": 66.4348,
      "eval_samples_per_second": 15.052,
      "eval_steps_per_second": 0.948,
      "step": 44500
    },
    {
      "epoch": 2.9870809704372334,
      "grad_norm": 0.7287365198135376,
      "learning_rate": 9.877964946869433e-09,
      "loss": 2.4411,
      "step": 44510
    },
    {
      "epoch": 2.9877520888560785,
      "grad_norm": 0.7438300251960754,
      "learning_rate": 8.885878792386226e-09,
      "loss": 2.5085,
      "step": 44520
    },
    {
      "epoch": 2.9884232072749235,
      "grad_norm": 0.6771840453147888,
      "learning_rate": 7.946280943704753e-09,
      "loss": 2.4309,
      "step": 44530
    },
    {
      "epoch": 2.9890943256937685,
      "grad_norm": 0.6687279939651489,
      "learning_rate": 7.059171894030492e-09,
      "loss": 2.4193,
      "step": 44540
    },
    {
      "epoch": 2.9897654441126136,
      "grad_norm": 0.6450448632240295,
      "learning_rate": 6.224552109046489e-09,
      "loss": 2.476,
      "step": 44550
    },
    {
      "epoch": 2.9897654441126136,
      "eval_bleu": 21.354553368644282,
      "eval_gen_len": 28.918,
      "eval_loss": 2.9291741847991943,
      "eval_runtime": 68.9452,
      "eval_samples_per_second": 14.504,
      "eval_steps_per_second": 0.914,
      "step": 44550
    },
    {
      "epoch": 2.9904365625314586,
      "grad_norm": 0.623991072177887,
      "learning_rate": 5.442422026868954e-09,
      "loss": 2.4209,
      "step": 44560
    },
    {
      "epoch": 2.9911076809503037,
      "grad_norm": 0.7227262854576111,
      "learning_rate": 4.71278205804726e-09,
      "loss": 2.4389,
      "step": 44570
    },
    {
      "epoch": 2.9917787993691487,
      "grad_norm": 0.6529095768928528,
      "learning_rate": 4.035632585608351e-09,
      "loss": 2.3956,
      "step": 44580
    },
    {
      "epoch": 2.9924499177879937,
      "grad_norm": 0.7123184204101562,
      "learning_rate": 3.4109739650012296e-09,
      "loss": 2.4302,
      "step": 44590
    },
    {
      "epoch": 2.993121036206839,
      "grad_norm": 0.6864901781082153,
      "learning_rate": 2.8388065241302665e-09,
      "loss": 2.4142,
      "step": 44600
    },
    {
      "epoch": 2.993121036206839,
      "eval_bleu": 21.422920947094024,
      "eval_gen_len": 28.889,
      "eval_loss": 2.9292030334472656,
      "eval_runtime": 69.319,
      "eval_samples_per_second": 14.426,
      "eval_steps_per_second": 0.909,
      "step": 44600
    },
    {
      "epoch": 2.993792154625684,
      "grad_norm": 0.7205923199653625,
      "learning_rate": 2.3191305633440965e-09,
      "loss": 2.4349,
      "step": 44610
    },
    {
      "epoch": 2.994463273044529,
      "grad_norm": 0.7006317377090454,
      "learning_rate": 1.8519463554245165e-09,
      "loss": 2.4704,
      "step": 44620
    },
    {
      "epoch": 2.995134391463374,
      "grad_norm": 0.7142077088356018,
      "learning_rate": 1.437254145619793e-09,
      "loss": 2.4646,
      "step": 44630
    },
    {
      "epoch": 2.995805509882219,
      "grad_norm": 0.6689660549163818,
      "learning_rate": 1.0750541516224567e-09,
      "loss": 2.4656,
      "step": 44640
    },
    {
      "epoch": 2.996476628301064,
      "grad_norm": 0.6587130427360535,
      "learning_rate": 7.65346563547098e-10,
      "loss": 2.4615,
      "step": 44650
    },
    {
      "epoch": 2.996476628301064,
      "eval_bleu": 21.375500083279338,
      "eval_gen_len": 28.859,
      "eval_loss": 2.929011821746826,
      "eval_runtime": 69.6546,
      "eval_samples_per_second": 14.357,
      "eval_steps_per_second": 0.904,
      "step": 44650
    },
    {
      "epoch": 2.9971477467199086,
      "grad_norm": 0.7054611444473267,
      "learning_rate": 5.081315439747769e-10,
      "loss": 2.5005,
      "step": 44660
    },
    {
      "epoch": 2.9978188651387536,
      "grad_norm": 0.6595999002456665,
      "learning_rate": 3.034092279197154e-10,
      "loss": 2.4355,
      "step": 44670
    },
    {
      "epoch": 2.9984899835575987,
      "grad_norm": 0.6581023335456848,
      "learning_rate": 1.511797228626044e-10,
      "loss": 2.4015,
      "step": 44680
    },
    {
      "epoch": 2.9991611019764437,
      "grad_norm": 0.6844831705093384,
      "learning_rate": 5.1443108695092835e-11,
      "loss": 2.4327,
      "step": 44690
    },
    {
      "epoch": 2.9998322203952887,
      "grad_norm": 0.6985793113708496,
      "learning_rate": 4.19943777529852e-12,
      "loss": 2.4036,
      "step": 44700
    },
    {
      "epoch": 2.9998322203952887,
      "eval_bleu": 21.292937143655706,
      "eval_gen_len": 28.886,
      "eval_loss": 2.929147720336914,
      "eval_runtime": 69.3373,
      "eval_samples_per_second": 14.422,
      "eval_steps_per_second": 0.909,
      "step": 44700
    },
    {
      "epoch": 3.0,
      "step": 44703,
      "total_flos": 4.9141057372328755e+17,
      "train_loss": 2.501045199018478,
      "train_runtime": 88172.0916,
      "train_samples_per_second": 32.446,
      "train_steps_per_second": 0.507
    }
  ],
  "logging_steps": 10,
  "max_steps": 44703,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.9141057372328755e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
