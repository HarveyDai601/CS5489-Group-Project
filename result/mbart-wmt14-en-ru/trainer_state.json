{
  "best_global_step": 35900,
  "best_metric": 27.771501831378007,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 50,
  "global_step": 69702,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00043040371868812945,
      "grad_norm": 2.821197748184204,
      "learning_rate": 8.604206500956023e-07,
      "loss": 3.5339,
      "step": 10
    },
    {
      "epoch": 0.0008608074373762589,
      "grad_norm": 2.709821939468384,
      "learning_rate": 1.8164435946462718e-06,
      "loss": 3.4917,
      "step": 20
    },
    {
      "epoch": 0.0012912111560643884,
      "grad_norm": 3.0269086360931396,
      "learning_rate": 2.772466539196941e-06,
      "loss": 3.5721,
      "step": 30
    },
    {
      "epoch": 0.0017216148747525178,
      "grad_norm": 2.5408549308776855,
      "learning_rate": 3.7284894837476104e-06,
      "loss": 3.5749,
      "step": 40
    },
    {
      "epoch": 0.0021520185934406472,
      "grad_norm": 2.951124906539917,
      "learning_rate": 4.68451242829828e-06,
      "loss": 3.6219,
      "step": 50
    },
    {
      "epoch": 0.0021520185934406472,
      "eval_bleu": 2.156062937368289,
      "eval_gen_len": 29.916,
      "eval_loss": 3.0939745903015137,
      "eval_runtime": 68.8039,
      "eval_samples_per_second": 14.534,
      "eval_steps_per_second": 0.916,
      "step": 50
    },
    {
      "epoch": 0.002582422312128777,
      "grad_norm": 2.642185926437378,
      "learning_rate": 5.6405353728489485e-06,
      "loss": 3.5321,
      "step": 60
    },
    {
      "epoch": 0.0030128260308169065,
      "grad_norm": 2.605483055114746,
      "learning_rate": 6.596558317399617e-06,
      "loss": 3.4672,
      "step": 70
    },
    {
      "epoch": 0.0034432297495050356,
      "grad_norm": 2.318887948989868,
      "learning_rate": 7.552581261950287e-06,
      "loss": 3.5142,
      "step": 80
    },
    {
      "epoch": 0.0038736334681931653,
      "grad_norm": 1.9149808883666992,
      "learning_rate": 8.508604206500955e-06,
      "loss": 3.4748,
      "step": 90
    },
    {
      "epoch": 0.0043040371868812944,
      "grad_norm": 2.021639585494995,
      "learning_rate": 9.464627151051626e-06,
      "loss": 3.4192,
      "step": 100
    },
    {
      "epoch": 0.0043040371868812944,
      "eval_bleu": 9.006018186023736,
      "eval_gen_len": 27.958,
      "eval_loss": 2.9813272953033447,
      "eval_runtime": 69.4733,
      "eval_samples_per_second": 14.394,
      "eval_steps_per_second": 0.907,
      "step": 100
    },
    {
      "epoch": 0.0047344409055694245,
      "grad_norm": 1.3941717147827148,
      "learning_rate": 1.0420650095602295e-05,
      "loss": 3.4065,
      "step": 110
    },
    {
      "epoch": 0.005164844624257554,
      "grad_norm": 1.3442776203155518,
      "learning_rate": 1.1376673040152965e-05,
      "loss": 3.4199,
      "step": 120
    },
    {
      "epoch": 0.005595248342945683,
      "grad_norm": 1.28822660446167,
      "learning_rate": 1.2332695984703634e-05,
      "loss": 3.3755,
      "step": 130
    },
    {
      "epoch": 0.006025652061633813,
      "grad_norm": 1.4348554611206055,
      "learning_rate": 1.3288718929254305e-05,
      "loss": 3.3765,
      "step": 140
    },
    {
      "epoch": 0.006456055780321942,
      "grad_norm": 1.2783855199813843,
      "learning_rate": 1.4244741873804973e-05,
      "loss": 3.2153,
      "step": 150
    },
    {
      "epoch": 0.006456055780321942,
      "eval_bleu": 24.805463741738226,
      "eval_gen_len": 26.999,
      "eval_loss": 2.9015891551971436,
      "eval_runtime": 57.6656,
      "eval_samples_per_second": 17.341,
      "eval_steps_per_second": 1.093,
      "step": 150
    },
    {
      "epoch": 0.006886459499010071,
      "grad_norm": 1.3624093532562256,
      "learning_rate": 1.5200764818355642e-05,
      "loss": 3.369,
      "step": 160
    },
    {
      "epoch": 0.007316863217698201,
      "grad_norm": 1.4815682172775269,
      "learning_rate": 1.615678776290631e-05,
      "loss": 3.3575,
      "step": 170
    },
    {
      "epoch": 0.0077472669363863305,
      "grad_norm": 1.247501015663147,
      "learning_rate": 1.7112810707456982e-05,
      "loss": 3.2578,
      "step": 180
    },
    {
      "epoch": 0.00817767065507446,
      "grad_norm": 1.3582278490066528,
      "learning_rate": 1.806883365200765e-05,
      "loss": 3.3941,
      "step": 190
    },
    {
      "epoch": 0.008608074373762589,
      "grad_norm": 1.3150789737701416,
      "learning_rate": 1.902485659655832e-05,
      "loss": 3.2839,
      "step": 200
    },
    {
      "epoch": 0.008608074373762589,
      "eval_bleu": 24.987587083398225,
      "eval_gen_len": 27.129,
      "eval_loss": 2.8959450721740723,
      "eval_runtime": 56.9951,
      "eval_samples_per_second": 17.545,
      "eval_steps_per_second": 1.105,
      "step": 200
    },
    {
      "epoch": 0.009038478092450718,
      "grad_norm": 1.22559654712677,
      "learning_rate": 1.9980879541108987e-05,
      "loss": 3.3919,
      "step": 210
    },
    {
      "epoch": 0.009468881811138849,
      "grad_norm": 1.219045639038086,
      "learning_rate": 2.0936902485659657e-05,
      "loss": 3.3738,
      "step": 220
    },
    {
      "epoch": 0.009899285529826978,
      "grad_norm": 1.357113003730774,
      "learning_rate": 2.1892925430210324e-05,
      "loss": 3.3324,
      "step": 230
    },
    {
      "epoch": 0.010329689248515107,
      "grad_norm": 1.3127143383026123,
      "learning_rate": 2.2848948374760995e-05,
      "loss": 3.2297,
      "step": 240
    },
    {
      "epoch": 0.010760092967203237,
      "grad_norm": 1.347825527191162,
      "learning_rate": 2.3804971319311666e-05,
      "loss": 3.3037,
      "step": 250
    },
    {
      "epoch": 0.010760092967203237,
      "eval_bleu": 24.906737465874027,
      "eval_gen_len": 27.183,
      "eval_loss": 2.893963575363159,
      "eval_runtime": 57.1448,
      "eval_samples_per_second": 17.499,
      "eval_steps_per_second": 1.102,
      "step": 250
    },
    {
      "epoch": 0.011190496685891366,
      "grad_norm": 1.3411082029342651,
      "learning_rate": 2.4760994263862333e-05,
      "loss": 3.2988,
      "step": 260
    },
    {
      "epoch": 0.011620900404579495,
      "grad_norm": 1.250380516052246,
      "learning_rate": 2.5717017208413003e-05,
      "loss": 3.3773,
      "step": 270
    },
    {
      "epoch": 0.012051304123267626,
      "grad_norm": 1.427154541015625,
      "learning_rate": 2.6673040152963674e-05,
      "loss": 3.3925,
      "step": 280
    },
    {
      "epoch": 0.012481707841955755,
      "grad_norm": 1.312418818473816,
      "learning_rate": 2.762906309751434e-05,
      "loss": 3.3067,
      "step": 290
    },
    {
      "epoch": 0.012912111560643884,
      "grad_norm": 1.1771533489227295,
      "learning_rate": 2.858508604206501e-05,
      "loss": 3.2373,
      "step": 300
    },
    {
      "epoch": 0.012912111560643884,
      "eval_bleu": 25.157082634210443,
      "eval_gen_len": 27.16,
      "eval_loss": 2.8933753967285156,
      "eval_runtime": 57.7574,
      "eval_samples_per_second": 17.314,
      "eval_steps_per_second": 1.091,
      "step": 300
    },
    {
      "epoch": 0.013342515279332013,
      "grad_norm": 1.36886727809906,
      "learning_rate": 2.954110898661568e-05,
      "loss": 3.3019,
      "step": 310
    },
    {
      "epoch": 0.013772918998020143,
      "grad_norm": 1.3493424654006958,
      "learning_rate": 3.049713193116635e-05,
      "loss": 3.3886,
      "step": 320
    },
    {
      "epoch": 0.014203322716708272,
      "grad_norm": 1.2386900186538696,
      "learning_rate": 3.145315487571702e-05,
      "loss": 3.2724,
      "step": 330
    },
    {
      "epoch": 0.014633726435396403,
      "grad_norm": 1.3291088342666626,
      "learning_rate": 3.240917782026769e-05,
      "loss": 3.3065,
      "step": 340
    },
    {
      "epoch": 0.015064130154084532,
      "grad_norm": 1.1130869388580322,
      "learning_rate": 3.3365200764818354e-05,
      "loss": 3.2441,
      "step": 350
    },
    {
      "epoch": 0.015064130154084532,
      "eval_bleu": 25.062233252715274,
      "eval_gen_len": 27.189,
      "eval_loss": 2.888784170150757,
      "eval_runtime": 57.3089,
      "eval_samples_per_second": 17.449,
      "eval_steps_per_second": 1.099,
      "step": 350
    },
    {
      "epoch": 0.015494533872772661,
      "grad_norm": 1.3773753643035889,
      "learning_rate": 3.432122370936903e-05,
      "loss": 3.3314,
      "step": 360
    },
    {
      "epoch": 0.01592493759146079,
      "grad_norm": 1.4555304050445557,
      "learning_rate": 3.5277246653919695e-05,
      "loss": 3.2909,
      "step": 370
    },
    {
      "epoch": 0.01635534131014892,
      "grad_norm": 1.093445062637329,
      "learning_rate": 3.623326959847036e-05,
      "loss": 3.3345,
      "step": 380
    },
    {
      "epoch": 0.01678574502883705,
      "grad_norm": 1.3913452625274658,
      "learning_rate": 3.7189292543021036e-05,
      "loss": 3.2345,
      "step": 390
    },
    {
      "epoch": 0.017216148747525178,
      "grad_norm": 1.4405943155288696,
      "learning_rate": 3.8145315487571704e-05,
      "loss": 3.2551,
      "step": 400
    },
    {
      "epoch": 0.017216148747525178,
      "eval_bleu": 24.996779440549965,
      "eval_gen_len": 27.089,
      "eval_loss": 2.8883821964263916,
      "eval_runtime": 56.5296,
      "eval_samples_per_second": 17.69,
      "eval_steps_per_second": 1.114,
      "step": 400
    },
    {
      "epoch": 0.017646552466213307,
      "grad_norm": 1.274413824081421,
      "learning_rate": 3.910133843212238e-05,
      "loss": 3.2427,
      "step": 410
    },
    {
      "epoch": 0.018076956184901436,
      "grad_norm": 1.327905297279358,
      "learning_rate": 4.0057361376673045e-05,
      "loss": 3.3626,
      "step": 420
    },
    {
      "epoch": 0.018507359903589565,
      "grad_norm": 1.3361523151397705,
      "learning_rate": 4.101338432122371e-05,
      "loss": 3.344,
      "step": 430
    },
    {
      "epoch": 0.018937763622277698,
      "grad_norm": 1.4809324741363525,
      "learning_rate": 4.196940726577438e-05,
      "loss": 3.2821,
      "step": 440
    },
    {
      "epoch": 0.019368167340965827,
      "grad_norm": 1.2653553485870361,
      "learning_rate": 4.292543021032505e-05,
      "loss": 3.2994,
      "step": 450
    },
    {
      "epoch": 0.019368167340965827,
      "eval_bleu": 24.914616697363712,
      "eval_gen_len": 27.169,
      "eval_loss": 2.8870279788970947,
      "eval_runtime": 57.2757,
      "eval_samples_per_second": 17.459,
      "eval_steps_per_second": 1.1,
      "step": 450
    },
    {
      "epoch": 0.019798571059653956,
      "grad_norm": 1.3439515829086304,
      "learning_rate": 4.388145315487572e-05,
      "loss": 3.3099,
      "step": 460
    },
    {
      "epoch": 0.020228974778342085,
      "grad_norm": 1.4088220596313477,
      "learning_rate": 4.483747609942639e-05,
      "loss": 3.2874,
      "step": 470
    },
    {
      "epoch": 0.020659378497030215,
      "grad_norm": 1.152896761894226,
      "learning_rate": 4.5793499043977055e-05,
      "loss": 3.2984,
      "step": 480
    },
    {
      "epoch": 0.021089782215718344,
      "grad_norm": 1.3268824815750122,
      "learning_rate": 4.674952198852773e-05,
      "loss": 3.23,
      "step": 490
    },
    {
      "epoch": 0.021520185934406473,
      "grad_norm": 1.4399406909942627,
      "learning_rate": 4.7705544933078396e-05,
      "loss": 3.3216,
      "step": 500
    },
    {
      "epoch": 0.021520185934406473,
      "eval_bleu": 25.276539626718353,
      "eval_gen_len": 27.101,
      "eval_loss": 2.8827614784240723,
      "eval_runtime": 56.7644,
      "eval_samples_per_second": 17.617,
      "eval_steps_per_second": 1.11,
      "step": 500
    },
    {
      "epoch": 0.021950589653094602,
      "grad_norm": 1.1956851482391357,
      "learning_rate": 4.866156787762906e-05,
      "loss": 3.2928,
      "step": 510
    },
    {
      "epoch": 0.02238099337178273,
      "grad_norm": 1.3294289112091064,
      "learning_rate": 4.961759082217973e-05,
      "loss": 3.2673,
      "step": 520
    },
    {
      "epoch": 0.02281139709047086,
      "grad_norm": 1.2732689380645752,
      "learning_rate": 5.05736137667304e-05,
      "loss": 3.3064,
      "step": 530
    },
    {
      "epoch": 0.02324180080915899,
      "grad_norm": 1.2211711406707764,
      "learning_rate": 5.152963671128107e-05,
      "loss": 3.3345,
      "step": 540
    },
    {
      "epoch": 0.02367220452784712,
      "grad_norm": 1.3778836727142334,
      "learning_rate": 5.2485659655831745e-05,
      "loss": 3.1831,
      "step": 550
    },
    {
      "epoch": 0.02367220452784712,
      "eval_bleu": 25.23595025377274,
      "eval_gen_len": 27.088,
      "eval_loss": 2.8810012340545654,
      "eval_runtime": 56.7534,
      "eval_samples_per_second": 17.62,
      "eval_steps_per_second": 1.11,
      "step": 550
    },
    {
      "epoch": 0.02410260824653525,
      "grad_norm": 1.4054253101348877,
      "learning_rate": 5.344168260038241e-05,
      "loss": 3.2248,
      "step": 560
    },
    {
      "epoch": 0.02453301196522338,
      "grad_norm": 1.1551679372787476,
      "learning_rate": 5.4397705544933086e-05,
      "loss": 3.2455,
      "step": 570
    },
    {
      "epoch": 0.02496341568391151,
      "grad_norm": 1.200948715209961,
      "learning_rate": 5.535372848948375e-05,
      "loss": 3.346,
      "step": 580
    },
    {
      "epoch": 0.02539381940259964,
      "grad_norm": 1.324035406112671,
      "learning_rate": 5.630975143403442e-05,
      "loss": 3.2978,
      "step": 590
    },
    {
      "epoch": 0.02582422312128777,
      "grad_norm": 1.3151090145111084,
      "learning_rate": 5.726577437858509e-05,
      "loss": 3.2606,
      "step": 600
    },
    {
      "epoch": 0.02582422312128777,
      "eval_bleu": 24.923199759176914,
      "eval_gen_len": 27.256,
      "eval_loss": 2.8817975521087646,
      "eval_runtime": 57.3193,
      "eval_samples_per_second": 17.446,
      "eval_steps_per_second": 1.099,
      "step": 600
    },
    {
      "epoch": 0.026254626839975898,
      "grad_norm": 1.2530509233474731,
      "learning_rate": 5.822179732313576e-05,
      "loss": 3.3323,
      "step": 610
    },
    {
      "epoch": 0.026685030558664027,
      "grad_norm": 1.3187426328659058,
      "learning_rate": 5.917782026768642e-05,
      "loss": 3.3451,
      "step": 620
    },
    {
      "epoch": 0.027115434277352156,
      "grad_norm": 1.4141713380813599,
      "learning_rate": 6.0133843212237096e-05,
      "loss": 3.2303,
      "step": 630
    },
    {
      "epoch": 0.027545837996040285,
      "grad_norm": 1.4845094680786133,
      "learning_rate": 6.108986615678777e-05,
      "loss": 3.2901,
      "step": 640
    },
    {
      "epoch": 0.027976241714728414,
      "grad_norm": 1.4087449312210083,
      "learning_rate": 6.204588910133844e-05,
      "loss": 3.3606,
      "step": 650
    },
    {
      "epoch": 0.027976241714728414,
      "eval_bleu": 24.661123020448812,
      "eval_gen_len": 27.16,
      "eval_loss": 2.8796582221984863,
      "eval_runtime": 58.0142,
      "eval_samples_per_second": 17.237,
      "eval_steps_per_second": 1.086,
      "step": 650
    },
    {
      "epoch": 0.028406645433416543,
      "grad_norm": 1.219738483428955,
      "learning_rate": 6.30019120458891e-05,
      "loss": 3.2622,
      "step": 660
    },
    {
      "epoch": 0.028837049152104673,
      "grad_norm": 1.2120169401168823,
      "learning_rate": 6.395793499043978e-05,
      "loss": 3.2488,
      "step": 670
    },
    {
      "epoch": 0.029267452870792805,
      "grad_norm": 1.2398502826690674,
      "learning_rate": 6.491395793499044e-05,
      "loss": 3.2378,
      "step": 680
    },
    {
      "epoch": 0.029697856589480934,
      "grad_norm": 1.2598360776901245,
      "learning_rate": 6.586998087954111e-05,
      "loss": 3.2071,
      "step": 690
    },
    {
      "epoch": 0.030128260308169064,
      "grad_norm": 1.3024451732635498,
      "learning_rate": 6.682600382409177e-05,
      "loss": 3.2886,
      "step": 700
    },
    {
      "epoch": 0.030128260308169064,
      "eval_bleu": 24.54387348273235,
      "eval_gen_len": 27.164,
      "eval_loss": 2.8809568881988525,
      "eval_runtime": 57.2709,
      "eval_samples_per_second": 17.461,
      "eval_steps_per_second": 1.1,
      "step": 700
    },
    {
      "epoch": 0.030558664026857193,
      "grad_norm": 1.2562509775161743,
      "learning_rate": 6.778202676864245e-05,
      "loss": 3.249,
      "step": 710
    },
    {
      "epoch": 0.030989067745545322,
      "grad_norm": 1.2168158292770386,
      "learning_rate": 6.873804971319312e-05,
      "loss": 3.25,
      "step": 720
    },
    {
      "epoch": 0.03141947146423345,
      "grad_norm": 1.231040120124817,
      "learning_rate": 6.96940726577438e-05,
      "loss": 3.3402,
      "step": 730
    },
    {
      "epoch": 0.03184987518292158,
      "grad_norm": 1.3880674839019775,
      "learning_rate": 7.065009560229447e-05,
      "loss": 3.3429,
      "step": 740
    },
    {
      "epoch": 0.03228027890160971,
      "grad_norm": 1.3102328777313232,
      "learning_rate": 7.160611854684513e-05,
      "loss": 3.2721,
      "step": 750
    },
    {
      "epoch": 0.03228027890160971,
      "eval_bleu": 25.47436148695641,
      "eval_gen_len": 27.26,
      "eval_loss": 2.875523567199707,
      "eval_runtime": 56.6577,
      "eval_samples_per_second": 17.65,
      "eval_steps_per_second": 1.112,
      "step": 750
    },
    {
      "epoch": 0.03271068262029784,
      "grad_norm": 1.5233298540115356,
      "learning_rate": 7.256214149139579e-05,
      "loss": 3.312,
      "step": 760
    },
    {
      "epoch": 0.03314108633898597,
      "grad_norm": 1.4420799016952515,
      "learning_rate": 7.351816443594646e-05,
      "loss": 3.1808,
      "step": 770
    },
    {
      "epoch": 0.0335714900576741,
      "grad_norm": 1.148765206336975,
      "learning_rate": 7.447418738049714e-05,
      "loss": 3.3636,
      "step": 780
    },
    {
      "epoch": 0.03400189377636223,
      "grad_norm": 1.3604127168655396,
      "learning_rate": 7.54302103250478e-05,
      "loss": 3.2136,
      "step": 790
    },
    {
      "epoch": 0.034432297495050355,
      "grad_norm": 1.2999773025512695,
      "learning_rate": 7.638623326959847e-05,
      "loss": 3.289,
      "step": 800
    },
    {
      "epoch": 0.034432297495050355,
      "eval_bleu": 25.445463068089055,
      "eval_gen_len": 27.264,
      "eval_loss": 2.8708486557006836,
      "eval_runtime": 57.5042,
      "eval_samples_per_second": 17.39,
      "eval_steps_per_second": 1.096,
      "step": 800
    },
    {
      "epoch": 0.03486270121373849,
      "grad_norm": 1.2611420154571533,
      "learning_rate": 7.734225621414915e-05,
      "loss": 3.2818,
      "step": 810
    },
    {
      "epoch": 0.035293104932426614,
      "grad_norm": 1.5337308645248413,
      "learning_rate": 7.829827915869982e-05,
      "loss": 3.2655,
      "step": 820
    },
    {
      "epoch": 0.035723508651114746,
      "grad_norm": 1.178931713104248,
      "learning_rate": 7.925430210325048e-05,
      "loss": 3.2083,
      "step": 830
    },
    {
      "epoch": 0.03615391236980287,
      "grad_norm": 1.3846242427825928,
      "learning_rate": 8.021032504780115e-05,
      "loss": 3.2425,
      "step": 840
    },
    {
      "epoch": 0.036584316088491005,
      "grad_norm": 1.2023563385009766,
      "learning_rate": 8.116634799235181e-05,
      "loss": 3.2883,
      "step": 850
    },
    {
      "epoch": 0.036584316088491005,
      "eval_bleu": 24.854200834213557,
      "eval_gen_len": 27.183,
      "eval_loss": 2.8786513805389404,
      "eval_runtime": 57.272,
      "eval_samples_per_second": 17.461,
      "eval_steps_per_second": 1.1,
      "step": 850
    },
    {
      "epoch": 0.03701471980717913,
      "grad_norm": 1.258606195449829,
      "learning_rate": 8.212237093690249e-05,
      "loss": 3.1383,
      "step": 860
    },
    {
      "epoch": 0.03744512352586726,
      "grad_norm": 1.2301732301712036,
      "learning_rate": 8.307839388145315e-05,
      "loss": 3.2608,
      "step": 870
    },
    {
      "epoch": 0.037875527244555396,
      "grad_norm": 1.3352291584014893,
      "learning_rate": 8.403441682600382e-05,
      "loss": 3.3171,
      "step": 880
    },
    {
      "epoch": 0.03830593096324352,
      "grad_norm": 1.2751888036727905,
      "learning_rate": 8.49904397705545e-05,
      "loss": 3.3612,
      "step": 890
    },
    {
      "epoch": 0.038736334681931654,
      "grad_norm": 1.3577942848205566,
      "learning_rate": 8.594646271510517e-05,
      "loss": 3.3777,
      "step": 900
    },
    {
      "epoch": 0.038736334681931654,
      "eval_bleu": 25.292780480421353,
      "eval_gen_len": 27.085,
      "eval_loss": 2.8779797554016113,
      "eval_runtime": 56.4034,
      "eval_samples_per_second": 17.729,
      "eval_steps_per_second": 1.117,
      "step": 900
    },
    {
      "epoch": 0.03916673840061978,
      "grad_norm": 1.184086561203003,
      "learning_rate": 8.690248565965584e-05,
      "loss": 3.2434,
      "step": 910
    },
    {
      "epoch": 0.03959714211930791,
      "grad_norm": 1.0699185132980347,
      "learning_rate": 8.78585086042065e-05,
      "loss": 3.2107,
      "step": 920
    },
    {
      "epoch": 0.04002754583799604,
      "grad_norm": 1.27617609500885,
      "learning_rate": 8.881453154875718e-05,
      "loss": 3.2864,
      "step": 930
    },
    {
      "epoch": 0.04045794955668417,
      "grad_norm": 1.340863823890686,
      "learning_rate": 8.977055449330784e-05,
      "loss": 3.3899,
      "step": 940
    },
    {
      "epoch": 0.0408883532753723,
      "grad_norm": 1.2452749013900757,
      "learning_rate": 9.072657743785851e-05,
      "loss": 3.2152,
      "step": 950
    },
    {
      "epoch": 0.0408883532753723,
      "eval_bleu": 25.036797258989715,
      "eval_gen_len": 27.175,
      "eval_loss": 2.876804828643799,
      "eval_runtime": 56.7778,
      "eval_samples_per_second": 17.613,
      "eval_steps_per_second": 1.11,
      "step": 950
    },
    {
      "epoch": 0.04131875699406043,
      "grad_norm": 1.1561095714569092,
      "learning_rate": 9.168260038240917e-05,
      "loss": 3.2722,
      "step": 960
    },
    {
      "epoch": 0.041749160712748555,
      "grad_norm": 1.2392487525939941,
      "learning_rate": 9.263862332695985e-05,
      "loss": 3.3156,
      "step": 970
    },
    {
      "epoch": 0.04217956443143669,
      "grad_norm": 1.3859269618988037,
      "learning_rate": 9.359464627151052e-05,
      "loss": 3.2238,
      "step": 980
    },
    {
      "epoch": 0.04260996815012482,
      "grad_norm": 1.2753137350082397,
      "learning_rate": 9.45506692160612e-05,
      "loss": 3.2545,
      "step": 990
    },
    {
      "epoch": 0.043040371868812946,
      "grad_norm": 1.3701846599578857,
      "learning_rate": 9.550669216061186e-05,
      "loss": 3.2689,
      "step": 1000
    },
    {
      "epoch": 0.043040371868812946,
      "eval_bleu": 25.0500132305641,
      "eval_gen_len": 27.088,
      "eval_loss": 2.881568431854248,
      "eval_runtime": 57.0504,
      "eval_samples_per_second": 17.528,
      "eval_steps_per_second": 1.104,
      "step": 1000
    },
    {
      "epoch": 0.04347077558750108,
      "grad_norm": 1.240537405014038,
      "learning_rate": 9.646271510516253e-05,
      "loss": 3.256,
      "step": 1010
    },
    {
      "epoch": 0.043901179306189204,
      "grad_norm": 1.317462682723999,
      "learning_rate": 9.74187380497132e-05,
      "loss": 3.2366,
      "step": 1020
    },
    {
      "epoch": 0.04433158302487734,
      "grad_norm": 1.3063018321990967,
      "learning_rate": 9.837476099426386e-05,
      "loss": 3.2534,
      "step": 1030
    },
    {
      "epoch": 0.04476198674356546,
      "grad_norm": 1.1319763660430908,
      "learning_rate": 9.933078393881452e-05,
      "loss": 3.1809,
      "step": 1040
    },
    {
      "epoch": 0.045192390462253595,
      "grad_norm": 1.2731056213378906,
      "learning_rate": 0.0001002868068833652,
      "loss": 3.1899,
      "step": 1050
    },
    {
      "epoch": 0.045192390462253595,
      "eval_bleu": 24.80677632431802,
      "eval_gen_len": 27.036,
      "eval_loss": 2.876093864440918,
      "eval_runtime": 56.2292,
      "eval_samples_per_second": 17.784,
      "eval_steps_per_second": 1.12,
      "step": 1050
    },
    {
      "epoch": 0.04562279418094172,
      "grad_norm": 1.3168785572052002,
      "learning_rate": 0.00010124282982791586,
      "loss": 3.2692,
      "step": 1060
    },
    {
      "epoch": 0.046053197899629854,
      "grad_norm": 1.178458571434021,
      "learning_rate": 0.00010219885277246655,
      "loss": 3.2474,
      "step": 1070
    },
    {
      "epoch": 0.04648360161831798,
      "grad_norm": 1.3205496072769165,
      "learning_rate": 0.00010315487571701721,
      "loss": 3.2069,
      "step": 1080
    },
    {
      "epoch": 0.04691400533700611,
      "grad_norm": 1.14223051071167,
      "learning_rate": 0.0001041108986615679,
      "loss": 3.2183,
      "step": 1090
    },
    {
      "epoch": 0.04734440905569424,
      "grad_norm": 1.1355775594711304,
      "learning_rate": 0.00010506692160611856,
      "loss": 3.2774,
      "step": 1100
    },
    {
      "epoch": 0.04734440905569424,
      "eval_bleu": 25.487084582949773,
      "eval_gen_len": 27.314,
      "eval_loss": 2.8737332820892334,
      "eval_runtime": 56.8041,
      "eval_samples_per_second": 17.604,
      "eval_steps_per_second": 1.109,
      "step": 1100
    },
    {
      "epoch": 0.04777481277438237,
      "grad_norm": 1.2086478471755981,
      "learning_rate": 0.00010602294455066922,
      "loss": 3.2287,
      "step": 1110
    },
    {
      "epoch": 0.0482052164930705,
      "grad_norm": 1.1256048679351807,
      "learning_rate": 0.00010697896749521989,
      "loss": 3.187,
      "step": 1120
    },
    {
      "epoch": 0.04863562021175863,
      "grad_norm": 1.1459156274795532,
      "learning_rate": 0.00010793499043977055,
      "loss": 3.2986,
      "step": 1130
    },
    {
      "epoch": 0.04906602393044676,
      "grad_norm": 1.186097502708435,
      "learning_rate": 0.00010889101338432124,
      "loss": 3.2812,
      "step": 1140
    },
    {
      "epoch": 0.04949642764913489,
      "grad_norm": 1.247374415397644,
      "learning_rate": 0.0001098470363288719,
      "loss": 3.3532,
      "step": 1150
    },
    {
      "epoch": 0.04949642764913489,
      "eval_bleu": 25.01785751061386,
      "eval_gen_len": 27.291,
      "eval_loss": 2.8797030448913574,
      "eval_runtime": 58.1321,
      "eval_samples_per_second": 17.202,
      "eval_steps_per_second": 1.084,
      "step": 1150
    },
    {
      "epoch": 0.04992683136782302,
      "grad_norm": 1.3956917524337769,
      "learning_rate": 0.00011080305927342256,
      "loss": 3.2724,
      "step": 1160
    },
    {
      "epoch": 0.050357235086511146,
      "grad_norm": 1.138282299041748,
      "learning_rate": 0.00011175908221797325,
      "loss": 3.1971,
      "step": 1170
    },
    {
      "epoch": 0.05078763880519928,
      "grad_norm": 1.2062106132507324,
      "learning_rate": 0.0001127151051625239,
      "loss": 3.2028,
      "step": 1180
    },
    {
      "epoch": 0.051218042523887404,
      "grad_norm": 1.330043077468872,
      "learning_rate": 0.00011367112810707457,
      "loss": 3.2902,
      "step": 1190
    },
    {
      "epoch": 0.05164844624257554,
      "grad_norm": 1.2101198434829712,
      "learning_rate": 0.00011462715105162525,
      "loss": 3.2399,
      "step": 1200
    },
    {
      "epoch": 0.05164844624257554,
      "eval_bleu": 25.33165680949369,
      "eval_gen_len": 27.332,
      "eval_loss": 2.877065420150757,
      "eval_runtime": 57.6017,
      "eval_samples_per_second": 17.361,
      "eval_steps_per_second": 1.094,
      "step": 1200
    },
    {
      "epoch": 0.05207884996126366,
      "grad_norm": 1.2919551134109497,
      "learning_rate": 0.00011558317399617591,
      "loss": 3.2454,
      "step": 1210
    },
    {
      "epoch": 0.052509253679951795,
      "grad_norm": 1.3192377090454102,
      "learning_rate": 0.00011653919694072659,
      "loss": 3.2309,
      "step": 1220
    },
    {
      "epoch": 0.05293965739863993,
      "grad_norm": 1.1211682558059692,
      "learning_rate": 0.00011749521988527725,
      "loss": 3.3313,
      "step": 1230
    },
    {
      "epoch": 0.05337006111732805,
      "grad_norm": 1.267964243888855,
      "learning_rate": 0.00011845124282982791,
      "loss": 3.17,
      "step": 1240
    },
    {
      "epoch": 0.053800464836016186,
      "grad_norm": 1.2920054197311401,
      "learning_rate": 0.0001194072657743786,
      "loss": 3.1769,
      "step": 1250
    },
    {
      "epoch": 0.053800464836016186,
      "eval_bleu": 25.411211618721733,
      "eval_gen_len": 27.339,
      "eval_loss": 2.875910758972168,
      "eval_runtime": 57.5434,
      "eval_samples_per_second": 17.378,
      "eval_steps_per_second": 1.095,
      "step": 1250
    },
    {
      "epoch": 0.05423086855470431,
      "grad_norm": 1.3934154510498047,
      "learning_rate": 0.00012036328871892926,
      "loss": 3.282,
      "step": 1260
    },
    {
      "epoch": 0.054661272273392444,
      "grad_norm": 1.0501891374588013,
      "learning_rate": 0.00012131931166347994,
      "loss": 3.1176,
      "step": 1270
    },
    {
      "epoch": 0.05509167599208057,
      "grad_norm": 1.1334882974624634,
      "learning_rate": 0.0001222753346080306,
      "loss": 3.2568,
      "step": 1280
    },
    {
      "epoch": 0.0555220797107687,
      "grad_norm": 1.2418369054794312,
      "learning_rate": 0.00012323135755258125,
      "loss": 3.2033,
      "step": 1290
    },
    {
      "epoch": 0.05595248342945683,
      "grad_norm": 1.1590495109558105,
      "learning_rate": 0.00012418738049713195,
      "loss": 3.2578,
      "step": 1300
    },
    {
      "epoch": 0.05595248342945683,
      "eval_bleu": 25.130496576990815,
      "eval_gen_len": 27.07,
      "eval_loss": 2.8767967224121094,
      "eval_runtime": 56.9287,
      "eval_samples_per_second": 17.566,
      "eval_steps_per_second": 1.107,
      "step": 1300
    },
    {
      "epoch": 0.05638288714814496,
      "grad_norm": 1.3249887228012085,
      "learning_rate": 0.0001251434034416826,
      "loss": 3.2509,
      "step": 1310
    },
    {
      "epoch": 0.05681329086683309,
      "grad_norm": 1.3436921834945679,
      "learning_rate": 0.00012609942638623327,
      "loss": 3.1955,
      "step": 1320
    },
    {
      "epoch": 0.05724369458552122,
      "grad_norm": 1.2527172565460205,
      "learning_rate": 0.00012705544933078395,
      "loss": 3.165,
      "step": 1330
    },
    {
      "epoch": 0.057674098304209345,
      "grad_norm": 1.383447289466858,
      "learning_rate": 0.00012801147227533462,
      "loss": 3.2923,
      "step": 1340
    },
    {
      "epoch": 0.05810450202289748,
      "grad_norm": 1.3430432081222534,
      "learning_rate": 0.0001289674952198853,
      "loss": 3.2561,
      "step": 1350
    },
    {
      "epoch": 0.05810450202289748,
      "eval_bleu": 25.471058711013484,
      "eval_gen_len": 27.2,
      "eval_loss": 2.8766095638275146,
      "eval_runtime": 58.0941,
      "eval_samples_per_second": 17.213,
      "eval_steps_per_second": 1.084,
      "step": 1350
    },
    {
      "epoch": 0.05853490574158561,
      "grad_norm": 1.2682093381881714,
      "learning_rate": 0.00012992351816443594,
      "loss": 3.2593,
      "step": 1360
    },
    {
      "epoch": 0.058965309460273736,
      "grad_norm": 1.289608120918274,
      "learning_rate": 0.00013087954110898662,
      "loss": 3.3917,
      "step": 1370
    },
    {
      "epoch": 0.05939571317896187,
      "grad_norm": 1.1768721342086792,
      "learning_rate": 0.0001318355640535373,
      "loss": 3.1405,
      "step": 1380
    },
    {
      "epoch": 0.059826116897649995,
      "grad_norm": 1.333670973777771,
      "learning_rate": 0.00013279158699808796,
      "loss": 3.1811,
      "step": 1390
    },
    {
      "epoch": 0.06025652061633813,
      "grad_norm": 1.2571231126785278,
      "learning_rate": 0.0001337476099426386,
      "loss": 3.1475,
      "step": 1400
    },
    {
      "epoch": 0.06025652061633813,
      "eval_bleu": 25.84757266509269,
      "eval_gen_len": 27.189,
      "eval_loss": 2.8737576007843018,
      "eval_runtime": 57.9628,
      "eval_samples_per_second": 17.252,
      "eval_steps_per_second": 1.087,
      "step": 1400
    },
    {
      "epoch": 0.06068692433502625,
      "grad_norm": 1.2710716724395752,
      "learning_rate": 0.0001347036328871893,
      "loss": 3.269,
      "step": 1410
    },
    {
      "epoch": 0.061117328053714386,
      "grad_norm": 1.2336152791976929,
      "learning_rate": 0.00013565965583173996,
      "loss": 3.2627,
      "step": 1420
    },
    {
      "epoch": 0.06154773177240251,
      "grad_norm": 1.3436957597732544,
      "learning_rate": 0.00013661567877629063,
      "loss": 3.3139,
      "step": 1430
    },
    {
      "epoch": 0.061978135491090644,
      "grad_norm": 1.1996783018112183,
      "learning_rate": 0.0001375717017208413,
      "loss": 3.2466,
      "step": 1440
    },
    {
      "epoch": 0.06240853920977877,
      "grad_norm": 1.1737582683563232,
      "learning_rate": 0.00013852772466539195,
      "loss": 3.2059,
      "step": 1450
    },
    {
      "epoch": 0.06240853920977877,
      "eval_bleu": 25.47880050321247,
      "eval_gen_len": 27.225,
      "eval_loss": 2.873514413833618,
      "eval_runtime": 58.3323,
      "eval_samples_per_second": 17.143,
      "eval_steps_per_second": 1.08,
      "step": 1450
    },
    {
      "epoch": 0.0628389429284669,
      "grad_norm": 1.2060585021972656,
      "learning_rate": 0.00013948374760994265,
      "loss": 3.1303,
      "step": 1460
    },
    {
      "epoch": 0.06326934664715503,
      "grad_norm": 1.0364371538162231,
      "learning_rate": 0.0001404397705544933,
      "loss": 3.2326,
      "step": 1470
    },
    {
      "epoch": 0.06369975036584316,
      "grad_norm": 1.1459945440292358,
      "learning_rate": 0.000141395793499044,
      "loss": 3.1859,
      "step": 1480
    },
    {
      "epoch": 0.0641301540845313,
      "grad_norm": 1.090523600578308,
      "learning_rate": 0.00014235181644359465,
      "loss": 3.2339,
      "step": 1490
    },
    {
      "epoch": 0.06456055780321943,
      "grad_norm": 1.1613396406173706,
      "learning_rate": 0.00014330783938814532,
      "loss": 3.2343,
      "step": 1500
    },
    {
      "epoch": 0.06456055780321943,
      "eval_bleu": 25.233119785576203,
      "eval_gen_len": 27.196,
      "eval_loss": 2.8716654777526855,
      "eval_runtime": 57.796,
      "eval_samples_per_second": 17.302,
      "eval_steps_per_second": 1.09,
      "step": 1500
    },
    {
      "epoch": 0.06499096152190754,
      "grad_norm": 1.2282541990280151,
      "learning_rate": 0.000144263862332696,
      "loss": 3.2336,
      "step": 1510
    },
    {
      "epoch": 0.06542136524059568,
      "grad_norm": 1.414649248123169,
      "learning_rate": 0.00014521988527724667,
      "loss": 3.2186,
      "step": 1520
    },
    {
      "epoch": 0.06585176895928381,
      "grad_norm": 1.1919753551483154,
      "learning_rate": 0.00014617590822179732,
      "loss": 3.2276,
      "step": 1530
    },
    {
      "epoch": 0.06628217267797194,
      "grad_norm": 1.1904233694076538,
      "learning_rate": 0.000147131931166348,
      "loss": 3.2613,
      "step": 1540
    },
    {
      "epoch": 0.06671257639666006,
      "grad_norm": 1.1469265222549438,
      "learning_rate": 0.00014808795411089867,
      "loss": 3.195,
      "step": 1550
    },
    {
      "epoch": 0.06671257639666006,
      "eval_bleu": 24.489160329915943,
      "eval_gen_len": 27.211,
      "eval_loss": 2.882389545440674,
      "eval_runtime": 57.9604,
      "eval_samples_per_second": 17.253,
      "eval_steps_per_second": 1.087,
      "step": 1550
    },
    {
      "epoch": 0.0671429801153482,
      "grad_norm": 1.2232705354690552,
      "learning_rate": 0.00014904397705544934,
      "loss": 3.1997,
      "step": 1560
    },
    {
      "epoch": 0.06757338383403633,
      "grad_norm": 1.13728928565979,
      "learning_rate": 0.00015000000000000001,
      "loss": 3.2143,
      "step": 1570
    },
    {
      "epoch": 0.06800378755272446,
      "grad_norm": 1.1255422830581665,
      "learning_rate": 0.00015095602294455066,
      "loss": 3.2149,
      "step": 1580
    },
    {
      "epoch": 0.06843419127141258,
      "grad_norm": 1.1333558559417725,
      "learning_rate": 0.00015191204588910136,
      "loss": 3.2629,
      "step": 1590
    },
    {
      "epoch": 0.06886459499010071,
      "grad_norm": 1.2136701345443726,
      "learning_rate": 0.000152868068833652,
      "loss": 3.2771,
      "step": 1600
    },
    {
      "epoch": 0.06886459499010071,
      "eval_bleu": 24.925168861486068,
      "eval_gen_len": 27.212,
      "eval_loss": 2.8770053386688232,
      "eval_runtime": 57.7802,
      "eval_samples_per_second": 17.307,
      "eval_steps_per_second": 1.09,
      "step": 1600
    },
    {
      "epoch": 0.06929499870878884,
      "grad_norm": 1.2273093461990356,
      "learning_rate": 0.00015382409177820268,
      "loss": 3.2805,
      "step": 1610
    },
    {
      "epoch": 0.06972540242747698,
      "grad_norm": 1.256893515586853,
      "learning_rate": 0.00015478011472275336,
      "loss": 3.1659,
      "step": 1620
    },
    {
      "epoch": 0.07015580614616511,
      "grad_norm": 1.2948123216629028,
      "learning_rate": 0.000155736137667304,
      "loss": 3.2866,
      "step": 1630
    },
    {
      "epoch": 0.07058620986485323,
      "grad_norm": 1.1549721956253052,
      "learning_rate": 0.0001566921606118547,
      "loss": 3.267,
      "step": 1640
    },
    {
      "epoch": 0.07101661358354136,
      "grad_norm": 1.1847724914550781,
      "learning_rate": 0.00015764818355640535,
      "loss": 3.1935,
      "step": 1650
    },
    {
      "epoch": 0.07101661358354136,
      "eval_bleu": 25.25922312318242,
      "eval_gen_len": 27.397,
      "eval_loss": 2.875014305114746,
      "eval_runtime": 58.6263,
      "eval_samples_per_second": 17.057,
      "eval_steps_per_second": 1.075,
      "step": 1650
    },
    {
      "epoch": 0.07144701730222949,
      "grad_norm": 1.1933836936950684,
      "learning_rate": 0.00015860420650095603,
      "loss": 3.1971,
      "step": 1660
    },
    {
      "epoch": 0.07187742102091763,
      "grad_norm": 1.2039945125579834,
      "learning_rate": 0.0001595602294455067,
      "loss": 3.2291,
      "step": 1670
    },
    {
      "epoch": 0.07230782473960574,
      "grad_norm": 1.193216323852539,
      "learning_rate": 0.00016051625239005737,
      "loss": 3.2402,
      "step": 1680
    },
    {
      "epoch": 0.07273822845829388,
      "grad_norm": 1.2032792568206787,
      "learning_rate": 0.00016147227533460805,
      "loss": 3.2713,
      "step": 1690
    },
    {
      "epoch": 0.07316863217698201,
      "grad_norm": 1.1015570163726807,
      "learning_rate": 0.00016242829827915872,
      "loss": 3.3283,
      "step": 1700
    },
    {
      "epoch": 0.07316863217698201,
      "eval_bleu": 24.811677678618057,
      "eval_gen_len": 27.17,
      "eval_loss": 2.8750598430633545,
      "eval_runtime": 57.975,
      "eval_samples_per_second": 17.249,
      "eval_steps_per_second": 1.087,
      "step": 1700
    },
    {
      "epoch": 0.07359903589567014,
      "grad_norm": 1.0049409866333008,
      "learning_rate": 0.00016338432122370937,
      "loss": 3.1268,
      "step": 1710
    },
    {
      "epoch": 0.07402943961435826,
      "grad_norm": 1.0393179655075073,
      "learning_rate": 0.00016434034416826004,
      "loss": 3.1969,
      "step": 1720
    },
    {
      "epoch": 0.0744598433330464,
      "grad_norm": 1.2331126928329468,
      "learning_rate": 0.00016529636711281072,
      "loss": 3.2495,
      "step": 1730
    },
    {
      "epoch": 0.07489024705173453,
      "grad_norm": 1.1047512292861938,
      "learning_rate": 0.0001662523900573614,
      "loss": 3.1399,
      "step": 1740
    },
    {
      "epoch": 0.07532065077042266,
      "grad_norm": 1.1742446422576904,
      "learning_rate": 0.00016720841300191206,
      "loss": 3.2703,
      "step": 1750
    },
    {
      "epoch": 0.07532065077042266,
      "eval_bleu": 25.241242864134033,
      "eval_gen_len": 27.242,
      "eval_loss": 2.8732948303222656,
      "eval_runtime": 58.0612,
      "eval_samples_per_second": 17.223,
      "eval_steps_per_second": 1.085,
      "step": 1750
    },
    {
      "epoch": 0.07575105448911079,
      "grad_norm": 1.3427127599716187,
      "learning_rate": 0.0001681644359464627,
      "loss": 3.2501,
      "step": 1760
    },
    {
      "epoch": 0.07618145820779891,
      "grad_norm": 1.0359169244766235,
      "learning_rate": 0.0001691204588910134,
      "loss": 3.1099,
      "step": 1770
    },
    {
      "epoch": 0.07661186192648704,
      "grad_norm": 1.0012140274047852,
      "learning_rate": 0.00017007648183556406,
      "loss": 3.194,
      "step": 1780
    },
    {
      "epoch": 0.07704226564517518,
      "grad_norm": 1.1030772924423218,
      "learning_rate": 0.00017103250478011473,
      "loss": 3.2596,
      "step": 1790
    },
    {
      "epoch": 0.07747266936386331,
      "grad_norm": 1.2786864042282104,
      "learning_rate": 0.0001719885277246654,
      "loss": 3.1431,
      "step": 1800
    },
    {
      "epoch": 0.07747266936386331,
      "eval_bleu": 25.31937455429668,
      "eval_gen_len": 27.255,
      "eval_loss": 2.868709087371826,
      "eval_runtime": 58.1109,
      "eval_samples_per_second": 17.208,
      "eval_steps_per_second": 1.084,
      "step": 1800
    },
    {
      "epoch": 0.07790307308255143,
      "grad_norm": 1.0882432460784912,
      "learning_rate": 0.00017294455066921605,
      "loss": 3.1898,
      "step": 1810
    },
    {
      "epoch": 0.07833347680123956,
      "grad_norm": 1.1105990409851074,
      "learning_rate": 0.00017390057361376675,
      "loss": 3.2265,
      "step": 1820
    },
    {
      "epoch": 0.07876388051992769,
      "grad_norm": 1.1106222867965698,
      "learning_rate": 0.0001748565965583174,
      "loss": 3.2298,
      "step": 1830
    },
    {
      "epoch": 0.07919428423861583,
      "grad_norm": 1.019593596458435,
      "learning_rate": 0.00017581261950286808,
      "loss": 3.3072,
      "step": 1840
    },
    {
      "epoch": 0.07962468795730396,
      "grad_norm": 1.1573444604873657,
      "learning_rate": 0.00017676864244741875,
      "loss": 3.2665,
      "step": 1850
    },
    {
      "epoch": 0.07962468795730396,
      "eval_bleu": 25.088639944634483,
      "eval_gen_len": 27.279,
      "eval_loss": 2.8762729167938232,
      "eval_runtime": 58.816,
      "eval_samples_per_second": 17.002,
      "eval_steps_per_second": 1.071,
      "step": 1850
    },
    {
      "epoch": 0.08005509167599208,
      "grad_norm": 1.0820512771606445,
      "learning_rate": 0.00017772466539196942,
      "loss": 3.2525,
      "step": 1860
    },
    {
      "epoch": 0.08048549539468021,
      "grad_norm": 1.070158839225769,
      "learning_rate": 0.00017868068833652007,
      "loss": 3.2533,
      "step": 1870
    },
    {
      "epoch": 0.08091589911336834,
      "grad_norm": 1.0870660543441772,
      "learning_rate": 0.00017963671128107077,
      "loss": 3.1684,
      "step": 1880
    },
    {
      "epoch": 0.08134630283205647,
      "grad_norm": 1.188638687133789,
      "learning_rate": 0.00018059273422562142,
      "loss": 3.182,
      "step": 1890
    },
    {
      "epoch": 0.0817767065507446,
      "grad_norm": 1.0295311212539673,
      "learning_rate": 0.0001815487571701721,
      "loss": 3.3081,
      "step": 1900
    },
    {
      "epoch": 0.0817767065507446,
      "eval_bleu": 24.6615558576856,
      "eval_gen_len": 27.45,
      "eval_loss": 2.8759827613830566,
      "eval_runtime": 58.8743,
      "eval_samples_per_second": 16.985,
      "eval_steps_per_second": 1.07,
      "step": 1900
    },
    {
      "epoch": 0.08220711026943273,
      "grad_norm": 1.09415602684021,
      "learning_rate": 0.00018250478011472277,
      "loss": 3.2185,
      "step": 1910
    },
    {
      "epoch": 0.08263751398812086,
      "grad_norm": 1.0572093725204468,
      "learning_rate": 0.0001834608030592734,
      "loss": 3.1686,
      "step": 1920
    },
    {
      "epoch": 0.08306791770680899,
      "grad_norm": 1.181727647781372,
      "learning_rate": 0.00018441682600382411,
      "loss": 3.2337,
      "step": 1930
    },
    {
      "epoch": 0.08349832142549711,
      "grad_norm": 1.1685264110565186,
      "learning_rate": 0.00018537284894837476,
      "loss": 3.1997,
      "step": 1940
    },
    {
      "epoch": 0.08392872514418524,
      "grad_norm": 1.1659108400344849,
      "learning_rate": 0.00018632887189292546,
      "loss": 3.0963,
      "step": 1950
    },
    {
      "epoch": 0.08392872514418524,
      "eval_bleu": 25.53205254827961,
      "eval_gen_len": 27.357,
      "eval_loss": 2.8738386631011963,
      "eval_runtime": 58.3461,
      "eval_samples_per_second": 17.139,
      "eval_steps_per_second": 1.08,
      "step": 1950
    },
    {
      "epoch": 0.08435912886287338,
      "grad_norm": 1.1258618831634521,
      "learning_rate": 0.0001872848948374761,
      "loss": 3.1759,
      "step": 1960
    },
    {
      "epoch": 0.08478953258156151,
      "grad_norm": 1.1500712633132935,
      "learning_rate": 0.00018824091778202678,
      "loss": 3.2333,
      "step": 1970
    },
    {
      "epoch": 0.08521993630024964,
      "grad_norm": 0.8455663323402405,
      "learning_rate": 0.00018919694072657746,
      "loss": 3.1115,
      "step": 1980
    },
    {
      "epoch": 0.08565034001893776,
      "grad_norm": 1.1867493391036987,
      "learning_rate": 0.0001901529636711281,
      "loss": 3.1269,
      "step": 1990
    },
    {
      "epoch": 0.08608074373762589,
      "grad_norm": 1.0023276805877686,
      "learning_rate": 0.00019110898661567878,
      "loss": 3.1572,
      "step": 2000
    },
    {
      "epoch": 0.08608074373762589,
      "eval_bleu": 25.11663626038272,
      "eval_gen_len": 27.352,
      "eval_loss": 2.8788204193115234,
      "eval_runtime": 57.6105,
      "eval_samples_per_second": 17.358,
      "eval_steps_per_second": 1.094,
      "step": 2000
    },
    {
      "epoch": 0.08651114745631402,
      "grad_norm": 1.0250756740570068,
      "learning_rate": 0.00019206500956022945,
      "loss": 3.219,
      "step": 2010
    },
    {
      "epoch": 0.08694155117500216,
      "grad_norm": 1.1559903621673584,
      "learning_rate": 0.00019302103250478012,
      "loss": 3.2688,
      "step": 2020
    },
    {
      "epoch": 0.08737195489369028,
      "grad_norm": 1.2554683685302734,
      "learning_rate": 0.0001939770554493308,
      "loss": 3.2148,
      "step": 2030
    },
    {
      "epoch": 0.08780235861237841,
      "grad_norm": 1.0748213529586792,
      "learning_rate": 0.00019493307839388147,
      "loss": 3.1436,
      "step": 2040
    },
    {
      "epoch": 0.08823276233106654,
      "grad_norm": 1.0834312438964844,
      "learning_rate": 0.00019588910133843212,
      "loss": 3.2534,
      "step": 2050
    },
    {
      "epoch": 0.08823276233106654,
      "eval_bleu": 24.756304792836143,
      "eval_gen_len": 27.318,
      "eval_loss": 2.879664897918701,
      "eval_runtime": 59.1265,
      "eval_samples_per_second": 16.913,
      "eval_steps_per_second": 1.066,
      "step": 2050
    },
    {
      "epoch": 0.08866316604975467,
      "grad_norm": 1.1791038513183594,
      "learning_rate": 0.0001968451242829828,
      "loss": 3.2561,
      "step": 2060
    },
    {
      "epoch": 0.08909356976844279,
      "grad_norm": 1.0998598337173462,
      "learning_rate": 0.00019780114722753347,
      "loss": 3.3217,
      "step": 2070
    },
    {
      "epoch": 0.08952397348713093,
      "grad_norm": 1.0878416299819946,
      "learning_rate": 0.00019875717017208414,
      "loss": 3.1877,
      "step": 2080
    },
    {
      "epoch": 0.08995437720581906,
      "grad_norm": 1.2807421684265137,
      "learning_rate": 0.00019971319311663482,
      "loss": 3.2634,
      "step": 2090
    },
    {
      "epoch": 0.09038478092450719,
      "grad_norm": 1.192642092704773,
      "learning_rate": 0.00019999999471014275,
      "loss": 3.1805,
      "step": 2100
    },
    {
      "epoch": 0.09038478092450719,
      "eval_bleu": 24.18317396704187,
      "eval_gen_len": 27.206,
      "eval_loss": 2.883521795272827,
      "eval_runtime": 58.0588,
      "eval_samples_per_second": 17.224,
      "eval_steps_per_second": 1.085,
      "step": 2100
    },
    {
      "epoch": 0.09081518464319532,
      "grad_norm": 1.1679607629776,
      "learning_rate": 0.0001999999688006391,
      "loss": 3.1886,
      "step": 2110
    },
    {
      "epoch": 0.09124558836188344,
      "grad_norm": 1.2201964855194092,
      "learning_rate": 0.00019999992129988823,
      "loss": 3.2318,
      "step": 2120
    },
    {
      "epoch": 0.09167599208057158,
      "grad_norm": 1.2031233310699463,
      "learning_rate": 0.00019999985220790038,
      "loss": 3.2315,
      "step": 2130
    },
    {
      "epoch": 0.09210639579925971,
      "grad_norm": 1.083640456199646,
      "learning_rate": 0.00019999976152469052,
      "loss": 3.2752,
      "step": 2140
    },
    {
      "epoch": 0.09253679951794784,
      "grad_norm": 1.1976312398910522,
      "learning_rate": 0.00019999964925027815,
      "loss": 3.2309,
      "step": 2150
    },
    {
      "epoch": 0.09253679951794784,
      "eval_bleu": 24.952427140362786,
      "eval_gen_len": 27.289,
      "eval_loss": 2.876431941986084,
      "eval_runtime": 58.1523,
      "eval_samples_per_second": 17.196,
      "eval_steps_per_second": 1.083,
      "step": 2150
    },
    {
      "epoch": 0.09296720323663596,
      "grad_norm": 0.9653682112693787,
      "learning_rate": 0.00019999951538468756,
      "loss": 3.1287,
      "step": 2160
    },
    {
      "epoch": 0.09339760695532409,
      "grad_norm": 1.006280779838562,
      "learning_rate": 0.00019999935992794763,
      "loss": 3.0953,
      "step": 2170
    },
    {
      "epoch": 0.09382801067401222,
      "grad_norm": 1.0924057960510254,
      "learning_rate": 0.00019999918288009195,
      "loss": 3.2494,
      "step": 2180
    },
    {
      "epoch": 0.09425841439270036,
      "grad_norm": 1.0620625019073486,
      "learning_rate": 0.00019999898424115874,
      "loss": 3.1867,
      "step": 2190
    },
    {
      "epoch": 0.09468881811138848,
      "grad_norm": 1.3098726272583008,
      "learning_rate": 0.00019999876401119088,
      "loss": 3.1929,
      "step": 2200
    },
    {
      "epoch": 0.09468881811138848,
      "eval_bleu": 24.443006634384503,
      "eval_gen_len": 27.212,
      "eval_loss": 2.879002094268799,
      "eval_runtime": 57.8177,
      "eval_samples_per_second": 17.296,
      "eval_steps_per_second": 1.09,
      "step": 2200
    },
    {
      "epoch": 0.09511922183007661,
      "grad_norm": 1.1558374166488647,
      "learning_rate": 0.00019999852219023594,
      "loss": 3.2939,
      "step": 2210
    },
    {
      "epoch": 0.09554962554876474,
      "grad_norm": 1.0357316732406616,
      "learning_rate": 0.00019999825877834611,
      "loss": 3.2331,
      "step": 2220
    },
    {
      "epoch": 0.09598002926745287,
      "grad_norm": 1.15109121799469,
      "learning_rate": 0.00019999797377557826,
      "loss": 3.1353,
      "step": 2230
    },
    {
      "epoch": 0.096410432986141,
      "grad_norm": 1.0330406427383423,
      "learning_rate": 0.00019999766718199394,
      "loss": 3.1022,
      "step": 2240
    },
    {
      "epoch": 0.09684083670482913,
      "grad_norm": 1.183284044265747,
      "learning_rate": 0.00019999733899765936,
      "loss": 3.2677,
      "step": 2250
    },
    {
      "epoch": 0.09684083670482913,
      "eval_bleu": 24.548200725870192,
      "eval_gen_len": 27.278,
      "eval_loss": 2.8791794776916504,
      "eval_runtime": 57.5459,
      "eval_samples_per_second": 17.377,
      "eval_steps_per_second": 1.095,
      "step": 2250
    },
    {
      "epoch": 0.09727124042351726,
      "grad_norm": 1.181990623474121,
      "learning_rate": 0.00019999698922264534,
      "loss": 3.2726,
      "step": 2260
    },
    {
      "epoch": 0.09770164414220539,
      "grad_norm": 1.0374176502227783,
      "learning_rate": 0.00019999661785702742,
      "loss": 3.1788,
      "step": 2270
    },
    {
      "epoch": 0.09813204786089352,
      "grad_norm": 1.0064173936843872,
      "learning_rate": 0.0001999962249008858,
      "loss": 3.1958,
      "step": 2280
    },
    {
      "epoch": 0.09856245157958164,
      "grad_norm": 1.1096978187561035,
      "learning_rate": 0.00019999581035430532,
      "loss": 3.1383,
      "step": 2290
    },
    {
      "epoch": 0.09899285529826977,
      "grad_norm": 1.0812056064605713,
      "learning_rate": 0.00019999537421737547,
      "loss": 3.2722,
      "step": 2300
    },
    {
      "epoch": 0.09899285529826977,
      "eval_bleu": 24.288696918997612,
      "eval_gen_len": 27.353,
      "eval_loss": 2.879150390625,
      "eval_runtime": 57.8744,
      "eval_samples_per_second": 17.279,
      "eval_steps_per_second": 1.089,
      "step": 2300
    },
    {
      "epoch": 0.09942325901695791,
      "grad_norm": 1.1555371284484863,
      "learning_rate": 0.00019999491649019043,
      "loss": 3.0853,
      "step": 2310
    },
    {
      "epoch": 0.09985366273564604,
      "grad_norm": 1.0620895624160767,
      "learning_rate": 0.000199994437172849,
      "loss": 3.1279,
      "step": 2320
    },
    {
      "epoch": 0.10028406645433416,
      "grad_norm": 0.9829036593437195,
      "learning_rate": 0.00019999393626545469,
      "loss": 3.2559,
      "step": 2330
    },
    {
      "epoch": 0.10071447017302229,
      "grad_norm": 1.1453301906585693,
      "learning_rate": 0.00019999341376811567,
      "loss": 3.2783,
      "step": 2340
    },
    {
      "epoch": 0.10114487389171042,
      "grad_norm": 1.1049247980117798,
      "learning_rate": 0.00019999286968094474,
      "loss": 3.1783,
      "step": 2350
    },
    {
      "epoch": 0.10114487389171042,
      "eval_bleu": 23.864041991231076,
      "eval_gen_len": 27.248,
      "eval_loss": 2.876450777053833,
      "eval_runtime": 57.7523,
      "eval_samples_per_second": 17.315,
      "eval_steps_per_second": 1.091,
      "step": 2350
    },
    {
      "epoch": 0.10157527761039856,
      "grad_norm": 1.082008957862854,
      "learning_rate": 0.00019999230400405939,
      "loss": 3.1467,
      "step": 2360
    },
    {
      "epoch": 0.10200568132908669,
      "grad_norm": 1.1573071479797363,
      "learning_rate": 0.0001999917167375817,
      "loss": 3.1209,
      "step": 2370
    },
    {
      "epoch": 0.10243608504777481,
      "grad_norm": 1.1250298023223877,
      "learning_rate": 0.00019999110788163855,
      "loss": 3.2324,
      "step": 2380
    },
    {
      "epoch": 0.10286648876646294,
      "grad_norm": 1.1318690776824951,
      "learning_rate": 0.00019999047743636132,
      "loss": 3.2807,
      "step": 2390
    },
    {
      "epoch": 0.10329689248515107,
      "grad_norm": 1.1144222021102905,
      "learning_rate": 0.0001999898254018862,
      "loss": 3.2422,
      "step": 2400
    },
    {
      "epoch": 0.10329689248515107,
      "eval_bleu": 24.344162956011377,
      "eval_gen_len": 27.302,
      "eval_loss": 2.8755221366882324,
      "eval_runtime": 57.084,
      "eval_samples_per_second": 17.518,
      "eval_steps_per_second": 1.104,
      "step": 2400
    },
    {
      "epoch": 0.1037272962038392,
      "grad_norm": 0.9715502262115479,
      "learning_rate": 0.00019998915177835394,
      "loss": 3.1892,
      "step": 2410
    },
    {
      "epoch": 0.10415769992252732,
      "grad_norm": 1.173471450805664,
      "learning_rate": 0.00019998845656590998,
      "loss": 3.3898,
      "step": 2420
    },
    {
      "epoch": 0.10458810364121546,
      "grad_norm": 1.145419716835022,
      "learning_rate": 0.00019998773976470443,
      "loss": 3.1733,
      "step": 2430
    },
    {
      "epoch": 0.10501850735990359,
      "grad_norm": 1.0819082260131836,
      "learning_rate": 0.00019998700137489206,
      "loss": 3.1309,
      "step": 2440
    },
    {
      "epoch": 0.10544891107859172,
      "grad_norm": 1.1687407493591309,
      "learning_rate": 0.0001999862413966323,
      "loss": 3.2315,
      "step": 2450
    },
    {
      "epoch": 0.10544891107859172,
      "eval_bleu": 25.14933205769361,
      "eval_gen_len": 27.312,
      "eval_loss": 2.8696157932281494,
      "eval_runtime": 58.1228,
      "eval_samples_per_second": 17.205,
      "eval_steps_per_second": 1.084,
      "step": 2450
    },
    {
      "epoch": 0.10587931479727986,
      "grad_norm": 1.0623468160629272,
      "learning_rate": 0.0001999854598300892,
      "loss": 3.1692,
      "step": 2460
    },
    {
      "epoch": 0.10630971851596797,
      "grad_norm": 1.069244146347046,
      "learning_rate": 0.0001999846566754316,
      "loss": 3.127,
      "step": 2470
    },
    {
      "epoch": 0.1067401222346561,
      "grad_norm": 1.2256437540054321,
      "learning_rate": 0.00019998383193283283,
      "loss": 3.2089,
      "step": 2480
    },
    {
      "epoch": 0.10717052595334424,
      "grad_norm": 1.0160223245620728,
      "learning_rate": 0.00019998298560247097,
      "loss": 3.2162,
      "step": 2490
    },
    {
      "epoch": 0.10760092967203237,
      "grad_norm": 1.035974383354187,
      "learning_rate": 0.00019998211768452879,
      "loss": 3.3704,
      "step": 2500
    },
    {
      "epoch": 0.10760092967203237,
      "eval_bleu": 24.580901793726436,
      "eval_gen_len": 27.312,
      "eval_loss": 2.8787424564361572,
      "eval_runtime": 58.2713,
      "eval_samples_per_second": 17.161,
      "eval_steps_per_second": 1.081,
      "step": 2500
    },
    {
      "epoch": 0.10803133339072049,
      "grad_norm": 1.0865142345428467,
      "learning_rate": 0.00019998122817919365,
      "loss": 3.2691,
      "step": 2510
    },
    {
      "epoch": 0.10846173710940862,
      "grad_norm": 1.1311589479446411,
      "learning_rate": 0.00019998031708665765,
      "loss": 3.1041,
      "step": 2520
    },
    {
      "epoch": 0.10889214082809676,
      "grad_norm": 1.1540583372116089,
      "learning_rate": 0.00019997938440711744,
      "loss": 3.2608,
      "step": 2530
    },
    {
      "epoch": 0.10932254454678489,
      "grad_norm": 1.1178913116455078,
      "learning_rate": 0.00019997843014077447,
      "loss": 3.2643,
      "step": 2540
    },
    {
      "epoch": 0.10975294826547301,
      "grad_norm": 1.0136334896087646,
      "learning_rate": 0.00019997745428783473,
      "loss": 3.1841,
      "step": 2550
    },
    {
      "epoch": 0.10975294826547301,
      "eval_bleu": 24.14652569769984,
      "eval_gen_len": 27.257,
      "eval_loss": 2.872978687286377,
      "eval_runtime": 58.3579,
      "eval_samples_per_second": 17.136,
      "eval_steps_per_second": 1.08,
      "step": 2550
    },
    {
      "epoch": 0.11018335198416114,
      "grad_norm": 1.1040188074111938,
      "learning_rate": 0.00019997645684850893,
      "loss": 3.1695,
      "step": 2560
    },
    {
      "epoch": 0.11061375570284927,
      "grad_norm": 1.0113285779953003,
      "learning_rate": 0.0001999754378230124,
      "loss": 3.1974,
      "step": 2570
    },
    {
      "epoch": 0.1110441594215374,
      "grad_norm": 1.0058753490447998,
      "learning_rate": 0.00019997439721156521,
      "loss": 3.2201,
      "step": 2580
    },
    {
      "epoch": 0.11147456314022554,
      "grad_norm": 1.0174264907836914,
      "learning_rate": 0.00019997333501439203,
      "loss": 3.2555,
      "step": 2590
    },
    {
      "epoch": 0.11190496685891366,
      "grad_norm": 1.0511369705200195,
      "learning_rate": 0.0001999722512317222,
      "loss": 3.2163,
      "step": 2600
    },
    {
      "epoch": 0.11190496685891366,
      "eval_bleu": 25.480556025924574,
      "eval_gen_len": 27.496,
      "eval_loss": 2.8740618228912354,
      "eval_runtime": 57.7688,
      "eval_samples_per_second": 17.31,
      "eval_steps_per_second": 1.091,
      "step": 2600
    },
    {
      "epoch": 0.11233537057760179,
      "grad_norm": 1.1312055587768555,
      "learning_rate": 0.0001999711458637897,
      "loss": 3.1979,
      "step": 2610
    },
    {
      "epoch": 0.11276577429628992,
      "grad_norm": 1.0461161136627197,
      "learning_rate": 0.00019997001891083324,
      "loss": 3.1956,
      "step": 2620
    },
    {
      "epoch": 0.11319617801497805,
      "grad_norm": 1.0545742511749268,
      "learning_rate": 0.00019996887037309607,
      "loss": 3.1517,
      "step": 2630
    },
    {
      "epoch": 0.11362658173366617,
      "grad_norm": 1.065488338470459,
      "learning_rate": 0.00019996770025082624,
      "loss": 3.2438,
      "step": 2640
    },
    {
      "epoch": 0.1140569854523543,
      "grad_norm": 1.1430076360702515,
      "learning_rate": 0.0001999665085442764,
      "loss": 3.2041,
      "step": 2650
    },
    {
      "epoch": 0.1140569854523543,
      "eval_bleu": 24.692277926212007,
      "eval_gen_len": 27.32,
      "eval_loss": 2.8779799938201904,
      "eval_runtime": 58.0065,
      "eval_samples_per_second": 17.239,
      "eval_steps_per_second": 1.086,
      "step": 2650
    },
    {
      "epoch": 0.11448738917104244,
      "grad_norm": 1.097752332687378,
      "learning_rate": 0.00019996529525370376,
      "loss": 3.1557,
      "step": 2660
    },
    {
      "epoch": 0.11491779288973057,
      "grad_norm": 1.0261101722717285,
      "learning_rate": 0.00019996406037937038,
      "loss": 3.2336,
      "step": 2670
    },
    {
      "epoch": 0.11534819660841869,
      "grad_norm": 1.0615655183792114,
      "learning_rate": 0.00019996280392154284,
      "loss": 3.092,
      "step": 2680
    },
    {
      "epoch": 0.11577860032710682,
      "grad_norm": 1.354414463043213,
      "learning_rate": 0.00019996152588049246,
      "loss": 3.1471,
      "step": 2690
    },
    {
      "epoch": 0.11620900404579496,
      "grad_norm": 0.9500570893287659,
      "learning_rate": 0.00019996022625649515,
      "loss": 3.0874,
      "step": 2700
    },
    {
      "epoch": 0.11620900404579496,
      "eval_bleu": 24.852356212649283,
      "eval_gen_len": 27.497,
      "eval_loss": 2.8737266063690186,
      "eval_runtime": 58.5162,
      "eval_samples_per_second": 17.089,
      "eval_steps_per_second": 1.077,
      "step": 2700
    },
    {
      "epoch": 0.11663940776448309,
      "grad_norm": 1.0886915922164917,
      "learning_rate": 0.00019995890504983155,
      "loss": 3.2491,
      "step": 2710
    },
    {
      "epoch": 0.11706981148317122,
      "grad_norm": 1.0414143800735474,
      "learning_rate": 0.0001999575622607869,
      "loss": 3.1762,
      "step": 2720
    },
    {
      "epoch": 0.11750021520185934,
      "grad_norm": 1.0197526216506958,
      "learning_rate": 0.00019995619788965108,
      "loss": 3.2297,
      "step": 2730
    },
    {
      "epoch": 0.11793061892054747,
      "grad_norm": 1.1793770790100098,
      "learning_rate": 0.00019995481193671878,
      "loss": 3.1735,
      "step": 2740
    },
    {
      "epoch": 0.1183610226392356,
      "grad_norm": 1.0616910457611084,
      "learning_rate": 0.0001999534044022892,
      "loss": 3.118,
      "step": 2750
    },
    {
      "epoch": 0.1183610226392356,
      "eval_bleu": 25.38234836386212,
      "eval_gen_len": 27.348,
      "eval_loss": 2.8726487159729004,
      "eval_runtime": 58.5751,
      "eval_samples_per_second": 17.072,
      "eval_steps_per_second": 1.076,
      "step": 2750
    },
    {
      "epoch": 0.11879142635792374,
      "grad_norm": 1.0504268407821655,
      "learning_rate": 0.00019995197528666618,
      "loss": 3.1518,
      "step": 2760
    },
    {
      "epoch": 0.11922183007661186,
      "grad_norm": 0.907339334487915,
      "learning_rate": 0.00019995052459015838,
      "loss": 3.1898,
      "step": 2770
    },
    {
      "epoch": 0.11965223379529999,
      "grad_norm": 1.1695362329483032,
      "learning_rate": 0.00019994905231307894,
      "loss": 3.1893,
      "step": 2780
    },
    {
      "epoch": 0.12008263751398812,
      "grad_norm": 1.0974031686782837,
      "learning_rate": 0.0001999475584557458,
      "loss": 3.1293,
      "step": 2790
    },
    {
      "epoch": 0.12051304123267625,
      "grad_norm": 0.9646326899528503,
      "learning_rate": 0.0001999460430184815,
      "loss": 3.2041,
      "step": 2800
    },
    {
      "epoch": 0.12051304123267625,
      "eval_bleu": 25.242377340008606,
      "eval_gen_len": 27.415,
      "eval_loss": 2.8723978996276855,
      "eval_runtime": 58.1113,
      "eval_samples_per_second": 17.208,
      "eval_steps_per_second": 1.084,
      "step": 2800
    },
    {
      "epoch": 0.12094344495136437,
      "grad_norm": 1.0475248098373413,
      "learning_rate": 0.00019994450600161322,
      "loss": 3.2779,
      "step": 2810
    },
    {
      "epoch": 0.1213738486700525,
      "grad_norm": 0.986565113067627,
      "learning_rate": 0.0001999429474054728,
      "loss": 3.2136,
      "step": 2820
    },
    {
      "epoch": 0.12180425238874064,
      "grad_norm": 1.1648468971252441,
      "learning_rate": 0.00019994136723039684,
      "loss": 3.2433,
      "step": 2830
    },
    {
      "epoch": 0.12223465610742877,
      "grad_norm": 1.0882682800292969,
      "learning_rate": 0.00019993976547672646,
      "loss": 3.2744,
      "step": 2840
    },
    {
      "epoch": 0.1226650598261169,
      "grad_norm": 1.0548629760742188,
      "learning_rate": 0.0001999381421448075,
      "loss": 3.1288,
      "step": 2850
    },
    {
      "epoch": 0.1226650598261169,
      "eval_bleu": 25.23515869173055,
      "eval_gen_len": 27.309,
      "eval_loss": 2.8680362701416016,
      "eval_runtime": 57.8566,
      "eval_samples_per_second": 17.284,
      "eval_steps_per_second": 1.089,
      "step": 2850
    },
    {
      "epoch": 0.12309546354480502,
      "grad_norm": 1.2903603315353394,
      "learning_rate": 0.00019993649723499044,
      "loss": 3.2455,
      "step": 2860
    },
    {
      "epoch": 0.12352586726349316,
      "grad_norm": 1.1433656215667725,
      "learning_rate": 0.0001999348307476305,
      "loss": 3.1484,
      "step": 2870
    },
    {
      "epoch": 0.12395627098218129,
      "grad_norm": 0.9616658091545105,
      "learning_rate": 0.00019993314268308742,
      "loss": 3.2538,
      "step": 2880
    },
    {
      "epoch": 0.12438667470086942,
      "grad_norm": 0.9842888712882996,
      "learning_rate": 0.00019993143304172572,
      "loss": 3.1904,
      "step": 2890
    },
    {
      "epoch": 0.12481707841955754,
      "grad_norm": 0.9777004718780518,
      "learning_rate": 0.00019992970182391455,
      "loss": 3.2442,
      "step": 2900
    },
    {
      "epoch": 0.12481707841955754,
      "eval_bleu": 25.11578360033762,
      "eval_gen_len": 27.389,
      "eval_loss": 2.866440773010254,
      "eval_runtime": 58.1203,
      "eval_samples_per_second": 17.206,
      "eval_steps_per_second": 1.084,
      "step": 2900
    },
    {
      "epoch": 0.12524748213824569,
      "grad_norm": 1.0794633626937866,
      "learning_rate": 0.00019992794903002766,
      "loss": 3.1574,
      "step": 2910
    },
    {
      "epoch": 0.1256778858569338,
      "grad_norm": 1.144630789756775,
      "learning_rate": 0.00019992617466044353,
      "loss": 3.2108,
      "step": 2920
    },
    {
      "epoch": 0.12610828957562192,
      "grad_norm": 1.1765286922454834,
      "learning_rate": 0.00019992437871554523,
      "loss": 3.2892,
      "step": 2930
    },
    {
      "epoch": 0.12653869329431006,
      "grad_norm": 1.0907026529312134,
      "learning_rate": 0.0001999225611957206,
      "loss": 3.187,
      "step": 2940
    },
    {
      "epoch": 0.1269690970129982,
      "grad_norm": 1.0544439554214478,
      "learning_rate": 0.00019992072210136196,
      "loss": 3.1689,
      "step": 2950
    },
    {
      "epoch": 0.1269690970129982,
      "eval_bleu": 25.16829020889108,
      "eval_gen_len": 27.405,
      "eval_loss": 2.867175340652466,
      "eval_runtime": 57.8963,
      "eval_samples_per_second": 17.272,
      "eval_steps_per_second": 1.088,
      "step": 2950
    },
    {
      "epoch": 0.12739950073168632,
      "grad_norm": 1.1089040040969849,
      "learning_rate": 0.0001999188614328665,
      "loss": 3.1368,
      "step": 2960
    },
    {
      "epoch": 0.12782990445037445,
      "grad_norm": 0.9550418853759766,
      "learning_rate": 0.00019991697919063587,
      "loss": 3.2181,
      "step": 2970
    },
    {
      "epoch": 0.1282603081690626,
      "grad_norm": 1.0180591344833374,
      "learning_rate": 0.00019991507537507654,
      "loss": 3.2496,
      "step": 2980
    },
    {
      "epoch": 0.12869071188775072,
      "grad_norm": 1.0111503601074219,
      "learning_rate": 0.00019991314998659952,
      "loss": 3.128,
      "step": 2990
    },
    {
      "epoch": 0.12912111560643885,
      "grad_norm": 0.9707870483398438,
      "learning_rate": 0.00019991120302562058,
      "loss": 3.1972,
      "step": 3000
    },
    {
      "epoch": 0.12912111560643885,
      "eval_bleu": 25.158482978412657,
      "eval_gen_len": 27.329,
      "eval_loss": 2.8684513568878174,
      "eval_runtime": 57.8516,
      "eval_samples_per_second": 17.286,
      "eval_steps_per_second": 1.089,
      "step": 3000
    },
    {
      "epoch": 0.12955151932512696,
      "grad_norm": 1.0397475957870483,
      "learning_rate": 0.00019990923449256004,
      "loss": 3.1558,
      "step": 3010
    },
    {
      "epoch": 0.1299819230438151,
      "grad_norm": 1.062960147857666,
      "learning_rate": 0.00019990724438784295,
      "loss": 3.1457,
      "step": 3020
    },
    {
      "epoch": 0.13041232676250322,
      "grad_norm": 1.031646490097046,
      "learning_rate": 0.00019990523271189902,
      "loss": 3.0572,
      "step": 3030
    },
    {
      "epoch": 0.13084273048119135,
      "grad_norm": 0.9902625679969788,
      "learning_rate": 0.0001999031994651625,
      "loss": 3.1513,
      "step": 3040
    },
    {
      "epoch": 0.1312731341998795,
      "grad_norm": 1.0339584350585938,
      "learning_rate": 0.00019990114464807257,
      "loss": 3.159,
      "step": 3050
    },
    {
      "epoch": 0.1312731341998795,
      "eval_bleu": 24.98212859512684,
      "eval_gen_len": 27.544,
      "eval_loss": 2.871663808822632,
      "eval_runtime": 58.4471,
      "eval_samples_per_second": 17.109,
      "eval_steps_per_second": 1.078,
      "step": 3050
    },
    {
      "epoch": 0.13170353791856762,
      "grad_norm": 1.029160737991333,
      "learning_rate": 0.00019989906826107273,
      "loss": 3.2135,
      "step": 3060
    },
    {
      "epoch": 0.13213394163725575,
      "grad_norm": 0.9562923908233643,
      "learning_rate": 0.00019989697030461137,
      "loss": 3.1218,
      "step": 3070
    },
    {
      "epoch": 0.13256434535594389,
      "grad_norm": 1.1192171573638916,
      "learning_rate": 0.00019989485077914144,
      "loss": 3.2302,
      "step": 3080
    },
    {
      "epoch": 0.13299474907463202,
      "grad_norm": 0.8763200044631958,
      "learning_rate": 0.00019989270968512058,
      "loss": 3.1507,
      "step": 3090
    },
    {
      "epoch": 0.13342515279332012,
      "grad_norm": 0.9595954418182373,
      "learning_rate": 0.0001998905470230111,
      "loss": 3.2085,
      "step": 3100
    },
    {
      "epoch": 0.13342515279332012,
      "eval_bleu": 24.72521836878769,
      "eval_gen_len": 27.307,
      "eval_loss": 2.859656572341919,
      "eval_runtime": 58.198,
      "eval_samples_per_second": 17.183,
      "eval_steps_per_second": 1.083,
      "step": 3100
    },
    {
      "epoch": 0.13385555651200826,
      "grad_norm": 1.0892410278320312,
      "learning_rate": 0.00019988836279327994,
      "loss": 3.1855,
      "step": 3110
    },
    {
      "epoch": 0.1342859602306964,
      "grad_norm": 1.1084632873535156,
      "learning_rate": 0.0001998861569963987,
      "loss": 3.1717,
      "step": 3120
    },
    {
      "epoch": 0.13471636394938452,
      "grad_norm": 1.146073818206787,
      "learning_rate": 0.0001998839296328436,
      "loss": 3.1844,
      "step": 3130
    },
    {
      "epoch": 0.13514676766807265,
      "grad_norm": 0.9589326977729797,
      "learning_rate": 0.00019988168070309562,
      "loss": 3.1539,
      "step": 3140
    },
    {
      "epoch": 0.1355771713867608,
      "grad_norm": 0.9765377640724182,
      "learning_rate": 0.00019987941020764026,
      "loss": 3.2702,
      "step": 3150
    },
    {
      "epoch": 0.1355771713867608,
      "eval_bleu": 25.016726731706953,
      "eval_gen_len": 27.173,
      "eval_loss": 2.864255666732788,
      "eval_runtime": 57.8548,
      "eval_samples_per_second": 17.285,
      "eval_steps_per_second": 1.089,
      "step": 3150
    },
    {
      "epoch": 0.13600757510544892,
      "grad_norm": 1.0016316175460815,
      "learning_rate": 0.00019987711814696782,
      "loss": 3.143,
      "step": 3160
    },
    {
      "epoch": 0.13643797882413705,
      "grad_norm": 1.0055949687957764,
      "learning_rate": 0.00019987480452157312,
      "loss": 3.2028,
      "step": 3170
    },
    {
      "epoch": 0.13686838254282516,
      "grad_norm": 1.0837242603302002,
      "learning_rate": 0.00019987246933195576,
      "loss": 3.3187,
      "step": 3180
    },
    {
      "epoch": 0.1372987862615133,
      "grad_norm": 1.1034044027328491,
      "learning_rate": 0.0001998701125786199,
      "loss": 3.2943,
      "step": 3190
    },
    {
      "epoch": 0.13772918998020142,
      "grad_norm": 0.9191151261329651,
      "learning_rate": 0.00019986773426207438,
      "loss": 3.2321,
      "step": 3200
    },
    {
      "epoch": 0.13772918998020142,
      "eval_bleu": 25.585417648738055,
      "eval_gen_len": 27.393,
      "eval_loss": 2.866539716720581,
      "eval_runtime": 58.1293,
      "eval_samples_per_second": 17.203,
      "eval_steps_per_second": 1.084,
      "step": 3200
    },
    {
      "epoch": 0.13815959369888955,
      "grad_norm": 0.9950697422027588,
      "learning_rate": 0.00019986533438283278,
      "loss": 3.1914,
      "step": 3210
    },
    {
      "epoch": 0.1385899974175777,
      "grad_norm": 0.9254275560379028,
      "learning_rate": 0.00019986291294141317,
      "loss": 3.2134,
      "step": 3220
    },
    {
      "epoch": 0.13902040113626582,
      "grad_norm": 1.005270004272461,
      "learning_rate": 0.00019986046993833843,
      "loss": 3.1924,
      "step": 3230
    },
    {
      "epoch": 0.13945080485495395,
      "grad_norm": 0.9605170488357544,
      "learning_rate": 0.000199858005374136,
      "loss": 3.2684,
      "step": 3240
    },
    {
      "epoch": 0.13988120857364209,
      "grad_norm": 1.1320651769638062,
      "learning_rate": 0.00019985551924933806,
      "loss": 3.2108,
      "step": 3250
    },
    {
      "epoch": 0.13988120857364209,
      "eval_bleu": 25.535433331955225,
      "eval_gen_len": 27.335,
      "eval_loss": 2.865891695022583,
      "eval_runtime": 58.2177,
      "eval_samples_per_second": 17.177,
      "eval_steps_per_second": 1.082,
      "step": 3250
    },
    {
      "epoch": 0.14031161229233022,
      "grad_norm": 0.9435115456581116,
      "learning_rate": 0.00019985301156448136,
      "loss": 3.1838,
      "step": 3260
    },
    {
      "epoch": 0.14074201601101832,
      "grad_norm": 1.0278874635696411,
      "learning_rate": 0.00019985048232010733,
      "loss": 3.1802,
      "step": 3270
    },
    {
      "epoch": 0.14117241972970646,
      "grad_norm": 1.0530534982681274,
      "learning_rate": 0.0001998479315167621,
      "loss": 3.2758,
      "step": 3280
    },
    {
      "epoch": 0.1416028234483946,
      "grad_norm": 1.0327163934707642,
      "learning_rate": 0.0001998453591549964,
      "loss": 3.1858,
      "step": 3290
    },
    {
      "epoch": 0.14203322716708272,
      "grad_norm": 0.9046713709831238,
      "learning_rate": 0.0001998427652353656,
      "loss": 3.2341,
      "step": 3300
    },
    {
      "epoch": 0.14203322716708272,
      "eval_bleu": 25.040883890998817,
      "eval_gen_len": 27.222,
      "eval_loss": 2.8654654026031494,
      "eval_runtime": 58.1042,
      "eval_samples_per_second": 17.21,
      "eval_steps_per_second": 1.084,
      "step": 3300
    },
    {
      "epoch": 0.14246363088577085,
      "grad_norm": 1.0054124593734741,
      "learning_rate": 0.00019984014975842982,
      "loss": 3.1936,
      "step": 3310
    },
    {
      "epoch": 0.14289403460445899,
      "grad_norm": 0.9610084891319275,
      "learning_rate": 0.00019983751272475379,
      "loss": 3.0339,
      "step": 3320
    },
    {
      "epoch": 0.14332443832314712,
      "grad_norm": 1.0241624116897583,
      "learning_rate": 0.0001998348541349068,
      "loss": 3.1338,
      "step": 3330
    },
    {
      "epoch": 0.14375484204183525,
      "grad_norm": 0.9962315559387207,
      "learning_rate": 0.0001998321739894629,
      "loss": 3.0933,
      "step": 3340
    },
    {
      "epoch": 0.14418524576052338,
      "grad_norm": 0.9882998466491699,
      "learning_rate": 0.0001998294722890008,
      "loss": 3.2028,
      "step": 3350
    },
    {
      "epoch": 0.14418524576052338,
      "eval_bleu": 25.212912408504625,
      "eval_gen_len": 27.417,
      "eval_loss": 2.8635685443878174,
      "eval_runtime": 58.5141,
      "eval_samples_per_second": 17.09,
      "eval_steps_per_second": 1.077,
      "step": 3350
    },
    {
      "epoch": 0.1446156494792115,
      "grad_norm": 0.9583525061607361,
      "learning_rate": 0.0001998267490341038,
      "loss": 3.2504,
      "step": 3360
    },
    {
      "epoch": 0.14504605319789962,
      "grad_norm": 1.1752997636795044,
      "learning_rate": 0.0001998240042253599,
      "loss": 3.2063,
      "step": 3370
    },
    {
      "epoch": 0.14547645691658775,
      "grad_norm": 1.1762250661849976,
      "learning_rate": 0.00019982123786336172,
      "loss": 3.2591,
      "step": 3380
    },
    {
      "epoch": 0.1459068606352759,
      "grad_norm": 0.9597151279449463,
      "learning_rate": 0.00019981844994870657,
      "loss": 3.2509,
      "step": 3390
    },
    {
      "epoch": 0.14633726435396402,
      "grad_norm": 0.8862666487693787,
      "learning_rate": 0.0001998156404819964,
      "loss": 3.1483,
      "step": 3400
    },
    {
      "epoch": 0.14633726435396402,
      "eval_bleu": 24.741990349311493,
      "eval_gen_len": 27.587,
      "eval_loss": 2.863795042037964,
      "eval_runtime": 59.4033,
      "eval_samples_per_second": 16.834,
      "eval_steps_per_second": 1.061,
      "step": 3400
    },
    {
      "epoch": 0.14676766807265215,
      "grad_norm": 0.9108953475952148,
      "learning_rate": 0.00019981280946383781,
      "loss": 3.1254,
      "step": 3410
    },
    {
      "epoch": 0.14719807179134028,
      "grad_norm": 1.0616172552108765,
      "learning_rate": 0.00019980995689484202,
      "loss": 3.2272,
      "step": 3420
    },
    {
      "epoch": 0.14762847551002842,
      "grad_norm": 0.9964044094085693,
      "learning_rate": 0.000199807082775625,
      "loss": 3.1587,
      "step": 3430
    },
    {
      "epoch": 0.14805887922871652,
      "grad_norm": 1.0257630348205566,
      "learning_rate": 0.00019980418710680725,
      "loss": 3.1973,
      "step": 3440
    },
    {
      "epoch": 0.14848928294740465,
      "grad_norm": 0.9587670564651489,
      "learning_rate": 0.00019980126988901396,
      "loss": 3.1984,
      "step": 3450
    },
    {
      "epoch": 0.14848928294740465,
      "eval_bleu": 25.277166203327113,
      "eval_gen_len": 27.411,
      "eval_loss": 2.8620853424072266,
      "eval_runtime": 58.1892,
      "eval_samples_per_second": 17.185,
      "eval_steps_per_second": 1.083,
      "step": 3450
    },
    {
      "epoch": 0.1489196866660928,
      "grad_norm": 1.0280195474624634,
      "learning_rate": 0.0001997983311228751,
      "loss": 3.1624,
      "step": 3460
    },
    {
      "epoch": 0.14935009038478092,
      "grad_norm": 0.9935880303382874,
      "learning_rate": 0.00019979537080902507,
      "loss": 3.2125,
      "step": 3470
    },
    {
      "epoch": 0.14978049410346905,
      "grad_norm": 0.9494873285293579,
      "learning_rate": 0.00019979238894810307,
      "loss": 3.2014,
      "step": 3480
    },
    {
      "epoch": 0.15021089782215719,
      "grad_norm": 1.0085681676864624,
      "learning_rate": 0.00019978938554075296,
      "loss": 3.0586,
      "step": 3490
    },
    {
      "epoch": 0.15064130154084532,
      "grad_norm": 1.016669750213623,
      "learning_rate": 0.0001997863605876232,
      "loss": 3.141,
      "step": 3500
    },
    {
      "epoch": 0.15064130154084532,
      "eval_bleu": 25.54958764180646,
      "eval_gen_len": 27.407,
      "eval_loss": 2.8573806285858154,
      "eval_runtime": 58.7124,
      "eval_samples_per_second": 17.032,
      "eval_steps_per_second": 1.073,
      "step": 3500
    },
    {
      "epoch": 0.15107170525953345,
      "grad_norm": 1.0643103122711182,
      "learning_rate": 0.00019978331408936694,
      "loss": 3.2326,
      "step": 3510
    },
    {
      "epoch": 0.15150210897822158,
      "grad_norm": 0.9100388288497925,
      "learning_rate": 0.00019978024604664187,
      "loss": 3.0293,
      "step": 3520
    },
    {
      "epoch": 0.1519325126969097,
      "grad_norm": 1.025871992111206,
      "learning_rate": 0.0001997771564601105,
      "loss": 3.1509,
      "step": 3530
    },
    {
      "epoch": 0.15236291641559782,
      "grad_norm": 1.0198136568069458,
      "learning_rate": 0.00019977404533043987,
      "loss": 3.1698,
      "step": 3540
    },
    {
      "epoch": 0.15279332013428595,
      "grad_norm": 0.9708639979362488,
      "learning_rate": 0.00019977091265830174,
      "loss": 3.1344,
      "step": 3550
    },
    {
      "epoch": 0.15279332013428595,
      "eval_bleu": 26.158718535968184,
      "eval_gen_len": 27.437,
      "eval_loss": 2.856478214263916,
      "eval_runtime": 59.0481,
      "eval_samples_per_second": 16.935,
      "eval_steps_per_second": 1.067,
      "step": 3550
    },
    {
      "epoch": 0.1532237238529741,
      "grad_norm": 1.006367802619934,
      "learning_rate": 0.00019976775844437246,
      "loss": 3.1553,
      "step": 3560
    },
    {
      "epoch": 0.15365412757166222,
      "grad_norm": 1.0192325115203857,
      "learning_rate": 0.0001997645826893331,
      "loss": 3.2135,
      "step": 3570
    },
    {
      "epoch": 0.15408453129035035,
      "grad_norm": 0.9787608981132507,
      "learning_rate": 0.0001997613853938693,
      "loss": 3.1119,
      "step": 3580
    },
    {
      "epoch": 0.15451493500903848,
      "grad_norm": 1.2114312648773193,
      "learning_rate": 0.00019975816655867144,
      "loss": 3.1465,
      "step": 3590
    },
    {
      "epoch": 0.15494533872772662,
      "grad_norm": 0.9068093299865723,
      "learning_rate": 0.00019975492618443452,
      "loss": 3.1718,
      "step": 3600
    },
    {
      "epoch": 0.15494533872772662,
      "eval_bleu": 25.498470791724998,
      "eval_gen_len": 27.343,
      "eval_loss": 2.859473705291748,
      "eval_runtime": 57.9052,
      "eval_samples_per_second": 17.27,
      "eval_steps_per_second": 1.088,
      "step": 3600
    },
    {
      "epoch": 0.15537574244641475,
      "grad_norm": 1.1609110832214355,
      "learning_rate": 0.0001997516642718581,
      "loss": 3.1781,
      "step": 3610
    },
    {
      "epoch": 0.15580614616510285,
      "grad_norm": 1.0199991464614868,
      "learning_rate": 0.00019974838082164657,
      "loss": 3.235,
      "step": 3620
    },
    {
      "epoch": 0.156236549883791,
      "grad_norm": 0.972547173500061,
      "learning_rate": 0.0001997450758345088,
      "loss": 3.1294,
      "step": 3630
    },
    {
      "epoch": 0.15666695360247912,
      "grad_norm": 0.8984225988388062,
      "learning_rate": 0.00019974174931115837,
      "loss": 3.1259,
      "step": 3640
    },
    {
      "epoch": 0.15709735732116725,
      "grad_norm": 1.1217074394226074,
      "learning_rate": 0.00019973840125231352,
      "loss": 3.1785,
      "step": 3650
    },
    {
      "epoch": 0.15709735732116725,
      "eval_bleu": 25.38276122660911,
      "eval_gen_len": 27.205,
      "eval_loss": 2.8632099628448486,
      "eval_runtime": 58.3099,
      "eval_samples_per_second": 17.15,
      "eval_steps_per_second": 1.08,
      "step": 3650
    },
    {
      "epoch": 0.15752776103985539,
      "grad_norm": 0.9727032780647278,
      "learning_rate": 0.00019973503165869721,
      "loss": 3.1815,
      "step": 3660
    },
    {
      "epoch": 0.15795816475854352,
      "grad_norm": 1.0370330810546875,
      "learning_rate": 0.0001997316405310369,
      "loss": 3.2055,
      "step": 3670
    },
    {
      "epoch": 0.15838856847723165,
      "grad_norm": 1.1172664165496826,
      "learning_rate": 0.0001997282278700648,
      "loss": 3.1359,
      "step": 3680
    },
    {
      "epoch": 0.15881897219591978,
      "grad_norm": 0.9673717021942139,
      "learning_rate": 0.00019972479367651776,
      "loss": 3.1771,
      "step": 3690
    },
    {
      "epoch": 0.15924937591460792,
      "grad_norm": 1.0037612915039062,
      "learning_rate": 0.0001997213379511373,
      "loss": 3.23,
      "step": 3700
    },
    {
      "epoch": 0.15924937591460792,
      "eval_bleu": 25.921816884234698,
      "eval_gen_len": 27.429,
      "eval_loss": 2.858936071395874,
      "eval_runtime": 58.3995,
      "eval_samples_per_second": 17.123,
      "eval_steps_per_second": 1.079,
      "step": 3700
    },
    {
      "epoch": 0.15967977963329602,
      "grad_norm": 0.9683079719543457,
      "learning_rate": 0.00019971786069466945,
      "loss": 3.2306,
      "step": 3710
    },
    {
      "epoch": 0.16011018335198415,
      "grad_norm": 1.1346911191940308,
      "learning_rate": 0.00019971436190786506,
      "loss": 3.068,
      "step": 3720
    },
    {
      "epoch": 0.16054058707067229,
      "grad_norm": 1.034437656402588,
      "learning_rate": 0.00019971084159147958,
      "loss": 3.1434,
      "step": 3730
    },
    {
      "epoch": 0.16097099078936042,
      "grad_norm": 1.0786374807357788,
      "learning_rate": 0.00019970729974627305,
      "loss": 3.181,
      "step": 3740
    },
    {
      "epoch": 0.16140139450804855,
      "grad_norm": 1.011777639389038,
      "learning_rate": 0.0001997037363730102,
      "loss": 3.1096,
      "step": 3750
    },
    {
      "epoch": 0.16140139450804855,
      "eval_bleu": 25.53859947034785,
      "eval_gen_len": 27.301,
      "eval_loss": 2.8560993671417236,
      "eval_runtime": 58.214,
      "eval_samples_per_second": 17.178,
      "eval_steps_per_second": 1.082,
      "step": 3750
    },
    {
      "epoch": 0.16183179822673668,
      "grad_norm": 1.0387730598449707,
      "learning_rate": 0.00019970015147246044,
      "loss": 3.1689,
      "step": 3760
    },
    {
      "epoch": 0.16226220194542482,
      "grad_norm": 1.0790753364562988,
      "learning_rate": 0.00019969654504539775,
      "loss": 3.1814,
      "step": 3770
    },
    {
      "epoch": 0.16269260566411295,
      "grad_norm": 0.8171712756156921,
      "learning_rate": 0.00019969291709260087,
      "loss": 3.1281,
      "step": 3780
    },
    {
      "epoch": 0.16312300938280105,
      "grad_norm": 0.9762257933616638,
      "learning_rate": 0.00019968926761485304,
      "loss": 3.1928,
      "step": 3790
    },
    {
      "epoch": 0.1635534131014892,
      "grad_norm": 1.0393997430801392,
      "learning_rate": 0.0001996855966129423,
      "loss": 3.1229,
      "step": 3800
    },
    {
      "epoch": 0.1635534131014892,
      "eval_bleu": 25.386772135090425,
      "eval_gen_len": 27.191,
      "eval_loss": 2.8605308532714844,
      "eval_runtime": 57.3146,
      "eval_samples_per_second": 17.448,
      "eval_steps_per_second": 1.099,
      "step": 3800
    },
    {
      "epoch": 0.16398381682017732,
      "grad_norm": 0.9748197197914124,
      "learning_rate": 0.00019968190408766124,
      "loss": 3.2069,
      "step": 3810
    },
    {
      "epoch": 0.16441422053886545,
      "grad_norm": 1.0733572244644165,
      "learning_rate": 0.0001996781900398071,
      "loss": 3.2262,
      "step": 3820
    },
    {
      "epoch": 0.16484462425755358,
      "grad_norm": 1.0800753831863403,
      "learning_rate": 0.00019967445447018178,
      "loss": 3.2876,
      "step": 3830
    },
    {
      "epoch": 0.16527502797624172,
      "grad_norm": 1.0441612005233765,
      "learning_rate": 0.00019967069737959186,
      "loss": 3.0962,
      "step": 3840
    },
    {
      "epoch": 0.16570543169492985,
      "grad_norm": 1.0955036878585815,
      "learning_rate": 0.0001996669187688486,
      "loss": 3.2488,
      "step": 3850
    },
    {
      "epoch": 0.16570543169492985,
      "eval_bleu": 25.44689194145686,
      "eval_gen_len": 27.314,
      "eval_loss": 2.854505777359009,
      "eval_runtime": 58.9789,
      "eval_samples_per_second": 16.955,
      "eval_steps_per_second": 1.068,
      "step": 3850
    },
    {
      "epoch": 0.16613583541361798,
      "grad_norm": 1.001577377319336,
      "learning_rate": 0.00019966311863876774,
      "loss": 3.1587,
      "step": 3860
    },
    {
      "epoch": 0.16656623913230612,
      "grad_norm": 1.0231389999389648,
      "learning_rate": 0.00019965929699016985,
      "loss": 3.1311,
      "step": 3870
    },
    {
      "epoch": 0.16699664285099422,
      "grad_norm": 0.9205288290977478,
      "learning_rate": 0.00019965545382388006,
      "loss": 3.083,
      "step": 3880
    },
    {
      "epoch": 0.16742704656968235,
      "grad_norm": 0.9505439400672913,
      "learning_rate": 0.00019965158914072814,
      "loss": 3.2411,
      "step": 3890
    },
    {
      "epoch": 0.16785745028837049,
      "grad_norm": 1.02622652053833,
      "learning_rate": 0.00019964770294154854,
      "loss": 3.2229,
      "step": 3900
    },
    {
      "epoch": 0.16785745028837049,
      "eval_bleu": 25.405016590347657,
      "eval_gen_len": 27.324,
      "eval_loss": 2.8628273010253906,
      "eval_runtime": 57.5791,
      "eval_samples_per_second": 17.367,
      "eval_steps_per_second": 1.094,
      "step": 3900
    },
    {
      "epoch": 0.16828785400705862,
      "grad_norm": 1.0607436895370483,
      "learning_rate": 0.0001996437952271803,
      "loss": 3.2193,
      "step": 3910
    },
    {
      "epoch": 0.16871825772574675,
      "grad_norm": 1.0285704135894775,
      "learning_rate": 0.0001996398659984672,
      "loss": 3.1323,
      "step": 3920
    },
    {
      "epoch": 0.16914866144443488,
      "grad_norm": 1.0694080591201782,
      "learning_rate": 0.0001996359152562576,
      "loss": 3.1476,
      "step": 3930
    },
    {
      "epoch": 0.16957906516312302,
      "grad_norm": 0.9643921256065369,
      "learning_rate": 0.00019963194300140448,
      "loss": 3.2057,
      "step": 3940
    },
    {
      "epoch": 0.17000946888181115,
      "grad_norm": 1.1524897813796997,
      "learning_rate": 0.00019962794923476552,
      "loss": 3.1932,
      "step": 3950
    },
    {
      "epoch": 0.17000946888181115,
      "eval_bleu": 25.292933861506636,
      "eval_gen_len": 27.238,
      "eval_loss": 2.861753463745117,
      "eval_runtime": 57.6752,
      "eval_samples_per_second": 17.338,
      "eval_steps_per_second": 1.092,
      "step": 3950
    },
    {
      "epoch": 0.17043987260049928,
      "grad_norm": 0.9600024819374084,
      "learning_rate": 0.00019962393395720303,
      "loss": 3.1353,
      "step": 3960
    },
    {
      "epoch": 0.1708702763191874,
      "grad_norm": 0.8685523271560669,
      "learning_rate": 0.00019961989716958396,
      "loss": 3.1132,
      "step": 3970
    },
    {
      "epoch": 0.17130068003787552,
      "grad_norm": 0.952203094959259,
      "learning_rate": 0.00019961583887277988,
      "loss": 3.0874,
      "step": 3980
    },
    {
      "epoch": 0.17173108375656365,
      "grad_norm": 1.072514295578003,
      "learning_rate": 0.00019961175906766705,
      "loss": 3.2618,
      "step": 3990
    },
    {
      "epoch": 0.17216148747525178,
      "grad_norm": 0.9500723481178284,
      "learning_rate": 0.00019960765775512635,
      "loss": 3.1185,
      "step": 4000
    },
    {
      "epoch": 0.17216148747525178,
      "eval_bleu": 24.843116353353786,
      "eval_gen_len": 27.317,
      "eval_loss": 2.864142417907715,
      "eval_runtime": 57.515,
      "eval_samples_per_second": 17.387,
      "eval_steps_per_second": 1.095,
      "step": 4000
    },
    {
      "epoch": 0.17259189119393992,
      "grad_norm": 1.0452264547348022,
      "learning_rate": 0.00019960353493604332,
      "loss": 3.0726,
      "step": 4010
    },
    {
      "epoch": 0.17302229491262805,
      "grad_norm": 1.0197631120681763,
      "learning_rate": 0.00019959939061130807,
      "loss": 3.1853,
      "step": 4020
    },
    {
      "epoch": 0.17345269863131618,
      "grad_norm": 1.0908085107803345,
      "learning_rate": 0.00019959522478181545,
      "loss": 3.2521,
      "step": 4030
    },
    {
      "epoch": 0.17388310235000431,
      "grad_norm": 0.9906242489814758,
      "learning_rate": 0.00019959103744846495,
      "loss": 3.1611,
      "step": 4040
    },
    {
      "epoch": 0.17431350606869242,
      "grad_norm": 1.0499423742294312,
      "learning_rate": 0.0001995868286121606,
      "loss": 3.212,
      "step": 4050
    },
    {
      "epoch": 0.17431350606869242,
      "eval_bleu": 25.78492112523791,
      "eval_gen_len": 27.428,
      "eval_loss": 2.8564281463623047,
      "eval_runtime": 57.4117,
      "eval_samples_per_second": 17.418,
      "eval_steps_per_second": 1.097,
      "step": 4050
    },
    {
      "epoch": 0.17474390978738055,
      "grad_norm": 0.8736504912376404,
      "learning_rate": 0.00019958259827381118,
      "loss": 3.2158,
      "step": 4060
    },
    {
      "epoch": 0.17517431350606869,
      "grad_norm": 0.9581466317176819,
      "learning_rate": 0.00019957834643433007,
      "loss": 3.2169,
      "step": 4070
    },
    {
      "epoch": 0.17560471722475682,
      "grad_norm": 0.9312865138053894,
      "learning_rate": 0.0001995740730946353,
      "loss": 3.207,
      "step": 4080
    },
    {
      "epoch": 0.17603512094344495,
      "grad_norm": 1.0775560140609741,
      "learning_rate": 0.0001995697782556495,
      "loss": 3.1871,
      "step": 4090
    },
    {
      "epoch": 0.17646552466213308,
      "grad_norm": 1.1066994667053223,
      "learning_rate": 0.00019956546191830007,
      "loss": 3.0404,
      "step": 4100
    },
    {
      "epoch": 0.17646552466213308,
      "eval_bleu": 25.263207533041594,
      "eval_gen_len": 27.188,
      "eval_loss": 2.857701063156128,
      "eval_runtime": 57.0822,
      "eval_samples_per_second": 17.519,
      "eval_steps_per_second": 1.104,
      "step": 4100
    },
    {
      "epoch": 0.17689592838082122,
      "grad_norm": 0.989528477191925,
      "learning_rate": 0.00019956112408351883,
      "loss": 3.2909,
      "step": 4110
    },
    {
      "epoch": 0.17732633209950935,
      "grad_norm": 0.9818349480628967,
      "learning_rate": 0.00019955676475224247,
      "loss": 3.2499,
      "step": 4120
    },
    {
      "epoch": 0.17775673581819748,
      "grad_norm": 0.9946051836013794,
      "learning_rate": 0.0001995523839254122,
      "loss": 3.2063,
      "step": 4130
    },
    {
      "epoch": 0.17818713953688559,
      "grad_norm": 1.043842077255249,
      "learning_rate": 0.0001995479816039739,
      "loss": 3.2144,
      "step": 4140
    },
    {
      "epoch": 0.17861754325557372,
      "grad_norm": 0.9908652901649475,
      "learning_rate": 0.00019954355778887804,
      "loss": 3.2074,
      "step": 4150
    },
    {
      "epoch": 0.17861754325557372,
      "eval_bleu": 25.470569989423836,
      "eval_gen_len": 27.338,
      "eval_loss": 2.8585686683654785,
      "eval_runtime": 57.4029,
      "eval_samples_per_second": 17.421,
      "eval_steps_per_second": 1.098,
      "step": 4150
    },
    {
      "epoch": 0.17904794697426185,
      "grad_norm": 1.0011916160583496,
      "learning_rate": 0.00019953911248107989,
      "loss": 3.1315,
      "step": 4160
    },
    {
      "epoch": 0.17947835069294998,
      "grad_norm": 1.0712080001831055,
      "learning_rate": 0.0001995346456815391,
      "loss": 3.2319,
      "step": 4170
    },
    {
      "epoch": 0.17990875441163812,
      "grad_norm": 0.9900404214859009,
      "learning_rate": 0.00019953015739122024,
      "loss": 3.1722,
      "step": 4180
    },
    {
      "epoch": 0.18033915813032625,
      "grad_norm": 1.004642367362976,
      "learning_rate": 0.00019952564761109226,
      "loss": 3.1268,
      "step": 4190
    },
    {
      "epoch": 0.18076956184901438,
      "grad_norm": 1.023789644241333,
      "learning_rate": 0.00019952111634212902,
      "loss": 3.1867,
      "step": 4200
    },
    {
      "epoch": 0.18076956184901438,
      "eval_bleu": 25.714312755904064,
      "eval_gen_len": 27.305,
      "eval_loss": 2.8578362464904785,
      "eval_runtime": 57.73,
      "eval_samples_per_second": 17.322,
      "eval_steps_per_second": 1.091,
      "step": 4200
    },
    {
      "epoch": 0.18119996556770251,
      "grad_norm": 0.864149272441864,
      "learning_rate": 0.00019951656358530877,
      "loss": 3.1687,
      "step": 4210
    },
    {
      "epoch": 0.18163036928639065,
      "grad_norm": 0.9301503896713257,
      "learning_rate": 0.00019951198934161455,
      "loss": 3.1451,
      "step": 4220
    },
    {
      "epoch": 0.18206077300507875,
      "grad_norm": 0.982107400894165,
      "learning_rate": 0.00019950739361203397,
      "loss": 3.1189,
      "step": 4230
    },
    {
      "epoch": 0.18249117672376688,
      "grad_norm": 0.9513602256774902,
      "learning_rate": 0.00019950277639755934,
      "loss": 3.1511,
      "step": 4240
    },
    {
      "epoch": 0.18292158044245502,
      "grad_norm": 1.0070666074752808,
      "learning_rate": 0.00019949813769918758,
      "loss": 3.1618,
      "step": 4250
    },
    {
      "epoch": 0.18292158044245502,
      "eval_bleu": 25.709987092297062,
      "eval_gen_len": 27.475,
      "eval_loss": 2.857154130935669,
      "eval_runtime": 57.5984,
      "eval_samples_per_second": 17.362,
      "eval_steps_per_second": 1.094,
      "step": 4250
    },
    {
      "epoch": 0.18335198416114315,
      "grad_norm": 0.9600232243537903,
      "learning_rate": 0.0001994934775179202,
      "loss": 3.1827,
      "step": 4260
    },
    {
      "epoch": 0.18378238787983128,
      "grad_norm": 0.9586527347564697,
      "learning_rate": 0.0001994887958547634,
      "loss": 3.1554,
      "step": 4270
    },
    {
      "epoch": 0.18421279159851942,
      "grad_norm": 1.1055890321731567,
      "learning_rate": 0.00019948409271072808,
      "loss": 3.1915,
      "step": 4280
    },
    {
      "epoch": 0.18464319531720755,
      "grad_norm": 0.9256753921508789,
      "learning_rate": 0.00019947936808682962,
      "loss": 3.0676,
      "step": 4290
    },
    {
      "epoch": 0.18507359903589568,
      "grad_norm": 1.0003042221069336,
      "learning_rate": 0.00019947462198408812,
      "loss": 3.1764,
      "step": 4300
    },
    {
      "epoch": 0.18507359903589568,
      "eval_bleu": 25.5905038722211,
      "eval_gen_len": 27.33,
      "eval_loss": 2.8579697608947754,
      "eval_runtime": 57.6703,
      "eval_samples_per_second": 17.34,
      "eval_steps_per_second": 1.092,
      "step": 4300
    },
    {
      "epoch": 0.1855040027545838,
      "grad_norm": 0.9588068723678589,
      "learning_rate": 0.00019946985440352842,
      "loss": 3.208,
      "step": 4310
    },
    {
      "epoch": 0.18593440647327192,
      "grad_norm": 0.9093586206436157,
      "learning_rate": 0.00019946506534617982,
      "loss": 3.0323,
      "step": 4320
    },
    {
      "epoch": 0.18636481019196005,
      "grad_norm": 1.0837169885635376,
      "learning_rate": 0.00019946025481307636,
      "loss": 3.2537,
      "step": 4330
    },
    {
      "epoch": 0.18679521391064818,
      "grad_norm": 0.9918267130851746,
      "learning_rate": 0.00019945542280525667,
      "loss": 3.2991,
      "step": 4340
    },
    {
      "epoch": 0.18722561762933632,
      "grad_norm": 1.0479776859283447,
      "learning_rate": 0.0001994505693237641,
      "loss": 3.2187,
      "step": 4350
    },
    {
      "epoch": 0.18722561762933632,
      "eval_bleu": 25.702490033888935,
      "eval_gen_len": 27.275,
      "eval_loss": 2.8542752265930176,
      "eval_runtime": 57.7121,
      "eval_samples_per_second": 17.327,
      "eval_steps_per_second": 1.092,
      "step": 4350
    },
    {
      "epoch": 0.18765602134802445,
      "grad_norm": 1.0127530097961426,
      "learning_rate": 0.0001994456943696465,
      "loss": 3.1255,
      "step": 4360
    },
    {
      "epoch": 0.18808642506671258,
      "grad_norm": 0.9366996884346008,
      "learning_rate": 0.0001994407979439565,
      "loss": 3.2167,
      "step": 4370
    },
    {
      "epoch": 0.18851682878540071,
      "grad_norm": 0.8467252850532532,
      "learning_rate": 0.00019943588004775128,
      "loss": 3.195,
      "step": 4380
    },
    {
      "epoch": 0.18894723250408885,
      "grad_norm": 1.0021547079086304,
      "learning_rate": 0.00019943094068209267,
      "loss": 3.1498,
      "step": 4390
    },
    {
      "epoch": 0.18937763622277695,
      "grad_norm": 1.0597292184829712,
      "learning_rate": 0.0001994259798480471,
      "loss": 3.304,
      "step": 4400
    },
    {
      "epoch": 0.18937763622277695,
      "eval_bleu": 25.56930399049486,
      "eval_gen_len": 27.316,
      "eval_loss": 2.8522896766662598,
      "eval_runtime": 57.5424,
      "eval_samples_per_second": 17.378,
      "eval_steps_per_second": 1.095,
      "step": 4400
    },
    {
      "epoch": 0.18980803994146508,
      "grad_norm": 0.9511388540267944,
      "learning_rate": 0.00019942099754668578,
      "loss": 3.1311,
      "step": 4410
    },
    {
      "epoch": 0.19023844366015322,
      "grad_norm": 0.9086552858352661,
      "learning_rate": 0.00019941599377908435,
      "loss": 3.1313,
      "step": 4420
    },
    {
      "epoch": 0.19066884737884135,
      "grad_norm": 0.9583826661109924,
      "learning_rate": 0.00019941096854632324,
      "loss": 3.1387,
      "step": 4430
    },
    {
      "epoch": 0.19109925109752948,
      "grad_norm": 1.004159688949585,
      "learning_rate": 0.00019940592184948747,
      "loss": 3.2711,
      "step": 4440
    },
    {
      "epoch": 0.19152965481621761,
      "grad_norm": 0.960399866104126,
      "learning_rate": 0.00019940085368966664,
      "loss": 3.1745,
      "step": 4450
    },
    {
      "epoch": 0.19152965481621761,
      "eval_bleu": 25.3000896573921,
      "eval_gen_len": 27.367,
      "eval_loss": 2.8580942153930664,
      "eval_runtime": 57.9723,
      "eval_samples_per_second": 17.25,
      "eval_steps_per_second": 1.087,
      "step": 4450
    },
    {
      "epoch": 0.19196005853490575,
      "grad_norm": 1.0359283685684204,
      "learning_rate": 0.00019939576406795504,
      "loss": 3.2451,
      "step": 4460
    },
    {
      "epoch": 0.19239046225359388,
      "grad_norm": 0.9733139872550964,
      "learning_rate": 0.0001993906529854516,
      "loss": 3.2084,
      "step": 4470
    },
    {
      "epoch": 0.192820865972282,
      "grad_norm": 1.1098716259002686,
      "learning_rate": 0.00019938552044325983,
      "loss": 3.0924,
      "step": 4480
    },
    {
      "epoch": 0.19325126969097012,
      "grad_norm": 1.0302250385284424,
      "learning_rate": 0.00019938036644248799,
      "loss": 3.2187,
      "step": 4490
    },
    {
      "epoch": 0.19368167340965825,
      "grad_norm": 1.1705989837646484,
      "learning_rate": 0.00019937519098424882,
      "loss": 3.1521,
      "step": 4500
    },
    {
      "epoch": 0.19368167340965825,
      "eval_bleu": 25.55675601886247,
      "eval_gen_len": 27.375,
      "eval_loss": 2.857041120529175,
      "eval_runtime": 57.4503,
      "eval_samples_per_second": 17.406,
      "eval_steps_per_second": 1.097,
      "step": 4500
    },
    {
      "epoch": 0.19411207712834638,
      "grad_norm": 1.090489149093628,
      "learning_rate": 0.00019936999406965978,
      "loss": 3.1962,
      "step": 4510
    },
    {
      "epoch": 0.19454248084703452,
      "grad_norm": 0.9739007949829102,
      "learning_rate": 0.000199364775699843,
      "loss": 3.0784,
      "step": 4520
    },
    {
      "epoch": 0.19497288456572265,
      "grad_norm": 1.0113364458084106,
      "learning_rate": 0.00019935953587592512,
      "loss": 3.1214,
      "step": 4530
    },
    {
      "epoch": 0.19540328828441078,
      "grad_norm": 0.9394798874855042,
      "learning_rate": 0.00019935427459903752,
      "loss": 3.1815,
      "step": 4540
    },
    {
      "epoch": 0.1958336920030989,
      "grad_norm": 1.0226019620895386,
      "learning_rate": 0.0001993489918703162,
      "loss": 3.3277,
      "step": 4550
    },
    {
      "epoch": 0.1958336920030989,
      "eval_bleu": 25.658976597482198,
      "eval_gen_len": 27.235,
      "eval_loss": 2.857717990875244,
      "eval_runtime": 58.1264,
      "eval_samples_per_second": 17.204,
      "eval_steps_per_second": 1.084,
      "step": 4550
    },
    {
      "epoch": 0.19626409572178705,
      "grad_norm": 1.07267427444458,
      "learning_rate": 0.0001993436876909017,
      "loss": 3.2585,
      "step": 4560
    },
    {
      "epoch": 0.19669449944047518,
      "grad_norm": 0.9631568193435669,
      "learning_rate": 0.0001993383620619393,
      "loss": 3.1794,
      "step": 4570
    },
    {
      "epoch": 0.19712490315916328,
      "grad_norm": 1.0494858026504517,
      "learning_rate": 0.00019933301498457887,
      "loss": 3.1839,
      "step": 4580
    },
    {
      "epoch": 0.19755530687785142,
      "grad_norm": 0.9821475148200989,
      "learning_rate": 0.0001993276464599749,
      "loss": 3.1938,
      "step": 4590
    },
    {
      "epoch": 0.19798571059653955,
      "grad_norm": 1.0135188102722168,
      "learning_rate": 0.00019932225648928653,
      "loss": 3.183,
      "step": 4600
    },
    {
      "epoch": 0.19798571059653955,
      "eval_bleu": 26.17110017719131,
      "eval_gen_len": 27.325,
      "eval_loss": 2.852492332458496,
      "eval_runtime": 57.8755,
      "eval_samples_per_second": 17.278,
      "eval_steps_per_second": 1.089,
      "step": 4600
    },
    {
      "epoch": 0.19841611431522768,
      "grad_norm": 0.9274747371673584,
      "learning_rate": 0.00019931684507367754,
      "loss": 3.2354,
      "step": 4610
    },
    {
      "epoch": 0.19884651803391581,
      "grad_norm": 0.9550734162330627,
      "learning_rate": 0.00019931141221431631,
      "loss": 3.1298,
      "step": 4620
    },
    {
      "epoch": 0.19927692175260395,
      "grad_norm": 1.032633900642395,
      "learning_rate": 0.00019930595791237582,
      "loss": 3.1416,
      "step": 4630
    },
    {
      "epoch": 0.19970732547129208,
      "grad_norm": 1.0769306421279907,
      "learning_rate": 0.00019930048216903378,
      "loss": 3.0955,
      "step": 4640
    },
    {
      "epoch": 0.2001377291899802,
      "grad_norm": 1.0742985010147095,
      "learning_rate": 0.00019929498498547248,
      "loss": 3.0658,
      "step": 4650
    },
    {
      "epoch": 0.2001377291899802,
      "eval_bleu": 25.918484924358992,
      "eval_gen_len": 27.38,
      "eval_loss": 2.8527631759643555,
      "eval_runtime": 57.5002,
      "eval_samples_per_second": 17.391,
      "eval_steps_per_second": 1.096,
      "step": 4650
    },
    {
      "epoch": 0.20056813290866832,
      "grad_norm": 1.1043422222137451,
      "learning_rate": 0.00019928946636287874,
      "loss": 3.1779,
      "step": 4660
    },
    {
      "epoch": 0.20099853662735645,
      "grad_norm": 1.0533535480499268,
      "learning_rate": 0.0001992839263024442,
      "loss": 3.1474,
      "step": 4670
    },
    {
      "epoch": 0.20142894034604458,
      "grad_norm": 1.1885457038879395,
      "learning_rate": 0.000199278364805365,
      "loss": 3.2021,
      "step": 4680
    },
    {
      "epoch": 0.20185934406473272,
      "grad_norm": 0.9245094656944275,
      "learning_rate": 0.00019927278187284187,
      "loss": 3.0951,
      "step": 4690
    },
    {
      "epoch": 0.20228974778342085,
      "grad_norm": 1.0247694253921509,
      "learning_rate": 0.00019926717750608038,
      "loss": 3.1456,
      "step": 4700
    },
    {
      "epoch": 0.20228974778342085,
      "eval_bleu": 25.485430159766953,
      "eval_gen_len": 27.502,
      "eval_loss": 2.85323429107666,
      "eval_runtime": 57.8558,
      "eval_samples_per_second": 17.284,
      "eval_steps_per_second": 1.089,
      "step": 4700
    },
    {
      "epoch": 0.20272015150210898,
      "grad_norm": 1.0860263109207153,
      "learning_rate": 0.00019926155170629044,
      "loss": 3.1108,
      "step": 4710
    },
    {
      "epoch": 0.2031505552207971,
      "grad_norm": 1.0271128416061401,
      "learning_rate": 0.00019925590447468676,
      "loss": 3.1282,
      "step": 4720
    },
    {
      "epoch": 0.20358095893948525,
      "grad_norm": 0.9287423491477966,
      "learning_rate": 0.00019925023581248872,
      "loss": 3.2261,
      "step": 4730
    },
    {
      "epoch": 0.20401136265817338,
      "grad_norm": 1.0207690000534058,
      "learning_rate": 0.0001992445457209202,
      "loss": 3.1534,
      "step": 4740
    },
    {
      "epoch": 0.20444176637686148,
      "grad_norm": 0.9782305359840393,
      "learning_rate": 0.00019923883420120976,
      "loss": 3.1543,
      "step": 4750
    },
    {
      "epoch": 0.20444176637686148,
      "eval_bleu": 25.868892052886853,
      "eval_gen_len": 27.436,
      "eval_loss": 2.849299430847168,
      "eval_runtime": 57.6287,
      "eval_samples_per_second": 17.352,
      "eval_steps_per_second": 1.093,
      "step": 4750
    },
    {
      "epoch": 0.20487217009554962,
      "grad_norm": 1.0215333700180054,
      "learning_rate": 0.00019923310125459062,
      "loss": 3.2255,
      "step": 4760
    },
    {
      "epoch": 0.20530257381423775,
      "grad_norm": 1.0179297924041748,
      "learning_rate": 0.00019922734688230053,
      "loss": 3.2089,
      "step": 4770
    },
    {
      "epoch": 0.20573297753292588,
      "grad_norm": 0.8491853475570679,
      "learning_rate": 0.000199221571085582,
      "loss": 3.1231,
      "step": 4780
    },
    {
      "epoch": 0.20616338125161401,
      "grad_norm": 0.897818922996521,
      "learning_rate": 0.00019921577386568208,
      "loss": 3.1796,
      "step": 4790
    },
    {
      "epoch": 0.20659378497030215,
      "grad_norm": 0.9167509078979492,
      "learning_rate": 0.0001992099552238525,
      "loss": 3.2013,
      "step": 4800
    },
    {
      "epoch": 0.20659378497030215,
      "eval_bleu": 25.25315193960238,
      "eval_gen_len": 27.232,
      "eval_loss": 2.852261543273926,
      "eval_runtime": 57.3047,
      "eval_samples_per_second": 17.451,
      "eval_steps_per_second": 1.099,
      "step": 4800
    },
    {
      "epoch": 0.20702418868899028,
      "grad_norm": 1.1054540872573853,
      "learning_rate": 0.00019920411516134948,
      "loss": 3.1684,
      "step": 4810
    },
    {
      "epoch": 0.2074545924076784,
      "grad_norm": 1.0095288753509521,
      "learning_rate": 0.000199198253679434,
      "loss": 3.0859,
      "step": 4820
    },
    {
      "epoch": 0.20788499612636654,
      "grad_norm": 0.973652720451355,
      "learning_rate": 0.00019919237077937164,
      "loss": 3.1513,
      "step": 4830
    },
    {
      "epoch": 0.20831539984505465,
      "grad_norm": 0.9720274209976196,
      "learning_rate": 0.00019918646646243263,
      "loss": 3.1763,
      "step": 4840
    },
    {
      "epoch": 0.20874580356374278,
      "grad_norm": 0.9386062026023865,
      "learning_rate": 0.00019918054072989177,
      "loss": 3.1852,
      "step": 4850
    },
    {
      "epoch": 0.20874580356374278,
      "eval_bleu": 25.94927954071443,
      "eval_gen_len": 27.264,
      "eval_loss": 2.8457980155944824,
      "eval_runtime": 57.5145,
      "eval_samples_per_second": 17.387,
      "eval_steps_per_second": 1.095,
      "step": 4850
    },
    {
      "epoch": 0.20917620728243091,
      "grad_norm": 0.9580058455467224,
      "learning_rate": 0.00019917459358302845,
      "loss": 3.1912,
      "step": 4860
    },
    {
      "epoch": 0.20960661100111905,
      "grad_norm": 0.9301682114601135,
      "learning_rate": 0.00019916862502312673,
      "loss": 3.2448,
      "step": 4870
    },
    {
      "epoch": 0.21003701471980718,
      "grad_norm": 0.8369381427764893,
      "learning_rate": 0.0001991626350514754,
      "loss": 3.1604,
      "step": 4880
    },
    {
      "epoch": 0.2104674184384953,
      "grad_norm": 1.3006089925765991,
      "learning_rate": 0.00019915662366936767,
      "loss": 3.1303,
      "step": 4890
    },
    {
      "epoch": 0.21089782215718345,
      "grad_norm": 0.9800781607627869,
      "learning_rate": 0.0001991505908781015,
      "loss": 3.1738,
      "step": 4900
    },
    {
      "epoch": 0.21089782215718345,
      "eval_bleu": 25.555643040465924,
      "eval_gen_len": 27.406,
      "eval_loss": 2.848675012588501,
      "eval_runtime": 57.9521,
      "eval_samples_per_second": 17.256,
      "eval_steps_per_second": 1.087,
      "step": 4900
    },
    {
      "epoch": 0.21132822587587158,
      "grad_norm": 0.94611656665802,
      "learning_rate": 0.00019914453667897944,
      "loss": 3.1634,
      "step": 4910
    },
    {
      "epoch": 0.2117586295945597,
      "grad_norm": 1.0982459783554077,
      "learning_rate": 0.0001991384610733087,
      "loss": 3.1268,
      "step": 4920
    },
    {
      "epoch": 0.21218903331324782,
      "grad_norm": 0.9661852717399597,
      "learning_rate": 0.00019913236406240105,
      "loss": 3.1446,
      "step": 4930
    },
    {
      "epoch": 0.21261943703193595,
      "grad_norm": 1.038192629814148,
      "learning_rate": 0.0001991262456475729,
      "loss": 3.2087,
      "step": 4940
    },
    {
      "epoch": 0.21304984075062408,
      "grad_norm": 1.0264137983322144,
      "learning_rate": 0.00019912010583014535,
      "loss": 3.1689,
      "step": 4950
    },
    {
      "epoch": 0.21304984075062408,
      "eval_bleu": 25.99484714708411,
      "eval_gen_len": 27.4,
      "eval_loss": 2.8427066802978516,
      "eval_runtime": 57.7687,
      "eval_samples_per_second": 17.31,
      "eval_steps_per_second": 1.091,
      "step": 4950
    },
    {
      "epoch": 0.2134802444693122,
      "grad_norm": 0.8951813578605652,
      "learning_rate": 0.00019911394461144403,
      "loss": 3.2005,
      "step": 4960
    },
    {
      "epoch": 0.21391064818800035,
      "grad_norm": 0.9890700578689575,
      "learning_rate": 0.00019910776199279914,
      "loss": 3.1535,
      "step": 4970
    },
    {
      "epoch": 0.21434105190668848,
      "grad_norm": 1.021851658821106,
      "learning_rate": 0.00019910155797554576,
      "loss": 3.1581,
      "step": 4980
    },
    {
      "epoch": 0.2147714556253766,
      "grad_norm": 0.9088782668113708,
      "learning_rate": 0.00019909533256102325,
      "loss": 3.2705,
      "step": 4990
    },
    {
      "epoch": 0.21520185934406474,
      "grad_norm": 1.0181068181991577,
      "learning_rate": 0.00019908908575057583,
      "loss": 3.2095,
      "step": 5000
    },
    {
      "epoch": 0.21520185934406474,
      "eval_bleu": 25.846232556293398,
      "eval_gen_len": 27.451,
      "eval_loss": 2.8480913639068604,
      "eval_runtime": 57.8478,
      "eval_samples_per_second": 17.287,
      "eval_steps_per_second": 1.089,
      "step": 5000
    },
    {
      "epoch": 0.21563226306275285,
      "grad_norm": 0.986112117767334,
      "learning_rate": 0.00019908281754555228,
      "loss": 3.1706,
      "step": 5010
    },
    {
      "epoch": 0.21606266678144098,
      "grad_norm": 1.0256551504135132,
      "learning_rate": 0.00019907652794730595,
      "loss": 3.211,
      "step": 5020
    },
    {
      "epoch": 0.21649307050012911,
      "grad_norm": 0.9316505789756775,
      "learning_rate": 0.0001990702169571949,
      "loss": 3.1351,
      "step": 5030
    },
    {
      "epoch": 0.21692347421881725,
      "grad_norm": 0.8721300363540649,
      "learning_rate": 0.00019906388457658164,
      "loss": 3.1357,
      "step": 5040
    },
    {
      "epoch": 0.21735387793750538,
      "grad_norm": 1.0134340524673462,
      "learning_rate": 0.00019905753080683348,
      "loss": 3.1249,
      "step": 5050
    },
    {
      "epoch": 0.21735387793750538,
      "eval_bleu": 25.56480806805967,
      "eval_gen_len": 27.291,
      "eval_loss": 2.847784996032715,
      "eval_runtime": 57.4614,
      "eval_samples_per_second": 17.403,
      "eval_steps_per_second": 1.096,
      "step": 5050
    },
    {
      "epoch": 0.2177842816561935,
      "grad_norm": 0.9732480645179749,
      "learning_rate": 0.00019905115564932232,
      "loss": 3.1522,
      "step": 5060
    },
    {
      "epoch": 0.21821468537488165,
      "grad_norm": 0.9545836448669434,
      "learning_rate": 0.00019904475910542457,
      "loss": 3.1201,
      "step": 5070
    },
    {
      "epoch": 0.21864508909356978,
      "grad_norm": 1.0939570665359497,
      "learning_rate": 0.00019903834117652135,
      "loss": 3.0847,
      "step": 5080
    },
    {
      "epoch": 0.2190754928122579,
      "grad_norm": 1.0606935024261475,
      "learning_rate": 0.00019903190186399837,
      "loss": 3.1125,
      "step": 5090
    },
    {
      "epoch": 0.21950589653094602,
      "grad_norm": 1.124518632888794,
      "learning_rate": 0.00019902544116924596,
      "loss": 3.2628,
      "step": 5100
    },
    {
      "epoch": 0.21950589653094602,
      "eval_bleu": 25.369017968513944,
      "eval_gen_len": 27.176,
      "eval_loss": 2.8510117530822754,
      "eval_runtime": 57.2348,
      "eval_samples_per_second": 17.472,
      "eval_steps_per_second": 1.101,
      "step": 5100
    },
    {
      "epoch": 0.21993630024963415,
      "grad_norm": 0.9547955393791199,
      "learning_rate": 0.00019901895909365904,
      "loss": 3.1502,
      "step": 5110
    },
    {
      "epoch": 0.22036670396832228,
      "grad_norm": 0.9678354263305664,
      "learning_rate": 0.00019901245563863718,
      "loss": 3.1523,
      "step": 5120
    },
    {
      "epoch": 0.2207971076870104,
      "grad_norm": 0.8963330984115601,
      "learning_rate": 0.00019900593080558464,
      "loss": 3.1965,
      "step": 5130
    },
    {
      "epoch": 0.22122751140569855,
      "grad_norm": 0.8550633788108826,
      "learning_rate": 0.00019899938459591007,
      "loss": 3.0967,
      "step": 5140
    },
    {
      "epoch": 0.22165791512438668,
      "grad_norm": 1.006473422050476,
      "learning_rate": 0.000198992817011027,
      "loss": 3.2049,
      "step": 5150
    },
    {
      "epoch": 0.22165791512438668,
      "eval_bleu": 25.6313263996279,
      "eval_gen_len": 27.219,
      "eval_loss": 2.844245195388794,
      "eval_runtime": 57.148,
      "eval_samples_per_second": 17.498,
      "eval_steps_per_second": 1.102,
      "step": 5150
    },
    {
      "epoch": 0.2220883188430748,
      "grad_norm": 1.0326669216156006,
      "learning_rate": 0.00019898622805235338,
      "loss": 3.1038,
      "step": 5160
    },
    {
      "epoch": 0.22251872256176294,
      "grad_norm": 1.0226434469223022,
      "learning_rate": 0.00019897961772131188,
      "loss": 3.1633,
      "step": 5170
    },
    {
      "epoch": 0.22294912628045108,
      "grad_norm": 1.0163074731826782,
      "learning_rate": 0.00019897298601932978,
      "loss": 3.1867,
      "step": 5180
    },
    {
      "epoch": 0.22337952999913918,
      "grad_norm": 0.9716505408287048,
      "learning_rate": 0.00019896633294783886,
      "loss": 3.1444,
      "step": 5190
    },
    {
      "epoch": 0.22380993371782731,
      "grad_norm": 1.0428866147994995,
      "learning_rate": 0.00019895965850827568,
      "loss": 3.1655,
      "step": 5200
    },
    {
      "epoch": 0.22380993371782731,
      "eval_bleu": 25.868884986103417,
      "eval_gen_len": 27.274,
      "eval_loss": 2.8488478660583496,
      "eval_runtime": 57.4684,
      "eval_samples_per_second": 17.401,
      "eval_steps_per_second": 1.096,
      "step": 5200
    },
    {
      "epoch": 0.22424033743651545,
      "grad_norm": 0.9470906853675842,
      "learning_rate": 0.00019895296270208132,
      "loss": 3.175,
      "step": 5210
    },
    {
      "epoch": 0.22467074115520358,
      "grad_norm": 1.0485461950302124,
      "learning_rate": 0.00019894624553070149,
      "loss": 3.1975,
      "step": 5220
    },
    {
      "epoch": 0.2251011448738917,
      "grad_norm": 0.8596625924110413,
      "learning_rate": 0.00019893950699558646,
      "loss": 3.1405,
      "step": 5230
    },
    {
      "epoch": 0.22553154859257984,
      "grad_norm": 0.9877997040748596,
      "learning_rate": 0.00019893274709819125,
      "loss": 3.0973,
      "step": 5240
    },
    {
      "epoch": 0.22596195231126798,
      "grad_norm": 1.0110626220703125,
      "learning_rate": 0.00019892596583997535,
      "loss": 3.1615,
      "step": 5250
    },
    {
      "epoch": 0.22596195231126798,
      "eval_bleu": 25.8680412427537,
      "eval_gen_len": 27.403,
      "eval_loss": 2.843780994415283,
      "eval_runtime": 57.8598,
      "eval_samples_per_second": 17.283,
      "eval_steps_per_second": 1.089,
      "step": 5250
    },
    {
      "epoch": 0.2263923560299561,
      "grad_norm": 0.9795849323272705,
      "learning_rate": 0.00019891916322240297,
      "loss": 3.1163,
      "step": 5260
    },
    {
      "epoch": 0.22682275974864421,
      "grad_norm": 0.9606716632843018,
      "learning_rate": 0.0001989123392469428,
      "loss": 3.0549,
      "step": 5270
    },
    {
      "epoch": 0.22725316346733235,
      "grad_norm": 1.0759915113449097,
      "learning_rate": 0.00019890549391506825,
      "loss": 3.2335,
      "step": 5280
    },
    {
      "epoch": 0.22768356718602048,
      "grad_norm": 1.0657655000686646,
      "learning_rate": 0.00019889862722825735,
      "loss": 3.1482,
      "step": 5290
    },
    {
      "epoch": 0.2281139709047086,
      "grad_norm": 1.0143723487854004,
      "learning_rate": 0.00019889173918799267,
      "loss": 3.2024,
      "step": 5300
    },
    {
      "epoch": 0.2281139709047086,
      "eval_bleu": 25.346679376060507,
      "eval_gen_len": 27.29,
      "eval_loss": 2.850287914276123,
      "eval_runtime": 57.8593,
      "eval_samples_per_second": 17.283,
      "eval_steps_per_second": 1.089,
      "step": 5300
    },
    {
      "epoch": 0.22854437462339675,
      "grad_norm": 0.9600435495376587,
      "learning_rate": 0.00019888482979576146,
      "loss": 3.0897,
      "step": 5310
    },
    {
      "epoch": 0.22897477834208488,
      "grad_norm": 1.0023115873336792,
      "learning_rate": 0.0001988778990530555,
      "loss": 3.1086,
      "step": 5320
    },
    {
      "epoch": 0.229405182060773,
      "grad_norm": 0.9435893893241882,
      "learning_rate": 0.00019887094696137124,
      "loss": 3.1862,
      "step": 5330
    },
    {
      "epoch": 0.22983558577946114,
      "grad_norm": 0.86482834815979,
      "learning_rate": 0.00019886397352220976,
      "loss": 3.1447,
      "step": 5340
    },
    {
      "epoch": 0.23026598949814928,
      "grad_norm": 0.9239035248756409,
      "learning_rate": 0.00019885697873707665,
      "loss": 3.1138,
      "step": 5350
    },
    {
      "epoch": 0.23026598949814928,
      "eval_bleu": 25.625374072638657,
      "eval_gen_len": 27.426,
      "eval_loss": 2.844517707824707,
      "eval_runtime": 58.3551,
      "eval_samples_per_second": 17.136,
      "eval_steps_per_second": 1.08,
      "step": 5350
    },
    {
      "epoch": 0.23069639321683738,
      "grad_norm": 0.9787756204605103,
      "learning_rate": 0.0001988499626074822,
      "loss": 3.106,
      "step": 5360
    },
    {
      "epoch": 0.2311267969355255,
      "grad_norm": 0.9687784314155579,
      "learning_rate": 0.0001988429251349413,
      "loss": 3.0765,
      "step": 5370
    },
    {
      "epoch": 0.23155720065421365,
      "grad_norm": 1.0156818628311157,
      "learning_rate": 0.0001988358663209734,
      "loss": 3.1132,
      "step": 5380
    },
    {
      "epoch": 0.23198760437290178,
      "grad_norm": 1.024409294128418,
      "learning_rate": 0.0001988287861671026,
      "loss": 3.1659,
      "step": 5390
    },
    {
      "epoch": 0.2324180080915899,
      "grad_norm": 0.9968332648277283,
      "learning_rate": 0.0001988216846748576,
      "loss": 3.1384,
      "step": 5400
    },
    {
      "epoch": 0.2324180080915899,
      "eval_bleu": 25.160198977008513,
      "eval_gen_len": 27.292,
      "eval_loss": 2.8483760356903076,
      "eval_runtime": 57.5112,
      "eval_samples_per_second": 17.388,
      "eval_steps_per_second": 1.095,
      "step": 5400
    },
    {
      "epoch": 0.23284841181027804,
      "grad_norm": 0.9565609693527222,
      "learning_rate": 0.0001988145618457717,
      "loss": 3.1221,
      "step": 5410
    },
    {
      "epoch": 0.23327881552896618,
      "grad_norm": 0.9489671587944031,
      "learning_rate": 0.0001988074176813828,
      "loss": 3.1232,
      "step": 5420
    },
    {
      "epoch": 0.2337092192476543,
      "grad_norm": 0.9355062246322632,
      "learning_rate": 0.00019880025218323337,
      "loss": 3.228,
      "step": 5430
    },
    {
      "epoch": 0.23413962296634244,
      "grad_norm": 0.9541338682174683,
      "learning_rate": 0.00019879306535287064,
      "loss": 3.1688,
      "step": 5440
    },
    {
      "epoch": 0.23457002668503055,
      "grad_norm": 0.9389947056770325,
      "learning_rate": 0.00019878585719184625,
      "loss": 3.2023,
      "step": 5450
    },
    {
      "epoch": 0.23457002668503055,
      "eval_bleu": 25.421225377500487,
      "eval_gen_len": 27.369,
      "eval_loss": 2.8463356494903564,
      "eval_runtime": 57.9652,
      "eval_samples_per_second": 17.252,
      "eval_steps_per_second": 1.087,
      "step": 5450
    },
    {
      "epoch": 0.23500043040371868,
      "grad_norm": 1.0729273557662964,
      "learning_rate": 0.00019877862770171655,
      "loss": 3.1136,
      "step": 5460
    },
    {
      "epoch": 0.2354308341224068,
      "grad_norm": 0.9619083404541016,
      "learning_rate": 0.00019877137688404246,
      "loss": 3.0673,
      "step": 5470
    },
    {
      "epoch": 0.23586123784109495,
      "grad_norm": 0.9750327467918396,
      "learning_rate": 0.0001987641047403896,
      "loss": 3.2088,
      "step": 5480
    },
    {
      "epoch": 0.23629164155978308,
      "grad_norm": 0.9028642773628235,
      "learning_rate": 0.000198756811272328,
      "loss": 3.16,
      "step": 5490
    },
    {
      "epoch": 0.2367220452784712,
      "grad_norm": 1.0716166496276855,
      "learning_rate": 0.00019874949648143254,
      "loss": 3.1716,
      "step": 5500
    },
    {
      "epoch": 0.2367220452784712,
      "eval_bleu": 25.49032716907282,
      "eval_gen_len": 27.366,
      "eval_loss": 2.848048686981201,
      "eval_runtime": 58.096,
      "eval_samples_per_second": 17.213,
      "eval_steps_per_second": 1.084,
      "step": 5500
    },
    {
      "epoch": 0.23715244899715934,
      "grad_norm": 0.951885461807251,
      "learning_rate": 0.00019874216036928249,
      "loss": 3.2023,
      "step": 5510
    },
    {
      "epoch": 0.23758285271584748,
      "grad_norm": 0.9921894669532776,
      "learning_rate": 0.0001987348029374618,
      "loss": 3.1911,
      "step": 5520
    },
    {
      "epoch": 0.23801325643453558,
      "grad_norm": 0.8872546553611755,
      "learning_rate": 0.0001987274241875591,
      "loss": 3.1868,
      "step": 5530
    },
    {
      "epoch": 0.2384436601532237,
      "grad_norm": 0.9607574939727783,
      "learning_rate": 0.0001987200241211675,
      "loss": 3.1594,
      "step": 5540
    },
    {
      "epoch": 0.23887406387191185,
      "grad_norm": 0.9456505179405212,
      "learning_rate": 0.00019871260273988478,
      "loss": 3.2229,
      "step": 5550
    },
    {
      "epoch": 0.23887406387191185,
      "eval_bleu": 25.256777927176284,
      "eval_gen_len": 27.417,
      "eval_loss": 2.842465400695801,
      "eval_runtime": 57.8056,
      "eval_samples_per_second": 17.299,
      "eval_steps_per_second": 1.09,
      "step": 5550
    },
    {
      "epoch": 0.23930446759059998,
      "grad_norm": 1.0431827306747437,
      "learning_rate": 0.00019870516004531327,
      "loss": 3.1771,
      "step": 5560
    },
    {
      "epoch": 0.2397348713092881,
      "grad_norm": 1.0624552965164185,
      "learning_rate": 0.00019869769603906003,
      "loss": 3.0817,
      "step": 5570
    },
    {
      "epoch": 0.24016527502797624,
      "grad_norm": 0.9239343404769897,
      "learning_rate": 0.00019869021072273658,
      "loss": 3.1186,
      "step": 5580
    },
    {
      "epoch": 0.24059567874666438,
      "grad_norm": 0.885517954826355,
      "learning_rate": 0.00019868270409795907,
      "loss": 3.1469,
      "step": 5590
    },
    {
      "epoch": 0.2410260824653525,
      "grad_norm": 0.9504395127296448,
      "learning_rate": 0.00019867517616634835,
      "loss": 3.232,
      "step": 5600
    },
    {
      "epoch": 0.2410260824653525,
      "eval_bleu": 25.91610715869755,
      "eval_gen_len": 27.425,
      "eval_loss": 2.841496229171753,
      "eval_runtime": 58.288,
      "eval_samples_per_second": 17.156,
      "eval_steps_per_second": 1.081,
      "step": 5600
    },
    {
      "epoch": 0.24145648618404064,
      "grad_norm": 1.0321485996246338,
      "learning_rate": 0.0001986676269295297,
      "loss": 3.1306,
      "step": 5610
    },
    {
      "epoch": 0.24188688990272875,
      "grad_norm": 1.074483871459961,
      "learning_rate": 0.00019866005638913316,
      "loss": 3.1164,
      "step": 5620
    },
    {
      "epoch": 0.24231729362141688,
      "grad_norm": 1.0048795938491821,
      "learning_rate": 0.00019865246454679332,
      "loss": 3.2939,
      "step": 5630
    },
    {
      "epoch": 0.242747697340105,
      "grad_norm": 0.9126718640327454,
      "learning_rate": 0.00019864485140414927,
      "loss": 3.198,
      "step": 5640
    },
    {
      "epoch": 0.24317810105879314,
      "grad_norm": 1.028338074684143,
      "learning_rate": 0.00019863721696284484,
      "loss": 3.0818,
      "step": 5650
    },
    {
      "epoch": 0.24317810105879314,
      "eval_bleu": 25.434682293601508,
      "eval_gen_len": 27.324,
      "eval_loss": 2.847424268722534,
      "eval_runtime": 58.0088,
      "eval_samples_per_second": 17.239,
      "eval_steps_per_second": 1.086,
      "step": 5650
    },
    {
      "epoch": 0.24360850477748128,
      "grad_norm": 0.9702244997024536,
      "learning_rate": 0.00019862956122452844,
      "loss": 3.1163,
      "step": 5660
    },
    {
      "epoch": 0.2440389084961694,
      "grad_norm": 0.9279699921607971,
      "learning_rate": 0.00019862188419085298,
      "loss": 3.1974,
      "step": 5670
    },
    {
      "epoch": 0.24446931221485754,
      "grad_norm": 0.9141049981117249,
      "learning_rate": 0.000198614185863476,
      "loss": 3.1049,
      "step": 5680
    },
    {
      "epoch": 0.24489971593354568,
      "grad_norm": 0.8688049912452698,
      "learning_rate": 0.00019860646624405973,
      "loss": 3.1636,
      "step": 5690
    },
    {
      "epoch": 0.2453301196522338,
      "grad_norm": 0.8968715071678162,
      "learning_rate": 0.00019859872533427094,
      "loss": 3.0806,
      "step": 5700
    },
    {
      "epoch": 0.2453301196522338,
      "eval_bleu": 26.20039939542204,
      "eval_gen_len": 27.433,
      "eval_loss": 2.8436167240142822,
      "eval_runtime": 58.1143,
      "eval_samples_per_second": 17.207,
      "eval_steps_per_second": 1.084,
      "step": 5700
    },
    {
      "epoch": 0.2457605233709219,
      "grad_norm": 0.9263499975204468,
      "learning_rate": 0.00019859096313578094,
      "loss": 3.0771,
      "step": 5710
    },
    {
      "epoch": 0.24619092708961005,
      "grad_norm": 1.0468991994857788,
      "learning_rate": 0.0001985831796502657,
      "loss": 3.1859,
      "step": 5720
    },
    {
      "epoch": 0.24662133080829818,
      "grad_norm": 0.9732518792152405,
      "learning_rate": 0.00019857537487940577,
      "loss": 3.1182,
      "step": 5730
    },
    {
      "epoch": 0.2470517345269863,
      "grad_norm": 1.03751540184021,
      "learning_rate": 0.00019856754882488633,
      "loss": 3.2418,
      "step": 5740
    },
    {
      "epoch": 0.24748213824567444,
      "grad_norm": 1.0546284914016724,
      "learning_rate": 0.0001985597014883971,
      "loss": 3.1443,
      "step": 5750
    },
    {
      "epoch": 0.24748213824567444,
      "eval_bleu": 25.556386381951647,
      "eval_gen_len": 27.288,
      "eval_loss": 2.847050666809082,
      "eval_runtime": 57.8868,
      "eval_samples_per_second": 17.275,
      "eval_steps_per_second": 1.088,
      "step": 5750
    },
    {
      "epoch": 0.24791254196436258,
      "grad_norm": 0.8677738904953003,
      "learning_rate": 0.0001985518328716324,
      "loss": 3.132,
      "step": 5760
    },
    {
      "epoch": 0.2483429456830507,
      "grad_norm": 0.9816423654556274,
      "learning_rate": 0.0001985439429762912,
      "loss": 3.1758,
      "step": 5770
    },
    {
      "epoch": 0.24877334940173884,
      "grad_norm": 1.0572004318237305,
      "learning_rate": 0.00019853603180407703,
      "loss": 3.2187,
      "step": 5780
    },
    {
      "epoch": 0.24920375312042697,
      "grad_norm": 1.0403422117233276,
      "learning_rate": 0.00019852809935669793,
      "loss": 3.2012,
      "step": 5790
    },
    {
      "epoch": 0.24963415683911508,
      "grad_norm": 0.8911119699478149,
      "learning_rate": 0.00019852014563586672,
      "loss": 3.2096,
      "step": 5800
    },
    {
      "epoch": 0.24963415683911508,
      "eval_bleu": 25.541471731900216,
      "eval_gen_len": 27.312,
      "eval_loss": 2.8468217849731445,
      "eval_runtime": 57.7096,
      "eval_samples_per_second": 17.328,
      "eval_steps_per_second": 1.092,
      "step": 5800
    },
    {
      "epoch": 0.25006456055780324,
      "grad_norm": 0.9617970585823059,
      "learning_rate": 0.00019851217064330065,
      "loss": 3.2124,
      "step": 5810
    },
    {
      "epoch": 0.25049496427649137,
      "grad_norm": 0.9361907839775085,
      "learning_rate": 0.00019850417438072165,
      "loss": 3.2573,
      "step": 5820
    },
    {
      "epoch": 0.2509253679951795,
      "grad_norm": 1.0363637208938599,
      "learning_rate": 0.00019849615684985617,
      "loss": 3.1956,
      "step": 5830
    },
    {
      "epoch": 0.2513557717138676,
      "grad_norm": 0.9265010952949524,
      "learning_rate": 0.00019848811805243534,
      "loss": 3.1844,
      "step": 5840
    },
    {
      "epoch": 0.2517861754325557,
      "grad_norm": 1.0095579624176025,
      "learning_rate": 0.00019848005799019482,
      "loss": 3.1614,
      "step": 5850
    },
    {
      "epoch": 0.2517861754325557,
      "eval_bleu": 26.03152744796077,
      "eval_gen_len": 27.399,
      "eval_loss": 2.84273624420166,
      "eval_runtime": 57.6724,
      "eval_samples_per_second": 17.339,
      "eval_steps_per_second": 1.092,
      "step": 5850
    },
    {
      "epoch": 0.25221657915124385,
      "grad_norm": 1.071854829788208,
      "learning_rate": 0.00019847197666487487,
      "loss": 3.1163,
      "step": 5860
    },
    {
      "epoch": 0.252646982869932,
      "grad_norm": 0.8968753218650818,
      "learning_rate": 0.00019846387407822035,
      "loss": 3.1124,
      "step": 5870
    },
    {
      "epoch": 0.2530773865886201,
      "grad_norm": 1.01584792137146,
      "learning_rate": 0.00019845575023198073,
      "loss": 3.1773,
      "step": 5880
    },
    {
      "epoch": 0.25350779030730825,
      "grad_norm": 1.0665665864944458,
      "learning_rate": 0.00019844760512791005,
      "loss": 3.2018,
      "step": 5890
    },
    {
      "epoch": 0.2539381940259964,
      "grad_norm": 0.9796882271766663,
      "learning_rate": 0.00019843943876776693,
      "loss": 3.226,
      "step": 5900
    },
    {
      "epoch": 0.2539381940259964,
      "eval_bleu": 25.817520171480226,
      "eval_gen_len": 27.404,
      "eval_loss": 2.845564842224121,
      "eval_runtime": 58.2689,
      "eval_samples_per_second": 17.162,
      "eval_steps_per_second": 1.081,
      "step": 5900
    },
    {
      "epoch": 0.2543685977446845,
      "grad_norm": 0.8724120855331421,
      "learning_rate": 0.00019843125115331453,
      "loss": 3.1167,
      "step": 5910
    },
    {
      "epoch": 0.25479900146337264,
      "grad_norm": 0.9469226002693176,
      "learning_rate": 0.00019842304228632077,
      "loss": 3.0716,
      "step": 5920
    },
    {
      "epoch": 0.2552294051820608,
      "grad_norm": 1.070071816444397,
      "learning_rate": 0.00019841481216855797,
      "loss": 3.0768,
      "step": 5930
    },
    {
      "epoch": 0.2556598089007489,
      "grad_norm": 0.8839632868766785,
      "learning_rate": 0.00019840656080180317,
      "loss": 3.0926,
      "step": 5940
    },
    {
      "epoch": 0.25609021261943704,
      "grad_norm": 1.0195211172103882,
      "learning_rate": 0.0001983982881878379,
      "loss": 3.1821,
      "step": 5950
    },
    {
      "epoch": 0.25609021261943704,
      "eval_bleu": 26.247456390674184,
      "eval_gen_len": 27.411,
      "eval_loss": 2.846651792526245,
      "eval_runtime": 57.6548,
      "eval_samples_per_second": 17.345,
      "eval_steps_per_second": 1.093,
      "step": 5950
    },
    {
      "epoch": 0.2565206163381252,
      "grad_norm": 1.0212668180465698,
      "learning_rate": 0.00019838999432844831,
      "loss": 3.1199,
      "step": 5960
    },
    {
      "epoch": 0.2569510200568133,
      "grad_norm": 0.873650074005127,
      "learning_rate": 0.00019838167922542522,
      "loss": 3.0602,
      "step": 5970
    },
    {
      "epoch": 0.25738142377550144,
      "grad_norm": 0.9952044486999512,
      "learning_rate": 0.00019837334288056387,
      "loss": 3.2602,
      "step": 5980
    },
    {
      "epoch": 0.25781182749418957,
      "grad_norm": 0.9228849411010742,
      "learning_rate": 0.00019836498529566426,
      "loss": 3.0696,
      "step": 5990
    },
    {
      "epoch": 0.2582422312128777,
      "grad_norm": 0.9929625988006592,
      "learning_rate": 0.00019835660647253084,
      "loss": 3.1126,
      "step": 6000
    },
    {
      "epoch": 0.2582422312128777,
      "eval_bleu": 25.599862480130746,
      "eval_gen_len": 27.477,
      "eval_loss": 2.843564748764038,
      "eval_runtime": 57.829,
      "eval_samples_per_second": 17.292,
      "eval_steps_per_second": 1.089,
      "step": 6000
    },
    {
      "epoch": 0.2586726349315658,
      "grad_norm": 0.9788253307342529,
      "learning_rate": 0.00019834820641297275,
      "loss": 3.2101,
      "step": 6010
    },
    {
      "epoch": 0.2591030386502539,
      "grad_norm": 0.9796926379203796,
      "learning_rate": 0.00019833978511880364,
      "loss": 3.1685,
      "step": 6020
    },
    {
      "epoch": 0.25953344236894205,
      "grad_norm": 0.9753658175468445,
      "learning_rate": 0.00019833134259184177,
      "loss": 3.1241,
      "step": 6030
    },
    {
      "epoch": 0.2599638460876302,
      "grad_norm": 0.8291313052177429,
      "learning_rate": 0.00019832287883391004,
      "loss": 3.09,
      "step": 6040
    },
    {
      "epoch": 0.2603942498063183,
      "grad_norm": 1.0170693397521973,
      "learning_rate": 0.00019831439384683579,
      "loss": 3.1269,
      "step": 6050
    },
    {
      "epoch": 0.2603942498063183,
      "eval_bleu": 26.187217404705912,
      "eval_gen_len": 27.361,
      "eval_loss": 2.8441624641418457,
      "eval_runtime": 57.8747,
      "eval_samples_per_second": 17.279,
      "eval_steps_per_second": 1.089,
      "step": 6050
    },
    {
      "epoch": 0.26082465352500644,
      "grad_norm": 1.0384674072265625,
      "learning_rate": 0.0001983058876324511,
      "loss": 3.1032,
      "step": 6060
    },
    {
      "epoch": 0.2612550572436946,
      "grad_norm": 0.9461928009986877,
      "learning_rate": 0.00019829736019259255,
      "loss": 3.1281,
      "step": 6070
    },
    {
      "epoch": 0.2616854609623827,
      "grad_norm": 1.0532811880111694,
      "learning_rate": 0.00019828881152910135,
      "loss": 3.253,
      "step": 6080
    },
    {
      "epoch": 0.26211586468107084,
      "grad_norm": 0.8794360160827637,
      "learning_rate": 0.00019828024164382323,
      "loss": 3.1792,
      "step": 6090
    },
    {
      "epoch": 0.262546268399759,
      "grad_norm": 0.9301809072494507,
      "learning_rate": 0.0001982716505386085,
      "loss": 3.1071,
      "step": 6100
    },
    {
      "epoch": 0.262546268399759,
      "eval_bleu": 26.430361749542733,
      "eval_gen_len": 27.399,
      "eval_loss": 2.8424718379974365,
      "eval_runtime": 58.3695,
      "eval_samples_per_second": 17.132,
      "eval_steps_per_second": 1.079,
      "step": 6100
    },
    {
      "epoch": 0.2629766721184471,
      "grad_norm": 0.9331299066543579,
      "learning_rate": 0.0001982630382153122,
      "loss": 3.1612,
      "step": 6110
    },
    {
      "epoch": 0.26340707583713524,
      "grad_norm": 1.022333025932312,
      "learning_rate": 0.0001982544046757937,
      "loss": 3.1419,
      "step": 6120
    },
    {
      "epoch": 0.2638374795558234,
      "grad_norm": 0.9428563117980957,
      "learning_rate": 0.0001982457499219172,
      "loss": 3.0815,
      "step": 6130
    },
    {
      "epoch": 0.2642678832745115,
      "grad_norm": 0.897826075553894,
      "learning_rate": 0.00019823707395555132,
      "loss": 3.0,
      "step": 6140
    },
    {
      "epoch": 0.26469828699319964,
      "grad_norm": 0.9891902804374695,
      "learning_rate": 0.0001982283767785693,
      "loss": 3.1381,
      "step": 6150
    },
    {
      "epoch": 0.26469828699319964,
      "eval_bleu": 26.01773318191057,
      "eval_gen_len": 27.362,
      "eval_loss": 2.8443682193756104,
      "eval_runtime": 57.919,
      "eval_samples_per_second": 17.265,
      "eval_steps_per_second": 1.088,
      "step": 6150
    },
    {
      "epoch": 0.26512869071188777,
      "grad_norm": 1.0116009712219238,
      "learning_rate": 0.00019821965839284902,
      "loss": 3.1794,
      "step": 6160
    },
    {
      "epoch": 0.2655590944305759,
      "grad_norm": 0.9742121696472168,
      "learning_rate": 0.00019821091880027286,
      "loss": 3.1669,
      "step": 6170
    },
    {
      "epoch": 0.26598949814926404,
      "grad_norm": 0.7864747047424316,
      "learning_rate": 0.00019820215800272773,
      "loss": 3.0687,
      "step": 6180
    },
    {
      "epoch": 0.2664199018679521,
      "grad_norm": 0.9946993589401245,
      "learning_rate": 0.00019819337600210534,
      "loss": 3.106,
      "step": 6190
    },
    {
      "epoch": 0.26685030558664025,
      "grad_norm": 1.073522686958313,
      "learning_rate": 0.00019818457280030175,
      "loss": 3.1891,
      "step": 6200
    },
    {
      "epoch": 0.26685030558664025,
      "eval_bleu": 26.068572279474314,
      "eval_gen_len": 27.311,
      "eval_loss": 2.839111328125,
      "eval_runtime": 57.9003,
      "eval_samples_per_second": 17.271,
      "eval_steps_per_second": 1.088,
      "step": 6200
    },
    {
      "epoch": 0.2672807093053284,
      "grad_norm": 0.9220913648605347,
      "learning_rate": 0.0001981757483992177,
      "loss": 3.1843,
      "step": 6210
    },
    {
      "epoch": 0.2677111130240165,
      "grad_norm": 0.898540198802948,
      "learning_rate": 0.0001981669028007585,
      "loss": 2.9984,
      "step": 6220
    },
    {
      "epoch": 0.26814151674270464,
      "grad_norm": 0.9610406160354614,
      "learning_rate": 0.00019815803600683397,
      "loss": 3.0883,
      "step": 6230
    },
    {
      "epoch": 0.2685719204613928,
      "grad_norm": 0.9771255254745483,
      "learning_rate": 0.00019814914801935865,
      "loss": 3.0663,
      "step": 6240
    },
    {
      "epoch": 0.2690023241800809,
      "grad_norm": 0.9373309016227722,
      "learning_rate": 0.00019814023884025147,
      "loss": 3.1155,
      "step": 6250
    },
    {
      "epoch": 0.2690023241800809,
      "eval_bleu": 25.696160138226524,
      "eval_gen_len": 27.455,
      "eval_loss": 2.8462350368499756,
      "eval_runtime": 57.9833,
      "eval_samples_per_second": 17.246,
      "eval_steps_per_second": 1.087,
      "step": 6250
    },
    {
      "epoch": 0.26943272789876904,
      "grad_norm": 0.9499581456184387,
      "learning_rate": 0.00019813130847143613,
      "loss": 3.1457,
      "step": 6260
    },
    {
      "epoch": 0.2698631316174572,
      "grad_norm": 0.9090079069137573,
      "learning_rate": 0.00019812235691484074,
      "loss": 3.188,
      "step": 6270
    },
    {
      "epoch": 0.2702935353361453,
      "grad_norm": 1.067699909210205,
      "learning_rate": 0.00019811338417239805,
      "loss": 3.1774,
      "step": 6280
    },
    {
      "epoch": 0.27072393905483344,
      "grad_norm": 0.9557921290397644,
      "learning_rate": 0.00019810439024604547,
      "loss": 3.0585,
      "step": 6290
    },
    {
      "epoch": 0.2711543427735216,
      "grad_norm": 0.9191426038742065,
      "learning_rate": 0.0001980953751377248,
      "loss": 3.1486,
      "step": 6300
    },
    {
      "epoch": 0.2711543427735216,
      "eval_bleu": 25.331381572652397,
      "eval_gen_len": 27.213,
      "eval_loss": 2.841182231903076,
      "eval_runtime": 57.4955,
      "eval_samples_per_second": 17.393,
      "eval_steps_per_second": 1.096,
      "step": 6300
    },
    {
      "epoch": 0.2715847464922097,
      "grad_norm": 1.082428216934204,
      "learning_rate": 0.0001980863388493826,
      "loss": 3.3942,
      "step": 6310
    },
    {
      "epoch": 0.27201515021089784,
      "grad_norm": 0.9261111617088318,
      "learning_rate": 0.00019807728138296983,
      "loss": 3.1104,
      "step": 6320
    },
    {
      "epoch": 0.27244555392958597,
      "grad_norm": 0.9247400164604187,
      "learning_rate": 0.0001980682027404422,
      "loss": 3.0066,
      "step": 6330
    },
    {
      "epoch": 0.2728759576482741,
      "grad_norm": 0.983665406703949,
      "learning_rate": 0.00019805910292375984,
      "loss": 3.0808,
      "step": 6340
    },
    {
      "epoch": 0.27330636136696224,
      "grad_norm": 0.9558126926422119,
      "learning_rate": 0.00019804998193488754,
      "loss": 3.1511,
      "step": 6350
    },
    {
      "epoch": 0.27330636136696224,
      "eval_bleu": 25.982786904721664,
      "eval_gen_len": 27.195,
      "eval_loss": 2.8419275283813477,
      "eval_runtime": 57.7299,
      "eval_samples_per_second": 17.322,
      "eval_steps_per_second": 1.091,
      "step": 6350
    },
    {
      "epoch": 0.2737367650856503,
      "grad_norm": 0.8895946741104126,
      "learning_rate": 0.00019804083977579463,
      "loss": 3.1406,
      "step": 6360
    },
    {
      "epoch": 0.27416716880433845,
      "grad_norm": 0.9633764624595642,
      "learning_rate": 0.00019803167644845502,
      "loss": 3.1076,
      "step": 6370
    },
    {
      "epoch": 0.2745975725230266,
      "grad_norm": 1.0756059885025024,
      "learning_rate": 0.00019802249195484718,
      "loss": 3.07,
      "step": 6380
    },
    {
      "epoch": 0.2750279762417147,
      "grad_norm": 0.9028191566467285,
      "learning_rate": 0.0001980132862969542,
      "loss": 3.1538,
      "step": 6390
    },
    {
      "epoch": 0.27545837996040284,
      "grad_norm": 0.992559552192688,
      "learning_rate": 0.00019800405947676363,
      "loss": 3.167,
      "step": 6400
    },
    {
      "epoch": 0.27545837996040284,
      "eval_bleu": 25.768715284810355,
      "eval_gen_len": 27.318,
      "eval_loss": 2.8422138690948486,
      "eval_runtime": 57.9119,
      "eval_samples_per_second": 17.268,
      "eval_steps_per_second": 1.088,
      "step": 6400
    },
    {
      "epoch": 0.275888783679091,
      "grad_norm": 0.9344359636306763,
      "learning_rate": 0.00019799481149626767,
      "loss": 3.1179,
      "step": 6410
    },
    {
      "epoch": 0.2763191873977791,
      "grad_norm": 1.2100577354431152,
      "learning_rate": 0.0001979855423574631,
      "loss": 3.2598,
      "step": 6420
    },
    {
      "epoch": 0.27674959111646724,
      "grad_norm": 0.888805627822876,
      "learning_rate": 0.00019797625206235123,
      "loss": 3.2439,
      "step": 6430
    },
    {
      "epoch": 0.2771799948351554,
      "grad_norm": 0.9946755766868591,
      "learning_rate": 0.00019796694061293798,
      "loss": 3.2411,
      "step": 6440
    },
    {
      "epoch": 0.2776103985538435,
      "grad_norm": 0.9626907110214233,
      "learning_rate": 0.0001979576080112338,
      "loss": 3.1264,
      "step": 6450
    },
    {
      "epoch": 0.2776103985538435,
      "eval_bleu": 25.699858989702175,
      "eval_gen_len": 27.425,
      "eval_loss": 2.8400347232818604,
      "eval_runtime": 57.7956,
      "eval_samples_per_second": 17.302,
      "eval_steps_per_second": 1.09,
      "step": 6450
    },
    {
      "epoch": 0.27804080227253164,
      "grad_norm": 0.9581143260002136,
      "learning_rate": 0.00019794825425925366,
      "loss": 3.2028,
      "step": 6460
    },
    {
      "epoch": 0.2784712059912198,
      "grad_norm": 1.074588656425476,
      "learning_rate": 0.0001979388793590172,
      "loss": 3.24,
      "step": 6470
    },
    {
      "epoch": 0.2789016097099079,
      "grad_norm": 0.9844720959663391,
      "learning_rate": 0.0001979294833125486,
      "loss": 3.2097,
      "step": 6480
    },
    {
      "epoch": 0.27933201342859604,
      "grad_norm": 1.0406609773635864,
      "learning_rate": 0.00019792006612187653,
      "loss": 3.2398,
      "step": 6490
    },
    {
      "epoch": 0.27976241714728417,
      "grad_norm": 0.8905289769172668,
      "learning_rate": 0.0001979106277890343,
      "loss": 3.2199,
      "step": 6500
    },
    {
      "epoch": 0.27976241714728417,
      "eval_bleu": 25.23433753088007,
      "eval_gen_len": 27.208,
      "eval_loss": 2.8457345962524414,
      "eval_runtime": 57.2528,
      "eval_samples_per_second": 17.466,
      "eval_steps_per_second": 1.1,
      "step": 6500
    },
    {
      "epoch": 0.2801928208659723,
      "grad_norm": 0.9185120463371277,
      "learning_rate": 0.0001979011683160598,
      "loss": 3.1098,
      "step": 6510
    },
    {
      "epoch": 0.28062322458466044,
      "grad_norm": 0.9334560632705688,
      "learning_rate": 0.00019789168770499536,
      "loss": 3.0553,
      "step": 6520
    },
    {
      "epoch": 0.28105362830334857,
      "grad_norm": 0.9347316026687622,
      "learning_rate": 0.00019788218595788806,
      "loss": 3.2066,
      "step": 6530
    },
    {
      "epoch": 0.28148403202203665,
      "grad_norm": 0.9723507165908813,
      "learning_rate": 0.0001978726630767894,
      "loss": 3.1113,
      "step": 6540
    },
    {
      "epoch": 0.2819144357407248,
      "grad_norm": 0.9728957414627075,
      "learning_rate": 0.00019786311906375552,
      "loss": 3.143,
      "step": 6550
    },
    {
      "epoch": 0.2819144357407248,
      "eval_bleu": 25.211976878793248,
      "eval_gen_len": 27.222,
      "eval_loss": 2.8489463329315186,
      "eval_runtime": 57.4572,
      "eval_samples_per_second": 17.404,
      "eval_steps_per_second": 1.096,
      "step": 6550
    },
    {
      "epoch": 0.2823448394594129,
      "grad_norm": 0.7771197557449341,
      "learning_rate": 0.00019785355392084705,
      "loss": 3.1288,
      "step": 6560
    },
    {
      "epoch": 0.28277524317810104,
      "grad_norm": 1.0118564367294312,
      "learning_rate": 0.00019784396765012922,
      "loss": 3.1935,
      "step": 6570
    },
    {
      "epoch": 0.2832056468967892,
      "grad_norm": 0.9586213231086731,
      "learning_rate": 0.00019783436025367187,
      "loss": 3.0997,
      "step": 6580
    },
    {
      "epoch": 0.2836360506154773,
      "grad_norm": 0.9847359657287598,
      "learning_rate": 0.00019782473173354933,
      "loss": 3.0269,
      "step": 6590
    },
    {
      "epoch": 0.28406645433416544,
      "grad_norm": 0.9334093332290649,
      "learning_rate": 0.00019781508209184054,
      "loss": 3.1433,
      "step": 6600
    },
    {
      "epoch": 0.28406645433416544,
      "eval_bleu": 25.866460105719373,
      "eval_gen_len": 27.355,
      "eval_loss": 2.8450255393981934,
      "eval_runtime": 58.7016,
      "eval_samples_per_second": 17.035,
      "eval_steps_per_second": 1.073,
      "step": 6600
    },
    {
      "epoch": 0.2844968580528536,
      "grad_norm": 0.8766794204711914,
      "learning_rate": 0.00019780541133062896,
      "loss": 3.1247,
      "step": 6610
    },
    {
      "epoch": 0.2849272617715417,
      "grad_norm": 1.2863625288009644,
      "learning_rate": 0.00019779571945200262,
      "loss": 3.2295,
      "step": 6620
    },
    {
      "epoch": 0.28535766549022984,
      "grad_norm": 0.9678082466125488,
      "learning_rate": 0.00019778600645805415,
      "loss": 3.0565,
      "step": 6630
    },
    {
      "epoch": 0.28578806920891797,
      "grad_norm": 0.9260534048080444,
      "learning_rate": 0.00019777627235088068,
      "loss": 3.1967,
      "step": 6640
    },
    {
      "epoch": 0.2862184729276061,
      "grad_norm": 0.9201626777648926,
      "learning_rate": 0.00019776651713258392,
      "loss": 3.0481,
      "step": 6650
    },
    {
      "epoch": 0.2862184729276061,
      "eval_bleu": 26.240996838725557,
      "eval_gen_len": 27.328,
      "eval_loss": 2.8420066833496094,
      "eval_runtime": 58.487,
      "eval_samples_per_second": 17.098,
      "eval_steps_per_second": 1.077,
      "step": 6650
    },
    {
      "epoch": 0.28664887664629424,
      "grad_norm": 1.009650468826294,
      "learning_rate": 0.00019775674080527015,
      "loss": 3.0984,
      "step": 6660
    },
    {
      "epoch": 0.28707928036498237,
      "grad_norm": 0.9236922264099121,
      "learning_rate": 0.00019774694337105025,
      "loss": 3.1202,
      "step": 6670
    },
    {
      "epoch": 0.2875096840836705,
      "grad_norm": 0.9067606925964355,
      "learning_rate": 0.00019773712483203953,
      "loss": 3.1214,
      "step": 6680
    },
    {
      "epoch": 0.28794008780235864,
      "grad_norm": 1.1277772188186646,
      "learning_rate": 0.00019772728519035798,
      "loss": 3.1775,
      "step": 6690
    },
    {
      "epoch": 0.28837049152104677,
      "grad_norm": 1.0015270709991455,
      "learning_rate": 0.0001977174244481301,
      "loss": 3.2094,
      "step": 6700
    },
    {
      "epoch": 0.28837049152104677,
      "eval_bleu": 26.08079094183417,
      "eval_gen_len": 27.431,
      "eval_loss": 2.843677282333374,
      "eval_runtime": 58.0555,
      "eval_samples_per_second": 17.225,
      "eval_steps_per_second": 1.085,
      "step": 6700
    },
    {
      "epoch": 0.28880089523973484,
      "grad_norm": 1.033720850944519,
      "learning_rate": 0.00019770754260748494,
      "loss": 3.1413,
      "step": 6710
    },
    {
      "epoch": 0.289231298958423,
      "grad_norm": 0.9250594973564148,
      "learning_rate": 0.00019769763967055615,
      "loss": 3.1974,
      "step": 6720
    },
    {
      "epoch": 0.2896617026771111,
      "grad_norm": 0.9757328033447266,
      "learning_rate": 0.0001976877156394818,
      "loss": 3.1349,
      "step": 6730
    },
    {
      "epoch": 0.29009210639579924,
      "grad_norm": 1.1080766916275024,
      "learning_rate": 0.00019767777051640472,
      "loss": 3.2406,
      "step": 6740
    },
    {
      "epoch": 0.2905225101144874,
      "grad_norm": 1.0380741357803345,
      "learning_rate": 0.00019766780430347213,
      "loss": 3.1122,
      "step": 6750
    },
    {
      "epoch": 0.2905225101144874,
      "eval_bleu": 25.322280152289583,
      "eval_gen_len": 27.43,
      "eval_loss": 2.845682144165039,
      "eval_runtime": 57.7598,
      "eval_samples_per_second": 17.313,
      "eval_steps_per_second": 1.091,
      "step": 6750
    },
    {
      "epoch": 0.2909529138331755,
      "grad_norm": 0.9336857199668884,
      "learning_rate": 0.0001976578170028359,
      "loss": 3.1105,
      "step": 6760
    },
    {
      "epoch": 0.29138331755186364,
      "grad_norm": 0.9942007660865784,
      "learning_rate": 0.00019764780861665238,
      "loss": 3.098,
      "step": 6770
    },
    {
      "epoch": 0.2918137212705518,
      "grad_norm": 0.8551523685455322,
      "learning_rate": 0.00019763777914708248,
      "loss": 3.0654,
      "step": 6780
    },
    {
      "epoch": 0.2922441249892399,
      "grad_norm": 0.959348738193512,
      "learning_rate": 0.00019762772859629175,
      "loss": 3.1821,
      "step": 6790
    },
    {
      "epoch": 0.29267452870792804,
      "grad_norm": 0.8474471569061279,
      "learning_rate": 0.0001976176569664502,
      "loss": 3.1112,
      "step": 6800
    },
    {
      "epoch": 0.29267452870792804,
      "eval_bleu": 26.293398911689863,
      "eval_gen_len": 27.396,
      "eval_loss": 2.84013295173645,
      "eval_runtime": 57.6432,
      "eval_samples_per_second": 17.348,
      "eval_steps_per_second": 1.093,
      "step": 6800
    },
    {
      "epoch": 0.29310493242661617,
      "grad_norm": 0.9923979640007019,
      "learning_rate": 0.00019760756425973242,
      "loss": 3.0632,
      "step": 6810
    },
    {
      "epoch": 0.2935353361453043,
      "grad_norm": 1.0348154306411743,
      "learning_rate": 0.00019759745047831756,
      "loss": 3.0988,
      "step": 6820
    },
    {
      "epoch": 0.29396573986399244,
      "grad_norm": 0.9221979379653931,
      "learning_rate": 0.00019758731562438933,
      "loss": 3.0896,
      "step": 6830
    },
    {
      "epoch": 0.29439614358268057,
      "grad_norm": 0.8668000102043152,
      "learning_rate": 0.0001975771597001359,
      "loss": 3.2505,
      "step": 6840
    },
    {
      "epoch": 0.2948265473013687,
      "grad_norm": 0.9380924105644226,
      "learning_rate": 0.00019756698270775015,
      "loss": 3.1221,
      "step": 6850
    },
    {
      "epoch": 0.2948265473013687,
      "eval_bleu": 25.730358155052418,
      "eval_gen_len": 27.351,
      "eval_loss": 2.847959041595459,
      "eval_runtime": 57.6727,
      "eval_samples_per_second": 17.339,
      "eval_steps_per_second": 1.092,
      "step": 6850
    },
    {
      "epoch": 0.29525695102005683,
      "grad_norm": 0.889427900314331,
      "learning_rate": 0.00019755678464942938,
      "loss": 3.0842,
      "step": 6860
    },
    {
      "epoch": 0.29568735473874497,
      "grad_norm": 1.021604061126709,
      "learning_rate": 0.00019754656552737547,
      "loss": 3.1079,
      "step": 6870
    },
    {
      "epoch": 0.29611775845743304,
      "grad_norm": 0.9519371390342712,
      "learning_rate": 0.00019753632534379487,
      "loss": 3.1124,
      "step": 6880
    },
    {
      "epoch": 0.2965481621761212,
      "grad_norm": 0.9442533850669861,
      "learning_rate": 0.00019752606410089856,
      "loss": 3.1238,
      "step": 6890
    },
    {
      "epoch": 0.2969785658948093,
      "grad_norm": 0.9348695278167725,
      "learning_rate": 0.00019751578180090203,
      "loss": 3.0858,
      "step": 6900
    },
    {
      "epoch": 0.2969785658948093,
      "eval_bleu": 26.15052410920382,
      "eval_gen_len": 27.358,
      "eval_loss": 2.841749906539917,
      "eval_runtime": 57.9915,
      "eval_samples_per_second": 17.244,
      "eval_steps_per_second": 1.086,
      "step": 6900
    },
    {
      "epoch": 0.29740896961349744,
      "grad_norm": 0.8469899296760559,
      "learning_rate": 0.00019750547844602547,
      "loss": 3.0142,
      "step": 6910
    },
    {
      "epoch": 0.2978393733321856,
      "grad_norm": 0.9322359561920166,
      "learning_rate": 0.00019749515403849342,
      "loss": 3.0487,
      "step": 6920
    },
    {
      "epoch": 0.2982697770508737,
      "grad_norm": 1.0170655250549316,
      "learning_rate": 0.00019748480858053502,
      "loss": 3.1301,
      "step": 6930
    },
    {
      "epoch": 0.29870018076956184,
      "grad_norm": 0.8495339751243591,
      "learning_rate": 0.00019747444207438407,
      "loss": 3.1263,
      "step": 6940
    },
    {
      "epoch": 0.29913058448825,
      "grad_norm": 1.0707621574401855,
      "learning_rate": 0.00019746405452227873,
      "loss": 3.1145,
      "step": 6950
    },
    {
      "epoch": 0.29913058448825,
      "eval_bleu": 26.16410756192257,
      "eval_gen_len": 27.586,
      "eval_loss": 2.83890438079834,
      "eval_runtime": 58.4552,
      "eval_samples_per_second": 17.107,
      "eval_steps_per_second": 1.078,
      "step": 6950
    },
    {
      "epoch": 0.2995609882069381,
      "grad_norm": 1.0374257564544678,
      "learning_rate": 0.0001974536459264619,
      "loss": 3.1143,
      "step": 6960
    },
    {
      "epoch": 0.29999139192562624,
      "grad_norm": 0.8775110840797424,
      "learning_rate": 0.00019744321628918087,
      "loss": 3.1168,
      "step": 6970
    },
    {
      "epoch": 0.30042179564431437,
      "grad_norm": 0.9014039039611816,
      "learning_rate": 0.00019743276561268758,
      "loss": 3.2239,
      "step": 6980
    },
    {
      "epoch": 0.3008521993630025,
      "grad_norm": 0.8741612434387207,
      "learning_rate": 0.00019742229389923836,
      "loss": 3.0006,
      "step": 6990
    },
    {
      "epoch": 0.30128260308169064,
      "grad_norm": 1.0650498867034912,
      "learning_rate": 0.0001974118011510943,
      "loss": 3.0604,
      "step": 7000
    },
    {
      "epoch": 0.30128260308169064,
      "eval_bleu": 26.20258401559786,
      "eval_gen_len": 27.467,
      "eval_loss": 2.836580276489258,
      "eval_runtime": 58.4467,
      "eval_samples_per_second": 17.11,
      "eval_steps_per_second": 1.078,
      "step": 7000
    },
    {
      "epoch": 0.30171300680037877,
      "grad_norm": 0.959293782711029,
      "learning_rate": 0.00019740128737052084,
      "loss": 3.1632,
      "step": 7010
    },
    {
      "epoch": 0.3021434105190669,
      "grad_norm": 1.0318424701690674,
      "learning_rate": 0.0001973907525597881,
      "loss": 3.161,
      "step": 7020
    },
    {
      "epoch": 0.30257381423775503,
      "grad_norm": 0.9466184377670288,
      "learning_rate": 0.0001973801967211706,
      "loss": 3.1441,
      "step": 7030
    },
    {
      "epoch": 0.30300421795644317,
      "grad_norm": 0.9266014099121094,
      "learning_rate": 0.0001973696198569475,
      "loss": 3.102,
      "step": 7040
    },
    {
      "epoch": 0.3034346216751313,
      "grad_norm": 0.9722874164581299,
      "learning_rate": 0.00019735902196940254,
      "loss": 3.0876,
      "step": 7050
    },
    {
      "epoch": 0.3034346216751313,
      "eval_bleu": 26.207952779295574,
      "eval_gen_len": 27.355,
      "eval_loss": 2.839517831802368,
      "eval_runtime": 58.1693,
      "eval_samples_per_second": 17.191,
      "eval_steps_per_second": 1.083,
      "step": 7050
    },
    {
      "epoch": 0.3038650253938194,
      "grad_norm": 1.0819529294967651,
      "learning_rate": 0.00019734840306082386,
      "loss": 3.2277,
      "step": 7060
    },
    {
      "epoch": 0.3042954291125075,
      "grad_norm": 0.8212118148803711,
      "learning_rate": 0.0001973377631335043,
      "loss": 3.194,
      "step": 7070
    },
    {
      "epoch": 0.30472583283119564,
      "grad_norm": 0.895704448223114,
      "learning_rate": 0.00019732710218974106,
      "loss": 3.1416,
      "step": 7080
    },
    {
      "epoch": 0.3051562365498838,
      "grad_norm": 0.925601601600647,
      "learning_rate": 0.00019731642023183604,
      "loss": 3.0694,
      "step": 7090
    },
    {
      "epoch": 0.3055866402685719,
      "grad_norm": 0.9740682244300842,
      "learning_rate": 0.00019730571726209555,
      "loss": 3.2808,
      "step": 7100
    },
    {
      "epoch": 0.3055866402685719,
      "eval_bleu": 25.569274002604548,
      "eval_gen_len": 27.517,
      "eval_loss": 2.8397865295410156,
      "eval_runtime": 58.2227,
      "eval_samples_per_second": 17.175,
      "eval_steps_per_second": 1.082,
      "step": 7100
    },
    {
      "epoch": 0.30601704398726004,
      "grad_norm": 0.92666095495224,
      "learning_rate": 0.00019729499328283054,
      "loss": 3.1271,
      "step": 7110
    },
    {
      "epoch": 0.3064474477059482,
      "grad_norm": 0.9816181063652039,
      "learning_rate": 0.00019728424829635642,
      "loss": 3.3222,
      "step": 7120
    },
    {
      "epoch": 0.3068778514246363,
      "grad_norm": 0.9211257696151733,
      "learning_rate": 0.00019727348230499323,
      "loss": 3.2084,
      "step": 7130
    },
    {
      "epoch": 0.30730825514332444,
      "grad_norm": 0.9727537631988525,
      "learning_rate": 0.0001972626953110654,
      "loss": 3.0944,
      "step": 7140
    },
    {
      "epoch": 0.30773865886201257,
      "grad_norm": 1.0182873010635376,
      "learning_rate": 0.00019725188731690204,
      "loss": 3.1582,
      "step": 7150
    },
    {
      "epoch": 0.30773865886201257,
      "eval_bleu": 25.654371817056735,
      "eval_gen_len": 27.292,
      "eval_loss": 2.8395469188690186,
      "eval_runtime": 58.5109,
      "eval_samples_per_second": 17.091,
      "eval_steps_per_second": 1.077,
      "step": 7150
    },
    {
      "epoch": 0.3081690625807007,
      "grad_norm": 0.9952307939529419,
      "learning_rate": 0.0001972410583248367,
      "loss": 3.1795,
      "step": 7160
    },
    {
      "epoch": 0.30859946629938884,
      "grad_norm": 0.945793867111206,
      "learning_rate": 0.00019723020833720752,
      "loss": 3.105,
      "step": 7170
    },
    {
      "epoch": 0.30902987001807697,
      "grad_norm": 0.9395440220832825,
      "learning_rate": 0.00019721933735635712,
      "loss": 3.1811,
      "step": 7180
    },
    {
      "epoch": 0.3094602737367651,
      "grad_norm": 0.8807660937309265,
      "learning_rate": 0.00019720844538463264,
      "loss": 3.1503,
      "step": 7190
    },
    {
      "epoch": 0.30989067745545323,
      "grad_norm": 0.934208333492279,
      "learning_rate": 0.00019719753242438591,
      "loss": 3.1183,
      "step": 7200
    },
    {
      "epoch": 0.30989067745545323,
      "eval_bleu": 25.806887777020904,
      "eval_gen_len": 27.38,
      "eval_loss": 2.8410537242889404,
      "eval_runtime": 58.1196,
      "eval_samples_per_second": 17.206,
      "eval_steps_per_second": 1.084,
      "step": 7200
    },
    {
      "epoch": 0.31032108117414137,
      "grad_norm": 1.0711408853530884,
      "learning_rate": 0.0001971865984779731,
      "loss": 3.0271,
      "step": 7210
    },
    {
      "epoch": 0.3107514848928295,
      "grad_norm": 1.0366824865341187,
      "learning_rate": 0.00019717564354775497,
      "loss": 3.0859,
      "step": 7220
    },
    {
      "epoch": 0.3111818886115176,
      "grad_norm": 0.9719657301902771,
      "learning_rate": 0.00019716466763609688,
      "loss": 3.1439,
      "step": 7230
    },
    {
      "epoch": 0.3116122923302057,
      "grad_norm": 1.0467745065689087,
      "learning_rate": 0.00019715367074536863,
      "loss": 3.1361,
      "step": 7240
    },
    {
      "epoch": 0.31204269604889384,
      "grad_norm": 1.0280897617340088,
      "learning_rate": 0.0001971426528779446,
      "loss": 3.2809,
      "step": 7250
    },
    {
      "epoch": 0.31204269604889384,
      "eval_bleu": 25.545611504238554,
      "eval_gen_len": 27.185,
      "eval_loss": 2.839965343475342,
      "eval_runtime": 58.3263,
      "eval_samples_per_second": 17.145,
      "eval_steps_per_second": 1.08,
      "step": 7250
    },
    {
      "epoch": 0.312473099767582,
      "grad_norm": 0.9363783597946167,
      "learning_rate": 0.0001971316140362037,
      "loss": 3.3078,
      "step": 7260
    },
    {
      "epoch": 0.3129035034862701,
      "grad_norm": 0.8700113892555237,
      "learning_rate": 0.00019712055422252932,
      "loss": 3.2468,
      "step": 7270
    },
    {
      "epoch": 0.31333390720495824,
      "grad_norm": 1.0207182168960571,
      "learning_rate": 0.00019710947343930943,
      "loss": 3.112,
      "step": 7280
    },
    {
      "epoch": 0.3137643109236464,
      "grad_norm": 0.8450835347175598,
      "learning_rate": 0.0001970983716889365,
      "loss": 3.0842,
      "step": 7290
    },
    {
      "epoch": 0.3141947146423345,
      "grad_norm": 1.1006262302398682,
      "learning_rate": 0.00019708724897380756,
      "loss": 3.2175,
      "step": 7300
    },
    {
      "epoch": 0.3141947146423345,
      "eval_bleu": 25.834303206261914,
      "eval_gen_len": 27.3,
      "eval_loss": 2.8386428356170654,
      "eval_runtime": 57.4275,
      "eval_samples_per_second": 17.413,
      "eval_steps_per_second": 1.097,
      "step": 7300
    },
    {
      "epoch": 0.31462511836102264,
      "grad_norm": 0.7946659922599792,
      "learning_rate": 0.00019707610529632412,
      "loss": 3.0853,
      "step": 7310
    },
    {
      "epoch": 0.31505552207971077,
      "grad_norm": 1.0394792556762695,
      "learning_rate": 0.00019706494065889225,
      "loss": 3.1111,
      "step": 7320
    },
    {
      "epoch": 0.3154859257983989,
      "grad_norm": 0.9499108195304871,
      "learning_rate": 0.00019705375506392256,
      "loss": 3.1519,
      "step": 7330
    },
    {
      "epoch": 0.31591632951708704,
      "grad_norm": 0.9770432710647583,
      "learning_rate": 0.00019704254851383012,
      "loss": 3.1155,
      "step": 7340
    },
    {
      "epoch": 0.31634673323577517,
      "grad_norm": 0.9025814533233643,
      "learning_rate": 0.00019703132101103456,
      "loss": 3.1478,
      "step": 7350
    },
    {
      "epoch": 0.31634673323577517,
      "eval_bleu": 25.81340775404921,
      "eval_gen_len": 27.339,
      "eval_loss": 2.8392159938812256,
      "eval_runtime": 58.3973,
      "eval_samples_per_second": 17.124,
      "eval_steps_per_second": 1.079,
      "step": 7350
    },
    {
      "epoch": 0.3167771369544633,
      "grad_norm": 0.8738747835159302,
      "learning_rate": 0.00019702007255796005,
      "loss": 3.1774,
      "step": 7360
    },
    {
      "epoch": 0.31720754067315143,
      "grad_norm": 0.8983461260795593,
      "learning_rate": 0.00019700880315703533,
      "loss": 3.092,
      "step": 7370
    },
    {
      "epoch": 0.31763794439183957,
      "grad_norm": 0.9402006268501282,
      "learning_rate": 0.0001969975128106935,
      "loss": 3.0503,
      "step": 7380
    },
    {
      "epoch": 0.3180683481105277,
      "grad_norm": 1.0819456577301025,
      "learning_rate": 0.0001969862015213724,
      "loss": 3.2654,
      "step": 7390
    },
    {
      "epoch": 0.31849875182921583,
      "grad_norm": 1.0284614562988281,
      "learning_rate": 0.00019697486929151422,
      "loss": 3.0893,
      "step": 7400
    },
    {
      "epoch": 0.31849875182921583,
      "eval_bleu": 26.063243250019653,
      "eval_gen_len": 27.282,
      "eval_loss": 2.839840888977051,
      "eval_runtime": 58.0134,
      "eval_samples_per_second": 17.237,
      "eval_steps_per_second": 1.086,
      "step": 7400
    },
    {
      "epoch": 0.3189291555479039,
      "grad_norm": 1.0541143417358398,
      "learning_rate": 0.00019696351612356568,
      "loss": 3.1678,
      "step": 7410
    },
    {
      "epoch": 0.31935955926659204,
      "grad_norm": 1.0101075172424316,
      "learning_rate": 0.00019695214201997816,
      "loss": 3.0705,
      "step": 7420
    },
    {
      "epoch": 0.3197899629852802,
      "grad_norm": 0.9550977945327759,
      "learning_rate": 0.00019694074698320743,
      "loss": 3.1636,
      "step": 7430
    },
    {
      "epoch": 0.3202203667039683,
      "grad_norm": 1.0091487169265747,
      "learning_rate": 0.00019692933101571382,
      "loss": 3.1453,
      "step": 7440
    },
    {
      "epoch": 0.32065077042265644,
      "grad_norm": 0.98199063539505,
      "learning_rate": 0.00019691789411996222,
      "loss": 3.1528,
      "step": 7450
    },
    {
      "epoch": 0.32065077042265644,
      "eval_bleu": 25.938016121953186,
      "eval_gen_len": 27.301,
      "eval_loss": 2.8370463848114014,
      "eval_runtime": 57.8513,
      "eval_samples_per_second": 17.286,
      "eval_steps_per_second": 1.089,
      "step": 7450
    },
    {
      "epoch": 0.32108117414134457,
      "grad_norm": 0.8393338322639465,
      "learning_rate": 0.00019690643629842193,
      "loss": 3.1522,
      "step": 7460
    },
    {
      "epoch": 0.3215115778600327,
      "grad_norm": 0.9862300157546997,
      "learning_rate": 0.00019689495755356688,
      "loss": 3.1406,
      "step": 7470
    },
    {
      "epoch": 0.32194198157872084,
      "grad_norm": 1.0504992008209229,
      "learning_rate": 0.0001968834578878755,
      "loss": 3.1238,
      "step": 7480
    },
    {
      "epoch": 0.32237238529740897,
      "grad_norm": 1.014931559562683,
      "learning_rate": 0.00019687193730383065,
      "loss": 3.0549,
      "step": 7490
    },
    {
      "epoch": 0.3228027890160971,
      "grad_norm": 0.9972665309906006,
      "learning_rate": 0.0001968603958039198,
      "loss": 3.1102,
      "step": 7500
    },
    {
      "epoch": 0.3228027890160971,
      "eval_bleu": 25.839779922408812,
      "eval_gen_len": 27.4,
      "eval_loss": 2.838463306427002,
      "eval_runtime": 58.277,
      "eval_samples_per_second": 17.159,
      "eval_steps_per_second": 1.081,
      "step": 7500
    },
    {
      "epoch": 0.32323319273478524,
      "grad_norm": 0.9422800540924072,
      "learning_rate": 0.00019684883339063491,
      "loss": 3.2351,
      "step": 7510
    },
    {
      "epoch": 0.32366359645347337,
      "grad_norm": 1.0424565076828003,
      "learning_rate": 0.00019683725006647244,
      "loss": 3.1722,
      "step": 7520
    },
    {
      "epoch": 0.3240940001721615,
      "grad_norm": 0.9196678400039673,
      "learning_rate": 0.0001968256458339334,
      "loss": 3.0661,
      "step": 7530
    },
    {
      "epoch": 0.32452440389084963,
      "grad_norm": 0.866577684879303,
      "learning_rate": 0.00019681402069552325,
      "loss": 3.0929,
      "step": 7540
    },
    {
      "epoch": 0.32495480760953777,
      "grad_norm": 0.9501830339431763,
      "learning_rate": 0.00019680237465375205,
      "loss": 3.0928,
      "step": 7550
    },
    {
      "epoch": 0.32495480760953777,
      "eval_bleu": 26.343629427332463,
      "eval_gen_len": 27.396,
      "eval_loss": 2.839289665222168,
      "eval_runtime": 58.0628,
      "eval_samples_per_second": 17.223,
      "eval_steps_per_second": 1.085,
      "step": 7550
    },
    {
      "epoch": 0.3253852113282259,
      "grad_norm": 0.924832820892334,
      "learning_rate": 0.00019679070771113426,
      "loss": 3.1889,
      "step": 7560
    },
    {
      "epoch": 0.32581561504691403,
      "grad_norm": 0.8763762712478638,
      "learning_rate": 0.00019677901987018897,
      "loss": 3.1924,
      "step": 7570
    },
    {
      "epoch": 0.3262460187656021,
      "grad_norm": 0.9857088923454285,
      "learning_rate": 0.0001967673111334397,
      "loss": 3.0542,
      "step": 7580
    },
    {
      "epoch": 0.32667642248429024,
      "grad_norm": 0.849115252494812,
      "learning_rate": 0.00019675558150341455,
      "loss": 3.1737,
      "step": 7590
    },
    {
      "epoch": 0.3271068262029784,
      "grad_norm": 0.9113079905509949,
      "learning_rate": 0.0001967438309826461,
      "loss": 3.09,
      "step": 7600
    },
    {
      "epoch": 0.3271068262029784,
      "eval_bleu": 26.032714471064416,
      "eval_gen_len": 27.367,
      "eval_loss": 2.8375651836395264,
      "eval_runtime": 57.9913,
      "eval_samples_per_second": 17.244,
      "eval_steps_per_second": 1.086,
      "step": 7600
    },
    {
      "epoch": 0.3275372299216665,
      "grad_norm": 0.9419001340866089,
      "learning_rate": 0.00019673205957367138,
      "loss": 3.1078,
      "step": 7610
    },
    {
      "epoch": 0.32796763364035464,
      "grad_norm": 0.9684818983078003,
      "learning_rate": 0.00019672026727903202,
      "loss": 3.1319,
      "step": 7620
    },
    {
      "epoch": 0.32839803735904277,
      "grad_norm": 0.923860490322113,
      "learning_rate": 0.0001967084541012741,
      "loss": 3.1733,
      "step": 7630
    },
    {
      "epoch": 0.3288284410777309,
      "grad_norm": 1.0285519361495972,
      "learning_rate": 0.0001966966200429483,
      "loss": 3.1291,
      "step": 7640
    },
    {
      "epoch": 0.32925884479641904,
      "grad_norm": 1.0276695489883423,
      "learning_rate": 0.0001966847651066097,
      "loss": 3.0993,
      "step": 7650
    },
    {
      "epoch": 0.32925884479641904,
      "eval_bleu": 25.53025305652607,
      "eval_gen_len": 27.383,
      "eval_loss": 2.839144229888916,
      "eval_runtime": 57.8921,
      "eval_samples_per_second": 17.274,
      "eval_steps_per_second": 1.088,
      "step": 7650
    },
    {
      "epoch": 0.32968924851510717,
      "grad_norm": 0.8258962631225586,
      "learning_rate": 0.00019667288929481788,
      "loss": 2.9731,
      "step": 7660
    },
    {
      "epoch": 0.3301196522337953,
      "grad_norm": 0.9995533227920532,
      "learning_rate": 0.00019666099261013705,
      "loss": 3.0976,
      "step": 7670
    },
    {
      "epoch": 0.33055005595248343,
      "grad_norm": 0.8626022338867188,
      "learning_rate": 0.00019664907505513582,
      "loss": 3.1883,
      "step": 7680
    },
    {
      "epoch": 0.33098045967117157,
      "grad_norm": 1.0604299306869507,
      "learning_rate": 0.0001966371366323873,
      "loss": 3.1326,
      "step": 7690
    },
    {
      "epoch": 0.3314108633898597,
      "grad_norm": 0.871244490146637,
      "learning_rate": 0.00019662517734446926,
      "loss": 3.1738,
      "step": 7700
    },
    {
      "epoch": 0.3314108633898597,
      "eval_bleu": 25.20492998694128,
      "eval_gen_len": 27.324,
      "eval_loss": 2.8455970287323,
      "eval_runtime": 58.8333,
      "eval_samples_per_second": 16.997,
      "eval_steps_per_second": 1.071,
      "step": 7700
    },
    {
      "epoch": 0.33184126710854783,
      "grad_norm": 0.8789103627204895,
      "learning_rate": 0.00019661319719396376,
      "loss": 3.1757,
      "step": 7710
    },
    {
      "epoch": 0.33227167082723597,
      "grad_norm": 1.0066478252410889,
      "learning_rate": 0.00019660119618345747,
      "loss": 3.156,
      "step": 7720
    },
    {
      "epoch": 0.3327020745459241,
      "grad_norm": 0.9461103081703186,
      "learning_rate": 0.0001965891743155416,
      "loss": 3.1096,
      "step": 7730
    },
    {
      "epoch": 0.33313247826461223,
      "grad_norm": 0.9289262294769287,
      "learning_rate": 0.00019657713159281181,
      "loss": 3.0769,
      "step": 7740
    },
    {
      "epoch": 0.33356288198330036,
      "grad_norm": 0.9708173871040344,
      "learning_rate": 0.0001965650680178683,
      "loss": 3.126,
      "step": 7750
    },
    {
      "epoch": 0.33356288198330036,
      "eval_bleu": 25.85176008117447,
      "eval_gen_len": 27.428,
      "eval_loss": 2.83475399017334,
      "eval_runtime": 58.324,
      "eval_samples_per_second": 17.146,
      "eval_steps_per_second": 1.08,
      "step": 7750
    },
    {
      "epoch": 0.33399328570198844,
      "grad_norm": 0.8967967629432678,
      "learning_rate": 0.00019655298359331567,
      "loss": 3.1536,
      "step": 7760
    },
    {
      "epoch": 0.3344236894206766,
      "grad_norm": 0.8583878874778748,
      "learning_rate": 0.00019654087832176312,
      "loss": 3.1976,
      "step": 7770
    },
    {
      "epoch": 0.3348540931393647,
      "grad_norm": 1.0067685842514038,
      "learning_rate": 0.00019652875220582444,
      "loss": 3.1252,
      "step": 7780
    },
    {
      "epoch": 0.33528449685805284,
      "grad_norm": 0.9700231552124023,
      "learning_rate": 0.00019651660524811767,
      "loss": 3.1821,
      "step": 7790
    },
    {
      "epoch": 0.33571490057674097,
      "grad_norm": 0.9366669058799744,
      "learning_rate": 0.00019650443745126555,
      "loss": 3.0936,
      "step": 7800
    },
    {
      "epoch": 0.33571490057674097,
      "eval_bleu": 25.988696998984445,
      "eval_gen_len": 27.347,
      "eval_loss": 2.8377952575683594,
      "eval_runtime": 58.0456,
      "eval_samples_per_second": 17.228,
      "eval_steps_per_second": 1.085,
      "step": 7800
    },
    {
      "epoch": 0.3361453042954291,
      "grad_norm": 0.8956116437911987,
      "learning_rate": 0.00019649224881789526,
      "loss": 3.1503,
      "step": 7810
    },
    {
      "epoch": 0.33657570801411724,
      "grad_norm": 0.9516004920005798,
      "learning_rate": 0.0001964800393506385,
      "loss": 3.1415,
      "step": 7820
    },
    {
      "epoch": 0.33700611173280537,
      "grad_norm": 0.9984503984451294,
      "learning_rate": 0.0001964678090521314,
      "loss": 3.2281,
      "step": 7830
    },
    {
      "epoch": 0.3374365154514935,
      "grad_norm": 1.0016252994537354,
      "learning_rate": 0.00019645555792501465,
      "loss": 3.1377,
      "step": 7840
    },
    {
      "epoch": 0.33786691917018163,
      "grad_norm": 0.8717944622039795,
      "learning_rate": 0.00019644328597193342,
      "loss": 3.1793,
      "step": 7850
    },
    {
      "epoch": 0.33786691917018163,
      "eval_bleu": 25.835965381789364,
      "eval_gen_len": 27.283,
      "eval_loss": 2.838667392730713,
      "eval_runtime": 57.6544,
      "eval_samples_per_second": 17.345,
      "eval_steps_per_second": 1.093,
      "step": 7850
    },
    {
      "epoch": 0.33829732288886977,
      "grad_norm": 0.9820029139518738,
      "learning_rate": 0.00019643099319553738,
      "loss": 3.0773,
      "step": 7860
    },
    {
      "epoch": 0.3387277266075579,
      "grad_norm": 0.7450546622276306,
      "learning_rate": 0.00019641867959848078,
      "loss": 3.054,
      "step": 7870
    },
    {
      "epoch": 0.33915813032624603,
      "grad_norm": 1.101105809211731,
      "learning_rate": 0.00019640634518342212,
      "loss": 3.2286,
      "step": 7880
    },
    {
      "epoch": 0.33958853404493416,
      "grad_norm": 0.9494277238845825,
      "learning_rate": 0.00019639398995302467,
      "loss": 3.1868,
      "step": 7890
    },
    {
      "epoch": 0.3400189377636223,
      "grad_norm": 0.9852756261825562,
      "learning_rate": 0.00019638161390995605,
      "loss": 3.0892,
      "step": 7900
    },
    {
      "epoch": 0.3400189377636223,
      "eval_bleu": 26.224396722879703,
      "eval_gen_len": 27.527,
      "eval_loss": 2.8328909873962402,
      "eval_runtime": 58.6964,
      "eval_samples_per_second": 17.037,
      "eval_steps_per_second": 1.073,
      "step": 7900
    },
    {
      "epoch": 0.34044934148231043,
      "grad_norm": 0.9779351949691772,
      "learning_rate": 0.0001963692170568884,
      "loss": 3.1391,
      "step": 7910
    },
    {
      "epoch": 0.34087974520099856,
      "grad_norm": 0.899334728717804,
      "learning_rate": 0.0001963567993964983,
      "loss": 3.0866,
      "step": 7920
    },
    {
      "epoch": 0.34131014891968664,
      "grad_norm": 0.9358937740325928,
      "learning_rate": 0.000196344360931467,
      "loss": 3.1131,
      "step": 7930
    },
    {
      "epoch": 0.3417405526383748,
      "grad_norm": 0.8875215649604797,
      "learning_rate": 0.00019633190166448003,
      "loss": 3.0832,
      "step": 7940
    },
    {
      "epoch": 0.3421709563570629,
      "grad_norm": 0.9109243154525757,
      "learning_rate": 0.00019631942159822755,
      "loss": 3.0894,
      "step": 7950
    },
    {
      "epoch": 0.3421709563570629,
      "eval_bleu": 26.402514316179158,
      "eval_gen_len": 27.536,
      "eval_loss": 2.8325557708740234,
      "eval_runtime": 58.3996,
      "eval_samples_per_second": 17.123,
      "eval_steps_per_second": 1.079,
      "step": 7950
    },
    {
      "epoch": 0.34260136007575104,
      "grad_norm": 1.0032864809036255,
      "learning_rate": 0.0001963069207354041,
      "loss": 3.1193,
      "step": 7960
    },
    {
      "epoch": 0.34303176379443917,
      "grad_norm": 0.9889510273933411,
      "learning_rate": 0.00019629439907870884,
      "loss": 3.1376,
      "step": 7970
    },
    {
      "epoch": 0.3434621675131273,
      "grad_norm": 0.9650645852088928,
      "learning_rate": 0.0001962818566308453,
      "loss": 3.188,
      "step": 7980
    },
    {
      "epoch": 0.34389257123181544,
      "grad_norm": 0.9633278846740723,
      "learning_rate": 0.0001962692933945216,
      "loss": 3.0931,
      "step": 7990
    },
    {
      "epoch": 0.34432297495050357,
      "grad_norm": 0.9892756938934326,
      "learning_rate": 0.00019625670937245025,
      "loss": 3.1864,
      "step": 8000
    },
    {
      "epoch": 0.34432297495050357,
      "eval_bleu": 25.62233375860946,
      "eval_gen_len": 27.287,
      "eval_loss": 2.8403615951538086,
      "eval_runtime": 57.9684,
      "eval_samples_per_second": 17.251,
      "eval_steps_per_second": 1.087,
      "step": 8000
    },
    {
      "epoch": 0.3447533786691917,
      "grad_norm": 0.9975327253341675,
      "learning_rate": 0.00019624410456734836,
      "loss": 3.2112,
      "step": 8010
    },
    {
      "epoch": 0.34518378238787983,
      "grad_norm": 0.9950954914093018,
      "learning_rate": 0.00019623147898193742,
      "loss": 3.1457,
      "step": 8020
    },
    {
      "epoch": 0.34561418610656797,
      "grad_norm": 0.9689834713935852,
      "learning_rate": 0.00019621883261894345,
      "loss": 3.1018,
      "step": 8030
    },
    {
      "epoch": 0.3460445898252561,
      "grad_norm": 0.9789122939109802,
      "learning_rate": 0.000196206165481097,
      "loss": 3.1369,
      "step": 8040
    },
    {
      "epoch": 0.34647499354394423,
      "grad_norm": 0.8867323398590088,
      "learning_rate": 0.00019619347757113297,
      "loss": 3.1179,
      "step": 8050
    },
    {
      "epoch": 0.34647499354394423,
      "eval_bleu": 25.386769478270747,
      "eval_gen_len": 27.366,
      "eval_loss": 2.8371083736419678,
      "eval_runtime": 58.7469,
      "eval_samples_per_second": 17.022,
      "eval_steps_per_second": 1.072,
      "step": 8050
    },
    {
      "epoch": 0.34690539726263236,
      "grad_norm": 0.9773485064506531,
      "learning_rate": 0.00019618076889179098,
      "loss": 3.0271,
      "step": 8060
    },
    {
      "epoch": 0.3473358009813205,
      "grad_norm": 0.9530239105224609,
      "learning_rate": 0.00019616803944581487,
      "loss": 3.1685,
      "step": 8070
    },
    {
      "epoch": 0.34776620470000863,
      "grad_norm": 0.9334058165550232,
      "learning_rate": 0.00019615528923595314,
      "loss": 3.2097,
      "step": 8080
    },
    {
      "epoch": 0.34819660841869676,
      "grad_norm": 0.9140515327453613,
      "learning_rate": 0.00019614251826495873,
      "loss": 3.1302,
      "step": 8090
    },
    {
      "epoch": 0.34862701213738484,
      "grad_norm": 0.8814863562583923,
      "learning_rate": 0.00019612972653558903,
      "loss": 3.1478,
      "step": 8100
    },
    {
      "epoch": 0.34862701213738484,
      "eval_bleu": 25.52295430051109,
      "eval_gen_len": 27.461,
      "eval_loss": 2.8360891342163086,
      "eval_runtime": 58.7627,
      "eval_samples_per_second": 17.018,
      "eval_steps_per_second": 1.072,
      "step": 8100
    },
    {
      "epoch": 0.349057415856073,
      "grad_norm": 0.8568890690803528,
      "learning_rate": 0.00019611691405060593,
      "loss": 3.1306,
      "step": 8110
    },
    {
      "epoch": 0.3494878195747611,
      "grad_norm": 0.9192766547203064,
      "learning_rate": 0.00019610408081277583,
      "loss": 3.1198,
      "step": 8120
    },
    {
      "epoch": 0.34991822329344924,
      "grad_norm": 1.0102709531784058,
      "learning_rate": 0.0001960912268248696,
      "loss": 3.1953,
      "step": 8130
    },
    {
      "epoch": 0.35034862701213737,
      "grad_norm": 0.9388445019721985,
      "learning_rate": 0.0001960783520896625,
      "loss": 3.1579,
      "step": 8140
    },
    {
      "epoch": 0.3507790307308255,
      "grad_norm": 0.9272701740264893,
      "learning_rate": 0.00019606545660993442,
      "loss": 3.0395,
      "step": 8150
    },
    {
      "epoch": 0.3507790307308255,
      "eval_bleu": 26.290496188510286,
      "eval_gen_len": 27.51,
      "eval_loss": 2.8340091705322266,
      "eval_runtime": 58.3268,
      "eval_samples_per_second": 17.145,
      "eval_steps_per_second": 1.08,
      "step": 8150
    },
    {
      "epoch": 0.35120943444951364,
      "grad_norm": 0.9297490119934082,
      "learning_rate": 0.00019605254038846965,
      "loss": 3.1903,
      "step": 8160
    },
    {
      "epoch": 0.35163983816820177,
      "grad_norm": 0.793128490447998,
      "learning_rate": 0.00019603960342805694,
      "loss": 3.1184,
      "step": 8170
    },
    {
      "epoch": 0.3520702418868899,
      "grad_norm": 0.8750312924385071,
      "learning_rate": 0.00019602664573148952,
      "loss": 3.1332,
      "step": 8180
    },
    {
      "epoch": 0.35250064560557803,
      "grad_norm": 1.0063635110855103,
      "learning_rate": 0.0001960136673015652,
      "loss": 3.0818,
      "step": 8190
    },
    {
      "epoch": 0.35293104932426617,
      "grad_norm": 0.9348094463348389,
      "learning_rate": 0.0001960006681410861,
      "loss": 3.1212,
      "step": 8200
    },
    {
      "epoch": 0.35293104932426617,
      "eval_bleu": 26.10850266257041,
      "eval_gen_len": 27.382,
      "eval_loss": 2.8332529067993164,
      "eval_runtime": 57.8716,
      "eval_samples_per_second": 17.28,
      "eval_steps_per_second": 1.089,
      "step": 8200
    },
    {
      "epoch": 0.3533614530429543,
      "grad_norm": 0.9806991219520569,
      "learning_rate": 0.00019598764825285895,
      "loss": 3.1448,
      "step": 8210
    },
    {
      "epoch": 0.35379185676164243,
      "grad_norm": 1.0017752647399902,
      "learning_rate": 0.0001959746076396949,
      "loss": 3.1719,
      "step": 8220
    },
    {
      "epoch": 0.35422226048033056,
      "grad_norm": 0.9174692034721375,
      "learning_rate": 0.00019596154630440956,
      "loss": 3.1444,
      "step": 8230
    },
    {
      "epoch": 0.3546526641990187,
      "grad_norm": 0.957684338092804,
      "learning_rate": 0.0001959484642498231,
      "loss": 3.1521,
      "step": 8240
    },
    {
      "epoch": 0.35508306791770683,
      "grad_norm": 0.8818613290786743,
      "learning_rate": 0.00019593536147875998,
      "loss": 3.1659,
      "step": 8250
    },
    {
      "epoch": 0.35508306791770683,
      "eval_bleu": 26.10734428146138,
      "eval_gen_len": 27.438,
      "eval_loss": 2.8325605392456055,
      "eval_runtime": 58.1176,
      "eval_samples_per_second": 17.206,
      "eval_steps_per_second": 1.084,
      "step": 8250
    },
    {
      "epoch": 0.35551347163639496,
      "grad_norm": 1.005780577659607,
      "learning_rate": 0.0001959222379940494,
      "loss": 3.1403,
      "step": 8260
    },
    {
      "epoch": 0.3559438753550831,
      "grad_norm": 0.8847543001174927,
      "learning_rate": 0.00019590909379852474,
      "loss": 3.183,
      "step": 8270
    },
    {
      "epoch": 0.35637427907377117,
      "grad_norm": 0.9527011513710022,
      "learning_rate": 0.0001958959288950241,
      "loss": 3.1543,
      "step": 8280
    },
    {
      "epoch": 0.3568046827924593,
      "grad_norm": 0.9575481414794922,
      "learning_rate": 0.0001958827432863899,
      "loss": 3.1082,
      "step": 8290
    },
    {
      "epoch": 0.35723508651114744,
      "grad_norm": 0.9030389785766602,
      "learning_rate": 0.0001958695369754691,
      "loss": 3.0824,
      "step": 8300
    },
    {
      "epoch": 0.35723508651114744,
      "eval_bleu": 25.982175462765717,
      "eval_gen_len": 27.391,
      "eval_loss": 2.8313710689544678,
      "eval_runtime": 58.2646,
      "eval_samples_per_second": 17.163,
      "eval_steps_per_second": 1.081,
      "step": 8300
    },
    {
      "epoch": 0.35766549022983557,
      "grad_norm": 1.0020805597305298,
      "learning_rate": 0.00019585630996511312,
      "loss": 3.0744,
      "step": 8310
    },
    {
      "epoch": 0.3580958939485237,
      "grad_norm": 0.9035937786102295,
      "learning_rate": 0.00019584306225817782,
      "loss": 3.1034,
      "step": 8320
    },
    {
      "epoch": 0.35852629766721184,
      "grad_norm": 0.8604617118835449,
      "learning_rate": 0.0001958297938575235,
      "loss": 3.1318,
      "step": 8330
    },
    {
      "epoch": 0.35895670138589997,
      "grad_norm": 0.8954468369483948,
      "learning_rate": 0.00019581650476601506,
      "loss": 3.0204,
      "step": 8340
    },
    {
      "epoch": 0.3593871051045881,
      "grad_norm": 1.031581163406372,
      "learning_rate": 0.00019580319498652173,
      "loss": 3.2045,
      "step": 8350
    },
    {
      "epoch": 0.3593871051045881,
      "eval_bleu": 26.57808367498685,
      "eval_gen_len": 27.309,
      "eval_loss": 2.832066059112549,
      "eval_runtime": 57.512,
      "eval_samples_per_second": 17.388,
      "eval_steps_per_second": 1.095,
      "step": 8350
    },
    {
      "epoch": 0.35981750882327623,
      "grad_norm": 1.0520415306091309,
      "learning_rate": 0.00019578986452191725,
      "loss": 3.1953,
      "step": 8360
    },
    {
      "epoch": 0.36024791254196437,
      "grad_norm": 1.02496337890625,
      "learning_rate": 0.00019577651337507988,
      "loss": 3.1801,
      "step": 8370
    },
    {
      "epoch": 0.3606783162606525,
      "grad_norm": 0.9994216561317444,
      "learning_rate": 0.00019576314154889224,
      "loss": 3.012,
      "step": 8380
    },
    {
      "epoch": 0.36110871997934063,
      "grad_norm": 0.9686086177825928,
      "learning_rate": 0.00019574974904624154,
      "loss": 3.1248,
      "step": 8390
    },
    {
      "epoch": 0.36153912369802876,
      "grad_norm": 0.8606737852096558,
      "learning_rate": 0.0001957363358700193,
      "loss": 3.1517,
      "step": 8400
    },
    {
      "epoch": 0.36153912369802876,
      "eval_bleu": 26.047738457214912,
      "eval_gen_len": 27.411,
      "eval_loss": 2.8341047763824463,
      "eval_runtime": 57.4415,
      "eval_samples_per_second": 17.409,
      "eval_steps_per_second": 1.097,
      "step": 8400
    },
    {
      "epoch": 0.3619695274167169,
      "grad_norm": 0.9644965529441833,
      "learning_rate": 0.0001957229020231217,
      "loss": 3.1473,
      "step": 8410
    },
    {
      "epoch": 0.36239993113540503,
      "grad_norm": 1.0362341403961182,
      "learning_rate": 0.0001957094475084492,
      "loss": 3.1647,
      "step": 8420
    },
    {
      "epoch": 0.36283033485409316,
      "grad_norm": 1.0197621583938599,
      "learning_rate": 0.00019569597232890686,
      "loss": 3.0429,
      "step": 8430
    },
    {
      "epoch": 0.3632607385727813,
      "grad_norm": 0.9451568126678467,
      "learning_rate": 0.00019568247648740409,
      "loss": 3.264,
      "step": 8440
    },
    {
      "epoch": 0.36369114229146937,
      "grad_norm": 0.9791689515113831,
      "learning_rate": 0.00019566895998685482,
      "loss": 3.1726,
      "step": 8450
    },
    {
      "epoch": 0.36369114229146937,
      "eval_bleu": 26.098724963734988,
      "eval_gen_len": 27.385,
      "eval_loss": 2.8361644744873047,
      "eval_runtime": 58.5315,
      "eval_samples_per_second": 17.085,
      "eval_steps_per_second": 1.076,
      "step": 8450
    },
    {
      "epoch": 0.3641215460101575,
      "grad_norm": 0.9934363961219788,
      "learning_rate": 0.0001956554228301774,
      "loss": 3.0499,
      "step": 8460
    },
    {
      "epoch": 0.36455194972884564,
      "grad_norm": 1.0996158123016357,
      "learning_rate": 0.00019564186502029477,
      "loss": 3.1696,
      "step": 8470
    },
    {
      "epoch": 0.36498235344753377,
      "grad_norm": 1.023368000984192,
      "learning_rate": 0.00019562828656013415,
      "loss": 3.0857,
      "step": 8480
    },
    {
      "epoch": 0.3654127571662219,
      "grad_norm": 0.9519481062889099,
      "learning_rate": 0.0001956146874526273,
      "loss": 3.1624,
      "step": 8490
    },
    {
      "epoch": 0.36584316088491003,
      "grad_norm": 1.0139310359954834,
      "learning_rate": 0.00019560106770071046,
      "loss": 3.1874,
      "step": 8500
    },
    {
      "epoch": 0.36584316088491003,
      "eval_bleu": 26.423961636143318,
      "eval_gen_len": 27.496,
      "eval_loss": 2.834857940673828,
      "eval_runtime": 58.7428,
      "eval_samples_per_second": 17.023,
      "eval_steps_per_second": 1.072,
      "step": 8500
    },
    {
      "epoch": 0.36627356460359817,
      "grad_norm": 0.9798719882965088,
      "learning_rate": 0.00019558742730732434,
      "loss": 3.1206,
      "step": 8510
    },
    {
      "epoch": 0.3667039683222863,
      "grad_norm": 0.8499940037727356,
      "learning_rate": 0.00019557376627541402,
      "loss": 3.0914,
      "step": 8520
    },
    {
      "epoch": 0.36713437204097443,
      "grad_norm": 0.8771629929542542,
      "learning_rate": 0.00019556008460792907,
      "loss": 3.1875,
      "step": 8530
    },
    {
      "epoch": 0.36756477575966257,
      "grad_norm": 0.9906907081604004,
      "learning_rate": 0.0001955463823078236,
      "loss": 3.2369,
      "step": 8540
    },
    {
      "epoch": 0.3679951794783507,
      "grad_norm": 1.0493249893188477,
      "learning_rate": 0.00019553265937805606,
      "loss": 3.1018,
      "step": 8550
    },
    {
      "epoch": 0.3679951794783507,
      "eval_bleu": 25.682918215957827,
      "eval_gen_len": 27.348,
      "eval_loss": 2.8393356800079346,
      "eval_runtime": 58.1401,
      "eval_samples_per_second": 17.2,
      "eval_steps_per_second": 1.084,
      "step": 8550
    },
    {
      "epoch": 0.36842558319703883,
      "grad_norm": 0.9513040781021118,
      "learning_rate": 0.00019551891582158943,
      "loss": 3.1364,
      "step": 8560
    },
    {
      "epoch": 0.36885598691572696,
      "grad_norm": 0.893471896648407,
      "learning_rate": 0.0001955051516413911,
      "loss": 3.1971,
      "step": 8570
    },
    {
      "epoch": 0.3692863906344151,
      "grad_norm": 1.1003302335739136,
      "learning_rate": 0.00019549136684043292,
      "loss": 3.1383,
      "step": 8580
    },
    {
      "epoch": 0.36971679435310323,
      "grad_norm": 0.9366612434387207,
      "learning_rate": 0.00019547756142169125,
      "loss": 3.0731,
      "step": 8590
    },
    {
      "epoch": 0.37014719807179136,
      "grad_norm": 0.841945230960846,
      "learning_rate": 0.00019546373538814678,
      "loss": 3.1687,
      "step": 8600
    },
    {
      "epoch": 0.37014719807179136,
      "eval_bleu": 25.87462233230796,
      "eval_gen_len": 27.355,
      "eval_loss": 2.8370800018310547,
      "eval_runtime": 57.8713,
      "eval_samples_per_second": 17.28,
      "eval_steps_per_second": 1.089,
      "step": 8600
    },
    {
      "epoch": 0.3705776017904795,
      "grad_norm": 0.9896413087844849,
      "learning_rate": 0.0001954498887427848,
      "loss": 3.1987,
      "step": 8610
    },
    {
      "epoch": 0.3710080055091676,
      "grad_norm": 0.9313833713531494,
      "learning_rate": 0.0001954360214885949,
      "loss": 3.101,
      "step": 8620
    },
    {
      "epoch": 0.3714384092278557,
      "grad_norm": 0.9280347228050232,
      "learning_rate": 0.00019542213362857123,
      "loss": 3.2066,
      "step": 8630
    },
    {
      "epoch": 0.37186881294654384,
      "grad_norm": 0.9499358534812927,
      "learning_rate": 0.00019540822516571238,
      "loss": 3.1934,
      "step": 8640
    },
    {
      "epoch": 0.37229921666523197,
      "grad_norm": 0.9114192724227905,
      "learning_rate": 0.00019539429610302133,
      "loss": 3.1324,
      "step": 8650
    },
    {
      "epoch": 0.37229921666523197,
      "eval_bleu": 26.386892163724795,
      "eval_gen_len": 27.452,
      "eval_loss": 2.8318874835968018,
      "eval_runtime": 59.2085,
      "eval_samples_per_second": 16.889,
      "eval_steps_per_second": 1.064,
      "step": 8650
    },
    {
      "epoch": 0.3727296203839201,
      "grad_norm": 0.9562193751335144,
      "learning_rate": 0.00019538034644350552,
      "loss": 3.1779,
      "step": 8660
    },
    {
      "epoch": 0.37316002410260823,
      "grad_norm": 0.9647411704063416,
      "learning_rate": 0.0001953663761901769,
      "loss": 3.0468,
      "step": 8670
    },
    {
      "epoch": 0.37359042782129637,
      "grad_norm": 1.066226601600647,
      "learning_rate": 0.0001953523853460518,
      "loss": 3.1294,
      "step": 8680
    },
    {
      "epoch": 0.3740208315399845,
      "grad_norm": 1.111289620399475,
      "learning_rate": 0.00019533837391415103,
      "loss": 3.212,
      "step": 8690
    },
    {
      "epoch": 0.37445123525867263,
      "grad_norm": 0.9804350733757019,
      "learning_rate": 0.0001953243418974998,
      "loss": 3.1477,
      "step": 8700
    },
    {
      "epoch": 0.37445123525867263,
      "eval_bleu": 25.860407966611007,
      "eval_gen_len": 27.399,
      "eval_loss": 2.8377230167388916,
      "eval_runtime": 58.4141,
      "eval_samples_per_second": 17.119,
      "eval_steps_per_second": 1.079,
      "step": 8700
    },
    {
      "epoch": 0.37488163897736076,
      "grad_norm": 0.9940239787101746,
      "learning_rate": 0.00019531028929912787,
      "loss": 3.1108,
      "step": 8710
    },
    {
      "epoch": 0.3753120426960489,
      "grad_norm": 0.9568914771080017,
      "learning_rate": 0.00019529621612206926,
      "loss": 3.1389,
      "step": 8720
    },
    {
      "epoch": 0.37574244641473703,
      "grad_norm": 0.9140427112579346,
      "learning_rate": 0.00019528212236936268,
      "loss": 3.1124,
      "step": 8730
    },
    {
      "epoch": 0.37617285013342516,
      "grad_norm": 1.0796171426773071,
      "learning_rate": 0.00019526800804405104,
      "loss": 3.0862,
      "step": 8740
    },
    {
      "epoch": 0.3766032538521133,
      "grad_norm": 0.8700526356697083,
      "learning_rate": 0.00019525387314918183,
      "loss": 3.1221,
      "step": 8750
    },
    {
      "epoch": 0.3766032538521133,
      "eval_bleu": 25.717875371701776,
      "eval_gen_len": 27.346,
      "eval_loss": 2.835156202316284,
      "eval_runtime": 58.2324,
      "eval_samples_per_second": 17.173,
      "eval_steps_per_second": 1.082,
      "step": 8750
    },
    {
      "epoch": 0.37703365757080143,
      "grad_norm": 0.9791494607925415,
      "learning_rate": 0.000195239717687807,
      "loss": 3.1152,
      "step": 8760
    },
    {
      "epoch": 0.37746406128948956,
      "grad_norm": 0.8224210739135742,
      "learning_rate": 0.00019522554166298285,
      "loss": 3.1431,
      "step": 8770
    },
    {
      "epoch": 0.3778944650081777,
      "grad_norm": 0.9441054463386536,
      "learning_rate": 0.00019521134507777014,
      "loss": 3.1404,
      "step": 8780
    },
    {
      "epoch": 0.3783248687268658,
      "grad_norm": 0.8357422947883606,
      "learning_rate": 0.00019519712793523414,
      "loss": 3.127,
      "step": 8790
    },
    {
      "epoch": 0.3787552724455539,
      "grad_norm": 0.8110448718070984,
      "learning_rate": 0.00019518289023844445,
      "loss": 3.1441,
      "step": 8800
    },
    {
      "epoch": 0.3787552724455539,
      "eval_bleu": 25.87577632214646,
      "eval_gen_len": 27.264,
      "eval_loss": 2.841233015060425,
      "eval_runtime": 58.1876,
      "eval_samples_per_second": 17.186,
      "eval_steps_per_second": 1.083,
      "step": 8800
    },
    {
      "epoch": 0.37918567616424204,
      "grad_norm": 0.9938775897026062,
      "learning_rate": 0.0001951686319904752,
      "loss": 3.1203,
      "step": 8810
    },
    {
      "epoch": 0.37961607988293017,
      "grad_norm": 0.9265856742858887,
      "learning_rate": 0.00019515435319440494,
      "loss": 3.1015,
      "step": 8820
    },
    {
      "epoch": 0.3800464836016183,
      "grad_norm": 0.9325282573699951,
      "learning_rate": 0.00019514005385331664,
      "loss": 3.1483,
      "step": 8830
    },
    {
      "epoch": 0.38047688732030643,
      "grad_norm": 0.9569534659385681,
      "learning_rate": 0.00019512573397029767,
      "loss": 3.2005,
      "step": 8840
    },
    {
      "epoch": 0.38090729103899457,
      "grad_norm": 0.9622396230697632,
      "learning_rate": 0.0001951113935484399,
      "loss": 3.1372,
      "step": 8850
    },
    {
      "epoch": 0.38090729103899457,
      "eval_bleu": 26.03401569284158,
      "eval_gen_len": 27.367,
      "eval_loss": 2.8336703777313232,
      "eval_runtime": 58.405,
      "eval_samples_per_second": 17.122,
      "eval_steps_per_second": 1.079,
      "step": 8850
    },
    {
      "epoch": 0.3813376947576827,
      "grad_norm": 0.8793647885322571,
      "learning_rate": 0.00019509703259083962,
      "loss": 3.0979,
      "step": 8860
    },
    {
      "epoch": 0.38176809847637083,
      "grad_norm": 0.9883198142051697,
      "learning_rate": 0.00019508265110059752,
      "loss": 3.1126,
      "step": 8870
    },
    {
      "epoch": 0.38219850219505896,
      "grad_norm": 1.0116254091262817,
      "learning_rate": 0.00019506824908081875,
      "loss": 3.1912,
      "step": 8880
    },
    {
      "epoch": 0.3826289059137471,
      "grad_norm": 0.9614993929862976,
      "learning_rate": 0.00019505382653461288,
      "loss": 3.2421,
      "step": 8890
    },
    {
      "epoch": 0.38305930963243523,
      "grad_norm": 0.9410784244537354,
      "learning_rate": 0.00019503938346509392,
      "loss": 3.0939,
      "step": 8900
    },
    {
      "epoch": 0.38305930963243523,
      "eval_bleu": 26.024007056672875,
      "eval_gen_len": 27.526,
      "eval_loss": 2.831631660461426,
      "eval_runtime": 58.7883,
      "eval_samples_per_second": 17.01,
      "eval_steps_per_second": 1.072,
      "step": 8900
    },
    {
      "epoch": 0.38348971335112336,
      "grad_norm": 0.971400260925293,
      "learning_rate": 0.00019502491987538032,
      "loss": 3.1928,
      "step": 8910
    },
    {
      "epoch": 0.3839201170698115,
      "grad_norm": 0.9326544404029846,
      "learning_rate": 0.00019501043576859495,
      "loss": 3.1762,
      "step": 8920
    },
    {
      "epoch": 0.38435052078849963,
      "grad_norm": 0.8661567568778992,
      "learning_rate": 0.00019499593114786508,
      "loss": 3.1671,
      "step": 8930
    },
    {
      "epoch": 0.38478092450718776,
      "grad_norm": 0.9289950728416443,
      "learning_rate": 0.00019498140601632247,
      "loss": 3.2474,
      "step": 8940
    },
    {
      "epoch": 0.3852113282258759,
      "grad_norm": 0.9232103228569031,
      "learning_rate": 0.00019496686037710328,
      "loss": 3.0637,
      "step": 8950
    },
    {
      "epoch": 0.3852113282258759,
      "eval_bleu": 26.078621033498806,
      "eval_gen_len": 27.45,
      "eval_loss": 2.8338356018066406,
      "eval_runtime": 58.0344,
      "eval_samples_per_second": 17.231,
      "eval_steps_per_second": 1.086,
      "step": 8950
    },
    {
      "epoch": 0.385641731944564,
      "grad_norm": 1.0007736682891846,
      "learning_rate": 0.00019495229423334808,
      "loss": 3.1734,
      "step": 8960
    },
    {
      "epoch": 0.3860721356632521,
      "grad_norm": 0.8960219621658325,
      "learning_rate": 0.0001949377075882019,
      "loss": 3.1318,
      "step": 8970
    },
    {
      "epoch": 0.38650253938194024,
      "grad_norm": 1.019270896911621,
      "learning_rate": 0.00019492310044481417,
      "loss": 3.0527,
      "step": 8980
    },
    {
      "epoch": 0.38693294310062837,
      "grad_norm": 0.9959369897842407,
      "learning_rate": 0.00019490847280633874,
      "loss": 3.1612,
      "step": 8990
    },
    {
      "epoch": 0.3873633468193165,
      "grad_norm": 1.0455620288848877,
      "learning_rate": 0.00019489382467593392,
      "loss": 3.0759,
      "step": 9000
    },
    {
      "epoch": 0.3873633468193165,
      "eval_bleu": 26.51237232653237,
      "eval_gen_len": 27.502,
      "eval_loss": 2.828436851501465,
      "eval_runtime": 58.7487,
      "eval_samples_per_second": 17.022,
      "eval_steps_per_second": 1.072,
      "step": 9000
    },
    {
      "epoch": 0.38779375053800463,
      "grad_norm": 0.9415783286094666,
      "learning_rate": 0.00019487915605676244,
      "loss": 3.0697,
      "step": 9010
    },
    {
      "epoch": 0.38822415425669277,
      "grad_norm": 0.8547847867012024,
      "learning_rate": 0.00019486446695199142,
      "loss": 3.1149,
      "step": 9020
    },
    {
      "epoch": 0.3886545579753809,
      "grad_norm": 0.8992058038711548,
      "learning_rate": 0.0001948497573647924,
      "loss": 3.1915,
      "step": 9030
    },
    {
      "epoch": 0.38908496169406903,
      "grad_norm": 0.9062134027481079,
      "learning_rate": 0.0001948350272983414,
      "loss": 3.0639,
      "step": 9040
    },
    {
      "epoch": 0.38951536541275716,
      "grad_norm": 0.9612917304039001,
      "learning_rate": 0.0001948202767558188,
      "loss": 3.172,
      "step": 9050
    },
    {
      "epoch": 0.38951536541275716,
      "eval_bleu": 25.98701655114336,
      "eval_gen_len": 27.359,
      "eval_loss": 2.8339436054229736,
      "eval_runtime": 57.7943,
      "eval_samples_per_second": 17.303,
      "eval_steps_per_second": 1.09,
      "step": 9050
    },
    {
      "epoch": 0.3899457691314453,
      "grad_norm": 1.0500043630599976,
      "learning_rate": 0.00019480550574040945,
      "loss": 3.1173,
      "step": 9060
    },
    {
      "epoch": 0.39037617285013343,
      "grad_norm": 0.9137840867042542,
      "learning_rate": 0.00019479071425530258,
      "loss": 3.1184,
      "step": 9070
    },
    {
      "epoch": 0.39080657656882156,
      "grad_norm": 0.9445932507514954,
      "learning_rate": 0.00019477590230369186,
      "loss": 3.1047,
      "step": 9080
    },
    {
      "epoch": 0.3912369802875097,
      "grad_norm": 0.8207273483276367,
      "learning_rate": 0.0001947610698887754,
      "loss": 3.0982,
      "step": 9090
    },
    {
      "epoch": 0.3916673840061978,
      "grad_norm": 0.9934651851654053,
      "learning_rate": 0.0001947462170137557,
      "loss": 3.1753,
      "step": 9100
    },
    {
      "epoch": 0.3916673840061978,
      "eval_bleu": 25.920899422168524,
      "eval_gen_len": 27.487,
      "eval_loss": 2.8335354328155518,
      "eval_runtime": 59.194,
      "eval_samples_per_second": 16.894,
      "eval_steps_per_second": 1.064,
      "step": 9100
    },
    {
      "epoch": 0.39209778772488596,
      "grad_norm": 0.8977352976799011,
      "learning_rate": 0.0001947313436818396,
      "loss": 3.2144,
      "step": 9110
    },
    {
      "epoch": 0.3925281914435741,
      "grad_norm": 0.9973471760749817,
      "learning_rate": 0.00019471644989623853,
      "loss": 3.0594,
      "step": 9120
    },
    {
      "epoch": 0.3929585951622622,
      "grad_norm": 0.9734596610069275,
      "learning_rate": 0.00019470153566016824,
      "loss": 3.149,
      "step": 9130
    },
    {
      "epoch": 0.39338899888095036,
      "grad_norm": 0.8749715685844421,
      "learning_rate": 0.00019468660097684886,
      "loss": 3.1371,
      "step": 9140
    },
    {
      "epoch": 0.39381940259963844,
      "grad_norm": 0.9515387415885925,
      "learning_rate": 0.00019467164584950503,
      "loss": 3.1082,
      "step": 9150
    },
    {
      "epoch": 0.39381940259963844,
      "eval_bleu": 25.82553644452947,
      "eval_gen_len": 27.498,
      "eval_loss": 2.831846237182617,
      "eval_runtime": 59.586,
      "eval_samples_per_second": 16.782,
      "eval_steps_per_second": 1.057,
      "step": 9150
    },
    {
      "epoch": 0.39424980631832657,
      "grad_norm": 0.9994783401489258,
      "learning_rate": 0.0001946566702813657,
      "loss": 3.1662,
      "step": 9160
    },
    {
      "epoch": 0.3946802100370147,
      "grad_norm": 0.8720825910568237,
      "learning_rate": 0.00019464167427566428,
      "loss": 3.1409,
      "step": 9170
    },
    {
      "epoch": 0.39511061375570283,
      "grad_norm": 0.8669927716255188,
      "learning_rate": 0.00019462665783563865,
      "loss": 3.0507,
      "step": 9180
    },
    {
      "epoch": 0.39554101747439097,
      "grad_norm": 1.021563172340393,
      "learning_rate": 0.00019461162096453096,
      "loss": 3.1354,
      "step": 9190
    },
    {
      "epoch": 0.3959714211930791,
      "grad_norm": 0.9512731432914734,
      "learning_rate": 0.00019459656366558795,
      "loss": 3.0619,
      "step": 9200
    },
    {
      "epoch": 0.3959714211930791,
      "eval_bleu": 25.927184047409142,
      "eval_gen_len": 27.362,
      "eval_loss": 2.8349902629852295,
      "eval_runtime": 58.5687,
      "eval_samples_per_second": 17.074,
      "eval_steps_per_second": 1.076,
      "step": 9200
    },
    {
      "epoch": 0.39640182491176723,
      "grad_norm": 0.9718518853187561,
      "learning_rate": 0.00019458148594206064,
      "loss": 3.1091,
      "step": 9210
    },
    {
      "epoch": 0.39683222863045536,
      "grad_norm": 0.8445250988006592,
      "learning_rate": 0.0001945663877972045,
      "loss": 3.0476,
      "step": 9220
    },
    {
      "epoch": 0.3972626323491435,
      "grad_norm": 0.8717868328094482,
      "learning_rate": 0.00019455126923427938,
      "loss": 3.1766,
      "step": 9230
    },
    {
      "epoch": 0.39769303606783163,
      "grad_norm": 0.9989506006240845,
      "learning_rate": 0.00019453613025654961,
      "loss": 3.3097,
      "step": 9240
    },
    {
      "epoch": 0.39812343978651976,
      "grad_norm": 0.874509871006012,
      "learning_rate": 0.0001945209708672839,
      "loss": 3.0838,
      "step": 9250
    },
    {
      "epoch": 0.39812343978651976,
      "eval_bleu": 26.012953531204342,
      "eval_gen_len": 27.371,
      "eval_loss": 2.83282470703125,
      "eval_runtime": 58.1072,
      "eval_samples_per_second": 17.21,
      "eval_steps_per_second": 1.084,
      "step": 9250
    },
    {
      "epoch": 0.3985538435052079,
      "grad_norm": 0.9078577756881714,
      "learning_rate": 0.00019450579106975528,
      "loss": 3.138,
      "step": 9260
    },
    {
      "epoch": 0.398984247223896,
      "grad_norm": 1.017953872680664,
      "learning_rate": 0.00019449059086724133,
      "loss": 3.2426,
      "step": 9270
    },
    {
      "epoch": 0.39941465094258416,
      "grad_norm": 0.9061712622642517,
      "learning_rate": 0.00019447537026302393,
      "loss": 3.1777,
      "step": 9280
    },
    {
      "epoch": 0.3998450546612723,
      "grad_norm": 0.9138116240501404,
      "learning_rate": 0.00019446012926038943,
      "loss": 3.0834,
      "step": 9290
    },
    {
      "epoch": 0.4002754583799604,
      "grad_norm": 0.9756264090538025,
      "learning_rate": 0.0001944448678626285,
      "loss": 3.0825,
      "step": 9300
    },
    {
      "epoch": 0.4002754583799604,
      "eval_bleu": 26.477684563034984,
      "eval_gen_len": 27.493,
      "eval_loss": 2.8315935134887695,
      "eval_runtime": 58.6451,
      "eval_samples_per_second": 17.052,
      "eval_steps_per_second": 1.074,
      "step": 9300
    },
    {
      "epoch": 0.40070586209864856,
      "grad_norm": 0.9162427186965942,
      "learning_rate": 0.0001944295860730363,
      "loss": 3.1474,
      "step": 9310
    },
    {
      "epoch": 0.40113626581733663,
      "grad_norm": 0.8963943719863892,
      "learning_rate": 0.00019441428389491234,
      "loss": 3.0703,
      "step": 9320
    },
    {
      "epoch": 0.40156666953602477,
      "grad_norm": 0.9769397377967834,
      "learning_rate": 0.00019439896133156058,
      "loss": 3.1224,
      "step": 9330
    },
    {
      "epoch": 0.4019970732547129,
      "grad_norm": 0.9964428544044495,
      "learning_rate": 0.00019438361838628934,
      "loss": 3.2687,
      "step": 9340
    },
    {
      "epoch": 0.40242747697340103,
      "grad_norm": 0.9823734760284424,
      "learning_rate": 0.0001943682550624114,
      "loss": 3.1326,
      "step": 9350
    },
    {
      "epoch": 0.40242747697340103,
      "eval_bleu": 26.21747253941039,
      "eval_gen_len": 27.383,
      "eval_loss": 2.835427761077881,
      "eval_runtime": 57.7353,
      "eval_samples_per_second": 17.32,
      "eval_steps_per_second": 1.091,
      "step": 9350
    },
    {
      "epoch": 0.40285788069208917,
      "grad_norm": 0.9899691343307495,
      "learning_rate": 0.0001943528713632438,
      "loss": 3.1306,
      "step": 9360
    },
    {
      "epoch": 0.4032882844107773,
      "grad_norm": 0.8446761965751648,
      "learning_rate": 0.00019433746729210816,
      "loss": 3.0677,
      "step": 9370
    },
    {
      "epoch": 0.40371868812946543,
      "grad_norm": 0.9239022731781006,
      "learning_rate": 0.00019432204285233035,
      "loss": 3.1781,
      "step": 9380
    },
    {
      "epoch": 0.40414909184815356,
      "grad_norm": 0.9452093243598938,
      "learning_rate": 0.00019430659804724074,
      "loss": 3.1493,
      "step": 9390
    },
    {
      "epoch": 0.4045794955668417,
      "grad_norm": 0.9173563718795776,
      "learning_rate": 0.00019429113288017401,
      "loss": 3.1584,
      "step": 9400
    },
    {
      "epoch": 0.4045794955668417,
      "eval_bleu": 26.242025376455143,
      "eval_gen_len": 27.472,
      "eval_loss": 2.831472158432007,
      "eval_runtime": 58.6255,
      "eval_samples_per_second": 17.057,
      "eval_steps_per_second": 1.075,
      "step": 9400
    },
    {
      "epoch": 0.40500989928552983,
      "grad_norm": 0.913045346736908,
      "learning_rate": 0.00019427564735446937,
      "loss": 3.2109,
      "step": 9410
    },
    {
      "epoch": 0.40544030300421796,
      "grad_norm": 1.0079212188720703,
      "learning_rate": 0.00019426014147347028,
      "loss": 3.1464,
      "step": 9420
    },
    {
      "epoch": 0.4058707067229061,
      "grad_norm": 0.8977532386779785,
      "learning_rate": 0.00019424461524052462,
      "loss": 3.1553,
      "step": 9430
    },
    {
      "epoch": 0.4063011104415942,
      "grad_norm": 0.9460171461105347,
      "learning_rate": 0.00019422906865898475,
      "loss": 3.0504,
      "step": 9440
    },
    {
      "epoch": 0.40673151416028236,
      "grad_norm": 0.9185818433761597,
      "learning_rate": 0.0001942135017322074,
      "loss": 3.0473,
      "step": 9450
    },
    {
      "epoch": 0.40673151416028236,
      "eval_bleu": 25.707888816935373,
      "eval_gen_len": 27.404,
      "eval_loss": 2.8366637229919434,
      "eval_runtime": 58.6632,
      "eval_samples_per_second": 17.046,
      "eval_steps_per_second": 1.074,
      "step": 9450
    },
    {
      "epoch": 0.4071619178789705,
      "grad_norm": 0.8543897271156311,
      "learning_rate": 0.0001941979144635536,
      "loss": 3.1651,
      "step": 9460
    },
    {
      "epoch": 0.4075923215976586,
      "grad_norm": 1.0170122385025024,
      "learning_rate": 0.00019418230685638884,
      "loss": 3.1449,
      "step": 9470
    },
    {
      "epoch": 0.40802272531634676,
      "grad_norm": 0.8752321600914001,
      "learning_rate": 0.00019416667891408306,
      "loss": 3.1508,
      "step": 9480
    },
    {
      "epoch": 0.4084531290350349,
      "grad_norm": 1.0772136449813843,
      "learning_rate": 0.00019415103064001046,
      "loss": 3.072,
      "step": 9490
    },
    {
      "epoch": 0.40888353275372297,
      "grad_norm": 1.0224114656448364,
      "learning_rate": 0.00019413536203754977,
      "loss": 3.1566,
      "step": 9500
    },
    {
      "epoch": 0.40888353275372297,
      "eval_bleu": 26.2580632848181,
      "eval_gen_len": 27.475,
      "eval_loss": 2.8336875438690186,
      "eval_runtime": 57.9259,
      "eval_samples_per_second": 17.263,
      "eval_steps_per_second": 1.088,
      "step": 9500
    },
    {
      "epoch": 0.4093139364724111,
      "grad_norm": 0.9123238325119019,
      "learning_rate": 0.00019411967311008392,
      "loss": 3.1307,
      "step": 9510
    },
    {
      "epoch": 0.40974434019109923,
      "grad_norm": 0.9202075004577637,
      "learning_rate": 0.0001941039638610005,
      "loss": 3.2175,
      "step": 9520
    },
    {
      "epoch": 0.41017474390978736,
      "grad_norm": 0.9584940671920776,
      "learning_rate": 0.0001940882342936912,
      "loss": 3.1132,
      "step": 9530
    },
    {
      "epoch": 0.4106051476284755,
      "grad_norm": 0.940453290939331,
      "learning_rate": 0.00019407248441155231,
      "loss": 3.1473,
      "step": 9540
    },
    {
      "epoch": 0.41103555134716363,
      "grad_norm": 0.9724789261817932,
      "learning_rate": 0.0001940567142179844,
      "loss": 3.0857,
      "step": 9550
    },
    {
      "epoch": 0.41103555134716363,
      "eval_bleu": 26.337201677815557,
      "eval_gen_len": 27.604,
      "eval_loss": 2.833116054534912,
      "eval_runtime": 58.5261,
      "eval_samples_per_second": 17.086,
      "eval_steps_per_second": 1.076,
      "step": 9550
    },
    {
      "epoch": 0.41146595506585176,
      "grad_norm": 0.911155641078949,
      "learning_rate": 0.00019404092371639244,
      "loss": 3.1265,
      "step": 9560
    },
    {
      "epoch": 0.4118963587845399,
      "grad_norm": 0.8955237865447998,
      "learning_rate": 0.00019402511291018585,
      "loss": 3.0402,
      "step": 9570
    },
    {
      "epoch": 0.41232676250322803,
      "grad_norm": 1.0496715307235718,
      "learning_rate": 0.00019400928180277833,
      "loss": 3.0807,
      "step": 9580
    },
    {
      "epoch": 0.41275716622191616,
      "grad_norm": 0.8769177198410034,
      "learning_rate": 0.000193993430397588,
      "loss": 3.1979,
      "step": 9590
    },
    {
      "epoch": 0.4131875699406043,
      "grad_norm": 0.9517010450363159,
      "learning_rate": 0.00019397755869803745,
      "loss": 3.0604,
      "step": 9600
    },
    {
      "epoch": 0.4131875699406043,
      "eval_bleu": 26.356922805802498,
      "eval_gen_len": 27.432,
      "eval_loss": 2.8310391902923584,
      "eval_runtime": 58.1631,
      "eval_samples_per_second": 17.193,
      "eval_steps_per_second": 1.083,
      "step": 9600
    },
    {
      "epoch": 0.4136179736592924,
      "grad_norm": 0.9348217248916626,
      "learning_rate": 0.00019396166670755349,
      "loss": 3.2319,
      "step": 9610
    },
    {
      "epoch": 0.41404837737798056,
      "grad_norm": 0.8896927833557129,
      "learning_rate": 0.00019394575442956748,
      "loss": 3.0595,
      "step": 9620
    },
    {
      "epoch": 0.4144787810966687,
      "grad_norm": 0.9307832717895508,
      "learning_rate": 0.00019392982186751504,
      "loss": 3.1428,
      "step": 9630
    },
    {
      "epoch": 0.4149091848153568,
      "grad_norm": 0.9713720083236694,
      "learning_rate": 0.00019391386902483618,
      "loss": 3.1969,
      "step": 9640
    },
    {
      "epoch": 0.41533958853404496,
      "grad_norm": 0.9996693134307861,
      "learning_rate": 0.0001938978959049754,
      "loss": 3.1399,
      "step": 9650
    },
    {
      "epoch": 0.41533958853404496,
      "eval_bleu": 26.615623805707962,
      "eval_gen_len": 27.401,
      "eval_loss": 2.831981658935547,
      "eval_runtime": 58.0854,
      "eval_samples_per_second": 17.216,
      "eval_steps_per_second": 1.085,
      "step": 9650
    },
    {
      "epoch": 0.4157699922527331,
      "grad_norm": 1.0482369661331177,
      "learning_rate": 0.00019388190251138146,
      "loss": 3.0718,
      "step": 9660
    },
    {
      "epoch": 0.41620039597142117,
      "grad_norm": 0.9241248369216919,
      "learning_rate": 0.0001938658888475075,
      "loss": 3.1225,
      "step": 9670
    },
    {
      "epoch": 0.4166307996901093,
      "grad_norm": 0.9405182003974915,
      "learning_rate": 0.0001938498549168111,
      "loss": 3.0569,
      "step": 9680
    },
    {
      "epoch": 0.41706120340879743,
      "grad_norm": 0.8482584357261658,
      "learning_rate": 0.00019383380072275416,
      "loss": 3.0649,
      "step": 9690
    },
    {
      "epoch": 0.41749160712748556,
      "grad_norm": 0.8641161918640137,
      "learning_rate": 0.00019381772626880304,
      "loss": 3.0486,
      "step": 9700
    },
    {
      "epoch": 0.41749160712748556,
      "eval_bleu": 26.23661910792703,
      "eval_gen_len": 27.58,
      "eval_loss": 2.836904764175415,
      "eval_runtime": 61.3555,
      "eval_samples_per_second": 16.298,
      "eval_steps_per_second": 1.027,
      "step": 9700
    },
    {
      "epoch": 0.4179220108461737,
      "grad_norm": 0.8819501399993896,
      "learning_rate": 0.00019380163155842834,
      "loss": 3.1323,
      "step": 9710
    },
    {
      "epoch": 0.41835241456486183,
      "grad_norm": 0.9772205352783203,
      "learning_rate": 0.0001937855165951052,
      "loss": 3.0745,
      "step": 9720
    },
    {
      "epoch": 0.41878281828354996,
      "grad_norm": 0.9759569764137268,
      "learning_rate": 0.00019376938138231299,
      "loss": 3.2158,
      "step": 9730
    },
    {
      "epoch": 0.4192132220022381,
      "grad_norm": 0.8052771091461182,
      "learning_rate": 0.00019375322592353545,
      "loss": 2.983,
      "step": 9740
    },
    {
      "epoch": 0.4196436257209262,
      "grad_norm": 1.026187539100647,
      "learning_rate": 0.00019373705022226084,
      "loss": 3.137,
      "step": 9750
    },
    {
      "epoch": 0.4196436257209262,
      "eval_bleu": 25.904817024338527,
      "eval_gen_len": 27.286,
      "eval_loss": 2.832214593887329,
      "eval_runtime": 57.6456,
      "eval_samples_per_second": 17.347,
      "eval_steps_per_second": 1.093,
      "step": 9750
    },
    {
      "epoch": 0.42007402943961436,
      "grad_norm": 1.0209828615188599,
      "learning_rate": 0.00019372085428198167,
      "loss": 3.1789,
      "step": 9760
    },
    {
      "epoch": 0.4205044331583025,
      "grad_norm": 0.9250434041023254,
      "learning_rate": 0.00019370463810619484,
      "loss": 2.9897,
      "step": 9770
    },
    {
      "epoch": 0.4209348368769906,
      "grad_norm": 0.9500429034233093,
      "learning_rate": 0.0001936884016984016,
      "loss": 3.1366,
      "step": 9780
    },
    {
      "epoch": 0.42136524059567876,
      "grad_norm": 0.8518621921539307,
      "learning_rate": 0.00019367214506210766,
      "loss": 3.0622,
      "step": 9790
    },
    {
      "epoch": 0.4217956443143669,
      "grad_norm": 0.9711977243423462,
      "learning_rate": 0.00019365586820082296,
      "loss": 3.0965,
      "step": 9800
    },
    {
      "epoch": 0.4217956443143669,
      "eval_bleu": 25.680892877624125,
      "eval_gen_len": 27.379,
      "eval_loss": 2.8336312770843506,
      "eval_runtime": 58.0221,
      "eval_samples_per_second": 17.235,
      "eval_steps_per_second": 1.086,
      "step": 9800
    },
    {
      "epoch": 0.422226048033055,
      "grad_norm": 0.9281753897666931,
      "learning_rate": 0.0001936395711180619,
      "loss": 3.1431,
      "step": 9810
    },
    {
      "epoch": 0.42265645175174316,
      "grad_norm": 0.9329720735549927,
      "learning_rate": 0.00019362325381734325,
      "loss": 3.0424,
      "step": 9820
    },
    {
      "epoch": 0.4230868554704313,
      "grad_norm": 0.9981812238693237,
      "learning_rate": 0.00019360691630219008,
      "loss": 3.0268,
      "step": 9830
    },
    {
      "epoch": 0.4235172591891194,
      "grad_norm": 0.9711543321609497,
      "learning_rate": 0.0001935905585761299,
      "loss": 3.1736,
      "step": 9840
    },
    {
      "epoch": 0.4239476629078075,
      "grad_norm": 0.9240247011184692,
      "learning_rate": 0.00019357418064269453,
      "loss": 3.1694,
      "step": 9850
    },
    {
      "epoch": 0.4239476629078075,
      "eval_bleu": 25.947413654068257,
      "eval_gen_len": 27.393,
      "eval_loss": 2.830374002456665,
      "eval_runtime": 57.706,
      "eval_samples_per_second": 17.329,
      "eval_steps_per_second": 1.092,
      "step": 9850
    },
    {
      "epoch": 0.42437806662649563,
      "grad_norm": 0.9712197780609131,
      "learning_rate": 0.00019355778250542018,
      "loss": 3.1985,
      "step": 9860
    },
    {
      "epoch": 0.42480847034518376,
      "grad_norm": 0.913020670413971,
      "learning_rate": 0.00019354136416784742,
      "loss": 3.1896,
      "step": 9870
    },
    {
      "epoch": 0.4252388740638719,
      "grad_norm": 0.9247981905937195,
      "learning_rate": 0.00019352492563352112,
      "loss": 3.2141,
      "step": 9880
    },
    {
      "epoch": 0.42566927778256003,
      "grad_norm": 0.8453980684280396,
      "learning_rate": 0.00019350846690599065,
      "loss": 3.1138,
      "step": 9890
    },
    {
      "epoch": 0.42609968150124816,
      "grad_norm": 0.9569222927093506,
      "learning_rate": 0.00019349198798880961,
      "loss": 3.1356,
      "step": 9900
    },
    {
      "epoch": 0.42609968150124816,
      "eval_bleu": 25.822071509060997,
      "eval_gen_len": 27.372,
      "eval_loss": 2.8336641788482666,
      "eval_runtime": 57.8917,
      "eval_samples_per_second": 17.274,
      "eval_steps_per_second": 1.088,
      "step": 9900
    },
    {
      "epoch": 0.4265300852199363,
      "grad_norm": 1.0283520221710205,
      "learning_rate": 0.000193475488885536,
      "loss": 3.1507,
      "step": 9910
    },
    {
      "epoch": 0.4269604889386244,
      "grad_norm": 0.8883797526359558,
      "learning_rate": 0.00019345896959973219,
      "loss": 3.0851,
      "step": 9920
    },
    {
      "epoch": 0.42739089265731256,
      "grad_norm": 1.0081737041473389,
      "learning_rate": 0.00019344243013496491,
      "loss": 3.273,
      "step": 9930
    },
    {
      "epoch": 0.4278212963760007,
      "grad_norm": 0.9481167197227478,
      "learning_rate": 0.00019342587049480528,
      "loss": 3.1617,
      "step": 9940
    },
    {
      "epoch": 0.4282517000946888,
      "grad_norm": 0.9462224245071411,
      "learning_rate": 0.00019340929068282863,
      "loss": 3.0675,
      "step": 9950
    },
    {
      "epoch": 0.4282517000946888,
      "eval_bleu": 26.600861851702422,
      "eval_gen_len": 27.488,
      "eval_loss": 2.827349901199341,
      "eval_runtime": 58.1741,
      "eval_samples_per_second": 17.19,
      "eval_steps_per_second": 1.083,
      "step": 9950
    },
    {
      "epoch": 0.42868210381337696,
      "grad_norm": 0.9398127198219299,
      "learning_rate": 0.0001933926907026148,
      "loss": 3.1613,
      "step": 9960
    },
    {
      "epoch": 0.4291125075320651,
      "grad_norm": 0.901203989982605,
      "learning_rate": 0.00019337607055774794,
      "loss": 3.2084,
      "step": 9970
    },
    {
      "epoch": 0.4295429112507532,
      "grad_norm": 1.0684072971343994,
      "learning_rate": 0.00019335943025181659,
      "loss": 2.9725,
      "step": 9980
    },
    {
      "epoch": 0.42997331496944136,
      "grad_norm": 0.8487862348556519,
      "learning_rate": 0.00019334276978841353,
      "loss": 3.0717,
      "step": 9990
    },
    {
      "epoch": 0.4304037186881295,
      "grad_norm": 0.8544957637786865,
      "learning_rate": 0.000193326089171136,
      "loss": 3.0052,
      "step": 10000
    },
    {
      "epoch": 0.4304037186881295,
      "eval_bleu": 25.751094038394555,
      "eval_gen_len": 27.298,
      "eval_loss": 2.829522132873535,
      "eval_runtime": 58.1762,
      "eval_samples_per_second": 17.189,
      "eval_steps_per_second": 1.083,
      "step": 10000
    },
    {
      "epoch": 0.4308341224068176,
      "grad_norm": 0.9416443705558777,
      "learning_rate": 0.00019330938840358551,
      "loss": 3.1148,
      "step": 10010
    },
    {
      "epoch": 0.4312645261255057,
      "grad_norm": 0.9088314175605774,
      "learning_rate": 0.00019329266748936805,
      "loss": 3.1771,
      "step": 10020
    },
    {
      "epoch": 0.43169492984419383,
      "grad_norm": 0.7863720655441284,
      "learning_rate": 0.0001932759264320938,
      "loss": 3.1539,
      "step": 10030
    },
    {
      "epoch": 0.43212533356288196,
      "grad_norm": 0.8780832290649414,
      "learning_rate": 0.00019325916523537742,
      "loss": 3.0673,
      "step": 10040
    },
    {
      "epoch": 0.4325557372815701,
      "grad_norm": 0.9625970721244812,
      "learning_rate": 0.0001932423839028378,
      "loss": 3.1162,
      "step": 10050
    },
    {
      "epoch": 0.4325557372815701,
      "eval_bleu": 26.69165129307826,
      "eval_gen_len": 27.379,
      "eval_loss": 2.826354503631592,
      "eval_runtime": 58.9111,
      "eval_samples_per_second": 16.975,
      "eval_steps_per_second": 1.069,
      "step": 10050
    },
    {
      "epoch": 0.43298614100025823,
      "grad_norm": 0.9592489004135132,
      "learning_rate": 0.00019322558243809826,
      "loss": 3.1674,
      "step": 10060
    },
    {
      "epoch": 0.43341654471894636,
      "grad_norm": 0.8052226305007935,
      "learning_rate": 0.00019320876084478648,
      "loss": 3.0975,
      "step": 10070
    },
    {
      "epoch": 0.4338469484376345,
      "grad_norm": 0.8359012603759766,
      "learning_rate": 0.00019319191912653443,
      "loss": 3.0506,
      "step": 10080
    },
    {
      "epoch": 0.4342773521563226,
      "grad_norm": 0.8620924949645996,
      "learning_rate": 0.00019317505728697846,
      "loss": 3.145,
      "step": 10090
    },
    {
      "epoch": 0.43470775587501076,
      "grad_norm": 0.9551845788955688,
      "learning_rate": 0.00019315817532975925,
      "loss": 3.2256,
      "step": 10100
    },
    {
      "epoch": 0.43470775587501076,
      "eval_bleu": 26.060026179982668,
      "eval_gen_len": 27.425,
      "eval_loss": 2.828204393386841,
      "eval_runtime": 58.9716,
      "eval_samples_per_second": 16.957,
      "eval_steps_per_second": 1.068,
      "step": 10100
    },
    {
      "epoch": 0.4351381595936989,
      "grad_norm": 0.9743267297744751,
      "learning_rate": 0.0001931412732585218,
      "loss": 3.1108,
      "step": 10110
    },
    {
      "epoch": 0.435568563312387,
      "grad_norm": 0.8778995275497437,
      "learning_rate": 0.00019312435107691548,
      "loss": 3.1192,
      "step": 10120
    },
    {
      "epoch": 0.43599896703107516,
      "grad_norm": 0.89536052942276,
      "learning_rate": 0.00019310740878859405,
      "loss": 3.1688,
      "step": 10130
    },
    {
      "epoch": 0.4364293707497633,
      "grad_norm": 0.9616006016731262,
      "learning_rate": 0.0001930904463972155,
      "loss": 3.1128,
      "step": 10140
    },
    {
      "epoch": 0.4368597744684514,
      "grad_norm": 0.9251446723937988,
      "learning_rate": 0.0001930734639064423,
      "loss": 3.1481,
      "step": 10150
    },
    {
      "epoch": 0.4368597744684514,
      "eval_bleu": 26.123001406520697,
      "eval_gen_len": 27.535,
      "eval_loss": 2.8274433612823486,
      "eval_runtime": 58.9235,
      "eval_samples_per_second": 16.971,
      "eval_steps_per_second": 1.069,
      "step": 10150
    },
    {
      "epoch": 0.43729017818713956,
      "grad_norm": 0.8610896468162537,
      "learning_rate": 0.0001930564613199411,
      "loss": 3.1617,
      "step": 10160
    },
    {
      "epoch": 0.4377205819058277,
      "grad_norm": 0.8770942687988281,
      "learning_rate": 0.00019303943864138303,
      "loss": 3.1579,
      "step": 10170
    },
    {
      "epoch": 0.4381509856245158,
      "grad_norm": 0.9352548718452454,
      "learning_rate": 0.0001930223958744435,
      "loss": 3.1177,
      "step": 10180
    },
    {
      "epoch": 0.4385813893432039,
      "grad_norm": 0.9874516725540161,
      "learning_rate": 0.0001930053330228022,
      "loss": 3.2124,
      "step": 10190
    },
    {
      "epoch": 0.43901179306189203,
      "grad_norm": 0.9333754181861877,
      "learning_rate": 0.00019298825009014326,
      "loss": 3.1782,
      "step": 10200
    },
    {
      "epoch": 0.43901179306189203,
      "eval_bleu": 26.21476276897983,
      "eval_gen_len": 27.331,
      "eval_loss": 2.8304288387298584,
      "eval_runtime": 58.0113,
      "eval_samples_per_second": 17.238,
      "eval_steps_per_second": 1.086,
      "step": 10200
    },
    {
      "epoch": 0.43944219678058016,
      "grad_norm": 0.8643304109573364,
      "learning_rate": 0.00019297114708015505,
      "loss": 3.1232,
      "step": 10210
    },
    {
      "epoch": 0.4398726004992683,
      "grad_norm": 0.9282239675521851,
      "learning_rate": 0.0001929540239965304,
      "loss": 3.1236,
      "step": 10220
    },
    {
      "epoch": 0.44030300421795643,
      "grad_norm": 0.8582714796066284,
      "learning_rate": 0.0001929368808429664,
      "loss": 3.0643,
      "step": 10230
    },
    {
      "epoch": 0.44073340793664456,
      "grad_norm": 0.9755439162254333,
      "learning_rate": 0.0001929197176231644,
      "loss": 3.0412,
      "step": 10240
    },
    {
      "epoch": 0.4411638116553327,
      "grad_norm": 0.9359210133552551,
      "learning_rate": 0.00019290253434083016,
      "loss": 3.166,
      "step": 10250
    },
    {
      "epoch": 0.4411638116553327,
      "eval_bleu": 25.57988217113126,
      "eval_gen_len": 27.435,
      "eval_loss": 2.8320069313049316,
      "eval_runtime": 58.8283,
      "eval_samples_per_second": 16.999,
      "eval_steps_per_second": 1.071,
      "step": 10250
    },
    {
      "epoch": 0.4415942153740208,
      "grad_norm": 0.9928232431411743,
      "learning_rate": 0.00019288533099967383,
      "loss": 3.0961,
      "step": 10260
    },
    {
      "epoch": 0.44202461909270896,
      "grad_norm": 1.0288829803466797,
      "learning_rate": 0.00019286810760340978,
      "loss": 3.2538,
      "step": 10270
    },
    {
      "epoch": 0.4424550228113971,
      "grad_norm": 1.1928647756576538,
      "learning_rate": 0.00019285086415575677,
      "loss": 3.1391,
      "step": 10280
    },
    {
      "epoch": 0.4428854265300852,
      "grad_norm": 0.9342504143714905,
      "learning_rate": 0.00019283360066043787,
      "loss": 3.2156,
      "step": 10290
    },
    {
      "epoch": 0.44331583024877336,
      "grad_norm": 0.9624930024147034,
      "learning_rate": 0.0001928163171211805,
      "loss": 3.1619,
      "step": 10300
    },
    {
      "epoch": 0.44331583024877336,
      "eval_bleu": 26.342691439648878,
      "eval_gen_len": 27.451,
      "eval_loss": 2.8281872272491455,
      "eval_runtime": 58.3957,
      "eval_samples_per_second": 17.125,
      "eval_steps_per_second": 1.079,
      "step": 10300
    },
    {
      "epoch": 0.4437462339674615,
      "grad_norm": 0.9776195287704468,
      "learning_rate": 0.00019279901354171637,
      "loss": 3.2256,
      "step": 10310
    },
    {
      "epoch": 0.4441766376861496,
      "grad_norm": 0.881128191947937,
      "learning_rate": 0.0001927816899257816,
      "loss": 3.0176,
      "step": 10320
    },
    {
      "epoch": 0.44460704140483776,
      "grad_norm": 0.9019588828086853,
      "learning_rate": 0.00019276434627711646,
      "loss": 3.1857,
      "step": 10330
    },
    {
      "epoch": 0.4450374451235259,
      "grad_norm": 0.9532907605171204,
      "learning_rate": 0.00019274698259946576,
      "loss": 3.1451,
      "step": 10340
    },
    {
      "epoch": 0.445467848842214,
      "grad_norm": 0.962924063205719,
      "learning_rate": 0.0001927295988965785,
      "loss": 3.0423,
      "step": 10350
    },
    {
      "epoch": 0.445467848842214,
      "eval_bleu": 26.034535866637423,
      "eval_gen_len": 27.275,
      "eval_loss": 2.8294460773468018,
      "eval_runtime": 57.9851,
      "eval_samples_per_second": 17.246,
      "eval_steps_per_second": 1.086,
      "step": 10350
    },
    {
      "epoch": 0.44589825256090215,
      "grad_norm": 0.9627518653869629,
      "learning_rate": 0.00019271219517220806,
      "loss": 3.1926,
      "step": 10360
    },
    {
      "epoch": 0.44632865627959023,
      "grad_norm": 0.8572517037391663,
      "learning_rate": 0.0001926947714301121,
      "loss": 3.0949,
      "step": 10370
    },
    {
      "epoch": 0.44675905999827836,
      "grad_norm": 0.9868847727775574,
      "learning_rate": 0.00019267732767405264,
      "loss": 3.0942,
      "step": 10380
    },
    {
      "epoch": 0.4471894637169665,
      "grad_norm": 0.9597799181938171,
      "learning_rate": 0.00019265986390779597,
      "loss": 3.1651,
      "step": 10390
    },
    {
      "epoch": 0.44761986743565463,
      "grad_norm": 1.0164086818695068,
      "learning_rate": 0.0001926423801351128,
      "loss": 3.1467,
      "step": 10400
    },
    {
      "epoch": 0.44761986743565463,
      "eval_bleu": 26.18589536044709,
      "eval_gen_len": 27.465,
      "eval_loss": 2.829050302505493,
      "eval_runtime": 58.2537,
      "eval_samples_per_second": 17.166,
      "eval_steps_per_second": 1.081,
      "step": 10400
    },
    {
      "epoch": 0.44805027115434276,
      "grad_norm": 0.8881533145904541,
      "learning_rate": 0.00019262487635977803,
      "loss": 3.1143,
      "step": 10410
    },
    {
      "epoch": 0.4484806748730309,
      "grad_norm": 0.9716580510139465,
      "learning_rate": 0.00019260735258557098,
      "loss": 3.127,
      "step": 10420
    },
    {
      "epoch": 0.448911078591719,
      "grad_norm": 0.916959285736084,
      "learning_rate": 0.00019258980881627528,
      "loss": 3.1227,
      "step": 10430
    },
    {
      "epoch": 0.44934148231040716,
      "grad_norm": 0.8973000049591064,
      "learning_rate": 0.00019257224505567878,
      "loss": 3.1416,
      "step": 10440
    },
    {
      "epoch": 0.4497718860290953,
      "grad_norm": 1.0798896551132202,
      "learning_rate": 0.00019255466130757375,
      "loss": 3.074,
      "step": 10450
    },
    {
      "epoch": 0.4497718860290953,
      "eval_bleu": 25.73032603611245,
      "eval_gen_len": 27.377,
      "eval_loss": 2.833892822265625,
      "eval_runtime": 58.3362,
      "eval_samples_per_second": 17.142,
      "eval_steps_per_second": 1.08,
      "step": 10450
    },
    {
      "epoch": 0.4502022897477834,
      "grad_norm": 0.8777201175689697,
      "learning_rate": 0.00019253705757575675,
      "loss": 3.0986,
      "step": 10460
    },
    {
      "epoch": 0.45063269346647156,
      "grad_norm": 0.9573115110397339,
      "learning_rate": 0.00019251943386402865,
      "loss": 3.171,
      "step": 10470
    },
    {
      "epoch": 0.4510630971851597,
      "grad_norm": 0.8405675292015076,
      "learning_rate": 0.00019250179017619464,
      "loss": 3.2087,
      "step": 10480
    },
    {
      "epoch": 0.4514935009038478,
      "grad_norm": 1.0010648965835571,
      "learning_rate": 0.00019248412651606418,
      "loss": 3.1066,
      "step": 10490
    },
    {
      "epoch": 0.45192390462253595,
      "grad_norm": 0.9523085355758667,
      "learning_rate": 0.00019246644288745105,
      "loss": 3.1376,
      "step": 10500
    },
    {
      "epoch": 0.45192390462253595,
      "eval_bleu": 25.867952351282067,
      "eval_gen_len": 27.331,
      "eval_loss": 2.8276946544647217,
      "eval_runtime": 58.309,
      "eval_samples_per_second": 17.15,
      "eval_steps_per_second": 1.08,
      "step": 10500
    },
    {
      "epoch": 0.4523543083412241,
      "grad_norm": 0.9103217720985413,
      "learning_rate": 0.00019244873929417347,
      "loss": 3.1955,
      "step": 10510
    },
    {
      "epoch": 0.4527847120599122,
      "grad_norm": 0.9729777574539185,
      "learning_rate": 0.00019243101574005378,
      "loss": 3.1339,
      "step": 10520
    },
    {
      "epoch": 0.45321511577860035,
      "grad_norm": 0.9623329043388367,
      "learning_rate": 0.00019241327222891874,
      "loss": 3.1301,
      "step": 10530
    },
    {
      "epoch": 0.45364551949728843,
      "grad_norm": 0.907167911529541,
      "learning_rate": 0.0001923955087645994,
      "loss": 3.0241,
      "step": 10540
    },
    {
      "epoch": 0.45407592321597656,
      "grad_norm": 1.0299118757247925,
      "learning_rate": 0.0001923777253509311,
      "loss": 3.0293,
      "step": 10550
    },
    {
      "epoch": 0.45407592321597656,
      "eval_bleu": 26.099746724862968,
      "eval_gen_len": 27.416,
      "eval_loss": 2.827662706375122,
      "eval_runtime": 58.6153,
      "eval_samples_per_second": 17.06,
      "eval_steps_per_second": 1.075,
      "step": 10550
    },
    {
      "epoch": 0.4545063269346647,
      "grad_norm": 0.9557310342788696,
      "learning_rate": 0.00019235992199175353,
      "loss": 3.1128,
      "step": 10560
    },
    {
      "epoch": 0.4549367306533528,
      "grad_norm": 0.9523369669914246,
      "learning_rate": 0.00019234209869091064,
      "loss": 3.0893,
      "step": 10570
    },
    {
      "epoch": 0.45536713437204096,
      "grad_norm": 1.0302035808563232,
      "learning_rate": 0.00019232425545225073,
      "loss": 3.0864,
      "step": 10580
    },
    {
      "epoch": 0.4557975380907291,
      "grad_norm": 0.9972229599952698,
      "learning_rate": 0.00019230639227962632,
      "loss": 3.2568,
      "step": 10590
    },
    {
      "epoch": 0.4562279418094172,
      "grad_norm": 0.9039544463157654,
      "learning_rate": 0.00019228850917689437,
      "loss": 3.0777,
      "step": 10600
    },
    {
      "epoch": 0.4562279418094172,
      "eval_bleu": 26.249674131996706,
      "eval_gen_len": 27.31,
      "eval_loss": 2.826592206954956,
      "eval_runtime": 58.1915,
      "eval_samples_per_second": 17.185,
      "eval_steps_per_second": 1.083,
      "step": 10600
    },
    {
      "epoch": 0.45665834552810536,
      "grad_norm": 0.8539618253707886,
      "learning_rate": 0.00019227060614791599,
      "loss": 3.1105,
      "step": 10610
    },
    {
      "epoch": 0.4570887492467935,
      "grad_norm": 0.9221635460853577,
      "learning_rate": 0.00019225268319655672,
      "loss": 3.1151,
      "step": 10620
    },
    {
      "epoch": 0.4575191529654816,
      "grad_norm": 0.9070770740509033,
      "learning_rate": 0.00019223474032668632,
      "loss": 3.1048,
      "step": 10630
    },
    {
      "epoch": 0.45794955668416976,
      "grad_norm": 0.9458054900169373,
      "learning_rate": 0.00019221677754217896,
      "loss": 3.0797,
      "step": 10640
    },
    {
      "epoch": 0.4583799604028579,
      "grad_norm": 0.9975200295448303,
      "learning_rate": 0.0001921987948469129,
      "loss": 3.0829,
      "step": 10650
    },
    {
      "epoch": 0.4583799604028579,
      "eval_bleu": 26.01645156143809,
      "eval_gen_len": 27.495,
      "eval_loss": 2.8293395042419434,
      "eval_runtime": 58.5646,
      "eval_samples_per_second": 17.075,
      "eval_steps_per_second": 1.076,
      "step": 10650
    },
    {
      "epoch": 0.458810364121546,
      "grad_norm": 0.7658501863479614,
      "learning_rate": 0.00019218079224477092,
      "loss": 3.0835,
      "step": 10660
    },
    {
      "epoch": 0.45924076784023415,
      "grad_norm": 0.9751368761062622,
      "learning_rate": 0.00019216276973963998,
      "loss": 3.1824,
      "step": 10670
    },
    {
      "epoch": 0.4596711715589223,
      "grad_norm": 0.9475564360618591,
      "learning_rate": 0.00019214472733541135,
      "loss": 3.1031,
      "step": 10680
    },
    {
      "epoch": 0.4601015752776104,
      "grad_norm": 0.8500077128410339,
      "learning_rate": 0.00019212666503598067,
      "loss": 3.0208,
      "step": 10690
    },
    {
      "epoch": 0.46053197899629855,
      "grad_norm": 0.9904443621635437,
      "learning_rate": 0.00019210858284524776,
      "loss": 3.1438,
      "step": 10700
    },
    {
      "epoch": 0.46053197899629855,
      "eval_bleu": 26.163714098322252,
      "eval_gen_len": 27.614,
      "eval_loss": 2.827409505844116,
      "eval_runtime": 59.4862,
      "eval_samples_per_second": 16.811,
      "eval_steps_per_second": 1.059,
      "step": 10700
    },
    {
      "epoch": 0.4609623827149867,
      "grad_norm": 0.89506596326828,
      "learning_rate": 0.0001920904807671168,
      "loss": 3.1602,
      "step": 10710
    },
    {
      "epoch": 0.46139278643367476,
      "grad_norm": 0.9841763377189636,
      "learning_rate": 0.00019207235880549622,
      "loss": 3.1055,
      "step": 10720
    },
    {
      "epoch": 0.4618231901523629,
      "grad_norm": 0.785602867603302,
      "learning_rate": 0.0001920542169642989,
      "loss": 3.1422,
      "step": 10730
    },
    {
      "epoch": 0.462253593871051,
      "grad_norm": 0.9482539296150208,
      "learning_rate": 0.00019203605524744177,
      "loss": 3.1566,
      "step": 10740
    },
    {
      "epoch": 0.46268399758973916,
      "grad_norm": 0.974463164806366,
      "learning_rate": 0.00019201787365884622,
      "loss": 3.2071,
      "step": 10750
    },
    {
      "epoch": 0.46268399758973916,
      "eval_bleu": 25.935762893514234,
      "eval_gen_len": 27.398,
      "eval_loss": 2.82828426361084,
      "eval_runtime": 57.8749,
      "eval_samples_per_second": 17.279,
      "eval_steps_per_second": 1.089,
      "step": 10750
    },
    {
      "epoch": 0.4631144013084273,
      "grad_norm": 0.9916736483573914,
      "learning_rate": 0.00019199967220243788,
      "loss": 3.1791,
      "step": 10760
    },
    {
      "epoch": 0.4635448050271154,
      "grad_norm": 0.9313351511955261,
      "learning_rate": 0.0001919814508821467,
      "loss": 3.0296,
      "step": 10770
    },
    {
      "epoch": 0.46397520874580356,
      "grad_norm": 0.8742120265960693,
      "learning_rate": 0.00019196320970190685,
      "loss": 3.0694,
      "step": 10780
    },
    {
      "epoch": 0.4644056124644917,
      "grad_norm": 0.986809253692627,
      "learning_rate": 0.00019194494866565682,
      "loss": 3.0963,
      "step": 10790
    },
    {
      "epoch": 0.4648360161831798,
      "grad_norm": 1.009730339050293,
      "learning_rate": 0.00019192666777733943,
      "loss": 3.171,
      "step": 10800
    },
    {
      "epoch": 0.4648360161831798,
      "eval_bleu": 26.30795950135861,
      "eval_gen_len": 27.481,
      "eval_loss": 2.828533411026001,
      "eval_runtime": 58.2084,
      "eval_samples_per_second": 17.18,
      "eval_steps_per_second": 1.082,
      "step": 10800
    },
    {
      "epoch": 0.46526641990186796,
      "grad_norm": 1.0649733543395996,
      "learning_rate": 0.00019190836704090173,
      "loss": 3.1794,
      "step": 10810
    },
    {
      "epoch": 0.4656968236205561,
      "grad_norm": 0.8826149702072144,
      "learning_rate": 0.00019189004646029512,
      "loss": 3.0431,
      "step": 10820
    },
    {
      "epoch": 0.4661272273392442,
      "grad_norm": 0.9872477650642395,
      "learning_rate": 0.0001918717060394752,
      "loss": 3.1025,
      "step": 10830
    },
    {
      "epoch": 0.46655763105793235,
      "grad_norm": 0.9784678220748901,
      "learning_rate": 0.0001918533457824019,
      "loss": 3.3036,
      "step": 10840
    },
    {
      "epoch": 0.4669880347766205,
      "grad_norm": 0.7631246447563171,
      "learning_rate": 0.00019183496569303947,
      "loss": 3.0226,
      "step": 10850
    },
    {
      "epoch": 0.4669880347766205,
      "eval_bleu": 26.281928424564278,
      "eval_gen_len": 27.305,
      "eval_loss": 2.8321175575256348,
      "eval_runtime": 58.1736,
      "eval_samples_per_second": 17.19,
      "eval_steps_per_second": 1.083,
      "step": 10850
    },
    {
      "epoch": 0.4674184384953086,
      "grad_norm": 0.8782216310501099,
      "learning_rate": 0.00019181656577535634,
      "loss": 3.2241,
      "step": 10860
    },
    {
      "epoch": 0.46784884221399675,
      "grad_norm": 0.738525390625,
      "learning_rate": 0.00019179814603332532,
      "loss": 3.0695,
      "step": 10870
    },
    {
      "epoch": 0.4682792459326849,
      "grad_norm": 1.7799508571624756,
      "learning_rate": 0.00019177970647092348,
      "loss": 3.1948,
      "step": 10880
    },
    {
      "epoch": 0.46870964965137296,
      "grad_norm": 0.958533525466919,
      "learning_rate": 0.0001917612470921321,
      "loss": 3.1176,
      "step": 10890
    },
    {
      "epoch": 0.4691400533700611,
      "grad_norm": 0.8057253956794739,
      "learning_rate": 0.00019174276790093683,
      "loss": 3.1057,
      "step": 10900
    },
    {
      "epoch": 0.4691400533700611,
      "eval_bleu": 25.750692817803106,
      "eval_gen_len": 27.356,
      "eval_loss": 2.832669258117676,
      "eval_runtime": 58.1455,
      "eval_samples_per_second": 17.198,
      "eval_steps_per_second": 1.083,
      "step": 10900
    },
    {
      "epoch": 0.4695704570887492,
      "grad_norm": 0.9072892069816589,
      "learning_rate": 0.00019172426890132758,
      "loss": 3.0849,
      "step": 10910
    },
    {
      "epoch": 0.47000086080743736,
      "grad_norm": 0.8568498492240906,
      "learning_rate": 0.00019170575009729848,
      "loss": 3.1979,
      "step": 10920
    },
    {
      "epoch": 0.4704312645261255,
      "grad_norm": 1.043427586555481,
      "learning_rate": 0.00019168721149284796,
      "loss": 3.0537,
      "step": 10930
    },
    {
      "epoch": 0.4708616682448136,
      "grad_norm": 0.974113404750824,
      "learning_rate": 0.00019166865309197875,
      "loss": 3.0447,
      "step": 10940
    },
    {
      "epoch": 0.47129207196350176,
      "grad_norm": 0.9471710920333862,
      "learning_rate": 0.0001916500748986979,
      "loss": 3.1512,
      "step": 10950
    },
    {
      "epoch": 0.47129207196350176,
      "eval_bleu": 25.779612664504814,
      "eval_gen_len": 27.438,
      "eval_loss": 2.8291897773742676,
      "eval_runtime": 58.9081,
      "eval_samples_per_second": 16.976,
      "eval_steps_per_second": 1.069,
      "step": 10950
    },
    {
      "epoch": 0.4717224756821899,
      "grad_norm": 0.9300083518028259,
      "learning_rate": 0.00019163147691701656,
      "loss": 3.088,
      "step": 10960
    },
    {
      "epoch": 0.472152879400878,
      "grad_norm": 0.90077143907547,
      "learning_rate": 0.00019161285915095038,
      "loss": 3.0854,
      "step": 10970
    },
    {
      "epoch": 0.47258328311956616,
      "grad_norm": 0.8108264207839966,
      "learning_rate": 0.0001915942216045191,
      "loss": 3.152,
      "step": 10980
    },
    {
      "epoch": 0.4730136868382543,
      "grad_norm": 0.9834164381027222,
      "learning_rate": 0.0001915755642817468,
      "loss": 3.18,
      "step": 10990
    },
    {
      "epoch": 0.4734440905569424,
      "grad_norm": 0.9737152457237244,
      "learning_rate": 0.0001915568871866619,
      "loss": 3.0279,
      "step": 11000
    },
    {
      "epoch": 0.4734440905569424,
      "eval_bleu": 25.955635280038774,
      "eval_gen_len": 27.427,
      "eval_loss": 2.826291561126709,
      "eval_runtime": 58.4886,
      "eval_samples_per_second": 17.097,
      "eval_steps_per_second": 1.077,
      "step": 11000
    },
    {
      "epoch": 0.47387449427563055,
      "grad_norm": 1.062057614326477,
      "learning_rate": 0.0001915381903232969,
      "loss": 2.9785,
      "step": 11010
    },
    {
      "epoch": 0.4743048979943187,
      "grad_norm": 0.951095461845398,
      "learning_rate": 0.00019151947369568881,
      "loss": 3.1294,
      "step": 11020
    },
    {
      "epoch": 0.4747353017130068,
      "grad_norm": 0.9210569858551025,
      "learning_rate": 0.00019150073730787872,
      "loss": 3.1007,
      "step": 11030
    },
    {
      "epoch": 0.47516570543169495,
      "grad_norm": 0.9728602170944214,
      "learning_rate": 0.00019148198116391204,
      "loss": 3.1123,
      "step": 11040
    },
    {
      "epoch": 0.4755961091503831,
      "grad_norm": 0.8741900324821472,
      "learning_rate": 0.00019146320526783849,
      "loss": 3.0993,
      "step": 11050
    },
    {
      "epoch": 0.4755961091503831,
      "eval_bleu": 25.75628617043804,
      "eval_gen_len": 27.367,
      "eval_loss": 2.827683448791504,
      "eval_runtime": 58.228,
      "eval_samples_per_second": 17.174,
      "eval_steps_per_second": 1.082,
      "step": 11050
    },
    {
      "epoch": 0.47602651286907116,
      "grad_norm": 0.9131535887718201,
      "learning_rate": 0.00019144440962371202,
      "loss": 3.1777,
      "step": 11060
    },
    {
      "epoch": 0.4764569165877593,
      "grad_norm": 0.9318097233772278,
      "learning_rate": 0.00019142559423559083,
      "loss": 3.2235,
      "step": 11070
    },
    {
      "epoch": 0.4768873203064474,
      "grad_norm": 0.9196944236755371,
      "learning_rate": 0.0001914067591075374,
      "loss": 3.1182,
      "step": 11080
    },
    {
      "epoch": 0.47731772402513556,
      "grad_norm": 0.8980391621589661,
      "learning_rate": 0.0001913879042436185,
      "loss": 3.1642,
      "step": 11090
    },
    {
      "epoch": 0.4777481277438237,
      "grad_norm": 0.875480592250824,
      "learning_rate": 0.00019136902964790505,
      "loss": 3.1837,
      "step": 11100
    },
    {
      "epoch": 0.4777481277438237,
      "eval_bleu": 25.68267968771089,
      "eval_gen_len": 27.37,
      "eval_loss": 2.8269569873809814,
      "eval_runtime": 58.612,
      "eval_samples_per_second": 17.061,
      "eval_steps_per_second": 1.075,
      "step": 11100
    },
    {
      "epoch": 0.4781785314625118,
      "grad_norm": 1.037714958190918,
      "learning_rate": 0.0001913501353244724,
      "loss": 3.1182,
      "step": 11110
    },
    {
      "epoch": 0.47860893518119996,
      "grad_norm": 0.9359232187271118,
      "learning_rate": 0.00019133122127740004,
      "loss": 3.1116,
      "step": 11120
    },
    {
      "epoch": 0.4790393388998881,
      "grad_norm": 0.9590954184532166,
      "learning_rate": 0.00019131228751077174,
      "loss": 3.1471,
      "step": 11130
    },
    {
      "epoch": 0.4794697426185762,
      "grad_norm": 0.9133670926094055,
      "learning_rate": 0.00019129333402867555,
      "loss": 3.0756,
      "step": 11140
    },
    {
      "epoch": 0.47990014633726436,
      "grad_norm": 0.864350438117981,
      "learning_rate": 0.00019127436083520377,
      "loss": 3.0427,
      "step": 11150
    },
    {
      "epoch": 0.47990014633726436,
      "eval_bleu": 25.83515410858738,
      "eval_gen_len": 27.472,
      "eval_loss": 2.8246641159057617,
      "eval_runtime": 59.1071,
      "eval_samples_per_second": 16.918,
      "eval_steps_per_second": 1.066,
      "step": 11150
    },
    {
      "epoch": 0.4803305500559525,
      "grad_norm": 0.910239040851593,
      "learning_rate": 0.0001912553679344529,
      "loss": 3.1073,
      "step": 11160
    },
    {
      "epoch": 0.4807609537746406,
      "grad_norm": 1.0344650745391846,
      "learning_rate": 0.00019123635533052383,
      "loss": 3.0742,
      "step": 11170
    },
    {
      "epoch": 0.48119135749332875,
      "grad_norm": 0.9215933680534363,
      "learning_rate": 0.00019121732302752157,
      "loss": 3.1313,
      "step": 11180
    },
    {
      "epoch": 0.4816217612120169,
      "grad_norm": 0.9255146384239197,
      "learning_rate": 0.00019119827102955544,
      "loss": 3.1399,
      "step": 11190
    },
    {
      "epoch": 0.482052164930705,
      "grad_norm": 1.0046340227127075,
      "learning_rate": 0.000191179199340739,
      "loss": 3.0341,
      "step": 11200
    },
    {
      "epoch": 0.482052164930705,
      "eval_bleu": 25.866453446982305,
      "eval_gen_len": 27.414,
      "eval_loss": 2.8310396671295166,
      "eval_runtime": 58.8483,
      "eval_samples_per_second": 16.993,
      "eval_steps_per_second": 1.071,
      "step": 11200
    },
    {
      "epoch": 0.48248256864939315,
      "grad_norm": 0.8254612684249878,
      "learning_rate": 0.00019116010796519007,
      "loss": 3.0867,
      "step": 11210
    },
    {
      "epoch": 0.4829129723680813,
      "grad_norm": 0.9441536664962769,
      "learning_rate": 0.0001911409969070307,
      "loss": 3.0712,
      "step": 11220
    },
    {
      "epoch": 0.4833433760867694,
      "grad_norm": 0.91473788022995,
      "learning_rate": 0.00019112186617038725,
      "loss": 3.1738,
      "step": 11230
    },
    {
      "epoch": 0.4837737798054575,
      "grad_norm": 0.8578932285308838,
      "learning_rate": 0.00019110271575939025,
      "loss": 3.0762,
      "step": 11240
    },
    {
      "epoch": 0.4842041835241456,
      "grad_norm": 0.9742098450660706,
      "learning_rate": 0.00019108354567817453,
      "loss": 3.1061,
      "step": 11250
    },
    {
      "epoch": 0.4842041835241456,
      "eval_bleu": 25.53803145225973,
      "eval_gen_len": 27.399,
      "eval_loss": 2.8315556049346924,
      "eval_runtime": 58.4774,
      "eval_samples_per_second": 17.101,
      "eval_steps_per_second": 1.077,
      "step": 11250
    },
    {
      "epoch": 0.48463458724283376,
      "grad_norm": 0.9915981292724609,
      "learning_rate": 0.00019106435593087916,
      "loss": 3.1117,
      "step": 11260
    },
    {
      "epoch": 0.4850649909615219,
      "grad_norm": 0.899394690990448,
      "learning_rate": 0.0001910451465216474,
      "loss": 2.9723,
      "step": 11270
    },
    {
      "epoch": 0.48549539468021,
      "grad_norm": 0.9785005450248718,
      "learning_rate": 0.00019102591745462686,
      "loss": 3.101,
      "step": 11280
    },
    {
      "epoch": 0.48592579839889816,
      "grad_norm": 1.0703390836715698,
      "learning_rate": 0.0001910066687339693,
      "loss": 3.1449,
      "step": 11290
    },
    {
      "epoch": 0.4863562021175863,
      "grad_norm": 1.019630789756775,
      "learning_rate": 0.00019098740036383079,
      "loss": 3.0979,
      "step": 11300
    },
    {
      "epoch": 0.4863562021175863,
      "eval_bleu": 25.707306359901857,
      "eval_gen_len": 27.323,
      "eval_loss": 2.8274130821228027,
      "eval_runtime": 58.4349,
      "eval_samples_per_second": 17.113,
      "eval_steps_per_second": 1.078,
      "step": 11300
    },
    {
      "epoch": 0.4867866058362744,
      "grad_norm": 1.0113154649734497,
      "learning_rate": 0.00019096811234837156,
      "loss": 3.1608,
      "step": 11310
    },
    {
      "epoch": 0.48721700955496255,
      "grad_norm": 1.0052525997161865,
      "learning_rate": 0.0001909488046917562,
      "loss": 3.2264,
      "step": 11320
    },
    {
      "epoch": 0.4876474132736507,
      "grad_norm": 0.9738736748695374,
      "learning_rate": 0.0001909294773981534,
      "loss": 3.0565,
      "step": 11330
    },
    {
      "epoch": 0.4880778169923388,
      "grad_norm": 0.8584324717521667,
      "learning_rate": 0.00019091013047173628,
      "loss": 3.0851,
      "step": 11340
    },
    {
      "epoch": 0.48850822071102695,
      "grad_norm": 0.9307119846343994,
      "learning_rate": 0.00019089076391668196,
      "loss": 3.1308,
      "step": 11350
    },
    {
      "epoch": 0.48850822071102695,
      "eval_bleu": 25.81909030914548,
      "eval_gen_len": 27.301,
      "eval_loss": 2.8291547298431396,
      "eval_runtime": 58.2767,
      "eval_samples_per_second": 17.16,
      "eval_steps_per_second": 1.081,
      "step": 11350
    },
    {
      "epoch": 0.4889386244297151,
      "grad_norm": 0.9447725415229797,
      "learning_rate": 0.000190871377737172,
      "loss": 3.0888,
      "step": 11360
    },
    {
      "epoch": 0.4893690281484032,
      "grad_norm": 0.9131414890289307,
      "learning_rate": 0.00019085197193739208,
      "loss": 3.1084,
      "step": 11370
    },
    {
      "epoch": 0.48979943186709135,
      "grad_norm": 0.9311015605926514,
      "learning_rate": 0.0001908325465215322,
      "loss": 3.1321,
      "step": 11380
    },
    {
      "epoch": 0.4902298355857795,
      "grad_norm": 0.9027346968650818,
      "learning_rate": 0.00019081310149378648,
      "loss": 3.0604,
      "step": 11390
    },
    {
      "epoch": 0.4906602393044676,
      "grad_norm": 1.0021971464157104,
      "learning_rate": 0.0001907936368583534,
      "loss": 3.0838,
      "step": 11400
    },
    {
      "epoch": 0.4906602393044676,
      "eval_bleu": 25.990340262844963,
      "eval_gen_len": 27.277,
      "eval_loss": 2.832521677017212,
      "eval_runtime": 58.5533,
      "eval_samples_per_second": 17.078,
      "eval_steps_per_second": 1.076,
      "step": 11400
    },
    {
      "epoch": 0.4910906430231557,
      "grad_norm": 0.9250534772872925,
      "learning_rate": 0.00019077415261943564,
      "loss": 3.0837,
      "step": 11410
    },
    {
      "epoch": 0.4915210467418438,
      "grad_norm": 0.8691904544830322,
      "learning_rate": 0.00019075464878124,
      "loss": 3.1336,
      "step": 11420
    },
    {
      "epoch": 0.49195145046053196,
      "grad_norm": 0.8487247228622437,
      "learning_rate": 0.0001907351253479777,
      "loss": 3.0821,
      "step": 11430
    },
    {
      "epoch": 0.4923818541792201,
      "grad_norm": 0.8958820700645447,
      "learning_rate": 0.00019071558232386403,
      "loss": 3.0635,
      "step": 11440
    },
    {
      "epoch": 0.4928122578979082,
      "grad_norm": 0.8369091153144836,
      "learning_rate": 0.00019069601971311863,
      "loss": 3.0955,
      "step": 11450
    },
    {
      "epoch": 0.4928122578979082,
      "eval_bleu": 25.38099993041812,
      "eval_gen_len": 27.357,
      "eval_loss": 2.8301563262939453,
      "eval_runtime": 58.7893,
      "eval_samples_per_second": 17.01,
      "eval_steps_per_second": 1.072,
      "step": 11450
    },
    {
      "epoch": 0.49324266161659636,
      "grad_norm": 0.8427524566650391,
      "learning_rate": 0.00019067643751996527,
      "loss": 3.1002,
      "step": 11460
    },
    {
      "epoch": 0.4936730653352845,
      "grad_norm": 0.8235974311828613,
      "learning_rate": 0.000190656835748632,
      "loss": 3.1877,
      "step": 11470
    },
    {
      "epoch": 0.4941034690539726,
      "grad_norm": 0.9441569447517395,
      "learning_rate": 0.00019063721440335107,
      "loss": 3.1779,
      "step": 11480
    },
    {
      "epoch": 0.49453387277266075,
      "grad_norm": 0.8316612243652344,
      "learning_rate": 0.00019061757348835904,
      "loss": 3.0455,
      "step": 11490
    },
    {
      "epoch": 0.4949642764913489,
      "grad_norm": 0.9157511591911316,
      "learning_rate": 0.00019059791300789653,
      "loss": 3.1975,
      "step": 11500
    },
    {
      "epoch": 0.4949642764913489,
      "eval_bleu": 25.91287081917857,
      "eval_gen_len": 27.386,
      "eval_loss": 2.827440023422241,
      "eval_runtime": 57.8937,
      "eval_samples_per_second": 17.273,
      "eval_steps_per_second": 1.088,
      "step": 11500
    },
    {
      "epoch": 0.495394680210037,
      "grad_norm": 0.880111813545227,
      "learning_rate": 0.00019057823296620856,
      "loss": 3.1698,
      "step": 11510
    },
    {
      "epoch": 0.49582508392872515,
      "grad_norm": 1.054360270500183,
      "learning_rate": 0.0001905585333675443,
      "loss": 3.2092,
      "step": 11520
    },
    {
      "epoch": 0.4962554876474133,
      "grad_norm": 0.8878052830696106,
      "learning_rate": 0.0001905388142161571,
      "loss": 3.0726,
      "step": 11530
    },
    {
      "epoch": 0.4966858913661014,
      "grad_norm": 0.7484291791915894,
      "learning_rate": 0.00019051907551630458,
      "loss": 3.1383,
      "step": 11540
    },
    {
      "epoch": 0.49711629508478955,
      "grad_norm": 0.9739546775817871,
      "learning_rate": 0.0001904993172722486,
      "loss": 3.1229,
      "step": 11550
    },
    {
      "epoch": 0.49711629508478955,
      "eval_bleu": 25.885120878305827,
      "eval_gen_len": 27.475,
      "eval_loss": 2.8293368816375732,
      "eval_runtime": 58.9914,
      "eval_samples_per_second": 16.952,
      "eval_steps_per_second": 1.068,
      "step": 11550
    },
    {
      "epoch": 0.4975466988034777,
      "grad_norm": 0.9622904658317566,
      "learning_rate": 0.00019047953948825517,
      "loss": 3.1015,
      "step": 11560
    },
    {
      "epoch": 0.4979771025221658,
      "grad_norm": 0.9566891193389893,
      "learning_rate": 0.00019045974216859462,
      "loss": 3.0965,
      "step": 11570
    },
    {
      "epoch": 0.49840750624085395,
      "grad_norm": 0.9596928954124451,
      "learning_rate": 0.00019043992531754138,
      "loss": 3.1868,
      "step": 11580
    },
    {
      "epoch": 0.498837909959542,
      "grad_norm": 1.1317799091339111,
      "learning_rate": 0.00019042008893937419,
      "loss": 3.1839,
      "step": 11590
    },
    {
      "epoch": 0.49926831367823016,
      "grad_norm": 0.9106561541557312,
      "learning_rate": 0.00019040023303837597,
      "loss": 3.1181,
      "step": 11600
    },
    {
      "epoch": 0.49926831367823016,
      "eval_bleu": 25.832881826986444,
      "eval_gen_len": 27.449,
      "eval_loss": 2.8289666175842285,
      "eval_runtime": 58.8299,
      "eval_samples_per_second": 16.998,
      "eval_steps_per_second": 1.071,
      "step": 11600
    },
    {
      "epoch": 0.4996987173969183,
      "grad_norm": 0.871161937713623,
      "learning_rate": 0.00019038035761883383,
      "loss": 3.0492,
      "step": 11610
    },
    {
      "epoch": 0.5001291211156065,
      "grad_norm": 0.9839112162590027,
      "learning_rate": 0.00019036046268503917,
      "loss": 3.0814,
      "step": 11620
    },
    {
      "epoch": 0.5005595248342946,
      "grad_norm": 0.8677092790603638,
      "learning_rate": 0.00019034054824128754,
      "loss": 3.1171,
      "step": 11630
    },
    {
      "epoch": 0.5009899285529827,
      "grad_norm": 0.9815446734428406,
      "learning_rate": 0.0001903206142918787,
      "loss": 3.1453,
      "step": 11640
    },
    {
      "epoch": 0.5014203322716708,
      "grad_norm": 0.9464719891548157,
      "learning_rate": 0.00019030066084111663,
      "loss": 3.0966,
      "step": 11650
    },
    {
      "epoch": 0.5014203322716708,
      "eval_bleu": 25.55871102369167,
      "eval_gen_len": 27.399,
      "eval_loss": 2.8301026821136475,
      "eval_runtime": 59.0193,
      "eval_samples_per_second": 16.944,
      "eval_steps_per_second": 1.067,
      "step": 11650
    },
    {
      "epoch": 0.501850735990359,
      "grad_norm": 0.9465276598930359,
      "learning_rate": 0.00019028068789330956,
      "loss": 3.1397,
      "step": 11660
    },
    {
      "epoch": 0.5022811397090471,
      "grad_norm": 0.9634228348731995,
      "learning_rate": 0.0001902606954527699,
      "loss": 3.1418,
      "step": 11670
    },
    {
      "epoch": 0.5027115434277352,
      "grad_norm": 0.885130763053894,
      "learning_rate": 0.00019024068352381426,
      "loss": 3.0637,
      "step": 11680
    },
    {
      "epoch": 0.5031419471464234,
      "grad_norm": 0.9747304916381836,
      "learning_rate": 0.00019022065211076345,
      "loss": 3.1757,
      "step": 11690
    },
    {
      "epoch": 0.5035723508651114,
      "grad_norm": 0.9076148271560669,
      "learning_rate": 0.00019020060121794253,
      "loss": 3.089,
      "step": 11700
    },
    {
      "epoch": 0.5035723508651114,
      "eval_bleu": 25.55280878277353,
      "eval_gen_len": 27.375,
      "eval_loss": 2.8276987075805664,
      "eval_runtime": 58.5001,
      "eval_samples_per_second": 17.094,
      "eval_steps_per_second": 1.077,
      "step": 11700
    },
    {
      "epoch": 0.5040027545837996,
      "grad_norm": 0.8968342542648315,
      "learning_rate": 0.00019018053084968073,
      "loss": 3.0741,
      "step": 11710
    },
    {
      "epoch": 0.5044331583024877,
      "grad_norm": 0.943644642829895,
      "learning_rate": 0.00019016044101031148,
      "loss": 3.2161,
      "step": 11720
    },
    {
      "epoch": 0.5048635620211759,
      "grad_norm": 1.0669738054275513,
      "learning_rate": 0.00019014033170417242,
      "loss": 3.074,
      "step": 11730
    },
    {
      "epoch": 0.505293965739864,
      "grad_norm": 0.8933173418045044,
      "learning_rate": 0.00019012020293560547,
      "loss": 3.1524,
      "step": 11740
    },
    {
      "epoch": 0.5057243694585521,
      "grad_norm": 0.9344244003295898,
      "learning_rate": 0.0001901000547089566,
      "loss": 3.1798,
      "step": 11750
    },
    {
      "epoch": 0.5057243694585521,
      "eval_bleu": 25.722186270275376,
      "eval_gen_len": 27.485,
      "eval_loss": 2.8315114974975586,
      "eval_runtime": 59.0936,
      "eval_samples_per_second": 16.922,
      "eval_steps_per_second": 1.066,
      "step": 11750
    },
    {
      "epoch": 0.5061547731772402,
      "grad_norm": 0.8982609510421753,
      "learning_rate": 0.0001900798870285761,
      "loss": 3.0873,
      "step": 11760
    },
    {
      "epoch": 0.5065851768959284,
      "grad_norm": 0.8748562335968018,
      "learning_rate": 0.0001900596998988184,
      "loss": 3.0589,
      "step": 11770
    },
    {
      "epoch": 0.5070155806146165,
      "grad_norm": 0.9236019253730774,
      "learning_rate": 0.00019003949332404224,
      "loss": 3.1639,
      "step": 11780
    },
    {
      "epoch": 0.5074459843333047,
      "grad_norm": 0.898769199848175,
      "learning_rate": 0.00019001926730861034,
      "loss": 3.1456,
      "step": 11790
    },
    {
      "epoch": 0.5078763880519928,
      "grad_norm": 0.9371046423912048,
      "learning_rate": 0.00018999902185688988,
      "loss": 3.0405,
      "step": 11800
    },
    {
      "epoch": 0.5078763880519928,
      "eval_bleu": 26.34063075680123,
      "eval_gen_len": 27.37,
      "eval_loss": 2.8256187438964844,
      "eval_runtime": 57.9919,
      "eval_samples_per_second": 17.244,
      "eval_steps_per_second": 1.086,
      "step": 11800
    },
    {
      "epoch": 0.5083067917706809,
      "grad_norm": 0.8957638144493103,
      "learning_rate": 0.00018997875697325203,
      "loss": 2.9985,
      "step": 11810
    },
    {
      "epoch": 0.508737195489369,
      "grad_norm": 0.8802031874656677,
      "learning_rate": 0.00018995847266207224,
      "loss": 3.1397,
      "step": 11820
    },
    {
      "epoch": 0.5091675992080572,
      "grad_norm": 0.9657410979270935,
      "learning_rate": 0.00018993816892773019,
      "loss": 3.2105,
      "step": 11830
    },
    {
      "epoch": 0.5095980029267453,
      "grad_norm": 0.9267991781234741,
      "learning_rate": 0.00018991784577460961,
      "loss": 3.1603,
      "step": 11840
    },
    {
      "epoch": 0.5100284066454334,
      "grad_norm": 0.9436365962028503,
      "learning_rate": 0.00018989750320709867,
      "loss": 3.0306,
      "step": 11850
    },
    {
      "epoch": 0.5100284066454334,
      "eval_bleu": 26.336728861760676,
      "eval_gen_len": 27.325,
      "eval_loss": 2.8265912532806396,
      "eval_runtime": 58.2213,
      "eval_samples_per_second": 17.176,
      "eval_steps_per_second": 1.082,
      "step": 11850
    },
    {
      "epoch": 0.5104588103641216,
      "grad_norm": 0.9313218593597412,
      "learning_rate": 0.0001898771412295895,
      "loss": 3.1798,
      "step": 11860
    },
    {
      "epoch": 0.5108892140828096,
      "grad_norm": 0.7638897895812988,
      "learning_rate": 0.00018985675984647845,
      "loss": 3.1038,
      "step": 11870
    },
    {
      "epoch": 0.5113196178014978,
      "grad_norm": 0.7910961508750916,
      "learning_rate": 0.00018983635906216623,
      "loss": 3.0882,
      "step": 11880
    },
    {
      "epoch": 0.5117500215201859,
      "grad_norm": 0.8770956993103027,
      "learning_rate": 0.0001898159388810576,
      "loss": 3.1727,
      "step": 11890
    },
    {
      "epoch": 0.5121804252388741,
      "grad_norm": 0.8718986511230469,
      "learning_rate": 0.00018979549930756145,
      "loss": 3.0085,
      "step": 11900
    },
    {
      "epoch": 0.5121804252388741,
      "eval_bleu": 26.205647712274335,
      "eval_gen_len": 27.364,
      "eval_loss": 2.8303191661834717,
      "eval_runtime": 58.1847,
      "eval_samples_per_second": 17.187,
      "eval_steps_per_second": 1.083,
      "step": 11900
    },
    {
      "epoch": 0.5126108289575622,
      "grad_norm": 0.8814435601234436,
      "learning_rate": 0.00018977504034609102,
      "loss": 3.0039,
      "step": 11910
    },
    {
      "epoch": 0.5130412326762503,
      "grad_norm": 0.9450489282608032,
      "learning_rate": 0.00018975456200106362,
      "loss": 3.097,
      "step": 11920
    },
    {
      "epoch": 0.5134716363949384,
      "grad_norm": 0.7250097990036011,
      "learning_rate": 0.00018973406427690083,
      "loss": 3.1265,
      "step": 11930
    },
    {
      "epoch": 0.5139020401136266,
      "grad_norm": 0.8617983460426331,
      "learning_rate": 0.00018971354717802833,
      "loss": 3.113,
      "step": 11940
    },
    {
      "epoch": 0.5143324438323147,
      "grad_norm": 1.1131370067596436,
      "learning_rate": 0.000189693010708876,
      "loss": 3.2247,
      "step": 11950
    },
    {
      "epoch": 0.5143324438323147,
      "eval_bleu": 26.300065719578832,
      "eval_gen_len": 27.489,
      "eval_loss": 2.825481653213501,
      "eval_runtime": 58.318,
      "eval_samples_per_second": 17.147,
      "eval_steps_per_second": 1.08,
      "step": 11950
    },
    {
      "epoch": 0.5147628475510029,
      "grad_norm": 0.8058760762214661,
      "learning_rate": 0.00018967245487387798,
      "loss": 3.1719,
      "step": 11960
    },
    {
      "epoch": 0.515193251269691,
      "grad_norm": 1.026109218597412,
      "learning_rate": 0.00018965187967747246,
      "loss": 3.0756,
      "step": 11970
    },
    {
      "epoch": 0.5156236549883791,
      "grad_norm": 1.02372407913208,
      "learning_rate": 0.0001896312851241019,
      "loss": 3.1561,
      "step": 11980
    },
    {
      "epoch": 0.5160540587070672,
      "grad_norm": 0.8951746225357056,
      "learning_rate": 0.00018961067121821298,
      "loss": 3.1586,
      "step": 11990
    },
    {
      "epoch": 0.5164844624257554,
      "grad_norm": 0.9994496703147888,
      "learning_rate": 0.00018959003796425645,
      "loss": 3.2057,
      "step": 12000
    },
    {
      "epoch": 0.5164844624257554,
      "eval_bleu": 26.229197717228224,
      "eval_gen_len": 27.446,
      "eval_loss": 2.830399751663208,
      "eval_runtime": 58.0042,
      "eval_samples_per_second": 17.24,
      "eval_steps_per_second": 1.086,
      "step": 12000
    },
    {
      "epoch": 0.5169148661444435,
      "grad_norm": 0.8707733750343323,
      "learning_rate": 0.0001895693853666873,
      "loss": 3.1206,
      "step": 12010
    },
    {
      "epoch": 0.5173452698631316,
      "grad_norm": 1.0110235214233398,
      "learning_rate": 0.00018954871342996468,
      "loss": 3.1107,
      "step": 12020
    },
    {
      "epoch": 0.5177756735818198,
      "grad_norm": 0.8498871326446533,
      "learning_rate": 0.0001895280221585519,
      "loss": 3.0322,
      "step": 12030
    },
    {
      "epoch": 0.5182060773005078,
      "grad_norm": 0.8743544220924377,
      "learning_rate": 0.00018950731155691655,
      "loss": 3.0631,
      "step": 12040
    },
    {
      "epoch": 0.518636481019196,
      "grad_norm": 0.9525520205497742,
      "learning_rate": 0.00018948658162953018,
      "loss": 3.0839,
      "step": 12050
    },
    {
      "epoch": 0.518636481019196,
      "eval_bleu": 26.444573459385516,
      "eval_gen_len": 27.381,
      "eval_loss": 2.8246920108795166,
      "eval_runtime": 58.1009,
      "eval_samples_per_second": 17.211,
      "eval_steps_per_second": 1.084,
      "step": 12050
    },
    {
      "epoch": 0.5190668847378841,
      "grad_norm": 1.0141243934631348,
      "learning_rate": 0.00018946583238086876,
      "loss": 3.1223,
      "step": 12060
    },
    {
      "epoch": 0.5194972884565723,
      "grad_norm": 0.8339999914169312,
      "learning_rate": 0.00018944506381541224,
      "loss": 3.0821,
      "step": 12070
    },
    {
      "epoch": 0.5199276921752604,
      "grad_norm": 0.840009331703186,
      "learning_rate": 0.00018942427593764488,
      "loss": 3.2103,
      "step": 12080
    },
    {
      "epoch": 0.5203580958939485,
      "grad_norm": 0.9280726313591003,
      "learning_rate": 0.00018940346875205496,
      "loss": 3.0282,
      "step": 12090
    },
    {
      "epoch": 0.5207884996126366,
      "grad_norm": 0.9483537077903748,
      "learning_rate": 0.00018938264226313502,
      "loss": 3.155,
      "step": 12100
    },
    {
      "epoch": 0.5207884996126366,
      "eval_bleu": 26.199775082183248,
      "eval_gen_len": 27.523,
      "eval_loss": 2.8306922912597656,
      "eval_runtime": 58.6495,
      "eval_samples_per_second": 17.05,
      "eval_steps_per_second": 1.074,
      "step": 12100
    },
    {
      "epoch": 0.5212189033313248,
      "grad_norm": 0.9449387788772583,
      "learning_rate": 0.00018936179647538183,
      "loss": 3.1274,
      "step": 12110
    },
    {
      "epoch": 0.5216493070500129,
      "grad_norm": 0.9904643297195435,
      "learning_rate": 0.0001893409313932962,
      "loss": 3.1188,
      "step": 12120
    },
    {
      "epoch": 0.5220797107687011,
      "grad_norm": 0.9195065498352051,
      "learning_rate": 0.00018932004702138322,
      "loss": 3.0633,
      "step": 12130
    },
    {
      "epoch": 0.5225101144873892,
      "grad_norm": 0.9384883642196655,
      "learning_rate": 0.000189299143364152,
      "loss": 3.1652,
      "step": 12140
    },
    {
      "epoch": 0.5229405182060773,
      "grad_norm": 0.9796660542488098,
      "learning_rate": 0.000189278220426116,
      "loss": 3.1073,
      "step": 12150
    },
    {
      "epoch": 0.5229405182060773,
      "eval_bleu": 26.19732059468156,
      "eval_gen_len": 27.356,
      "eval_loss": 2.823209762573242,
      "eval_runtime": 58.1158,
      "eval_samples_per_second": 17.207,
      "eval_steps_per_second": 1.084,
      "step": 12150
    },
    {
      "epoch": 0.5233709219247654,
      "grad_norm": 0.9744898080825806,
      "learning_rate": 0.00018925727821179265,
      "loss": 3.1826,
      "step": 12160
    },
    {
      "epoch": 0.5238013256434536,
      "grad_norm": 0.9800271987915039,
      "learning_rate": 0.00018923631672570373,
      "loss": 3.0834,
      "step": 12170
    },
    {
      "epoch": 0.5242317293621417,
      "grad_norm": 0.8589775562286377,
      "learning_rate": 0.00018921533597237499,
      "loss": 3.1004,
      "step": 12180
    },
    {
      "epoch": 0.5246621330808299,
      "grad_norm": 0.8328539729118347,
      "learning_rate": 0.00018919433595633654,
      "loss": 3.0897,
      "step": 12190
    },
    {
      "epoch": 0.525092536799518,
      "grad_norm": 0.9037803411483765,
      "learning_rate": 0.00018917331668212245,
      "loss": 3.0919,
      "step": 12200
    },
    {
      "epoch": 0.525092536799518,
      "eval_bleu": 25.8675624782033,
      "eval_gen_len": 27.389,
      "eval_loss": 2.821706533432007,
      "eval_runtime": 58.0468,
      "eval_samples_per_second": 17.227,
      "eval_steps_per_second": 1.085,
      "step": 12200
    },
    {
      "epoch": 0.525522940518206,
      "grad_norm": 0.9019142389297485,
      "learning_rate": 0.00018915227815427112,
      "loss": 3.098,
      "step": 12210
    },
    {
      "epoch": 0.5259533442368942,
      "grad_norm": 1.141721487045288,
      "learning_rate": 0.000189131220377325,
      "loss": 3.0966,
      "step": 12220
    },
    {
      "epoch": 0.5263837479555823,
      "grad_norm": 0.8242177963256836,
      "learning_rate": 0.00018911014335583072,
      "loss": 3.099,
      "step": 12230
    },
    {
      "epoch": 0.5268141516742705,
      "grad_norm": 0.8202824592590332,
      "learning_rate": 0.00018908904709433907,
      "loss": 3.0649,
      "step": 12240
    },
    {
      "epoch": 0.5272445553929586,
      "grad_norm": 0.8523191809654236,
      "learning_rate": 0.00018906793159740502,
      "loss": 3.1904,
      "step": 12250
    },
    {
      "epoch": 0.5272445553929586,
      "eval_bleu": 26.792366127360243,
      "eval_gen_len": 27.528,
      "eval_loss": 2.822723865509033,
      "eval_runtime": 57.9887,
      "eval_samples_per_second": 17.245,
      "eval_steps_per_second": 1.086,
      "step": 12250
    },
    {
      "epoch": 0.5276749591116467,
      "grad_norm": 0.8945109844207764,
      "learning_rate": 0.00018904679686958766,
      "loss": 3.1482,
      "step": 12260
    },
    {
      "epoch": 0.5281053628303348,
      "grad_norm": 1.0250366926193237,
      "learning_rate": 0.00018902564291545026,
      "loss": 3.1519,
      "step": 12270
    },
    {
      "epoch": 0.528535766549023,
      "grad_norm": 0.8989444971084595,
      "learning_rate": 0.00018900446973956018,
      "loss": 3.0069,
      "step": 12280
    },
    {
      "epoch": 0.5289661702677111,
      "grad_norm": 0.8802327513694763,
      "learning_rate": 0.00018898327734648903,
      "loss": 3.0019,
      "step": 12290
    },
    {
      "epoch": 0.5293965739863993,
      "grad_norm": 0.8284242749214172,
      "learning_rate": 0.0001889620657408125,
      "loss": 3.1026,
      "step": 12300
    },
    {
      "epoch": 0.5293965739863993,
      "eval_bleu": 26.236155725313907,
      "eval_gen_len": 27.272,
      "eval_loss": 2.8221442699432373,
      "eval_runtime": 58.2769,
      "eval_samples_per_second": 17.159,
      "eval_steps_per_second": 1.081,
      "step": 12300
    },
    {
      "epoch": 0.5298269777050874,
      "grad_norm": 0.9686641693115234,
      "learning_rate": 0.00018894083492711038,
      "loss": 3.0829,
      "step": 12310
    },
    {
      "epoch": 0.5302573814237755,
      "grad_norm": 0.8912843465805054,
      "learning_rate": 0.00018891958490996672,
      "loss": 3.2405,
      "step": 12320
    },
    {
      "epoch": 0.5306877851424636,
      "grad_norm": 0.9222985506057739,
      "learning_rate": 0.0001888983156939697,
      "loss": 3.0237,
      "step": 12330
    },
    {
      "epoch": 0.5311181888611518,
      "grad_norm": 0.91606605052948,
      "learning_rate": 0.00018887702728371153,
      "loss": 3.2874,
      "step": 12340
    },
    {
      "epoch": 0.5315485925798399,
      "grad_norm": 0.8927385807037354,
      "learning_rate": 0.0001888557196837887,
      "loss": 3.0617,
      "step": 12350
    },
    {
      "epoch": 0.5315485925798399,
      "eval_bleu": 25.944292653611058,
      "eval_gen_len": 27.422,
      "eval_loss": 2.8231916427612305,
      "eval_runtime": 57.9562,
      "eval_samples_per_second": 17.254,
      "eval_steps_per_second": 1.087,
      "step": 12350
    },
    {
      "epoch": 0.5319789962985281,
      "grad_norm": 1.0312936305999756,
      "learning_rate": 0.0001888343928988018,
      "loss": 3.1547,
      "step": 12360
    },
    {
      "epoch": 0.5324094000172162,
      "grad_norm": 0.9984005093574524,
      "learning_rate": 0.0001888130469333555,
      "loss": 3.0641,
      "step": 12370
    },
    {
      "epoch": 0.5328398037359042,
      "grad_norm": 1.0514614582061768,
      "learning_rate": 0.00018879168179205868,
      "loss": 3.1089,
      "step": 12380
    },
    {
      "epoch": 0.5332702074545924,
      "grad_norm": 0.9385287761688232,
      "learning_rate": 0.00018877029747952438,
      "loss": 3.1771,
      "step": 12390
    },
    {
      "epoch": 0.5337006111732805,
      "grad_norm": 0.8978572487831116,
      "learning_rate": 0.00018874889400036967,
      "loss": 3.0916,
      "step": 12400
    },
    {
      "epoch": 0.5337006111732805,
      "eval_bleu": 26.484946790941155,
      "eval_gen_len": 27.457,
      "eval_loss": 2.8202011585235596,
      "eval_runtime": 57.6517,
      "eval_samples_per_second": 17.346,
      "eval_steps_per_second": 1.093,
      "step": 12400
    },
    {
      "epoch": 0.5341310148919687,
      "grad_norm": 1.0214152336120605,
      "learning_rate": 0.0001887274713592159,
      "loss": 3.2649,
      "step": 12410
    },
    {
      "epoch": 0.5345614186106568,
      "grad_norm": 0.9242154955863953,
      "learning_rate": 0.00018870602956068844,
      "loss": 3.1353,
      "step": 12420
    },
    {
      "epoch": 0.534991822329345,
      "grad_norm": 0.9507319927215576,
      "learning_rate": 0.00018868456860941685,
      "loss": 3.0587,
      "step": 12430
    },
    {
      "epoch": 0.535422226048033,
      "grad_norm": 0.9085583686828613,
      "learning_rate": 0.00018866308851003485,
      "loss": 3.0179,
      "step": 12440
    },
    {
      "epoch": 0.5358526297667212,
      "grad_norm": 0.9965799450874329,
      "learning_rate": 0.00018864158926718022,
      "loss": 3.0649,
      "step": 12450
    },
    {
      "epoch": 0.5358526297667212,
      "eval_bleu": 26.030954320184062,
      "eval_gen_len": 27.364,
      "eval_loss": 2.822396993637085,
      "eval_runtime": 57.4984,
      "eval_samples_per_second": 17.392,
      "eval_steps_per_second": 1.096,
      "step": 12450
    },
    {
      "epoch": 0.5362830334854093,
      "grad_norm": 0.8533308506011963,
      "learning_rate": 0.00018862007088549495,
      "loss": 3.1663,
      "step": 12460
    },
    {
      "epoch": 0.5367134372040975,
      "grad_norm": 0.9360208511352539,
      "learning_rate": 0.0001885985333696251,
      "loss": 3.1102,
      "step": 12470
    },
    {
      "epoch": 0.5371438409227856,
      "grad_norm": 1.0173356533050537,
      "learning_rate": 0.00018857697672422093,
      "loss": 3.1081,
      "step": 12480
    },
    {
      "epoch": 0.5375742446414737,
      "grad_norm": 0.8420482873916626,
      "learning_rate": 0.00018855540095393675,
      "loss": 3.0279,
      "step": 12490
    },
    {
      "epoch": 0.5380046483601618,
      "grad_norm": 0.9027042984962463,
      "learning_rate": 0.00018853380606343104,
      "loss": 3.2093,
      "step": 12500
    },
    {
      "epoch": 0.5380046483601618,
      "eval_bleu": 25.476618020732715,
      "eval_gen_len": 27.508,
      "eval_loss": 2.821779489517212,
      "eval_runtime": 58.2363,
      "eval_samples_per_second": 17.171,
      "eval_steps_per_second": 1.082,
      "step": 12500
    },
    {
      "epoch": 0.53843505207885,
      "grad_norm": 0.9863025546073914,
      "learning_rate": 0.00018851219205736643,
      "loss": 3.0439,
      "step": 12510
    },
    {
      "epoch": 0.5388654557975381,
      "grad_norm": 1.0256508588790894,
      "learning_rate": 0.00018849055894040967,
      "loss": 3.1223,
      "step": 12520
    },
    {
      "epoch": 0.5392958595162263,
      "grad_norm": 0.9462162256240845,
      "learning_rate": 0.00018846890671723156,
      "loss": 3.1255,
      "step": 12530
    },
    {
      "epoch": 0.5397262632349143,
      "grad_norm": 0.9250925183296204,
      "learning_rate": 0.00018844723539250712,
      "loss": 3.1366,
      "step": 12540
    },
    {
      "epoch": 0.5401566669536024,
      "grad_norm": 0.9742225408554077,
      "learning_rate": 0.0001884255449709155,
      "loss": 3.3229,
      "step": 12550
    },
    {
      "epoch": 0.5401566669536024,
      "eval_bleu": 25.871542898827045,
      "eval_gen_len": 27.395,
      "eval_loss": 2.8177127838134766,
      "eval_runtime": 59.7013,
      "eval_samples_per_second": 16.75,
      "eval_steps_per_second": 1.055,
      "step": 12550
    },
    {
      "epoch": 0.5405870706722906,
      "grad_norm": 0.853975236415863,
      "learning_rate": 0.00018840383545713988,
      "loss": 3.1236,
      "step": 12560
    },
    {
      "epoch": 0.5410174743909787,
      "grad_norm": 0.9623641967773438,
      "learning_rate": 0.00018838210685586765,
      "loss": 3.1842,
      "step": 12570
    },
    {
      "epoch": 0.5414478781096669,
      "grad_norm": 0.8780213594436646,
      "learning_rate": 0.00018836035917179026,
      "loss": 3.1089,
      "step": 12580
    },
    {
      "epoch": 0.541878281828355,
      "grad_norm": 0.9868690371513367,
      "learning_rate": 0.00018833859240960333,
      "loss": 3.0865,
      "step": 12590
    },
    {
      "epoch": 0.5423086855470431,
      "grad_norm": 0.9673725366592407,
      "learning_rate": 0.00018831680657400654,
      "loss": 3.1334,
      "step": 12600
    },
    {
      "epoch": 0.5423086855470431,
      "eval_bleu": 26.425616663114717,
      "eval_gen_len": 27.42,
      "eval_loss": 2.819077730178833,
      "eval_runtime": 58.2448,
      "eval_samples_per_second": 17.169,
      "eval_steps_per_second": 1.082,
      "step": 12600
    },
    {
      "epoch": 0.5427390892657312,
      "grad_norm": 0.8407650589942932,
      "learning_rate": 0.00018829500166970376,
      "loss": 3.1046,
      "step": 12610
    },
    {
      "epoch": 0.5431694929844194,
      "grad_norm": 0.9888479113578796,
      "learning_rate": 0.00018827317770140297,
      "loss": 3.1373,
      "step": 12620
    },
    {
      "epoch": 0.5435998967031075,
      "grad_norm": 0.95953768491745,
      "learning_rate": 0.0001882513346738162,
      "loss": 3.1514,
      "step": 12630
    },
    {
      "epoch": 0.5440303004217957,
      "grad_norm": 0.9698238968849182,
      "learning_rate": 0.00018822947259165962,
      "loss": 3.1042,
      "step": 12640
    },
    {
      "epoch": 0.5444607041404838,
      "grad_norm": 0.9510096907615662,
      "learning_rate": 0.00018820759145965355,
      "loss": 3.1122,
      "step": 12650
    },
    {
      "epoch": 0.5444607041404838,
      "eval_bleu": 26.252286892812858,
      "eval_gen_len": 27.41,
      "eval_loss": 2.8204238414764404,
      "eval_runtime": 58.1163,
      "eval_samples_per_second": 17.207,
      "eval_steps_per_second": 1.084,
      "step": 12650
    },
    {
      "epoch": 0.5448911078591719,
      "grad_norm": 0.9721822738647461,
      "learning_rate": 0.00018818569128252236,
      "loss": 3.2584,
      "step": 12660
    },
    {
      "epoch": 0.54532151157786,
      "grad_norm": 0.8891068696975708,
      "learning_rate": 0.00018816377206499465,
      "loss": 3.132,
      "step": 12670
    },
    {
      "epoch": 0.5457519152965482,
      "grad_norm": 0.8297709822654724,
      "learning_rate": 0.00018814183381180298,
      "loss": 3.0255,
      "step": 12680
    },
    {
      "epoch": 0.5461823190152363,
      "grad_norm": 0.895761251449585,
      "learning_rate": 0.00018811987652768414,
      "loss": 3.2121,
      "step": 12690
    },
    {
      "epoch": 0.5466127227339245,
      "grad_norm": 0.8822512030601501,
      "learning_rate": 0.000188097900217379,
      "loss": 3.0647,
      "step": 12700
    },
    {
      "epoch": 0.5466127227339245,
      "eval_bleu": 26.31025019937887,
      "eval_gen_len": 27.336,
      "eval_loss": 2.8215761184692383,
      "eval_runtime": 58.2958,
      "eval_samples_per_second": 17.154,
      "eval_steps_per_second": 1.081,
      "step": 12700
    },
    {
      "epoch": 0.5470431264526125,
      "grad_norm": 0.8688364028930664,
      "learning_rate": 0.00018807590488563244,
      "loss": 3.0834,
      "step": 12710
    },
    {
      "epoch": 0.5474735301713006,
      "grad_norm": 0.9452201724052429,
      "learning_rate": 0.0001880538905371936,
      "loss": 3.1418,
      "step": 12720
    },
    {
      "epoch": 0.5479039338899888,
      "grad_norm": 0.9219996333122253,
      "learning_rate": 0.00018803185717681563,
      "loss": 3.2086,
      "step": 12730
    },
    {
      "epoch": 0.5483343376086769,
      "grad_norm": 1.0265486240386963,
      "learning_rate": 0.00018800980480925583,
      "loss": 3.1742,
      "step": 12740
    },
    {
      "epoch": 0.5487647413273651,
      "grad_norm": 0.9222385287284851,
      "learning_rate": 0.00018798773343927554,
      "loss": 3.1663,
      "step": 12750
    },
    {
      "epoch": 0.5487647413273651,
      "eval_bleu": 25.56575456263818,
      "eval_gen_len": 27.325,
      "eval_loss": 2.824112892150879,
      "eval_runtime": 57.7529,
      "eval_samples_per_second": 17.315,
      "eval_steps_per_second": 1.091,
      "step": 12750
    },
    {
      "epoch": 0.5491951450460532,
      "grad_norm": 0.9504430294036865,
      "learning_rate": 0.0001879656430716403,
      "loss": 3.0807,
      "step": 12760
    },
    {
      "epoch": 0.5496255487647413,
      "grad_norm": 0.7722640037536621,
      "learning_rate": 0.0001879435337111196,
      "loss": 3.0207,
      "step": 12770
    },
    {
      "epoch": 0.5500559524834294,
      "grad_norm": 0.8234261870384216,
      "learning_rate": 0.00018792140536248725,
      "loss": 3.1247,
      "step": 12780
    },
    {
      "epoch": 0.5504863562021176,
      "grad_norm": 0.9215700030326843,
      "learning_rate": 0.00018789925803052097,
      "loss": 3.101,
      "step": 12790
    },
    {
      "epoch": 0.5509167599208057,
      "grad_norm": 0.8496492505073547,
      "learning_rate": 0.00018787709172000266,
      "loss": 3.0852,
      "step": 12800
    },
    {
      "epoch": 0.5509167599208057,
      "eval_bleu": 25.964817457412217,
      "eval_gen_len": 27.448,
      "eval_loss": 2.82208251953125,
      "eval_runtime": 58.3618,
      "eval_samples_per_second": 17.134,
      "eval_steps_per_second": 1.079,
      "step": 12800
    },
    {
      "epoch": 0.5513471636394939,
      "grad_norm": 0.9726148247718811,
      "learning_rate": 0.00018785490643571828,
      "loss": 3.1425,
      "step": 12810
    },
    {
      "epoch": 0.551777567358182,
      "grad_norm": 0.947726845741272,
      "learning_rate": 0.00018783270218245796,
      "loss": 3.1654,
      "step": 12820
    },
    {
      "epoch": 0.5522079710768701,
      "grad_norm": 0.9159807562828064,
      "learning_rate": 0.00018781047896501585,
      "loss": 3.1893,
      "step": 12830
    },
    {
      "epoch": 0.5526383747955582,
      "grad_norm": 0.9972255229949951,
      "learning_rate": 0.0001877882367881902,
      "loss": 3.164,
      "step": 12840
    },
    {
      "epoch": 0.5530687785142464,
      "grad_norm": 0.8890758752822876,
      "learning_rate": 0.00018776597565678342,
      "loss": 3.1678,
      "step": 12850
    },
    {
      "epoch": 0.5530687785142464,
      "eval_bleu": 26.1590169228202,
      "eval_gen_len": 27.404,
      "eval_loss": 2.821408987045288,
      "eval_runtime": 57.5409,
      "eval_samples_per_second": 17.379,
      "eval_steps_per_second": 1.095,
      "step": 12850
    },
    {
      "epoch": 0.5534991822329345,
      "grad_norm": 0.8428252935409546,
      "learning_rate": 0.00018774369557560195,
      "loss": 3.1519,
      "step": 12860
    },
    {
      "epoch": 0.5539295859516227,
      "grad_norm": 1.0111864805221558,
      "learning_rate": 0.00018772139654945632,
      "loss": 3.1671,
      "step": 12870
    },
    {
      "epoch": 0.5543599896703107,
      "grad_norm": 1.1220053434371948,
      "learning_rate": 0.00018769907858316116,
      "loss": 3.1721,
      "step": 12880
    },
    {
      "epoch": 0.5547903933889988,
      "grad_norm": 0.9699562788009644,
      "learning_rate": 0.00018767674168153526,
      "loss": 3.1881,
      "step": 12890
    },
    {
      "epoch": 0.555220797107687,
      "grad_norm": 0.9419149160385132,
      "learning_rate": 0.00018765438584940138,
      "loss": 3.2092,
      "step": 12900
    },
    {
      "epoch": 0.555220797107687,
      "eval_bleu": 26.83946581657152,
      "eval_gen_len": 27.45,
      "eval_loss": 2.8164474964141846,
      "eval_runtime": 58.0374,
      "eval_samples_per_second": 17.23,
      "eval_steps_per_second": 1.086,
      "step": 12900
    },
    {
      "epoch": 0.5556512008263751,
      "grad_norm": 0.8256968259811401,
      "learning_rate": 0.00018763201109158647,
      "loss": 3.0975,
      "step": 12910
    },
    {
      "epoch": 0.5560816045450633,
      "grad_norm": 0.8537541627883911,
      "learning_rate": 0.00018760961741292147,
      "loss": 3.1251,
      "step": 12920
    },
    {
      "epoch": 0.5565120082637514,
      "grad_norm": 1.0022215843200684,
      "learning_rate": 0.0001875872048182415,
      "loss": 3.1157,
      "step": 12930
    },
    {
      "epoch": 0.5569424119824395,
      "grad_norm": 0.965076208114624,
      "learning_rate": 0.00018756477331238568,
      "loss": 3.1647,
      "step": 12940
    },
    {
      "epoch": 0.5573728157011276,
      "grad_norm": 0.8736220598220825,
      "learning_rate": 0.00018754232290019724,
      "loss": 3.1131,
      "step": 12950
    },
    {
      "epoch": 0.5573728157011276,
      "eval_bleu": 26.503893878107558,
      "eval_gen_len": 27.46,
      "eval_loss": 2.8203182220458984,
      "eval_runtime": 57.9099,
      "eval_samples_per_second": 17.268,
      "eval_steps_per_second": 1.088,
      "step": 12950
    },
    {
      "epoch": 0.5578032194198158,
      "grad_norm": 0.9349443912506104,
      "learning_rate": 0.0001875198535865236,
      "loss": 2.9844,
      "step": 12960
    },
    {
      "epoch": 0.5582336231385039,
      "grad_norm": 0.9424708485603333,
      "learning_rate": 0.00018749736537621608,
      "loss": 3.1516,
      "step": 12970
    },
    {
      "epoch": 0.5586640268571921,
      "grad_norm": 0.8577423095703125,
      "learning_rate": 0.00018747485827413018,
      "loss": 3.0632,
      "step": 12980
    },
    {
      "epoch": 0.5590944305758802,
      "grad_norm": 0.930292546749115,
      "learning_rate": 0.00018745233228512547,
      "loss": 3.1231,
      "step": 12990
    },
    {
      "epoch": 0.5595248342945683,
      "grad_norm": 0.8696532845497131,
      "learning_rate": 0.00018742978741406564,
      "loss": 3.1294,
      "step": 13000
    },
    {
      "epoch": 0.5595248342945683,
      "eval_bleu": 26.76048228541934,
      "eval_gen_len": 27.437,
      "eval_loss": 2.8206167221069336,
      "eval_runtime": 57.8936,
      "eval_samples_per_second": 17.273,
      "eval_steps_per_second": 1.088,
      "step": 13000
    },
    {
      "epoch": 0.5599552380132564,
      "grad_norm": 0.9862940907478333,
      "learning_rate": 0.00018740722366581837,
      "loss": 3.1904,
      "step": 13010
    },
    {
      "epoch": 0.5603856417319446,
      "grad_norm": 0.9295531511306763,
      "learning_rate": 0.00018738464104525545,
      "loss": 3.1509,
      "step": 13020
    },
    {
      "epoch": 0.5608160454506327,
      "grad_norm": 0.9679827690124512,
      "learning_rate": 0.00018736203955725274,
      "loss": 2.9893,
      "step": 13030
    },
    {
      "epoch": 0.5612464491693209,
      "grad_norm": 0.8657132387161255,
      "learning_rate": 0.00018733941920669024,
      "loss": 3.1205,
      "step": 13040
    },
    {
      "epoch": 0.561676852888009,
      "grad_norm": 0.8467110991477966,
      "learning_rate": 0.00018731677999845188,
      "loss": 3.0852,
      "step": 13050
    },
    {
      "epoch": 0.561676852888009,
      "eval_bleu": 26.461021945891943,
      "eval_gen_len": 27.405,
      "eval_loss": 2.820571184158325,
      "eval_runtime": 58.3513,
      "eval_samples_per_second": 17.138,
      "eval_steps_per_second": 1.08,
      "step": 13050
    },
    {
      "epoch": 0.5621072566066971,
      "grad_norm": 0.9133071303367615,
      "learning_rate": 0.00018729412193742583,
      "loss": 3.0458,
      "step": 13060
    },
    {
      "epoch": 0.5625376603253852,
      "grad_norm": 1.06170654296875,
      "learning_rate": 0.0001872714450285042,
      "loss": 3.1318,
      "step": 13070
    },
    {
      "epoch": 0.5629680640440733,
      "grad_norm": 0.9272535443305969,
      "learning_rate": 0.00018724874927658326,
      "loss": 3.1667,
      "step": 13080
    },
    {
      "epoch": 0.5633984677627615,
      "grad_norm": 0.8997225761413574,
      "learning_rate": 0.0001872260346865633,
      "loss": 3.0822,
      "step": 13090
    },
    {
      "epoch": 0.5638288714814496,
      "grad_norm": 0.9719956517219543,
      "learning_rate": 0.00018720330126334865,
      "loss": 3.0919,
      "step": 13100
    },
    {
      "epoch": 0.5638288714814496,
      "eval_bleu": 26.71255480189474,
      "eval_gen_len": 27.39,
      "eval_loss": 2.8170053958892822,
      "eval_runtime": 57.6759,
      "eval_samples_per_second": 17.338,
      "eval_steps_per_second": 1.092,
      "step": 13100
    },
    {
      "epoch": 0.5642592752001377,
      "grad_norm": 0.9987194538116455,
      "learning_rate": 0.00018718054901184776,
      "loss": 3.1268,
      "step": 13110
    },
    {
      "epoch": 0.5646896789188258,
      "grad_norm": 1.021852970123291,
      "learning_rate": 0.00018715777793697314,
      "loss": 3.1225,
      "step": 13120
    },
    {
      "epoch": 0.565120082637514,
      "grad_norm": 0.8941965699195862,
      "learning_rate": 0.0001871349880436413,
      "loss": 3.0527,
      "step": 13130
    },
    {
      "epoch": 0.5655504863562021,
      "grad_norm": 0.9380699396133423,
      "learning_rate": 0.00018711217933677296,
      "loss": 3.1087,
      "step": 13140
    },
    {
      "epoch": 0.5659808900748903,
      "grad_norm": 0.8930032253265381,
      "learning_rate": 0.00018708935182129273,
      "loss": 3.2576,
      "step": 13150
    },
    {
      "epoch": 0.5659808900748903,
      "eval_bleu": 25.906510117870106,
      "eval_gen_len": 27.273,
      "eval_loss": 2.8234360218048096,
      "eval_runtime": 58.2611,
      "eval_samples_per_second": 17.164,
      "eval_steps_per_second": 1.081,
      "step": 13150
    },
    {
      "epoch": 0.5664112937935784,
      "grad_norm": 0.8988800048828125,
      "learning_rate": 0.00018706650550212936,
      "loss": 3.0886,
      "step": 13160
    },
    {
      "epoch": 0.5668416975122665,
      "grad_norm": 1.0733044147491455,
      "learning_rate": 0.0001870436403842157,
      "loss": 3.2445,
      "step": 13170
    },
    {
      "epoch": 0.5672721012309546,
      "grad_norm": 0.8983640074729919,
      "learning_rate": 0.00018702075647248853,
      "loss": 3.0374,
      "step": 13180
    },
    {
      "epoch": 0.5677025049496428,
      "grad_norm": 0.9095431566238403,
      "learning_rate": 0.00018699785377188888,
      "loss": 3.1644,
      "step": 13190
    },
    {
      "epoch": 0.5681329086683309,
      "grad_norm": 0.9020195007324219,
      "learning_rate": 0.00018697493228736167,
      "loss": 3.0603,
      "step": 13200
    },
    {
      "epoch": 0.5681329086683309,
      "eval_bleu": 26.186167673808352,
      "eval_gen_len": 27.343,
      "eval_loss": 2.824420213699341,
      "eval_runtime": 57.937,
      "eval_samples_per_second": 17.26,
      "eval_steps_per_second": 1.087,
      "step": 13200
    },
    {
      "epoch": 0.5685633123870191,
      "grad_norm": 0.830683708190918,
      "learning_rate": 0.00018695199202385597,
      "loss": 3.1049,
      "step": 13210
    },
    {
      "epoch": 0.5689937161057071,
      "grad_norm": 1.0049424171447754,
      "learning_rate": 0.00018692903298632484,
      "loss": 3.0705,
      "step": 13220
    },
    {
      "epoch": 0.5694241198243953,
      "grad_norm": 0.9430285096168518,
      "learning_rate": 0.0001869060551797254,
      "loss": 3.0794,
      "step": 13230
    },
    {
      "epoch": 0.5698545235430834,
      "grad_norm": 0.8599889278411865,
      "learning_rate": 0.0001868830586090189,
      "loss": 3.0247,
      "step": 13240
    },
    {
      "epoch": 0.5702849272617715,
      "grad_norm": 0.8678902387619019,
      "learning_rate": 0.00018686004327917054,
      "loss": 3.1833,
      "step": 13250
    },
    {
      "epoch": 0.5702849272617715,
      "eval_bleu": 26.79974478461847,
      "eval_gen_len": 27.5,
      "eval_loss": 2.8208725452423096,
      "eval_runtime": 58.0872,
      "eval_samples_per_second": 17.216,
      "eval_steps_per_second": 1.085,
      "step": 13250
    },
    {
      "epoch": 0.5707153309804597,
      "grad_norm": 0.8786870837211609,
      "learning_rate": 0.0001868370091951497,
      "loss": 3.0238,
      "step": 13260
    },
    {
      "epoch": 0.5711457346991478,
      "grad_norm": 0.7964017391204834,
      "learning_rate": 0.00018681395636192962,
      "loss": 3.2367,
      "step": 13270
    },
    {
      "epoch": 0.5715761384178359,
      "grad_norm": 0.9035767316818237,
      "learning_rate": 0.00018679088478448777,
      "loss": 3.1518,
      "step": 13280
    },
    {
      "epoch": 0.572006542136524,
      "grad_norm": 0.9823068976402283,
      "learning_rate": 0.00018676779446780557,
      "loss": 3.1122,
      "step": 13290
    },
    {
      "epoch": 0.5724369458552122,
      "grad_norm": 0.9081305265426636,
      "learning_rate": 0.0001867446854168685,
      "loss": 3.1395,
      "step": 13300
    },
    {
      "epoch": 0.5724369458552122,
      "eval_bleu": 26.392430385339686,
      "eval_gen_len": 27.433,
      "eval_loss": 2.821549415588379,
      "eval_runtime": 58.2454,
      "eval_samples_per_second": 17.169,
      "eval_steps_per_second": 1.082,
      "step": 13300
    },
    {
      "epoch": 0.5728673495739003,
      "grad_norm": 0.966876745223999,
      "learning_rate": 0.00018672155763666614,
      "loss": 3.0793,
      "step": 13310
    },
    {
      "epoch": 0.5732977532925885,
      "grad_norm": 0.876397430896759,
      "learning_rate": 0.00018669841113219196,
      "loss": 3.0506,
      "step": 13320
    },
    {
      "epoch": 0.5737281570112766,
      "grad_norm": 0.9824056029319763,
      "learning_rate": 0.00018667524590844372,
      "loss": 3.185,
      "step": 13330
    },
    {
      "epoch": 0.5741585607299647,
      "grad_norm": 0.9089789390563965,
      "learning_rate": 0.000186652061970423,
      "loss": 3.1051,
      "step": 13340
    },
    {
      "epoch": 0.5745889644486528,
      "grad_norm": 1.0642317533493042,
      "learning_rate": 0.0001866288593231355,
      "loss": 3.0736,
      "step": 13350
    },
    {
      "epoch": 0.5745889644486528,
      "eval_bleu": 26.630070330708126,
      "eval_gen_len": 27.545,
      "eval_loss": 2.817291259765625,
      "eval_runtime": 59.0641,
      "eval_samples_per_second": 16.931,
      "eval_steps_per_second": 1.067,
      "step": 13350
    },
    {
      "epoch": 0.575019368167341,
      "grad_norm": 0.9583277106285095,
      "learning_rate": 0.000186605637971591,
      "loss": 3.1048,
      "step": 13360
    },
    {
      "epoch": 0.5754497718860291,
      "grad_norm": 0.8950944542884827,
      "learning_rate": 0.00018658239792080327,
      "loss": 3.1136,
      "step": 13370
    },
    {
      "epoch": 0.5758801756047173,
      "grad_norm": 0.9051192998886108,
      "learning_rate": 0.00018655913917579007,
      "loss": 3.0892,
      "step": 13380
    },
    {
      "epoch": 0.5763105793234053,
      "grad_norm": 0.9093227982521057,
      "learning_rate": 0.00018653586174157332,
      "loss": 3.0662,
      "step": 13390
    },
    {
      "epoch": 0.5767409830420935,
      "grad_norm": 0.8752075433731079,
      "learning_rate": 0.00018651256562317894,
      "loss": 3.1674,
      "step": 13400
    },
    {
      "epoch": 0.5767409830420935,
      "eval_bleu": 26.080334558122797,
      "eval_gen_len": 27.395,
      "eval_loss": 2.8232369422912598,
      "eval_runtime": 58.2908,
      "eval_samples_per_second": 17.155,
      "eval_steps_per_second": 1.081,
      "step": 13400
    },
    {
      "epoch": 0.5771713867607816,
      "grad_norm": 0.9570127129554749,
      "learning_rate": 0.0001864892508256368,
      "loss": 3.0964,
      "step": 13410
    },
    {
      "epoch": 0.5776017904794697,
      "grad_norm": 0.8579843640327454,
      "learning_rate": 0.00018646591735398083,
      "loss": 3.157,
      "step": 13420
    },
    {
      "epoch": 0.5780321941981579,
      "grad_norm": 0.9511250257492065,
      "learning_rate": 0.00018644256521324905,
      "loss": 3.1262,
      "step": 13430
    },
    {
      "epoch": 0.578462597916846,
      "grad_norm": 0.9033975005149841,
      "learning_rate": 0.0001864191944084835,
      "loss": 3.1008,
      "step": 13440
    },
    {
      "epoch": 0.5788930016355341,
      "grad_norm": 0.9712128639221191,
      "learning_rate": 0.00018639580494473024,
      "loss": 3.026,
      "step": 13450
    },
    {
      "epoch": 0.5788930016355341,
      "eval_bleu": 26.458566540497525,
      "eval_gen_len": 27.307,
      "eval_loss": 2.821131706237793,
      "eval_runtime": 58.1686,
      "eval_samples_per_second": 17.191,
      "eval_steps_per_second": 1.083,
      "step": 13450
    },
    {
      "epoch": 0.5793234053542222,
      "grad_norm": 1.0138896703720093,
      "learning_rate": 0.0001863723968270393,
      "loss": 3.1237,
      "step": 13460
    },
    {
      "epoch": 0.5797538090729104,
      "grad_norm": 0.9011107683181763,
      "learning_rate": 0.00018634897006046482,
      "loss": 3.0466,
      "step": 13470
    },
    {
      "epoch": 0.5801842127915985,
      "grad_norm": 0.772587776184082,
      "learning_rate": 0.0001863255246500649,
      "loss": 3.0894,
      "step": 13480
    },
    {
      "epoch": 0.5806146165102867,
      "grad_norm": 0.9162428379058838,
      "learning_rate": 0.00018630206060090172,
      "loss": 3.1497,
      "step": 13490
    },
    {
      "epoch": 0.5810450202289748,
      "grad_norm": 0.9063317179679871,
      "learning_rate": 0.00018627857791804147,
      "loss": 3.0928,
      "step": 13500
    },
    {
      "epoch": 0.5810450202289748,
      "eval_bleu": 26.582851674294968,
      "eval_gen_len": 27.487,
      "eval_loss": 2.815751314163208,
      "eval_runtime": 57.7746,
      "eval_samples_per_second": 17.309,
      "eval_steps_per_second": 1.09,
      "step": 13500
    },
    {
      "epoch": 0.5814754239476629,
      "grad_norm": 0.9866411685943604,
      "learning_rate": 0.00018625507660655438,
      "loss": 3.1287,
      "step": 13510
    },
    {
      "epoch": 0.581905827666351,
      "grad_norm": 0.9659485816955566,
      "learning_rate": 0.00018623155667151458,
      "loss": 3.0457,
      "step": 13520
    },
    {
      "epoch": 0.5823362313850392,
      "grad_norm": 0.7727152109146118,
      "learning_rate": 0.00018620801811800042,
      "loss": 3.0677,
      "step": 13530
    },
    {
      "epoch": 0.5827666351037273,
      "grad_norm": 0.8541759252548218,
      "learning_rate": 0.00018618446095109415,
      "loss": 3.0419,
      "step": 13540
    },
    {
      "epoch": 0.5831970388224155,
      "grad_norm": 0.8776414394378662,
      "learning_rate": 0.00018616088517588202,
      "loss": 3.1275,
      "step": 13550
    },
    {
      "epoch": 0.5831970388224155,
      "eval_bleu": 26.64817507837197,
      "eval_gen_len": 27.485,
      "eval_loss": 2.8202829360961914,
      "eval_runtime": 57.6071,
      "eval_samples_per_second": 17.359,
      "eval_steps_per_second": 1.094,
      "step": 13550
    },
    {
      "epoch": 0.5836274425411035,
      "grad_norm": 0.9130600094795227,
      "learning_rate": 0.00018613729079745435,
      "loss": 3.0,
      "step": 13560
    },
    {
      "epoch": 0.5840578462597917,
      "grad_norm": 0.8164783716201782,
      "learning_rate": 0.00018611367782090548,
      "loss": 3.0511,
      "step": 13570
    },
    {
      "epoch": 0.5844882499784798,
      "grad_norm": 0.7423323392868042,
      "learning_rate": 0.00018609004625133374,
      "loss": 2.9997,
      "step": 13580
    },
    {
      "epoch": 0.5849186536971679,
      "grad_norm": 1.446844458580017,
      "learning_rate": 0.00018606639609384149,
      "loss": 3.0846,
      "step": 13590
    },
    {
      "epoch": 0.5853490574158561,
      "grad_norm": 0.9316521883010864,
      "learning_rate": 0.00018604272735353505,
      "loss": 2.9682,
      "step": 13600
    },
    {
      "epoch": 0.5853490574158561,
      "eval_bleu": 26.843536472230728,
      "eval_gen_len": 27.358,
      "eval_loss": 2.8173696994781494,
      "eval_runtime": 58.1514,
      "eval_samples_per_second": 17.196,
      "eval_steps_per_second": 1.083,
      "step": 13600
    },
    {
      "epoch": 0.5857794611345442,
      "grad_norm": 0.9542946219444275,
      "learning_rate": 0.00018601904003552483,
      "loss": 3.1506,
      "step": 13610
    },
    {
      "epoch": 0.5862098648532323,
      "grad_norm": 0.825537383556366,
      "learning_rate": 0.00018599533414492527,
      "loss": 3.125,
      "step": 13620
    },
    {
      "epoch": 0.5866402685719204,
      "grad_norm": 0.9083294868469238,
      "learning_rate": 0.00018597160968685468,
      "loss": 3.157,
      "step": 13630
    },
    {
      "epoch": 0.5870706722906086,
      "grad_norm": 0.9722162485122681,
      "learning_rate": 0.00018594786666643553,
      "loss": 3.107,
      "step": 13640
    },
    {
      "epoch": 0.5875010760092967,
      "grad_norm": 1.0292048454284668,
      "learning_rate": 0.0001859241050887942,
      "loss": 3.1256,
      "step": 13650
    },
    {
      "epoch": 0.5875010760092967,
      "eval_bleu": 26.70677745254128,
      "eval_gen_len": 27.399,
      "eval_loss": 2.819444417953491,
      "eval_runtime": 58.2461,
      "eval_samples_per_second": 17.169,
      "eval_steps_per_second": 1.082,
      "step": 13650
    },
    {
      "epoch": 0.5879314797279849,
      "grad_norm": 0.9853898882865906,
      "learning_rate": 0.00018590032495906114,
      "loss": 3.1098,
      "step": 13660
    },
    {
      "epoch": 0.588361883446673,
      "grad_norm": 1.0040203332901,
      "learning_rate": 0.00018587652628237076,
      "loss": 3.0547,
      "step": 13670
    },
    {
      "epoch": 0.5887922871653611,
      "grad_norm": 0.9444446563720703,
      "learning_rate": 0.0001858527090638615,
      "loss": 3.1171,
      "step": 13680
    },
    {
      "epoch": 0.5892226908840492,
      "grad_norm": 0.9067866206169128,
      "learning_rate": 0.00018582887330867578,
      "loss": 3.1907,
      "step": 13690
    },
    {
      "epoch": 0.5896530946027374,
      "grad_norm": 0.9229626059532166,
      "learning_rate": 0.00018580501902196005,
      "loss": 3.0833,
      "step": 13700
    },
    {
      "epoch": 0.5896530946027374,
      "eval_bleu": 26.862448241546915,
      "eval_gen_len": 27.351,
      "eval_loss": 2.820380210876465,
      "eval_runtime": 58.3335,
      "eval_samples_per_second": 17.143,
      "eval_steps_per_second": 1.08,
      "step": 13700
    },
    {
      "epoch": 0.5900834983214255,
      "grad_norm": 0.8218826651573181,
      "learning_rate": 0.00018578114620886477,
      "loss": 3.2043,
      "step": 13710
    },
    {
      "epoch": 0.5905139020401137,
      "grad_norm": 0.8850094676017761,
      "learning_rate": 0.00018575725487454437,
      "loss": 3.0952,
      "step": 13720
    },
    {
      "epoch": 0.5909443057588017,
      "grad_norm": 0.8526446223258972,
      "learning_rate": 0.00018573334502415724,
      "loss": 3.0679,
      "step": 13730
    },
    {
      "epoch": 0.5913747094774899,
      "grad_norm": 1.0762864351272583,
      "learning_rate": 0.0001857094166628659,
      "loss": 3.2103,
      "step": 13740
    },
    {
      "epoch": 0.591805113196178,
      "grad_norm": 0.8949851393699646,
      "learning_rate": 0.0001856854697958367,
      "loss": 3.1593,
      "step": 13750
    },
    {
      "epoch": 0.591805113196178,
      "eval_bleu": 26.4566249740798,
      "eval_gen_len": 27.419,
      "eval_loss": 2.8180646896362305,
      "eval_runtime": 57.9494,
      "eval_samples_per_second": 17.256,
      "eval_steps_per_second": 1.087,
      "step": 13750
    },
    {
      "epoch": 0.5922355169148661,
      "grad_norm": 0.8771790266036987,
      "learning_rate": 0.00018566150442824014,
      "loss": 3.1787,
      "step": 13760
    },
    {
      "epoch": 0.5926659206335543,
      "grad_norm": 0.879345178604126,
      "learning_rate": 0.0001856375205652506,
      "loss": 3.1151,
      "step": 13770
    },
    {
      "epoch": 0.5930963243522424,
      "grad_norm": 0.9012362360954285,
      "learning_rate": 0.00018561351821204652,
      "loss": 3.0898,
      "step": 13780
    },
    {
      "epoch": 0.5935267280709305,
      "grad_norm": 0.8411998152732849,
      "learning_rate": 0.00018558949737381027,
      "loss": 3.0572,
      "step": 13790
    },
    {
      "epoch": 0.5939571317896186,
      "grad_norm": 0.9247516989707947,
      "learning_rate": 0.00018556545805572828,
      "loss": 3.0581,
      "step": 13800
    },
    {
      "epoch": 0.5939571317896186,
      "eval_bleu": 26.754222954324113,
      "eval_gen_len": 27.425,
      "eval_loss": 2.8206257820129395,
      "eval_runtime": 58.1195,
      "eval_samples_per_second": 17.206,
      "eval_steps_per_second": 1.084,
      "step": 13800
    },
    {
      "epoch": 0.5943875355083068,
      "grad_norm": 0.9286110997200012,
      "learning_rate": 0.000185541400262991,
      "loss": 3.0922,
      "step": 13810
    },
    {
      "epoch": 0.5948179392269949,
      "grad_norm": 0.9486551880836487,
      "learning_rate": 0.00018551732400079267,
      "loss": 3.1801,
      "step": 13820
    },
    {
      "epoch": 0.5952483429456831,
      "grad_norm": 0.866291880607605,
      "learning_rate": 0.00018549322927433176,
      "loss": 3.0187,
      "step": 13830
    },
    {
      "epoch": 0.5956787466643712,
      "grad_norm": 0.8022032380104065,
      "learning_rate": 0.00018546911608881058,
      "loss": 3.0255,
      "step": 13840
    },
    {
      "epoch": 0.5961091503830593,
      "grad_norm": 1.0009032487869263,
      "learning_rate": 0.00018544498444943554,
      "loss": 3.2593,
      "step": 13850
    },
    {
      "epoch": 0.5961091503830593,
      "eval_bleu": 26.152569137974673,
      "eval_gen_len": 27.328,
      "eval_loss": 2.8268566131591797,
      "eval_runtime": 57.9641,
      "eval_samples_per_second": 17.252,
      "eval_steps_per_second": 1.087,
      "step": 13850
    },
    {
      "epoch": 0.5965395541017474,
      "grad_norm": 0.9085633158683777,
      "learning_rate": 0.0001854208343614169,
      "loss": 3.1285,
      "step": 13860
    },
    {
      "epoch": 0.5969699578204356,
      "grad_norm": 0.9358021020889282,
      "learning_rate": 0.00018539666582996893,
      "loss": 3.1661,
      "step": 13870
    },
    {
      "epoch": 0.5974003615391237,
      "grad_norm": 0.8596528172492981,
      "learning_rate": 0.00018537247886031,
      "loss": 3.1228,
      "step": 13880
    },
    {
      "epoch": 0.5978307652578119,
      "grad_norm": 0.8823263645172119,
      "learning_rate": 0.00018534827345766236,
      "loss": 3.0572,
      "step": 13890
    },
    {
      "epoch": 0.5982611689765,
      "grad_norm": 0.8877504467964172,
      "learning_rate": 0.00018532404962725223,
      "loss": 3.1073,
      "step": 13900
    },
    {
      "epoch": 0.5982611689765,
      "eval_bleu": 26.71973578360696,
      "eval_gen_len": 27.384,
      "eval_loss": 2.821442127227783,
      "eval_runtime": 57.9016,
      "eval_samples_per_second": 17.271,
      "eval_steps_per_second": 1.088,
      "step": 13900
    },
    {
      "epoch": 0.5986915726951881,
      "grad_norm": 0.8871505856513977,
      "learning_rate": 0.00018529980737430984,
      "loss": 3.0623,
      "step": 13910
    },
    {
      "epoch": 0.5991219764138762,
      "grad_norm": 0.8824507594108582,
      "learning_rate": 0.00018527554670406943,
      "loss": 3.093,
      "step": 13920
    },
    {
      "epoch": 0.5995523801325644,
      "grad_norm": 0.9452130794525146,
      "learning_rate": 0.00018525126762176917,
      "loss": 3.1413,
      "step": 13930
    },
    {
      "epoch": 0.5999827838512525,
      "grad_norm": 0.8908469676971436,
      "learning_rate": 0.00018522697013265117,
      "loss": 3.0176,
      "step": 13940
    },
    {
      "epoch": 0.6004131875699406,
      "grad_norm": 1.0507049560546875,
      "learning_rate": 0.00018520265424196164,
      "loss": 3.1515,
      "step": 13950
    },
    {
      "epoch": 0.6004131875699406,
      "eval_bleu": 26.67420645791438,
      "eval_gen_len": 27.401,
      "eval_loss": 2.82002592086792,
      "eval_runtime": 58.5632,
      "eval_samples_per_second": 17.076,
      "eval_steps_per_second": 1.076,
      "step": 13950
    },
    {
      "epoch": 0.6008435912886287,
      "grad_norm": 0.896562933921814,
      "learning_rate": 0.00018517831995495064,
      "loss": 3.0819,
      "step": 13960
    },
    {
      "epoch": 0.6012739950073168,
      "grad_norm": 0.9727809429168701,
      "learning_rate": 0.00018515396727687228,
      "loss": 3.0845,
      "step": 13970
    },
    {
      "epoch": 0.601704398726005,
      "grad_norm": 0.960119366645813,
      "learning_rate": 0.00018512959621298458,
      "loss": 2.9925,
      "step": 13980
    },
    {
      "epoch": 0.6021348024446931,
      "grad_norm": 0.8909314870834351,
      "learning_rate": 0.00018510520676854957,
      "loss": 3.1586,
      "step": 13990
    },
    {
      "epoch": 0.6025652061633813,
      "grad_norm": 0.938746452331543,
      "learning_rate": 0.00018508079894883324,
      "loss": 3.0253,
      "step": 14000
    },
    {
      "epoch": 0.6025652061633813,
      "eval_bleu": 26.172876999213706,
      "eval_gen_len": 27.329,
      "eval_loss": 2.8237202167510986,
      "eval_runtime": 57.9497,
      "eval_samples_per_second": 17.256,
      "eval_steps_per_second": 1.087,
      "step": 14000
    },
    {
      "epoch": 0.6029956098820693,
      "grad_norm": 0.9768249988555908,
      "learning_rate": 0.0001850563727591055,
      "loss": 3.0854,
      "step": 14010
    },
    {
      "epoch": 0.6034260136007575,
      "grad_norm": 1.023377776145935,
      "learning_rate": 0.00018503192820464032,
      "loss": 3.1036,
      "step": 14020
    },
    {
      "epoch": 0.6038564173194456,
      "grad_norm": 0.8572577238082886,
      "learning_rate": 0.00018500746529071557,
      "loss": 3.1399,
      "step": 14030
    },
    {
      "epoch": 0.6042868210381338,
      "grad_norm": 0.8611871600151062,
      "learning_rate": 0.00018498298402261313,
      "loss": 3.1287,
      "step": 14040
    },
    {
      "epoch": 0.6047172247568219,
      "grad_norm": 0.8402244448661804,
      "learning_rate": 0.0001849584844056188,
      "loss": 3.137,
      "step": 14050
    },
    {
      "epoch": 0.6047172247568219,
      "eval_bleu": 26.289273242624482,
      "eval_gen_len": 27.433,
      "eval_loss": 2.8234291076660156,
      "eval_runtime": 57.8884,
      "eval_samples_per_second": 17.275,
      "eval_steps_per_second": 1.088,
      "step": 14050
    },
    {
      "epoch": 0.6051476284755101,
      "grad_norm": 0.8280022144317627,
      "learning_rate": 0.0001849339664450223,
      "loss": 3.0845,
      "step": 14060
    },
    {
      "epoch": 0.6055780321941981,
      "grad_norm": 0.9218228459358215,
      "learning_rate": 0.0001849094301461174,
      "loss": 3.0822,
      "step": 14070
    },
    {
      "epoch": 0.6060084359128863,
      "grad_norm": 0.977230966091156,
      "learning_rate": 0.00018488487551420181,
      "loss": 3.0338,
      "step": 14080
    },
    {
      "epoch": 0.6064388396315744,
      "grad_norm": 0.9344472289085388,
      "learning_rate": 0.0001848603025545772,
      "loss": 3.1498,
      "step": 14090
    },
    {
      "epoch": 0.6068692433502626,
      "grad_norm": 0.8307791352272034,
      "learning_rate": 0.00018483571127254913,
      "loss": 3.1901,
      "step": 14100
    },
    {
      "epoch": 0.6068692433502626,
      "eval_bleu": 26.10122539830361,
      "eval_gen_len": 27.512,
      "eval_loss": 2.8218815326690674,
      "eval_runtime": 57.7473,
      "eval_samples_per_second": 17.317,
      "eval_steps_per_second": 1.091,
      "step": 14100
    },
    {
      "epoch": 0.6072996470689507,
      "grad_norm": 1.0137097835540771,
      "learning_rate": 0.0001848111016734272,
      "loss": 3.0626,
      "step": 14110
    },
    {
      "epoch": 0.6077300507876388,
      "grad_norm": 1.0206607580184937,
      "learning_rate": 0.0001847864737625249,
      "loss": 3.1002,
      "step": 14120
    },
    {
      "epoch": 0.6081604545063269,
      "grad_norm": 0.9520052075386047,
      "learning_rate": 0.00018476182754515973,
      "loss": 3.2819,
      "step": 14130
    },
    {
      "epoch": 0.608590858225015,
      "grad_norm": 0.7261347770690918,
      "learning_rate": 0.00018473716302665313,
      "loss": 3.0312,
      "step": 14140
    },
    {
      "epoch": 0.6090212619437032,
      "grad_norm": 0.905181884765625,
      "learning_rate": 0.00018471248021233047,
      "loss": 2.9924,
      "step": 14150
    },
    {
      "epoch": 0.6090212619437032,
      "eval_bleu": 26.00347331990195,
      "eval_gen_len": 27.389,
      "eval_loss": 2.82047963142395,
      "eval_runtime": 58.0218,
      "eval_samples_per_second": 17.235,
      "eval_steps_per_second": 1.086,
      "step": 14150
    },
    {
      "epoch": 0.6094516656623913,
      "grad_norm": 0.8560343384742737,
      "learning_rate": 0.00018468777910752104,
      "loss": 3.0684,
      "step": 14160
    },
    {
      "epoch": 0.6098820693810795,
      "grad_norm": 0.9781336188316345,
      "learning_rate": 0.00018466305971755819,
      "loss": 3.0823,
      "step": 14170
    },
    {
      "epoch": 0.6103124730997675,
      "grad_norm": 0.9564378261566162,
      "learning_rate": 0.00018463832204777906,
      "loss": 3.1726,
      "step": 14180
    },
    {
      "epoch": 0.6107428768184557,
      "grad_norm": 0.8915886282920837,
      "learning_rate": 0.0001846135661035249,
      "loss": 3.0448,
      "step": 14190
    },
    {
      "epoch": 0.6111732805371438,
      "grad_norm": 0.9392222166061401,
      "learning_rate": 0.00018458879189014077,
      "loss": 3.0888,
      "step": 14200
    },
    {
      "epoch": 0.6111732805371438,
      "eval_bleu": 26.023629332962134,
      "eval_gen_len": 27.413,
      "eval_loss": 2.8184213638305664,
      "eval_runtime": 57.7541,
      "eval_samples_per_second": 17.315,
      "eval_steps_per_second": 1.091,
      "step": 14200
    },
    {
      "epoch": 0.611603684255832,
      "grad_norm": 1.0720534324645996,
      "learning_rate": 0.00018456399941297577,
      "loss": 3.0933,
      "step": 14210
    },
    {
      "epoch": 0.6120340879745201,
      "grad_norm": 0.8955146670341492,
      "learning_rate": 0.0001845391886773829,
      "loss": 3.1832,
      "step": 14220
    },
    {
      "epoch": 0.6124644916932083,
      "grad_norm": 0.8949115872383118,
      "learning_rate": 0.00018451435968871912,
      "loss": 3.0546,
      "step": 14230
    },
    {
      "epoch": 0.6128948954118963,
      "grad_norm": 0.8670847415924072,
      "learning_rate": 0.00018448951245234532,
      "loss": 3.1045,
      "step": 14240
    },
    {
      "epoch": 0.6133252991305845,
      "grad_norm": 0.9855724573135376,
      "learning_rate": 0.00018446464697362627,
      "loss": 3.1617,
      "step": 14250
    },
    {
      "epoch": 0.6133252991305845,
      "eval_bleu": 26.606006800508037,
      "eval_gen_len": 27.54,
      "eval_loss": 2.816045045852661,
      "eval_runtime": 57.6867,
      "eval_samples_per_second": 17.335,
      "eval_steps_per_second": 1.092,
      "step": 14250
    },
    {
      "epoch": 0.6137557028492726,
      "grad_norm": 0.8853995203971863,
      "learning_rate": 0.0001844397632579308,
      "loss": 3.1471,
      "step": 14260
    },
    {
      "epoch": 0.6141861065679608,
      "grad_norm": 0.9778439402580261,
      "learning_rate": 0.0001844148613106316,
      "loss": 3.0903,
      "step": 14270
    },
    {
      "epoch": 0.6146165102866489,
      "grad_norm": 0.964383602142334,
      "learning_rate": 0.0001843899411371053,
      "loss": 3.1207,
      "step": 14280
    },
    {
      "epoch": 0.615046914005337,
      "grad_norm": 0.8847180604934692,
      "learning_rate": 0.00018436500274273253,
      "loss": 3.1658,
      "step": 14290
    },
    {
      "epoch": 0.6154773177240251,
      "grad_norm": 0.9879415035247803,
      "learning_rate": 0.00018434004613289778,
      "loss": 3.2038,
      "step": 14300
    },
    {
      "epoch": 0.6154773177240251,
      "eval_bleu": 26.71658190934431,
      "eval_gen_len": 27.386,
      "eval_loss": 2.8164315223693848,
      "eval_runtime": 57.4849,
      "eval_samples_per_second": 17.396,
      "eval_steps_per_second": 1.096,
      "step": 14300
    },
    {
      "epoch": 0.6159077214427132,
      "grad_norm": 0.9550597667694092,
      "learning_rate": 0.00018431507131298942,
      "loss": 3.0525,
      "step": 14310
    },
    {
      "epoch": 0.6163381251614014,
      "grad_norm": 0.9292977452278137,
      "learning_rate": 0.00018429007828839992,
      "loss": 3.1224,
      "step": 14320
    },
    {
      "epoch": 0.6167685288800895,
      "grad_norm": 0.8987004160881042,
      "learning_rate": 0.00018426506706452554,
      "loss": 3.1547,
      "step": 14330
    },
    {
      "epoch": 0.6171989325987777,
      "grad_norm": 0.8395829796791077,
      "learning_rate": 0.00018424003764676652,
      "loss": 3.1219,
      "step": 14340
    },
    {
      "epoch": 0.6176293363174657,
      "grad_norm": 0.9956786632537842,
      "learning_rate": 0.00018421499004052705,
      "loss": 3.1293,
      "step": 14350
    },
    {
      "epoch": 0.6176293363174657,
      "eval_bleu": 25.87775181303057,
      "eval_gen_len": 27.398,
      "eval_loss": 2.8205459117889404,
      "eval_runtime": 57.7955,
      "eval_samples_per_second": 17.302,
      "eval_steps_per_second": 1.09,
      "step": 14350
    },
    {
      "epoch": 0.6180597400361539,
      "grad_norm": 0.9817995429039001,
      "learning_rate": 0.0001841899242512152,
      "loss": 3.1329,
      "step": 14360
    },
    {
      "epoch": 0.618490143754842,
      "grad_norm": 1.051772952079773,
      "learning_rate": 0.000184164840284243,
      "loss": 3.1154,
      "step": 14370
    },
    {
      "epoch": 0.6189205474735302,
      "grad_norm": 0.9371243119239807,
      "learning_rate": 0.0001841397381450264,
      "loss": 3.1049,
      "step": 14380
    },
    {
      "epoch": 0.6193509511922183,
      "grad_norm": 0.8822656869888306,
      "learning_rate": 0.00018411461783898525,
      "loss": 3.0613,
      "step": 14390
    },
    {
      "epoch": 0.6197813549109065,
      "grad_norm": 0.8688216209411621,
      "learning_rate": 0.00018408947937154332,
      "loss": 3.0975,
      "step": 14400
    },
    {
      "epoch": 0.6197813549109065,
      "eval_bleu": 26.89433746037566,
      "eval_gen_len": 27.384,
      "eval_loss": 2.81758189201355,
      "eval_runtime": 57.8365,
      "eval_samples_per_second": 17.29,
      "eval_steps_per_second": 1.089,
      "step": 14400
    },
    {
      "epoch": 0.6202117586295945,
      "grad_norm": 1.041521668434143,
      "learning_rate": 0.00018406432274812836,
      "loss": 3.1293,
      "step": 14410
    },
    {
      "epoch": 0.6206421623482827,
      "grad_norm": 0.964760422706604,
      "learning_rate": 0.00018403914797417202,
      "loss": 3.2346,
      "step": 14420
    },
    {
      "epoch": 0.6210725660669708,
      "grad_norm": 0.8831268548965454,
      "learning_rate": 0.00018401395505510975,
      "loss": 3.1078,
      "step": 14430
    },
    {
      "epoch": 0.621502969785659,
      "grad_norm": 0.965855062007904,
      "learning_rate": 0.00018398874399638113,
      "loss": 3.0635,
      "step": 14440
    },
    {
      "epoch": 0.6219333735043471,
      "grad_norm": 0.8704310655593872,
      "learning_rate": 0.00018396351480342947,
      "loss": 3.1327,
      "step": 14450
    },
    {
      "epoch": 0.6219333735043471,
      "eval_bleu": 26.64095289256623,
      "eval_gen_len": 27.333,
      "eval_loss": 2.8210575580596924,
      "eval_runtime": 58.275,
      "eval_samples_per_second": 17.16,
      "eval_steps_per_second": 1.081,
      "step": 14450
    },
    {
      "epoch": 0.6223637772230352,
      "grad_norm": 0.9800312519073486,
      "learning_rate": 0.0001839382674817021,
      "loss": 3.2193,
      "step": 14460
    },
    {
      "epoch": 0.6227941809417233,
      "grad_norm": 0.8583387732505798,
      "learning_rate": 0.00018391300203665024,
      "loss": 3.0985,
      "step": 14470
    },
    {
      "epoch": 0.6232245846604114,
      "grad_norm": 0.8928281664848328,
      "learning_rate": 0.00018388771847372895,
      "loss": 3.0437,
      "step": 14480
    },
    {
      "epoch": 0.6236549883790996,
      "grad_norm": 0.869051456451416,
      "learning_rate": 0.0001838624167983974,
      "loss": 3.056,
      "step": 14490
    },
    {
      "epoch": 0.6240853920977877,
      "grad_norm": 0.9740707874298096,
      "learning_rate": 0.00018383709701611843,
      "loss": 3.1259,
      "step": 14500
    },
    {
      "epoch": 0.6240853920977877,
      "eval_bleu": 26.46306488344107,
      "eval_gen_len": 27.489,
      "eval_loss": 2.81973934173584,
      "eval_runtime": 58.1105,
      "eval_samples_per_second": 17.209,
      "eval_steps_per_second": 1.084,
      "step": 14500
    },
    {
      "epoch": 0.6245157958164759,
      "grad_norm": 0.9070046544075012,
      "learning_rate": 0.00018381175913235892,
      "loss": 3.1724,
      "step": 14510
    },
    {
      "epoch": 0.624946199535164,
      "grad_norm": 0.8684366345405579,
      "learning_rate": 0.00018378640315258965,
      "loss": 3.1033,
      "step": 14520
    },
    {
      "epoch": 0.6253766032538521,
      "grad_norm": 0.8818222880363464,
      "learning_rate": 0.00018376102908228528,
      "loss": 3.1369,
      "step": 14530
    },
    {
      "epoch": 0.6258070069725402,
      "grad_norm": 1.0096524953842163,
      "learning_rate": 0.00018373563692692443,
      "loss": 3.1069,
      "step": 14540
    },
    {
      "epoch": 0.6262374106912284,
      "grad_norm": 0.9408580660820007,
      "learning_rate": 0.00018371022669198955,
      "loss": 3.1914,
      "step": 14550
    },
    {
      "epoch": 0.6262374106912284,
      "eval_bleu": 25.87894622228433,
      "eval_gen_len": 27.448,
      "eval_loss": 2.824927806854248,
      "eval_runtime": 58.0272,
      "eval_samples_per_second": 17.233,
      "eval_steps_per_second": 1.086,
      "step": 14550
    },
    {
      "epoch": 0.6266678144099165,
      "grad_norm": 1.0043210983276367,
      "learning_rate": 0.00018368479838296698,
      "loss": 3.1399,
      "step": 14560
    },
    {
      "epoch": 0.6270982181286047,
      "grad_norm": 0.9509664177894592,
      "learning_rate": 0.00018365935200534712,
      "loss": 3.1237,
      "step": 14570
    },
    {
      "epoch": 0.6275286218472927,
      "grad_norm": 0.986590564250946,
      "learning_rate": 0.0001836338875646241,
      "loss": 3.1079,
      "step": 14580
    },
    {
      "epoch": 0.6279590255659809,
      "grad_norm": 0.8107681274414062,
      "learning_rate": 0.00018360840506629602,
      "loss": 3.0834,
      "step": 14590
    },
    {
      "epoch": 0.628389429284669,
      "grad_norm": 0.8965789079666138,
      "learning_rate": 0.00018358290451586486,
      "loss": 3.1873,
      "step": 14600
    },
    {
      "epoch": 0.628389429284669,
      "eval_bleu": 26.40401343226963,
      "eval_gen_len": 27.536,
      "eval_loss": 2.82236909866333,
      "eval_runtime": 58.0914,
      "eval_samples_per_second": 17.214,
      "eval_steps_per_second": 1.084,
      "step": 14600
    },
    {
      "epoch": 0.6288198330033572,
      "grad_norm": 0.8973609209060669,
      "learning_rate": 0.0001835573859188365,
      "loss": 3.0338,
      "step": 14610
    },
    {
      "epoch": 0.6292502367220453,
      "grad_norm": 0.8528141975402832,
      "learning_rate": 0.00018353184928072077,
      "loss": 3.0662,
      "step": 14620
    },
    {
      "epoch": 0.6296806404407335,
      "grad_norm": 1.1131565570831299,
      "learning_rate": 0.00018350629460703132,
      "loss": 3.148,
      "step": 14630
    },
    {
      "epoch": 0.6301110441594215,
      "grad_norm": 0.907284140586853,
      "learning_rate": 0.00018348072190328574,
      "loss": 3.1156,
      "step": 14640
    },
    {
      "epoch": 0.6305414478781096,
      "grad_norm": 0.9090038537979126,
      "learning_rate": 0.00018345513117500547,
      "loss": 3.1006,
      "step": 14650
    },
    {
      "epoch": 0.6305414478781096,
      "eval_bleu": 26.268526127212564,
      "eval_gen_len": 27.254,
      "eval_loss": 2.8181841373443604,
      "eval_runtime": 57.5939,
      "eval_samples_per_second": 17.363,
      "eval_steps_per_second": 1.094,
      "step": 14650
    },
    {
      "epoch": 0.6309718515967978,
      "grad_norm": 0.88777756690979,
      "learning_rate": 0.00018342952242771587,
      "loss": 3.031,
      "step": 14660
    },
    {
      "epoch": 0.6314022553154859,
      "grad_norm": 0.8673839569091797,
      "learning_rate": 0.00018340389566694621,
      "loss": 3.1411,
      "step": 14670
    },
    {
      "epoch": 0.6318326590341741,
      "grad_norm": 1.0123671293258667,
      "learning_rate": 0.00018337825089822967,
      "loss": 3.0749,
      "step": 14680
    },
    {
      "epoch": 0.6322630627528621,
      "grad_norm": 0.8920077085494995,
      "learning_rate": 0.00018335258812710316,
      "loss": 3.0496,
      "step": 14690
    },
    {
      "epoch": 0.6326934664715503,
      "grad_norm": 1.0007463693618774,
      "learning_rate": 0.0001833269073591077,
      "loss": 3.146,
      "step": 14700
    },
    {
      "epoch": 0.6326934664715503,
      "eval_bleu": 26.79311345578572,
      "eval_gen_len": 27.431,
      "eval_loss": 2.8177132606506348,
      "eval_runtime": 58.0078,
      "eval_samples_per_second": 17.239,
      "eval_steps_per_second": 1.086,
      "step": 14700
    },
    {
      "epoch": 0.6331238701902384,
      "grad_norm": 0.8727408051490784,
      "learning_rate": 0.00018330120859978805,
      "loss": 3.1133,
      "step": 14710
    },
    {
      "epoch": 0.6335542739089266,
      "grad_norm": 1.0241806507110596,
      "learning_rate": 0.0001832754918546929,
      "loss": 3.1012,
      "step": 14720
    },
    {
      "epoch": 0.6339846776276147,
      "grad_norm": 0.9278683662414551,
      "learning_rate": 0.00018324975712937484,
      "loss": 3.1366,
      "step": 14730
    },
    {
      "epoch": 0.6344150813463029,
      "grad_norm": 1.0018489360809326,
      "learning_rate": 0.00018322400442939024,
      "loss": 3.0405,
      "step": 14740
    },
    {
      "epoch": 0.6348454850649909,
      "grad_norm": 0.9656998515129089,
      "learning_rate": 0.00018319823376029953,
      "loss": 3.053,
      "step": 14750
    },
    {
      "epoch": 0.6348454850649909,
      "eval_bleu": 26.670936259834413,
      "eval_gen_len": 27.342,
      "eval_loss": 2.818265199661255,
      "eval_runtime": 57.6373,
      "eval_samples_per_second": 17.35,
      "eval_steps_per_second": 1.093,
      "step": 14750
    },
    {
      "epoch": 0.6352758887836791,
      "grad_norm": 1.0909943580627441,
      "learning_rate": 0.00018317244512766688,
      "loss": 3.1011,
      "step": 14760
    },
    {
      "epoch": 0.6357062925023672,
      "grad_norm": 0.8948687314987183,
      "learning_rate": 0.00018314663853706038,
      "loss": 3.0392,
      "step": 14770
    },
    {
      "epoch": 0.6361366962210554,
      "grad_norm": 0.9180293083190918,
      "learning_rate": 0.00018312081399405195,
      "loss": 3.0423,
      "step": 14780
    },
    {
      "epoch": 0.6365670999397435,
      "grad_norm": 0.8847595453262329,
      "learning_rate": 0.00018309497150421753,
      "loss": 3.1048,
      "step": 14790
    },
    {
      "epoch": 0.6369975036584317,
      "grad_norm": 1.0216338634490967,
      "learning_rate": 0.00018306911107313672,
      "loss": 3.083,
      "step": 14800
    },
    {
      "epoch": 0.6369975036584317,
      "eval_bleu": 26.73937194032648,
      "eval_gen_len": 27.235,
      "eval_loss": 2.812687873840332,
      "eval_runtime": 57.5949,
      "eval_samples_per_second": 17.363,
      "eval_steps_per_second": 1.094,
      "step": 14800
    },
    {
      "epoch": 0.6374279073771197,
      "grad_norm": 0.8598374128341675,
      "learning_rate": 0.00018304323270639322,
      "loss": 3.0263,
      "step": 14810
    },
    {
      "epoch": 0.6378583110958078,
      "grad_norm": 0.9249195456504822,
      "learning_rate": 0.00018301733640957446,
      "loss": 3.1076,
      "step": 14820
    },
    {
      "epoch": 0.638288714814496,
      "grad_norm": 0.9713784456253052,
      "learning_rate": 0.00018299142218827175,
      "loss": 3.1069,
      "step": 14830
    },
    {
      "epoch": 0.6387191185331841,
      "grad_norm": 0.9034835696220398,
      "learning_rate": 0.0001829654900480803,
      "loss": 3.2065,
      "step": 14840
    },
    {
      "epoch": 0.6391495222518723,
      "grad_norm": 0.8393269777297974,
      "learning_rate": 0.00018293953999459918,
      "loss": 3.1935,
      "step": 14850
    },
    {
      "epoch": 0.6391495222518723,
      "eval_bleu": 26.455328290168445,
      "eval_gen_len": 27.311,
      "eval_loss": 2.8192200660705566,
      "eval_runtime": 58.3336,
      "eval_samples_per_second": 17.143,
      "eval_steps_per_second": 1.08,
      "step": 14850
    },
    {
      "epoch": 0.6395799259705603,
      "grad_norm": 0.8607416749000549,
      "learning_rate": 0.00018291357203343138,
      "loss": 3.0265,
      "step": 14860
    },
    {
      "epoch": 0.6400103296892485,
      "grad_norm": 0.9376556277275085,
      "learning_rate": 0.00018288758617018367,
      "loss": 3.0893,
      "step": 14870
    },
    {
      "epoch": 0.6404407334079366,
      "grad_norm": 0.9009509086608887,
      "learning_rate": 0.0001828615824104667,
      "loss": 3.1258,
      "step": 14880
    },
    {
      "epoch": 0.6408711371266248,
      "grad_norm": 0.8489353656768799,
      "learning_rate": 0.00018283556075989504,
      "loss": 3.1145,
      "step": 14890
    },
    {
      "epoch": 0.6413015408453129,
      "grad_norm": 0.9101945161819458,
      "learning_rate": 0.00018280952122408712,
      "loss": 3.2114,
      "step": 14900
    },
    {
      "epoch": 0.6413015408453129,
      "eval_bleu": 26.27121721729244,
      "eval_gen_len": 27.478,
      "eval_loss": 2.8189027309417725,
      "eval_runtime": 57.9873,
      "eval_samples_per_second": 17.245,
      "eval_steps_per_second": 1.086,
      "step": 14900
    },
    {
      "epoch": 0.6417319445640011,
      "grad_norm": 0.8929763436317444,
      "learning_rate": 0.00018278346380866514,
      "loss": 3.0635,
      "step": 14910
    },
    {
      "epoch": 0.6421623482826891,
      "grad_norm": 1.062174916267395,
      "learning_rate": 0.00018275738851925529,
      "loss": 3.1373,
      "step": 14920
    },
    {
      "epoch": 0.6425927520013773,
      "grad_norm": 0.9044035077095032,
      "learning_rate": 0.0001827312953614875,
      "loss": 3.0896,
      "step": 14930
    },
    {
      "epoch": 0.6430231557200654,
      "grad_norm": 0.899959146976471,
      "learning_rate": 0.00018270518434099556,
      "loss": 3.2389,
      "step": 14940
    },
    {
      "epoch": 0.6434535594387536,
      "grad_norm": 1.0029816627502441,
      "learning_rate": 0.00018267905546341727,
      "loss": 3.1534,
      "step": 14950
    },
    {
      "epoch": 0.6434535594387536,
      "eval_bleu": 26.703063443525817,
      "eval_gen_len": 27.454,
      "eval_loss": 2.8164310455322266,
      "eval_runtime": 58.0869,
      "eval_samples_per_second": 17.216,
      "eval_steps_per_second": 1.085,
      "step": 14950
    },
    {
      "epoch": 0.6438839631574417,
      "grad_norm": 0.9079928398132324,
      "learning_rate": 0.00018265290873439416,
      "loss": 3.0906,
      "step": 14960
    },
    {
      "epoch": 0.6443143668761299,
      "grad_norm": 0.8950659036636353,
      "learning_rate": 0.0001826267441595716,
      "loss": 3.1193,
      "step": 14970
    },
    {
      "epoch": 0.6447447705948179,
      "grad_norm": 0.9336145520210266,
      "learning_rate": 0.0001826005617445989,
      "loss": 3.119,
      "step": 14980
    },
    {
      "epoch": 0.645175174313506,
      "grad_norm": 1.011574149131775,
      "learning_rate": 0.0001825743614951291,
      "loss": 3.0696,
      "step": 14990
    },
    {
      "epoch": 0.6456055780321942,
      "grad_norm": 0.9424334168434143,
      "learning_rate": 0.0001825481434168192,
      "loss": 3.1625,
      "step": 15000
    },
    {
      "epoch": 0.6456055780321942,
      "eval_bleu": 26.606804284634666,
      "eval_gen_len": 27.417,
      "eval_loss": 2.8191959857940674,
      "eval_runtime": 58.7201,
      "eval_samples_per_second": 17.03,
      "eval_steps_per_second": 1.073,
      "step": 15000
    },
    {
      "epoch": 0.6460359817508823,
      "grad_norm": 0.7590682506561279,
      "learning_rate": 0.00018252190751533008,
      "loss": 3.0725,
      "step": 15010
    },
    {
      "epoch": 0.6464663854695705,
      "grad_norm": 0.934704601764679,
      "learning_rate": 0.00018249565379632626,
      "loss": 3.1713,
      "step": 15020
    },
    {
      "epoch": 0.6468967891882585,
      "grad_norm": 1.0233449935913086,
      "learning_rate": 0.00018246938226547634,
      "loss": 3.1745,
      "step": 15030
    },
    {
      "epoch": 0.6473271929069467,
      "grad_norm": 0.9656887054443359,
      "learning_rate": 0.00018244309292845268,
      "loss": 3.1786,
      "step": 15040
    },
    {
      "epoch": 0.6477575966256348,
      "grad_norm": 0.9282048344612122,
      "learning_rate": 0.00018241678579093145,
      "loss": 3.0656,
      "step": 15050
    },
    {
      "epoch": 0.6477575966256348,
      "eval_bleu": 26.45546818098722,
      "eval_gen_len": 27.434,
      "eval_loss": 2.8172996044158936,
      "eval_runtime": 57.841,
      "eval_samples_per_second": 17.289,
      "eval_steps_per_second": 1.089,
      "step": 15050
    },
    {
      "epoch": 0.648188000344323,
      "grad_norm": 0.9546552300453186,
      "learning_rate": 0.00018239046085859268,
      "loss": 3.0616,
      "step": 15060
    },
    {
      "epoch": 0.6486184040630111,
      "grad_norm": 0.9495472311973572,
      "learning_rate": 0.00018236411813712028,
      "loss": 3.1496,
      "step": 15070
    },
    {
      "epoch": 0.6490488077816993,
      "grad_norm": 0.973601222038269,
      "learning_rate": 0.00018233775763220193,
      "loss": 3.1059,
      "step": 15080
    },
    {
      "epoch": 0.6494792115003873,
      "grad_norm": 0.9686954617500305,
      "learning_rate": 0.00018231137934952924,
      "loss": 3.1322,
      "step": 15090
    },
    {
      "epoch": 0.6499096152190755,
      "grad_norm": 0.7605112791061401,
      "learning_rate": 0.00018228498329479761,
      "loss": 3.024,
      "step": 15100
    },
    {
      "epoch": 0.6499096152190755,
      "eval_bleu": 26.299916642766966,
      "eval_gen_len": 27.359,
      "eval_loss": 2.81577205657959,
      "eval_runtime": 57.7197,
      "eval_samples_per_second": 17.325,
      "eval_steps_per_second": 1.091,
      "step": 15100
    },
    {
      "epoch": 0.6503400189377636,
      "grad_norm": 0.8596087098121643,
      "learning_rate": 0.00018225856947370626,
      "loss": 3.0742,
      "step": 15110
    },
    {
      "epoch": 0.6507704226564518,
      "grad_norm": 0.9738649129867554,
      "learning_rate": 0.00018223213789195827,
      "loss": 3.0967,
      "step": 15120
    },
    {
      "epoch": 0.6512008263751399,
      "grad_norm": 0.9659648537635803,
      "learning_rate": 0.00018220568855526053,
      "loss": 3.1131,
      "step": 15130
    },
    {
      "epoch": 0.6516312300938281,
      "grad_norm": 1.0129233598709106,
      "learning_rate": 0.00018217922146932382,
      "loss": 3.0619,
      "step": 15140
    },
    {
      "epoch": 0.6520616338125161,
      "grad_norm": 0.9121274352073669,
      "learning_rate": 0.0001821527366398627,
      "loss": 3.0673,
      "step": 15150
    },
    {
      "epoch": 0.6520616338125161,
      "eval_bleu": 26.896607958102486,
      "eval_gen_len": 27.531,
      "eval_loss": 2.8114840984344482,
      "eval_runtime": 58.096,
      "eval_samples_per_second": 17.213,
      "eval_steps_per_second": 1.084,
      "step": 15150
    },
    {
      "epoch": 0.6524920375312042,
      "grad_norm": 0.800308108329773,
      "learning_rate": 0.00018212623407259557,
      "loss": 3.2134,
      "step": 15160
    },
    {
      "epoch": 0.6529224412498924,
      "grad_norm": 0.8552595973014832,
      "learning_rate": 0.00018209971377324466,
      "loss": 3.262,
      "step": 15170
    },
    {
      "epoch": 0.6533528449685805,
      "grad_norm": 0.9054268002510071,
      "learning_rate": 0.00018207317574753606,
      "loss": 3.0946,
      "step": 15180
    },
    {
      "epoch": 0.6537832486872687,
      "grad_norm": 0.9274761080741882,
      "learning_rate": 0.00018204662000119968,
      "loss": 3.2,
      "step": 15190
    },
    {
      "epoch": 0.6542136524059567,
      "grad_norm": 0.948969841003418,
      "learning_rate": 0.00018202004653996917,
      "loss": 3.026,
      "step": 15200
    },
    {
      "epoch": 0.6542136524059567,
      "eval_bleu": 26.841585116710807,
      "eval_gen_len": 27.483,
      "eval_loss": 2.8154587745666504,
      "eval_runtime": 58.1246,
      "eval_samples_per_second": 17.204,
      "eval_steps_per_second": 1.084,
      "step": 15200
    },
    {
      "epoch": 0.6546440561246449,
      "grad_norm": 0.9705988168716431,
      "learning_rate": 0.00018199345536958213,
      "loss": 3.1051,
      "step": 15210
    },
    {
      "epoch": 0.655074459843333,
      "grad_norm": 0.895399808883667,
      "learning_rate": 0.0001819668464957799,
      "loss": 3.1015,
      "step": 15220
    },
    {
      "epoch": 0.6555048635620212,
      "grad_norm": 0.9177248477935791,
      "learning_rate": 0.0001819402199243077,
      "loss": 3.1477,
      "step": 15230
    },
    {
      "epoch": 0.6559352672807093,
      "grad_norm": 0.8997437357902527,
      "learning_rate": 0.0001819135756609145,
      "loss": 3.0771,
      "step": 15240
    },
    {
      "epoch": 0.6563656709993975,
      "grad_norm": 1.128035545349121,
      "learning_rate": 0.00018188691371135316,
      "loss": 3.1949,
      "step": 15250
    },
    {
      "epoch": 0.6563656709993975,
      "eval_bleu": 26.783495340533523,
      "eval_gen_len": 27.328,
      "eval_loss": 2.813641309738159,
      "eval_runtime": 57.94,
      "eval_samples_per_second": 17.259,
      "eval_steps_per_second": 1.087,
      "step": 15250
    },
    {
      "epoch": 0.6567960747180855,
      "grad_norm": 0.9563908576965332,
      "learning_rate": 0.00018186023408138033,
      "loss": 3.1718,
      "step": 15260
    },
    {
      "epoch": 0.6572264784367737,
      "grad_norm": 0.8428646922111511,
      "learning_rate": 0.00018183353677675643,
      "loss": 3.0901,
      "step": 15270
    },
    {
      "epoch": 0.6576568821554618,
      "grad_norm": 0.9288281202316284,
      "learning_rate": 0.00018180682180324583,
      "loss": 3.0907,
      "step": 15280
    },
    {
      "epoch": 0.65808728587415,
      "grad_norm": 0.9288966059684753,
      "learning_rate": 0.00018178008916661654,
      "loss": 3.1273,
      "step": 15290
    },
    {
      "epoch": 0.6585176895928381,
      "grad_norm": 0.8651356101036072,
      "learning_rate": 0.0001817533388726405,
      "loss": 3.073,
      "step": 15300
    },
    {
      "epoch": 0.6585176895928381,
      "eval_bleu": 26.703214055105562,
      "eval_gen_len": 27.366,
      "eval_loss": 2.8107821941375732,
      "eval_runtime": 57.9566,
      "eval_samples_per_second": 17.254,
      "eval_steps_per_second": 1.087,
      "step": 15300
    },
    {
      "epoch": 0.6589480933115263,
      "grad_norm": 0.8371562361717224,
      "learning_rate": 0.00018172657092709347,
      "loss": 3.0716,
      "step": 15310
    },
    {
      "epoch": 0.6593784970302143,
      "grad_norm": 0.9269874691963196,
      "learning_rate": 0.00018169978533575493,
      "loss": 3.1352,
      "step": 15320
    },
    {
      "epoch": 0.6598089007489024,
      "grad_norm": 0.9714882969856262,
      "learning_rate": 0.0001816729821044083,
      "loss": 3.0079,
      "step": 15330
    },
    {
      "epoch": 0.6602393044675906,
      "grad_norm": 0.9189127683639526,
      "learning_rate": 0.00018164616123884065,
      "loss": 3.2113,
      "step": 15340
    },
    {
      "epoch": 0.6606697081862787,
      "grad_norm": 0.9412631392478943,
      "learning_rate": 0.00018161932274484297,
      "loss": 3.1199,
      "step": 15350
    },
    {
      "epoch": 0.6606697081862787,
      "eval_bleu": 26.543084425236497,
      "eval_gen_len": 27.464,
      "eval_loss": 2.8139121532440186,
      "eval_runtime": 57.9606,
      "eval_samples_per_second": 17.253,
      "eval_steps_per_second": 1.087,
      "step": 15350
    },
    {
      "epoch": 0.6611001119049669,
      "grad_norm": 0.899647057056427,
      "learning_rate": 0.00018159246662821006,
      "loss": 3.0924,
      "step": 15360
    },
    {
      "epoch": 0.661530515623655,
      "grad_norm": 0.8963887691497803,
      "learning_rate": 0.00018156559289474045,
      "loss": 3.111,
      "step": 15370
    },
    {
      "epoch": 0.6619609193423431,
      "grad_norm": 0.9438804388046265,
      "learning_rate": 0.00018153870155023655,
      "loss": 3.1403,
      "step": 15380
    },
    {
      "epoch": 0.6623913230610312,
      "grad_norm": 0.879381537437439,
      "learning_rate": 0.0001815117926005045,
      "loss": 3.1204,
      "step": 15390
    },
    {
      "epoch": 0.6628217267797194,
      "grad_norm": 0.975429892539978,
      "learning_rate": 0.00018148486605135431,
      "loss": 3.0603,
      "step": 15400
    },
    {
      "epoch": 0.6628217267797194,
      "eval_bleu": 26.35854347360345,
      "eval_gen_len": 27.405,
      "eval_loss": 2.8177926540374756,
      "eval_runtime": 57.8057,
      "eval_samples_per_second": 17.299,
      "eval_steps_per_second": 1.09,
      "step": 15400
    },
    {
      "epoch": 0.6632521304984075,
      "grad_norm": 0.8446887731552124,
      "learning_rate": 0.00018145792190859975,
      "loss": 3.0812,
      "step": 15410
    },
    {
      "epoch": 0.6636825342170957,
      "grad_norm": 0.940867006778717,
      "learning_rate": 0.00018143096017805843,
      "loss": 3.0886,
      "step": 15420
    },
    {
      "epoch": 0.6641129379357837,
      "grad_norm": 0.8619218468666077,
      "learning_rate": 0.00018140398086555166,
      "loss": 3.0873,
      "step": 15430
    },
    {
      "epoch": 0.6645433416544719,
      "grad_norm": 1.0228899717330933,
      "learning_rate": 0.00018137698397690467,
      "loss": 3.1062,
      "step": 15440
    },
    {
      "epoch": 0.66497374537316,
      "grad_norm": 0.958126962184906,
      "learning_rate": 0.00018134996951794637,
      "loss": 3.2431,
      "step": 15450
    },
    {
      "epoch": 0.66497374537316,
      "eval_bleu": 26.58696458533608,
      "eval_gen_len": 27.419,
      "eval_loss": 2.8152709007263184,
      "eval_runtime": 58.1715,
      "eval_samples_per_second": 17.191,
      "eval_steps_per_second": 1.083,
      "step": 15450
    },
    {
      "epoch": 0.6654041490918482,
      "grad_norm": 0.9076598882675171,
      "learning_rate": 0.00018132293749450958,
      "loss": 3.0785,
      "step": 15460
    },
    {
      "epoch": 0.6658345528105363,
      "grad_norm": 0.8594904541969299,
      "learning_rate": 0.00018129588791243083,
      "loss": 3.1822,
      "step": 15470
    },
    {
      "epoch": 0.6662649565292245,
      "grad_norm": 0.8996680974960327,
      "learning_rate": 0.00018126882077755044,
      "loss": 3.131,
      "step": 15480
    },
    {
      "epoch": 0.6666953602479125,
      "grad_norm": 0.9836994409561157,
      "learning_rate": 0.00018124173609571258,
      "loss": 3.2227,
      "step": 15490
    },
    {
      "epoch": 0.6671257639666007,
      "grad_norm": 0.8784188628196716,
      "learning_rate": 0.00018121463387276517,
      "loss": 3.0949,
      "step": 15500
    },
    {
      "epoch": 0.6671257639666007,
      "eval_bleu": 26.489636732534485,
      "eval_gen_len": 27.384,
      "eval_loss": 2.816338539123535,
      "eval_runtime": 58.3702,
      "eval_samples_per_second": 17.132,
      "eval_steps_per_second": 1.079,
      "step": 15500
    },
    {
      "epoch": 0.6675561676852888,
      "grad_norm": 0.840183675289154,
      "learning_rate": 0.00018118751411455987,
      "loss": 3.0426,
      "step": 15510
    },
    {
      "epoch": 0.6679865714039769,
      "grad_norm": 0.8580219149589539,
      "learning_rate": 0.00018116037682695224,
      "loss": 3.2348,
      "step": 15520
    },
    {
      "epoch": 0.6684169751226651,
      "grad_norm": 0.9957285523414612,
      "learning_rate": 0.0001811332220158015,
      "loss": 3.1078,
      "step": 15530
    },
    {
      "epoch": 0.6688473788413531,
      "grad_norm": 0.9238216876983643,
      "learning_rate": 0.0001811060496869708,
      "loss": 3.1223,
      "step": 15540
    },
    {
      "epoch": 0.6692777825600413,
      "grad_norm": 0.9480274319648743,
      "learning_rate": 0.00018107885984632691,
      "loss": 3.0138,
      "step": 15550
    },
    {
      "epoch": 0.6692777825600413,
      "eval_bleu": 26.672858646811953,
      "eval_gen_len": 27.468,
      "eval_loss": 2.8159687519073486,
      "eval_runtime": 58.011,
      "eval_samples_per_second": 17.238,
      "eval_steps_per_second": 1.086,
      "step": 15550
    },
    {
      "epoch": 0.6697081862787294,
      "grad_norm": 0.8749781250953674,
      "learning_rate": 0.0001810516524997405,
      "loss": 3.1276,
      "step": 15560
    },
    {
      "epoch": 0.6701385899974176,
      "grad_norm": 1.0006123781204224,
      "learning_rate": 0.0001810244276530859,
      "loss": 3.0875,
      "step": 15570
    },
    {
      "epoch": 0.6705689937161057,
      "grad_norm": 0.9224953651428223,
      "learning_rate": 0.00018099718531224142,
      "loss": 3.1312,
      "step": 15580
    },
    {
      "epoch": 0.6709993974347939,
      "grad_norm": 0.941916823387146,
      "learning_rate": 0.00018096992548308894,
      "loss": 3.1026,
      "step": 15590
    },
    {
      "epoch": 0.6714298011534819,
      "grad_norm": 1.0079299211502075,
      "learning_rate": 0.0001809426481715142,
      "loss": 3.1315,
      "step": 15600
    },
    {
      "epoch": 0.6714298011534819,
      "eval_bleu": 26.497792176151123,
      "eval_gen_len": 27.581,
      "eval_loss": 2.811889171600342,
      "eval_runtime": 58.585,
      "eval_samples_per_second": 17.069,
      "eval_steps_per_second": 1.075,
      "step": 15600
    },
    {
      "epoch": 0.6718602048721701,
      "grad_norm": 1.0000841617584229,
      "learning_rate": 0.00018091535338340674,
      "loss": 3.066,
      "step": 15610
    },
    {
      "epoch": 0.6722906085908582,
      "grad_norm": 0.8358224630355835,
      "learning_rate": 0.00018088804112465984,
      "loss": 3.0857,
      "step": 15620
    },
    {
      "epoch": 0.6727210123095464,
      "grad_norm": 0.9355760812759399,
      "learning_rate": 0.00018086071140117058,
      "loss": 3.1365,
      "step": 15630
    },
    {
      "epoch": 0.6731514160282345,
      "grad_norm": 0.9930720925331116,
      "learning_rate": 0.00018083336421883975,
      "loss": 3.0753,
      "step": 15640
    },
    {
      "epoch": 0.6735818197469227,
      "grad_norm": 1.0178401470184326,
      "learning_rate": 0.00018080599958357195,
      "loss": 3.1745,
      "step": 15650
    },
    {
      "epoch": 0.6735818197469227,
      "eval_bleu": 26.23470911894367,
      "eval_gen_len": 27.368,
      "eval_loss": 2.8160855770111084,
      "eval_runtime": 58.0657,
      "eval_samples_per_second": 17.222,
      "eval_steps_per_second": 1.085,
      "step": 15650
    },
    {
      "epoch": 0.6740122234656107,
      "grad_norm": 0.9086315631866455,
      "learning_rate": 0.00018077861750127557,
      "loss": 3.0981,
      "step": 15660
    },
    {
      "epoch": 0.6744426271842989,
      "grad_norm": 0.8826108574867249,
      "learning_rate": 0.00018075121797786272,
      "loss": 3.1504,
      "step": 15670
    },
    {
      "epoch": 0.674873030902987,
      "grad_norm": 0.9231064915657043,
      "learning_rate": 0.00018072380101924934,
      "loss": 3.1045,
      "step": 15680
    },
    {
      "epoch": 0.6753034346216751,
      "grad_norm": 0.9463726878166199,
      "learning_rate": 0.0001806963666313551,
      "loss": 3.0452,
      "step": 15690
    },
    {
      "epoch": 0.6757338383403633,
      "grad_norm": 0.9121786952018738,
      "learning_rate": 0.00018066891482010336,
      "loss": 2.979,
      "step": 15700
    },
    {
      "epoch": 0.6757338383403633,
      "eval_bleu": 25.85931964950766,
      "eval_gen_len": 27.431,
      "eval_loss": 2.8244411945343018,
      "eval_runtime": 57.9588,
      "eval_samples_per_second": 17.254,
      "eval_steps_per_second": 1.087,
      "step": 15700
    },
    {
      "epoch": 0.6761642420590513,
      "grad_norm": 0.8328373432159424,
      "learning_rate": 0.00018064144559142137,
      "loss": 3.1126,
      "step": 15710
    },
    {
      "epoch": 0.6765946457777395,
      "grad_norm": 0.7734793424606323,
      "learning_rate": 0.0001806139589512401,
      "loss": 3.0312,
      "step": 15720
    },
    {
      "epoch": 0.6770250494964276,
      "grad_norm": 0.9976523518562317,
      "learning_rate": 0.00018058645490549418,
      "loss": 3.1612,
      "step": 15730
    },
    {
      "epoch": 0.6774554532151158,
      "grad_norm": 0.9433070421218872,
      "learning_rate": 0.00018055893346012215,
      "loss": 3.0774,
      "step": 15740
    },
    {
      "epoch": 0.6778858569338039,
      "grad_norm": 0.8523299694061279,
      "learning_rate": 0.00018053139462106618,
      "loss": 3.1145,
      "step": 15750
    },
    {
      "epoch": 0.6778858569338039,
      "eval_bleu": 26.72852864437654,
      "eval_gen_len": 27.595,
      "eval_loss": 2.812734365463257,
      "eval_runtime": 58.6032,
      "eval_samples_per_second": 17.064,
      "eval_steps_per_second": 1.075,
      "step": 15750
    },
    {
      "epoch": 0.6783162606524921,
      "grad_norm": 0.9632008075714111,
      "learning_rate": 0.0001805038383942723,
      "loss": 3.1922,
      "step": 15760
    },
    {
      "epoch": 0.6787466643711801,
      "grad_norm": 0.9092721939086914,
      "learning_rate": 0.00018047626478569023,
      "loss": 3.1015,
      "step": 15770
    },
    {
      "epoch": 0.6791770680898683,
      "grad_norm": 0.9770941138267517,
      "learning_rate": 0.00018044867380127345,
      "loss": 3.1348,
      "step": 15780
    },
    {
      "epoch": 0.6796074718085564,
      "grad_norm": 0.8574297428131104,
      "learning_rate": 0.00018042106544697916,
      "loss": 3.1282,
      "step": 15790
    },
    {
      "epoch": 0.6800378755272446,
      "grad_norm": 0.9238321781158447,
      "learning_rate": 0.00018039343972876845,
      "loss": 3.11,
      "step": 15800
    },
    {
      "epoch": 0.6800378755272446,
      "eval_bleu": 26.060088607855196,
      "eval_gen_len": 27.412,
      "eval_loss": 2.819685697555542,
      "eval_runtime": 58.4387,
      "eval_samples_per_second": 17.112,
      "eval_steps_per_second": 1.078,
      "step": 15800
    },
    {
      "epoch": 0.6804682792459327,
      "grad_norm": 1.0236490964889526,
      "learning_rate": 0.00018036579665260596,
      "loss": 3.1176,
      "step": 15810
    },
    {
      "epoch": 0.6808986829646209,
      "grad_norm": 0.8416922688484192,
      "learning_rate": 0.00018033813622446023,
      "loss": 3.0582,
      "step": 15820
    },
    {
      "epoch": 0.6813290866833089,
      "grad_norm": 0.8851177096366882,
      "learning_rate": 0.00018031045845030348,
      "loss": 3.0655,
      "step": 15830
    },
    {
      "epoch": 0.6817594904019971,
      "grad_norm": 1.053815484046936,
      "learning_rate": 0.00018028276333611167,
      "loss": 3.1993,
      "step": 15840
    },
    {
      "epoch": 0.6821898941206852,
      "grad_norm": 0.9078363180160522,
      "learning_rate": 0.00018025505088786458,
      "loss": 3.1011,
      "step": 15850
    },
    {
      "epoch": 0.6821898941206852,
      "eval_bleu": 26.27620648274495,
      "eval_gen_len": 27.491,
      "eval_loss": 2.817899227142334,
      "eval_runtime": 58.4036,
      "eval_samples_per_second": 17.122,
      "eval_steps_per_second": 1.079,
      "step": 15850
    },
    {
      "epoch": 0.6826202978393733,
      "grad_norm": 0.8247270584106445,
      "learning_rate": 0.00018022732111154562,
      "loss": 3.0676,
      "step": 15860
    },
    {
      "epoch": 0.6830507015580615,
      "grad_norm": 0.9225106835365295,
      "learning_rate": 0.000180199574013142,
      "loss": 3.2038,
      "step": 15870
    },
    {
      "epoch": 0.6834811052767495,
      "grad_norm": 0.8132544755935669,
      "learning_rate": 0.0001801718095986447,
      "loss": 2.9622,
      "step": 15880
    },
    {
      "epoch": 0.6839115089954377,
      "grad_norm": 0.8639751076698303,
      "learning_rate": 0.00018014402787404837,
      "loss": 3.1213,
      "step": 15890
    },
    {
      "epoch": 0.6843419127141258,
      "grad_norm": 0.9326210021972656,
      "learning_rate": 0.00018011622884535144,
      "loss": 3.0914,
      "step": 15900
    },
    {
      "epoch": 0.6843419127141258,
      "eval_bleu": 26.633760495698137,
      "eval_gen_len": 27.527,
      "eval_loss": 2.8133058547973633,
      "eval_runtime": 57.8367,
      "eval_samples_per_second": 17.29,
      "eval_steps_per_second": 1.089,
      "step": 15900
    },
    {
      "epoch": 0.684772316432814,
      "grad_norm": 0.9187031984329224,
      "learning_rate": 0.0001800884125185561,
      "loss": 3.0809,
      "step": 15910
    },
    {
      "epoch": 0.6852027201515021,
      "grad_norm": 0.8825398683547974,
      "learning_rate": 0.0001800605788996682,
      "loss": 3.0445,
      "step": 15920
    },
    {
      "epoch": 0.6856331238701903,
      "grad_norm": 0.9177283644676208,
      "learning_rate": 0.0001800327279946974,
      "loss": 3.1371,
      "step": 15930
    },
    {
      "epoch": 0.6860635275888783,
      "grad_norm": 0.8493064641952515,
      "learning_rate": 0.00018000485980965703,
      "loss": 3.0103,
      "step": 15940
    },
    {
      "epoch": 0.6864939313075665,
      "grad_norm": 0.9188804626464844,
      "learning_rate": 0.0001799769743505642,
      "loss": 3.1189,
      "step": 15950
    },
    {
      "epoch": 0.6864939313075665,
      "eval_bleu": 26.4759986484377,
      "eval_gen_len": 27.362,
      "eval_loss": 2.8165462017059326,
      "eval_runtime": 57.6835,
      "eval_samples_per_second": 17.336,
      "eval_steps_per_second": 1.092,
      "step": 15950
    },
    {
      "epoch": 0.6869243350262546,
      "grad_norm": 0.8772609829902649,
      "learning_rate": 0.00017994907162343973,
      "loss": 3.0449,
      "step": 15960
    },
    {
      "epoch": 0.6873547387449428,
      "grad_norm": 0.8984400629997253,
      "learning_rate": 0.00017992115163430818,
      "loss": 3.0776,
      "step": 15970
    },
    {
      "epoch": 0.6877851424636309,
      "grad_norm": 0.8555580973625183,
      "learning_rate": 0.0001798932143891978,
      "loss": 3.0676,
      "step": 15980
    },
    {
      "epoch": 0.6882155461823191,
      "grad_norm": 0.9189282059669495,
      "learning_rate": 0.0001798652598941406,
      "loss": 3.1528,
      "step": 15990
    },
    {
      "epoch": 0.6886459499010071,
      "grad_norm": 0.8786725401878357,
      "learning_rate": 0.00017983728815517232,
      "loss": 3.0138,
      "step": 16000
    },
    {
      "epoch": 0.6886459499010071,
      "eval_bleu": 26.117386818798977,
      "eval_gen_len": 27.423,
      "eval_loss": 2.8182106018066406,
      "eval_runtime": 58.1072,
      "eval_samples_per_second": 17.21,
      "eval_steps_per_second": 1.084,
      "step": 16000
    },
    {
      "epoch": 0.6890763536196953,
      "grad_norm": 0.9467384219169617,
      "learning_rate": 0.0001798092991783324,
      "loss": 3.1622,
      "step": 16010
    },
    {
      "epoch": 0.6895067573383834,
      "grad_norm": 0.9503769874572754,
      "learning_rate": 0.00017978129296966402,
      "loss": 3.163,
      "step": 16020
    },
    {
      "epoch": 0.6899371610570715,
      "grad_norm": 0.8933273553848267,
      "learning_rate": 0.00017975326953521402,
      "loss": 3.0574,
      "step": 16030
    },
    {
      "epoch": 0.6903675647757597,
      "grad_norm": 0.9159904718399048,
      "learning_rate": 0.00017972522888103312,
      "loss": 3.1043,
      "step": 16040
    },
    {
      "epoch": 0.6907979684944477,
      "grad_norm": 0.8643025755882263,
      "learning_rate": 0.00017969717101317553,
      "loss": 2.992,
      "step": 16050
    },
    {
      "epoch": 0.6907979684944477,
      "eval_bleu": 26.381253613420903,
      "eval_gen_len": 27.507,
      "eval_loss": 2.8207550048828125,
      "eval_runtime": 57.9108,
      "eval_samples_per_second": 17.268,
      "eval_steps_per_second": 1.088,
      "step": 16050
    },
    {
      "epoch": 0.6912283722131359,
      "grad_norm": 0.9751484990119934,
      "learning_rate": 0.00017966909593769933,
      "loss": 3.0536,
      "step": 16060
    },
    {
      "epoch": 0.691658775931824,
      "grad_norm": 1.0053596496582031,
      "learning_rate": 0.00017964100366066633,
      "loss": 3.1267,
      "step": 16070
    },
    {
      "epoch": 0.6920891796505122,
      "grad_norm": 0.8205652236938477,
      "learning_rate": 0.000179612894188142,
      "loss": 3.0241,
      "step": 16080
    },
    {
      "epoch": 0.6925195833692003,
      "grad_norm": 0.8826799988746643,
      "learning_rate": 0.00017958476752619545,
      "loss": 3.0401,
      "step": 16090
    },
    {
      "epoch": 0.6929499870878885,
      "grad_norm": 0.8090205788612366,
      "learning_rate": 0.00017955662368089964,
      "loss": 3.123,
      "step": 16100
    },
    {
      "epoch": 0.6929499870878885,
      "eval_bleu": 26.34613943597302,
      "eval_gen_len": 27.496,
      "eval_loss": 2.8147573471069336,
      "eval_runtime": 57.9508,
      "eval_samples_per_second": 17.256,
      "eval_steps_per_second": 1.087,
      "step": 16100
    },
    {
      "epoch": 0.6933803908065765,
      "grad_norm": 0.9292753338813782,
      "learning_rate": 0.00017952846265833122,
      "loss": 3.157,
      "step": 16110
    },
    {
      "epoch": 0.6938107945252647,
      "grad_norm": 0.9520556330680847,
      "learning_rate": 0.0001795002844645704,
      "loss": 3.0865,
      "step": 16120
    },
    {
      "epoch": 0.6942411982439528,
      "grad_norm": 0.9839298129081726,
      "learning_rate": 0.00017947208910570127,
      "loss": 3.0824,
      "step": 16130
    },
    {
      "epoch": 0.694671601962641,
      "grad_norm": 0.9370334148406982,
      "learning_rate": 0.00017944387658781153,
      "loss": 3.0982,
      "step": 16140
    },
    {
      "epoch": 0.6951020056813291,
      "grad_norm": 0.9420077800750732,
      "learning_rate": 0.00017941564691699267,
      "loss": 2.9679,
      "step": 16150
    },
    {
      "epoch": 0.6951020056813291,
      "eval_bleu": 26.587685119312773,
      "eval_gen_len": 27.378,
      "eval_loss": 2.8152050971984863,
      "eval_runtime": 58.2868,
      "eval_samples_per_second": 17.157,
      "eval_steps_per_second": 1.081,
      "step": 16150
    },
    {
      "epoch": 0.6955324094000173,
      "grad_norm": 0.942357063293457,
      "learning_rate": 0.00017938740009933982,
      "loss": 3.0859,
      "step": 16160
    },
    {
      "epoch": 0.6959628131187053,
      "grad_norm": 0.8681102991104126,
      "learning_rate": 0.00017935913614095176,
      "loss": 2.981,
      "step": 16170
    },
    {
      "epoch": 0.6963932168373935,
      "grad_norm": 0.8939318656921387,
      "learning_rate": 0.0001793308550479311,
      "loss": 3.127,
      "step": 16180
    },
    {
      "epoch": 0.6968236205560816,
      "grad_norm": 0.8972680568695068,
      "learning_rate": 0.00017930255682638407,
      "loss": 3.0767,
      "step": 16190
    },
    {
      "epoch": 0.6972540242747697,
      "grad_norm": 0.8987353444099426,
      "learning_rate": 0.00017927424148242053,
      "loss": 3.0503,
      "step": 16200
    },
    {
      "epoch": 0.6972540242747697,
      "eval_bleu": 26.68012776280551,
      "eval_gen_len": 27.356,
      "eval_loss": 2.8122565746307373,
      "eval_runtime": 57.9722,
      "eval_samples_per_second": 17.25,
      "eval_steps_per_second": 1.087,
      "step": 16200
    },
    {
      "epoch": 0.6976844279934579,
      "grad_norm": 0.9333630800247192,
      "learning_rate": 0.00017924590902215426,
      "loss": 3.094,
      "step": 16210
    },
    {
      "epoch": 0.698114831712146,
      "grad_norm": 0.9145109057426453,
      "learning_rate": 0.00017921755945170248,
      "loss": 3.0687,
      "step": 16220
    },
    {
      "epoch": 0.6985452354308341,
      "grad_norm": 0.8624247312545776,
      "learning_rate": 0.00017918919277718626,
      "loss": 3.1001,
      "step": 16230
    },
    {
      "epoch": 0.6989756391495222,
      "grad_norm": 0.8528456091880798,
      "learning_rate": 0.00017916080900473035,
      "loss": 3.0594,
      "step": 16240
    },
    {
      "epoch": 0.6994060428682104,
      "grad_norm": 0.8227938413619995,
      "learning_rate": 0.0001791324081404631,
      "loss": 3.0925,
      "step": 16250
    },
    {
      "epoch": 0.6994060428682104,
      "eval_bleu": 26.761633934062043,
      "eval_gen_len": 27.526,
      "eval_loss": 2.817765235900879,
      "eval_runtime": 58.3922,
      "eval_samples_per_second": 17.126,
      "eval_steps_per_second": 1.079,
      "step": 16250
    },
    {
      "epoch": 0.6998364465868985,
      "grad_norm": 0.8625863790512085,
      "learning_rate": 0.00017910399019051667,
      "loss": 3.1437,
      "step": 16260
    },
    {
      "epoch": 0.7002668503055867,
      "grad_norm": 0.855749785900116,
      "learning_rate": 0.0001790755551610268,
      "loss": 3.0895,
      "step": 16270
    },
    {
      "epoch": 0.7006972540242747,
      "grad_norm": 0.9404522776603699,
      "learning_rate": 0.00017904710305813299,
      "loss": 3.0357,
      "step": 16280
    },
    {
      "epoch": 0.7011276577429629,
      "grad_norm": 0.8813808560371399,
      "learning_rate": 0.0001790186338879784,
      "loss": 3.0583,
      "step": 16290
    },
    {
      "epoch": 0.701558061461651,
      "grad_norm": 0.8680629134178162,
      "learning_rate": 0.0001789901476567099,
      "loss": 3.065,
      "step": 16300
    },
    {
      "epoch": 0.701558061461651,
      "eval_bleu": 26.556756197107322,
      "eval_gen_len": 27.359,
      "eval_loss": 2.814749002456665,
      "eval_runtime": 58.2374,
      "eval_samples_per_second": 17.171,
      "eval_steps_per_second": 1.082,
      "step": 16300
    },
    {
      "epoch": 0.7019884651803392,
      "grad_norm": 0.9171344041824341,
      "learning_rate": 0.00017896164437047806,
      "loss": 3.1055,
      "step": 16310
    },
    {
      "epoch": 0.7024188688990273,
      "grad_norm": 0.8977063894271851,
      "learning_rate": 0.000178933124035437,
      "loss": 3.1301,
      "step": 16320
    },
    {
      "epoch": 0.7028492726177155,
      "grad_norm": 0.7878223061561584,
      "learning_rate": 0.0001789045866577447,
      "loss": 3.0842,
      "step": 16330
    },
    {
      "epoch": 0.7032796763364035,
      "grad_norm": 1.0018607378005981,
      "learning_rate": 0.0001788760322435627,
      "loss": 3.061,
      "step": 16340
    },
    {
      "epoch": 0.7037100800550917,
      "grad_norm": 0.9100384712219238,
      "learning_rate": 0.00017884746079905626,
      "loss": 3.0251,
      "step": 16350
    },
    {
      "epoch": 0.7037100800550917,
      "eval_bleu": 26.496948279304362,
      "eval_gen_len": 27.274,
      "eval_loss": 2.814091682434082,
      "eval_runtime": 57.4647,
      "eval_samples_per_second": 17.402,
      "eval_steps_per_second": 1.096,
      "step": 16350
    },
    {
      "epoch": 0.7041404837737798,
      "grad_norm": 0.9154542088508606,
      "learning_rate": 0.00017881887233039433,
      "loss": 3.1626,
      "step": 16360
    },
    {
      "epoch": 0.704570887492468,
      "grad_norm": 0.9863870739936829,
      "learning_rate": 0.00017879026684374948,
      "loss": 3.1661,
      "step": 16370
    },
    {
      "epoch": 0.7050012912111561,
      "grad_norm": 0.9777681827545166,
      "learning_rate": 0.00017876164434529803,
      "loss": 3.0663,
      "step": 16380
    },
    {
      "epoch": 0.7054316949298441,
      "grad_norm": 0.9946035146713257,
      "learning_rate": 0.00017873300484121994,
      "loss": 3.1119,
      "step": 16390
    },
    {
      "epoch": 0.7058620986485323,
      "grad_norm": 0.8887955546379089,
      "learning_rate": 0.0001787043483376988,
      "loss": 3.0512,
      "step": 16400
    },
    {
      "epoch": 0.7058620986485323,
      "eval_bleu": 26.642318693310106,
      "eval_gen_len": 27.565,
      "eval_loss": 2.817533254623413,
      "eval_runtime": 58.2986,
      "eval_samples_per_second": 17.153,
      "eval_steps_per_second": 1.081,
      "step": 16400
    },
    {
      "epoch": 0.7062925023672204,
      "grad_norm": 0.9156551361083984,
      "learning_rate": 0.00017867567484092196,
      "loss": 3.0296,
      "step": 16410
    },
    {
      "epoch": 0.7067229060859086,
      "grad_norm": 0.9747077822685242,
      "learning_rate": 0.00017864698435708033,
      "loss": 3.104,
      "step": 16420
    },
    {
      "epoch": 0.7071533098045967,
      "grad_norm": 0.8748925924301147,
      "learning_rate": 0.0001786182768923686,
      "loss": 3.2112,
      "step": 16430
    },
    {
      "epoch": 0.7075837135232849,
      "grad_norm": 1.052920937538147,
      "learning_rate": 0.00017858955245298502,
      "loss": 3.0656,
      "step": 16440
    },
    {
      "epoch": 0.7080141172419729,
      "grad_norm": 0.9961444139480591,
      "learning_rate": 0.0001785608110451316,
      "loss": 3.1304,
      "step": 16450
    },
    {
      "epoch": 0.7080141172419729,
      "eval_bleu": 26.35128254965227,
      "eval_gen_len": 27.312,
      "eval_loss": 2.8205270767211914,
      "eval_runtime": 57.9038,
      "eval_samples_per_second": 17.27,
      "eval_steps_per_second": 1.088,
      "step": 16450
    },
    {
      "epoch": 0.7084445209606611,
      "grad_norm": 0.9141892790794373,
      "learning_rate": 0.00017853205267501397,
      "loss": 3.0892,
      "step": 16460
    },
    {
      "epoch": 0.7088749246793492,
      "grad_norm": 0.7994264960289001,
      "learning_rate": 0.00017850327734884137,
      "loss": 3.1201,
      "step": 16470
    },
    {
      "epoch": 0.7093053283980374,
      "grad_norm": 0.9271587133407593,
      "learning_rate": 0.0001784744850728268,
      "loss": 3.0905,
      "step": 16480
    },
    {
      "epoch": 0.7097357321167255,
      "grad_norm": 0.936945915222168,
      "learning_rate": 0.00017844567585318687,
      "loss": 3.2005,
      "step": 16490
    },
    {
      "epoch": 0.7101661358354137,
      "grad_norm": 0.8719211220741272,
      "learning_rate": 0.00017841684969614185,
      "loss": 3.0676,
      "step": 16500
    },
    {
      "epoch": 0.7101661358354137,
      "eval_bleu": 25.715753884986356,
      "eval_gen_len": 27.416,
      "eval_loss": 2.821840763092041,
      "eval_runtime": 57.7081,
      "eval_samples_per_second": 17.329,
      "eval_steps_per_second": 1.092,
      "step": 16500
    },
    {
      "epoch": 0.7105965395541017,
      "grad_norm": 0.8971794247627258,
      "learning_rate": 0.00017838800660791566,
      "loss": 3.0491,
      "step": 16510
    },
    {
      "epoch": 0.7110269432727899,
      "grad_norm": 0.8918379545211792,
      "learning_rate": 0.0001783591465947359,
      "loss": 3.0255,
      "step": 16520
    },
    {
      "epoch": 0.711457346991478,
      "grad_norm": 0.8783791065216064,
      "learning_rate": 0.00017833026966283377,
      "loss": 3.0814,
      "step": 16530
    },
    {
      "epoch": 0.7118877507101662,
      "grad_norm": 0.8972482681274414,
      "learning_rate": 0.0001783013758184442,
      "loss": 3.0766,
      "step": 16540
    },
    {
      "epoch": 0.7123181544288543,
      "grad_norm": 0.9513424038887024,
      "learning_rate": 0.00017827246506780573,
      "loss": 3.0573,
      "step": 16550
    },
    {
      "epoch": 0.7123181544288543,
      "eval_bleu": 25.953267735048996,
      "eval_gen_len": 27.263,
      "eval_loss": 2.820291519165039,
      "eval_runtime": 57.6102,
      "eval_samples_per_second": 17.358,
      "eval_steps_per_second": 1.094,
      "step": 16550
    },
    {
      "epoch": 0.7127485581475423,
      "grad_norm": 0.9770433306694031,
      "learning_rate": 0.00017824353741716054,
      "loss": 3.1033,
      "step": 16560
    },
    {
      "epoch": 0.7131789618662305,
      "grad_norm": 0.837787389755249,
      "learning_rate": 0.00017821459287275447,
      "loss": 3.0414,
      "step": 16570
    },
    {
      "epoch": 0.7136093655849186,
      "grad_norm": 0.8405433297157288,
      "learning_rate": 0.00017818563144083704,
      "loss": 3.0859,
      "step": 16580
    },
    {
      "epoch": 0.7140397693036068,
      "grad_norm": 0.9330837726593018,
      "learning_rate": 0.00017815665312766134,
      "loss": 3.0848,
      "step": 16590
    },
    {
      "epoch": 0.7144701730222949,
      "grad_norm": 0.9828150868415833,
      "learning_rate": 0.0001781276579394842,
      "loss": 3.2228,
      "step": 16600
    },
    {
      "epoch": 0.7144701730222949,
      "eval_bleu": 26.255511648306893,
      "eval_gen_len": 27.413,
      "eval_loss": 2.8151400089263916,
      "eval_runtime": 58.1572,
      "eval_samples_per_second": 17.195,
      "eval_steps_per_second": 1.083,
      "step": 16600
    },
    {
      "epoch": 0.7149005767409831,
      "grad_norm": 1.0028208494186401,
      "learning_rate": 0.000178098645882566,
      "loss": 3.086,
      "step": 16610
    },
    {
      "epoch": 0.7153309804596711,
      "grad_norm": 0.9082738757133484,
      "learning_rate": 0.00017806961696317087,
      "loss": 3.1104,
      "step": 16620
    },
    {
      "epoch": 0.7157613841783593,
      "grad_norm": 0.8518376350402832,
      "learning_rate": 0.00017804057118756643,
      "loss": 3.0986,
      "step": 16630
    },
    {
      "epoch": 0.7161917878970474,
      "grad_norm": 0.959732711315155,
      "learning_rate": 0.00017801150856202406,
      "loss": 3.0443,
      "step": 16640
    },
    {
      "epoch": 0.7166221916157356,
      "grad_norm": 1.0428920984268188,
      "learning_rate": 0.0001779824290928188,
      "loss": 3.0686,
      "step": 16650
    },
    {
      "epoch": 0.7166221916157356,
      "eval_bleu": 25.94275174623422,
      "eval_gen_len": 27.466,
      "eval_loss": 2.8129584789276123,
      "eval_runtime": 58.4009,
      "eval_samples_per_second": 17.123,
      "eval_steps_per_second": 1.079,
      "step": 16650
    },
    {
      "epoch": 0.7170525953344237,
      "grad_norm": 0.7800912857055664,
      "learning_rate": 0.00017795333278622922,
      "loss": 3.1032,
      "step": 16660
    },
    {
      "epoch": 0.7174829990531119,
      "grad_norm": 1.0563578605651855,
      "learning_rate": 0.00017792421964853757,
      "loss": 3.1144,
      "step": 16670
    },
    {
      "epoch": 0.7179134027717999,
      "grad_norm": 0.9276536703109741,
      "learning_rate": 0.00017789508968602978,
      "loss": 3.0884,
      "step": 16680
    },
    {
      "epoch": 0.7183438064904881,
      "grad_norm": 1.172382116317749,
      "learning_rate": 0.00017786594290499533,
      "loss": 3.0194,
      "step": 16690
    },
    {
      "epoch": 0.7187742102091762,
      "grad_norm": 0.9082244634628296,
      "learning_rate": 0.0001778367793117274,
      "loss": 3.072,
      "step": 16700
    },
    {
      "epoch": 0.7187742102091762,
      "eval_bleu": 25.96950585326834,
      "eval_gen_len": 27.405,
      "eval_loss": 2.8141090869903564,
      "eval_runtime": 58.4356,
      "eval_samples_per_second": 17.113,
      "eval_steps_per_second": 1.078,
      "step": 16700
    },
    {
      "epoch": 0.7192046139278644,
      "grad_norm": 0.9599907994270325,
      "learning_rate": 0.00017780759891252278,
      "loss": 3.129,
      "step": 16710
    },
    {
      "epoch": 0.7196350176465525,
      "grad_norm": 0.864025890827179,
      "learning_rate": 0.00017777840171368187,
      "loss": 3.09,
      "step": 16720
    },
    {
      "epoch": 0.7200654213652405,
      "grad_norm": 0.9210453033447266,
      "learning_rate": 0.00017774918772150872,
      "loss": 3.0462,
      "step": 16730
    },
    {
      "epoch": 0.7204958250839287,
      "grad_norm": 0.8548815846443176,
      "learning_rate": 0.00017771995694231102,
      "loss": 3.1352,
      "step": 16740
    },
    {
      "epoch": 0.7209262288026168,
      "grad_norm": 0.7891044020652771,
      "learning_rate": 0.00017769070938240003,
      "loss": 3.1832,
      "step": 16750
    },
    {
      "epoch": 0.7209262288026168,
      "eval_bleu": 25.466375983168202,
      "eval_gen_len": 27.524,
      "eval_loss": 2.8225204944610596,
      "eval_runtime": 58.4255,
      "eval_samples_per_second": 17.116,
      "eval_steps_per_second": 1.078,
      "step": 16750
    },
    {
      "epoch": 0.721356632521305,
      "grad_norm": 0.8294369578361511,
      "learning_rate": 0.00017766144504809068,
      "loss": 3.1001,
      "step": 16760
    },
    {
      "epoch": 0.7217870362399931,
      "grad_norm": 1.076407790184021,
      "learning_rate": 0.0001776321639457015,
      "loss": 3.1428,
      "step": 16770
    },
    {
      "epoch": 0.7222174399586813,
      "grad_norm": 0.7989675402641296,
      "learning_rate": 0.0001776028660815546,
      "loss": 3.1784,
      "step": 16780
    },
    {
      "epoch": 0.7226478436773693,
      "grad_norm": 0.8436287641525269,
      "learning_rate": 0.00017757355146197584,
      "loss": 3.0765,
      "step": 16790
    },
    {
      "epoch": 0.7230782473960575,
      "grad_norm": 0.910770833492279,
      "learning_rate": 0.00017754422009329458,
      "loss": 3.0791,
      "step": 16800
    },
    {
      "epoch": 0.7230782473960575,
      "eval_bleu": 26.353316053745754,
      "eval_gen_len": 27.408,
      "eval_loss": 2.80971360206604,
      "eval_runtime": 58.0139,
      "eval_samples_per_second": 17.237,
      "eval_steps_per_second": 1.086,
      "step": 16800
    },
    {
      "epoch": 0.7235086511147456,
      "grad_norm": 0.9403042793273926,
      "learning_rate": 0.00017751487198184384,
      "loss": 3.0814,
      "step": 16810
    },
    {
      "epoch": 0.7239390548334338,
      "grad_norm": 0.8414732813835144,
      "learning_rate": 0.0001774855071339602,
      "loss": 3.0437,
      "step": 16820
    },
    {
      "epoch": 0.7243694585521219,
      "grad_norm": 0.9273107051849365,
      "learning_rate": 0.00017745612555598395,
      "loss": 3.0843,
      "step": 16830
    },
    {
      "epoch": 0.7247998622708101,
      "grad_norm": 0.9111921191215515,
      "learning_rate": 0.0001774267272542589,
      "loss": 3.0501,
      "step": 16840
    },
    {
      "epoch": 0.7252302659894981,
      "grad_norm": 0.9195778369903564,
      "learning_rate": 0.0001773973122351326,
      "loss": 3.0093,
      "step": 16850
    },
    {
      "epoch": 0.7252302659894981,
      "eval_bleu": 26.240796786329874,
      "eval_gen_len": 27.406,
      "eval_loss": 2.822253942489624,
      "eval_runtime": 57.9773,
      "eval_samples_per_second": 17.248,
      "eval_steps_per_second": 1.087,
      "step": 16850
    },
    {
      "epoch": 0.7256606697081863,
      "grad_norm": 1.0211204290390015,
      "learning_rate": 0.00017736788050495597,
      "loss": 3.1274,
      "step": 16860
    },
    {
      "epoch": 0.7260910734268744,
      "grad_norm": 0.9507011771202087,
      "learning_rate": 0.00017733843207008381,
      "loss": 3.1295,
      "step": 16870
    },
    {
      "epoch": 0.7265214771455626,
      "grad_norm": 0.9653699994087219,
      "learning_rate": 0.0001773089669368744,
      "loss": 3.1215,
      "step": 16880
    },
    {
      "epoch": 0.7269518808642507,
      "grad_norm": 0.9753057956695557,
      "learning_rate": 0.00017727948511168958,
      "loss": 3.1284,
      "step": 16890
    },
    {
      "epoch": 0.7273822845829387,
      "grad_norm": 0.9200213551521301,
      "learning_rate": 0.00017724998660089488,
      "loss": 3.2187,
      "step": 16900
    },
    {
      "epoch": 0.7273822845829387,
      "eval_bleu": 25.960634181860076,
      "eval_gen_len": 27.34,
      "eval_loss": 2.816554307937622,
      "eval_runtime": 57.3976,
      "eval_samples_per_second": 17.422,
      "eval_steps_per_second": 1.098,
      "step": 16900
    },
    {
      "epoch": 0.7278126883016269,
      "grad_norm": 0.9445805549621582,
      "learning_rate": 0.00017722047141085936,
      "loss": 3.0192,
      "step": 16910
    },
    {
      "epoch": 0.728243092020315,
      "grad_norm": 0.8034295439720154,
      "learning_rate": 0.0001771909395479558,
      "loss": 3.2681,
      "step": 16920
    },
    {
      "epoch": 0.7286734957390032,
      "grad_norm": 0.9220972657203674,
      "learning_rate": 0.00017716139101856042,
      "loss": 3.0207,
      "step": 16930
    },
    {
      "epoch": 0.7291038994576913,
      "grad_norm": 0.9394607543945312,
      "learning_rate": 0.0001771318258290531,
      "loss": 3.0122,
      "step": 16940
    },
    {
      "epoch": 0.7295343031763795,
      "grad_norm": 0.8172647356987,
      "learning_rate": 0.00017710224398581742,
      "loss": 3.0448,
      "step": 16950
    },
    {
      "epoch": 0.7295343031763795,
      "eval_bleu": 25.760777791331417,
      "eval_gen_len": 27.301,
      "eval_loss": 2.817728042602539,
      "eval_runtime": 57.6248,
      "eval_samples_per_second": 17.354,
      "eval_steps_per_second": 1.093,
      "step": 16950
    },
    {
      "epoch": 0.7299647068950675,
      "grad_norm": 0.9643159508705139,
      "learning_rate": 0.00017707264549524044,
      "loss": 3.1019,
      "step": 16960
    },
    {
      "epoch": 0.7303951106137557,
      "grad_norm": 0.8662776350975037,
      "learning_rate": 0.00017704303036371287,
      "loss": 3.1073,
      "step": 16970
    },
    {
      "epoch": 0.7308255143324438,
      "grad_norm": 0.8374319076538086,
      "learning_rate": 0.00017701339859762892,
      "loss": 3.1347,
      "step": 16980
    },
    {
      "epoch": 0.731255918051132,
      "grad_norm": 0.8641972541809082,
      "learning_rate": 0.00017698375020338647,
      "loss": 3.0564,
      "step": 16990
    },
    {
      "epoch": 0.7316863217698201,
      "grad_norm": 0.939686119556427,
      "learning_rate": 0.00017695408518738704,
      "loss": 3.1025,
      "step": 17000
    },
    {
      "epoch": 0.7316863217698201,
      "eval_bleu": 26.206073044917158,
      "eval_gen_len": 27.282,
      "eval_loss": 2.8155603408813477,
      "eval_runtime": 57.4002,
      "eval_samples_per_second": 17.422,
      "eval_steps_per_second": 1.098,
      "step": 17000
    },
    {
      "epoch": 0.7321167254885083,
      "grad_norm": 1.0358599424362183,
      "learning_rate": 0.0001769244035560356,
      "loss": 3.1224,
      "step": 17010
    },
    {
      "epoch": 0.7325471292071963,
      "grad_norm": 0.8469325304031372,
      "learning_rate": 0.00017689470531574085,
      "loss": 3.0521,
      "step": 17020
    },
    {
      "epoch": 0.7329775329258845,
      "grad_norm": 0.9766533970832825,
      "learning_rate": 0.00017686499047291502,
      "loss": 3.0333,
      "step": 17030
    },
    {
      "epoch": 0.7334079366445726,
      "grad_norm": 0.8453407883644104,
      "learning_rate": 0.00017683525903397387,
      "loss": 3.0021,
      "step": 17040
    },
    {
      "epoch": 0.7338383403632608,
      "grad_norm": 0.9265643358230591,
      "learning_rate": 0.00017680551100533683,
      "loss": 3.0982,
      "step": 17050
    },
    {
      "epoch": 0.7338383403632608,
      "eval_bleu": 26.343917432169995,
      "eval_gen_len": 27.307,
      "eval_loss": 2.8135323524475098,
      "eval_runtime": 57.9858,
      "eval_samples_per_second": 17.246,
      "eval_steps_per_second": 1.086,
      "step": 17050
    },
    {
      "epoch": 0.7342687440819489,
      "grad_norm": 0.934981644153595,
      "learning_rate": 0.00017677574639342686,
      "loss": 3.1669,
      "step": 17060
    },
    {
      "epoch": 0.7346991478006369,
      "grad_norm": 1.1410530805587769,
      "learning_rate": 0.00017674596520467044,
      "loss": 2.9849,
      "step": 17070
    },
    {
      "epoch": 0.7351295515193251,
      "grad_norm": 0.991534948348999,
      "learning_rate": 0.0001767161674454978,
      "loss": 3.1656,
      "step": 17080
    },
    {
      "epoch": 0.7355599552380132,
      "grad_norm": 0.8620188236236572,
      "learning_rate": 0.00017668635312234265,
      "loss": 3.1278,
      "step": 17090
    },
    {
      "epoch": 0.7359903589567014,
      "grad_norm": 0.9208911657333374,
      "learning_rate": 0.0001766565222416422,
      "loss": 3.073,
      "step": 17100
    },
    {
      "epoch": 0.7359903589567014,
      "eval_bleu": 26.48389417533786,
      "eval_gen_len": 27.333,
      "eval_loss": 2.8199095726013184,
      "eval_runtime": 57.5983,
      "eval_samples_per_second": 17.362,
      "eval_steps_per_second": 1.094,
      "step": 17100
    },
    {
      "epoch": 0.7364207626753895,
      "grad_norm": 0.8171501755714417,
      "learning_rate": 0.0001766266748098374,
      "loss": 3.0689,
      "step": 17110
    },
    {
      "epoch": 0.7368511663940777,
      "grad_norm": 0.7976154685020447,
      "learning_rate": 0.0001765968108333726,
      "loss": 3.0842,
      "step": 17120
    },
    {
      "epoch": 0.7372815701127657,
      "grad_norm": 0.9684808254241943,
      "learning_rate": 0.00017656693031869588,
      "loss": 3.0496,
      "step": 17130
    },
    {
      "epoch": 0.7377119738314539,
      "grad_norm": 0.9120163321495056,
      "learning_rate": 0.00017653703327225875,
      "loss": 3.0485,
      "step": 17140
    },
    {
      "epoch": 0.738142377550142,
      "grad_norm": 0.9368422627449036,
      "learning_rate": 0.0001765071197005164,
      "loss": 3.0659,
      "step": 17150
    },
    {
      "epoch": 0.738142377550142,
      "eval_bleu": 26.52914870485982,
      "eval_gen_len": 27.35,
      "eval_loss": 2.8145408630371094,
      "eval_runtime": 58.1368,
      "eval_samples_per_second": 17.201,
      "eval_steps_per_second": 1.084,
      "step": 17150
    },
    {
      "epoch": 0.7385727812688302,
      "grad_norm": 0.9374244213104248,
      "learning_rate": 0.00017647718960992756,
      "loss": 3.0353,
      "step": 17160
    },
    {
      "epoch": 0.7390031849875183,
      "grad_norm": 0.9373812079429626,
      "learning_rate": 0.00017644724300695447,
      "loss": 3.1241,
      "step": 17170
    },
    {
      "epoch": 0.7394335887062065,
      "grad_norm": 0.9271810054779053,
      "learning_rate": 0.000176417279898063,
      "loss": 3.0872,
      "step": 17180
    },
    {
      "epoch": 0.7398639924248945,
      "grad_norm": 0.807170033454895,
      "learning_rate": 0.00017638730028972258,
      "loss": 3.0799,
      "step": 17190
    },
    {
      "epoch": 0.7402943961435827,
      "grad_norm": 1.0634713172912598,
      "learning_rate": 0.00017635730418840613,
      "loss": 3.1193,
      "step": 17200
    },
    {
      "epoch": 0.7402943961435827,
      "eval_bleu": 26.384852207379918,
      "eval_gen_len": 27.388,
      "eval_loss": 2.813952684402466,
      "eval_runtime": 57.5654,
      "eval_samples_per_second": 17.372,
      "eval_steps_per_second": 1.094,
      "step": 17200
    },
    {
      "epoch": 0.7407247998622708,
      "grad_norm": 0.9549627900123596,
      "learning_rate": 0.00017632729160059024,
      "loss": 3.1442,
      "step": 17210
    },
    {
      "epoch": 0.741155203580959,
      "grad_norm": 0.9818102121353149,
      "learning_rate": 0.00017629726253275493,
      "loss": 3.1637,
      "step": 17220
    },
    {
      "epoch": 0.7415856072996471,
      "grad_norm": 0.9046564698219299,
      "learning_rate": 0.00017626721699138395,
      "loss": 3.0311,
      "step": 17230
    },
    {
      "epoch": 0.7420160110183353,
      "grad_norm": 0.9118125438690186,
      "learning_rate": 0.00017623715498296444,
      "loss": 3.1481,
      "step": 17240
    },
    {
      "epoch": 0.7424464147370233,
      "grad_norm": 0.8982129693031311,
      "learning_rate": 0.0001762070765139872,
      "loss": 3.1857,
      "step": 17250
    },
    {
      "epoch": 0.7424464147370233,
      "eval_bleu": 25.92937969326411,
      "eval_gen_len": 27.432,
      "eval_loss": 2.8153955936431885,
      "eval_runtime": 57.4799,
      "eval_samples_per_second": 17.397,
      "eval_steps_per_second": 1.096,
      "step": 17250
    },
    {
      "epoch": 0.7428768184557114,
      "grad_norm": 0.9639352560043335,
      "learning_rate": 0.00017617698159094652,
      "loss": 3.0015,
      "step": 17260
    },
    {
      "epoch": 0.7433072221743996,
      "grad_norm": 0.845120370388031,
      "learning_rate": 0.00017614687022034028,
      "loss": 3.0815,
      "step": 17270
    },
    {
      "epoch": 0.7437376258930877,
      "grad_norm": 1.004058837890625,
      "learning_rate": 0.00017611674240866992,
      "loss": 3.1219,
      "step": 17280
    },
    {
      "epoch": 0.7441680296117759,
      "grad_norm": 1.0143911838531494,
      "learning_rate": 0.0001760865981624404,
      "loss": 3.1281,
      "step": 17290
    },
    {
      "epoch": 0.7445984333304639,
      "grad_norm": 0.929045557975769,
      "learning_rate": 0.00017605643748816024,
      "loss": 3.0488,
      "step": 17300
    },
    {
      "epoch": 0.7445984333304639,
      "eval_bleu": 26.389850830004633,
      "eval_gen_len": 27.239,
      "eval_loss": 2.810380220413208,
      "eval_runtime": 57.6434,
      "eval_samples_per_second": 17.348,
      "eval_steps_per_second": 1.093,
      "step": 17300
    },
    {
      "epoch": 0.7450288370491521,
      "grad_norm": 0.9503012895584106,
      "learning_rate": 0.0001760262603923415,
      "loss": 3.1105,
      "step": 17310
    },
    {
      "epoch": 0.7454592407678402,
      "grad_norm": 0.9272844195365906,
      "learning_rate": 0.0001759960668814998,
      "loss": 3.0491,
      "step": 17320
    },
    {
      "epoch": 0.7458896444865284,
      "grad_norm": 0.8877793550491333,
      "learning_rate": 0.00017596585696215433,
      "loss": 3.1128,
      "step": 17330
    },
    {
      "epoch": 0.7463200482052165,
      "grad_norm": 1.0768481492996216,
      "learning_rate": 0.00017593563064082776,
      "loss": 3.0891,
      "step": 17340
    },
    {
      "epoch": 0.7467504519239047,
      "grad_norm": 0.8259531855583191,
      "learning_rate": 0.00017590538792404628,
      "loss": 3.0745,
      "step": 17350
    },
    {
      "epoch": 0.7467504519239047,
      "eval_bleu": 26.411483697418408,
      "eval_gen_len": 27.407,
      "eval_loss": 2.811633586883545,
      "eval_runtime": 57.943,
      "eval_samples_per_second": 17.258,
      "eval_steps_per_second": 1.087,
      "step": 17350
    },
    {
      "epoch": 0.7471808556425927,
      "grad_norm": 0.9535338282585144,
      "learning_rate": 0.00017587512881833974,
      "loss": 3.1082,
      "step": 17360
    },
    {
      "epoch": 0.7476112593612809,
      "grad_norm": 0.8340772986412048,
      "learning_rate": 0.0001758448533302415,
      "loss": 3.0699,
      "step": 17370
    },
    {
      "epoch": 0.748041663079969,
      "grad_norm": 0.8954629898071289,
      "learning_rate": 0.00017581456146628828,
      "loss": 3.1309,
      "step": 17380
    },
    {
      "epoch": 0.7484720667986572,
      "grad_norm": 0.9393510818481445,
      "learning_rate": 0.00017578425323302058,
      "loss": 3.0979,
      "step": 17390
    },
    {
      "epoch": 0.7489024705173453,
      "grad_norm": 1.0006617307662964,
      "learning_rate": 0.00017575392863698232,
      "loss": 3.0768,
      "step": 17400
    },
    {
      "epoch": 0.7489024705173453,
      "eval_bleu": 26.169318372069153,
      "eval_gen_len": 27.429,
      "eval_loss": 2.8147432804107666,
      "eval_runtime": 57.7886,
      "eval_samples_per_second": 17.304,
      "eval_steps_per_second": 1.09,
      "step": 17400
    },
    {
      "epoch": 0.7493328742360335,
      "grad_norm": 0.8883116841316223,
      "learning_rate": 0.00017572358768472093,
      "loss": 3.051,
      "step": 17410
    },
    {
      "epoch": 0.7497632779547215,
      "grad_norm": 1.0773096084594727,
      "learning_rate": 0.00017569323038278743,
      "loss": 3.0794,
      "step": 17420
    },
    {
      "epoch": 0.7501936816734096,
      "grad_norm": 0.8892773985862732,
      "learning_rate": 0.0001756628567377363,
      "loss": 3.0876,
      "step": 17430
    },
    {
      "epoch": 0.7506240853920978,
      "grad_norm": 0.9130094051361084,
      "learning_rate": 0.00017563246675612564,
      "loss": 3.0906,
      "step": 17440
    },
    {
      "epoch": 0.7510544891107859,
      "grad_norm": 0.9644394516944885,
      "learning_rate": 0.000175602060444517,
      "loss": 3.0656,
      "step": 17450
    },
    {
      "epoch": 0.7510544891107859,
      "eval_bleu": 26.24251083054249,
      "eval_gen_len": 27.293,
      "eval_loss": 2.8146774768829346,
      "eval_runtime": 57.597,
      "eval_samples_per_second": 17.362,
      "eval_steps_per_second": 1.094,
      "step": 17450
    },
    {
      "epoch": 0.7514848928294741,
      "grad_norm": 0.9765461683273315,
      "learning_rate": 0.00017557163780947547,
      "loss": 3.1598,
      "step": 17460
    },
    {
      "epoch": 0.7519152965481621,
      "grad_norm": 0.8682713508605957,
      "learning_rate": 0.00017554119885756974,
      "loss": 3.1902,
      "step": 17470
    },
    {
      "epoch": 0.7523457002668503,
      "grad_norm": 0.9087728261947632,
      "learning_rate": 0.0001755107435953719,
      "loss": 3.0005,
      "step": 17480
    },
    {
      "epoch": 0.7527761039855384,
      "grad_norm": 0.7585774660110474,
      "learning_rate": 0.00017548027202945763,
      "loss": 3.0258,
      "step": 17490
    },
    {
      "epoch": 0.7532065077042266,
      "grad_norm": 0.9370798468589783,
      "learning_rate": 0.00017544978416640615,
      "loss": 3.0741,
      "step": 17500
    },
    {
      "epoch": 0.7532065077042266,
      "eval_bleu": 26.03115087293723,
      "eval_gen_len": 27.39,
      "eval_loss": 2.8134140968322754,
      "eval_runtime": 57.8581,
      "eval_samples_per_second": 17.284,
      "eval_steps_per_second": 1.089,
      "step": 17500
    },
    {
      "epoch": 0.7536369114229147,
      "grad_norm": 0.9748256802558899,
      "learning_rate": 0.00017541928001280015,
      "loss": 3.0928,
      "step": 17510
    },
    {
      "epoch": 0.7540673151416029,
      "grad_norm": 0.9722902774810791,
      "learning_rate": 0.00017538875957522586,
      "loss": 3.0143,
      "step": 17520
    },
    {
      "epoch": 0.7544977188602909,
      "grad_norm": 0.8633862137794495,
      "learning_rate": 0.00017535822286027307,
      "loss": 3.1966,
      "step": 17530
    },
    {
      "epoch": 0.7549281225789791,
      "grad_norm": 0.94935142993927,
      "learning_rate": 0.00017532766987453496,
      "loss": 3.0801,
      "step": 17540
    },
    {
      "epoch": 0.7553585262976672,
      "grad_norm": 0.8090884685516357,
      "learning_rate": 0.00017529710062460835,
      "loss": 3.1115,
      "step": 17550
    },
    {
      "epoch": 0.7553585262976672,
      "eval_bleu": 26.56824024555899,
      "eval_gen_len": 27.408,
      "eval_loss": 2.813601016998291,
      "eval_runtime": 57.8263,
      "eval_samples_per_second": 17.293,
      "eval_steps_per_second": 1.089,
      "step": 17550
    },
    {
      "epoch": 0.7557889300163554,
      "grad_norm": 1.0783541202545166,
      "learning_rate": 0.00017526651511709352,
      "loss": 3.107,
      "step": 17560
    },
    {
      "epoch": 0.7562193337350435,
      "grad_norm": 0.9301024675369263,
      "learning_rate": 0.00017523591335859428,
      "loss": 3.1167,
      "step": 17570
    },
    {
      "epoch": 0.7566497374537317,
      "grad_norm": 0.9435732364654541,
      "learning_rate": 0.0001752052953557179,
      "loss": 3.0431,
      "step": 17580
    },
    {
      "epoch": 0.7570801411724197,
      "grad_norm": 0.9753397703170776,
      "learning_rate": 0.0001751746611150752,
      "loss": 3.1159,
      "step": 17590
    },
    {
      "epoch": 0.7575105448911078,
      "grad_norm": 0.9569426774978638,
      "learning_rate": 0.00017514401064328054,
      "loss": 3.0933,
      "step": 17600
    },
    {
      "epoch": 0.7575105448911078,
      "eval_bleu": 25.880412943361993,
      "eval_gen_len": 27.456,
      "eval_loss": 2.8118178844451904,
      "eval_runtime": 58.0966,
      "eval_samples_per_second": 17.213,
      "eval_steps_per_second": 1.084,
      "step": 17600
    },
    {
      "epoch": 0.757940948609796,
      "grad_norm": 1.0337451696395874,
      "learning_rate": 0.0001751133439469517,
      "loss": 3.0846,
      "step": 17610
    },
    {
      "epoch": 0.7583713523284841,
      "grad_norm": 1.0081194639205933,
      "learning_rate": 0.00017508266103270998,
      "loss": 3.1712,
      "step": 17620
    },
    {
      "epoch": 0.7588017560471723,
      "grad_norm": 0.8405554890632629,
      "learning_rate": 0.00017505196190718025,
      "loss": 3.1061,
      "step": 17630
    },
    {
      "epoch": 0.7592321597658603,
      "grad_norm": 0.9699069261550903,
      "learning_rate": 0.00017502124657699082,
      "loss": 3.1678,
      "step": 17640
    },
    {
      "epoch": 0.7596625634845485,
      "grad_norm": 0.8241530060768127,
      "learning_rate": 0.00017499051504877352,
      "loss": 3.1034,
      "step": 17650
    },
    {
      "epoch": 0.7596625634845485,
      "eval_bleu": 26.889418620071574,
      "eval_gen_len": 27.47,
      "eval_loss": 2.8078904151916504,
      "eval_runtime": 57.9695,
      "eval_samples_per_second": 17.25,
      "eval_steps_per_second": 1.087,
      "step": 17650
    },
    {
      "epoch": 0.7600929672032366,
      "grad_norm": 0.8875434994697571,
      "learning_rate": 0.00017495976732916367,
      "loss": 3.1114,
      "step": 17660
    },
    {
      "epoch": 0.7605233709219248,
      "grad_norm": 1.0167064666748047,
      "learning_rate": 0.00017492900342480007,
      "loss": 3.1545,
      "step": 17670
    },
    {
      "epoch": 0.7609537746406129,
      "grad_norm": 0.9215189814567566,
      "learning_rate": 0.0001748982233423251,
      "loss": 3.1039,
      "step": 17680
    },
    {
      "epoch": 0.7613841783593011,
      "grad_norm": 0.9355830550193787,
      "learning_rate": 0.00017486742708838445,
      "loss": 3.0821,
      "step": 17690
    },
    {
      "epoch": 0.7618145820779891,
      "grad_norm": 0.9946203231811523,
      "learning_rate": 0.00017483661466962752,
      "loss": 3.155,
      "step": 17700
    },
    {
      "epoch": 0.7618145820779891,
      "eval_bleu": 26.223378928909213,
      "eval_gen_len": 27.32,
      "eval_loss": 2.8109307289123535,
      "eval_runtime": 57.7695,
      "eval_samples_per_second": 17.31,
      "eval_steps_per_second": 1.091,
      "step": 17700
    },
    {
      "epoch": 0.7622449857966773,
      "grad_norm": 0.8185842037200928,
      "learning_rate": 0.00017480578609270709,
      "loss": 3.1003,
      "step": 17710
    },
    {
      "epoch": 0.7626753895153654,
      "grad_norm": 0.9412878155708313,
      "learning_rate": 0.00017477494136427938,
      "loss": 3.0773,
      "step": 17720
    },
    {
      "epoch": 0.7631057932340536,
      "grad_norm": 1.05472731590271,
      "learning_rate": 0.00017474408049100414,
      "loss": 3.1436,
      "step": 17730
    },
    {
      "epoch": 0.7635361969527417,
      "grad_norm": 1.0041252374649048,
      "learning_rate": 0.0001747132034795447,
      "loss": 3.109,
      "step": 17740
    },
    {
      "epoch": 0.7639666006714299,
      "grad_norm": 0.8156348466873169,
      "learning_rate": 0.00017468231033656776,
      "loss": 3.2267,
      "step": 17750
    },
    {
      "epoch": 0.7639666006714299,
      "eval_bleu": 26.046308241742437,
      "eval_gen_len": 27.348,
      "eval_loss": 2.8157546520233154,
      "eval_runtime": 57.7692,
      "eval_samples_per_second": 17.31,
      "eval_steps_per_second": 1.091,
      "step": 17750
    },
    {
      "epoch": 0.7643970043901179,
      "grad_norm": 0.9049878120422363,
      "learning_rate": 0.0001746514010687435,
      "loss": 3.1079,
      "step": 17760
    },
    {
      "epoch": 0.764827408108806,
      "grad_norm": 0.9611096382141113,
      "learning_rate": 0.0001746204756827457,
      "loss": 3.1107,
      "step": 17770
    },
    {
      "epoch": 0.7652578118274942,
      "grad_norm": 0.9584765434265137,
      "learning_rate": 0.00017458953418525143,
      "loss": 3.0601,
      "step": 17780
    },
    {
      "epoch": 0.7656882155461823,
      "grad_norm": 0.9959468841552734,
      "learning_rate": 0.00017455857658294144,
      "loss": 3.1639,
      "step": 17790
    },
    {
      "epoch": 0.7661186192648705,
      "grad_norm": 0.8744387030601501,
      "learning_rate": 0.00017452760288249984,
      "loss": 3.0785,
      "step": 17800
    },
    {
      "epoch": 0.7661186192648705,
      "eval_bleu": 26.587907510712288,
      "eval_gen_len": 27.372,
      "eval_loss": 2.80631160736084,
      "eval_runtime": 57.5187,
      "eval_samples_per_second": 17.386,
      "eval_steps_per_second": 1.095,
      "step": 17800
    },
    {
      "epoch": 0.7665490229835585,
      "grad_norm": 0.9524948596954346,
      "learning_rate": 0.0001744966130906142,
      "loss": 3.0706,
      "step": 17810
    },
    {
      "epoch": 0.7669794267022467,
      "grad_norm": 1.0143836736679077,
      "learning_rate": 0.00017446560721397564,
      "loss": 3.1294,
      "step": 17820
    },
    {
      "epoch": 0.7674098304209348,
      "grad_norm": 0.9430230855941772,
      "learning_rate": 0.0001744345852592787,
      "loss": 3.0889,
      "step": 17830
    },
    {
      "epoch": 0.767840234139623,
      "grad_norm": 0.8162497282028198,
      "learning_rate": 0.00017440354723322147,
      "loss": 3.0353,
      "step": 17840
    },
    {
      "epoch": 0.7682706378583111,
      "grad_norm": 0.9404364228248596,
      "learning_rate": 0.00017437249314250538,
      "loss": 3.078,
      "step": 17850
    },
    {
      "epoch": 0.7682706378583111,
      "eval_bleu": 25.856138117316046,
      "eval_gen_len": 27.338,
      "eval_loss": 2.81427001953125,
      "eval_runtime": 57.672,
      "eval_samples_per_second": 17.339,
      "eval_steps_per_second": 1.092,
      "step": 17850
    },
    {
      "epoch": 0.7687010415769993,
      "grad_norm": 0.9898384809494019,
      "learning_rate": 0.00017434142299383544,
      "loss": 3.1834,
      "step": 17860
    },
    {
      "epoch": 0.7691314452956873,
      "grad_norm": 1.0254586935043335,
      "learning_rate": 0.00017431033679392,
      "loss": 3.1694,
      "step": 17870
    },
    {
      "epoch": 0.7695618490143755,
      "grad_norm": 0.9227811098098755,
      "learning_rate": 0.00017427923454947108,
      "loss": 3.1348,
      "step": 17880
    },
    {
      "epoch": 0.7699922527330636,
      "grad_norm": 0.8949626088142395,
      "learning_rate": 0.00017424811626720396,
      "loss": 3.1353,
      "step": 17890
    },
    {
      "epoch": 0.7704226564517518,
      "grad_norm": 1.0181100368499756,
      "learning_rate": 0.0001742169819538375,
      "loss": 3.0929,
      "step": 17900
    },
    {
      "epoch": 0.7704226564517518,
      "eval_bleu": 26.14770647807212,
      "eval_gen_len": 27.372,
      "eval_loss": 2.81365966796875,
      "eval_runtime": 57.9955,
      "eval_samples_per_second": 17.243,
      "eval_steps_per_second": 1.086,
      "step": 17900
    },
    {
      "epoch": 0.7708530601704399,
      "grad_norm": 0.8258217573165894,
      "learning_rate": 0.000174185831616094,
      "loss": 3.0985,
      "step": 17910
    },
    {
      "epoch": 0.771283463889128,
      "grad_norm": 0.9262021780014038,
      "learning_rate": 0.00017415466526069916,
      "loss": 3.2144,
      "step": 17920
    },
    {
      "epoch": 0.7717138676078161,
      "grad_norm": 0.9454318881034851,
      "learning_rate": 0.00017412348289438226,
      "loss": 3.0841,
      "step": 17930
    },
    {
      "epoch": 0.7721442713265042,
      "grad_norm": 0.9023833870887756,
      "learning_rate": 0.0001740922845238759,
      "loss": 2.9907,
      "step": 17940
    },
    {
      "epoch": 0.7725746750451924,
      "grad_norm": 0.9320566058158875,
      "learning_rate": 0.00017406107015591625,
      "loss": 3.1256,
      "step": 17950
    },
    {
      "epoch": 0.7725746750451924,
      "eval_bleu": 26.769129565909232,
      "eval_gen_len": 27.323,
      "eval_loss": 2.8076171875,
      "eval_runtime": 57.639,
      "eval_samples_per_second": 17.349,
      "eval_steps_per_second": 1.093,
      "step": 17950
    },
    {
      "epoch": 0.7730050787638805,
      "grad_norm": 0.945531964302063,
      "learning_rate": 0.0001740298397972428,
      "loss": 3.0945,
      "step": 17960
    },
    {
      "epoch": 0.7734354824825687,
      "grad_norm": 0.8665612936019897,
      "learning_rate": 0.0001739985934545987,
      "loss": 3.0941,
      "step": 17970
    },
    {
      "epoch": 0.7738658862012567,
      "grad_norm": 0.870940089225769,
      "learning_rate": 0.00017396733113473034,
      "loss": 3.094,
      "step": 17980
    },
    {
      "epoch": 0.7742962899199449,
      "grad_norm": 0.9105831384658813,
      "learning_rate": 0.00017393605284438763,
      "loss": 3.1516,
      "step": 17990
    },
    {
      "epoch": 0.774726693638633,
      "grad_norm": 0.8644453287124634,
      "learning_rate": 0.000173904758590324,
      "loss": 3.1131,
      "step": 18000
    },
    {
      "epoch": 0.774726693638633,
      "eval_bleu": 26.491480888844567,
      "eval_gen_len": 27.297,
      "eval_loss": 2.8101463317871094,
      "eval_runtime": 57.5197,
      "eval_samples_per_second": 17.385,
      "eval_steps_per_second": 1.095,
      "step": 18000
    },
    {
      "epoch": 0.7751570973573212,
      "grad_norm": 1.0045310258865356,
      "learning_rate": 0.00017387344837929626,
      "loss": 3.0781,
      "step": 18010
    },
    {
      "epoch": 0.7755875010760093,
      "grad_norm": 0.9119118452072144,
      "learning_rate": 0.00017384212221806467,
      "loss": 3.0886,
      "step": 18020
    },
    {
      "epoch": 0.7760179047946975,
      "grad_norm": 0.9233046770095825,
      "learning_rate": 0.00017381078011339293,
      "loss": 3.1364,
      "step": 18030
    },
    {
      "epoch": 0.7764483085133855,
      "grad_norm": 1.0265840291976929,
      "learning_rate": 0.00017377942207204826,
      "loss": 3.1454,
      "step": 18040
    },
    {
      "epoch": 0.7768787122320737,
      "grad_norm": 0.8803142309188843,
      "learning_rate": 0.00017374804810080114,
      "loss": 3.0215,
      "step": 18050
    },
    {
      "epoch": 0.7768787122320737,
      "eval_bleu": 26.301028188685443,
      "eval_gen_len": 27.258,
      "eval_loss": 2.815805673599243,
      "eval_runtime": 57.4418,
      "eval_samples_per_second": 17.409,
      "eval_steps_per_second": 1.097,
      "step": 18050
    },
    {
      "epoch": 0.7773091159507618,
      "grad_norm": 0.8828250169754028,
      "learning_rate": 0.00017371665820642567,
      "loss": 3.0802,
      "step": 18060
    },
    {
      "epoch": 0.77773951966945,
      "grad_norm": 0.8976221084594727,
      "learning_rate": 0.00017368525239569934,
      "loss": 3.1946,
      "step": 18070
    },
    {
      "epoch": 0.7781699233881381,
      "grad_norm": 0.8337244987487793,
      "learning_rate": 0.00017365383067540301,
      "loss": 3.1221,
      "step": 18080
    },
    {
      "epoch": 0.7786003271068263,
      "grad_norm": 0.9953499436378479,
      "learning_rate": 0.00017362239305232104,
      "loss": 3.1654,
      "step": 18090
    },
    {
      "epoch": 0.7790307308255143,
      "grad_norm": 0.8620975613594055,
      "learning_rate": 0.00017359093953324124,
      "loss": 3.0178,
      "step": 18100
    },
    {
      "epoch": 0.7790307308255143,
      "eval_bleu": 26.145215361063364,
      "eval_gen_len": 27.352,
      "eval_loss": 2.8118953704833984,
      "eval_runtime": 57.8809,
      "eval_samples_per_second": 17.277,
      "eval_steps_per_second": 1.088,
      "step": 18100
    },
    {
      "epoch": 0.7794611345442025,
      "grad_norm": 0.8985755443572998,
      "learning_rate": 0.00017355947012495478,
      "loss": 3.199,
      "step": 18110
    },
    {
      "epoch": 0.7798915382628906,
      "grad_norm": 0.8924806714057922,
      "learning_rate": 0.0001735279848342563,
      "loss": 3.0812,
      "step": 18120
    },
    {
      "epoch": 0.7803219419815787,
      "grad_norm": 0.8634482026100159,
      "learning_rate": 0.00017349648366794392,
      "loss": 3.088,
      "step": 18130
    },
    {
      "epoch": 0.7807523457002669,
      "grad_norm": 0.9242662787437439,
      "learning_rate": 0.00017346496663281905,
      "loss": 3.1023,
      "step": 18140
    },
    {
      "epoch": 0.7811827494189549,
      "grad_norm": 0.947701632976532,
      "learning_rate": 0.0001734334337356867,
      "loss": 3.067,
      "step": 18150
    },
    {
      "epoch": 0.7811827494189549,
      "eval_bleu": 26.40568785816641,
      "eval_gen_len": 27.334,
      "eval_loss": 2.8086905479431152,
      "eval_runtime": 57.6824,
      "eval_samples_per_second": 17.336,
      "eval_steps_per_second": 1.092,
      "step": 18150
    },
    {
      "epoch": 0.7816131531376431,
      "grad_norm": 0.9914455413818359,
      "learning_rate": 0.00017340188498335516,
      "loss": 3.1003,
      "step": 18160
    },
    {
      "epoch": 0.7820435568563312,
      "grad_norm": 0.9155399203300476,
      "learning_rate": 0.00017337032038263622,
      "loss": 3.0291,
      "step": 18170
    },
    {
      "epoch": 0.7824739605750194,
      "grad_norm": 1.012789011001587,
      "learning_rate": 0.0001733387399403451,
      "loss": 3.1029,
      "step": 18180
    },
    {
      "epoch": 0.7829043642937075,
      "grad_norm": 0.948168158531189,
      "learning_rate": 0.00017330714366330037,
      "loss": 2.9855,
      "step": 18190
    },
    {
      "epoch": 0.7833347680123957,
      "grad_norm": 0.910392701625824,
      "learning_rate": 0.0001732755315583241,
      "loss": 3.1468,
      "step": 18200
    },
    {
      "epoch": 0.7833347680123957,
      "eval_bleu": 26.75911714493038,
      "eval_gen_len": 27.174,
      "eval_loss": 2.8099734783172607,
      "eval_runtime": 57.5726,
      "eval_samples_per_second": 17.369,
      "eval_steps_per_second": 1.094,
      "step": 18200
    },
    {
      "epoch": 0.7837651717310837,
      "grad_norm": 0.9461367726325989,
      "learning_rate": 0.0001732439036322417,
      "loss": 3.0669,
      "step": 18210
    },
    {
      "epoch": 0.7841955754497719,
      "grad_norm": 0.8995304703712463,
      "learning_rate": 0.00017321225989188203,
      "loss": 3.1271,
      "step": 18220
    },
    {
      "epoch": 0.78462597916846,
      "grad_norm": 0.8636119365692139,
      "learning_rate": 0.00017318060034407742,
      "loss": 3.1406,
      "step": 18230
    },
    {
      "epoch": 0.7850563828871482,
      "grad_norm": 1.0465339422225952,
      "learning_rate": 0.00017314892499566356,
      "loss": 3.1076,
      "step": 18240
    },
    {
      "epoch": 0.7854867866058363,
      "grad_norm": 0.9805688261985779,
      "learning_rate": 0.0001731172338534795,
      "loss": 3.1126,
      "step": 18250
    },
    {
      "epoch": 0.7854867866058363,
      "eval_bleu": 26.367094231629437,
      "eval_gen_len": 27.303,
      "eval_loss": 2.813286304473877,
      "eval_runtime": 57.2382,
      "eval_samples_per_second": 17.471,
      "eval_steps_per_second": 1.101,
      "step": 18250
    },
    {
      "epoch": 0.7859171903245245,
      "grad_norm": 0.8237065672874451,
      "learning_rate": 0.00017308552692436781,
      "loss": 3.0782,
      "step": 18260
    },
    {
      "epoch": 0.7863475940432125,
      "grad_norm": 0.8996642827987671,
      "learning_rate": 0.0001730538042151744,
      "loss": 3.0867,
      "step": 18270
    },
    {
      "epoch": 0.7867779977619007,
      "grad_norm": 0.9158669710159302,
      "learning_rate": 0.0001730220657327486,
      "loss": 3.1101,
      "step": 18280
    },
    {
      "epoch": 0.7872084014805888,
      "grad_norm": 0.8931041359901428,
      "learning_rate": 0.0001729903114839431,
      "loss": 3.0895,
      "step": 18290
    },
    {
      "epoch": 0.7876388051992769,
      "grad_norm": 0.880416989326477,
      "learning_rate": 0.00017295854147561412,
      "loss": 3.0391,
      "step": 18300
    },
    {
      "epoch": 0.7876388051992769,
      "eval_bleu": 26.54159797529386,
      "eval_gen_len": 27.319,
      "eval_loss": 2.808263063430786,
      "eval_runtime": 57.2924,
      "eval_samples_per_second": 17.454,
      "eval_steps_per_second": 1.1,
      "step": 18300
    },
    {
      "epoch": 0.7880692089179651,
      "grad_norm": 0.9491683840751648,
      "learning_rate": 0.00017292675571462115,
      "loss": 3.1369,
      "step": 18310
    },
    {
      "epoch": 0.7884996126366531,
      "grad_norm": 0.7351040840148926,
      "learning_rate": 0.00017289495420782713,
      "loss": 3.0436,
      "step": 18320
    },
    {
      "epoch": 0.7889300163553413,
      "grad_norm": 0.9328140616416931,
      "learning_rate": 0.00017286313696209844,
      "loss": 3.0771,
      "step": 18330
    },
    {
      "epoch": 0.7893604200740294,
      "grad_norm": 0.9504871964454651,
      "learning_rate": 0.0001728313039843048,
      "loss": 3.0111,
      "step": 18340
    },
    {
      "epoch": 0.7897908237927176,
      "grad_norm": 0.8012583255767822,
      "learning_rate": 0.00017279945528131936,
      "loss": 3.065,
      "step": 18350
    },
    {
      "epoch": 0.7897908237927176,
      "eval_bleu": 26.114686020846005,
      "eval_gen_len": 27.319,
      "eval_loss": 2.808910608291626,
      "eval_runtime": 57.3225,
      "eval_samples_per_second": 17.445,
      "eval_steps_per_second": 1.099,
      "step": 18350
    },
    {
      "epoch": 0.7902212275114057,
      "grad_norm": 0.9445289373397827,
      "learning_rate": 0.00017276759086001865,
      "loss": 3.1038,
      "step": 18360
    },
    {
      "epoch": 0.7906516312300939,
      "grad_norm": 0.8196885585784912,
      "learning_rate": 0.0001727357107272826,
      "loss": 3.0475,
      "step": 18370
    },
    {
      "epoch": 0.7910820349487819,
      "grad_norm": 0.8512479066848755,
      "learning_rate": 0.00017270381488999453,
      "loss": 3.02,
      "step": 18380
    },
    {
      "epoch": 0.7915124386674701,
      "grad_norm": 1.0320740938186646,
      "learning_rate": 0.0001726719033550411,
      "loss": 3.148,
      "step": 18390
    },
    {
      "epoch": 0.7919428423861582,
      "grad_norm": 0.9118044972419739,
      "learning_rate": 0.00017263997612931248,
      "loss": 3.1255,
      "step": 18400
    },
    {
      "epoch": 0.7919428423861582,
      "eval_bleu": 25.96141042888516,
      "eval_gen_len": 27.368,
      "eval_loss": 2.810314893722534,
      "eval_runtime": 56.9123,
      "eval_samples_per_second": 17.571,
      "eval_steps_per_second": 1.107,
      "step": 18400
    },
    {
      "epoch": 0.7923732461048464,
      "grad_norm": 0.7890820503234863,
      "learning_rate": 0.00017260803321970215,
      "loss": 3.0104,
      "step": 18410
    },
    {
      "epoch": 0.7928036498235345,
      "grad_norm": 0.8466106653213501,
      "learning_rate": 0.00017257607463310698,
      "loss": 3.1265,
      "step": 18420
    },
    {
      "epoch": 0.7932340535422227,
      "grad_norm": 0.9321570992469788,
      "learning_rate": 0.0001725441003764272,
      "loss": 3.0406,
      "step": 18430
    },
    {
      "epoch": 0.7936644572609107,
      "grad_norm": 0.8569533228874207,
      "learning_rate": 0.00017251211045656652,
      "loss": 3.1446,
      "step": 18440
    },
    {
      "epoch": 0.7940948609795989,
      "grad_norm": 0.9044644236564636,
      "learning_rate": 0.00017248010488043187,
      "loss": 3.1978,
      "step": 18450
    },
    {
      "epoch": 0.7940948609795989,
      "eval_bleu": 25.660327832704027,
      "eval_gen_len": 27.288,
      "eval_loss": 2.8182284832000732,
      "eval_runtime": 57.8025,
      "eval_samples_per_second": 17.3,
      "eval_steps_per_second": 1.09,
      "step": 18450
    },
    {
      "epoch": 0.794525264698287,
      "grad_norm": 0.818245530128479,
      "learning_rate": 0.00017244808365493371,
      "loss": 3.1297,
      "step": 18460
    },
    {
      "epoch": 0.7949556684169751,
      "grad_norm": 1.0002919435501099,
      "learning_rate": 0.00017241604678698585,
      "loss": 3.058,
      "step": 18470
    },
    {
      "epoch": 0.7953860721356633,
      "grad_norm": 0.9563137292861938,
      "learning_rate": 0.0001723839942835054,
      "loss": 3.0827,
      "step": 18480
    },
    {
      "epoch": 0.7958164758543513,
      "grad_norm": 0.9606627821922302,
      "learning_rate": 0.00017235192615141292,
      "loss": 3.1538,
      "step": 18490
    },
    {
      "epoch": 0.7962468795730395,
      "grad_norm": 0.973164975643158,
      "learning_rate": 0.0001723198423976323,
      "loss": 3.0815,
      "step": 18500
    },
    {
      "epoch": 0.7962468795730395,
      "eval_bleu": 26.821774551790156,
      "eval_gen_len": 27.44,
      "eval_loss": 2.8104586601257324,
      "eval_runtime": 57.4869,
      "eval_samples_per_second": 17.395,
      "eval_steps_per_second": 1.096,
      "step": 18500
    },
    {
      "epoch": 0.7966772832917276,
      "grad_norm": 0.8887767195701599,
      "learning_rate": 0.00017228774302909086,
      "loss": 3.0317,
      "step": 18510
    },
    {
      "epoch": 0.7971076870104158,
      "grad_norm": 0.9489519596099854,
      "learning_rate": 0.00017225562805271922,
      "loss": 3.1577,
      "step": 18520
    },
    {
      "epoch": 0.7975380907291039,
      "grad_norm": 0.9328476786613464,
      "learning_rate": 0.00017222349747545145,
      "loss": 3.0718,
      "step": 18530
    },
    {
      "epoch": 0.797968494447792,
      "grad_norm": 0.8645482659339905,
      "learning_rate": 0.00017219135130422492,
      "loss": 3.0774,
      "step": 18540
    },
    {
      "epoch": 0.7983988981664801,
      "grad_norm": 0.8086804747581482,
      "learning_rate": 0.00017215918954598038,
      "loss": 3.1337,
      "step": 18550
    },
    {
      "epoch": 0.7983988981664801,
      "eval_bleu": 26.558286571659195,
      "eval_gen_len": 27.318,
      "eval_loss": 2.810650110244751,
      "eval_runtime": 57.3124,
      "eval_samples_per_second": 17.448,
      "eval_steps_per_second": 1.099,
      "step": 18550
    },
    {
      "epoch": 0.7988293018851683,
      "grad_norm": 0.8294590711593628,
      "learning_rate": 0.00017212701220766197,
      "loss": 3.1245,
      "step": 18560
    },
    {
      "epoch": 0.7992597056038564,
      "grad_norm": 0.8671245574951172,
      "learning_rate": 0.0001720948192962172,
      "loss": 3.1158,
      "step": 18570
    },
    {
      "epoch": 0.7996901093225446,
      "grad_norm": 0.9297916293144226,
      "learning_rate": 0.00017206261081859688,
      "loss": 2.9935,
      "step": 18580
    },
    {
      "epoch": 0.8001205130412327,
      "grad_norm": 0.8852419853210449,
      "learning_rate": 0.00017203038678175524,
      "loss": 3.1574,
      "step": 18590
    },
    {
      "epoch": 0.8005509167599208,
      "grad_norm": 1.0529037714004517,
      "learning_rate": 0.00017199814719264992,
      "loss": 3.1035,
      "step": 18600
    },
    {
      "epoch": 0.8005509167599208,
      "eval_bleu": 26.523047286890026,
      "eval_gen_len": 27.385,
      "eval_loss": 2.8107261657714844,
      "eval_runtime": 57.4266,
      "eval_samples_per_second": 17.414,
      "eval_steps_per_second": 1.097,
      "step": 18600
    },
    {
      "epoch": 0.8009813204786089,
      "grad_norm": 0.9722619652748108,
      "learning_rate": 0.00017196589205824175,
      "loss": 3.0758,
      "step": 18610
    },
    {
      "epoch": 0.8014117241972971,
      "grad_norm": 1.011156439781189,
      "learning_rate": 0.00017193362138549504,
      "loss": 3.2317,
      "step": 18620
    },
    {
      "epoch": 0.8018421279159852,
      "grad_norm": 0.8531031012535095,
      "learning_rate": 0.00017190133518137746,
      "loss": 3.0362,
      "step": 18630
    },
    {
      "epoch": 0.8022725316346733,
      "grad_norm": 0.8784408569335938,
      "learning_rate": 0.00017186903345286,
      "loss": 3.1347,
      "step": 18640
    },
    {
      "epoch": 0.8027029353533615,
      "grad_norm": 0.8908144235610962,
      "learning_rate": 0.00017183671620691704,
      "loss": 3.0983,
      "step": 18650
    },
    {
      "epoch": 0.8027029353533615,
      "eval_bleu": 26.511392403181222,
      "eval_gen_len": 27.22,
      "eval_loss": 2.806814432144165,
      "eval_runtime": 57.5525,
      "eval_samples_per_second": 17.375,
      "eval_steps_per_second": 1.095,
      "step": 18650
    },
    {
      "epoch": 0.8031333390720495,
      "grad_norm": 0.8173786997795105,
      "learning_rate": 0.0001718043834505262,
      "loss": 3.0882,
      "step": 18660
    },
    {
      "epoch": 0.8035637427907377,
      "grad_norm": 0.8328935503959656,
      "learning_rate": 0.00017177203519066862,
      "loss": 3.2305,
      "step": 18670
    },
    {
      "epoch": 0.8039941465094258,
      "grad_norm": 0.863444447517395,
      "learning_rate": 0.00017173967143432862,
      "loss": 3.0934,
      "step": 18680
    },
    {
      "epoch": 0.804424550228114,
      "grad_norm": 1.1256318092346191,
      "learning_rate": 0.000171707292188494,
      "loss": 3.0631,
      "step": 18690
    },
    {
      "epoch": 0.8048549539468021,
      "grad_norm": 0.8937386274337769,
      "learning_rate": 0.00017167489746015578,
      "loss": 3.0992,
      "step": 18700
    },
    {
      "epoch": 0.8048549539468021,
      "eval_bleu": 26.33636912743906,
      "eval_gen_len": 27.36,
      "eval_loss": 2.811915397644043,
      "eval_runtime": 58.025,
      "eval_samples_per_second": 17.234,
      "eval_steps_per_second": 1.086,
      "step": 18700
    },
    {
      "epoch": 0.8052853576654903,
      "grad_norm": 0.9427624344825745,
      "learning_rate": 0.00017164248725630844,
      "loss": 3.012,
      "step": 18710
    },
    {
      "epoch": 0.8057157613841783,
      "grad_norm": 0.9101919531822205,
      "learning_rate": 0.0001716100615839497,
      "loss": 3.0472,
      "step": 18720
    },
    {
      "epoch": 0.8061461651028665,
      "grad_norm": 0.8507339954376221,
      "learning_rate": 0.00017157762045008076,
      "loss": 3.023,
      "step": 18730
    },
    {
      "epoch": 0.8065765688215546,
      "grad_norm": 0.938922643661499,
      "learning_rate": 0.000171545163861706,
      "loss": 3.1848,
      "step": 18740
    },
    {
      "epoch": 0.8070069725402428,
      "grad_norm": 0.8476879000663757,
      "learning_rate": 0.0001715126918258332,
      "loss": 3.1133,
      "step": 18750
    },
    {
      "epoch": 0.8070069725402428,
      "eval_bleu": 26.516042250353046,
      "eval_gen_len": 27.416,
      "eval_loss": 2.809852123260498,
      "eval_runtime": 57.7597,
      "eval_samples_per_second": 17.313,
      "eval_steps_per_second": 1.091,
      "step": 18750
    },
    {
      "epoch": 0.8074373762589309,
      "grad_norm": 0.9637842774391174,
      "learning_rate": 0.00017148020434947346,
      "loss": 3.1205,
      "step": 18760
    },
    {
      "epoch": 0.807867779977619,
      "grad_norm": 0.9824212789535522,
      "learning_rate": 0.00017144770143964132,
      "loss": 3.2347,
      "step": 18770
    },
    {
      "epoch": 0.8082981836963071,
      "grad_norm": 0.9012235403060913,
      "learning_rate": 0.00017141518310335448,
      "loss": 3.0549,
      "step": 18780
    },
    {
      "epoch": 0.8087285874149953,
      "grad_norm": 0.9578210711479187,
      "learning_rate": 0.00017138264934763407,
      "loss": 3.1691,
      "step": 18790
    },
    {
      "epoch": 0.8091589911336834,
      "grad_norm": 0.9199259281158447,
      "learning_rate": 0.0001713501001795046,
      "loss": 3.1008,
      "step": 18800
    },
    {
      "epoch": 0.8091589911336834,
      "eval_bleu": 26.84690659773075,
      "eval_gen_len": 27.411,
      "eval_loss": 2.8067362308502197,
      "eval_runtime": 57.6646,
      "eval_samples_per_second": 17.342,
      "eval_steps_per_second": 1.093,
      "step": 18800
    },
    {
      "epoch": 0.8095893948523716,
      "grad_norm": 1.0188384056091309,
      "learning_rate": 0.0001713175356059938,
      "loss": 3.1784,
      "step": 18810
    },
    {
      "epoch": 0.8100197985710597,
      "grad_norm": 0.864364504814148,
      "learning_rate": 0.00017128495563413276,
      "loss": 3.113,
      "step": 18820
    },
    {
      "epoch": 0.8104502022897477,
      "grad_norm": 0.8482152819633484,
      "learning_rate": 0.00017125236027095588,
      "loss": 3.0077,
      "step": 18830
    },
    {
      "epoch": 0.8108806060084359,
      "grad_norm": 0.8510863780975342,
      "learning_rate": 0.00017121974952350098,
      "loss": 3.1978,
      "step": 18840
    },
    {
      "epoch": 0.811311009727124,
      "grad_norm": 0.9464660882949829,
      "learning_rate": 0.00017118712339880907,
      "loss": 3.1836,
      "step": 18850
    },
    {
      "epoch": 0.811311009727124,
      "eval_bleu": 26.40015406474996,
      "eval_gen_len": 27.388,
      "eval_loss": 2.808958053588867,
      "eval_runtime": 57.5539,
      "eval_samples_per_second": 17.375,
      "eval_steps_per_second": 1.095,
      "step": 18850
    },
    {
      "epoch": 0.8117414134458122,
      "grad_norm": 0.8920908570289612,
      "learning_rate": 0.00017115448190392458,
      "loss": 3.0948,
      "step": 18860
    },
    {
      "epoch": 0.8121718171645003,
      "grad_norm": 0.8668274879455566,
      "learning_rate": 0.00017112182504589515,
      "loss": 3.1066,
      "step": 18870
    },
    {
      "epoch": 0.8126022208831885,
      "grad_norm": 0.9171513319015503,
      "learning_rate": 0.0001710891528317719,
      "loss": 3.0637,
      "step": 18880
    },
    {
      "epoch": 0.8130326246018765,
      "grad_norm": 0.9076463580131531,
      "learning_rate": 0.00017105646526860912,
      "loss": 3.1122,
      "step": 18890
    },
    {
      "epoch": 0.8134630283205647,
      "grad_norm": 0.8583588004112244,
      "learning_rate": 0.00017102376236346445,
      "loss": 3.018,
      "step": 18900
    },
    {
      "epoch": 0.8134630283205647,
      "eval_bleu": 26.30493608734249,
      "eval_gen_len": 27.357,
      "eval_loss": 2.811765670776367,
      "eval_runtime": 57.7726,
      "eval_samples_per_second": 17.309,
      "eval_steps_per_second": 1.09,
      "step": 18900
    },
    {
      "epoch": 0.8138934320392528,
      "grad_norm": 0.9653623104095459,
      "learning_rate": 0.00017099104412339887,
      "loss": 3.0585,
      "step": 18910
    },
    {
      "epoch": 0.814323835757941,
      "grad_norm": 0.8202214241027832,
      "learning_rate": 0.00017095831055547665,
      "loss": 3.078,
      "step": 18920
    },
    {
      "epoch": 0.8147542394766291,
      "grad_norm": 0.9709504842758179,
      "learning_rate": 0.00017092556166676545,
      "loss": 3.1984,
      "step": 18930
    },
    {
      "epoch": 0.8151846431953172,
      "grad_norm": 0.891776978969574,
      "learning_rate": 0.0001708927974643361,
      "loss": 2.9696,
      "step": 18940
    },
    {
      "epoch": 0.8156150469140053,
      "grad_norm": 0.8490894436836243,
      "learning_rate": 0.00017086001795526277,
      "loss": 3.0753,
      "step": 18950
    },
    {
      "epoch": 0.8156150469140053,
      "eval_bleu": 26.59544523723596,
      "eval_gen_len": 27.436,
      "eval_loss": 2.8073878288269043,
      "eval_runtime": 58.5442,
      "eval_samples_per_second": 17.081,
      "eval_steps_per_second": 1.076,
      "step": 18950
    },
    {
      "epoch": 0.8160454506326935,
      "grad_norm": 1.0795224905014038,
      "learning_rate": 0.000170827223146623,
      "loss": 3.0816,
      "step": 18960
    },
    {
      "epoch": 0.8164758543513816,
      "grad_norm": 0.8425004482269287,
      "learning_rate": 0.00017079441304549764,
      "loss": 3.1834,
      "step": 18970
    },
    {
      "epoch": 0.8169062580700698,
      "grad_norm": 0.9109787344932556,
      "learning_rate": 0.00017076158765897073,
      "loss": 2.9495,
      "step": 18980
    },
    {
      "epoch": 0.8173366617887579,
      "grad_norm": 0.9045068025588989,
      "learning_rate": 0.00017072874699412978,
      "loss": 3.0944,
      "step": 18990
    },
    {
      "epoch": 0.8177670655074459,
      "grad_norm": 0.8234739303588867,
      "learning_rate": 0.0001706958910580654,
      "loss": 3.0954,
      "step": 19000
    },
    {
      "epoch": 0.8177670655074459,
      "eval_bleu": 26.700100496036484,
      "eval_gen_len": 27.53,
      "eval_loss": 2.8109214305877686,
      "eval_runtime": 58.3778,
      "eval_samples_per_second": 17.13,
      "eval_steps_per_second": 1.079,
      "step": 19000
    },
    {
      "epoch": 0.8181974692261341,
      "grad_norm": 0.9078642725944519,
      "learning_rate": 0.00017066301985787166,
      "loss": 3.1371,
      "step": 19010
    },
    {
      "epoch": 0.8186278729448222,
      "grad_norm": 0.9410614371299744,
      "learning_rate": 0.00017063013340064585,
      "loss": 3.0782,
      "step": 19020
    },
    {
      "epoch": 0.8190582766635104,
      "grad_norm": 0.9399613738059998,
      "learning_rate": 0.00017059723169348854,
      "loss": 3.1216,
      "step": 19030
    },
    {
      "epoch": 0.8194886803821985,
      "grad_norm": 0.8803504705429077,
      "learning_rate": 0.00017056431474350364,
      "loss": 3.1361,
      "step": 19040
    },
    {
      "epoch": 0.8199190841008867,
      "grad_norm": 0.8389722108840942,
      "learning_rate": 0.00017053138255779837,
      "loss": 3.2106,
      "step": 19050
    },
    {
      "epoch": 0.8199190841008867,
      "eval_bleu": 26.79256504731821,
      "eval_gen_len": 27.416,
      "eval_loss": 2.80953311920166,
      "eval_runtime": 57.6115,
      "eval_samples_per_second": 17.358,
      "eval_steps_per_second": 1.094,
      "step": 19050
    },
    {
      "epoch": 0.8203494878195747,
      "grad_norm": 0.9145163893699646,
      "learning_rate": 0.00017049843514348317,
      "loss": 3.0827,
      "step": 19060
    },
    {
      "epoch": 0.8207798915382629,
      "grad_norm": 0.8617284893989563,
      "learning_rate": 0.00017046547250767179,
      "loss": 2.9956,
      "step": 19070
    },
    {
      "epoch": 0.821210295256951,
      "grad_norm": 0.8081896305084229,
      "learning_rate": 0.00017043249465748125,
      "loss": 3.1044,
      "step": 19080
    },
    {
      "epoch": 0.8216406989756392,
      "grad_norm": 0.9632390141487122,
      "learning_rate": 0.00017039950160003197,
      "loss": 3.0441,
      "step": 19090
    },
    {
      "epoch": 0.8220711026943273,
      "grad_norm": 0.8125175833702087,
      "learning_rate": 0.0001703664933424475,
      "loss": 3.0738,
      "step": 19100
    },
    {
      "epoch": 0.8220711026943273,
      "eval_bleu": 26.71627533789675,
      "eval_gen_len": 27.416,
      "eval_loss": 2.806626081466675,
      "eval_runtime": 57.7988,
      "eval_samples_per_second": 17.301,
      "eval_steps_per_second": 1.09,
      "step": 19100
    },
    {
      "epoch": 0.8225015064130154,
      "grad_norm": 0.9093649983406067,
      "learning_rate": 0.00017033346989185473,
      "loss": 3.0854,
      "step": 19110
    },
    {
      "epoch": 0.8229319101317035,
      "grad_norm": 0.8957718014717102,
      "learning_rate": 0.00017030043125538385,
      "loss": 3.1856,
      "step": 19120
    },
    {
      "epoch": 0.8233623138503917,
      "grad_norm": 0.8227353692054749,
      "learning_rate": 0.00017026737744016835,
      "loss": 3.1174,
      "step": 19130
    },
    {
      "epoch": 0.8237927175690798,
      "grad_norm": 0.9222418665885925,
      "learning_rate": 0.00017023430845334493,
      "loss": 3.1055,
      "step": 19140
    },
    {
      "epoch": 0.824223121287768,
      "grad_norm": 0.9068642258644104,
      "learning_rate": 0.0001702012243020536,
      "loss": 3.0977,
      "step": 19150
    },
    {
      "epoch": 0.824223121287768,
      "eval_bleu": 26.721364097123143,
      "eval_gen_len": 27.333,
      "eval_loss": 2.8063454627990723,
      "eval_runtime": 57.5766,
      "eval_samples_per_second": 17.368,
      "eval_steps_per_second": 1.094,
      "step": 19150
    },
    {
      "epoch": 0.8246535250064561,
      "grad_norm": 0.8688651919364929,
      "learning_rate": 0.00017016812499343764,
      "loss": 3.0044,
      "step": 19160
    },
    {
      "epoch": 0.8250839287251441,
      "grad_norm": 0.9341773986816406,
      "learning_rate": 0.00017013501053464363,
      "loss": 3.0604,
      "step": 19170
    },
    {
      "epoch": 0.8255143324438323,
      "grad_norm": 1.0134587287902832,
      "learning_rate": 0.00017010188093282138,
      "loss": 3.2105,
      "step": 19180
    },
    {
      "epoch": 0.8259447361625204,
      "grad_norm": 0.8420982956886292,
      "learning_rate": 0.00017006873619512396,
      "loss": 3.0895,
      "step": 19190
    },
    {
      "epoch": 0.8263751398812086,
      "grad_norm": 0.9048322439193726,
      "learning_rate": 0.00017003557632870776,
      "loss": 3.0502,
      "step": 19200
    },
    {
      "epoch": 0.8263751398812086,
      "eval_bleu": 27.212813909096038,
      "eval_gen_len": 27.352,
      "eval_loss": 2.8055856227874756,
      "eval_runtime": 57.6294,
      "eval_samples_per_second": 17.352,
      "eval_steps_per_second": 1.093,
      "step": 19200
    },
    {
      "epoch": 0.8268055435998967,
      "grad_norm": 0.9711194038391113,
      "learning_rate": 0.00017000240134073247,
      "loss": 3.1198,
      "step": 19210
    },
    {
      "epoch": 0.8272359473185849,
      "grad_norm": 0.9292662143707275,
      "learning_rate": 0.00016996921123836085,
      "loss": 3.1421,
      "step": 19220
    },
    {
      "epoch": 0.8276663510372729,
      "grad_norm": 0.8748718500137329,
      "learning_rate": 0.00016993600602875918,
      "loss": 3.045,
      "step": 19230
    },
    {
      "epoch": 0.8280967547559611,
      "grad_norm": 0.9367777705192566,
      "learning_rate": 0.00016990278571909684,
      "loss": 3.1406,
      "step": 19240
    },
    {
      "epoch": 0.8285271584746492,
      "grad_norm": 0.8434250354766846,
      "learning_rate": 0.0001698695503165465,
      "loss": 3.0268,
      "step": 19250
    },
    {
      "epoch": 0.8285271584746492,
      "eval_bleu": 26.773922693573017,
      "eval_gen_len": 27.459,
      "eval_loss": 2.807887554168701,
      "eval_runtime": 58.647,
      "eval_samples_per_second": 17.051,
      "eval_steps_per_second": 1.074,
      "step": 19250
    },
    {
      "epoch": 0.8289575621933374,
      "grad_norm": 0.8930071592330933,
      "learning_rate": 0.0001698362998282841,
      "loss": 3.1802,
      "step": 19260
    },
    {
      "epoch": 0.8293879659120255,
      "grad_norm": 0.8698945045471191,
      "learning_rate": 0.00016980303426148886,
      "loss": 3.1287,
      "step": 19270
    },
    {
      "epoch": 0.8298183696307136,
      "grad_norm": 0.875353991985321,
      "learning_rate": 0.0001697697536233432,
      "loss": 3.0667,
      "step": 19280
    },
    {
      "epoch": 0.8302487733494017,
      "grad_norm": 0.9274212718009949,
      "learning_rate": 0.0001697364579210329,
      "loss": 3.1008,
      "step": 19290
    },
    {
      "epoch": 0.8306791770680899,
      "grad_norm": 0.8468190431594849,
      "learning_rate": 0.00016970314716174682,
      "loss": 3.1376,
      "step": 19300
    },
    {
      "epoch": 0.8306791770680899,
      "eval_bleu": 26.571225536286548,
      "eval_gen_len": 27.479,
      "eval_loss": 2.8020691871643066,
      "eval_runtime": 58.3317,
      "eval_samples_per_second": 17.143,
      "eval_steps_per_second": 1.08,
      "step": 19300
    },
    {
      "epoch": 0.831109580786778,
      "grad_norm": 0.7851371169090271,
      "learning_rate": 0.00016966982135267723,
      "loss": 3.0952,
      "step": 19310
    },
    {
      "epoch": 0.8315399845054662,
      "grad_norm": 0.9508910179138184,
      "learning_rate": 0.00016963648050101956,
      "loss": 3.0199,
      "step": 19320
    },
    {
      "epoch": 0.8319703882241543,
      "grad_norm": 0.9211186766624451,
      "learning_rate": 0.00016960312461397257,
      "loss": 3.0726,
      "step": 19330
    },
    {
      "epoch": 0.8324007919428423,
      "grad_norm": 0.9331501722335815,
      "learning_rate": 0.00016956975369873816,
      "loss": 3.1152,
      "step": 19340
    },
    {
      "epoch": 0.8328311956615305,
      "grad_norm": 0.9630509614944458,
      "learning_rate": 0.00016953636776252155,
      "loss": 3.231,
      "step": 19350
    },
    {
      "epoch": 0.8328311956615305,
      "eval_bleu": 26.72888381392303,
      "eval_gen_len": 27.431,
      "eval_loss": 2.805859327316284,
      "eval_runtime": 57.5019,
      "eval_samples_per_second": 17.391,
      "eval_steps_per_second": 1.096,
      "step": 19350
    },
    {
      "epoch": 0.8332615993802186,
      "grad_norm": 0.9571950435638428,
      "learning_rate": 0.0001695029668125312,
      "loss": 3.1169,
      "step": 19360
    },
    {
      "epoch": 0.8336920030989068,
      "grad_norm": 0.9444241523742676,
      "learning_rate": 0.00016946955085597875,
      "loss": 3.0568,
      "step": 19370
    },
    {
      "epoch": 0.8341224068175949,
      "grad_norm": 0.9281295537948608,
      "learning_rate": 0.00016943611990007915,
      "loss": 3.0008,
      "step": 19380
    },
    {
      "epoch": 0.834552810536283,
      "grad_norm": 0.9315198063850403,
      "learning_rate": 0.00016940267395205055,
      "loss": 3.0237,
      "step": 19390
    },
    {
      "epoch": 0.8349832142549711,
      "grad_norm": 0.9124487042427063,
      "learning_rate": 0.0001693692130191144,
      "loss": 3.1792,
      "step": 19400
    },
    {
      "epoch": 0.8349832142549711,
      "eval_bleu": 26.673911478861314,
      "eval_gen_len": 27.446,
      "eval_loss": 2.8024096488952637,
      "eval_runtime": 57.3675,
      "eval_samples_per_second": 17.431,
      "eval_steps_per_second": 1.098,
      "step": 19400
    },
    {
      "epoch": 0.8354136179736593,
      "grad_norm": 0.9345874786376953,
      "learning_rate": 0.00016933573710849528,
      "loss": 3.11,
      "step": 19410
    },
    {
      "epoch": 0.8358440216923474,
      "grad_norm": 0.929064154624939,
      "learning_rate": 0.00016930224622742105,
      "loss": 3.0893,
      "step": 19420
    },
    {
      "epoch": 0.8362744254110356,
      "grad_norm": 0.9957621693611145,
      "learning_rate": 0.00016926874038312287,
      "loss": 3.2154,
      "step": 19430
    },
    {
      "epoch": 0.8367048291297237,
      "grad_norm": 0.9457353949546814,
      "learning_rate": 0.00016923521958283502,
      "loss": 3.0464,
      "step": 19440
    },
    {
      "epoch": 0.8371352328484118,
      "grad_norm": 0.9816279411315918,
      "learning_rate": 0.0001692016838337951,
      "loss": 3.0632,
      "step": 19450
    },
    {
      "epoch": 0.8371352328484118,
      "eval_bleu": 26.479986934716667,
      "eval_gen_len": 27.49,
      "eval_loss": 2.8080172538757324,
      "eval_runtime": 57.6058,
      "eval_samples_per_second": 17.359,
      "eval_steps_per_second": 1.094,
      "step": 19450
    },
    {
      "epoch": 0.8375656365670999,
      "grad_norm": 0.9680072665214539,
      "learning_rate": 0.00016916813314324386,
      "loss": 3.1353,
      "step": 19460
    },
    {
      "epoch": 0.8379960402857881,
      "grad_norm": 0.8740391731262207,
      "learning_rate": 0.0001691345675184253,
      "loss": 3.1491,
      "step": 19470
    },
    {
      "epoch": 0.8384264440044762,
      "grad_norm": 0.9934391379356384,
      "learning_rate": 0.00016910098696658676,
      "loss": 3.1737,
      "step": 19480
    },
    {
      "epoch": 0.8388568477231644,
      "grad_norm": 0.9760257601737976,
      "learning_rate": 0.00016906739149497862,
      "loss": 3.1377,
      "step": 19490
    },
    {
      "epoch": 0.8392872514418525,
      "grad_norm": 0.9274486303329468,
      "learning_rate": 0.00016903378111085454,
      "loss": 3.0882,
      "step": 19500
    },
    {
      "epoch": 0.8392872514418525,
      "eval_bleu": 26.71999758838647,
      "eval_gen_len": 27.459,
      "eval_loss": 2.8042354583740234,
      "eval_runtime": 58.7394,
      "eval_samples_per_second": 17.024,
      "eval_steps_per_second": 1.073,
      "step": 19500
    },
    {
      "epoch": 0.8397176551605405,
      "grad_norm": 0.7783628702163696,
      "learning_rate": 0.0001690001558214715,
      "loss": 3.0499,
      "step": 19510
    },
    {
      "epoch": 0.8401480588792287,
      "grad_norm": 0.9568380117416382,
      "learning_rate": 0.00016896651563408957,
      "loss": 3.1309,
      "step": 19520
    },
    {
      "epoch": 0.8405784625979168,
      "grad_norm": 0.8870548605918884,
      "learning_rate": 0.00016893286055597208,
      "loss": 3.1328,
      "step": 19530
    },
    {
      "epoch": 0.841008866316605,
      "grad_norm": 1.0197134017944336,
      "learning_rate": 0.00016889919059438562,
      "loss": 3.1334,
      "step": 19540
    },
    {
      "epoch": 0.8414392700352931,
      "grad_norm": 0.9969643354415894,
      "learning_rate": 0.00016886550575659993,
      "loss": 3.1113,
      "step": 19550
    },
    {
      "epoch": 0.8414392700352931,
      "eval_bleu": 26.622221644559023,
      "eval_gen_len": 27.376,
      "eval_loss": 2.8092098236083984,
      "eval_runtime": 58.3605,
      "eval_samples_per_second": 17.135,
      "eval_steps_per_second": 1.079,
      "step": 19550
    },
    {
      "epoch": 0.8418696737539813,
      "grad_norm": 0.9048312902450562,
      "learning_rate": 0.00016883180604988803,
      "loss": 3.1722,
      "step": 19560
    },
    {
      "epoch": 0.8423000774726693,
      "grad_norm": 1.011294960975647,
      "learning_rate": 0.00016879809148152608,
      "loss": 3.0196,
      "step": 19570
    },
    {
      "epoch": 0.8427304811913575,
      "grad_norm": 0.8292204141616821,
      "learning_rate": 0.00016876436205879344,
      "loss": 3.0055,
      "step": 19580
    },
    {
      "epoch": 0.8431608849100456,
      "grad_norm": 0.9037085175514221,
      "learning_rate": 0.00016873061778897278,
      "loss": 3.0697,
      "step": 19590
    },
    {
      "epoch": 0.8435912886287338,
      "grad_norm": 0.9986342191696167,
      "learning_rate": 0.0001686968586793499,
      "loss": 3.0803,
      "step": 19600
    },
    {
      "epoch": 0.8435912886287338,
      "eval_bleu": 26.551417532921636,
      "eval_gen_len": 27.42,
      "eval_loss": 2.8086838722229004,
      "eval_runtime": 58.466,
      "eval_samples_per_second": 17.104,
      "eval_steps_per_second": 1.078,
      "step": 19600
    },
    {
      "epoch": 0.8440216923474219,
      "grad_norm": 0.798670768737793,
      "learning_rate": 0.00016866308473721377,
      "loss": 3.0398,
      "step": 19610
    },
    {
      "epoch": 0.84445209606611,
      "grad_norm": 0.9069505333900452,
      "learning_rate": 0.00016862929596985664,
      "loss": 3.1309,
      "step": 19620
    },
    {
      "epoch": 0.8448824997847981,
      "grad_norm": 0.92681884765625,
      "learning_rate": 0.00016859549238457393,
      "loss": 3.0619,
      "step": 19630
    },
    {
      "epoch": 0.8453129035034863,
      "grad_norm": 0.7426938414573669,
      "learning_rate": 0.00016856167398866426,
      "loss": 3.0328,
      "step": 19640
    },
    {
      "epoch": 0.8457433072221744,
      "grad_norm": 0.89988112449646,
      "learning_rate": 0.00016852784078942942,
      "loss": 2.9716,
      "step": 19650
    },
    {
      "epoch": 0.8457433072221744,
      "eval_bleu": 26.789017612616995,
      "eval_gen_len": 27.39,
      "eval_loss": 2.8037631511688232,
      "eval_runtime": 57.7928,
      "eval_samples_per_second": 17.303,
      "eval_steps_per_second": 1.09,
      "step": 19650
    },
    {
      "epoch": 0.8461737109408626,
      "grad_norm": 0.9131150245666504,
      "learning_rate": 0.00016849399279417448,
      "loss": 3.0648,
      "step": 19660
    },
    {
      "epoch": 0.8466041146595507,
      "grad_norm": 0.8333912491798401,
      "learning_rate": 0.00016846013001020757,
      "loss": 3.076,
      "step": 19670
    },
    {
      "epoch": 0.8470345183782388,
      "grad_norm": 0.7827264070510864,
      "learning_rate": 0.00016842625244484015,
      "loss": 3.0837,
      "step": 19680
    },
    {
      "epoch": 0.8474649220969269,
      "grad_norm": 0.9066987633705139,
      "learning_rate": 0.00016839236010538676,
      "loss": 3.1161,
      "step": 19690
    },
    {
      "epoch": 0.847895325815615,
      "grad_norm": 0.9535252451896667,
      "learning_rate": 0.00016835845299916527,
      "loss": 3.0136,
      "step": 19700
    },
    {
      "epoch": 0.847895325815615,
      "eval_bleu": 26.870769850204407,
      "eval_gen_len": 27.399,
      "eval_loss": 2.804326057434082,
      "eval_runtime": 57.4198,
      "eval_samples_per_second": 17.416,
      "eval_steps_per_second": 1.097,
      "step": 19700
    },
    {
      "epoch": 0.8483257295343032,
      "grad_norm": 0.833986759185791,
      "learning_rate": 0.00016832453113349653,
      "loss": 3.1649,
      "step": 19710
    },
    {
      "epoch": 0.8487561332529913,
      "grad_norm": 0.9328680634498596,
      "learning_rate": 0.00016829059451570476,
      "loss": 2.981,
      "step": 19720
    },
    {
      "epoch": 0.8491865369716795,
      "grad_norm": 0.8412505984306335,
      "learning_rate": 0.0001682566431531173,
      "loss": 3.1236,
      "step": 19730
    },
    {
      "epoch": 0.8496169406903675,
      "grad_norm": 0.9649348855018616,
      "learning_rate": 0.0001682226770530647,
      "loss": 3.089,
      "step": 19740
    },
    {
      "epoch": 0.8500473444090557,
      "grad_norm": 0.8282386660575867,
      "learning_rate": 0.0001681886962228806,
      "loss": 3.1442,
      "step": 19750
    },
    {
      "epoch": 0.8500473444090557,
      "eval_bleu": 26.467703844344985,
      "eval_gen_len": 27.3,
      "eval_loss": 2.8076388835906982,
      "eval_runtime": 58.1387,
      "eval_samples_per_second": 17.2,
      "eval_steps_per_second": 1.084,
      "step": 19750
    },
    {
      "epoch": 0.8504777481277438,
      "grad_norm": 0.9893370866775513,
      "learning_rate": 0.00016815470066990198,
      "loss": 3.0632,
      "step": 19760
    },
    {
      "epoch": 0.850908151846432,
      "grad_norm": 0.9003425240516663,
      "learning_rate": 0.0001681206904014688,
      "loss": 3.0458,
      "step": 19770
    },
    {
      "epoch": 0.8513385555651201,
      "grad_norm": 0.8219820261001587,
      "learning_rate": 0.00016808666542492438,
      "loss": 3.081,
      "step": 19780
    },
    {
      "epoch": 0.8517689592838082,
      "grad_norm": 0.9365851879119873,
      "learning_rate": 0.00016805262574761512,
      "loss": 2.9823,
      "step": 19790
    },
    {
      "epoch": 0.8521993630024963,
      "grad_norm": 0.9537845849990845,
      "learning_rate": 0.00016801857137689057,
      "loss": 3.0738,
      "step": 19800
    },
    {
      "epoch": 0.8521993630024963,
      "eval_bleu": 26.67613764178292,
      "eval_gen_len": 27.286,
      "eval_loss": 2.8039472103118896,
      "eval_runtime": 58.1564,
      "eval_samples_per_second": 17.195,
      "eval_steps_per_second": 1.083,
      "step": 19800
    },
    {
      "epoch": 0.8526297667211845,
      "grad_norm": 0.8417157530784607,
      "learning_rate": 0.00016798450232010357,
      "loss": 3.0577,
      "step": 19810
    },
    {
      "epoch": 0.8530601704398726,
      "grad_norm": 0.9115989208221436,
      "learning_rate": 0.00016795041858461002,
      "loss": 2.9844,
      "step": 19820
    },
    {
      "epoch": 0.8534905741585608,
      "grad_norm": 0.8729825615882874,
      "learning_rate": 0.000167916320177769,
      "loss": 3.0783,
      "step": 19830
    },
    {
      "epoch": 0.8539209778772489,
      "grad_norm": 0.8452032804489136,
      "learning_rate": 0.00016788220710694285,
      "loss": 3.1509,
      "step": 19840
    },
    {
      "epoch": 0.854351381595937,
      "grad_norm": 0.9260943531990051,
      "learning_rate": 0.00016784807937949694,
      "loss": 3.2177,
      "step": 19850
    },
    {
      "epoch": 0.854351381595937,
      "eval_bleu": 26.22503566044841,
      "eval_gen_len": 27.21,
      "eval_loss": 2.8118178844451904,
      "eval_runtime": 58.225,
      "eval_samples_per_second": 17.175,
      "eval_steps_per_second": 1.082,
      "step": 19850
    },
    {
      "epoch": 0.8547817853146251,
      "grad_norm": 0.8744789958000183,
      "learning_rate": 0.0001678139370027999,
      "loss": 3.0776,
      "step": 19860
    },
    {
      "epoch": 0.8552121890333132,
      "grad_norm": 0.8827633857727051,
      "learning_rate": 0.0001677797799842235,
      "loss": 3.1326,
      "step": 19870
    },
    {
      "epoch": 0.8556425927520014,
      "grad_norm": 0.9570947885513306,
      "learning_rate": 0.0001677456083311427,
      "loss": 3.1,
      "step": 19880
    },
    {
      "epoch": 0.8560729964706895,
      "grad_norm": 0.9910210967063904,
      "learning_rate": 0.00016771142205093554,
      "loss": 3.0697,
      "step": 19890
    },
    {
      "epoch": 0.8565034001893777,
      "grad_norm": 0.9285196661949158,
      "learning_rate": 0.00016767722115098324,
      "loss": 3.0766,
      "step": 19900
    },
    {
      "epoch": 0.8565034001893777,
      "eval_bleu": 26.75575308674511,
      "eval_gen_len": 27.318,
      "eval_loss": 2.8059263229370117,
      "eval_runtime": 57.8807,
      "eval_samples_per_second": 17.277,
      "eval_steps_per_second": 1.088,
      "step": 19900
    },
    {
      "epoch": 0.8569338039080657,
      "grad_norm": 0.920307457447052,
      "learning_rate": 0.00016764300563867034,
      "loss": 3.0625,
      "step": 19910
    },
    {
      "epoch": 0.8573642076267539,
      "grad_norm": 0.9131752848625183,
      "learning_rate": 0.00016760877552138422,
      "loss": 3.141,
      "step": 19920
    },
    {
      "epoch": 0.857794611345442,
      "grad_norm": 0.989102840423584,
      "learning_rate": 0.00016757453080651572,
      "loss": 3.1801,
      "step": 19930
    },
    {
      "epoch": 0.8582250150641302,
      "grad_norm": 0.8610934019088745,
      "learning_rate": 0.00016754027150145867,
      "loss": 3.0405,
      "step": 19940
    },
    {
      "epoch": 0.8586554187828183,
      "grad_norm": 0.8359650373458862,
      "learning_rate": 0.00016750599761361002,
      "loss": 3.0262,
      "step": 19950
    },
    {
      "epoch": 0.8586554187828183,
      "eval_bleu": 26.199500580404038,
      "eval_gen_len": 27.249,
      "eval_loss": 2.8112690448760986,
      "eval_runtime": 57.5891,
      "eval_samples_per_second": 17.364,
      "eval_steps_per_second": 1.094,
      "step": 19950
    },
    {
      "epoch": 0.8590858225015064,
      "grad_norm": 0.9500235915184021,
      "learning_rate": 0.00016747170915037006,
      "loss": 3.0979,
      "step": 19960
    },
    {
      "epoch": 0.8595162262201945,
      "grad_norm": 0.9725549221038818,
      "learning_rate": 0.00016743740611914197,
      "loss": 3.0459,
      "step": 19970
    },
    {
      "epoch": 0.8599466299388827,
      "grad_norm": 1.0134116411209106,
      "learning_rate": 0.0001674030885273323,
      "loss": 3.0817,
      "step": 19980
    },
    {
      "epoch": 0.8603770336575708,
      "grad_norm": 0.8460531830787659,
      "learning_rate": 0.00016736875638235057,
      "loss": 3.165,
      "step": 19990
    },
    {
      "epoch": 0.860807437376259,
      "grad_norm": 0.9005998373031616,
      "learning_rate": 0.00016733440969160957,
      "loss": 3.1152,
      "step": 20000
    },
    {
      "epoch": 0.860807437376259,
      "eval_bleu": 26.67238777629094,
      "eval_gen_len": 27.57,
      "eval_loss": 2.8034842014312744,
      "eval_runtime": 58.8619,
      "eval_samples_per_second": 16.989,
      "eval_steps_per_second": 1.07,
      "step": 20000
    },
    {
      "epoch": 0.861237841094947,
      "grad_norm": 0.8746156096458435,
      "learning_rate": 0.00016730004846252517,
      "loss": 3.0192,
      "step": 20010
    },
    {
      "epoch": 0.8616682448136352,
      "grad_norm": 0.9561342000961304,
      "learning_rate": 0.0001672656727025164,
      "loss": 3.0282,
      "step": 20020
    },
    {
      "epoch": 0.8620986485323233,
      "grad_norm": 0.9024398326873779,
      "learning_rate": 0.00016723128241900542,
      "loss": 3.0985,
      "step": 20030
    },
    {
      "epoch": 0.8625290522510114,
      "grad_norm": 0.8364403247833252,
      "learning_rate": 0.0001671968776194175,
      "loss": 3.0552,
      "step": 20040
    },
    {
      "epoch": 0.8629594559696996,
      "grad_norm": 0.9090531468391418,
      "learning_rate": 0.00016716245831118105,
      "loss": 3.0958,
      "step": 20050
    },
    {
      "epoch": 0.8629594559696996,
      "eval_bleu": 26.43039987125402,
      "eval_gen_len": 27.419,
      "eval_loss": 2.8056728839874268,
      "eval_runtime": 58.7077,
      "eval_samples_per_second": 17.034,
      "eval_steps_per_second": 1.073,
      "step": 20050
    },
    {
      "epoch": 0.8633898596883877,
      "grad_norm": 0.9795029163360596,
      "learning_rate": 0.00016712802450172772,
      "loss": 3.1045,
      "step": 20060
    },
    {
      "epoch": 0.8638202634070759,
      "grad_norm": 1.0201865434646606,
      "learning_rate": 0.00016709357619849207,
      "loss": 3.0859,
      "step": 20070
    },
    {
      "epoch": 0.8642506671257639,
      "grad_norm": 0.968115508556366,
      "learning_rate": 0.00016705911340891204,
      "loss": 3.2535,
      "step": 20080
    },
    {
      "epoch": 0.8646810708444521,
      "grad_norm": 0.9101348519325256,
      "learning_rate": 0.00016702463614042852,
      "loss": 3.0445,
      "step": 20090
    },
    {
      "epoch": 0.8651114745631402,
      "grad_norm": 0.8471274375915527,
      "learning_rate": 0.0001669901444004856,
      "loss": 3.11,
      "step": 20100
    },
    {
      "epoch": 0.8651114745631402,
      "eval_bleu": 26.90709167379659,
      "eval_gen_len": 27.449,
      "eval_loss": 2.805518865585327,
      "eval_runtime": 58.5182,
      "eval_samples_per_second": 17.089,
      "eval_steps_per_second": 1.077,
      "step": 20100
    },
    {
      "epoch": 0.8655418782818284,
      "grad_norm": 0.8304389715194702,
      "learning_rate": 0.00016695563819653044,
      "loss": 3.0828,
      "step": 20110
    },
    {
      "epoch": 0.8659722820005165,
      "grad_norm": 0.9644360542297363,
      "learning_rate": 0.00016692111753601342,
      "loss": 3.0769,
      "step": 20120
    },
    {
      "epoch": 0.8664026857192046,
      "grad_norm": 0.9858716726303101,
      "learning_rate": 0.00016688658242638798,
      "loss": 3.0549,
      "step": 20130
    },
    {
      "epoch": 0.8668330894378927,
      "grad_norm": 0.8122805953025818,
      "learning_rate": 0.00016685203287511064,
      "loss": 3.047,
      "step": 20140
    },
    {
      "epoch": 0.8672634931565809,
      "grad_norm": 0.8717455267906189,
      "learning_rate": 0.0001668174688896411,
      "loss": 3.0555,
      "step": 20150
    },
    {
      "epoch": 0.8672634931565809,
      "eval_bleu": 26.741710679789826,
      "eval_gen_len": 27.478,
      "eval_loss": 2.8048112392425537,
      "eval_runtime": 58.0943,
      "eval_samples_per_second": 17.213,
      "eval_steps_per_second": 1.084,
      "step": 20150
    },
    {
      "epoch": 0.867693896875269,
      "grad_norm": 1.004296064376831,
      "learning_rate": 0.00016678289047744217,
      "loss": 3.1069,
      "step": 20160
    },
    {
      "epoch": 0.8681243005939572,
      "grad_norm": 0.8775492310523987,
      "learning_rate": 0.00016674829764597976,
      "loss": 2.9938,
      "step": 20170
    },
    {
      "epoch": 0.8685547043126453,
      "grad_norm": 0.8143115043640137,
      "learning_rate": 0.0001667136904027229,
      "loss": 3.1385,
      "step": 20180
    },
    {
      "epoch": 0.8689851080313334,
      "grad_norm": 0.9314906001091003,
      "learning_rate": 0.0001666790687551437,
      "loss": 3.1312,
      "step": 20190
    },
    {
      "epoch": 0.8694155117500215,
      "grad_norm": 0.8043249249458313,
      "learning_rate": 0.0001666444327107174,
      "loss": 3.1568,
      "step": 20200
    },
    {
      "epoch": 0.8694155117500215,
      "eval_bleu": 26.840386738507586,
      "eval_gen_len": 27.343,
      "eval_loss": 2.805459499359131,
      "eval_runtime": 57.7875,
      "eval_samples_per_second": 17.305,
      "eval_steps_per_second": 1.09,
      "step": 20200
    },
    {
      "epoch": 0.8698459154687096,
      "grad_norm": 0.928159236907959,
      "learning_rate": 0.0001666097822769224,
      "loss": 3.0359,
      "step": 20210
    },
    {
      "epoch": 0.8702763191873978,
      "grad_norm": 0.9392634630203247,
      "learning_rate": 0.0001665751174612402,
      "loss": 3.1371,
      "step": 20220
    },
    {
      "epoch": 0.8707067229060859,
      "grad_norm": 0.8260013461112976,
      "learning_rate": 0.00016654043827115528,
      "loss": 3.0823,
      "step": 20230
    },
    {
      "epoch": 0.871137126624774,
      "grad_norm": 0.8717995285987854,
      "learning_rate": 0.0001665057447141553,
      "loss": 3.1454,
      "step": 20240
    },
    {
      "epoch": 0.8715675303434621,
      "grad_norm": 0.9865022301673889,
      "learning_rate": 0.00016647103679773113,
      "loss": 3.092,
      "step": 20250
    },
    {
      "epoch": 0.8715675303434621,
      "eval_bleu": 26.366648796766597,
      "eval_gen_len": 27.35,
      "eval_loss": 2.8079519271850586,
      "eval_runtime": 57.8873,
      "eval_samples_per_second": 17.275,
      "eval_steps_per_second": 1.088,
      "step": 20250
    },
    {
      "epoch": 0.8719979340621503,
      "grad_norm": 0.8617936968803406,
      "learning_rate": 0.0001664363145293766,
      "loss": 3.0604,
      "step": 20260
    },
    {
      "epoch": 0.8724283377808384,
      "grad_norm": 0.8424561023712158,
      "learning_rate": 0.00016640157791658866,
      "loss": 3.1231,
      "step": 20270
    },
    {
      "epoch": 0.8728587414995266,
      "grad_norm": 0.9664786458015442,
      "learning_rate": 0.0001663668269668674,
      "loss": 3.1456,
      "step": 20280
    },
    {
      "epoch": 0.8732891452182147,
      "grad_norm": 0.8782809376716614,
      "learning_rate": 0.000166332061687716,
      "loss": 3.0583,
      "step": 20290
    },
    {
      "epoch": 0.8737195489369028,
      "grad_norm": 0.8030580878257751,
      "learning_rate": 0.00016629728208664065,
      "loss": 3.121,
      "step": 20300
    },
    {
      "epoch": 0.8737195489369028,
      "eval_bleu": 26.631923782176624,
      "eval_gen_len": 27.36,
      "eval_loss": 2.805018424987793,
      "eval_runtime": 57.7413,
      "eval_samples_per_second": 17.319,
      "eval_steps_per_second": 1.091,
      "step": 20300
    },
    {
      "epoch": 0.8741499526555909,
      "grad_norm": 0.8467273712158203,
      "learning_rate": 0.0001662624881711508,
      "loss": 3.1261,
      "step": 20310
    },
    {
      "epoch": 0.8745803563742791,
      "grad_norm": 0.8579219579696655,
      "learning_rate": 0.00016622767994875883,
      "loss": 3.0383,
      "step": 20320
    },
    {
      "epoch": 0.8750107600929672,
      "grad_norm": 0.9531747698783875,
      "learning_rate": 0.00016619285742698028,
      "loss": 3.1351,
      "step": 20330
    },
    {
      "epoch": 0.8754411638116554,
      "grad_norm": 1.0138359069824219,
      "learning_rate": 0.00016615802061333384,
      "loss": 3.0881,
      "step": 20340
    },
    {
      "epoch": 0.8758715675303435,
      "grad_norm": 0.906761884689331,
      "learning_rate": 0.0001661231695153411,
      "loss": 3.0964,
      "step": 20350
    },
    {
      "epoch": 0.8758715675303435,
      "eval_bleu": 26.472598998432883,
      "eval_gen_len": 27.334,
      "eval_loss": 2.808195114135742,
      "eval_runtime": 58.4219,
      "eval_samples_per_second": 17.117,
      "eval_steps_per_second": 1.078,
      "step": 20350
    },
    {
      "epoch": 0.8763019712490316,
      "grad_norm": 0.9559569954872131,
      "learning_rate": 0.00016608830414052692,
      "loss": 3.0866,
      "step": 20360
    },
    {
      "epoch": 0.8767323749677197,
      "grad_norm": 0.909984827041626,
      "learning_rate": 0.00016605342449641915,
      "loss": 3.1566,
      "step": 20370
    },
    {
      "epoch": 0.8771627786864078,
      "grad_norm": 0.8420453071594238,
      "learning_rate": 0.00016601853059054872,
      "loss": 3.0186,
      "step": 20380
    },
    {
      "epoch": 0.877593182405096,
      "grad_norm": 1.020202875137329,
      "learning_rate": 0.0001659836224304497,
      "loss": 3.1371,
      "step": 20390
    },
    {
      "epoch": 0.8780235861237841,
      "grad_norm": 0.8775212168693542,
      "learning_rate": 0.00016594870002365923,
      "loss": 3.1504,
      "step": 20400
    },
    {
      "epoch": 0.8780235861237841,
      "eval_bleu": 26.704687838483682,
      "eval_gen_len": 27.523,
      "eval_loss": 2.8074278831481934,
      "eval_runtime": 58.8588,
      "eval_samples_per_second": 16.99,
      "eval_steps_per_second": 1.07,
      "step": 20400
    },
    {
      "epoch": 0.8784539898424722,
      "grad_norm": 0.9277061820030212,
      "learning_rate": 0.0001659137633777174,
      "loss": 3.1109,
      "step": 20410
    },
    {
      "epoch": 0.8788843935611603,
      "grad_norm": 0.9460464119911194,
      "learning_rate": 0.00016587881250016757,
      "loss": 3.0751,
      "step": 20420
    },
    {
      "epoch": 0.8793147972798485,
      "grad_norm": 0.8704456686973572,
      "learning_rate": 0.00016584384739855602,
      "loss": 3.0719,
      "step": 20430
    },
    {
      "epoch": 0.8797452009985366,
      "grad_norm": 0.9245694875717163,
      "learning_rate": 0.00016580886808043214,
      "loss": 3.1199,
      "step": 20440
    },
    {
      "epoch": 0.8801756047172248,
      "grad_norm": 0.8823703527450562,
      "learning_rate": 0.00016577387455334844,
      "loss": 3.1142,
      "step": 20450
    },
    {
      "epoch": 0.8801756047172248,
      "eval_bleu": 26.656927244441118,
      "eval_gen_len": 27.529,
      "eval_loss": 2.80338454246521,
      "eval_runtime": 58.1211,
      "eval_samples_per_second": 17.205,
      "eval_steps_per_second": 1.084,
      "step": 20450
    },
    {
      "epoch": 0.8806060084359129,
      "grad_norm": 0.9338849782943726,
      "learning_rate": 0.00016573886682486042,
      "loss": 3.1281,
      "step": 20460
    },
    {
      "epoch": 0.881036412154601,
      "grad_norm": 0.9296801686286926,
      "learning_rate": 0.00016570384490252672,
      "loss": 3.0682,
      "step": 20470
    },
    {
      "epoch": 0.8814668158732891,
      "grad_norm": 0.9757401943206787,
      "learning_rate": 0.00016566880879390902,
      "loss": 3.0552,
      "step": 20480
    },
    {
      "epoch": 0.8818972195919773,
      "grad_norm": 0.8824202418327332,
      "learning_rate": 0.00016563375850657205,
      "loss": 3.073,
      "step": 20490
    },
    {
      "epoch": 0.8823276233106654,
      "grad_norm": 1.044052004814148,
      "learning_rate": 0.00016559869404808358,
      "loss": 3.0589,
      "step": 20500
    },
    {
      "epoch": 0.8823276233106654,
      "eval_bleu": 26.192538246147212,
      "eval_gen_len": 27.328,
      "eval_loss": 2.809929609298706,
      "eval_runtime": 57.8445,
      "eval_samples_per_second": 17.288,
      "eval_steps_per_second": 1.089,
      "step": 20500
    },
    {
      "epoch": 0.8827580270293536,
      "grad_norm": 1.0794174671173096,
      "learning_rate": 0.0001655636154260145,
      "loss": 3.1141,
      "step": 20510
    },
    {
      "epoch": 0.8831884307480417,
      "grad_norm": 0.819347620010376,
      "learning_rate": 0.00016552852264793867,
      "loss": 3.1722,
      "step": 20520
    },
    {
      "epoch": 0.8836188344667298,
      "grad_norm": 0.9124224185943604,
      "learning_rate": 0.00016549341572143314,
      "loss": 3.1111,
      "step": 20530
    },
    {
      "epoch": 0.8840492381854179,
      "grad_norm": 0.887680172920227,
      "learning_rate": 0.00016545829465407788,
      "loss": 2.9704,
      "step": 20540
    },
    {
      "epoch": 0.8844796419041061,
      "grad_norm": 0.8890607953071594,
      "learning_rate": 0.00016542315945345596,
      "loss": 3.1746,
      "step": 20550
    },
    {
      "epoch": 0.8844796419041061,
      "eval_bleu": 25.97341677641837,
      "eval_gen_len": 27.321,
      "eval_loss": 2.808820962905884,
      "eval_runtime": 57.6479,
      "eval_samples_per_second": 17.347,
      "eval_steps_per_second": 1.093,
      "step": 20550
    },
    {
      "epoch": 0.8849100456227942,
      "grad_norm": 0.9983134865760803,
      "learning_rate": 0.00016538801012715357,
      "loss": 3.0489,
      "step": 20560
    },
    {
      "epoch": 0.8853404493414823,
      "grad_norm": 0.9388550519943237,
      "learning_rate": 0.0001653528466827598,
      "loss": 3.122,
      "step": 20570
    },
    {
      "epoch": 0.8857708530601704,
      "grad_norm": 0.9322118759155273,
      "learning_rate": 0.00016531766912786697,
      "loss": 3.1965,
      "step": 20580
    },
    {
      "epoch": 0.8862012567788585,
      "grad_norm": 0.8800962567329407,
      "learning_rate": 0.00016528247747007034,
      "loss": 3.148,
      "step": 20590
    },
    {
      "epoch": 0.8866316604975467,
      "grad_norm": 0.8807560801506042,
      "learning_rate": 0.0001652472717169682,
      "loss": 2.9964,
      "step": 20600
    },
    {
      "epoch": 0.8866316604975467,
      "eval_bleu": 26.328219032097298,
      "eval_gen_len": 27.357,
      "eval_loss": 2.802755117416382,
      "eval_runtime": 57.5792,
      "eval_samples_per_second": 17.367,
      "eval_steps_per_second": 1.094,
      "step": 20600
    },
    {
      "epoch": 0.8870620642162348,
      "grad_norm": 0.8828364610671997,
      "learning_rate": 0.00016521205187616187,
      "loss": 3.106,
      "step": 20610
    },
    {
      "epoch": 0.887492467934923,
      "grad_norm": 0.8640177845954895,
      "learning_rate": 0.00016517681795525583,
      "loss": 3.1146,
      "step": 20620
    },
    {
      "epoch": 0.8879228716536111,
      "grad_norm": 0.8316651582717896,
      "learning_rate": 0.00016514156996185752,
      "loss": 3.0154,
      "step": 20630
    },
    {
      "epoch": 0.8883532753722992,
      "grad_norm": 0.9457326531410217,
      "learning_rate": 0.0001651063079035774,
      "loss": 3.1879,
      "step": 20640
    },
    {
      "epoch": 0.8887836790909873,
      "grad_norm": 0.9543862342834473,
      "learning_rate": 0.00016507103178802897,
      "loss": 3.0238,
      "step": 20650
    },
    {
      "epoch": 0.8887836790909873,
      "eval_bleu": 26.514286006623557,
      "eval_gen_len": 27.411,
      "eval_loss": 2.80767822265625,
      "eval_runtime": 57.8606,
      "eval_samples_per_second": 17.283,
      "eval_steps_per_second": 1.089,
      "step": 20650
    },
    {
      "epoch": 0.8892140828096755,
      "grad_norm": 0.84368896484375,
      "learning_rate": 0.00016503574162282883,
      "loss": 3.0593,
      "step": 20660
    },
    {
      "epoch": 0.8896444865283636,
      "grad_norm": 1.02164888381958,
      "learning_rate": 0.00016500043741559658,
      "loss": 3.2202,
      "step": 20670
    },
    {
      "epoch": 0.8900748902470518,
      "grad_norm": 0.975661039352417,
      "learning_rate": 0.0001649651191739548,
      "loss": 3.0952,
      "step": 20680
    },
    {
      "epoch": 0.8905052939657399,
      "grad_norm": 0.9017836451530457,
      "learning_rate": 0.00016492978690552912,
      "loss": 3.1053,
      "step": 20690
    },
    {
      "epoch": 0.890935697684428,
      "grad_norm": 0.9087052345275879,
      "learning_rate": 0.00016489444061794828,
      "loss": 3.0583,
      "step": 20700
    },
    {
      "epoch": 0.890935697684428,
      "eval_bleu": 26.192233261013453,
      "eval_gen_len": 27.293,
      "eval_loss": 2.8071744441986084,
      "eval_runtime": 58.0743,
      "eval_samples_per_second": 17.219,
      "eval_steps_per_second": 1.085,
      "step": 20700
    },
    {
      "epoch": 0.8913661014031161,
      "grad_norm": 0.9417381882667542,
      "learning_rate": 0.00016485908031884394,
      "loss": 3.0844,
      "step": 20710
    },
    {
      "epoch": 0.8917965051218043,
      "grad_norm": 0.9026410579681396,
      "learning_rate": 0.00016482370601585088,
      "loss": 2.9796,
      "step": 20720
    },
    {
      "epoch": 0.8922269088404924,
      "grad_norm": 0.7870886921882629,
      "learning_rate": 0.0001647883177166068,
      "loss": 2.9819,
      "step": 20730
    },
    {
      "epoch": 0.8926573125591805,
      "grad_norm": 0.9486691951751709,
      "learning_rate": 0.00016475291542875252,
      "loss": 3.1131,
      "step": 20740
    },
    {
      "epoch": 0.8930877162778686,
      "grad_norm": 0.9536856412887573,
      "learning_rate": 0.0001647174991599318,
      "loss": 3.0078,
      "step": 20750
    },
    {
      "epoch": 0.8930877162778686,
      "eval_bleu": 25.98579099249489,
      "eval_gen_len": 27.366,
      "eval_loss": 2.811217784881592,
      "eval_runtime": 57.8041,
      "eval_samples_per_second": 17.3,
      "eval_steps_per_second": 1.09,
      "step": 20750
    },
    {
      "epoch": 0.8935181199965567,
      "grad_norm": 0.9351814389228821,
      "learning_rate": 0.0001646820689177915,
      "loss": 3.0532,
      "step": 20760
    },
    {
      "epoch": 0.8939485237152449,
      "grad_norm": 0.9833585023880005,
      "learning_rate": 0.00016464662470998143,
      "loss": 3.0677,
      "step": 20770
    },
    {
      "epoch": 0.894378927433933,
      "grad_norm": 0.9438548684120178,
      "learning_rate": 0.00016461116654415444,
      "loss": 3.1698,
      "step": 20780
    },
    {
      "epoch": 0.8948093311526212,
      "grad_norm": 0.9397281408309937,
      "learning_rate": 0.00016457569442796639,
      "loss": 3.0868,
      "step": 20790
    },
    {
      "epoch": 0.8952397348713093,
      "grad_norm": 0.9104891419410706,
      "learning_rate": 0.00016454020836907616,
      "loss": 3.0869,
      "step": 20800
    },
    {
      "epoch": 0.8952397348713093,
      "eval_bleu": 26.47424726448215,
      "eval_gen_len": 27.342,
      "eval_loss": 2.806117296218872,
      "eval_runtime": 58.3509,
      "eval_samples_per_second": 17.138,
      "eval_steps_per_second": 1.08,
      "step": 20800
    },
    {
      "epoch": 0.8956701385899974,
      "grad_norm": 0.8665309548377991,
      "learning_rate": 0.00016450470837514565,
      "loss": 3.0938,
      "step": 20810
    },
    {
      "epoch": 0.8961005423086855,
      "grad_norm": 0.8131983876228333,
      "learning_rate": 0.00016446919445383974,
      "loss": 3.1946,
      "step": 20820
    },
    {
      "epoch": 0.8965309460273737,
      "grad_norm": 0.8526939153671265,
      "learning_rate": 0.0001644336666128263,
      "loss": 3.114,
      "step": 20830
    },
    {
      "epoch": 0.8969613497460618,
      "grad_norm": 1.1429443359375,
      "learning_rate": 0.00016439812485977628,
      "loss": 3.1641,
      "step": 20840
    },
    {
      "epoch": 0.89739175346475,
      "grad_norm": 1.1065125465393066,
      "learning_rate": 0.00016436256920236356,
      "loss": 3.1454,
      "step": 20850
    },
    {
      "epoch": 0.89739175346475,
      "eval_bleu": 26.21206501345239,
      "eval_gen_len": 27.442,
      "eval_loss": 2.8094308376312256,
      "eval_runtime": 58.2634,
      "eval_samples_per_second": 17.163,
      "eval_steps_per_second": 1.081,
      "step": 20850
    },
    {
      "epoch": 0.897822157183438,
      "grad_norm": 0.8487751483917236,
      "learning_rate": 0.00016432699964826508,
      "loss": 3.1279,
      "step": 20860
    },
    {
      "epoch": 0.8982525609021262,
      "grad_norm": 0.8884120583534241,
      "learning_rate": 0.00016429141620516075,
      "loss": 3.0304,
      "step": 20870
    },
    {
      "epoch": 0.8986829646208143,
      "grad_norm": 1.0304694175720215,
      "learning_rate": 0.00016425581888073346,
      "loss": 3.1136,
      "step": 20880
    },
    {
      "epoch": 0.8991133683395025,
      "grad_norm": 0.8606708645820618,
      "learning_rate": 0.00016422020768266915,
      "loss": 3.0701,
      "step": 20890
    },
    {
      "epoch": 0.8995437720581906,
      "grad_norm": 0.9625104069709778,
      "learning_rate": 0.0001641845826186567,
      "loss": 3.1209,
      "step": 20900
    },
    {
      "epoch": 0.8995437720581906,
      "eval_bleu": 26.152082510627107,
      "eval_gen_len": 27.357,
      "eval_loss": 2.810345411300659,
      "eval_runtime": 57.9984,
      "eval_samples_per_second": 17.242,
      "eval_steps_per_second": 1.086,
      "step": 20900
    },
    {
      "epoch": 0.8999741757768787,
      "grad_norm": 1.0611861944198608,
      "learning_rate": 0.00016414894369638802,
      "loss": 3.0626,
      "step": 20910
    },
    {
      "epoch": 0.9004045794955668,
      "grad_norm": 0.9562587738037109,
      "learning_rate": 0.00016411329092355797,
      "loss": 3.1507,
      "step": 20920
    },
    {
      "epoch": 0.9008349832142549,
      "grad_norm": 0.9593023061752319,
      "learning_rate": 0.00016407762430786443,
      "loss": 3.0297,
      "step": 20930
    },
    {
      "epoch": 0.9012653869329431,
      "grad_norm": 0.968783974647522,
      "learning_rate": 0.00016404194385700836,
      "loss": 3.1471,
      "step": 20940
    },
    {
      "epoch": 0.9016957906516312,
      "grad_norm": 0.8486621975898743,
      "learning_rate": 0.0001640062495786935,
      "loss": 3.1151,
      "step": 20950
    },
    {
      "epoch": 0.9016957906516312,
      "eval_bleu": 26.30909972323194,
      "eval_gen_len": 27.328,
      "eval_loss": 2.809370994567871,
      "eval_runtime": 57.4902,
      "eval_samples_per_second": 17.394,
      "eval_steps_per_second": 1.096,
      "step": 20950
    },
    {
      "epoch": 0.9021261943703194,
      "grad_norm": 0.892896294593811,
      "learning_rate": 0.00016397054148062677,
      "loss": 3.0565,
      "step": 20960
    },
    {
      "epoch": 0.9025565980890075,
      "grad_norm": 0.922021746635437,
      "learning_rate": 0.00016393481957051794,
      "loss": 3.1007,
      "step": 20970
    },
    {
      "epoch": 0.9029870018076956,
      "grad_norm": 0.8362019658088684,
      "learning_rate": 0.00016389908385607986,
      "loss": 3.0482,
      "step": 20980
    },
    {
      "epoch": 0.9034174055263837,
      "grad_norm": 1.0922366380691528,
      "learning_rate": 0.0001638633343450283,
      "loss": 3.0439,
      "step": 20990
    },
    {
      "epoch": 0.9038478092450719,
      "grad_norm": 0.9588043093681335,
      "learning_rate": 0.00016382757104508206,
      "loss": 3.0717,
      "step": 21000
    },
    {
      "epoch": 0.9038478092450719,
      "eval_bleu": 26.673004346613276,
      "eval_gen_len": 27.377,
      "eval_loss": 2.8046164512634277,
      "eval_runtime": 57.7966,
      "eval_samples_per_second": 17.302,
      "eval_steps_per_second": 1.09,
      "step": 21000
    },
    {
      "epoch": 0.90427821296376,
      "grad_norm": 0.8224920630455017,
      "learning_rate": 0.00016379179396396284,
      "loss": 3.0719,
      "step": 21010
    },
    {
      "epoch": 0.9047086166824482,
      "grad_norm": 0.8849114775657654,
      "learning_rate": 0.00016375600310939537,
      "loss": 3.0812,
      "step": 21020
    },
    {
      "epoch": 0.9051390204011363,
      "grad_norm": 1.0284020900726318,
      "learning_rate": 0.00016372019848910738,
      "loss": 3.1036,
      "step": 21030
    },
    {
      "epoch": 0.9055694241198244,
      "grad_norm": 0.8801280856132507,
      "learning_rate": 0.00016368438011082952,
      "loss": 3.1165,
      "step": 21040
    },
    {
      "epoch": 0.9059998278385125,
      "grad_norm": 0.7999560832977295,
      "learning_rate": 0.00016364854798229538,
      "loss": 3.0559,
      "step": 21050
    },
    {
      "epoch": 0.9059998278385125,
      "eval_bleu": 26.575240023821948,
      "eval_gen_len": 27.446,
      "eval_loss": 2.8061330318450928,
      "eval_runtime": 58.1014,
      "eval_samples_per_second": 17.211,
      "eval_steps_per_second": 1.084,
      "step": 21050
    },
    {
      "epoch": 0.9064302315572007,
      "grad_norm": 1.0188268423080444,
      "learning_rate": 0.0001636127021112416,
      "loss": 3.0809,
      "step": 21060
    },
    {
      "epoch": 0.9068606352758888,
      "grad_norm": 0.8330427408218384,
      "learning_rate": 0.00016357684250540777,
      "loss": 3.0881,
      "step": 21070
    },
    {
      "epoch": 0.9072910389945769,
      "grad_norm": 0.9193918704986572,
      "learning_rate": 0.00016354096917253644,
      "loss": 3.0837,
      "step": 21080
    },
    {
      "epoch": 0.907721442713265,
      "grad_norm": 0.8189619779586792,
      "learning_rate": 0.00016350508212037304,
      "loss": 3.0145,
      "step": 21090
    },
    {
      "epoch": 0.9081518464319531,
      "grad_norm": 0.9598433375358582,
      "learning_rate": 0.00016346918135666608,
      "loss": 3.0824,
      "step": 21100
    },
    {
      "epoch": 0.9081518464319531,
      "eval_bleu": 26.3813307593322,
      "eval_gen_len": 27.279,
      "eval_loss": 2.80649471282959,
      "eval_runtime": 57.7641,
      "eval_samples_per_second": 17.312,
      "eval_steps_per_second": 1.091,
      "step": 21100
    },
    {
      "epoch": 0.9085822501506413,
      "grad_norm": 1.05544912815094,
      "learning_rate": 0.00016343326688916704,
      "loss": 3.1139,
      "step": 21110
    },
    {
      "epoch": 0.9090126538693294,
      "grad_norm": 0.9481346607208252,
      "learning_rate": 0.00016339733872563022,
      "loss": 2.97,
      "step": 21120
    },
    {
      "epoch": 0.9094430575880176,
      "grad_norm": 0.9032576084136963,
      "learning_rate": 0.00016336139687381297,
      "loss": 3.0486,
      "step": 21130
    },
    {
      "epoch": 0.9098734613067057,
      "grad_norm": 0.8785426616668701,
      "learning_rate": 0.00016332544134147563,
      "loss": 3.0291,
      "step": 21140
    },
    {
      "epoch": 0.9103038650253938,
      "grad_norm": 0.9606419801712036,
      "learning_rate": 0.00016328947213638145,
      "loss": 3.147,
      "step": 21150
    },
    {
      "epoch": 0.9103038650253938,
      "eval_bleu": 26.090868222155404,
      "eval_gen_len": 27.305,
      "eval_loss": 2.810086727142334,
      "eval_runtime": 58.0573,
      "eval_samples_per_second": 17.224,
      "eval_steps_per_second": 1.085,
      "step": 21150
    },
    {
      "epoch": 0.9107342687440819,
      "grad_norm": 0.9222928285598755,
      "learning_rate": 0.00016325348926629656,
      "loss": 3.0757,
      "step": 21160
    },
    {
      "epoch": 0.9111646724627701,
      "grad_norm": 0.7627678513526917,
      "learning_rate": 0.0001632174927389902,
      "loss": 3.1103,
      "step": 21170
    },
    {
      "epoch": 0.9115950761814582,
      "grad_norm": 0.9881723523139954,
      "learning_rate": 0.00016318148256223443,
      "loss": 3.0922,
      "step": 21180
    },
    {
      "epoch": 0.9120254799001464,
      "grad_norm": 0.9781174659729004,
      "learning_rate": 0.0001631454587438043,
      "loss": 3.0886,
      "step": 21190
    },
    {
      "epoch": 0.9124558836188345,
      "grad_norm": 0.8948253393173218,
      "learning_rate": 0.0001631094212914778,
      "loss": 3.1883,
      "step": 21200
    },
    {
      "epoch": 0.9124558836188345,
      "eval_bleu": 26.23343526502492,
      "eval_gen_len": 27.202,
      "eval_loss": 2.80607008934021,
      "eval_runtime": 57.8607,
      "eval_samples_per_second": 17.283,
      "eval_steps_per_second": 1.089,
      "step": 21200
    },
    {
      "epoch": 0.9128862873375226,
      "grad_norm": 0.9353960752487183,
      "learning_rate": 0.00016307337021303586,
      "loss": 3.1343,
      "step": 21210
    },
    {
      "epoch": 0.9133166910562107,
      "grad_norm": 0.9845846891403198,
      "learning_rate": 0.0001630373055162624,
      "loss": 3.1518,
      "step": 21220
    },
    {
      "epoch": 0.9137470947748989,
      "grad_norm": 0.8070367574691772,
      "learning_rate": 0.00016300122720894423,
      "loss": 3.0859,
      "step": 21230
    },
    {
      "epoch": 0.914177498493587,
      "grad_norm": 0.9014627933502197,
      "learning_rate": 0.0001629651352988711,
      "loss": 3.101,
      "step": 21240
    },
    {
      "epoch": 0.9146079022122751,
      "grad_norm": 0.9361225962638855,
      "learning_rate": 0.00016292902979383564,
      "loss": 2.9748,
      "step": 21250
    },
    {
      "epoch": 0.9146079022122751,
      "eval_bleu": 26.373491807251998,
      "eval_gen_len": 27.251,
      "eval_loss": 2.806260824203491,
      "eval_runtime": 57.9993,
      "eval_samples_per_second": 17.242,
      "eval_steps_per_second": 1.086,
      "step": 21250
    },
    {
      "epoch": 0.9150383059309632,
      "grad_norm": 0.7605023384094238,
      "learning_rate": 0.00016289291070163358,
      "loss": 3.0792,
      "step": 21260
    },
    {
      "epoch": 0.9154687096496513,
      "grad_norm": 0.9861080050468445,
      "learning_rate": 0.00016285677803006346,
      "loss": 3.1467,
      "step": 21270
    },
    {
      "epoch": 0.9158991133683395,
      "grad_norm": 0.9810206890106201,
      "learning_rate": 0.00016282063178692675,
      "loss": 3.0141,
      "step": 21280
    },
    {
      "epoch": 0.9163295170870276,
      "grad_norm": 0.8724931478500366,
      "learning_rate": 0.0001627844719800279,
      "loss": 3.0629,
      "step": 21290
    },
    {
      "epoch": 0.9167599208057158,
      "grad_norm": 0.8362638354301453,
      "learning_rate": 0.00016274829861717422,
      "loss": 3.0624,
      "step": 21300
    },
    {
      "epoch": 0.9167599208057158,
      "eval_bleu": 26.531313895009283,
      "eval_gen_len": 27.346,
      "eval_loss": 2.8051533699035645,
      "eval_runtime": 58.0923,
      "eval_samples_per_second": 17.214,
      "eval_steps_per_second": 1.084,
      "step": 21300
    },
    {
      "epoch": 0.9171903245244039,
      "grad_norm": 0.8791851997375488,
      "learning_rate": 0.00016271211170617607,
      "loss": 3.008,
      "step": 21310
    },
    {
      "epoch": 0.917620728243092,
      "grad_norm": 0.9847776889801025,
      "learning_rate": 0.00016267591125484663,
      "loss": 3.0165,
      "step": 21320
    },
    {
      "epoch": 0.9180511319617801,
      "grad_norm": 1.1034572124481201,
      "learning_rate": 0.000162639697271002,
      "loss": 3.0397,
      "step": 21330
    },
    {
      "epoch": 0.9184815356804683,
      "grad_norm": 0.932536780834198,
      "learning_rate": 0.0001626034697624612,
      "loss": 2.997,
      "step": 21340
    },
    {
      "epoch": 0.9189119393991564,
      "grad_norm": 0.8293874859809875,
      "learning_rate": 0.00016256722873704633,
      "loss": 2.9511,
      "step": 21350
    },
    {
      "epoch": 0.9189119393991564,
      "eval_bleu": 26.130935147697926,
      "eval_gen_len": 27.408,
      "eval_loss": 2.8084499835968018,
      "eval_runtime": 58.2089,
      "eval_samples_per_second": 17.18,
      "eval_steps_per_second": 1.082,
      "step": 21350
    },
    {
      "epoch": 0.9193423431178446,
      "grad_norm": 0.8495360612869263,
      "learning_rate": 0.0001625309742025822,
      "loss": 3.0985,
      "step": 21360
    },
    {
      "epoch": 0.9197727468365327,
      "grad_norm": 0.9665018916130066,
      "learning_rate": 0.00016249470616689656,
      "loss": 3.0522,
      "step": 21370
    },
    {
      "epoch": 0.9202031505552208,
      "grad_norm": 0.9251036047935486,
      "learning_rate": 0.00016245842463782025,
      "loss": 3.1117,
      "step": 21380
    },
    {
      "epoch": 0.9206335542739089,
      "grad_norm": 0.9441245198249817,
      "learning_rate": 0.00016242212962318687,
      "loss": 3.1611,
      "step": 21390
    },
    {
      "epoch": 0.9210639579925971,
      "grad_norm": 0.9501627087593079,
      "learning_rate": 0.00016238582113083295,
      "loss": 3.1099,
      "step": 21400
    },
    {
      "epoch": 0.9210639579925971,
      "eval_bleu": 25.982207995806505,
      "eval_gen_len": 27.369,
      "eval_loss": 2.8064591884613037,
      "eval_runtime": 58.9085,
      "eval_samples_per_second": 16.975,
      "eval_steps_per_second": 1.069,
      "step": 21400
    },
    {
      "epoch": 0.9214943617112852,
      "grad_norm": 0.9012548923492432,
      "learning_rate": 0.00016234949916859792,
      "loss": 3.2205,
      "step": 21410
    },
    {
      "epoch": 0.9219247654299734,
      "grad_norm": 0.8818203210830688,
      "learning_rate": 0.00016231316374432423,
      "loss": 3.064,
      "step": 21420
    },
    {
      "epoch": 0.9223551691486614,
      "grad_norm": 0.9365659952163696,
      "learning_rate": 0.00016227681486585704,
      "loss": 3.0734,
      "step": 21430
    },
    {
      "epoch": 0.9227855728673495,
      "grad_norm": 0.976238489151001,
      "learning_rate": 0.00016224045254104464,
      "loss": 3.1044,
      "step": 21440
    },
    {
      "epoch": 0.9232159765860377,
      "grad_norm": 0.8702897429466248,
      "learning_rate": 0.00016220407677773805,
      "loss": 2.9659,
      "step": 21450
    },
    {
      "epoch": 0.9232159765860377,
      "eval_bleu": 26.433104942159897,
      "eval_gen_len": 27.312,
      "eval_loss": 2.8039259910583496,
      "eval_runtime": 58.1653,
      "eval_samples_per_second": 17.192,
      "eval_steps_per_second": 1.083,
      "step": 21450
    },
    {
      "epoch": 0.9236463803047258,
      "grad_norm": 0.8242309093475342,
      "learning_rate": 0.0001621676875837913,
      "loss": 3.0188,
      "step": 21460
    },
    {
      "epoch": 0.924076784023414,
      "grad_norm": 0.9536245465278625,
      "learning_rate": 0.0001621312849670612,
      "loss": 3.148,
      "step": 21470
    },
    {
      "epoch": 0.924507187742102,
      "grad_norm": 0.893742561340332,
      "learning_rate": 0.00016209486893540757,
      "loss": 3.0672,
      "step": 21480
    },
    {
      "epoch": 0.9249375914607902,
      "grad_norm": 0.9285909533500671,
      "learning_rate": 0.00016205843949669313,
      "loss": 3.0391,
      "step": 21490
    },
    {
      "epoch": 0.9253679951794783,
      "grad_norm": 0.9840859770774841,
      "learning_rate": 0.0001620219966587834,
      "loss": 3.0673,
      "step": 21500
    },
    {
      "epoch": 0.9253679951794783,
      "eval_bleu": 25.996601454149033,
      "eval_gen_len": 27.25,
      "eval_loss": 2.80635404586792,
      "eval_runtime": 57.4338,
      "eval_samples_per_second": 17.411,
      "eval_steps_per_second": 1.097,
      "step": 21500
    },
    {
      "epoch": 0.9257983988981665,
      "grad_norm": 0.9182040691375732,
      "learning_rate": 0.00016198554042954683,
      "loss": 3.1753,
      "step": 21510
    },
    {
      "epoch": 0.9262288026168546,
      "grad_norm": 0.8535206317901611,
      "learning_rate": 0.00016194907081685484,
      "loss": 2.9973,
      "step": 21520
    },
    {
      "epoch": 0.9266592063355428,
      "grad_norm": 0.9405617713928223,
      "learning_rate": 0.00016191258782858163,
      "loss": 3.1105,
      "step": 21530
    },
    {
      "epoch": 0.9270896100542309,
      "grad_norm": 0.944109320640564,
      "learning_rate": 0.00016187609147260435,
      "loss": 3.1505,
      "step": 21540
    },
    {
      "epoch": 0.927520013772919,
      "grad_norm": 1.0287266969680786,
      "learning_rate": 0.00016183958175680302,
      "loss": 3.0984,
      "step": 21550
    },
    {
      "epoch": 0.927520013772919,
      "eval_bleu": 26.58816442158764,
      "eval_gen_len": 27.363,
      "eval_loss": 2.803623676300049,
      "eval_runtime": 58.5352,
      "eval_samples_per_second": 17.084,
      "eval_steps_per_second": 1.076,
      "step": 21550
    },
    {
      "epoch": 0.9279504174916071,
      "grad_norm": 0.906807541847229,
      "learning_rate": 0.00016180305868906055,
      "loss": 3.0006,
      "step": 21560
    },
    {
      "epoch": 0.9283808212102953,
      "grad_norm": 0.8631189465522766,
      "learning_rate": 0.00016176652227726273,
      "loss": 3.0321,
      "step": 21570
    },
    {
      "epoch": 0.9288112249289834,
      "grad_norm": 0.9660593271255493,
      "learning_rate": 0.0001617299725292982,
      "loss": 3.0549,
      "step": 21580
    },
    {
      "epoch": 0.9292416286476716,
      "grad_norm": 1.0418070554733276,
      "learning_rate": 0.00016169340945305853,
      "loss": 3.0608,
      "step": 21590
    },
    {
      "epoch": 0.9296720323663596,
      "grad_norm": 0.8835307359695435,
      "learning_rate": 0.00016165683305643816,
      "loss": 3.036,
      "step": 21600
    },
    {
      "epoch": 0.9296720323663596,
      "eval_bleu": 26.646555679727747,
      "eval_gen_len": 27.49,
      "eval_loss": 2.8036930561065674,
      "eval_runtime": 58.4647,
      "eval_samples_per_second": 17.104,
      "eval_steps_per_second": 1.078,
      "step": 21600
    },
    {
      "epoch": 0.9301024360850477,
      "grad_norm": 0.9562724828720093,
      "learning_rate": 0.00016162024334733438,
      "loss": 3.1595,
      "step": 21610
    },
    {
      "epoch": 0.9305328398037359,
      "grad_norm": 0.9259724020957947,
      "learning_rate": 0.00016158364033364738,
      "loss": 3.0616,
      "step": 21620
    },
    {
      "epoch": 0.930963243522424,
      "grad_norm": 0.9652058482170105,
      "learning_rate": 0.0001615470240232802,
      "loss": 3.0519,
      "step": 21630
    },
    {
      "epoch": 0.9313936472411122,
      "grad_norm": 0.8678233027458191,
      "learning_rate": 0.00016151039442413874,
      "loss": 3.1818,
      "step": 21640
    },
    {
      "epoch": 0.9318240509598003,
      "grad_norm": 0.8784568905830383,
      "learning_rate": 0.0001614737515441318,
      "loss": 3.0476,
      "step": 21650
    },
    {
      "epoch": 0.9318240509598003,
      "eval_bleu": 26.07229254352523,
      "eval_gen_len": 27.403,
      "eval_loss": 2.811098337173462,
      "eval_runtime": 58.045,
      "eval_samples_per_second": 17.228,
      "eval_steps_per_second": 1.085,
      "step": 21650
    },
    {
      "epoch": 0.9322544546784884,
      "grad_norm": 0.990449070930481,
      "learning_rate": 0.00016143709539117104,
      "loss": 3.131,
      "step": 21660
    },
    {
      "epoch": 0.9326848583971765,
      "grad_norm": 0.8504739999771118,
      "learning_rate": 0.000161400425973171,
      "loss": 2.9925,
      "step": 21670
    },
    {
      "epoch": 0.9331152621158647,
      "grad_norm": 0.8631118535995483,
      "learning_rate": 0.00016136374329804907,
      "loss": 3.1652,
      "step": 21680
    },
    {
      "epoch": 0.9335456658345528,
      "grad_norm": 0.8152486681938171,
      "learning_rate": 0.00016132704737372548,
      "loss": 3.0366,
      "step": 21690
    },
    {
      "epoch": 0.933976069553241,
      "grad_norm": 0.8869628310203552,
      "learning_rate": 0.00016129033820812334,
      "loss": 3.0022,
      "step": 21700
    },
    {
      "epoch": 0.933976069553241,
      "eval_bleu": 25.57979962150256,
      "eval_gen_len": 27.362,
      "eval_loss": 2.812215805053711,
      "eval_runtime": 58.2644,
      "eval_samples_per_second": 17.163,
      "eval_steps_per_second": 1.081,
      "step": 21700
    },
    {
      "epoch": 0.934406473271929,
      "grad_norm": 0.9505263566970825,
      "learning_rate": 0.00016125361580916861,
      "loss": 3.0397,
      "step": 21710
    },
    {
      "epoch": 0.9348368769906172,
      "grad_norm": 0.9767853617668152,
      "learning_rate": 0.00016121688018479012,
      "loss": 3.193,
      "step": 21720
    },
    {
      "epoch": 0.9352672807093053,
      "grad_norm": 0.9513344168663025,
      "learning_rate": 0.00016118013134291964,
      "loss": 3.1147,
      "step": 21730
    },
    {
      "epoch": 0.9356976844279935,
      "grad_norm": 0.9258440136909485,
      "learning_rate": 0.00016114336929149155,
      "loss": 3.0108,
      "step": 21740
    },
    {
      "epoch": 0.9361280881466816,
      "grad_norm": 0.8663904070854187,
      "learning_rate": 0.00016110659403844333,
      "loss": 3.0659,
      "step": 21750
    },
    {
      "epoch": 0.9361280881466816,
      "eval_bleu": 25.66362833696157,
      "eval_gen_len": 27.351,
      "eval_loss": 2.81070876121521,
      "eval_runtime": 58.2629,
      "eval_samples_per_second": 17.164,
      "eval_steps_per_second": 1.081,
      "step": 21750
    },
    {
      "epoch": 0.9365584918653698,
      "grad_norm": 0.9078238010406494,
      "learning_rate": 0.0001610698055917152,
      "loss": 3.1045,
      "step": 21760
    },
    {
      "epoch": 0.9369888955840578,
      "grad_norm": 0.9589694142341614,
      "learning_rate": 0.0001610330039592503,
      "loss": 3.0531,
      "step": 21770
    },
    {
      "epoch": 0.9374192993027459,
      "grad_norm": 1.0344817638397217,
      "learning_rate": 0.00016099618914899446,
      "loss": 3.0378,
      "step": 21780
    },
    {
      "epoch": 0.9378497030214341,
      "grad_norm": 0.8755537271499634,
      "learning_rate": 0.0001609593611688965,
      "loss": 3.0375,
      "step": 21790
    },
    {
      "epoch": 0.9382801067401222,
      "grad_norm": 0.9701433181762695,
      "learning_rate": 0.00016092252002690812,
      "loss": 3.0,
      "step": 21800
    },
    {
      "epoch": 0.9382801067401222,
      "eval_bleu": 26.261050784662103,
      "eval_gen_len": 27.306,
      "eval_loss": 2.80415678024292,
      "eval_runtime": 58.3787,
      "eval_samples_per_second": 17.13,
      "eval_steps_per_second": 1.079,
      "step": 21800
    },
    {
      "epoch": 0.9387105104588104,
      "grad_norm": 0.9640540480613708,
      "learning_rate": 0.0001608856657309837,
      "loss": 3.1379,
      "step": 21810
    },
    {
      "epoch": 0.9391409141774985,
      "grad_norm": 0.8411017060279846,
      "learning_rate": 0.00016084879828908054,
      "loss": 2.999,
      "step": 21820
    },
    {
      "epoch": 0.9395713178961866,
      "grad_norm": 0.9362074136734009,
      "learning_rate": 0.00016081191770915884,
      "loss": 3.0756,
      "step": 21830
    },
    {
      "epoch": 0.9400017216148747,
      "grad_norm": 0.9397209882736206,
      "learning_rate": 0.0001607750239991815,
      "loss": 3.0915,
      "step": 21840
    },
    {
      "epoch": 0.9404321253335629,
      "grad_norm": 1.0441951751708984,
      "learning_rate": 0.00016073811716711448,
      "loss": 3.0881,
      "step": 21850
    },
    {
      "epoch": 0.9404321253335629,
      "eval_bleu": 26.650963883314684,
      "eval_gen_len": 27.45,
      "eval_loss": 2.803173780441284,
      "eval_runtime": 58.8885,
      "eval_samples_per_second": 16.981,
      "eval_steps_per_second": 1.07,
      "step": 21850
    },
    {
      "epoch": 0.940862529052251,
      "grad_norm": 0.9496792554855347,
      "learning_rate": 0.00016070119722092624,
      "loss": 3.0714,
      "step": 21860
    },
    {
      "epoch": 0.9412929327709392,
      "grad_norm": 0.9570040106773376,
      "learning_rate": 0.0001606642641685884,
      "loss": 3.0664,
      "step": 21870
    },
    {
      "epoch": 0.9417233364896272,
      "grad_norm": 0.9363078474998474,
      "learning_rate": 0.0001606273180180752,
      "loss": 3.0637,
      "step": 21880
    },
    {
      "epoch": 0.9421537402083154,
      "grad_norm": 0.9556175470352173,
      "learning_rate": 0.00016059035877736378,
      "loss": 3.1433,
      "step": 21890
    },
    {
      "epoch": 0.9425841439270035,
      "grad_norm": 0.8103839159011841,
      "learning_rate": 0.00016055338645443415,
      "loss": 3.1307,
      "step": 21900
    },
    {
      "epoch": 0.9425841439270035,
      "eval_bleu": 26.288241212833295,
      "eval_gen_len": 27.36,
      "eval_loss": 2.805246591567993,
      "eval_runtime": 58.2538,
      "eval_samples_per_second": 17.166,
      "eval_steps_per_second": 1.081,
      "step": 21900
    },
    {
      "epoch": 0.9430145476456917,
      "grad_norm": 0.7779670357704163,
      "learning_rate": 0.00016051640105726905,
      "loss": 2.9735,
      "step": 21910
    },
    {
      "epoch": 0.9434449513643798,
      "grad_norm": 0.86432284116745,
      "learning_rate": 0.00016047940259385413,
      "loss": 3.1725,
      "step": 21920
    },
    {
      "epoch": 0.943875355083068,
      "grad_norm": 0.9315436482429504,
      "learning_rate": 0.00016044239107217777,
      "loss": 3.0813,
      "step": 21930
    },
    {
      "epoch": 0.944305758801756,
      "grad_norm": 0.9377707242965698,
      "learning_rate": 0.00016040536650023128,
      "loss": 3.0614,
      "step": 21940
    },
    {
      "epoch": 0.9447361625204441,
      "grad_norm": 0.8971773386001587,
      "learning_rate": 0.00016036832888600868,
      "loss": 3.124,
      "step": 21950
    },
    {
      "epoch": 0.9447361625204441,
      "eval_bleu": 26.608498649935356,
      "eval_gen_len": 27.482,
      "eval_loss": 2.802671432495117,
      "eval_runtime": 58.7258,
      "eval_samples_per_second": 17.028,
      "eval_steps_per_second": 1.073,
      "step": 21950
    },
    {
      "epoch": 0.9451665662391323,
      "grad_norm": 0.9005202054977417,
      "learning_rate": 0.00016033127823750692,
      "loss": 3.1,
      "step": 21960
    },
    {
      "epoch": 0.9455969699578204,
      "grad_norm": 0.9831898808479309,
      "learning_rate": 0.0001602942145627256,
      "loss": 3.0567,
      "step": 21970
    },
    {
      "epoch": 0.9460273736765086,
      "grad_norm": 0.9407119750976562,
      "learning_rate": 0.00016025713786966734,
      "loss": 3.1601,
      "step": 21980
    },
    {
      "epoch": 0.9464577773951967,
      "grad_norm": 0.8605350852012634,
      "learning_rate": 0.0001602200481663374,
      "loss": 3.091,
      "step": 21990
    },
    {
      "epoch": 0.9468881811138848,
      "grad_norm": 0.9159192442893982,
      "learning_rate": 0.00016018294546074393,
      "loss": 3.1529,
      "step": 22000
    },
    {
      "epoch": 0.9468881811138848,
      "eval_bleu": 26.10032998336264,
      "eval_gen_len": 27.288,
      "eval_loss": 2.8092124462127686,
      "eval_runtime": 57.761,
      "eval_samples_per_second": 17.313,
      "eval_steps_per_second": 1.091,
      "step": 22000
    },
    {
      "epoch": 0.9473185848325729,
      "grad_norm": 0.9264890551567078,
      "learning_rate": 0.00016014582976089784,
      "loss": 3.1518,
      "step": 22010
    },
    {
      "epoch": 0.9477489885512611,
      "grad_norm": 0.932494044303894,
      "learning_rate": 0.00016010870107481293,
      "loss": 3.1403,
      "step": 22020
    },
    {
      "epoch": 0.9481793922699492,
      "grad_norm": 0.9321013689041138,
      "learning_rate": 0.00016007155941050568,
      "loss": 3.0238,
      "step": 22030
    },
    {
      "epoch": 0.9486097959886374,
      "grad_norm": 0.9118994474411011,
      "learning_rate": 0.0001600344047759955,
      "loss": 3.0451,
      "step": 22040
    },
    {
      "epoch": 0.9490401997073254,
      "grad_norm": 0.9113146066665649,
      "learning_rate": 0.00015999723717930454,
      "loss": 3.1282,
      "step": 22050
    },
    {
      "epoch": 0.9490401997073254,
      "eval_bleu": 26.44590078590195,
      "eval_gen_len": 27.352,
      "eval_loss": 2.8085834980010986,
      "eval_runtime": 58.1109,
      "eval_samples_per_second": 17.208,
      "eval_steps_per_second": 1.084,
      "step": 22050
    },
    {
      "epoch": 0.9494706034260136,
      "grad_norm": 1.0115405321121216,
      "learning_rate": 0.00015996005662845773,
      "loss": 3.0055,
      "step": 22060
    },
    {
      "epoch": 0.9499010071447017,
      "grad_norm": 0.8644253611564636,
      "learning_rate": 0.00015992286313148277,
      "loss": 3.0677,
      "step": 22070
    },
    {
      "epoch": 0.9503314108633899,
      "grad_norm": 0.9342380166053772,
      "learning_rate": 0.0001598856566964103,
      "loss": 3.0676,
      "step": 22080
    },
    {
      "epoch": 0.950761814582078,
      "grad_norm": 0.9529562592506409,
      "learning_rate": 0.0001598484373312736,
      "loss": 3.1512,
      "step": 22090
    },
    {
      "epoch": 0.9511922183007662,
      "grad_norm": 0.9416645765304565,
      "learning_rate": 0.00015981120504410877,
      "loss": 3.1035,
      "step": 22100
    },
    {
      "epoch": 0.9511922183007662,
      "eval_bleu": 26.084121152111308,
      "eval_gen_len": 27.326,
      "eval_loss": 2.8095552921295166,
      "eval_runtime": 58.3259,
      "eval_samples_per_second": 17.145,
      "eval_steps_per_second": 1.08,
      "step": 22100
    },
    {
      "epoch": 0.9516226220194542,
      "grad_norm": 0.9307861328125,
      "learning_rate": 0.0001597739598429548,
      "loss": 3.0767,
      "step": 22110
    },
    {
      "epoch": 0.9520530257381423,
      "grad_norm": 0.8785627484321594,
      "learning_rate": 0.00015973670173585332,
      "loss": 3.0668,
      "step": 22120
    },
    {
      "epoch": 0.9524834294568305,
      "grad_norm": 0.8105840682983398,
      "learning_rate": 0.0001596994307308489,
      "loss": 3.0428,
      "step": 22130
    },
    {
      "epoch": 0.9529138331755186,
      "grad_norm": 0.8843272924423218,
      "learning_rate": 0.00015966214683598874,
      "loss": 3.1666,
      "step": 22140
    },
    {
      "epoch": 0.9533442368942068,
      "grad_norm": 0.9145228266716003,
      "learning_rate": 0.00015962485005932298,
      "loss": 2.9831,
      "step": 22150
    },
    {
      "epoch": 0.9533442368942068,
      "eval_bleu": 26.2779626013254,
      "eval_gen_len": 27.348,
      "eval_loss": 2.8065052032470703,
      "eval_runtime": 57.9462,
      "eval_samples_per_second": 17.257,
      "eval_steps_per_second": 1.087,
      "step": 22150
    },
    {
      "epoch": 0.9537746406128949,
      "grad_norm": 1.0002397298812866,
      "learning_rate": 0.00015958754040890438,
      "loss": 3.1657,
      "step": 22160
    },
    {
      "epoch": 0.954205044331583,
      "grad_norm": 0.9505955576896667,
      "learning_rate": 0.00015955021789278864,
      "loss": 3.0643,
      "step": 22170
    },
    {
      "epoch": 0.9546354480502711,
      "grad_norm": 0.8921598792076111,
      "learning_rate": 0.0001595128825190341,
      "loss": 3.0797,
      "step": 22180
    },
    {
      "epoch": 0.9550658517689593,
      "grad_norm": 0.9800552725791931,
      "learning_rate": 0.00015947553429570193,
      "loss": 3.0645,
      "step": 22190
    },
    {
      "epoch": 0.9554962554876474,
      "grad_norm": 0.8613110780715942,
      "learning_rate": 0.00015943817323085612,
      "loss": 3.0346,
      "step": 22200
    },
    {
      "epoch": 0.9554962554876474,
      "eval_bleu": 26.095414236860307,
      "eval_gen_len": 27.322,
      "eval_loss": 2.80607533454895,
      "eval_runtime": 58.4341,
      "eval_samples_per_second": 17.113,
      "eval_steps_per_second": 1.078,
      "step": 22200
    },
    {
      "epoch": 0.9559266592063356,
      "grad_norm": 0.8563313484191895,
      "learning_rate": 0.00015940079933256344,
      "loss": 3.1578,
      "step": 22210
    },
    {
      "epoch": 0.9563570629250236,
      "grad_norm": 0.8267583250999451,
      "learning_rate": 0.00015936341260889324,
      "loss": 3.0017,
      "step": 22220
    },
    {
      "epoch": 0.9567874666437118,
      "grad_norm": 0.8880476951599121,
      "learning_rate": 0.0001593260130679179,
      "loss": 3.1101,
      "step": 22230
    },
    {
      "epoch": 0.9572178703623999,
      "grad_norm": 0.8898981213569641,
      "learning_rate": 0.0001592886007177124,
      "loss": 3.1614,
      "step": 22240
    },
    {
      "epoch": 0.9576482740810881,
      "grad_norm": 0.9834921956062317,
      "learning_rate": 0.00015925117556635457,
      "loss": 3.1301,
      "step": 22250
    },
    {
      "epoch": 0.9576482740810881,
      "eval_bleu": 26.41483634200331,
      "eval_gen_len": 27.4,
      "eval_loss": 2.804641008377075,
      "eval_runtime": 58.7528,
      "eval_samples_per_second": 17.02,
      "eval_steps_per_second": 1.072,
      "step": 22250
    },
    {
      "epoch": 0.9580786777997762,
      "grad_norm": 0.8956394791603088,
      "learning_rate": 0.00015921373762192492,
      "loss": 3.1095,
      "step": 22260
    },
    {
      "epoch": 0.9585090815184644,
      "grad_norm": 0.8350057005882263,
      "learning_rate": 0.00015917628689250682,
      "loss": 3.1656,
      "step": 22270
    },
    {
      "epoch": 0.9589394852371524,
      "grad_norm": 0.8691501617431641,
      "learning_rate": 0.00015913882338618632,
      "loss": 3.1002,
      "step": 22280
    },
    {
      "epoch": 0.9593698889558406,
      "grad_norm": 0.860974907875061,
      "learning_rate": 0.00015910134711105228,
      "loss": 3.075,
      "step": 22290
    },
    {
      "epoch": 0.9598002926745287,
      "grad_norm": 0.8567731976509094,
      "learning_rate": 0.0001590638580751963,
      "loss": 3.0375,
      "step": 22300
    },
    {
      "epoch": 0.9598002926745287,
      "eval_bleu": 26.747584712708957,
      "eval_gen_len": 27.469,
      "eval_loss": 2.8029911518096924,
      "eval_runtime": 58.0619,
      "eval_samples_per_second": 17.223,
      "eval_steps_per_second": 1.085,
      "step": 22300
    },
    {
      "epoch": 0.9602306963932168,
      "grad_norm": 0.9281300902366638,
      "learning_rate": 0.00015902635628671272,
      "loss": 3.08,
      "step": 22310
    },
    {
      "epoch": 0.960661100111905,
      "grad_norm": 0.9093451499938965,
      "learning_rate": 0.00015898884175369863,
      "loss": 3.0675,
      "step": 22320
    },
    {
      "epoch": 0.961091503830593,
      "grad_norm": 0.9276674389839172,
      "learning_rate": 0.00015895131448425394,
      "loss": 2.9834,
      "step": 22330
    },
    {
      "epoch": 0.9615219075492812,
      "grad_norm": 0.9730120897293091,
      "learning_rate": 0.00015891377448648122,
      "loss": 3.1232,
      "step": 22340
    },
    {
      "epoch": 0.9619523112679693,
      "grad_norm": 0.8863537311553955,
      "learning_rate": 0.00015887622176848583,
      "loss": 3.1521,
      "step": 22350
    },
    {
      "epoch": 0.9619523112679693,
      "eval_bleu": 26.82809209728887,
      "eval_gen_len": 27.413,
      "eval_loss": 2.8016979694366455,
      "eval_runtime": 58.4177,
      "eval_samples_per_second": 17.118,
      "eval_steps_per_second": 1.078,
      "step": 22350
    },
    {
      "epoch": 0.9623827149866575,
      "grad_norm": 0.79799485206604,
      "learning_rate": 0.00015883865633837586,
      "loss": 3.2392,
      "step": 22360
    },
    {
      "epoch": 0.9628131187053456,
      "grad_norm": 0.9700968265533447,
      "learning_rate": 0.00015880107820426216,
      "loss": 3.0927,
      "step": 22370
    },
    {
      "epoch": 0.9632435224240338,
      "grad_norm": 0.9430755972862244,
      "learning_rate": 0.00015876348737425838,
      "loss": 3.0806,
      "step": 22380
    },
    {
      "epoch": 0.9636739261427218,
      "grad_norm": 1.0417228937149048,
      "learning_rate": 0.00015872588385648078,
      "loss": 3.093,
      "step": 22390
    },
    {
      "epoch": 0.96410432986141,
      "grad_norm": 0.8660354018211365,
      "learning_rate": 0.00015868826765904842,
      "loss": 3.091,
      "step": 22400
    },
    {
      "epoch": 0.96410432986141,
      "eval_bleu": 26.73147150753481,
      "eval_gen_len": 27.447,
      "eval_loss": 2.804356098175049,
      "eval_runtime": 58.4831,
      "eval_samples_per_second": 17.099,
      "eval_steps_per_second": 1.077,
      "step": 22400
    },
    {
      "epoch": 0.9645347335800981,
      "grad_norm": 0.9104781746864319,
      "learning_rate": 0.0001586506387900832,
      "loss": 2.989,
      "step": 22410
    },
    {
      "epoch": 0.9649651372987863,
      "grad_norm": 1.060535192489624,
      "learning_rate": 0.0001586129972577096,
      "loss": 3.0147,
      "step": 22420
    },
    {
      "epoch": 0.9653955410174744,
      "grad_norm": 0.9139978289604187,
      "learning_rate": 0.00015857534307005491,
      "loss": 3.1898,
      "step": 22430
    },
    {
      "epoch": 0.9658259447361626,
      "grad_norm": 0.9589056372642517,
      "learning_rate": 0.0001585376762352491,
      "loss": 3.1102,
      "step": 22440
    },
    {
      "epoch": 0.9662563484548506,
      "grad_norm": 0.9063710570335388,
      "learning_rate": 0.000158499996761425,
      "loss": 3.1113,
      "step": 22450
    },
    {
      "epoch": 0.9662563484548506,
      "eval_bleu": 27.070845548562048,
      "eval_gen_len": 27.432,
      "eval_loss": 2.8047983646392822,
      "eval_runtime": 58.3622,
      "eval_samples_per_second": 17.134,
      "eval_steps_per_second": 1.079,
      "step": 22450
    },
    {
      "epoch": 0.9666867521735388,
      "grad_norm": 0.9826892614364624,
      "learning_rate": 0.000158462304656718,
      "loss": 3.0709,
      "step": 22460
    },
    {
      "epoch": 0.9671171558922269,
      "grad_norm": 1.02883780002594,
      "learning_rate": 0.00015842459992926634,
      "loss": 3.1518,
      "step": 22470
    },
    {
      "epoch": 0.967547559610915,
      "grad_norm": 1.0901957750320435,
      "learning_rate": 0.00015838688258721091,
      "loss": 3.1867,
      "step": 22480
    },
    {
      "epoch": 0.9679779633296032,
      "grad_norm": 0.8800325393676758,
      "learning_rate": 0.0001583491526386954,
      "loss": 3.0544,
      "step": 22490
    },
    {
      "epoch": 0.9684083670482913,
      "grad_norm": 0.8792123198509216,
      "learning_rate": 0.00015831141009186618,
      "loss": 3.1141,
      "step": 22500
    },
    {
      "epoch": 0.9684083670482913,
      "eval_bleu": 26.39986176996839,
      "eval_gen_len": 27.485,
      "eval_loss": 2.804924488067627,
      "eval_runtime": 58.9447,
      "eval_samples_per_second": 16.965,
      "eval_steps_per_second": 1.069,
      "step": 22500
    },
    {
      "epoch": 0.9688387707669794,
      "grad_norm": 0.8658339977264404,
      "learning_rate": 0.00015827365495487233,
      "loss": 3.0629,
      "step": 22510
    },
    {
      "epoch": 0.9692691744856675,
      "grad_norm": 0.8895694017410278,
      "learning_rate": 0.0001582358872358656,
      "loss": 3.1464,
      "step": 22520
    },
    {
      "epoch": 0.9696995782043557,
      "grad_norm": 0.8781157732009888,
      "learning_rate": 0.00015819810694300056,
      "loss": 3.1279,
      "step": 22530
    },
    {
      "epoch": 0.9701299819230438,
      "grad_norm": 0.9633194804191589,
      "learning_rate": 0.0001581603140844345,
      "loss": 3.3073,
      "step": 22540
    },
    {
      "epoch": 0.970560385641732,
      "grad_norm": 0.8747073411941528,
      "learning_rate": 0.00015812250866832728,
      "loss": 3.0672,
      "step": 22550
    },
    {
      "epoch": 0.970560385641732,
      "eval_bleu": 26.496333001676778,
      "eval_gen_len": 27.405,
      "eval_loss": 2.8071508407592773,
      "eval_runtime": 58.3421,
      "eval_samples_per_second": 17.14,
      "eval_steps_per_second": 1.08,
      "step": 22550
    },
    {
      "epoch": 0.97099078936042,
      "grad_norm": 0.8373820781707764,
      "learning_rate": 0.00015808469070284161,
      "loss": 3.0772,
      "step": 22560
    },
    {
      "epoch": 0.9714211930791082,
      "grad_norm": 0.8972393274307251,
      "learning_rate": 0.00015804686019614284,
      "loss": 3.0542,
      "step": 22570
    },
    {
      "epoch": 0.9718515967977963,
      "grad_norm": 1.0141912698745728,
      "learning_rate": 0.00015800901715639913,
      "loss": 3.2011,
      "step": 22580
    },
    {
      "epoch": 0.9722820005164845,
      "grad_norm": 0.9440823793411255,
      "learning_rate": 0.00015797116159178116,
      "loss": 3.1052,
      "step": 22590
    },
    {
      "epoch": 0.9727124042351726,
      "grad_norm": 0.8893561363220215,
      "learning_rate": 0.00015793329351046246,
      "loss": 3.0949,
      "step": 22600
    },
    {
      "epoch": 0.9727124042351726,
      "eval_bleu": 27.071554409461196,
      "eval_gen_len": 27.406,
      "eval_loss": 2.8013672828674316,
      "eval_runtime": 58.7635,
      "eval_samples_per_second": 17.017,
      "eval_steps_per_second": 1.072,
      "step": 22600
    },
    {
      "epoch": 0.9731428079538608,
      "grad_norm": 0.9812151789665222,
      "learning_rate": 0.00015789541292061924,
      "loss": 3.0151,
      "step": 22610
    },
    {
      "epoch": 0.9735732116725488,
      "grad_norm": 0.9208599328994751,
      "learning_rate": 0.0001578575198304304,
      "loss": 3.0953,
      "step": 22620
    },
    {
      "epoch": 0.974003615391237,
      "grad_norm": 0.857749342918396,
      "learning_rate": 0.0001578196142480775,
      "loss": 3.176,
      "step": 22630
    },
    {
      "epoch": 0.9744340191099251,
      "grad_norm": 0.9489359259605408,
      "learning_rate": 0.0001577816961817449,
      "loss": 3.0784,
      "step": 22640
    },
    {
      "epoch": 0.9748644228286132,
      "grad_norm": 0.8311068415641785,
      "learning_rate": 0.00015774376563961945,
      "loss": 3.0422,
      "step": 22650
    },
    {
      "epoch": 0.9748644228286132,
      "eval_bleu": 26.87017937874058,
      "eval_gen_len": 27.346,
      "eval_loss": 2.803466796875,
      "eval_runtime": 58.5234,
      "eval_samples_per_second": 17.087,
      "eval_steps_per_second": 1.076,
      "step": 22650
    },
    {
      "epoch": 0.9752948265473014,
      "grad_norm": 1.025463581085205,
      "learning_rate": 0.00015770582262989095,
      "loss": 3.0258,
      "step": 22660
    },
    {
      "epoch": 0.9757252302659895,
      "grad_norm": 1.0236347913742065,
      "learning_rate": 0.00015766786716075174,
      "loss": 3.2612,
      "step": 22670
    },
    {
      "epoch": 0.9761556339846776,
      "grad_norm": 0.9580194354057312,
      "learning_rate": 0.00015762989924039689,
      "loss": 3.2338,
      "step": 22680
    },
    {
      "epoch": 0.9765860377033657,
      "grad_norm": 0.8841593861579895,
      "learning_rate": 0.00015759191887702411,
      "loss": 3.1468,
      "step": 22690
    },
    {
      "epoch": 0.9770164414220539,
      "grad_norm": 1.043129801750183,
      "learning_rate": 0.0001575539260788339,
      "loss": 3.1323,
      "step": 22700
    },
    {
      "epoch": 0.9770164414220539,
      "eval_bleu": 26.394136388849,
      "eval_gen_len": 27.381,
      "eval_loss": 2.803792715072632,
      "eval_runtime": 58.2051,
      "eval_samples_per_second": 17.181,
      "eval_steps_per_second": 1.082,
      "step": 22700
    },
    {
      "epoch": 0.977446845140742,
      "grad_norm": 0.8962627053260803,
      "learning_rate": 0.0001575159208540293,
      "loss": 3.1009,
      "step": 22710
    },
    {
      "epoch": 0.9778772488594302,
      "grad_norm": 0.9499772191047668,
      "learning_rate": 0.0001574779032108162,
      "loss": 3.0977,
      "step": 22720
    },
    {
      "epoch": 0.9783076525781182,
      "grad_norm": 0.8630962371826172,
      "learning_rate": 0.00015743987315740304,
      "loss": 3.113,
      "step": 22730
    },
    {
      "epoch": 0.9787380562968064,
      "grad_norm": 0.8644706606864929,
      "learning_rate": 0.00015740183070200097,
      "loss": 3.087,
      "step": 22740
    },
    {
      "epoch": 0.9791684600154945,
      "grad_norm": 0.9210832715034485,
      "learning_rate": 0.00015736377585282387,
      "loss": 3.0821,
      "step": 22750
    },
    {
      "epoch": 0.9791684600154945,
      "eval_bleu": 26.69344101816402,
      "eval_gen_len": 27.401,
      "eval_loss": 2.8035714626312256,
      "eval_runtime": 58.4565,
      "eval_samples_per_second": 17.107,
      "eval_steps_per_second": 1.078,
      "step": 22750
    },
    {
      "epoch": 0.9795988637341827,
      "grad_norm": 0.8762169480323792,
      "learning_rate": 0.00015732570861808824,
      "loss": 3.2013,
      "step": 22760
    },
    {
      "epoch": 0.9800292674528708,
      "grad_norm": 0.948847770690918,
      "learning_rate": 0.00015728762900601328,
      "loss": 3.1485,
      "step": 22770
    },
    {
      "epoch": 0.980459671171559,
      "grad_norm": 0.9113715291023254,
      "learning_rate": 0.00015724953702482086,
      "loss": 3.0572,
      "step": 22780
    },
    {
      "epoch": 0.980890074890247,
      "grad_norm": 0.925506055355072,
      "learning_rate": 0.00015721143268273552,
      "loss": 3.1863,
      "step": 22790
    },
    {
      "epoch": 0.9813204786089352,
      "grad_norm": 0.905301570892334,
      "learning_rate": 0.0001571733159879844,
      "loss": 3.0693,
      "step": 22800
    },
    {
      "epoch": 0.9813204786089352,
      "eval_bleu": 26.804306216149246,
      "eval_gen_len": 27.394,
      "eval_loss": 2.805203437805176,
      "eval_runtime": 58.4984,
      "eval_samples_per_second": 17.094,
      "eval_steps_per_second": 1.077,
      "step": 22800
    },
    {
      "epoch": 0.9817508823276233,
      "grad_norm": 0.9636554718017578,
      "learning_rate": 0.00015713518694879746,
      "loss": 3.0525,
      "step": 22810
    },
    {
      "epoch": 0.9821812860463114,
      "grad_norm": 0.9110063314437866,
      "learning_rate": 0.00015709704557340722,
      "loss": 3.0557,
      "step": 22820
    },
    {
      "epoch": 0.9826116897649996,
      "grad_norm": 0.8919631838798523,
      "learning_rate": 0.00015705889187004886,
      "loss": 3.0896,
      "step": 22830
    },
    {
      "epoch": 0.9830420934836877,
      "grad_norm": 0.8623886108398438,
      "learning_rate": 0.00015702072584696027,
      "loss": 3.0799,
      "step": 22840
    },
    {
      "epoch": 0.9834724972023758,
      "grad_norm": 0.9292396903038025,
      "learning_rate": 0.00015698254751238188,
      "loss": 3.1326,
      "step": 22850
    },
    {
      "epoch": 0.9834724972023758,
      "eval_bleu": 26.599230836439087,
      "eval_gen_len": 27.38,
      "eval_loss": 2.8061776161193848,
      "eval_runtime": 58.2374,
      "eval_samples_per_second": 17.171,
      "eval_steps_per_second": 1.082,
      "step": 22850
    },
    {
      "epoch": 0.9839029009210639,
      "grad_norm": 0.8960265517234802,
      "learning_rate": 0.000156944356874557,
      "loss": 2.9902,
      "step": 22860
    },
    {
      "epoch": 0.9843333046397521,
      "grad_norm": 0.838252067565918,
      "learning_rate": 0.0001569061539417314,
      "loss": 3.1577,
      "step": 22870
    },
    {
      "epoch": 0.9847637083584402,
      "grad_norm": 0.8860718011856079,
      "learning_rate": 0.0001568679387221536,
      "loss": 3.1253,
      "step": 22880
    },
    {
      "epoch": 0.9851941120771284,
      "grad_norm": 0.9390687942504883,
      "learning_rate": 0.0001568297112240747,
      "loss": 2.9974,
      "step": 22890
    },
    {
      "epoch": 0.9856245157958164,
      "grad_norm": 0.8449162244796753,
      "learning_rate": 0.00015679147145574853,
      "loss": 3.111,
      "step": 22900
    },
    {
      "epoch": 0.9856245157958164,
      "eval_bleu": 26.701446470930566,
      "eval_gen_len": 27.471,
      "eval_loss": 2.802955150604248,
      "eval_runtime": 58.7458,
      "eval_samples_per_second": 17.022,
      "eval_steps_per_second": 1.072,
      "step": 22900
    },
    {
      "epoch": 0.9860549195145046,
      "grad_norm": 0.9022119641304016,
      "learning_rate": 0.00015675321942543153,
      "loss": 3.0607,
      "step": 22910
    },
    {
      "epoch": 0.9864853232331927,
      "grad_norm": 0.9720008969306946,
      "learning_rate": 0.0001567149551413828,
      "loss": 3.1196,
      "step": 22920
    },
    {
      "epoch": 0.9869157269518809,
      "grad_norm": 0.9125061631202698,
      "learning_rate": 0.0001566766786118641,
      "loss": 3.143,
      "step": 22930
    },
    {
      "epoch": 0.987346130670569,
      "grad_norm": 0.8445602059364319,
      "learning_rate": 0.00015663838984513974,
      "loss": 3.1,
      "step": 22940
    },
    {
      "epoch": 0.9877765343892572,
      "grad_norm": 0.9340270161628723,
      "learning_rate": 0.00015660008884947678,
      "loss": 3.1237,
      "step": 22950
    },
    {
      "epoch": 0.9877765343892572,
      "eval_bleu": 26.96233154952918,
      "eval_gen_len": 27.534,
      "eval_loss": 2.805856466293335,
      "eval_runtime": 58.6706,
      "eval_samples_per_second": 17.044,
      "eval_steps_per_second": 1.074,
      "step": 22950
    },
    {
      "epoch": 0.9882069381079452,
      "grad_norm": 0.9586655497550964,
      "learning_rate": 0.00015656177563314495,
      "loss": 3.0921,
      "step": 22960
    },
    {
      "epoch": 0.9886373418266334,
      "grad_norm": 0.9149983525276184,
      "learning_rate": 0.00015652345020441644,
      "loss": 3.1013,
      "step": 22970
    },
    {
      "epoch": 0.9890677455453215,
      "grad_norm": 0.9328097701072693,
      "learning_rate": 0.0001564851125715663,
      "loss": 3.055,
      "step": 22980
    },
    {
      "epoch": 0.9894981492640097,
      "grad_norm": 0.8781647682189941,
      "learning_rate": 0.000156446762742872,
      "loss": 3.0813,
      "step": 22990
    },
    {
      "epoch": 0.9899285529826978,
      "grad_norm": 1.0201131105422974,
      "learning_rate": 0.00015640840072661384,
      "loss": 3.1246,
      "step": 23000
    },
    {
      "epoch": 0.9899285529826978,
      "eval_bleu": 26.651823920122762,
      "eval_gen_len": 27.373,
      "eval_loss": 2.80649471282959,
      "eval_runtime": 58.5307,
      "eval_samples_per_second": 17.085,
      "eval_steps_per_second": 1.076,
      "step": 23000
    },
    {
      "epoch": 0.9903589567013859,
      "grad_norm": 0.9765799045562744,
      "learning_rate": 0.00015637002653107461,
      "loss": 3.0729,
      "step": 23010
    },
    {
      "epoch": 0.990789360420074,
      "grad_norm": 0.7929737567901611,
      "learning_rate": 0.00015633164016453982,
      "loss": 2.9773,
      "step": 23020
    },
    {
      "epoch": 0.9912197641387621,
      "grad_norm": 0.9650450944900513,
      "learning_rate": 0.00015629324163529752,
      "loss": 3.1507,
      "step": 23030
    },
    {
      "epoch": 0.9916501678574503,
      "grad_norm": 0.9200395345687866,
      "learning_rate": 0.00015625483095163846,
      "loss": 3.1136,
      "step": 23040
    },
    {
      "epoch": 0.9920805715761384,
      "grad_norm": 0.9663427472114563,
      "learning_rate": 0.00015621640812185595,
      "loss": 3.1076,
      "step": 23050
    },
    {
      "epoch": 0.9920805715761384,
      "eval_bleu": 26.80819586526929,
      "eval_gen_len": 27.528,
      "eval_loss": 2.807697296142578,
      "eval_runtime": 58.5155,
      "eval_samples_per_second": 17.089,
      "eval_steps_per_second": 1.077,
      "step": 23050
    },
    {
      "epoch": 0.9925109752948266,
      "grad_norm": 0.9168487787246704,
      "learning_rate": 0.00015617797315424606,
      "loss": 3.1206,
      "step": 23060
    },
    {
      "epoch": 0.9929413790135146,
      "grad_norm": 0.913203239440918,
      "learning_rate": 0.00015613952605710726,
      "loss": 3.204,
      "step": 23070
    },
    {
      "epoch": 0.9933717827322028,
      "grad_norm": 1.005238652229309,
      "learning_rate": 0.00015610106683874086,
      "loss": 3.0063,
      "step": 23080
    },
    {
      "epoch": 0.9938021864508909,
      "grad_norm": 0.8843246102333069,
      "learning_rate": 0.00015606259550745061,
      "loss": 3.1946,
      "step": 23090
    },
    {
      "epoch": 0.9942325901695791,
      "grad_norm": 0.9284904599189758,
      "learning_rate": 0.000156024112071543,
      "loss": 3.1376,
      "step": 23100
    },
    {
      "epoch": 0.9942325901695791,
      "eval_bleu": 26.72132497140051,
      "eval_gen_len": 27.41,
      "eval_loss": 2.806145668029785,
      "eval_runtime": 58.6477,
      "eval_samples_per_second": 17.051,
      "eval_steps_per_second": 1.074,
      "step": 23100
    },
    {
      "epoch": 0.9946629938882672,
      "grad_norm": 0.8415508270263672,
      "learning_rate": 0.00015598561653932708,
      "loss": 3.0855,
      "step": 23110
    },
    {
      "epoch": 0.9950933976069554,
      "grad_norm": 0.8290408253669739,
      "learning_rate": 0.0001559471089191145,
      "loss": 2.9862,
      "step": 23120
    },
    {
      "epoch": 0.9955238013256434,
      "grad_norm": 0.891453742980957,
      "learning_rate": 0.00015590858921921954,
      "loss": 3.1224,
      "step": 23130
    },
    {
      "epoch": 0.9959542050443316,
      "grad_norm": 0.8153274655342102,
      "learning_rate": 0.0001558700574479591,
      "loss": 3.175,
      "step": 23140
    },
    {
      "epoch": 0.9963846087630197,
      "grad_norm": 0.8887988924980164,
      "learning_rate": 0.00015583151361365269,
      "loss": 3.0822,
      "step": 23150
    },
    {
      "epoch": 0.9963846087630197,
      "eval_bleu": 26.99288926281777,
      "eval_gen_len": 27.379,
      "eval_loss": 2.806722640991211,
      "eval_runtime": 57.9586,
      "eval_samples_per_second": 17.254,
      "eval_steps_per_second": 1.087,
      "step": 23150
    },
    {
      "epoch": 0.9968150124817079,
      "grad_norm": 0.8534485697746277,
      "learning_rate": 0.0001557929577246224,
      "loss": 3.106,
      "step": 23160
    },
    {
      "epoch": 0.997245416200396,
      "grad_norm": 0.7730618119239807,
      "learning_rate": 0.00015575438978919287,
      "loss": 3.0564,
      "step": 23170
    },
    {
      "epoch": 0.997675819919084,
      "grad_norm": 0.8694674372673035,
      "learning_rate": 0.00015571580981569146,
      "loss": 2.973,
      "step": 23180
    },
    {
      "epoch": 0.9981062236377722,
      "grad_norm": 0.8871007561683655,
      "learning_rate": 0.00015567721781244807,
      "loss": 3.0778,
      "step": 23190
    },
    {
      "epoch": 0.9985366273564603,
      "grad_norm": 0.9269606471061707,
      "learning_rate": 0.00015563861378779516,
      "loss": 3.0825,
      "step": 23200
    },
    {
      "epoch": 0.9985366273564603,
      "eval_bleu": 26.473468121607834,
      "eval_gen_len": 27.423,
      "eval_loss": 2.807971715927124,
      "eval_runtime": 58.2807,
      "eval_samples_per_second": 17.158,
      "eval_steps_per_second": 1.081,
      "step": 23200
    },
    {
      "epoch": 0.9989670310751485,
      "grad_norm": 0.8334829807281494,
      "learning_rate": 0.00015559999775006787,
      "loss": 3.046,
      "step": 23210
    },
    {
      "epoch": 0.9993974347938366,
      "grad_norm": 0.9226022958755493,
      "learning_rate": 0.00015556136970760386,
      "loss": 3.0477,
      "step": 23220
    },
    {
      "epoch": 0.9998278385125248,
      "grad_norm": 0.8683477640151978,
      "learning_rate": 0.00015552272966874343,
      "loss": 3.0498,
      "step": 23230
    },
    {
      "epoch": 1.000258242231213,
      "grad_norm": 0.9964432716369629,
      "learning_rate": 0.00015548407764182938,
      "loss": 2.9472,
      "step": 23240
    },
    {
      "epoch": 1.000688645949901,
      "grad_norm": 0.9431445598602295,
      "learning_rate": 0.00015544541363520726,
      "loss": 3.072,
      "step": 23250
    },
    {
      "epoch": 1.000688645949901,
      "eval_bleu": 26.945361267103603,
      "eval_gen_len": 27.435,
      "eval_loss": 2.8036673069000244,
      "eval_runtime": 58.8199,
      "eval_samples_per_second": 17.001,
      "eval_steps_per_second": 1.071,
      "step": 23250
    },
    {
      "epoch": 1.0011190496685891,
      "grad_norm": 0.9440919756889343,
      "learning_rate": 0.00015540673765722504,
      "loss": 3.0455,
      "step": 23260
    },
    {
      "epoch": 1.0015494533872773,
      "grad_norm": 0.9272528886795044,
      "learning_rate": 0.0001553680497162334,
      "loss": 3.1192,
      "step": 23270
    },
    {
      "epoch": 1.0019798571059655,
      "grad_norm": 0.9115141034126282,
      "learning_rate": 0.00015532934982058553,
      "loss": 3.0509,
      "step": 23280
    },
    {
      "epoch": 1.0024102608246535,
      "grad_norm": 0.9574916958808899,
      "learning_rate": 0.00015529063797863724,
      "loss": 3.015,
      "step": 23290
    },
    {
      "epoch": 1.0028406645433416,
      "grad_norm": 0.9789866209030151,
      "learning_rate": 0.00015525191419874686,
      "loss": 3.0185,
      "step": 23300
    },
    {
      "epoch": 1.0028406645433416,
      "eval_bleu": 26.58947325477006,
      "eval_gen_len": 27.507,
      "eval_loss": 2.8078997135162354,
      "eval_runtime": 59.0073,
      "eval_samples_per_second": 16.947,
      "eval_steps_per_second": 1.068,
      "step": 23300
    },
    {
      "epoch": 1.0032710682620298,
      "grad_norm": 0.9517245888710022,
      "learning_rate": 0.0001552131784892754,
      "loss": 3.0824,
      "step": 23310
    },
    {
      "epoch": 1.003701471980718,
      "grad_norm": 1.014074444770813,
      "learning_rate": 0.00015517443085858633,
      "loss": 3.0665,
      "step": 23320
    },
    {
      "epoch": 1.004131875699406,
      "grad_norm": 0.8069735765457153,
      "learning_rate": 0.00015513567131504577,
      "loss": 2.9621,
      "step": 23330
    },
    {
      "epoch": 1.0045622794180942,
      "grad_norm": 0.9522185325622559,
      "learning_rate": 0.00015509689986702242,
      "loss": 3.0348,
      "step": 23340
    },
    {
      "epoch": 1.0049926831367824,
      "grad_norm": 0.8995912671089172,
      "learning_rate": 0.00015505811652288747,
      "loss": 3.0225,
      "step": 23350
    },
    {
      "epoch": 1.0049926831367824,
      "eval_bleu": 26.980564414177543,
      "eval_gen_len": 27.496,
      "eval_loss": 2.803889274597168,
      "eval_runtime": 58.5605,
      "eval_samples_per_second": 17.076,
      "eval_steps_per_second": 1.076,
      "step": 23350
    },
    {
      "epoch": 1.0054230868554703,
      "grad_norm": 0.9143812656402588,
      "learning_rate": 0.00015501932129101476,
      "loss": 2.9881,
      "step": 23360
    },
    {
      "epoch": 1.0058534905741585,
      "grad_norm": 1.0594507455825806,
      "learning_rate": 0.00015498051417978066,
      "loss": 3.1721,
      "step": 23370
    },
    {
      "epoch": 1.0062838942928467,
      "grad_norm": 0.9407605528831482,
      "learning_rate": 0.00015494169519756409,
      "loss": 3.0165,
      "step": 23380
    },
    {
      "epoch": 1.006714298011535,
      "grad_norm": 1.0562686920166016,
      "learning_rate": 0.00015490286435274663,
      "loss": 3.0779,
      "step": 23390
    },
    {
      "epoch": 1.0071447017302229,
      "grad_norm": 0.8166009783744812,
      "learning_rate": 0.00015486402165371227,
      "loss": 2.9559,
      "step": 23400
    },
    {
      "epoch": 1.0071447017302229,
      "eval_bleu": 26.979049747272356,
      "eval_gen_len": 27.49,
      "eval_loss": 2.8028738498687744,
      "eval_runtime": 58.2298,
      "eval_samples_per_second": 17.173,
      "eval_steps_per_second": 1.082,
      "step": 23400
    },
    {
      "epoch": 1.007575105448911,
      "grad_norm": 0.8633055090904236,
      "learning_rate": 0.00015482516710884766,
      "loss": 3.0533,
      "step": 23410
    },
    {
      "epoch": 1.0080055091675992,
      "grad_norm": 0.9932971000671387,
      "learning_rate": 0.000154786300726542,
      "loss": 2.9973,
      "step": 23420
    },
    {
      "epoch": 1.0084359128862874,
      "grad_norm": 0.9744293093681335,
      "learning_rate": 0.000154747422515187,
      "loss": 3.0442,
      "step": 23430
    },
    {
      "epoch": 1.0088663166049754,
      "grad_norm": 0.8446297645568848,
      "learning_rate": 0.00015470853248317695,
      "loss": 2.9386,
      "step": 23440
    },
    {
      "epoch": 1.0092967203236636,
      "grad_norm": 0.9048442244529724,
      "learning_rate": 0.00015466963063890876,
      "loss": 3.0321,
      "step": 23450
    },
    {
      "epoch": 1.0092967203236636,
      "eval_bleu": 26.536607290687325,
      "eval_gen_len": 27.382,
      "eval_loss": 2.8095703125,
      "eval_runtime": 58.1462,
      "eval_samples_per_second": 17.198,
      "eval_steps_per_second": 1.083,
      "step": 23450
    },
    {
      "epoch": 1.0097271240423518,
      "grad_norm": 0.9248453974723816,
      "learning_rate": 0.00015463071699078174,
      "loss": 2.941,
      "step": 23460
    },
    {
      "epoch": 1.01015752776104,
      "grad_norm": 0.9169692397117615,
      "learning_rate": 0.0001545917915471979,
      "loss": 3.0524,
      "step": 23470
    },
    {
      "epoch": 1.010587931479728,
      "grad_norm": 0.9430558085441589,
      "learning_rate": 0.00015455285431656171,
      "loss": 3.049,
      "step": 23480
    },
    {
      "epoch": 1.011018335198416,
      "grad_norm": 0.9864226579666138,
      "learning_rate": 0.00015451390530728015,
      "loss": 3.0758,
      "step": 23490
    },
    {
      "epoch": 1.0114487389171043,
      "grad_norm": 0.8833491802215576,
      "learning_rate": 0.0001544749445277629,
      "loss": 3.0368,
      "step": 23500
    },
    {
      "epoch": 1.0114487389171043,
      "eval_bleu": 26.83046134192635,
      "eval_gen_len": 27.446,
      "eval_loss": 2.806795835494995,
      "eval_runtime": 58.951,
      "eval_samples_per_second": 16.963,
      "eval_steps_per_second": 1.069,
      "step": 23500
    },
    {
      "epoch": 1.0118791426357925,
      "grad_norm": 0.9881935715675354,
      "learning_rate": 0.00015443597198642203,
      "loss": 3.0091,
      "step": 23510
    },
    {
      "epoch": 1.0123095463544804,
      "grad_norm": 0.9584417939186096,
      "learning_rate": 0.00015439698769167216,
      "loss": 3.0286,
      "step": 23520
    },
    {
      "epoch": 1.0127399500731686,
      "grad_norm": 0.9077657461166382,
      "learning_rate": 0.00015435799165193056,
      "loss": 3.011,
      "step": 23530
    },
    {
      "epoch": 1.0131703537918568,
      "grad_norm": 0.9543184638023376,
      "learning_rate": 0.00015431898387561693,
      "loss": 3.066,
      "step": 23540
    },
    {
      "epoch": 1.0136007575105448,
      "grad_norm": 0.8528680801391602,
      "learning_rate": 0.00015427996437115358,
      "loss": 3.1058,
      "step": 23550
    },
    {
      "epoch": 1.0136007575105448,
      "eval_bleu": 27.054765346983697,
      "eval_gen_len": 27.593,
      "eval_loss": 2.8058035373687744,
      "eval_runtime": 59.4761,
      "eval_samples_per_second": 16.813,
      "eval_steps_per_second": 1.059,
      "step": 23550
    },
    {
      "epoch": 1.014031161229233,
      "grad_norm": 0.9291816353797913,
      "learning_rate": 0.00015424093314696523,
      "loss": 3.1348,
      "step": 23560
    },
    {
      "epoch": 1.0144615649479212,
      "grad_norm": 0.79727703332901,
      "learning_rate": 0.00015420189021147926,
      "loss": 3.0431,
      "step": 23570
    },
    {
      "epoch": 1.0148919686666094,
      "grad_norm": 0.8949565291404724,
      "learning_rate": 0.00015416283557312553,
      "loss": 2.9837,
      "step": 23580
    },
    {
      "epoch": 1.0153223723852973,
      "grad_norm": 0.9754967093467712,
      "learning_rate": 0.0001541237692403364,
      "loss": 3.1361,
      "step": 23590
    },
    {
      "epoch": 1.0157527761039855,
      "grad_norm": 0.9412514567375183,
      "learning_rate": 0.00015408469122154682,
      "loss": 3.065,
      "step": 23600
    },
    {
      "epoch": 1.0157527761039855,
      "eval_bleu": 25.979406914779272,
      "eval_gen_len": 27.527,
      "eval_loss": 2.811267614364624,
      "eval_runtime": 58.6156,
      "eval_samples_per_second": 17.06,
      "eval_steps_per_second": 1.075,
      "step": 23600
    },
    {
      "epoch": 1.0161831798226737,
      "grad_norm": 0.9190945625305176,
      "learning_rate": 0.00015404560152519422,
      "loss": 3.0215,
      "step": 23610
    },
    {
      "epoch": 1.0166135835413619,
      "grad_norm": 0.8755475282669067,
      "learning_rate": 0.00015400650015971848,
      "loss": 2.9694,
      "step": 23620
    },
    {
      "epoch": 1.0170439872600499,
      "grad_norm": 0.8487980365753174,
      "learning_rate": 0.0001539673871335622,
      "loss": 3.0035,
      "step": 23630
    },
    {
      "epoch": 1.017474390978738,
      "grad_norm": 0.8984558582305908,
      "learning_rate": 0.0001539282624551703,
      "loss": 3.0657,
      "step": 23640
    },
    {
      "epoch": 1.0179047946974262,
      "grad_norm": 0.954550564289093,
      "learning_rate": 0.00015388912613299025,
      "loss": 3.0457,
      "step": 23650
    },
    {
      "epoch": 1.0179047946974262,
      "eval_bleu": 27.30061810019799,
      "eval_gen_len": 27.458,
      "eval_loss": 2.8028204441070557,
      "eval_runtime": 58.3401,
      "eval_samples_per_second": 17.141,
      "eval_steps_per_second": 1.08,
      "step": 23650
    },
    {
      "epoch": 1.0183351984161144,
      "grad_norm": 1.0052199363708496,
      "learning_rate": 0.00015384997817547214,
      "loss": 3.0313,
      "step": 23660
    },
    {
      "epoch": 1.0187656021348024,
      "grad_norm": 0.8816834092140198,
      "learning_rate": 0.00015381081859106848,
      "loss": 2.9759,
      "step": 23670
    },
    {
      "epoch": 1.0191960058534906,
      "grad_norm": 0.9557874202728271,
      "learning_rate": 0.00015377164738823439,
      "loss": 3.0169,
      "step": 23680
    },
    {
      "epoch": 1.0196264095721788,
      "grad_norm": 0.8944732546806335,
      "learning_rate": 0.00015373246457542727,
      "loss": 2.9372,
      "step": 23690
    },
    {
      "epoch": 1.0200568132908667,
      "grad_norm": 0.8887656927108765,
      "learning_rate": 0.0001536932701611073,
      "loss": 3.035,
      "step": 23700
    },
    {
      "epoch": 1.0200568132908667,
      "eval_bleu": 26.91955613477252,
      "eval_gen_len": 27.428,
      "eval_loss": 2.8030614852905273,
      "eval_runtime": 58.3237,
      "eval_samples_per_second": 17.146,
      "eval_steps_per_second": 1.08,
      "step": 23700
    },
    {
      "epoch": 1.020487217009555,
      "grad_norm": 0.9275685548782349,
      "learning_rate": 0.00015365406415373699,
      "loss": 3.0744,
      "step": 23710
    },
    {
      "epoch": 1.020917620728243,
      "grad_norm": 0.9524468779563904,
      "learning_rate": 0.00015361484656178145,
      "loss": 3.0326,
      "step": 23720
    },
    {
      "epoch": 1.0213480244469313,
      "grad_norm": 0.882868766784668,
      "learning_rate": 0.0001535756173937082,
      "loss": 2.9624,
      "step": 23730
    },
    {
      "epoch": 1.0217784281656193,
      "grad_norm": 0.7704656720161438,
      "learning_rate": 0.00015353637665798737,
      "loss": 2.9484,
      "step": 23740
    },
    {
      "epoch": 1.0222088318843074,
      "grad_norm": 0.9407050609588623,
      "learning_rate": 0.00015349712436309144,
      "loss": 3.0712,
      "step": 23750
    },
    {
      "epoch": 1.0222088318843074,
      "eval_bleu": 27.21874735536824,
      "eval_gen_len": 27.464,
      "eval_loss": 2.803561210632324,
      "eval_runtime": 58.6242,
      "eval_samples_per_second": 17.058,
      "eval_steps_per_second": 1.075,
      "step": 23750
    },
    {
      "epoch": 1.0226392356029956,
      "grad_norm": 0.9834998846054077,
      "learning_rate": 0.00015345786051749558,
      "loss": 3.0917,
      "step": 23760
    },
    {
      "epoch": 1.0230696393216838,
      "grad_norm": 0.9601624608039856,
      "learning_rate": 0.00015341858512967727,
      "loss": 3.0035,
      "step": 23770
    },
    {
      "epoch": 1.0235000430403718,
      "grad_norm": 0.9247798919677734,
      "learning_rate": 0.00015337929820811658,
      "loss": 2.9915,
      "step": 23780
    },
    {
      "epoch": 1.02393044675906,
      "grad_norm": 0.8704931735992432,
      "learning_rate": 0.00015333999976129608,
      "loss": 2.9351,
      "step": 23790
    },
    {
      "epoch": 1.0243608504777482,
      "grad_norm": 0.8406919240951538,
      "learning_rate": 0.00015330068979770077,
      "loss": 2.9169,
      "step": 23800
    },
    {
      "epoch": 1.0243608504777482,
      "eval_bleu": 26.953409918062807,
      "eval_gen_len": 27.485,
      "eval_loss": 2.8045918941497803,
      "eval_runtime": 58.4806,
      "eval_samples_per_second": 17.1,
      "eval_steps_per_second": 1.077,
      "step": 23800
    },
    {
      "epoch": 1.0247912541964364,
      "grad_norm": 0.9524956345558167,
      "learning_rate": 0.0001532613683258181,
      "loss": 3.0293,
      "step": 23810
    },
    {
      "epoch": 1.0252216579151243,
      "grad_norm": 0.909494161605835,
      "learning_rate": 0.0001532220353541382,
      "loss": 3.0344,
      "step": 23820
    },
    {
      "epoch": 1.0256520616338125,
      "grad_norm": 0.8548329472541809,
      "learning_rate": 0.00015318269089115345,
      "loss": 3.034,
      "step": 23830
    },
    {
      "epoch": 1.0260824653525007,
      "grad_norm": 0.8988355398178101,
      "learning_rate": 0.00015314333494535886,
      "loss": 3.0338,
      "step": 23840
    },
    {
      "epoch": 1.0265128690711889,
      "grad_norm": 0.8812910318374634,
      "learning_rate": 0.00015310396752525184,
      "loss": 2.9699,
      "step": 23850
    },
    {
      "epoch": 1.0265128690711889,
      "eval_bleu": 26.96397509861664,
      "eval_gen_len": 27.495,
      "eval_loss": 2.8042590618133545,
      "eval_runtime": 58.4736,
      "eval_samples_per_second": 17.102,
      "eval_steps_per_second": 1.077,
      "step": 23850
    },
    {
      "epoch": 1.0269432727898768,
      "grad_norm": 0.9164372682571411,
      "learning_rate": 0.00015306458863933236,
      "loss": 3.016,
      "step": 23860
    },
    {
      "epoch": 1.027373676508565,
      "grad_norm": 0.9836767911911011,
      "learning_rate": 0.00015302519829610276,
      "loss": 2.9859,
      "step": 23870
    },
    {
      "epoch": 1.0278040802272532,
      "grad_norm": 0.9068275690078735,
      "learning_rate": 0.00015298579650406793,
      "loss": 3.0257,
      "step": 23880
    },
    {
      "epoch": 1.0282344839459412,
      "grad_norm": 0.9751457571983337,
      "learning_rate": 0.00015294638327173523,
      "loss": 2.9334,
      "step": 23890
    },
    {
      "epoch": 1.0286648876646294,
      "grad_norm": 0.882320761680603,
      "learning_rate": 0.00015290695860761445,
      "loss": 2.9944,
      "step": 23900
    },
    {
      "epoch": 1.0286648876646294,
      "eval_bleu": 26.765635517174307,
      "eval_gen_len": 27.556,
      "eval_loss": 2.8079867362976074,
      "eval_runtime": 58.79,
      "eval_samples_per_second": 17.01,
      "eval_steps_per_second": 1.072,
      "step": 23900
    },
    {
      "epoch": 1.0290952913833176,
      "grad_norm": 0.8723240494728088,
      "learning_rate": 0.00015286752252021785,
      "loss": 3.1025,
      "step": 23910
    },
    {
      "epoch": 1.0295256951020058,
      "grad_norm": 0.9076417684555054,
      "learning_rate": 0.0001528280750180602,
      "loss": 3.0682,
      "step": 23920
    },
    {
      "epoch": 1.0299560988206937,
      "grad_norm": 0.876336395740509,
      "learning_rate": 0.00015278861610965874,
      "loss": 2.8444,
      "step": 23930
    },
    {
      "epoch": 1.030386502539382,
      "grad_norm": 0.9565269351005554,
      "learning_rate": 0.0001527491458035331,
      "loss": 2.9976,
      "step": 23940
    },
    {
      "epoch": 1.03081690625807,
      "grad_norm": 0.9815735220909119,
      "learning_rate": 0.00015270966410820544,
      "loss": 3.0138,
      "step": 23950
    },
    {
      "epoch": 1.03081690625807,
      "eval_bleu": 26.535415296369997,
      "eval_gen_len": 27.32,
      "eval_loss": 2.8058669567108154,
      "eval_runtime": 58.055,
      "eval_samples_per_second": 17.225,
      "eval_steps_per_second": 1.085,
      "step": 23950
    },
    {
      "epoch": 1.0312473099767583,
      "grad_norm": 0.94673752784729,
      "learning_rate": 0.00015267017103220032,
      "loss": 3.1086,
      "step": 23960
    },
    {
      "epoch": 1.0316777136954463,
      "grad_norm": 0.963151216506958,
      "learning_rate": 0.00015263066658404483,
      "loss": 3.0517,
      "step": 23970
    },
    {
      "epoch": 1.0321081174141344,
      "grad_norm": 0.9026240110397339,
      "learning_rate": 0.00015259115077226847,
      "loss": 2.9767,
      "step": 23980
    },
    {
      "epoch": 1.0325385211328226,
      "grad_norm": 0.8699150681495667,
      "learning_rate": 0.00015255162360540314,
      "loss": 2.9663,
      "step": 23990
    },
    {
      "epoch": 1.0329689248515108,
      "grad_norm": 0.8103477954864502,
      "learning_rate": 0.00015251208509198334,
      "loss": 3.0374,
      "step": 24000
    },
    {
      "epoch": 1.0329689248515108,
      "eval_bleu": 27.23150720794187,
      "eval_gen_len": 27.583,
      "eval_loss": 2.801579475402832,
      "eval_runtime": 58.958,
      "eval_samples_per_second": 16.961,
      "eval_steps_per_second": 1.069,
      "step": 24000
    },
    {
      "epoch": 1.0333993285701988,
      "grad_norm": 0.9072594046592712,
      "learning_rate": 0.00015247253524054588,
      "loss": 3.0215,
      "step": 24010
    },
    {
      "epoch": 1.033829732288887,
      "grad_norm": 1.0484763383865356,
      "learning_rate": 0.00015243297405963003,
      "loss": 2.9971,
      "step": 24020
    },
    {
      "epoch": 1.0342601360075752,
      "grad_norm": 0.864109218120575,
      "learning_rate": 0.0001523934015577776,
      "loss": 3.0564,
      "step": 24030
    },
    {
      "epoch": 1.0346905397262631,
      "grad_norm": 0.9026110768318176,
      "learning_rate": 0.00015235381774353286,
      "loss": 3.026,
      "step": 24040
    },
    {
      "epoch": 1.0351209434449513,
      "grad_norm": 0.9190629720687866,
      "learning_rate": 0.0001523142226254423,
      "loss": 2.93,
      "step": 24050
    },
    {
      "epoch": 1.0351209434449513,
      "eval_bleu": 26.58254737423307,
      "eval_gen_len": 27.451,
      "eval_loss": 2.807642936706543,
      "eval_runtime": 58.5156,
      "eval_samples_per_second": 17.089,
      "eval_steps_per_second": 1.077,
      "step": 24050
    },
    {
      "epoch": 1.0355513471636395,
      "grad_norm": 0.8115623593330383,
      "learning_rate": 0.0001522746162120551,
      "loss": 3.0712,
      "step": 24060
    },
    {
      "epoch": 1.0359817508823277,
      "grad_norm": 0.8291106820106506,
      "learning_rate": 0.00015223499851192273,
      "loss": 3.0475,
      "step": 24070
    },
    {
      "epoch": 1.0364121546010157,
      "grad_norm": 0.9609695076942444,
      "learning_rate": 0.00015219536953359924,
      "loss": 3.0196,
      "step": 24080
    },
    {
      "epoch": 1.0368425583197038,
      "grad_norm": 0.8520423769950867,
      "learning_rate": 0.0001521557292856409,
      "loss": 2.9392,
      "step": 24090
    },
    {
      "epoch": 1.037272962038392,
      "grad_norm": 1.000781774520874,
      "learning_rate": 0.0001521160777766066,
      "loss": 3.0568,
      "step": 24100
    },
    {
      "epoch": 1.037272962038392,
      "eval_bleu": 26.53804083037078,
      "eval_gen_len": 27.525,
      "eval_loss": 2.8030521869659424,
      "eval_runtime": 58.5413,
      "eval_samples_per_second": 17.082,
      "eval_steps_per_second": 1.076,
      "step": 24100
    },
    {
      "epoch": 1.0377033657570802,
      "grad_norm": 0.9108303189277649,
      "learning_rate": 0.00015207641501505757,
      "loss": 3.0635,
      "step": 24110
    },
    {
      "epoch": 1.0381337694757682,
      "grad_norm": 0.942830502986908,
      "learning_rate": 0.0001520367410095576,
      "loss": 2.9669,
      "step": 24120
    },
    {
      "epoch": 1.0385641731944564,
      "grad_norm": 0.8946195840835571,
      "learning_rate": 0.00015199705576867265,
      "loss": 3.0113,
      "step": 24130
    },
    {
      "epoch": 1.0389945769131446,
      "grad_norm": 0.8583912253379822,
      "learning_rate": 0.00015195735930097136,
      "loss": 2.9826,
      "step": 24140
    },
    {
      "epoch": 1.0394249806318328,
      "grad_norm": 1.0339099168777466,
      "learning_rate": 0.0001519176516150247,
      "loss": 3.0731,
      "step": 24150
    },
    {
      "epoch": 1.0394249806318328,
      "eval_bleu": 26.919537650003676,
      "eval_gen_len": 27.605,
      "eval_loss": 2.8039212226867676,
      "eval_runtime": 58.2366,
      "eval_samples_per_second": 17.171,
      "eval_steps_per_second": 1.082,
      "step": 24150
    },
    {
      "epoch": 1.0398553843505207,
      "grad_norm": 0.9996572136878967,
      "learning_rate": 0.000151877932719406,
      "loss": 2.9527,
      "step": 24160
    },
    {
      "epoch": 1.040285788069209,
      "grad_norm": 0.9982077479362488,
      "learning_rate": 0.0001518382026226911,
      "loss": 3.0187,
      "step": 24170
    },
    {
      "epoch": 1.040716191787897,
      "grad_norm": 0.8779394030570984,
      "learning_rate": 0.0001517984613334582,
      "loss": 3.0233,
      "step": 24180
    },
    {
      "epoch": 1.0411465955065853,
      "grad_norm": 0.8307713866233826,
      "learning_rate": 0.000151758708860288,
      "loss": 2.9793,
      "step": 24190
    },
    {
      "epoch": 1.0415769992252732,
      "grad_norm": 0.9399834275245667,
      "learning_rate": 0.0001517189452117635,
      "loss": 3.0148,
      "step": 24200
    },
    {
      "epoch": 1.0415769992252732,
      "eval_bleu": 26.782854120578,
      "eval_gen_len": 27.445,
      "eval_loss": 2.805508852005005,
      "eval_runtime": 58.7978,
      "eval_samples_per_second": 17.007,
      "eval_steps_per_second": 1.071,
      "step": 24200
    },
    {
      "epoch": 1.0420074029439614,
      "grad_norm": 0.8935649991035461,
      "learning_rate": 0.0001516791703964702,
      "loss": 2.9271,
      "step": 24210
    },
    {
      "epoch": 1.0424378066626496,
      "grad_norm": 0.9878196716308594,
      "learning_rate": 0.000151639384422996,
      "loss": 3.0831,
      "step": 24220
    },
    {
      "epoch": 1.0428682103813376,
      "grad_norm": 1.0462058782577515,
      "learning_rate": 0.00015159958729993114,
      "loss": 3.0169,
      "step": 24230
    },
    {
      "epoch": 1.0432986141000258,
      "grad_norm": 0.8999403715133667,
      "learning_rate": 0.00015155977903586834,
      "loss": 3.0721,
      "step": 24240
    },
    {
      "epoch": 1.043729017818714,
      "grad_norm": 0.9247612953186035,
      "learning_rate": 0.00015151995963940274,
      "loss": 2.9825,
      "step": 24250
    },
    {
      "epoch": 1.043729017818714,
      "eval_bleu": 27.129507920282652,
      "eval_gen_len": 27.429,
      "eval_loss": 2.8066179752349854,
      "eval_runtime": 58.064,
      "eval_samples_per_second": 17.222,
      "eval_steps_per_second": 1.085,
      "step": 24250
    },
    {
      "epoch": 1.0441594215374022,
      "grad_norm": 0.9171693325042725,
      "learning_rate": 0.00015148012911913182,
      "loss": 3.0284,
      "step": 24260
    },
    {
      "epoch": 1.0445898252560901,
      "grad_norm": 0.7941011190414429,
      "learning_rate": 0.00015144028748365545,
      "loss": 2.9999,
      "step": 24270
    },
    {
      "epoch": 1.0450202289747783,
      "grad_norm": 0.9460298418998718,
      "learning_rate": 0.00015140043474157596,
      "loss": 2.979,
      "step": 24280
    },
    {
      "epoch": 1.0454506326934665,
      "grad_norm": 1.0011036396026611,
      "learning_rate": 0.00015136057090149807,
      "loss": 3.0586,
      "step": 24290
    },
    {
      "epoch": 1.0458810364121547,
      "grad_norm": 0.8414595127105713,
      "learning_rate": 0.0001513206959720289,
      "loss": 3.0202,
      "step": 24300
    },
    {
      "epoch": 1.0458810364121547,
      "eval_bleu": 26.79364786364794,
      "eval_gen_len": 27.485,
      "eval_loss": 2.8048744201660156,
      "eval_runtime": 58.7267,
      "eval_samples_per_second": 17.028,
      "eval_steps_per_second": 1.073,
      "step": 24300
    },
    {
      "epoch": 1.0463114401308427,
      "grad_norm": 0.9183123707771301,
      "learning_rate": 0.0001512808099617779,
      "loss": 3.017,
      "step": 24310
    },
    {
      "epoch": 1.0467418438495308,
      "grad_norm": 0.959750771522522,
      "learning_rate": 0.000151240912879357,
      "loss": 3.0303,
      "step": 24320
    },
    {
      "epoch": 1.047172247568219,
      "grad_norm": 0.8116564154624939,
      "learning_rate": 0.0001512010047333805,
      "loss": 2.9647,
      "step": 24330
    },
    {
      "epoch": 1.0476026512869072,
      "grad_norm": 0.9226555228233337,
      "learning_rate": 0.00015116108553246503,
      "loss": 3.0182,
      "step": 24340
    },
    {
      "epoch": 1.0480330550055952,
      "grad_norm": 0.8555219173431396,
      "learning_rate": 0.00015112115528522963,
      "loss": 2.9773,
      "step": 24350
    },
    {
      "epoch": 1.0480330550055952,
      "eval_bleu": 26.770177075380744,
      "eval_gen_len": 27.391,
      "eval_loss": 2.8007616996765137,
      "eval_runtime": 58.1963,
      "eval_samples_per_second": 17.183,
      "eval_steps_per_second": 1.083,
      "step": 24350
    },
    {
      "epoch": 1.0484634587242834,
      "grad_norm": 0.9634248614311218,
      "learning_rate": 0.00015108121400029577,
      "loss": 2.9808,
      "step": 24360
    },
    {
      "epoch": 1.0488938624429716,
      "grad_norm": 1.041300892829895,
      "learning_rate": 0.00015104126168628728,
      "loss": 3.0864,
      "step": 24370
    },
    {
      "epoch": 1.0493242661616597,
      "grad_norm": 0.9215757250785828,
      "learning_rate": 0.00015100129835183036,
      "loss": 3.102,
      "step": 24380
    },
    {
      "epoch": 1.0497546698803477,
      "grad_norm": 0.8393563032150269,
      "learning_rate": 0.00015096132400555353,
      "loss": 3.0171,
      "step": 24390
    },
    {
      "epoch": 1.050185073599036,
      "grad_norm": 0.9911548495292664,
      "learning_rate": 0.0001509213386560879,
      "loss": 3.0176,
      "step": 24400
    },
    {
      "epoch": 1.050185073599036,
      "eval_bleu": 26.93154402362289,
      "eval_gen_len": 27.525,
      "eval_loss": 2.8088815212249756,
      "eval_runtime": 58.7642,
      "eval_samples_per_second": 17.017,
      "eval_steps_per_second": 1.072,
      "step": 24400
    },
    {
      "epoch": 1.050615477317724,
      "grad_norm": 0.8952337503433228,
      "learning_rate": 0.00015088134231206667,
      "loss": 3.0666,
      "step": 24410
    },
    {
      "epoch": 1.051045881036412,
      "grad_norm": 0.8372141122817993,
      "learning_rate": 0.00015084133498212562,
      "loss": 3.0433,
      "step": 24420
    },
    {
      "epoch": 1.0514762847551002,
      "grad_norm": 0.989355206489563,
      "learning_rate": 0.0001508013166749028,
      "loss": 2.9804,
      "step": 24430
    },
    {
      "epoch": 1.0519066884737884,
      "grad_norm": 0.8411699533462524,
      "learning_rate": 0.00015076128739903867,
      "loss": 3.0464,
      "step": 24440
    },
    {
      "epoch": 1.0523370921924766,
      "grad_norm": 0.8070863485336304,
      "learning_rate": 0.00015072124716317614,
      "loss": 2.9474,
      "step": 24450
    },
    {
      "epoch": 1.0523370921924766,
      "eval_bleu": 26.983873579911094,
      "eval_gen_len": 27.569,
      "eval_loss": 2.8085310459136963,
      "eval_runtime": 58.0843,
      "eval_samples_per_second": 17.216,
      "eval_steps_per_second": 1.085,
      "step": 24450
    },
    {
      "epoch": 1.0527674959111646,
      "grad_norm": 0.8387488126754761,
      "learning_rate": 0.00015068119597596023,
      "loss": 3.0847,
      "step": 24460
    },
    {
      "epoch": 1.0531978996298528,
      "grad_norm": 0.825686514377594,
      "learning_rate": 0.00015064113384603863,
      "loss": 2.9714,
      "step": 24470
    },
    {
      "epoch": 1.053628303348541,
      "grad_norm": 0.9666914343833923,
      "learning_rate": 0.00015060106078206118,
      "loss": 2.9568,
      "step": 24480
    },
    {
      "epoch": 1.0540587070672292,
      "grad_norm": 0.8666554093360901,
      "learning_rate": 0.00015056097679268024,
      "loss": 3.0313,
      "step": 24490
    },
    {
      "epoch": 1.0544891107859171,
      "grad_norm": 0.9512449502944946,
      "learning_rate": 0.00015052088188655035,
      "loss": 3.1044,
      "step": 24500
    },
    {
      "epoch": 1.0544891107859171,
      "eval_bleu": 27.152394048160183,
      "eval_gen_len": 27.51,
      "eval_loss": 2.8069188594818115,
      "eval_runtime": 59.0828,
      "eval_samples_per_second": 16.925,
      "eval_steps_per_second": 1.066,
      "step": 24500
    },
    {
      "epoch": 1.0549195145046053,
      "grad_norm": 0.9318680763244629,
      "learning_rate": 0.0001504807760723286,
      "loss": 3.0768,
      "step": 24510
    },
    {
      "epoch": 1.0553499182232935,
      "grad_norm": 0.7926671504974365,
      "learning_rate": 0.00015044065935867424,
      "loss": 3.0291,
      "step": 24520
    },
    {
      "epoch": 1.0557803219419817,
      "grad_norm": 0.8280757069587708,
      "learning_rate": 0.00015040053175424903,
      "loss": 3.0758,
      "step": 24530
    },
    {
      "epoch": 1.0562107256606696,
      "grad_norm": 0.8258306384086609,
      "learning_rate": 0.00015036039326771702,
      "loss": 3.0906,
      "step": 24540
    },
    {
      "epoch": 1.0566411293793578,
      "grad_norm": 0.861484944820404,
      "learning_rate": 0.0001503202439077446,
      "loss": 3.0203,
      "step": 24550
    },
    {
      "epoch": 1.0566411293793578,
      "eval_bleu": 27.268680590047833,
      "eval_gen_len": 27.644,
      "eval_loss": 2.8079164028167725,
      "eval_runtime": 58.9585,
      "eval_samples_per_second": 16.961,
      "eval_steps_per_second": 1.069,
      "step": 24550
    },
    {
      "epoch": 1.057071533098046,
      "grad_norm": 0.9055728316307068,
      "learning_rate": 0.0001502800836830005,
      "loss": 3.0031,
      "step": 24560
    },
    {
      "epoch": 1.057501936816734,
      "grad_norm": 0.845073938369751,
      "learning_rate": 0.00015023991260215586,
      "loss": 2.8684,
      "step": 24570
    },
    {
      "epoch": 1.0579323405354222,
      "grad_norm": 0.8026037812232971,
      "learning_rate": 0.00015019973067388414,
      "loss": 2.9647,
      "step": 24580
    },
    {
      "epoch": 1.0583627442541104,
      "grad_norm": 0.9648601412773132,
      "learning_rate": 0.00015015953790686103,
      "loss": 2.9193,
      "step": 24590
    },
    {
      "epoch": 1.0587931479727986,
      "grad_norm": 0.8294512629508972,
      "learning_rate": 0.0001501193343097647,
      "loss": 3.0754,
      "step": 24600
    },
    {
      "epoch": 1.0587931479727986,
      "eval_bleu": 27.07331139232216,
      "eval_gen_len": 27.409,
      "eval_loss": 2.810153007507324,
      "eval_runtime": 58.604,
      "eval_samples_per_second": 17.064,
      "eval_steps_per_second": 1.075,
      "step": 24600
    },
    {
      "epoch": 1.0592235516914865,
      "grad_norm": 1.2670609951019287,
      "learning_rate": 0.00015007911989127566,
      "loss": 3.0386,
      "step": 24610
    },
    {
      "epoch": 1.0596539554101747,
      "grad_norm": 0.9627676010131836,
      "learning_rate": 0.00015003889466007664,
      "loss": 3.0573,
      "step": 24620
    },
    {
      "epoch": 1.060084359128863,
      "grad_norm": 0.8591370582580566,
      "learning_rate": 0.00014999865862485277,
      "loss": 3.0249,
      "step": 24630
    },
    {
      "epoch": 1.060514762847551,
      "grad_norm": 0.986710250377655,
      "learning_rate": 0.00014995841179429157,
      "loss": 2.9917,
      "step": 24640
    },
    {
      "epoch": 1.060945166566239,
      "grad_norm": 0.9502800703048706,
      "learning_rate": 0.0001499181541770828,
      "loss": 2.9973,
      "step": 24650
    },
    {
      "epoch": 1.060945166566239,
      "eval_bleu": 26.67800378022202,
      "eval_gen_len": 27.838,
      "eval_loss": 2.8115525245666504,
      "eval_runtime": 64.4493,
      "eval_samples_per_second": 15.516,
      "eval_steps_per_second": 0.978,
      "step": 24650
    },
    {
      "epoch": 1.0613755702849272,
      "grad_norm": 0.9552857279777527,
      "learning_rate": 0.0001498778857819186,
      "loss": 3.0799,
      "step": 24660
    },
    {
      "epoch": 1.0618059740036154,
      "grad_norm": 0.9695901870727539,
      "learning_rate": 0.0001498376066174934,
      "loss": 3.0229,
      "step": 24670
    },
    {
      "epoch": 1.0622363777223036,
      "grad_norm": 0.9246274828910828,
      "learning_rate": 0.00014979731669250397,
      "loss": 2.9283,
      "step": 24680
    },
    {
      "epoch": 1.0626667814409916,
      "grad_norm": 0.9254319667816162,
      "learning_rate": 0.00014975701601564946,
      "loss": 2.9788,
      "step": 24690
    },
    {
      "epoch": 1.0630971851596798,
      "grad_norm": 0.9047719240188599,
      "learning_rate": 0.00014971670459563123,
      "loss": 3.1342,
      "step": 24700
    },
    {
      "epoch": 1.0630971851596798,
      "eval_bleu": 26.51493071379391,
      "eval_gen_len": 27.904,
      "eval_loss": 2.811180830001831,
      "eval_runtime": 64.5873,
      "eval_samples_per_second": 15.483,
      "eval_steps_per_second": 0.975,
      "step": 24700
    },
    {
      "epoch": 1.063527588878368,
      "grad_norm": 0.870520830154419,
      "learning_rate": 0.00014967638244115308,
      "loss": 3.043,
      "step": 24710
    },
    {
      "epoch": 1.063957992597056,
      "grad_norm": 0.8750525116920471,
      "learning_rate": 0.000149636049560921,
      "loss": 2.9814,
      "step": 24720
    },
    {
      "epoch": 1.0643883963157441,
      "grad_norm": 0.8127573132514954,
      "learning_rate": 0.00014959570596364343,
      "loss": 3.0384,
      "step": 24730
    },
    {
      "epoch": 1.0648188000344323,
      "grad_norm": 0.9129241108894348,
      "learning_rate": 0.00014955535165803104,
      "loss": 3.0415,
      "step": 24740
    },
    {
      "epoch": 1.0652492037531205,
      "grad_norm": 0.8736069798469543,
      "learning_rate": 0.00014951498665279677,
      "loss": 2.971,
      "step": 24750
    },
    {
      "epoch": 1.0652492037531205,
      "eval_bleu": 26.977066300859356,
      "eval_gen_len": 27.349,
      "eval_loss": 2.81040620803833,
      "eval_runtime": 58.0691,
      "eval_samples_per_second": 17.221,
      "eval_steps_per_second": 1.085,
      "step": 24750
    },
    {
      "epoch": 1.0656796074718085,
      "grad_norm": 0.8652798533439636,
      "learning_rate": 0.000149474610956656,
      "loss": 3.0338,
      "step": 24760
    },
    {
      "epoch": 1.0661100111904966,
      "grad_norm": 1.0170164108276367,
      "learning_rate": 0.0001494342245783264,
      "loss": 3.0587,
      "step": 24770
    },
    {
      "epoch": 1.0665404149091848,
      "grad_norm": 0.8609590530395508,
      "learning_rate": 0.00014939382752652774,
      "loss": 3.0181,
      "step": 24780
    },
    {
      "epoch": 1.066970818627873,
      "grad_norm": 0.8792190551757812,
      "learning_rate": 0.0001493534198099824,
      "loss": 3.0123,
      "step": 24790
    },
    {
      "epoch": 1.067401222346561,
      "grad_norm": 0.9189691543579102,
      "learning_rate": 0.00014931300143741481,
      "loss": 3.0744,
      "step": 24800
    },
    {
      "epoch": 1.067401222346561,
      "eval_bleu": 27.1504017330357,
      "eval_gen_len": 27.446,
      "eval_loss": 2.805183172225952,
      "eval_runtime": 58.2663,
      "eval_samples_per_second": 17.163,
      "eval_steps_per_second": 1.081,
      "step": 24800
    },
    {
      "epoch": 1.0678316260652492,
      "grad_norm": 0.960949718952179,
      "learning_rate": 0.00014927257241755188,
      "loss": 3.004,
      "step": 24810
    },
    {
      "epoch": 1.0682620297839374,
      "grad_norm": 0.8236644864082336,
      "learning_rate": 0.0001492321327591227,
      "loss": 3.0483,
      "step": 24820
    },
    {
      "epoch": 1.0686924335026255,
      "grad_norm": 0.8333791494369507,
      "learning_rate": 0.00014919168247085868,
      "loss": 3.0072,
      "step": 24830
    },
    {
      "epoch": 1.0691228372213135,
      "grad_norm": 0.9476833343505859,
      "learning_rate": 0.00014915122156149358,
      "loss": 3.025,
      "step": 24840
    },
    {
      "epoch": 1.0695532409400017,
      "grad_norm": 0.9808852672576904,
      "learning_rate": 0.00014911075003976338,
      "loss": 3.0784,
      "step": 24850
    },
    {
      "epoch": 1.0695532409400017,
      "eval_bleu": 26.962978523415252,
      "eval_gen_len": 27.488,
      "eval_loss": 2.806544780731201,
      "eval_runtime": 58.1712,
      "eval_samples_per_second": 17.191,
      "eval_steps_per_second": 1.083,
      "step": 24850
    },
    {
      "epoch": 1.06998364465869,
      "grad_norm": 0.9866514801979065,
      "learning_rate": 0.0001490702679144065,
      "loss": 3.0152,
      "step": 24860
    },
    {
      "epoch": 1.070414048377378,
      "grad_norm": 0.9120269417762756,
      "learning_rate": 0.00014902977519416338,
      "loss": 3.0744,
      "step": 24870
    },
    {
      "epoch": 1.070844452096066,
      "grad_norm": 0.8535768985748291,
      "learning_rate": 0.000148989271887777,
      "loss": 3.0859,
      "step": 24880
    },
    {
      "epoch": 1.0712748558147542,
      "grad_norm": 0.936538577079773,
      "learning_rate": 0.0001489487580039925,
      "loss": 3.0577,
      "step": 24890
    },
    {
      "epoch": 1.0717052595334424,
      "grad_norm": 0.9206570982933044,
      "learning_rate": 0.00014890823355155738,
      "loss": 3.0632,
      "step": 24900
    },
    {
      "epoch": 1.0717052595334424,
      "eval_bleu": 26.670855264534307,
      "eval_gen_len": 27.585,
      "eval_loss": 2.8108341693878174,
      "eval_runtime": 58.5743,
      "eval_samples_per_second": 17.072,
      "eval_steps_per_second": 1.076,
      "step": 24900
    },
    {
      "epoch": 1.0721356632521304,
      "grad_norm": 0.972919762134552,
      "learning_rate": 0.00014886769853922132,
      "loss": 3.0495,
      "step": 24910
    },
    {
      "epoch": 1.0725660669708186,
      "grad_norm": 0.9568228721618652,
      "learning_rate": 0.00014882715297573638,
      "loss": 3.0778,
      "step": 24920
    },
    {
      "epoch": 1.0729964706895068,
      "grad_norm": 1.0027740001678467,
      "learning_rate": 0.00014878659686985682,
      "loss": 3.0087,
      "step": 24930
    },
    {
      "epoch": 1.073426874408195,
      "grad_norm": 0.8965824842453003,
      "learning_rate": 0.00014874603023033926,
      "loss": 3.0203,
      "step": 24940
    },
    {
      "epoch": 1.073857278126883,
      "grad_norm": 0.9334518909454346,
      "learning_rate": 0.0001487054530659425,
      "loss": 2.9986,
      "step": 24950
    },
    {
      "epoch": 1.073857278126883,
      "eval_bleu": 26.961788758908682,
      "eval_gen_len": 27.439,
      "eval_loss": 2.8108303546905518,
      "eval_runtime": 57.9633,
      "eval_samples_per_second": 17.252,
      "eval_steps_per_second": 1.087,
      "step": 24950
    },
    {
      "epoch": 1.074287681845571,
      "grad_norm": 0.9115158915519714,
      "learning_rate": 0.00014866486538542766,
      "loss": 3.1434,
      "step": 24960
    },
    {
      "epoch": 1.0747180855642593,
      "grad_norm": 0.9009280800819397,
      "learning_rate": 0.00014862426719755817,
      "loss": 3.0203,
      "step": 24970
    },
    {
      "epoch": 1.0751484892829475,
      "grad_norm": 0.8359889984130859,
      "learning_rate": 0.00014858365851109966,
      "loss": 3.0754,
      "step": 24980
    },
    {
      "epoch": 1.0755788930016354,
      "grad_norm": 1.1484005451202393,
      "learning_rate": 0.00014854303933482007,
      "loss": 2.9908,
      "step": 24990
    },
    {
      "epoch": 1.0760092967203236,
      "grad_norm": 0.8966162204742432,
      "learning_rate": 0.00014850240967748956,
      "loss": 3.02,
      "step": 25000
    },
    {
      "epoch": 1.0760092967203236,
      "eval_bleu": 26.572690439536643,
      "eval_gen_len": 27.461,
      "eval_loss": 2.80850887298584,
      "eval_runtime": 58.4413,
      "eval_samples_per_second": 17.111,
      "eval_steps_per_second": 1.078,
      "step": 25000
    },
    {
      "epoch": 1.0764397004390118,
      "grad_norm": 0.9978868365287781,
      "learning_rate": 0.0001484617695478806,
      "loss": 2.9745,
      "step": 25010
    },
    {
      "epoch": 1.0768701041577,
      "grad_norm": 0.8546624779701233,
      "learning_rate": 0.0001484211189547679,
      "loss": 2.986,
      "step": 25020
    },
    {
      "epoch": 1.077300507876388,
      "grad_norm": 0.8881964087486267,
      "learning_rate": 0.00014838045790692842,
      "loss": 3.0622,
      "step": 25030
    },
    {
      "epoch": 1.0777309115950762,
      "grad_norm": 0.803087055683136,
      "learning_rate": 0.00014833978641314144,
      "loss": 3.0816,
      "step": 25040
    },
    {
      "epoch": 1.0781613153137644,
      "grad_norm": 0.900993287563324,
      "learning_rate": 0.00014829910448218837,
      "loss": 3.0575,
      "step": 25050
    },
    {
      "epoch": 1.0781613153137644,
      "eval_bleu": 26.8568924949791,
      "eval_gen_len": 27.548,
      "eval_loss": 2.809737205505371,
      "eval_runtime": 58.8299,
      "eval_samples_per_second": 16.998,
      "eval_steps_per_second": 1.071,
      "step": 25050
    },
    {
      "epoch": 1.0785917190324525,
      "grad_norm": 0.9641463160514832,
      "learning_rate": 0.00014825841212285306,
      "loss": 2.8782,
      "step": 25060
    },
    {
      "epoch": 1.0790221227511405,
      "grad_norm": 0.8725694417953491,
      "learning_rate": 0.00014821770934392135,
      "loss": 2.9627,
      "step": 25070
    },
    {
      "epoch": 1.0794525264698287,
      "grad_norm": 0.9483562111854553,
      "learning_rate": 0.0001481769961541816,
      "loss": 3.0818,
      "step": 25080
    },
    {
      "epoch": 1.0798829301885169,
      "grad_norm": 0.9471169114112854,
      "learning_rate": 0.00014813627256242426,
      "loss": 3.0633,
      "step": 25090
    },
    {
      "epoch": 1.0803133339072049,
      "grad_norm": 0.9229062795639038,
      "learning_rate": 0.00014809553857744208,
      "loss": 3.0802,
      "step": 25100
    },
    {
      "epoch": 1.0803133339072049,
      "eval_bleu": 26.919923576404816,
      "eval_gen_len": 27.509,
      "eval_loss": 2.810789108276367,
      "eval_runtime": 58.6074,
      "eval_samples_per_second": 17.063,
      "eval_steps_per_second": 1.075,
      "step": 25100
    },
    {
      "epoch": 1.080743737625893,
      "grad_norm": 0.9859967231750488,
      "learning_rate": 0.00014805479420803,
      "loss": 2.9742,
      "step": 25110
    },
    {
      "epoch": 1.0811741413445812,
      "grad_norm": 0.9020294547080994,
      "learning_rate": 0.00014801403946298523,
      "loss": 3.057,
      "step": 25120
    },
    {
      "epoch": 1.0816045450632694,
      "grad_norm": 0.9479894042015076,
      "learning_rate": 0.00014797327435110732,
      "loss": 2.9553,
      "step": 25130
    },
    {
      "epoch": 1.0820349487819574,
      "grad_norm": 0.921301007270813,
      "learning_rate": 0.0001479324988811979,
      "loss": 3.0386,
      "step": 25140
    },
    {
      "epoch": 1.0824653525006456,
      "grad_norm": 0.8247307538986206,
      "learning_rate": 0.0001478917130620609,
      "loss": 3.011,
      "step": 25150
    },
    {
      "epoch": 1.0824653525006456,
      "eval_bleu": 26.69486533898578,
      "eval_gen_len": 27.48,
      "eval_loss": 2.809868812561035,
      "eval_runtime": 58.2,
      "eval_samples_per_second": 17.182,
      "eval_steps_per_second": 1.082,
      "step": 25150
    },
    {
      "epoch": 1.0828957562193338,
      "grad_norm": 0.8899262547492981,
      "learning_rate": 0.0001478509169025025,
      "loss": 2.9495,
      "step": 25160
    },
    {
      "epoch": 1.083326159938022,
      "grad_norm": 0.9211719036102295,
      "learning_rate": 0.00014781011041133113,
      "loss": 3.0635,
      "step": 25170
    },
    {
      "epoch": 1.08375656365671,
      "grad_norm": 0.9483282566070557,
      "learning_rate": 0.0001477692935973574,
      "loss": 3.0275,
      "step": 25180
    },
    {
      "epoch": 1.084186967375398,
      "grad_norm": 0.8975272178649902,
      "learning_rate": 0.0001477284664693942,
      "loss": 3.0406,
      "step": 25190
    },
    {
      "epoch": 1.0846173710940863,
      "grad_norm": 0.8945572972297668,
      "learning_rate": 0.00014768762903625654,
      "loss": 3.0597,
      "step": 25200
    },
    {
      "epoch": 1.0846173710940863,
      "eval_bleu": 27.00839086800255,
      "eval_gen_len": 27.403,
      "eval_loss": 2.8060996532440186,
      "eval_runtime": 58.2545,
      "eval_samples_per_second": 17.166,
      "eval_steps_per_second": 1.081,
      "step": 25200
    },
    {
      "epoch": 1.0850477748127745,
      "grad_norm": 0.9412238001823425,
      "learning_rate": 0.00014764678130676178,
      "loss": 3.0701,
      "step": 25210
    },
    {
      "epoch": 1.0854781785314624,
      "grad_norm": 0.8811342716217041,
      "learning_rate": 0.0001476059232897295,
      "loss": 2.8933,
      "step": 25220
    },
    {
      "epoch": 1.0859085822501506,
      "grad_norm": 0.8635034561157227,
      "learning_rate": 0.0001475650549939814,
      "loss": 2.9607,
      "step": 25230
    },
    {
      "epoch": 1.0863389859688388,
      "grad_norm": 0.8618882298469543,
      "learning_rate": 0.0001475241764283415,
      "loss": 3.0007,
      "step": 25240
    },
    {
      "epoch": 1.086769389687527,
      "grad_norm": 0.9004302024841309,
      "learning_rate": 0.00014748328760163596,
      "loss": 3.0221,
      "step": 25250
    },
    {
      "epoch": 1.086769389687527,
      "eval_bleu": 27.166933351724627,
      "eval_gen_len": 27.512,
      "eval_loss": 2.8026020526885986,
      "eval_runtime": 58.441,
      "eval_samples_per_second": 17.111,
      "eval_steps_per_second": 1.078,
      "step": 25250
    },
    {
      "epoch": 1.087199793406215,
      "grad_norm": 1.009055256843567,
      "learning_rate": 0.00014744238852269323,
      "loss": 2.9657,
      "step": 25260
    },
    {
      "epoch": 1.0876301971249032,
      "grad_norm": 0.8018627166748047,
      "learning_rate": 0.0001474014792003439,
      "loss": 2.9309,
      "step": 25270
    },
    {
      "epoch": 1.0880606008435914,
      "grad_norm": 1.0117908716201782,
      "learning_rate": 0.0001473605596434208,
      "loss": 3.0329,
      "step": 25280
    },
    {
      "epoch": 1.0884910045622793,
      "grad_norm": 0.8119659423828125,
      "learning_rate": 0.000147319629860759,
      "loss": 2.8827,
      "step": 25290
    },
    {
      "epoch": 1.0889214082809675,
      "grad_norm": 0.8081923127174377,
      "learning_rate": 0.00014727868986119574,
      "loss": 2.9859,
      "step": 25300
    },
    {
      "epoch": 1.0889214082809675,
      "eval_bleu": 26.942581286751103,
      "eval_gen_len": 27.402,
      "eval_loss": 2.8014705181121826,
      "eval_runtime": 58.6275,
      "eval_samples_per_second": 17.057,
      "eval_steps_per_second": 1.075,
      "step": 25300
    },
    {
      "epoch": 1.0893518119996557,
      "grad_norm": 0.830369234085083,
      "learning_rate": 0.00014723773965357047,
      "loss": 2.9903,
      "step": 25310
    },
    {
      "epoch": 1.0897822157183439,
      "grad_norm": 0.849520742893219,
      "learning_rate": 0.00014719677924672486,
      "loss": 3.0229,
      "step": 25320
    },
    {
      "epoch": 1.0902126194370318,
      "grad_norm": 0.9091050624847412,
      "learning_rate": 0.0001471558086495028,
      "loss": 3.023,
      "step": 25330
    },
    {
      "epoch": 1.09064302315572,
      "grad_norm": 0.8575016260147095,
      "learning_rate": 0.00014711482787075036,
      "loss": 2.9364,
      "step": 25340
    },
    {
      "epoch": 1.0910734268744082,
      "grad_norm": 0.9475963711738586,
      "learning_rate": 0.00014707383691931576,
      "loss": 3.0217,
      "step": 25350
    },
    {
      "epoch": 1.0910734268744082,
      "eval_bleu": 26.977426615566948,
      "eval_gen_len": 27.488,
      "eval_loss": 2.805283308029175,
      "eval_runtime": 58.7622,
      "eval_samples_per_second": 17.018,
      "eval_steps_per_second": 1.072,
      "step": 25350
    },
    {
      "epoch": 1.0915038305930964,
      "grad_norm": 1.0858465433120728,
      "learning_rate": 0.00014703283580404946,
      "loss": 3.0644,
      "step": 25360
    },
    {
      "epoch": 1.0919342343117844,
      "grad_norm": 0.9492331743240356,
      "learning_rate": 0.00014699182453380418,
      "loss": 3.0548,
      "step": 25370
    },
    {
      "epoch": 1.0923646380304726,
      "grad_norm": 0.8623969554901123,
      "learning_rate": 0.00014695080311743466,
      "loss": 3.029,
      "step": 25380
    },
    {
      "epoch": 1.0927950417491608,
      "grad_norm": 0.9176276326179504,
      "learning_rate": 0.00014690977156379807,
      "loss": 3.0738,
      "step": 25390
    },
    {
      "epoch": 1.093225445467849,
      "grad_norm": 0.9409194588661194,
      "learning_rate": 0.00014686872988175354,
      "loss": 3.0301,
      "step": 25400
    },
    {
      "epoch": 1.093225445467849,
      "eval_bleu": 27.488822965602424,
      "eval_gen_len": 27.488,
      "eval_loss": 2.803676128387451,
      "eval_runtime": 58.7664,
      "eval_samples_per_second": 17.017,
      "eval_steps_per_second": 1.072,
      "step": 25400
    },
    {
      "epoch": 1.093655849186537,
      "grad_norm": 0.8001681566238403,
      "learning_rate": 0.0001468276780801625,
      "loss": 2.9316,
      "step": 25410
    },
    {
      "epoch": 1.094086252905225,
      "grad_norm": 0.9576607346534729,
      "learning_rate": 0.0001467866161678886,
      "loss": 2.961,
      "step": 25420
    },
    {
      "epoch": 1.0945166566239133,
      "grad_norm": 0.8805145025253296,
      "learning_rate": 0.00014674554415379756,
      "loss": 2.9219,
      "step": 25430
    },
    {
      "epoch": 1.0949470603426015,
      "grad_norm": 0.9954363703727722,
      "learning_rate": 0.00014670446204675735,
      "loss": 3.0612,
      "step": 25440
    },
    {
      "epoch": 1.0953774640612894,
      "grad_norm": 0.8486347794532776,
      "learning_rate": 0.00014666336985563814,
      "loss": 3.0643,
      "step": 25450
    },
    {
      "epoch": 1.0953774640612894,
      "eval_bleu": 27.020980240572857,
      "eval_gen_len": 27.481,
      "eval_loss": 2.8061296939849854,
      "eval_runtime": 58.9777,
      "eval_samples_per_second": 16.956,
      "eval_steps_per_second": 1.068,
      "step": 25450
    },
    {
      "epoch": 1.0958078677799776,
      "grad_norm": 0.8403779864311218,
      "learning_rate": 0.00014662226758931226,
      "loss": 3.0323,
      "step": 25460
    },
    {
      "epoch": 1.0962382714986658,
      "grad_norm": 0.8406552076339722,
      "learning_rate": 0.00014658115525665417,
      "loss": 2.9471,
      "step": 25470
    },
    {
      "epoch": 1.0966686752173538,
      "grad_norm": 1.01978600025177,
      "learning_rate": 0.00014654003286654053,
      "loss": 3.0164,
      "step": 25480
    },
    {
      "epoch": 1.097099078936042,
      "grad_norm": 0.9358261227607727,
      "learning_rate": 0.0001464989004278502,
      "loss": 3.0737,
      "step": 25490
    },
    {
      "epoch": 1.0975294826547302,
      "grad_norm": 0.9477863907814026,
      "learning_rate": 0.0001464577579494642,
      "loss": 3.0345,
      "step": 25500
    },
    {
      "epoch": 1.0975294826547302,
      "eval_bleu": 27.281037491221053,
      "eval_gen_len": 27.444,
      "eval_loss": 2.80375075340271,
      "eval_runtime": 58.3673,
      "eval_samples_per_second": 17.133,
      "eval_steps_per_second": 1.079,
      "step": 25500
    },
    {
      "epoch": 1.0979598863734183,
      "grad_norm": 0.8855701684951782,
      "learning_rate": 0.00014641660544026573,
      "loss": 3.0243,
      "step": 25510
    },
    {
      "epoch": 1.0983902900921063,
      "grad_norm": 0.8454798460006714,
      "learning_rate": 0.00014637544290914005,
      "loss": 3.0105,
      "step": 25520
    },
    {
      "epoch": 1.0988206938107945,
      "grad_norm": 0.9563127756118774,
      "learning_rate": 0.00014633427036497474,
      "loss": 3.0296,
      "step": 25530
    },
    {
      "epoch": 1.0992510975294827,
      "grad_norm": 0.9071846604347229,
      "learning_rate": 0.0001462930878166594,
      "loss": 3.046,
      "step": 25540
    },
    {
      "epoch": 1.0996815012481709,
      "grad_norm": 0.8813143968582153,
      "learning_rate": 0.000146251895273086,
      "loss": 3.1235,
      "step": 25550
    },
    {
      "epoch": 1.0996815012481709,
      "eval_bleu": 27.071109544067117,
      "eval_gen_len": 27.442,
      "eval_loss": 2.807965040206909,
      "eval_runtime": 58.5538,
      "eval_samples_per_second": 17.078,
      "eval_steps_per_second": 1.076,
      "step": 25550
    },
    {
      "epoch": 1.1001119049668588,
      "grad_norm": 1.0039145946502686,
      "learning_rate": 0.00014621069274314835,
      "loss": 3.0496,
      "step": 25560
    },
    {
      "epoch": 1.100542308685547,
      "grad_norm": 0.8909034132957458,
      "learning_rate": 0.0001461694802357427,
      "loss": 3.0499,
      "step": 25570
    },
    {
      "epoch": 1.1009727124042352,
      "grad_norm": 0.8361367583274841,
      "learning_rate": 0.00014612825775976731,
      "loss": 2.9651,
      "step": 25580
    },
    {
      "epoch": 1.1014031161229232,
      "grad_norm": 0.9315258264541626,
      "learning_rate": 0.00014608702532412267,
      "loss": 3.0005,
      "step": 25590
    },
    {
      "epoch": 1.1018335198416114,
      "grad_norm": 0.9504165649414062,
      "learning_rate": 0.00014604578293771133,
      "loss": 3.0313,
      "step": 25600
    },
    {
      "epoch": 1.1018335198416114,
      "eval_bleu": 27.030657348866022,
      "eval_gen_len": 27.323,
      "eval_loss": 2.8067197799682617,
      "eval_runtime": 57.6567,
      "eval_samples_per_second": 17.344,
      "eval_steps_per_second": 1.093,
      "step": 25600
    },
    {
      "epoch": 1.1022639235602996,
      "grad_norm": 0.9119063019752502,
      "learning_rate": 0.000146004530609438,
      "loss": 3.0521,
      "step": 25610
    },
    {
      "epoch": 1.1026943272789878,
      "grad_norm": 0.8632280826568604,
      "learning_rate": 0.0001459632683482097,
      "loss": 3.1406,
      "step": 25620
    },
    {
      "epoch": 1.1031247309976757,
      "grad_norm": 0.970810055732727,
      "learning_rate": 0.0001459219961629354,
      "loss": 2.9684,
      "step": 25630
    },
    {
      "epoch": 1.103555134716364,
      "grad_norm": 0.8260698318481445,
      "learning_rate": 0.0001458807140625263,
      "loss": 2.9936,
      "step": 25640
    },
    {
      "epoch": 1.103985538435052,
      "grad_norm": 0.9464333653450012,
      "learning_rate": 0.00014583942205589567,
      "loss": 3.0844,
      "step": 25650
    },
    {
      "epoch": 1.103985538435052,
      "eval_bleu": 26.82737930337696,
      "eval_gen_len": 27.379,
      "eval_loss": 2.8042757511138916,
      "eval_runtime": 57.9587,
      "eval_samples_per_second": 17.254,
      "eval_steps_per_second": 1.087,
      "step": 25650
    },
    {
      "epoch": 1.1044159421537403,
      "grad_norm": 0.9074807167053223,
      "learning_rate": 0.000145798120151959,
      "loss": 3.0546,
      "step": 25660
    },
    {
      "epoch": 1.1048463458724282,
      "grad_norm": 0.8411916494369507,
      "learning_rate": 0.00014575680835963393,
      "loss": 3.0623,
      "step": 25670
    },
    {
      "epoch": 1.1052767495911164,
      "grad_norm": 0.8028072714805603,
      "learning_rate": 0.00014571548668784013,
      "loss": 2.9652,
      "step": 25680
    },
    {
      "epoch": 1.1057071533098046,
      "grad_norm": 0.9540218114852905,
      "learning_rate": 0.00014567415514549952,
      "loss": 3.0764,
      "step": 25690
    },
    {
      "epoch": 1.1061375570284928,
      "grad_norm": 0.9437403678894043,
      "learning_rate": 0.00014563281374153607,
      "loss": 3.0452,
      "step": 25700
    },
    {
      "epoch": 1.1061375570284928,
      "eval_bleu": 27.03418867720917,
      "eval_gen_len": 27.36,
      "eval_loss": 2.8018999099731445,
      "eval_runtime": 58.1835,
      "eval_samples_per_second": 17.187,
      "eval_steps_per_second": 1.083,
      "step": 25700
    },
    {
      "epoch": 1.1065679607471808,
      "grad_norm": 0.9523783922195435,
      "learning_rate": 0.00014559146248487595,
      "loss": 2.9527,
      "step": 25710
    },
    {
      "epoch": 1.106998364465869,
      "grad_norm": 0.9435705542564392,
      "learning_rate": 0.00014555010138444735,
      "loss": 3.047,
      "step": 25720
    },
    {
      "epoch": 1.1074287681845572,
      "grad_norm": 0.884973406791687,
      "learning_rate": 0.00014550873044918066,
      "loss": 3.0468,
      "step": 25730
    },
    {
      "epoch": 1.1078591719032453,
      "grad_norm": 0.9184661507606506,
      "learning_rate": 0.00014546734968800846,
      "loss": 2.9365,
      "step": 25740
    },
    {
      "epoch": 1.1082895756219333,
      "grad_norm": 0.8976736068725586,
      "learning_rate": 0.00014542595910986528,
      "loss": 2.9783,
      "step": 25750
    },
    {
      "epoch": 1.1082895756219333,
      "eval_bleu": 26.935695617787378,
      "eval_gen_len": 27.373,
      "eval_loss": 2.804561138153076,
      "eval_runtime": 58.8766,
      "eval_samples_per_second": 16.985,
      "eval_steps_per_second": 1.07,
      "step": 25750
    },
    {
      "epoch": 1.1087199793406215,
      "grad_norm": 0.9674123525619507,
      "learning_rate": 0.0001453845587236879,
      "loss": 2.9939,
      "step": 25760
    },
    {
      "epoch": 1.1091503830593097,
      "grad_norm": 0.8491121530532837,
      "learning_rate": 0.00014534314853841522,
      "loss": 3.0177,
      "step": 25770
    },
    {
      "epoch": 1.1095807867779977,
      "grad_norm": 0.9642374515533447,
      "learning_rate": 0.00014530172856298815,
      "loss": 3.0636,
      "step": 25780
    },
    {
      "epoch": 1.1100111904966858,
      "grad_norm": 0.859569251537323,
      "learning_rate": 0.00014526029880634984,
      "loss": 3.1275,
      "step": 25790
    },
    {
      "epoch": 1.110441594215374,
      "grad_norm": 0.8329877257347107,
      "learning_rate": 0.00014521885927744547,
      "loss": 3.0849,
      "step": 25800
    },
    {
      "epoch": 1.110441594215374,
      "eval_bleu": 26.59198551395597,
      "eval_gen_len": 27.468,
      "eval_loss": 2.80761456489563,
      "eval_runtime": 58.6507,
      "eval_samples_per_second": 17.05,
      "eval_steps_per_second": 1.074,
      "step": 25800
    },
    {
      "epoch": 1.1108719979340622,
      "grad_norm": 0.9533448815345764,
      "learning_rate": 0.00014517740998522234,
      "loss": 3.0579,
      "step": 25810
    },
    {
      "epoch": 1.1113024016527502,
      "grad_norm": 0.9112969636917114,
      "learning_rate": 0.0001451359509386299,
      "loss": 2.9545,
      "step": 25820
    },
    {
      "epoch": 1.1117328053714384,
      "grad_norm": 1.0139261484146118,
      "learning_rate": 0.00014509448214661966,
      "loss": 3.0326,
      "step": 25830
    },
    {
      "epoch": 1.1121632090901266,
      "grad_norm": 0.8570111393928528,
      "learning_rate": 0.00014505300361814528,
      "loss": 2.9094,
      "step": 25840
    },
    {
      "epoch": 1.1125936128088147,
      "grad_norm": 0.9164050221443176,
      "learning_rate": 0.0001450115153621624,
      "loss": 3.0768,
      "step": 25850
    },
    {
      "epoch": 1.1125936128088147,
      "eval_bleu": 27.02437247312463,
      "eval_gen_len": 27.414,
      "eval_loss": 2.801610231399536,
      "eval_runtime": 58.9841,
      "eval_samples_per_second": 16.954,
      "eval_steps_per_second": 1.068,
      "step": 25850
    },
    {
      "epoch": 1.1130240165275027,
      "grad_norm": 0.934451699256897,
      "learning_rate": 0.00014497001738762898,
      "loss": 2.9389,
      "step": 25860
    },
    {
      "epoch": 1.113454420246191,
      "grad_norm": 0.9751725792884827,
      "learning_rate": 0.0001449285097035049,
      "loss": 3.0368,
      "step": 25870
    },
    {
      "epoch": 1.113884823964879,
      "grad_norm": 0.850376546382904,
      "learning_rate": 0.0001448869923187522,
      "loss": 2.9741,
      "step": 25880
    },
    {
      "epoch": 1.1143152276835673,
      "grad_norm": 0.8666056990623474,
      "learning_rate": 0.00014484546524233497,
      "loss": 3.1095,
      "step": 25890
    },
    {
      "epoch": 1.1147456314022552,
      "grad_norm": 0.9893869757652283,
      "learning_rate": 0.00014480392848321947,
      "loss": 2.9729,
      "step": 25900
    },
    {
      "epoch": 1.1147456314022552,
      "eval_bleu": 26.81031906193268,
      "eval_gen_len": 27.458,
      "eval_loss": 2.8034138679504395,
      "eval_runtime": 58.6937,
      "eval_samples_per_second": 17.038,
      "eval_steps_per_second": 1.073,
      "step": 25900
    },
    {
      "epoch": 1.1151760351209434,
      "grad_norm": 0.8517439961433411,
      "learning_rate": 0.00014476238205037397,
      "loss": 3.0465,
      "step": 25910
    },
    {
      "epoch": 1.1156064388396316,
      "grad_norm": 0.9380923509597778,
      "learning_rate": 0.0001447208259527689,
      "loss": 3.0976,
      "step": 25920
    },
    {
      "epoch": 1.1160368425583198,
      "grad_norm": 1.0122700929641724,
      "learning_rate": 0.0001446792601993767,
      "loss": 3.077,
      "step": 25930
    },
    {
      "epoch": 1.1164672462770078,
      "grad_norm": 0.8710286617279053,
      "learning_rate": 0.000144637684799172,
      "loss": 3.0398,
      "step": 25940
    },
    {
      "epoch": 1.116897649995696,
      "grad_norm": 0.8913876414299011,
      "learning_rate": 0.00014459609976113139,
      "loss": 3.1005,
      "step": 25950
    },
    {
      "epoch": 1.116897649995696,
      "eval_bleu": 26.976236891934093,
      "eval_gen_len": 27.508,
      "eval_loss": 2.8031115531921387,
      "eval_runtime": 58.6923,
      "eval_samples_per_second": 17.038,
      "eval_steps_per_second": 1.073,
      "step": 25950
    },
    {
      "epoch": 1.1173280537143842,
      "grad_norm": 0.8979902863502502,
      "learning_rate": 0.00014455450509423358,
      "loss": 3.0605,
      "step": 25960
    },
    {
      "epoch": 1.1177584574330721,
      "grad_norm": 0.797199547290802,
      "learning_rate": 0.00014451290080745948,
      "loss": 2.9853,
      "step": 25970
    },
    {
      "epoch": 1.1181888611517603,
      "grad_norm": 0.9020522236824036,
      "learning_rate": 0.0001444712869097919,
      "loss": 3.0047,
      "step": 25980
    },
    {
      "epoch": 1.1186192648704485,
      "grad_norm": 1.0049749612808228,
      "learning_rate": 0.00014442966341021585,
      "loss": 3.1318,
      "step": 25990
    },
    {
      "epoch": 1.1190496685891367,
      "grad_norm": 0.8563540577888489,
      "learning_rate": 0.0001443880303177183,
      "loss": 3.0252,
      "step": 26000
    },
    {
      "epoch": 1.1190496685891367,
      "eval_bleu": 26.912197542699854,
      "eval_gen_len": 27.352,
      "eval_loss": 2.806090831756592,
      "eval_runtime": 58.7531,
      "eval_samples_per_second": 17.02,
      "eval_steps_per_second": 1.072,
      "step": 26000
    },
    {
      "epoch": 1.1194800723078246,
      "grad_norm": 1.1621696949005127,
      "learning_rate": 0.00014434638764128843,
      "loss": 3.1117,
      "step": 26010
    },
    {
      "epoch": 1.1199104760265128,
      "grad_norm": 0.9484320878982544,
      "learning_rate": 0.00014430473538991736,
      "loss": 2.9566,
      "step": 26020
    },
    {
      "epoch": 1.120340879745201,
      "grad_norm": 0.9906860589981079,
      "learning_rate": 0.00014426307357259837,
      "loss": 3.0565,
      "step": 26030
    },
    {
      "epoch": 1.1207712834638892,
      "grad_norm": 0.8269852995872498,
      "learning_rate": 0.00014422140219832674,
      "loss": 2.9651,
      "step": 26040
    },
    {
      "epoch": 1.1212016871825772,
      "grad_norm": 0.989526093006134,
      "learning_rate": 0.00014417972127609983,
      "loss": 2.987,
      "step": 26050
    },
    {
      "epoch": 1.1212016871825772,
      "eval_bleu": 27.182414941947535,
      "eval_gen_len": 27.425,
      "eval_loss": 2.8052215576171875,
      "eval_runtime": 59.2169,
      "eval_samples_per_second": 16.887,
      "eval_steps_per_second": 1.064,
      "step": 26050
    },
    {
      "epoch": 1.1216320909012654,
      "grad_norm": 0.9168775081634521,
      "learning_rate": 0.00014413803081491714,
      "loss": 3.0851,
      "step": 26060
    },
    {
      "epoch": 1.1220624946199536,
      "grad_norm": 1.044209599494934,
      "learning_rate": 0.00014409633082378015,
      "loss": 2.9378,
      "step": 26070
    },
    {
      "epoch": 1.1224928983386417,
      "grad_norm": 0.9345852732658386,
      "learning_rate": 0.00014405462131169235,
      "loss": 3.0518,
      "step": 26080
    },
    {
      "epoch": 1.1229233020573297,
      "grad_norm": 0.7895018458366394,
      "learning_rate": 0.00014401290228765939,
      "loss": 3.0368,
      "step": 26090
    },
    {
      "epoch": 1.123353705776018,
      "grad_norm": 0.8720537424087524,
      "learning_rate": 0.0001439711737606889,
      "loss": 3.0798,
      "step": 26100
    },
    {
      "epoch": 1.123353705776018,
      "eval_bleu": 27.08716712235954,
      "eval_gen_len": 27.554,
      "eval_loss": 2.804694414138794,
      "eval_runtime": 59.0536,
      "eval_samples_per_second": 16.934,
      "eval_steps_per_second": 1.067,
      "step": 26100
    },
    {
      "epoch": 1.123784109494706,
      "grad_norm": 0.7323521375656128,
      "learning_rate": 0.00014392943573979063,
      "loss": 2.9702,
      "step": 26110
    },
    {
      "epoch": 1.1242145132133943,
      "grad_norm": 1.0573298931121826,
      "learning_rate": 0.0001438876882339763,
      "loss": 3.0323,
      "step": 26120
    },
    {
      "epoch": 1.1246449169320822,
      "grad_norm": 0.8135226368904114,
      "learning_rate": 0.00014384593125225977,
      "loss": 3.1339,
      "step": 26130
    },
    {
      "epoch": 1.1250753206507704,
      "grad_norm": 0.916756808757782,
      "learning_rate": 0.00014380416480365687,
      "loss": 2.9665,
      "step": 26140
    },
    {
      "epoch": 1.1255057243694586,
      "grad_norm": 0.9534763693809509,
      "learning_rate": 0.0001437623888971855,
      "loss": 2.993,
      "step": 26150
    },
    {
      "epoch": 1.1255057243694586,
      "eval_bleu": 26.79089649988137,
      "eval_gen_len": 27.361,
      "eval_loss": 2.804425001144409,
      "eval_runtime": 59.0137,
      "eval_samples_per_second": 16.945,
      "eval_steps_per_second": 1.068,
      "step": 26150
    },
    {
      "epoch": 1.1259361280881466,
      "grad_norm": 0.9118690490722656,
      "learning_rate": 0.00014372060354186564,
      "loss": 2.9273,
      "step": 26160
    },
    {
      "epoch": 1.1263665318068348,
      "grad_norm": 0.955810010433197,
      "learning_rate": 0.00014367880874671917,
      "loss": 3.0425,
      "step": 26170
    },
    {
      "epoch": 1.126796935525523,
      "grad_norm": 0.9255896806716919,
      "learning_rate": 0.0001436370045207702,
      "loss": 3.0643,
      "step": 26180
    },
    {
      "epoch": 1.1272273392442111,
      "grad_norm": 0.9680836200714111,
      "learning_rate": 0.00014359519087304477,
      "loss": 3.0418,
      "step": 26190
    },
    {
      "epoch": 1.1276577429628991,
      "grad_norm": 0.9310771226882935,
      "learning_rate": 0.000143553367812571,
      "loss": 3.0009,
      "step": 26200
    },
    {
      "epoch": 1.1276577429628991,
      "eval_bleu": 27.109269201644217,
      "eval_gen_len": 27.492,
      "eval_loss": 2.8022117614746094,
      "eval_runtime": 59.2776,
      "eval_samples_per_second": 16.87,
      "eval_steps_per_second": 1.063,
      "step": 26200
    },
    {
      "epoch": 1.1280881466815873,
      "grad_norm": 0.8661640286445618,
      "learning_rate": 0.0001435115353483789,
      "loss": 2.9902,
      "step": 26210
    },
    {
      "epoch": 1.1285185504002755,
      "grad_norm": 0.8352171182632446,
      "learning_rate": 0.00014346969348950073,
      "loss": 3.0408,
      "step": 26220
    },
    {
      "epoch": 1.1289489541189637,
      "grad_norm": 0.9072070717811584,
      "learning_rate": 0.0001434278422449707,
      "loss": 3.0543,
      "step": 26230
    },
    {
      "epoch": 1.1293793578376516,
      "grad_norm": 0.9001736640930176,
      "learning_rate": 0.0001433859816238249,
      "loss": 2.931,
      "step": 26240
    },
    {
      "epoch": 1.1298097615563398,
      "grad_norm": 0.7982718348503113,
      "learning_rate": 0.00014334411163510164,
      "loss": 2.9577,
      "step": 26250
    },
    {
      "epoch": 1.1298097615563398,
      "eval_bleu": 27.304338081901445,
      "eval_gen_len": 27.446,
      "eval_loss": 2.7994234561920166,
      "eval_runtime": 58.7956,
      "eval_samples_per_second": 17.008,
      "eval_steps_per_second": 1.072,
      "step": 26250
    },
    {
      "epoch": 1.130240165275028,
      "grad_norm": 0.8760781288146973,
      "learning_rate": 0.00014330223228784116,
      "loss": 3.0077,
      "step": 26260
    },
    {
      "epoch": 1.130670568993716,
      "grad_norm": 0.9296665787696838,
      "learning_rate": 0.00014326034359108574,
      "loss": 3.0295,
      "step": 26270
    },
    {
      "epoch": 1.1311009727124042,
      "grad_norm": 0.9556498527526855,
      "learning_rate": 0.00014321844555387968,
      "loss": 3.0038,
      "step": 26280
    },
    {
      "epoch": 1.1315313764310924,
      "grad_norm": 0.9638528227806091,
      "learning_rate": 0.00014317653818526926,
      "loss": 2.9755,
      "step": 26290
    },
    {
      "epoch": 1.1319617801497805,
      "grad_norm": 0.9916957020759583,
      "learning_rate": 0.00014313462149430283,
      "loss": 3.0115,
      "step": 26300
    },
    {
      "epoch": 1.1319617801497805,
      "eval_bleu": 26.983129360971365,
      "eval_gen_len": 27.493,
      "eval_loss": 2.803272008895874,
      "eval_runtime": 58.3513,
      "eval_samples_per_second": 17.138,
      "eval_steps_per_second": 1.08,
      "step": 26300
    },
    {
      "epoch": 1.1323921838684687,
      "grad_norm": 0.9032408595085144,
      "learning_rate": 0.00014309269549003074,
      "loss": 3.0036,
      "step": 26310
    },
    {
      "epoch": 1.1328225875871567,
      "grad_norm": 0.8956769704818726,
      "learning_rate": 0.00014305076018150534,
      "loss": 3.0904,
      "step": 26320
    },
    {
      "epoch": 1.133252991305845,
      "grad_norm": 0.8877392411231995,
      "learning_rate": 0.00014300881557778095,
      "loss": 3.1115,
      "step": 26330
    },
    {
      "epoch": 1.133683395024533,
      "grad_norm": 0.9053099751472473,
      "learning_rate": 0.000142966861687914,
      "loss": 2.9934,
      "step": 26340
    },
    {
      "epoch": 1.134113798743221,
      "grad_norm": 0.8515250086784363,
      "learning_rate": 0.00014292489852096277,
      "loss": 3.0492,
      "step": 26350
    },
    {
      "epoch": 1.134113798743221,
      "eval_bleu": 27.080894632665665,
      "eval_gen_len": 27.425,
      "eval_loss": 2.800757884979248,
      "eval_runtime": 58.7115,
      "eval_samples_per_second": 17.032,
      "eval_steps_per_second": 1.073,
      "step": 26350
    },
    {
      "epoch": 1.1345442024619092,
      "grad_norm": 1.033046841621399,
      "learning_rate": 0.00014288292608598773,
      "loss": 3.0183,
      "step": 26360
    },
    {
      "epoch": 1.1349746061805974,
      "grad_norm": 0.9624415040016174,
      "learning_rate": 0.00014284094439205117,
      "loss": 3.0944,
      "step": 26370
    },
    {
      "epoch": 1.1354050098992856,
      "grad_norm": 1.0205539464950562,
      "learning_rate": 0.00014279895344821756,
      "loss": 3.0427,
      "step": 26380
    },
    {
      "epoch": 1.1358354136179736,
      "grad_norm": 0.8954449892044067,
      "learning_rate": 0.00014275695326355318,
      "loss": 3.0946,
      "step": 26390
    },
    {
      "epoch": 1.1362658173366618,
      "grad_norm": 0.9413663148880005,
      "learning_rate": 0.00014271494384712643,
      "loss": 3.006,
      "step": 26400
    },
    {
      "epoch": 1.1362658173366618,
      "eval_bleu": 26.458114301940242,
      "eval_gen_len": 27.46,
      "eval_loss": 2.803236246109009,
      "eval_runtime": 58.3834,
      "eval_samples_per_second": 17.128,
      "eval_steps_per_second": 1.079,
      "step": 26400
    },
    {
      "epoch": 1.13669622105535,
      "grad_norm": 0.9747597575187683,
      "learning_rate": 0.00014267292520800772,
      "loss": 2.9936,
      "step": 26410
    },
    {
      "epoch": 1.1371266247740381,
      "grad_norm": 0.9482889771461487,
      "learning_rate": 0.00014263089735526934,
      "loss": 3.0059,
      "step": 26420
    },
    {
      "epoch": 1.137557028492726,
      "grad_norm": 0.8726398348808289,
      "learning_rate": 0.00014258886029798563,
      "loss": 3.0291,
      "step": 26430
    },
    {
      "epoch": 1.1379874322114143,
      "grad_norm": 0.9040411114692688,
      "learning_rate": 0.00014254681404523293,
      "loss": 2.9825,
      "step": 26440
    },
    {
      "epoch": 1.1384178359301025,
      "grad_norm": 0.9067627191543579,
      "learning_rate": 0.00014250475860608957,
      "loss": 3.0613,
      "step": 26450
    },
    {
      "epoch": 1.1384178359301025,
      "eval_bleu": 26.53412187120786,
      "eval_gen_len": 27.435,
      "eval_loss": 2.8070404529571533,
      "eval_runtime": 58.7903,
      "eval_samples_per_second": 17.01,
      "eval_steps_per_second": 1.072,
      "step": 26450
    },
    {
      "epoch": 1.1388482396487905,
      "grad_norm": 0.8699650764465332,
      "learning_rate": 0.00014246269398963582,
      "loss": 3.0509,
      "step": 26460
    },
    {
      "epoch": 1.1392786433674786,
      "grad_norm": 0.9076765179634094,
      "learning_rate": 0.000142420620204954,
      "loss": 3.0769,
      "step": 26470
    },
    {
      "epoch": 1.1397090470861668,
      "grad_norm": 1.0169579982757568,
      "learning_rate": 0.0001423785372611283,
      "loss": 3.0942,
      "step": 26480
    },
    {
      "epoch": 1.140139450804855,
      "grad_norm": 0.9356956481933594,
      "learning_rate": 0.000142336445167245,
      "loss": 2.9875,
      "step": 26490
    },
    {
      "epoch": 1.1405698545235432,
      "grad_norm": 1.0738575458526611,
      "learning_rate": 0.00014229434393239236,
      "loss": 3.0481,
      "step": 26500
    },
    {
      "epoch": 1.1405698545235432,
      "eval_bleu": 26.57679521202048,
      "eval_gen_len": 27.449,
      "eval_loss": 2.8029427528381348,
      "eval_runtime": 58.5995,
      "eval_samples_per_second": 17.065,
      "eval_steps_per_second": 1.075,
      "step": 26500
    },
    {
      "epoch": 1.1410002582422312,
      "grad_norm": 0.9435524344444275,
      "learning_rate": 0.00014225223356566046,
      "loss": 3.0034,
      "step": 26510
    },
    {
      "epoch": 1.1414306619609194,
      "grad_norm": 0.8692683577537537,
      "learning_rate": 0.00014221011407614155,
      "loss": 3.1263,
      "step": 26520
    },
    {
      "epoch": 1.1418610656796075,
      "grad_norm": 0.8753546476364136,
      "learning_rate": 0.00014216798547292967,
      "loss": 3.1018,
      "step": 26530
    },
    {
      "epoch": 1.1422914693982955,
      "grad_norm": 0.9437097311019897,
      "learning_rate": 0.00014212584776512096,
      "loss": 3.1101,
      "step": 26540
    },
    {
      "epoch": 1.1427218731169837,
      "grad_norm": 0.9516935348510742,
      "learning_rate": 0.00014208370096181348,
      "loss": 3.019,
      "step": 26550
    },
    {
      "epoch": 1.1427218731169837,
      "eval_bleu": 26.823502854515006,
      "eval_gen_len": 27.437,
      "eval_loss": 2.802368640899658,
      "eval_runtime": 58.355,
      "eval_samples_per_second": 17.136,
      "eval_steps_per_second": 1.08,
      "step": 26550
    },
    {
      "epoch": 1.1431522768356719,
      "grad_norm": 0.967887282371521,
      "learning_rate": 0.00014204154507210727,
      "loss": 2.9611,
      "step": 26560
    },
    {
      "epoch": 1.14358268055436,
      "grad_norm": 0.8140769600868225,
      "learning_rate": 0.00014199938010510429,
      "loss": 3.1352,
      "step": 26570
    },
    {
      "epoch": 1.144013084273048,
      "grad_norm": 0.8676623702049255,
      "learning_rate": 0.00014195720606990846,
      "loss": 3.0309,
      "step": 26580
    },
    {
      "epoch": 1.1444434879917362,
      "grad_norm": 0.9770610928535461,
      "learning_rate": 0.00014191502297562574,
      "loss": 2.9551,
      "step": 26590
    },
    {
      "epoch": 1.1448738917104244,
      "grad_norm": 0.8769440054893494,
      "learning_rate": 0.00014187283083136397,
      "loss": 3.0048,
      "step": 26600
    },
    {
      "epoch": 1.1448738917104244,
      "eval_bleu": 26.8242487644659,
      "eval_gen_len": 27.403,
      "eval_loss": 2.805077075958252,
      "eval_runtime": 58.3612,
      "eval_samples_per_second": 17.135,
      "eval_steps_per_second": 1.079,
      "step": 26600
    },
    {
      "epoch": 1.1453042954291126,
      "grad_norm": 0.9446013569831848,
      "learning_rate": 0.00014183062964623293,
      "loss": 3.0117,
      "step": 26610
    },
    {
      "epoch": 1.1457346991478006,
      "grad_norm": 0.8929200172424316,
      "learning_rate": 0.0001417884194293444,
      "loss": 3.0039,
      "step": 26620
    },
    {
      "epoch": 1.1461651028664888,
      "grad_norm": 0.8664130568504333,
      "learning_rate": 0.00014174620018981212,
      "loss": 3.0023,
      "step": 26630
    },
    {
      "epoch": 1.146595506585177,
      "grad_norm": 0.9639654159545898,
      "learning_rate": 0.00014170397193675175,
      "loss": 3.038,
      "step": 26640
    },
    {
      "epoch": 1.147025910303865,
      "grad_norm": 1.044966220855713,
      "learning_rate": 0.00014166173467928088,
      "loss": 2.9178,
      "step": 26650
    },
    {
      "epoch": 1.147025910303865,
      "eval_bleu": 26.892370884642663,
      "eval_gen_len": 27.371,
      "eval_loss": 2.8056557178497314,
      "eval_runtime": 58.7469,
      "eval_samples_per_second": 17.022,
      "eval_steps_per_second": 1.072,
      "step": 26650
    },
    {
      "epoch": 1.147456314022553,
      "grad_norm": 0.9786038398742676,
      "learning_rate": 0.00014161948842651907,
      "loss": 3.1022,
      "step": 26660
    },
    {
      "epoch": 1.1478867177412413,
      "grad_norm": 0.9044528007507324,
      "learning_rate": 0.0001415772331875878,
      "loss": 3.0655,
      "step": 26670
    },
    {
      "epoch": 1.1483171214599295,
      "grad_norm": 0.9052013754844666,
      "learning_rate": 0.00014153496897161054,
      "loss": 3.1179,
      "step": 26680
    },
    {
      "epoch": 1.1487475251786177,
      "grad_norm": 0.92408686876297,
      "learning_rate": 0.00014149269578771264,
      "loss": 3.0229,
      "step": 26690
    },
    {
      "epoch": 1.1491779288973056,
      "grad_norm": 1.050222396850586,
      "learning_rate": 0.00014145041364502142,
      "loss": 3.0501,
      "step": 26700
    },
    {
      "epoch": 1.1491779288973056,
      "eval_bleu": 26.59625979389245,
      "eval_gen_len": 27.535,
      "eval_loss": 2.803203821182251,
      "eval_runtime": 58.3642,
      "eval_samples_per_second": 17.134,
      "eval_steps_per_second": 1.079,
      "step": 26700
    },
    {
      "epoch": 1.1496083326159938,
      "grad_norm": 0.7916387319564819,
      "learning_rate": 0.00014140812255266613,
      "loss": 2.9673,
      "step": 26710
    },
    {
      "epoch": 1.150038736334682,
      "grad_norm": 1.0037894248962402,
      "learning_rate": 0.00014136582251977794,
      "loss": 3.126,
      "step": 26720
    },
    {
      "epoch": 1.15046914005337,
      "grad_norm": 0.9425111413002014,
      "learning_rate": 0.00014132351355548997,
      "loss": 2.9552,
      "step": 26730
    },
    {
      "epoch": 1.1508995437720582,
      "grad_norm": 0.8827081322669983,
      "learning_rate": 0.00014128119566893718,
      "loss": 2.9387,
      "step": 26740
    },
    {
      "epoch": 1.1513299474907464,
      "grad_norm": 0.8695101141929626,
      "learning_rate": 0.00014123886886925665,
      "loss": 3.0159,
      "step": 26750
    },
    {
      "epoch": 1.1513299474907464,
      "eval_bleu": 26.721394827884062,
      "eval_gen_len": 27.508,
      "eval_loss": 2.802807092666626,
      "eval_runtime": 58.5403,
      "eval_samples_per_second": 17.082,
      "eval_steps_per_second": 1.076,
      "step": 26750
    },
    {
      "epoch": 1.1517603512094345,
      "grad_norm": 0.8719493746757507,
      "learning_rate": 0.0001411965331655872,
      "loss": 3.0957,
      "step": 26760
    },
    {
      "epoch": 1.1521907549281225,
      "grad_norm": 0.8875188231468201,
      "learning_rate": 0.00014115418856706964,
      "loss": 2.971,
      "step": 26770
    },
    {
      "epoch": 1.1526211586468107,
      "grad_norm": 0.8960638642311096,
      "learning_rate": 0.00014111183508284673,
      "loss": 3.0295,
      "step": 26780
    },
    {
      "epoch": 1.1530515623654989,
      "grad_norm": 1.0465598106384277,
      "learning_rate": 0.0001410694727220631,
      "loss": 3.0903,
      "step": 26790
    },
    {
      "epoch": 1.153481966084187,
      "grad_norm": 0.9374534487724304,
      "learning_rate": 0.0001410271014938653,
      "loss": 2.9127,
      "step": 26800
    },
    {
      "epoch": 1.153481966084187,
      "eval_bleu": 26.80532092608081,
      "eval_gen_len": 27.337,
      "eval_loss": 2.8020851612091064,
      "eval_runtime": 57.9484,
      "eval_samples_per_second": 17.257,
      "eval_steps_per_second": 1.087,
      "step": 26800
    },
    {
      "epoch": 1.153912369802875,
      "grad_norm": 0.8853946328163147,
      "learning_rate": 0.0001409847214074018,
      "loss": 3.116,
      "step": 26810
    },
    {
      "epoch": 1.1543427735215632,
      "grad_norm": 0.8791924715042114,
      "learning_rate": 0.00014094233247182307,
      "loss": 3.041,
      "step": 26820
    },
    {
      "epoch": 1.1547731772402514,
      "grad_norm": 0.8737019896507263,
      "learning_rate": 0.00014089993469628133,
      "loss": 3.0171,
      "step": 26830
    },
    {
      "epoch": 1.1552035809589394,
      "grad_norm": 0.9676870107650757,
      "learning_rate": 0.00014085752808993082,
      "loss": 3.1291,
      "step": 26840
    },
    {
      "epoch": 1.1556339846776276,
      "grad_norm": 0.9229918122291565,
      "learning_rate": 0.00014081511266192764,
      "loss": 2.9991,
      "step": 26850
    },
    {
      "epoch": 1.1556339846776276,
      "eval_bleu": 26.545934851939172,
      "eval_gen_len": 27.42,
      "eval_loss": 2.8014371395111084,
      "eval_runtime": 58.4756,
      "eval_samples_per_second": 17.101,
      "eval_steps_per_second": 1.077,
      "step": 26850
    },
    {
      "epoch": 1.1560643883963158,
      "grad_norm": 0.8844460844993591,
      "learning_rate": 0.00014077268842142986,
      "loss": 2.9656,
      "step": 26860
    },
    {
      "epoch": 1.156494792115004,
      "grad_norm": 1.0321810245513916,
      "learning_rate": 0.00014073025537759737,
      "loss": 2.9992,
      "step": 26870
    },
    {
      "epoch": 1.156925195833692,
      "grad_norm": 0.8331021070480347,
      "learning_rate": 0.00014068781353959197,
      "loss": 2.9474,
      "step": 26880
    },
    {
      "epoch": 1.15735559955238,
      "grad_norm": 1.0597102642059326,
      "learning_rate": 0.0001406453629165775,
      "loss": 3.0295,
      "step": 26890
    },
    {
      "epoch": 1.1577860032710683,
      "grad_norm": 0.9137314558029175,
      "learning_rate": 0.00014060290351771944,
      "loss": 3.0411,
      "step": 26900
    },
    {
      "epoch": 1.1577860032710683,
      "eval_bleu": 27.13880247893032,
      "eval_gen_len": 27.439,
      "eval_loss": 2.7995688915252686,
      "eval_runtime": 58.1959,
      "eval_samples_per_second": 17.183,
      "eval_steps_per_second": 1.083,
      "step": 26900
    },
    {
      "epoch": 1.1582164069897565,
      "grad_norm": 0.9036325812339783,
      "learning_rate": 0.00014056043535218534,
      "loss": 3.0636,
      "step": 26910
    },
    {
      "epoch": 1.1586468107084444,
      "grad_norm": 0.8409227132797241,
      "learning_rate": 0.0001405179584291447,
      "loss": 2.9927,
      "step": 26920
    },
    {
      "epoch": 1.1590772144271326,
      "grad_norm": 0.9560302495956421,
      "learning_rate": 0.0001404754727577687,
      "loss": 3.0694,
      "step": 26930
    },
    {
      "epoch": 1.1595076181458208,
      "grad_norm": 0.7717974781990051,
      "learning_rate": 0.00014043297834723058,
      "loss": 3.063,
      "step": 26940
    },
    {
      "epoch": 1.159938021864509,
      "grad_norm": 0.8962326645851135,
      "learning_rate": 0.00014039047520670548,
      "loss": 2.9657,
      "step": 26950
    },
    {
      "epoch": 1.159938021864509,
      "eval_bleu": 26.451697518915932,
      "eval_gen_len": 27.341,
      "eval_loss": 2.803861618041992,
      "eval_runtime": 58.2744,
      "eval_samples_per_second": 17.16,
      "eval_steps_per_second": 1.081,
      "step": 26950
    },
    {
      "epoch": 1.160368425583197,
      "grad_norm": 0.8941118717193604,
      "learning_rate": 0.00014034796334537025,
      "loss": 3.0266,
      "step": 26960
    },
    {
      "epoch": 1.1607988293018852,
      "grad_norm": 0.9080703258514404,
      "learning_rate": 0.00014030544277240383,
      "loss": 3.0278,
      "step": 26970
    },
    {
      "epoch": 1.1612292330205733,
      "grad_norm": 0.9372168779373169,
      "learning_rate": 0.00014026291349698687,
      "loss": 2.9835,
      "step": 26980
    },
    {
      "epoch": 1.1616596367392615,
      "grad_norm": 0.8980123400688171,
      "learning_rate": 0.000140220375528302,
      "loss": 3.0382,
      "step": 26990
    },
    {
      "epoch": 1.1620900404579495,
      "grad_norm": 0.8609248399734497,
      "learning_rate": 0.00014017782887553373,
      "loss": 3.0185,
      "step": 27000
    },
    {
      "epoch": 1.1620900404579495,
      "eval_bleu": 26.91215980723589,
      "eval_gen_len": 27.4,
      "eval_loss": 2.801892042160034,
      "eval_runtime": 58.1781,
      "eval_samples_per_second": 17.189,
      "eval_steps_per_second": 1.083,
      "step": 27000
    },
    {
      "epoch": 1.1625204441766377,
      "grad_norm": 0.8574472069740295,
      "learning_rate": 0.00014013527354786838,
      "loss": 3.0618,
      "step": 27010
    },
    {
      "epoch": 1.1629508478953259,
      "grad_norm": 0.9509608745574951,
      "learning_rate": 0.0001400927095544942,
      "loss": 2.9507,
      "step": 27020
    },
    {
      "epoch": 1.1633812516140138,
      "grad_norm": 0.9962447285652161,
      "learning_rate": 0.00014005013690460128,
      "loss": 3.1379,
      "step": 27030
    },
    {
      "epoch": 1.163811655332702,
      "grad_norm": 0.9757311940193176,
      "learning_rate": 0.00014000755560738157,
      "loss": 3.0364,
      "step": 27040
    },
    {
      "epoch": 1.1642420590513902,
      "grad_norm": 0.9625189900398254,
      "learning_rate": 0.00013996496567202893,
      "loss": 2.8991,
      "step": 27050
    },
    {
      "epoch": 1.1642420590513902,
      "eval_bleu": 26.94783754257878,
      "eval_gen_len": 27.355,
      "eval_loss": 2.799588203430176,
      "eval_runtime": 57.9875,
      "eval_samples_per_second": 17.245,
      "eval_steps_per_second": 1.086,
      "step": 27050
    },
    {
      "epoch": 1.1646724627700784,
      "grad_norm": 0.8665328621864319,
      "learning_rate": 0.00013992236710773904,
      "loss": 3.0489,
      "step": 27060
    },
    {
      "epoch": 1.1651028664887664,
      "grad_norm": 0.872539222240448,
      "learning_rate": 0.00013987975992370952,
      "loss": 3.0756,
      "step": 27070
    },
    {
      "epoch": 1.1655332702074546,
      "grad_norm": 0.9670940637588501,
      "learning_rate": 0.00013983714412913972,
      "loss": 3.056,
      "step": 27080
    },
    {
      "epoch": 1.1659636739261428,
      "grad_norm": 1.0871058702468872,
      "learning_rate": 0.000139794519733231,
      "loss": 3.0882,
      "step": 27090
    },
    {
      "epoch": 1.166394077644831,
      "grad_norm": 0.9971653819084167,
      "learning_rate": 0.00013975188674518645,
      "loss": 3.0426,
      "step": 27100
    },
    {
      "epoch": 1.166394077644831,
      "eval_bleu": 26.959202493802593,
      "eval_gen_len": 27.329,
      "eval_loss": 2.800783157348633,
      "eval_runtime": 58.1704,
      "eval_samples_per_second": 17.191,
      "eval_steps_per_second": 1.083,
      "step": 27100
    },
    {
      "epoch": 1.166824481363519,
      "grad_norm": 0.9349181652069092,
      "learning_rate": 0.00013970924517421108,
      "loss": 3.0392,
      "step": 27110
    },
    {
      "epoch": 1.167254885082207,
      "grad_norm": 0.9682422280311584,
      "learning_rate": 0.00013966659502951168,
      "loss": 3.0138,
      "step": 27120
    },
    {
      "epoch": 1.1676852888008953,
      "grad_norm": 1.0107016563415527,
      "learning_rate": 0.00013962393632029708,
      "loss": 3.0488,
      "step": 27130
    },
    {
      "epoch": 1.1681156925195832,
      "grad_norm": 0.8286248445510864,
      "learning_rate": 0.00013958126905577774,
      "loss": 2.9821,
      "step": 27140
    },
    {
      "epoch": 1.1685460962382714,
      "grad_norm": 0.8722807168960571,
      "learning_rate": 0.00013953859324516605,
      "loss": 3.0796,
      "step": 27150
    },
    {
      "epoch": 1.1685460962382714,
      "eval_bleu": 27.10240145479745,
      "eval_gen_len": 27.402,
      "eval_loss": 2.802255868911743,
      "eval_runtime": 58.373,
      "eval_samples_per_second": 17.131,
      "eval_steps_per_second": 1.079,
      "step": 27150
    },
    {
      "epoch": 1.1689764999569596,
      "grad_norm": 0.9459089040756226,
      "learning_rate": 0.00013949590889767628,
      "loss": 3.0658,
      "step": 27160
    },
    {
      "epoch": 1.1694069036756478,
      "grad_norm": 0.7883638739585876,
      "learning_rate": 0.0001394532160225246,
      "loss": 2.9541,
      "step": 27170
    },
    {
      "epoch": 1.169837307394336,
      "grad_norm": 0.8649691343307495,
      "learning_rate": 0.00013941051462892877,
      "loss": 3.0488,
      "step": 27180
    },
    {
      "epoch": 1.170267711113024,
      "grad_norm": 0.918243944644928,
      "learning_rate": 0.00013936780472610866,
      "loss": 2.9818,
      "step": 27190
    },
    {
      "epoch": 1.1706981148317122,
      "grad_norm": 0.9772835373878479,
      "learning_rate": 0.00013932508632328585,
      "loss": 3.1491,
      "step": 27200
    },
    {
      "epoch": 1.1706981148317122,
      "eval_bleu": 26.736101503869858,
      "eval_gen_len": 27.291,
      "eval_loss": 2.804011106491089,
      "eval_runtime": 58.0944,
      "eval_samples_per_second": 17.213,
      "eval_steps_per_second": 1.084,
      "step": 27200
    },
    {
      "epoch": 1.1711285185504003,
      "grad_norm": 0.891094982624054,
      "learning_rate": 0.00013928235942968378,
      "loss": 2.9129,
      "step": 27210
    },
    {
      "epoch": 1.1715589222690883,
      "grad_norm": 0.967266857624054,
      "learning_rate": 0.00013923962405452774,
      "loss": 2.9975,
      "step": 27220
    },
    {
      "epoch": 1.1719893259877765,
      "grad_norm": 0.8630532622337341,
      "learning_rate": 0.0001391968802070448,
      "loss": 3.0002,
      "step": 27230
    },
    {
      "epoch": 1.1724197297064647,
      "grad_norm": 0.8845338225364685,
      "learning_rate": 0.0001391541278964639,
      "loss": 2.999,
      "step": 27240
    },
    {
      "epoch": 1.1728501334251529,
      "grad_norm": 0.8762720823287964,
      "learning_rate": 0.00013911136713201585,
      "loss": 2.9464,
      "step": 27250
    },
    {
      "epoch": 1.1728501334251529,
      "eval_bleu": 27.010796493262283,
      "eval_gen_len": 27.356,
      "eval_loss": 2.7997677326202393,
      "eval_runtime": 57.9097,
      "eval_samples_per_second": 17.268,
      "eval_steps_per_second": 1.088,
      "step": 27250
    },
    {
      "epoch": 1.1732805371438408,
      "grad_norm": 0.994292140007019,
      "learning_rate": 0.00013906859792293317,
      "loss": 3.0824,
      "step": 27260
    },
    {
      "epoch": 1.173710940862529,
      "grad_norm": 0.9114242196083069,
      "learning_rate": 0.00013902582027845029,
      "loss": 3.0323,
      "step": 27270
    },
    {
      "epoch": 1.1741413445812172,
      "grad_norm": 0.9441501498222351,
      "learning_rate": 0.00013898303420780344,
      "loss": 3.0795,
      "step": 27280
    },
    {
      "epoch": 1.1745717482999054,
      "grad_norm": 0.9420647025108337,
      "learning_rate": 0.0001389402397202307,
      "loss": 3.0846,
      "step": 27290
    },
    {
      "epoch": 1.1750021520185934,
      "grad_norm": 0.9143452048301697,
      "learning_rate": 0.0001388974368249719,
      "loss": 2.9822,
      "step": 27300
    },
    {
      "epoch": 1.1750021520185934,
      "eval_bleu": 26.716158415480347,
      "eval_gen_len": 27.485,
      "eval_loss": 2.8075029850006104,
      "eval_runtime": 58.9646,
      "eval_samples_per_second": 16.959,
      "eval_steps_per_second": 1.068,
      "step": 27300
    },
    {
      "epoch": 1.1754325557372816,
      "grad_norm": 0.8674576282501221,
      "learning_rate": 0.00013885462553126868,
      "loss": 3.0384,
      "step": 27310
    },
    {
      "epoch": 1.1758629594559697,
      "grad_norm": 0.9330261945724487,
      "learning_rate": 0.00013881180584836462,
      "loss": 2.9957,
      "step": 27320
    },
    {
      "epoch": 1.1762933631746577,
      "grad_norm": 0.9046264290809631,
      "learning_rate": 0.000138768977785505,
      "loss": 2.9366,
      "step": 27330
    },
    {
      "epoch": 1.176723766893346,
      "grad_norm": 0.9241552948951721,
      "learning_rate": 0.00013872614135193695,
      "loss": 3.1514,
      "step": 27340
    },
    {
      "epoch": 1.177154170612034,
      "grad_norm": 0.9300393462181091,
      "learning_rate": 0.00013868329655690933,
      "loss": 2.9481,
      "step": 27350
    },
    {
      "epoch": 1.177154170612034,
      "eval_bleu": 26.906145622507786,
      "eval_gen_len": 27.546,
      "eval_loss": 2.805361270904541,
      "eval_runtime": 58.6706,
      "eval_samples_per_second": 17.044,
      "eval_steps_per_second": 1.074,
      "step": 27350
    },
    {
      "epoch": 1.1775845743307223,
      "grad_norm": 0.8983712196350098,
      "learning_rate": 0.00013864044340967293,
      "loss": 3.0023,
      "step": 27360
    },
    {
      "epoch": 1.1780149780494105,
      "grad_norm": 0.8198054432868958,
      "learning_rate": 0.00013859758191948028,
      "loss": 3.0325,
      "step": 27370
    },
    {
      "epoch": 1.1784453817680984,
      "grad_norm": 0.8799516558647156,
      "learning_rate": 0.0001385547120955857,
      "loss": 3.0731,
      "step": 27380
    },
    {
      "epoch": 1.1788757854867866,
      "grad_norm": 0.8727443218231201,
      "learning_rate": 0.00013851183394724526,
      "loss": 3.1023,
      "step": 27390
    },
    {
      "epoch": 1.1793061892054748,
      "grad_norm": 0.9857727885246277,
      "learning_rate": 0.00013846894748371696,
      "loss": 3.0928,
      "step": 27400
    },
    {
      "epoch": 1.1793061892054748,
      "eval_bleu": 26.842375121108404,
      "eval_gen_len": 27.529,
      "eval_loss": 2.801737070083618,
      "eval_runtime": 59.2521,
      "eval_samples_per_second": 16.877,
      "eval_steps_per_second": 1.063,
      "step": 27400
    },
    {
      "epoch": 1.1797365929241628,
      "grad_norm": 0.9425446391105652,
      "learning_rate": 0.00013842605271426053,
      "loss": 3.0898,
      "step": 27410
    },
    {
      "epoch": 1.180166996642851,
      "grad_norm": 0.8901601433753967,
      "learning_rate": 0.00013838314964813748,
      "loss": 3.0637,
      "step": 27420
    },
    {
      "epoch": 1.1805974003615392,
      "grad_norm": 0.8551876544952393,
      "learning_rate": 0.0001383402382946111,
      "loss": 3.0056,
      "step": 27430
    },
    {
      "epoch": 1.1810278040802273,
      "grad_norm": 0.9657149314880371,
      "learning_rate": 0.00013829731866294652,
      "loss": 3.0855,
      "step": 27440
    },
    {
      "epoch": 1.1814582077989153,
      "grad_norm": 0.9015184640884399,
      "learning_rate": 0.00013825439076241058,
      "loss": 2.921,
      "step": 27450
    },
    {
      "epoch": 1.1814582077989153,
      "eval_bleu": 26.830878088451932,
      "eval_gen_len": 27.479,
      "eval_loss": 2.802746534347534,
      "eval_runtime": 59.225,
      "eval_samples_per_second": 16.885,
      "eval_steps_per_second": 1.064,
      "step": 27450
    },
    {
      "epoch": 1.1818886115176035,
      "grad_norm": 0.9207348823547363,
      "learning_rate": 0.00013821145460227201,
      "loss": 3.0499,
      "step": 27460
    },
    {
      "epoch": 1.1823190152362917,
      "grad_norm": 1.0733259916305542,
      "learning_rate": 0.00013816851019180122,
      "loss": 2.9896,
      "step": 27470
    },
    {
      "epoch": 1.1827494189549799,
      "grad_norm": 1.0002650022506714,
      "learning_rate": 0.00013812555754027044,
      "loss": 3.0942,
      "step": 27480
    },
    {
      "epoch": 1.1831798226736678,
      "grad_norm": 0.9709746241569519,
      "learning_rate": 0.00013808259665695373,
      "loss": 2.9828,
      "step": 27490
    },
    {
      "epoch": 1.183610226392356,
      "grad_norm": 0.8940593600273132,
      "learning_rate": 0.00013803962755112685,
      "loss": 3.0017,
      "step": 27500
    },
    {
      "epoch": 1.183610226392356,
      "eval_bleu": 26.612972669862582,
      "eval_gen_len": 27.453,
      "eval_loss": 2.805208683013916,
      "eval_runtime": 58.4118,
      "eval_samples_per_second": 17.12,
      "eval_steps_per_second": 1.079,
      "step": 27500
    },
    {
      "epoch": 1.1840406301110442,
      "grad_norm": 0.8263776898384094,
      "learning_rate": 0.0001379966502320674,
      "loss": 2.9815,
      "step": 27510
    },
    {
      "epoch": 1.1844710338297322,
      "grad_norm": 0.9093518853187561,
      "learning_rate": 0.00013795366470905466,
      "loss": 2.9518,
      "step": 27520
    },
    {
      "epoch": 1.1849014375484204,
      "grad_norm": 0.9947023391723633,
      "learning_rate": 0.00013791067099136982,
      "loss": 3.0057,
      "step": 27530
    },
    {
      "epoch": 1.1853318412671086,
      "grad_norm": 0.8759405016899109,
      "learning_rate": 0.00013786766908829574,
      "loss": 3.058,
      "step": 27540
    },
    {
      "epoch": 1.1857622449857967,
      "grad_norm": 1.0261510610580444,
      "learning_rate": 0.00013782465900911704,
      "loss": 3.046,
      "step": 27550
    },
    {
      "epoch": 1.1857622449857967,
      "eval_bleu": 26.80667944227228,
      "eval_gen_len": 27.587,
      "eval_loss": 2.803178310394287,
      "eval_runtime": 58.8855,
      "eval_samples_per_second": 16.982,
      "eval_steps_per_second": 1.07,
      "step": 27550
    },
    {
      "epoch": 1.186192648704485,
      "grad_norm": 0.9009307026863098,
      "learning_rate": 0.00013778164076312015,
      "loss": 3.0066,
      "step": 27560
    },
    {
      "epoch": 1.186623052423173,
      "grad_norm": 1.0248160362243652,
      "learning_rate": 0.00013773861435959324,
      "loss": 3.0076,
      "step": 27570
    },
    {
      "epoch": 1.187053456141861,
      "grad_norm": 1.0113520622253418,
      "learning_rate": 0.00013769557980782628,
      "loss": 3.0457,
      "step": 27580
    },
    {
      "epoch": 1.1874838598605493,
      "grad_norm": 0.9095500707626343,
      "learning_rate": 0.00013765253711711095,
      "loss": 3.0822,
      "step": 27590
    },
    {
      "epoch": 1.1879142635792372,
      "grad_norm": 0.9090281128883362,
      "learning_rate": 0.00013760948629674069,
      "loss": 2.9941,
      "step": 27600
    },
    {
      "epoch": 1.1879142635792372,
      "eval_bleu": 26.707977567935174,
      "eval_gen_len": 27.357,
      "eval_loss": 2.80301833152771,
      "eval_runtime": 58.3952,
      "eval_samples_per_second": 17.125,
      "eval_steps_per_second": 1.079,
      "step": 27600
    },
    {
      "epoch": 1.1883446672979254,
      "grad_norm": 0.9571593403816223,
      "learning_rate": 0.00013756642735601076,
      "loss": 3.0223,
      "step": 27610
    },
    {
      "epoch": 1.1887750710166136,
      "grad_norm": 1.003611445426941,
      "learning_rate": 0.0001375233603042181,
      "loss": 3.0133,
      "step": 27620
    },
    {
      "epoch": 1.1892054747353018,
      "grad_norm": 0.8483901619911194,
      "learning_rate": 0.00013748028515066138,
      "loss": 3.1004,
      "step": 27630
    },
    {
      "epoch": 1.1896358784539898,
      "grad_norm": 0.9452928304672241,
      "learning_rate": 0.00013743720190464114,
      "loss": 3.0222,
      "step": 27640
    },
    {
      "epoch": 1.190066282172678,
      "grad_norm": 0.9420109987258911,
      "learning_rate": 0.00013739411057545953,
      "loss": 3.0573,
      "step": 27650
    },
    {
      "epoch": 1.190066282172678,
      "eval_bleu": 26.882952053750184,
      "eval_gen_len": 27.535,
      "eval_loss": 2.806278944015503,
      "eval_runtime": 59.0861,
      "eval_samples_per_second": 16.924,
      "eval_steps_per_second": 1.066,
      "step": 27650
    },
    {
      "epoch": 1.1904966858913661,
      "grad_norm": 0.9036616086959839,
      "learning_rate": 0.0001373510111724206,
      "loss": 3.0482,
      "step": 27660
    },
    {
      "epoch": 1.1909270896100543,
      "grad_norm": 0.8529059886932373,
      "learning_rate": 0.00013730790370482994,
      "loss": 3.0238,
      "step": 27670
    },
    {
      "epoch": 1.1913574933287423,
      "grad_norm": 0.8892298936843872,
      "learning_rate": 0.00013726478818199505,
      "loss": 2.9863,
      "step": 27680
    },
    {
      "epoch": 1.1917878970474305,
      "grad_norm": 0.8984922170639038,
      "learning_rate": 0.0001372216646132251,
      "loss": 2.8769,
      "step": 27690
    },
    {
      "epoch": 1.1922183007661187,
      "grad_norm": 1.0093417167663574,
      "learning_rate": 0.00013717853300783102,
      "loss": 3.0302,
      "step": 27700
    },
    {
      "epoch": 1.1922183007661187,
      "eval_bleu": 27.088592764209203,
      "eval_gen_len": 27.558,
      "eval_loss": 2.797553539276123,
      "eval_runtime": 58.591,
      "eval_samples_per_second": 17.067,
      "eval_steps_per_second": 1.075,
      "step": 27700
    },
    {
      "epoch": 1.1926487044848066,
      "grad_norm": 0.8328936696052551,
      "learning_rate": 0.00013713539337512548,
      "loss": 2.9692,
      "step": 27710
    },
    {
      "epoch": 1.1930791082034948,
      "grad_norm": 0.831283688545227,
      "learning_rate": 0.00013709224572442283,
      "loss": 2.959,
      "step": 27720
    },
    {
      "epoch": 1.193509511922183,
      "grad_norm": 1.014305830001831,
      "learning_rate": 0.0001370490900650392,
      "loss": 2.9913,
      "step": 27730
    },
    {
      "epoch": 1.1939399156408712,
      "grad_norm": 0.9159823656082153,
      "learning_rate": 0.0001370059264062925,
      "loss": 3.0427,
      "step": 27740
    },
    {
      "epoch": 1.1943703193595592,
      "grad_norm": 1.0572433471679688,
      "learning_rate": 0.00013696275475750218,
      "loss": 3.0752,
      "step": 27750
    },
    {
      "epoch": 1.1943703193595592,
      "eval_bleu": 26.99915525777927,
      "eval_gen_len": 27.605,
      "eval_loss": 2.8035695552825928,
      "eval_runtime": 58.8981,
      "eval_samples_per_second": 16.978,
      "eval_steps_per_second": 1.07,
      "step": 27750
    },
    {
      "epoch": 1.1948007230782474,
      "grad_norm": 0.9110327363014221,
      "learning_rate": 0.00013691957512798963,
      "loss": 3.0158,
      "step": 27760
    },
    {
      "epoch": 1.1952311267969356,
      "grad_norm": 1.0180200338363647,
      "learning_rate": 0.00013687638752707786,
      "loss": 2.976,
      "step": 27770
    },
    {
      "epoch": 1.1956615305156237,
      "grad_norm": 0.8286318182945251,
      "learning_rate": 0.0001368331919640916,
      "loss": 2.9792,
      "step": 27780
    },
    {
      "epoch": 1.1960919342343117,
      "grad_norm": 0.9951903223991394,
      "learning_rate": 0.0001367899884483573,
      "loss": 2.9621,
      "step": 27790
    },
    {
      "epoch": 1.196522337953,
      "grad_norm": 0.9749011993408203,
      "learning_rate": 0.00013674677698920318,
      "loss": 3.0005,
      "step": 27800
    },
    {
      "epoch": 1.196522337953,
      "eval_bleu": 26.998937693433067,
      "eval_gen_len": 27.548,
      "eval_loss": 2.7998650074005127,
      "eval_runtime": 58.7464,
      "eval_samples_per_second": 17.022,
      "eval_steps_per_second": 1.072,
      "step": 27800
    },
    {
      "epoch": 1.196952741671688,
      "grad_norm": 0.8852875232696533,
      "learning_rate": 0.00013670355759595913,
      "loss": 3.0398,
      "step": 27810
    },
    {
      "epoch": 1.1973831453903763,
      "grad_norm": 0.876070499420166,
      "learning_rate": 0.00013666033027795674,
      "loss": 3.0377,
      "step": 27820
    },
    {
      "epoch": 1.1978135491090642,
      "grad_norm": 0.8978708386421204,
      "learning_rate": 0.00013661709504452936,
      "loss": 3.0179,
      "step": 27830
    },
    {
      "epoch": 1.1982439528277524,
      "grad_norm": 1.004509687423706,
      "learning_rate": 0.00013657385190501194,
      "loss": 3.1334,
      "step": 27840
    },
    {
      "epoch": 1.1986743565464406,
      "grad_norm": 0.9037157893180847,
      "learning_rate": 0.00013653060086874131,
      "loss": 2.9916,
      "step": 27850
    },
    {
      "epoch": 1.1986743565464406,
      "eval_bleu": 26.622522741695665,
      "eval_gen_len": 27.504,
      "eval_loss": 2.8045222759246826,
      "eval_runtime": 58.4442,
      "eval_samples_per_second": 17.11,
      "eval_steps_per_second": 1.078,
      "step": 27850
    },
    {
      "epoch": 1.1991047602651288,
      "grad_norm": 0.8083489537239075,
      "learning_rate": 0.00013648734194505584,
      "loss": 3.0187,
      "step": 27860
    },
    {
      "epoch": 1.1995351639838168,
      "grad_norm": 0.9068928360939026,
      "learning_rate": 0.00013644407514329577,
      "loss": 3.1137,
      "step": 27870
    },
    {
      "epoch": 1.199965567702505,
      "grad_norm": 0.9287480711936951,
      "learning_rate": 0.00013640080047280282,
      "loss": 3.1238,
      "step": 27880
    },
    {
      "epoch": 1.2003959714211931,
      "grad_norm": 0.8555922508239746,
      "learning_rate": 0.00013635751794292063,
      "loss": 3.0949,
      "step": 27890
    },
    {
      "epoch": 1.200826375139881,
      "grad_norm": 0.8498854637145996,
      "learning_rate": 0.00013631422756299442,
      "loss": 3.0466,
      "step": 27900
    },
    {
      "epoch": 1.200826375139881,
      "eval_bleu": 26.85830568482282,
      "eval_gen_len": 27.447,
      "eval_loss": 2.802212953567505,
      "eval_runtime": 58.4738,
      "eval_samples_per_second": 17.102,
      "eval_steps_per_second": 1.077,
      "step": 27900
    },
    {
      "epoch": 1.2012567788585693,
      "grad_norm": 0.8966606855392456,
      "learning_rate": 0.0001362709293423711,
      "loss": 3.0127,
      "step": 27910
    },
    {
      "epoch": 1.2016871825772575,
      "grad_norm": 0.8757481575012207,
      "learning_rate": 0.0001362276232903993,
      "loss": 3.0711,
      "step": 27920
    },
    {
      "epoch": 1.2021175862959457,
      "grad_norm": 1.1659926176071167,
      "learning_rate": 0.00013618430941642935,
      "loss": 3.0045,
      "step": 27930
    },
    {
      "epoch": 1.2025479900146336,
      "grad_norm": 0.8862165212631226,
      "learning_rate": 0.00013614098772981326,
      "loss": 3.0086,
      "step": 27940
    },
    {
      "epoch": 1.2029783937333218,
      "grad_norm": 0.7953133583068848,
      "learning_rate": 0.00013609765823990473,
      "loss": 3.0306,
      "step": 27950
    },
    {
      "epoch": 1.2029783937333218,
      "eval_bleu": 26.799919025588448,
      "eval_gen_len": 27.386,
      "eval_loss": 2.800374746322632,
      "eval_runtime": 58.4132,
      "eval_samples_per_second": 17.119,
      "eval_steps_per_second": 1.079,
      "step": 27950
    },
    {
      "epoch": 1.20340879745201,
      "grad_norm": 0.9928591251373291,
      "learning_rate": 0.00013605432095605913,
      "loss": 3.0272,
      "step": 27960
    },
    {
      "epoch": 1.2038392011706982,
      "grad_norm": 0.9762970805168152,
      "learning_rate": 0.00013601097588763353,
      "loss": 3.115,
      "step": 27970
    },
    {
      "epoch": 1.2042696048893862,
      "grad_norm": 1.0175716876983643,
      "learning_rate": 0.00013596762304398668,
      "loss": 3.0384,
      "step": 27980
    },
    {
      "epoch": 1.2047000086080744,
      "grad_norm": 0.8921935558319092,
      "learning_rate": 0.00013592426243447898,
      "loss": 3.0956,
      "step": 27990
    },
    {
      "epoch": 1.2051304123267625,
      "grad_norm": 1.0255019664764404,
      "learning_rate": 0.00013588089406847256,
      "loss": 3.0569,
      "step": 28000
    },
    {
      "epoch": 1.2051304123267625,
      "eval_bleu": 26.46026369900972,
      "eval_gen_len": 27.42,
      "eval_loss": 2.805105209350586,
      "eval_runtime": 58.0794,
      "eval_samples_per_second": 17.218,
      "eval_steps_per_second": 1.085,
      "step": 28000
    },
    {
      "epoch": 1.2055608160454505,
      "grad_norm": 0.904878556728363,
      "learning_rate": 0.00013583751795533117,
      "loss": 3.0812,
      "step": 28010
    },
    {
      "epoch": 1.2059912197641387,
      "grad_norm": 0.9172275066375732,
      "learning_rate": 0.0001357941341044203,
      "loss": 3.0573,
      "step": 28020
    },
    {
      "epoch": 1.2064216234828269,
      "grad_norm": 0.7669629454612732,
      "learning_rate": 0.000135750742525107,
      "loss": 2.9787,
      "step": 28030
    },
    {
      "epoch": 1.206852027201515,
      "grad_norm": 0.8965808749198914,
      "learning_rate": 0.00013570734322676008,
      "loss": 3.0513,
      "step": 28040
    },
    {
      "epoch": 1.2072824309202033,
      "grad_norm": 0.931929349899292,
      "learning_rate": 0.00013566393621874996,
      "loss": 3.0331,
      "step": 28050
    },
    {
      "epoch": 1.2072824309202033,
      "eval_bleu": 27.071067815965066,
      "eval_gen_len": 27.522,
      "eval_loss": 2.8013103008270264,
      "eval_runtime": 58.4927,
      "eval_samples_per_second": 17.096,
      "eval_steps_per_second": 1.077,
      "step": 28050
    },
    {
      "epoch": 1.2077128346388912,
      "grad_norm": 0.9916948080062866,
      "learning_rate": 0.00013562052151044887,
      "loss": 3.0568,
      "step": 28060
    },
    {
      "epoch": 1.2081432383575794,
      "grad_norm": 1.0348708629608154,
      "learning_rate": 0.00013557709911123051,
      "loss": 3.1291,
      "step": 28070
    },
    {
      "epoch": 1.2085736420762676,
      "grad_norm": 0.9962469935417175,
      "learning_rate": 0.0001355336690304703,
      "loss": 3.079,
      "step": 28080
    },
    {
      "epoch": 1.2090040457949556,
      "grad_norm": 0.9195934534072876,
      "learning_rate": 0.0001354902312775454,
      "loss": 3.0745,
      "step": 28090
    },
    {
      "epoch": 1.2094344495136438,
      "grad_norm": 0.9822903871536255,
      "learning_rate": 0.00013544678586183451,
      "loss": 3.1501,
      "step": 28100
    },
    {
      "epoch": 1.2094344495136438,
      "eval_bleu": 26.7328596473929,
      "eval_gen_len": 27.558,
      "eval_loss": 2.8045194149017334,
      "eval_runtime": 57.7658,
      "eval_samples_per_second": 17.311,
      "eval_steps_per_second": 1.091,
      "step": 28100
    },
    {
      "epoch": 1.209864853232332,
      "grad_norm": 0.9054829478263855,
      "learning_rate": 0.00013540333279271808,
      "loss": 3.1341,
      "step": 28110
    },
    {
      "epoch": 1.2102952569510201,
      "grad_norm": 0.942866861820221,
      "learning_rate": 0.00013535987207957816,
      "loss": 3.0322,
      "step": 28120
    },
    {
      "epoch": 1.210725660669708,
      "grad_norm": 0.8847404718399048,
      "learning_rate": 0.00013531640373179844,
      "loss": 3.024,
      "step": 28130
    },
    {
      "epoch": 1.2111560643883963,
      "grad_norm": 0.8230764865875244,
      "learning_rate": 0.0001352729277587643,
      "loss": 3.0022,
      "step": 28140
    },
    {
      "epoch": 1.2115864681070845,
      "grad_norm": 0.9463727474212646,
      "learning_rate": 0.00013522944416986276,
      "loss": 2.9873,
      "step": 28150
    },
    {
      "epoch": 1.2115864681070845,
      "eval_bleu": 26.614612999697535,
      "eval_gen_len": 27.376,
      "eval_loss": 2.8051087856292725,
      "eval_runtime": 58.0952,
      "eval_samples_per_second": 17.213,
      "eval_steps_per_second": 1.084,
      "step": 28150
    },
    {
      "epoch": 1.2120168718257727,
      "grad_norm": 0.9239397644996643,
      "learning_rate": 0.00013518595297448244,
      "loss": 3.0058,
      "step": 28160
    },
    {
      "epoch": 1.2124472755444606,
      "grad_norm": 0.9361575245857239,
      "learning_rate": 0.00013514245418201368,
      "loss": 3.0202,
      "step": 28170
    },
    {
      "epoch": 1.2128776792631488,
      "grad_norm": 1.098589301109314,
      "learning_rate": 0.00013509894780184837,
      "loss": 2.9972,
      "step": 28180
    },
    {
      "epoch": 1.213308082981837,
      "grad_norm": 0.9926831126213074,
      "learning_rate": 0.00013505543384338014,
      "loss": 2.995,
      "step": 28190
    },
    {
      "epoch": 1.213738486700525,
      "grad_norm": 0.8614456057548523,
      "learning_rate": 0.0001350119123160041,
      "loss": 3.0549,
      "step": 28200
    },
    {
      "epoch": 1.213738486700525,
      "eval_bleu": 26.69023959480472,
      "eval_gen_len": 27.544,
      "eval_loss": 2.8029019832611084,
      "eval_runtime": 58.5686,
      "eval_samples_per_second": 17.074,
      "eval_steps_per_second": 1.076,
      "step": 28200
    },
    {
      "epoch": 1.2141688904192132,
      "grad_norm": 0.9695780277252197,
      "learning_rate": 0.0001349683832291172,
      "loss": 3.1355,
      "step": 28210
    },
    {
      "epoch": 1.2145992941379014,
      "grad_norm": 0.9939009547233582,
      "learning_rate": 0.00013492484659211786,
      "loss": 3.0057,
      "step": 28220
    },
    {
      "epoch": 1.2150296978565895,
      "grad_norm": 0.83246248960495,
      "learning_rate": 0.0001348813024144062,
      "loss": 2.8817,
      "step": 28230
    },
    {
      "epoch": 1.2154601015752777,
      "grad_norm": 0.8660234212875366,
      "learning_rate": 0.00013483775070538393,
      "loss": 3.0271,
      "step": 28240
    },
    {
      "epoch": 1.2158905052939657,
      "grad_norm": 0.8914315104484558,
      "learning_rate": 0.00013479419147445447,
      "loss": 3.0583,
      "step": 28250
    },
    {
      "epoch": 1.2158905052939657,
      "eval_bleu": 26.636086838653046,
      "eval_gen_len": 27.473,
      "eval_loss": 2.8040151596069336,
      "eval_runtime": 58.145,
      "eval_samples_per_second": 17.198,
      "eval_steps_per_second": 1.083,
      "step": 28250
    },
    {
      "epoch": 1.2163209090126539,
      "grad_norm": 0.989529550075531,
      "learning_rate": 0.00013475062473102271,
      "loss": 3.0945,
      "step": 28260
    },
    {
      "epoch": 1.216751312731342,
      "grad_norm": 0.9535933136940002,
      "learning_rate": 0.00013470705048449538,
      "loss": 3.0206,
      "step": 28270
    },
    {
      "epoch": 1.21718171645003,
      "grad_norm": 0.9504647254943848,
      "learning_rate": 0.0001346634687442806,
      "loss": 2.9967,
      "step": 28280
    },
    {
      "epoch": 1.2176121201687182,
      "grad_norm": 0.8649418354034424,
      "learning_rate": 0.00013461987951978824,
      "loss": 2.9833,
      "step": 28290
    },
    {
      "epoch": 1.2180425238874064,
      "grad_norm": 0.864658534526825,
      "learning_rate": 0.0001345762828204298,
      "loss": 2.96,
      "step": 28300
    },
    {
      "epoch": 1.2180425238874064,
      "eval_bleu": 26.92476179160378,
      "eval_gen_len": 27.458,
      "eval_loss": 2.80334734916687,
      "eval_runtime": 58.2325,
      "eval_samples_per_second": 17.173,
      "eval_steps_per_second": 1.082,
      "step": 28300
    },
    {
      "epoch": 1.2184729276060946,
      "grad_norm": 0.9406525492668152,
      "learning_rate": 0.0001345326786556183,
      "loss": 2.983,
      "step": 28310
    },
    {
      "epoch": 1.2189033313247826,
      "grad_norm": 0.8676363229751587,
      "learning_rate": 0.00013448906703476848,
      "loss": 3.1176,
      "step": 28320
    },
    {
      "epoch": 1.2193337350434708,
      "grad_norm": 0.8683159947395325,
      "learning_rate": 0.00013444544796729658,
      "loss": 3.0398,
      "step": 28330
    },
    {
      "epoch": 1.219764138762159,
      "grad_norm": 0.8170113563537598,
      "learning_rate": 0.00013440182146262053,
      "loss": 3.0263,
      "step": 28340
    },
    {
      "epoch": 1.2201945424808471,
      "grad_norm": 0.9302219152450562,
      "learning_rate": 0.00013435818753015986,
      "loss": 3.0593,
      "step": 28350
    },
    {
      "epoch": 1.2201945424808471,
      "eval_bleu": 26.875178222024466,
      "eval_gen_len": 27.399,
      "eval_loss": 2.80147647857666,
      "eval_runtime": 58.5207,
      "eval_samples_per_second": 17.088,
      "eval_steps_per_second": 1.077,
      "step": 28350
    },
    {
      "epoch": 1.220624946199535,
      "grad_norm": 0.8627659678459167,
      "learning_rate": 0.0001343145461793357,
      "loss": 3.0281,
      "step": 28360
    },
    {
      "epoch": 1.2210553499182233,
      "grad_norm": 0.9054973125457764,
      "learning_rate": 0.00013427089741957065,
      "loss": 3.0872,
      "step": 28370
    },
    {
      "epoch": 1.2214857536369115,
      "grad_norm": 0.7938016057014465,
      "learning_rate": 0.00013422724126028915,
      "loss": 2.9097,
      "step": 28380
    },
    {
      "epoch": 1.2219161573555994,
      "grad_norm": 0.8997344374656677,
      "learning_rate": 0.00013418357771091704,
      "loss": 3.1447,
      "step": 28390
    },
    {
      "epoch": 1.2223465610742876,
      "grad_norm": 0.9395167827606201,
      "learning_rate": 0.00013413990678088188,
      "loss": 2.9498,
      "step": 28400
    },
    {
      "epoch": 1.2223465610742876,
      "eval_bleu": 26.97050455012666,
      "eval_gen_len": 27.439,
      "eval_loss": 2.803419828414917,
      "eval_runtime": 58.3258,
      "eval_samples_per_second": 17.145,
      "eval_steps_per_second": 1.08,
      "step": 28400
    },
    {
      "epoch": 1.2227769647929758,
      "grad_norm": 0.9897380471229553,
      "learning_rate": 0.00013409622847961272,
      "loss": 3.0583,
      "step": 28410
    },
    {
      "epoch": 1.223207368511664,
      "grad_norm": 0.8991509675979614,
      "learning_rate": 0.0001340525428165403,
      "loss": 3.0915,
      "step": 28420
    },
    {
      "epoch": 1.2236377722303522,
      "grad_norm": 0.8868342041969299,
      "learning_rate": 0.00013400884980109686,
      "loss": 3.0059,
      "step": 28430
    },
    {
      "epoch": 1.2240681759490402,
      "grad_norm": 0.8891673684120178,
      "learning_rate": 0.0001339651494427163,
      "loss": 3.0216,
      "step": 28440
    },
    {
      "epoch": 1.2244985796677283,
      "grad_norm": 0.9310041666030884,
      "learning_rate": 0.00013392144175083408,
      "loss": 3.0111,
      "step": 28450
    },
    {
      "epoch": 1.2244985796677283,
      "eval_bleu": 27.316976824077912,
      "eval_gen_len": 27.498,
      "eval_loss": 2.8042051792144775,
      "eval_runtime": 58.6295,
      "eval_samples_per_second": 17.056,
      "eval_steps_per_second": 1.075,
      "step": 28450
    },
    {
      "epoch": 1.2249289833864165,
      "grad_norm": 0.8898471593856812,
      "learning_rate": 0.0001338777267348872,
      "loss": 3.0439,
      "step": 28460
    },
    {
      "epoch": 1.2253593871051045,
      "grad_norm": 0.9456202387809753,
      "learning_rate": 0.00013383400440431436,
      "loss": 3.001,
      "step": 28470
    },
    {
      "epoch": 1.2257897908237927,
      "grad_norm": 0.9184179902076721,
      "learning_rate": 0.00013379027476855562,
      "loss": 2.9812,
      "step": 28480
    },
    {
      "epoch": 1.2262201945424809,
      "grad_norm": 0.9332661032676697,
      "learning_rate": 0.0001337465378370529,
      "loss": 2.9732,
      "step": 28490
    },
    {
      "epoch": 1.226650598261169,
      "grad_norm": 0.942807137966156,
      "learning_rate": 0.00013370279361924947,
      "loss": 3.1352,
      "step": 28500
    },
    {
      "epoch": 1.226650598261169,
      "eval_bleu": 27.16341427596264,
      "eval_gen_len": 27.478,
      "eval_loss": 2.804107189178467,
      "eval_runtime": 58.4649,
      "eval_samples_per_second": 17.104,
      "eval_steps_per_second": 1.078,
      "step": 28500
    },
    {
      "epoch": 1.227081001979857,
      "grad_norm": 0.9866600632667542,
      "learning_rate": 0.00013365904212459028,
      "loss": 3.0285,
      "step": 28510
    },
    {
      "epoch": 1.2275114056985452,
      "grad_norm": 0.9988558888435364,
      "learning_rate": 0.00013361528336252183,
      "loss": 3.0216,
      "step": 28520
    },
    {
      "epoch": 1.2279418094172334,
      "grad_norm": 1.0266865491867065,
      "learning_rate": 0.00013357151734249217,
      "loss": 3.0968,
      "step": 28530
    },
    {
      "epoch": 1.2283722131359216,
      "grad_norm": 0.9493260383605957,
      "learning_rate": 0.00013352774407395096,
      "loss": 3.0019,
      "step": 28540
    },
    {
      "epoch": 1.2288026168546096,
      "grad_norm": 0.8272375464439392,
      "learning_rate": 0.00013348396356634935,
      "loss": 2.9641,
      "step": 28550
    },
    {
      "epoch": 1.2288026168546096,
      "eval_bleu": 27.22882993163256,
      "eval_gen_len": 27.422,
      "eval_loss": 2.8038089275360107,
      "eval_runtime": 58.1417,
      "eval_samples_per_second": 17.199,
      "eval_steps_per_second": 1.084,
      "step": 28550
    },
    {
      "epoch": 1.2292330205732978,
      "grad_norm": 0.9111949801445007,
      "learning_rate": 0.00013344017582914017,
      "loss": 3.0458,
      "step": 28560
    },
    {
      "epoch": 1.229663424291986,
      "grad_norm": 0.9360350966453552,
      "learning_rate": 0.00013339638087177765,
      "loss": 3.024,
      "step": 28570
    },
    {
      "epoch": 1.230093828010674,
      "grad_norm": 0.7905888557434082,
      "learning_rate": 0.00013335257870371775,
      "loss": 2.9854,
      "step": 28580
    },
    {
      "epoch": 1.230524231729362,
      "grad_norm": 1.0477997064590454,
      "learning_rate": 0.0001333087693344179,
      "loss": 3.0566,
      "step": 28590
    },
    {
      "epoch": 1.2309546354480503,
      "grad_norm": 0.7739883065223694,
      "learning_rate": 0.00013326495277333705,
      "loss": 2.9493,
      "step": 28600
    },
    {
      "epoch": 1.2309546354480503,
      "eval_bleu": 27.083549302306853,
      "eval_gen_len": 27.503,
      "eval_loss": 2.800920009613037,
      "eval_runtime": 58.6928,
      "eval_samples_per_second": 17.038,
      "eval_steps_per_second": 1.073,
      "step": 28600
    },
    {
      "epoch": 1.2313850391667385,
      "grad_norm": 0.9705886244773865,
      "learning_rate": 0.00013322112902993576,
      "loss": 3.0368,
      "step": 28610
    },
    {
      "epoch": 1.2318154428854264,
      "grad_norm": 0.7454349994659424,
      "learning_rate": 0.00013317729811367614,
      "loss": 2.9846,
      "step": 28620
    },
    {
      "epoch": 1.2322458466041146,
      "grad_norm": 0.951883852481842,
      "learning_rate": 0.00013313346003402185,
      "loss": 3.0028,
      "step": 28630
    },
    {
      "epoch": 1.2326762503228028,
      "grad_norm": 0.8397554159164429,
      "learning_rate": 0.00013308961480043804,
      "loss": 3.0754,
      "step": 28640
    },
    {
      "epoch": 1.233106654041491,
      "grad_norm": 0.9444931745529175,
      "learning_rate": 0.00013304576242239145,
      "loss": 3.0709,
      "step": 28650
    },
    {
      "epoch": 1.233106654041491,
      "eval_bleu": 27.026832076181723,
      "eval_gen_len": 27.51,
      "eval_loss": 2.803402900695801,
      "eval_runtime": 58.3948,
      "eval_samples_per_second": 17.125,
      "eval_steps_per_second": 1.079,
      "step": 28650
    },
    {
      "epoch": 1.233537057760179,
      "grad_norm": 0.8996413350105286,
      "learning_rate": 0.00013300190290935036,
      "loss": 3.0624,
      "step": 28660
    },
    {
      "epoch": 1.2339674614788672,
      "grad_norm": 0.8962480425834656,
      "learning_rate": 0.00013295803627078466,
      "loss": 3.0023,
      "step": 28670
    },
    {
      "epoch": 1.2343978651975553,
      "grad_norm": 0.953238844871521,
      "learning_rate": 0.00013291416251616557,
      "loss": 3.0646,
      "step": 28680
    },
    {
      "epoch": 1.2348282689162435,
      "grad_norm": 0.9146140813827515,
      "learning_rate": 0.0001328702816549661,
      "loss": 2.9939,
      "step": 28690
    },
    {
      "epoch": 1.2352586726349315,
      "grad_norm": 0.8393023014068604,
      "learning_rate": 0.00013282639369666065,
      "loss": 2.9538,
      "step": 28700
    },
    {
      "epoch": 1.2352586726349315,
      "eval_bleu": 27.087010244520346,
      "eval_gen_len": 27.339,
      "eval_loss": 2.799456834793091,
      "eval_runtime": 57.8172,
      "eval_samples_per_second": 17.296,
      "eval_steps_per_second": 1.09,
      "step": 28700
    },
    {
      "epoch": 1.2356890763536197,
      "grad_norm": 0.991561233997345,
      "learning_rate": 0.00013278249865072517,
      "loss": 2.9993,
      "step": 28710
    },
    {
      "epoch": 1.2361194800723079,
      "grad_norm": 0.9046757221221924,
      "learning_rate": 0.00013273859652663717,
      "loss": 3.1043,
      "step": 28720
    },
    {
      "epoch": 1.236549883790996,
      "grad_norm": 0.8675528168678284,
      "learning_rate": 0.00013269468733387562,
      "loss": 3.0952,
      "step": 28730
    },
    {
      "epoch": 1.236980287509684,
      "grad_norm": 0.8408423662185669,
      "learning_rate": 0.0001326507710819211,
      "loss": 3.0083,
      "step": 28740
    },
    {
      "epoch": 1.2374106912283722,
      "grad_norm": 0.9614627361297607,
      "learning_rate": 0.00013260684778025568,
      "loss": 3.1125,
      "step": 28750
    },
    {
      "epoch": 1.2374106912283722,
      "eval_bleu": 27.300771920009193,
      "eval_gen_len": 27.466,
      "eval_loss": 2.7999825477600098,
      "eval_runtime": 58.3626,
      "eval_samples_per_second": 17.134,
      "eval_steps_per_second": 1.079,
      "step": 28750
    },
    {
      "epoch": 1.2378410949470604,
      "grad_norm": 0.8860646486282349,
      "learning_rate": 0.00013256291743836296,
      "loss": 2.9744,
      "step": 28760
    },
    {
      "epoch": 1.2382714986657484,
      "grad_norm": 0.9730126857757568,
      "learning_rate": 0.00013251898006572802,
      "loss": 3.027,
      "step": 28770
    },
    {
      "epoch": 1.2387019023844366,
      "grad_norm": 0.9834538102149963,
      "learning_rate": 0.00013247503567183748,
      "loss": 3.1313,
      "step": 28780
    },
    {
      "epoch": 1.2391323061031247,
      "grad_norm": 0.8585113883018494,
      "learning_rate": 0.00013243108426617956,
      "loss": 3.0332,
      "step": 28790
    },
    {
      "epoch": 1.239562709821813,
      "grad_norm": 0.8377330899238586,
      "learning_rate": 0.00013238712585824386,
      "loss": 3.0267,
      "step": 28800
    },
    {
      "epoch": 1.239562709821813,
      "eval_bleu": 26.86360344438843,
      "eval_gen_len": 27.441,
      "eval_loss": 2.8021059036254883,
      "eval_runtime": 58.5262,
      "eval_samples_per_second": 17.086,
      "eval_steps_per_second": 1.076,
      "step": 28800
    },
    {
      "epoch": 1.239993113540501,
      "grad_norm": 0.8511685729026794,
      "learning_rate": 0.00013234316045752158,
      "loss": 2.942,
      "step": 28810
    },
    {
      "epoch": 1.240423517259189,
      "grad_norm": 1.0085991621017456,
      "learning_rate": 0.00013229918807350537,
      "loss": 2.9721,
      "step": 28820
    },
    {
      "epoch": 1.2408539209778773,
      "grad_norm": 0.8660999536514282,
      "learning_rate": 0.0001322552087156894,
      "loss": 2.9526,
      "step": 28830
    },
    {
      "epoch": 1.2412843246965655,
      "grad_norm": 1.0567548274993896,
      "learning_rate": 0.0001322112223935695,
      "loss": 3.0125,
      "step": 28840
    },
    {
      "epoch": 1.2417147284152534,
      "grad_norm": 0.8684208393096924,
      "learning_rate": 0.0001321672291166427,
      "loss": 3.0541,
      "step": 28850
    },
    {
      "epoch": 1.2417147284152534,
      "eval_bleu": 27.108160799294932,
      "eval_gen_len": 27.478,
      "eval_loss": 2.80001163482666,
      "eval_runtime": 58.3748,
      "eval_samples_per_second": 17.131,
      "eval_steps_per_second": 1.079,
      "step": 28850
    },
    {
      "epoch": 1.2421451321339416,
      "grad_norm": 0.8516762852668762,
      "learning_rate": 0.00013212322889440776,
      "loss": 3.0088,
      "step": 28860
    },
    {
      "epoch": 1.2425755358526298,
      "grad_norm": 0.9194235801696777,
      "learning_rate": 0.0001320792217363649,
      "loss": 3.023,
      "step": 28870
    },
    {
      "epoch": 1.2430059395713178,
      "grad_norm": 0.9018391370773315,
      "learning_rate": 0.0001320352076520158,
      "loss": 3.0429,
      "step": 28880
    },
    {
      "epoch": 1.243436343290006,
      "grad_norm": 0.9227842092514038,
      "learning_rate": 0.0001319911866508637,
      "loss": 2.98,
      "step": 28890
    },
    {
      "epoch": 1.2438667470086942,
      "grad_norm": 0.8880703449249268,
      "learning_rate": 0.0001319471587424132,
      "loss": 3.0802,
      "step": 28900
    },
    {
      "epoch": 1.2438667470086942,
      "eval_bleu": 27.04353266865148,
      "eval_gen_len": 27.449,
      "eval_loss": 2.8021042346954346,
      "eval_runtime": 58.6764,
      "eval_samples_per_second": 17.043,
      "eval_steps_per_second": 1.074,
      "step": 28900
    },
    {
      "epoch": 1.2442971507273823,
      "grad_norm": 0.8702956438064575,
      "learning_rate": 0.00013190312393617052,
      "loss": 2.987,
      "step": 28910
    },
    {
      "epoch": 1.2447275544460705,
      "grad_norm": 0.8951894640922546,
      "learning_rate": 0.00013185908224164339,
      "loss": 2.9798,
      "step": 28920
    },
    {
      "epoch": 1.2451579581647585,
      "grad_norm": 0.8979642391204834,
      "learning_rate": 0.00013181503366834084,
      "loss": 2.987,
      "step": 28930
    },
    {
      "epoch": 1.2455883618834467,
      "grad_norm": 0.9319269061088562,
      "learning_rate": 0.0001317709782257736,
      "loss": 2.9396,
      "step": 28940
    },
    {
      "epoch": 1.2460187656021349,
      "grad_norm": 0.9412586092948914,
      "learning_rate": 0.00013172691592345376,
      "loss": 3.0619,
      "step": 28950
    },
    {
      "epoch": 1.2460187656021349,
      "eval_bleu": 26.648293895681643,
      "eval_gen_len": 27.436,
      "eval_loss": 2.801889181137085,
      "eval_runtime": 58.9468,
      "eval_samples_per_second": 16.964,
      "eval_steps_per_second": 1.069,
      "step": 28950
    },
    {
      "epoch": 1.2464491693208228,
      "grad_norm": 0.9163965582847595,
      "learning_rate": 0.00013168284677089493,
      "loss": 2.9765,
      "step": 28960
    },
    {
      "epoch": 1.246879573039511,
      "grad_norm": 0.887519359588623,
      "learning_rate": 0.00013163877077761218,
      "loss": 3.0622,
      "step": 28970
    },
    {
      "epoch": 1.2473099767581992,
      "grad_norm": 0.9585708379745483,
      "learning_rate": 0.00013159468795312208,
      "loss": 3.0661,
      "step": 28980
    },
    {
      "epoch": 1.2477403804768874,
      "grad_norm": 0.9235091805458069,
      "learning_rate": 0.00013155059830694267,
      "loss": 3.1242,
      "step": 28990
    },
    {
      "epoch": 1.2481707841955754,
      "grad_norm": 0.9698060750961304,
      "learning_rate": 0.0001315065018485935,
      "loss": 2.9736,
      "step": 29000
    },
    {
      "epoch": 1.2481707841955754,
      "eval_bleu": 26.95678540213409,
      "eval_gen_len": 27.427,
      "eval_loss": 2.8006467819213867,
      "eval_runtime": 59.0318,
      "eval_samples_per_second": 16.94,
      "eval_steps_per_second": 1.067,
      "step": 29000
    },
    {
      "epoch": 1.2486011879142636,
      "grad_norm": 0.8448758721351624,
      "learning_rate": 0.00013146239858759546,
      "loss": 3.0046,
      "step": 29010
    },
    {
      "epoch": 1.2490315916329517,
      "grad_norm": 1.0941566228866577,
      "learning_rate": 0.00013141828853347102,
      "loss": 2.9975,
      "step": 29020
    },
    {
      "epoch": 1.24946199535164,
      "grad_norm": 0.9017223119735718,
      "learning_rate": 0.00013137417169574415,
      "loss": 2.9364,
      "step": 29030
    },
    {
      "epoch": 1.249892399070328,
      "grad_norm": 0.962057888507843,
      "learning_rate": 0.00013133004808394015,
      "loss": 3.1388,
      "step": 29040
    },
    {
      "epoch": 1.250322802789016,
      "grad_norm": 0.9794290065765381,
      "learning_rate": 0.00013128591770758595,
      "loss": 2.9663,
      "step": 29050
    },
    {
      "epoch": 1.250322802789016,
      "eval_bleu": 27.21647081345242,
      "eval_gen_len": 27.612,
      "eval_loss": 2.798691987991333,
      "eval_runtime": 58.8852,
      "eval_samples_per_second": 16.982,
      "eval_steps_per_second": 1.07,
      "step": 29050
    },
    {
      "epoch": 1.2507532065077043,
      "grad_norm": 0.8578888773918152,
      "learning_rate": 0.00013124178057620977,
      "loss": 3.0538,
      "step": 29060
    },
    {
      "epoch": 1.2511836102263922,
      "grad_norm": 1.046947956085205,
      "learning_rate": 0.00013119763669934141,
      "loss": 3.0559,
      "step": 29070
    },
    {
      "epoch": 1.2516140139450804,
      "grad_norm": 0.9146355390548706,
      "learning_rate": 0.0001311534860865121,
      "loss": 3.0643,
      "step": 29080
    },
    {
      "epoch": 1.2520444176637686,
      "grad_norm": 0.9236950874328613,
      "learning_rate": 0.00013110932874725448,
      "loss": 2.9403,
      "step": 29090
    },
    {
      "epoch": 1.2524748213824568,
      "grad_norm": 0.9020147919654846,
      "learning_rate": 0.0001310651646911027,
      "loss": 3.0813,
      "step": 29100
    },
    {
      "epoch": 1.2524748213824568,
      "eval_bleu": 26.79021471797173,
      "eval_gen_len": 27.47,
      "eval_loss": 2.8019983768463135,
      "eval_runtime": 58.6464,
      "eval_samples_per_second": 17.051,
      "eval_steps_per_second": 1.074,
      "step": 29100
    },
    {
      "epoch": 1.252905225101145,
      "grad_norm": 0.9745152592658997,
      "learning_rate": 0.00013102099392759228,
      "loss": 3.0919,
      "step": 29110
    },
    {
      "epoch": 1.253335628819833,
      "grad_norm": 0.8252161741256714,
      "learning_rate": 0.0001309768164662603,
      "loss": 2.946,
      "step": 29120
    },
    {
      "epoch": 1.2537660325385211,
      "grad_norm": 0.9325058460235596,
      "learning_rate": 0.0001309326323166452,
      "loss": 3.0042,
      "step": 29130
    },
    {
      "epoch": 1.2541964362572093,
      "grad_norm": 1.0872722864151,
      "learning_rate": 0.00013088844148828689,
      "loss": 2.9962,
      "step": 29140
    },
    {
      "epoch": 1.2546268399758973,
      "grad_norm": 0.970999002456665,
      "learning_rate": 0.00013084424399072673,
      "loss": 3.0204,
      "step": 29150
    },
    {
      "epoch": 1.2546268399758973,
      "eval_bleu": 26.80947953643406,
      "eval_gen_len": 27.391,
      "eval_loss": 2.8031320571899414,
      "eval_runtime": 58.2633,
      "eval_samples_per_second": 17.163,
      "eval_steps_per_second": 1.081,
      "step": 29150
    },
    {
      "epoch": 1.2550572436945855,
      "grad_norm": 1.0173295736312866,
      "learning_rate": 0.0001308000398335076,
      "loss": 3.1441,
      "step": 29160
    },
    {
      "epoch": 1.2554876474132737,
      "grad_norm": 0.9923445582389832,
      "learning_rate": 0.0001307558290261736,
      "loss": 2.9975,
      "step": 29170
    },
    {
      "epoch": 1.2559180511319616,
      "grad_norm": 1.0198296308517456,
      "learning_rate": 0.0001307116115782704,
      "loss": 3.0642,
      "step": 29180
    },
    {
      "epoch": 1.2563484548506498,
      "grad_norm": 1.0068387985229492,
      "learning_rate": 0.0001306673874993452,
      "loss": 3.0275,
      "step": 29190
    },
    {
      "epoch": 1.256778858569338,
      "grad_norm": 0.8709439635276794,
      "learning_rate": 0.00013062315679894648,
      "loss": 3.1215,
      "step": 29200
    },
    {
      "epoch": 1.256778858569338,
      "eval_bleu": 26.62407637300473,
      "eval_gen_len": 27.471,
      "eval_loss": 2.804699659347534,
      "eval_runtime": 58.6733,
      "eval_samples_per_second": 17.044,
      "eval_steps_per_second": 1.074,
      "step": 29200
    },
    {
      "epoch": 1.2572092622880262,
      "grad_norm": 0.814208984375,
      "learning_rate": 0.00013057891948662416,
      "loss": 3.0267,
      "step": 29210
    },
    {
      "epoch": 1.2576396660067144,
      "grad_norm": 0.9784443378448486,
      "learning_rate": 0.00013053467557192972,
      "loss": 3.0253,
      "step": 29220
    },
    {
      "epoch": 1.2580700697254024,
      "grad_norm": 0.9416245818138123,
      "learning_rate": 0.0001304904250644159,
      "loss": 3.0482,
      "step": 29230
    },
    {
      "epoch": 1.2585004734440906,
      "grad_norm": 0.8890315890312195,
      "learning_rate": 0.00013044616797363697,
      "loss": 2.9295,
      "step": 29240
    },
    {
      "epoch": 1.2589308771627787,
      "grad_norm": 0.8090717792510986,
      "learning_rate": 0.00013040190430914863,
      "loss": 2.938,
      "step": 29250
    },
    {
      "epoch": 1.2589308771627787,
      "eval_bleu": 26.957340223001463,
      "eval_gen_len": 27.421,
      "eval_loss": 2.8020269870758057,
      "eval_runtime": 58.8752,
      "eval_samples_per_second": 16.985,
      "eval_steps_per_second": 1.07,
      "step": 29250
    },
    {
      "epoch": 1.2593612808814667,
      "grad_norm": 0.9427603483200073,
      "learning_rate": 0.0001303576340805079,
      "loss": 3.1064,
      "step": 29260
    },
    {
      "epoch": 1.259791684600155,
      "grad_norm": 0.9752861261367798,
      "learning_rate": 0.0001303133572972733,
      "loss": 2.9733,
      "step": 29270
    },
    {
      "epoch": 1.260222088318843,
      "grad_norm": 0.8988770246505737,
      "learning_rate": 0.00013026907396900477,
      "loss": 2.9592,
      "step": 29280
    },
    {
      "epoch": 1.2606524920375313,
      "grad_norm": 1.0505824089050293,
      "learning_rate": 0.00013022478410526357,
      "loss": 3.0213,
      "step": 29290
    },
    {
      "epoch": 1.2610828957562195,
      "grad_norm": 0.900547444820404,
      "learning_rate": 0.00013018048771561247,
      "loss": 2.9727,
      "step": 29300
    },
    {
      "epoch": 1.2610828957562195,
      "eval_bleu": 27.1480050841414,
      "eval_gen_len": 27.532,
      "eval_loss": 2.800710916519165,
      "eval_runtime": 58.7345,
      "eval_samples_per_second": 17.026,
      "eval_steps_per_second": 1.073,
      "step": 29300
    },
    {
      "epoch": 1.2615132994749074,
      "grad_norm": 1.0005825757980347,
      "learning_rate": 0.00013013618480961562,
      "loss": 3.0553,
      "step": 29310
    },
    {
      "epoch": 1.2619437031935956,
      "grad_norm": 0.8795276880264282,
      "learning_rate": 0.00013009187539683858,
      "loss": 2.968,
      "step": 29320
    },
    {
      "epoch": 1.2623741069122838,
      "grad_norm": 0.9676612019538879,
      "learning_rate": 0.0001300475594868483,
      "loss": 2.9837,
      "step": 29330
    },
    {
      "epoch": 1.2628045106309718,
      "grad_norm": 1.0016595125198364,
      "learning_rate": 0.00013000323708921315,
      "loss": 2.9794,
      "step": 29340
    },
    {
      "epoch": 1.26323491434966,
      "grad_norm": 0.996882975101471,
      "learning_rate": 0.0001299589082135029,
      "loss": 3.1405,
      "step": 29350
    },
    {
      "epoch": 1.26323491434966,
      "eval_bleu": 27.056513578386976,
      "eval_gen_len": 27.523,
      "eval_loss": 2.8039073944091797,
      "eval_runtime": 58.7798,
      "eval_samples_per_second": 17.013,
      "eval_steps_per_second": 1.072,
      "step": 29350
    },
    {
      "epoch": 1.2636653180683481,
      "grad_norm": 0.9803366661071777,
      "learning_rate": 0.00012991457286928867,
      "loss": 3.154,
      "step": 29360
    },
    {
      "epoch": 1.264095721787036,
      "grad_norm": 0.8773493766784668,
      "learning_rate": 0.00012987023106614305,
      "loss": 3.0147,
      "step": 29370
    },
    {
      "epoch": 1.2645261255057243,
      "grad_norm": 0.9171867370605469,
      "learning_rate": 0.00012982588281364,
      "loss": 3.0199,
      "step": 29380
    },
    {
      "epoch": 1.2649565292244125,
      "grad_norm": 0.9447789788246155,
      "learning_rate": 0.00012978152812135482,
      "loss": 3.0898,
      "step": 29390
    },
    {
      "epoch": 1.2653869329431007,
      "grad_norm": 0.9267942309379578,
      "learning_rate": 0.00012973716699886428,
      "loss": 3.0247,
      "step": 29400
    },
    {
      "epoch": 1.2653869329431007,
      "eval_bleu": 27.159065915313224,
      "eval_gen_len": 27.525,
      "eval_loss": 2.8038218021392822,
      "eval_runtime": 58.9101,
      "eval_samples_per_second": 16.975,
      "eval_steps_per_second": 1.069,
      "step": 29400
    },
    {
      "epoch": 1.2658173366617889,
      "grad_norm": 0.9170032143592834,
      "learning_rate": 0.0001296927994557465,
      "loss": 2.9866,
      "step": 29410
    },
    {
      "epoch": 1.2662477403804768,
      "grad_norm": 0.8801712393760681,
      "learning_rate": 0.00012964842550158094,
      "loss": 2.9607,
      "step": 29420
    },
    {
      "epoch": 1.266678144099165,
      "grad_norm": 0.9253548383712769,
      "learning_rate": 0.00012960404514594857,
      "loss": 3.1098,
      "step": 29430
    },
    {
      "epoch": 1.2671085478178532,
      "grad_norm": 0.9998061656951904,
      "learning_rate": 0.00012955965839843162,
      "loss": 2.9614,
      "step": 29440
    },
    {
      "epoch": 1.2675389515365412,
      "grad_norm": 0.9710481762886047,
      "learning_rate": 0.00012951526526861377,
      "loss": 3.0649,
      "step": 29450
    },
    {
      "epoch": 1.2675389515365412,
      "eval_bleu": 27.22745837405827,
      "eval_gen_len": 27.416,
      "eval_loss": 2.80505108833313,
      "eval_runtime": 58.38,
      "eval_samples_per_second": 17.129,
      "eval_steps_per_second": 1.079,
      "step": 29450
    },
    {
      "epoch": 1.2679693552552294,
      "grad_norm": 0.9180364608764648,
      "learning_rate": 0.00012947086576608002,
      "loss": 3.0272,
      "step": 29460
    },
    {
      "epoch": 1.2683997589739175,
      "grad_norm": 0.9228707551956177,
      "learning_rate": 0.00012942645990041683,
      "loss": 3.0489,
      "step": 29470
    },
    {
      "epoch": 1.2688301626926057,
      "grad_norm": 0.912753701210022,
      "learning_rate": 0.0001293820476812119,
      "loss": 3.0276,
      "step": 29480
    },
    {
      "epoch": 1.269260566411294,
      "grad_norm": 0.9329215884208679,
      "learning_rate": 0.00012933762911805448,
      "loss": 3.124,
      "step": 29490
    },
    {
      "epoch": 1.2696909701299819,
      "grad_norm": 0.9258515238761902,
      "learning_rate": 0.00012929320422053504,
      "loss": 3.0902,
      "step": 29500
    },
    {
      "epoch": 1.2696909701299819,
      "eval_bleu": 27.226108860994838,
      "eval_gen_len": 27.452,
      "eval_loss": 2.8015286922454834,
      "eval_runtime": 58.6731,
      "eval_samples_per_second": 17.044,
      "eval_steps_per_second": 1.074,
      "step": 29500
    },
    {
      "epoch": 1.27012137384867,
      "grad_norm": 0.9167565107345581,
      "learning_rate": 0.00012924877299824546,
      "loss": 2.995,
      "step": 29510
    },
    {
      "epoch": 1.2705517775673583,
      "grad_norm": 0.969182550907135,
      "learning_rate": 0.00012920433546077903,
      "loss": 3.0296,
      "step": 29520
    },
    {
      "epoch": 1.2709821812860462,
      "grad_norm": 0.9295341968536377,
      "learning_rate": 0.0001291598916177304,
      "loss": 3.0869,
      "step": 29530
    },
    {
      "epoch": 1.2714125850047344,
      "grad_norm": 0.9005464911460876,
      "learning_rate": 0.00012911544147869547,
      "loss": 3.0486,
      "step": 29540
    },
    {
      "epoch": 1.2718429887234226,
      "grad_norm": 0.8835427165031433,
      "learning_rate": 0.00012907098505327165,
      "loss": 3.0655,
      "step": 29550
    },
    {
      "epoch": 1.2718429887234226,
      "eval_bleu": 26.272007664182297,
      "eval_gen_len": 27.468,
      "eval_loss": 2.8084754943847656,
      "eval_runtime": 58.6179,
      "eval_samples_per_second": 17.06,
      "eval_steps_per_second": 1.075,
      "step": 29550
    },
    {
      "epoch": 1.2722733924421106,
      "grad_norm": 0.8700810670852661,
      "learning_rate": 0.0001290265223510576,
      "loss": 3.042,
      "step": 29560
    },
    {
      "epoch": 1.2727037961607988,
      "grad_norm": 0.9093247652053833,
      "learning_rate": 0.00012898205338165343,
      "loss": 3.099,
      "step": 29570
    },
    {
      "epoch": 1.273134199879487,
      "grad_norm": 0.8963387608528137,
      "learning_rate": 0.0001289375781546605,
      "loss": 2.935,
      "step": 29580
    },
    {
      "epoch": 1.2735646035981751,
      "grad_norm": 0.8533034324645996,
      "learning_rate": 0.00012889309667968158,
      "loss": 2.9867,
      "step": 29590
    },
    {
      "epoch": 1.2739950073168633,
      "grad_norm": 0.9311421513557434,
      "learning_rate": 0.00012884860896632077,
      "loss": 3.0177,
      "step": 29600
    },
    {
      "epoch": 1.2739950073168633,
      "eval_bleu": 27.171907510738233,
      "eval_gen_len": 27.367,
      "eval_loss": 2.80289888381958,
      "eval_runtime": 58.1936,
      "eval_samples_per_second": 17.184,
      "eval_steps_per_second": 1.083,
      "step": 29600
    },
    {
      "epoch": 1.2744254110355513,
      "grad_norm": 0.9124325513839722,
      "learning_rate": 0.00012880411502418353,
      "loss": 2.9434,
      "step": 29610
    },
    {
      "epoch": 1.2748558147542395,
      "grad_norm": 0.8815791606903076,
      "learning_rate": 0.00012875961486287664,
      "loss": 2.9801,
      "step": 29620
    },
    {
      "epoch": 1.2752862184729277,
      "grad_norm": 1.0089436769485474,
      "learning_rate": 0.0001287151084920083,
      "loss": 3.0295,
      "step": 29630
    },
    {
      "epoch": 1.2757166221916156,
      "grad_norm": 0.8745969533920288,
      "learning_rate": 0.00012867059592118797,
      "loss": 3.0386,
      "step": 29640
    },
    {
      "epoch": 1.2761470259103038,
      "grad_norm": 0.8640177845954895,
      "learning_rate": 0.00012862607716002643,
      "loss": 3.0093,
      "step": 29650
    },
    {
      "epoch": 1.2761470259103038,
      "eval_bleu": 26.786679697252996,
      "eval_gen_len": 27.575,
      "eval_loss": 2.805652379989624,
      "eval_runtime": 58.6552,
      "eval_samples_per_second": 17.049,
      "eval_steps_per_second": 1.074,
      "step": 29650
    },
    {
      "epoch": 1.276577429628992,
      "grad_norm": 0.8355072736740112,
      "learning_rate": 0.0001285815522181359,
      "loss": 3.0744,
      "step": 29660
    },
    {
      "epoch": 1.2770078333476802,
      "grad_norm": 0.9583775401115417,
      "learning_rate": 0.00012853702110512982,
      "loss": 3.0317,
      "step": 29670
    },
    {
      "epoch": 1.2774382370663684,
      "grad_norm": 0.9332136511802673,
      "learning_rate": 0.00012849248383062304,
      "loss": 2.9739,
      "step": 29680
    },
    {
      "epoch": 1.2778686407850564,
      "grad_norm": 0.9511855244636536,
      "learning_rate": 0.00012844794040423174,
      "loss": 3.1155,
      "step": 29690
    },
    {
      "epoch": 1.2782990445037445,
      "grad_norm": 0.9274440407752991,
      "learning_rate": 0.00012840339083557337,
      "loss": 3.062,
      "step": 29700
    },
    {
      "epoch": 1.2782990445037445,
      "eval_bleu": 27.188185420455348,
      "eval_gen_len": 27.516,
      "eval_loss": 2.806089401245117,
      "eval_runtime": 58.3969,
      "eval_samples_per_second": 17.124,
      "eval_steps_per_second": 1.079,
      "step": 29700
    },
    {
      "epoch": 1.2787294482224327,
      "grad_norm": 0.9798241257667542,
      "learning_rate": 0.00012835883513426675,
      "loss": 3.0898,
      "step": 29710
    },
    {
      "epoch": 1.2791598519411207,
      "grad_norm": 0.9753576517105103,
      "learning_rate": 0.000128314273309932,
      "loss": 3.0402,
      "step": 29720
    },
    {
      "epoch": 1.2795902556598089,
      "grad_norm": 0.9332136511802673,
      "learning_rate": 0.00012826970537219062,
      "loss": 3.0342,
      "step": 29730
    },
    {
      "epoch": 1.280020659378497,
      "grad_norm": 0.7708290219306946,
      "learning_rate": 0.00012822513133066535,
      "loss": 3.0214,
      "step": 29740
    },
    {
      "epoch": 1.280451063097185,
      "grad_norm": 1.0704668760299683,
      "learning_rate": 0.0001281805511949803,
      "loss": 3.0866,
      "step": 29750
    },
    {
      "epoch": 1.280451063097185,
      "eval_bleu": 26.936194231537062,
      "eval_gen_len": 27.504,
      "eval_loss": 2.8064827919006348,
      "eval_runtime": 59.0795,
      "eval_samples_per_second": 16.926,
      "eval_steps_per_second": 1.066,
      "step": 29750
    },
    {
      "epoch": 1.2808814668158732,
      "grad_norm": 0.8608789443969727,
      "learning_rate": 0.00012813596497476086,
      "loss": 2.9553,
      "step": 29760
    },
    {
      "epoch": 1.2813118705345614,
      "grad_norm": 1.0476303100585938,
      "learning_rate": 0.00012809137267963378,
      "loss": 3.0241,
      "step": 29770
    },
    {
      "epoch": 1.2817422742532496,
      "grad_norm": 0.8909686803817749,
      "learning_rate": 0.00012804677431922708,
      "loss": 3.02,
      "step": 29780
    },
    {
      "epoch": 1.2821726779719378,
      "grad_norm": 0.9023210406303406,
      "learning_rate": 0.0001280021699031701,
      "loss": 3.0203,
      "step": 29790
    },
    {
      "epoch": 1.2826030816906258,
      "grad_norm": 0.8830628991127014,
      "learning_rate": 0.00012795755944109352,
      "loss": 3.069,
      "step": 29800
    },
    {
      "epoch": 1.2826030816906258,
      "eval_bleu": 26.906741809002945,
      "eval_gen_len": 27.599,
      "eval_loss": 2.8012020587921143,
      "eval_runtime": 58.6952,
      "eval_samples_per_second": 17.037,
      "eval_steps_per_second": 1.073,
      "step": 29800
    },
    {
      "epoch": 1.283033485409314,
      "grad_norm": 0.895677387714386,
      "learning_rate": 0.00012791294294262924,
      "loss": 3.0678,
      "step": 29810
    },
    {
      "epoch": 1.2834638891280021,
      "grad_norm": 0.9219744801521301,
      "learning_rate": 0.00012786832041741062,
      "loss": 3.0551,
      "step": 29820
    },
    {
      "epoch": 1.28389429284669,
      "grad_norm": 0.9575300216674805,
      "learning_rate": 0.00012782369187507213,
      "loss": 2.9641,
      "step": 29830
    },
    {
      "epoch": 1.2843246965653783,
      "grad_norm": 0.8654351830482483,
      "learning_rate": 0.00012777905732524967,
      "loss": 3.1055,
      "step": 29840
    },
    {
      "epoch": 1.2847551002840665,
      "grad_norm": 0.9510665535926819,
      "learning_rate": 0.0001277344167775804,
      "loss": 3.0823,
      "step": 29850
    },
    {
      "epoch": 1.2847551002840665,
      "eval_bleu": 27.003428896949956,
      "eval_gen_len": 27.429,
      "eval_loss": 2.806386709213257,
      "eval_runtime": 58.3554,
      "eval_samples_per_second": 17.136,
      "eval_steps_per_second": 1.08,
      "step": 29850
    },
    {
      "epoch": 1.2851855040027547,
      "grad_norm": 0.9411402940750122,
      "learning_rate": 0.00012768977024170278,
      "loss": 3.0201,
      "step": 29860
    },
    {
      "epoch": 1.2856159077214426,
      "grad_norm": 0.9386880397796631,
      "learning_rate": 0.00012764511772725648,
      "loss": 3.0015,
      "step": 29870
    },
    {
      "epoch": 1.2860463114401308,
      "grad_norm": 0.9256893992424011,
      "learning_rate": 0.00012760045924388265,
      "loss": 2.973,
      "step": 29880
    },
    {
      "epoch": 1.286476715158819,
      "grad_norm": 0.9131497740745544,
      "learning_rate": 0.0001275557948012236,
      "loss": 3.0647,
      "step": 29890
    },
    {
      "epoch": 1.2869071188775072,
      "grad_norm": 0.8640978336334229,
      "learning_rate": 0.00012751112440892288,
      "loss": 3.0442,
      "step": 29900
    },
    {
      "epoch": 1.2869071188775072,
      "eval_bleu": 27.075284144620454,
      "eval_gen_len": 27.51,
      "eval_loss": 2.80301833152771,
      "eval_runtime": 58.1806,
      "eval_samples_per_second": 17.188,
      "eval_steps_per_second": 1.083,
      "step": 29900
    },
    {
      "epoch": 1.2873375225961952,
      "grad_norm": 0.9795967936515808,
      "learning_rate": 0.00012746644807662543,
      "loss": 3.1158,
      "step": 29910
    },
    {
      "epoch": 1.2877679263148833,
      "grad_norm": 0.9287007451057434,
      "learning_rate": 0.0001274217658139774,
      "loss": 3.0532,
      "step": 29920
    },
    {
      "epoch": 1.2881983300335715,
      "grad_norm": 0.7803946733474731,
      "learning_rate": 0.00012737707763062632,
      "loss": 3.0,
      "step": 29930
    },
    {
      "epoch": 1.2886287337522595,
      "grad_norm": 0.9790818691253662,
      "learning_rate": 0.00012733238353622084,
      "loss": 3.0114,
      "step": 29940
    },
    {
      "epoch": 1.2890591374709477,
      "grad_norm": 0.906661331653595,
      "learning_rate": 0.00012728768354041103,
      "loss": 2.8889,
      "step": 29950
    },
    {
      "epoch": 1.2890591374709477,
      "eval_bleu": 27.1449492028413,
      "eval_gen_len": 27.636,
      "eval_loss": 2.804727554321289,
      "eval_runtime": 58.7675,
      "eval_samples_per_second": 17.016,
      "eval_steps_per_second": 1.072,
      "step": 29950
    },
    {
      "epoch": 1.2894895411896359,
      "grad_norm": 0.9670389890670776,
      "learning_rate": 0.00012724297765284815,
      "loss": 3.1033,
      "step": 29960
    },
    {
      "epoch": 1.289919944908324,
      "grad_norm": 0.920078456401825,
      "learning_rate": 0.00012719826588318482,
      "loss": 3.0248,
      "step": 29970
    },
    {
      "epoch": 1.2903503486270123,
      "grad_norm": 0.9124032258987427,
      "learning_rate": 0.0001271535482410748,
      "loss": 3.0768,
      "step": 29980
    },
    {
      "epoch": 1.2907807523457002,
      "grad_norm": 0.8474282026290894,
      "learning_rate": 0.00012710882473617323,
      "loss": 3.041,
      "step": 29990
    },
    {
      "epoch": 1.2912111560643884,
      "grad_norm": 0.8963813781738281,
      "learning_rate": 0.00012706409537813643,
      "loss": 3.0342,
      "step": 30000
    },
    {
      "epoch": 1.2912111560643884,
      "eval_bleu": 27.32764335796826,
      "eval_gen_len": 27.43,
      "eval_loss": 2.8024790287017822,
      "eval_runtime": 58.1771,
      "eval_samples_per_second": 17.189,
      "eval_steps_per_second": 1.083,
      "step": 30000
    },
    {
      "epoch": 1.2916415597830766,
      "grad_norm": 0.8024893999099731,
      "learning_rate": 0.00012701936017662211,
      "loss": 3.0142,
      "step": 30010
    },
    {
      "epoch": 1.2920719635017646,
      "grad_norm": 0.9209449887275696,
      "learning_rate": 0.00012697461914128912,
      "loss": 3.0922,
      "step": 30020
    },
    {
      "epoch": 1.2925023672204528,
      "grad_norm": 0.8775542974472046,
      "learning_rate": 0.0001269298722817976,
      "loss": 2.9565,
      "step": 30030
    },
    {
      "epoch": 1.292932770939141,
      "grad_norm": 0.8397893309593201,
      "learning_rate": 0.00012688511960780893,
      "loss": 3.0294,
      "step": 30040
    },
    {
      "epoch": 1.293363174657829,
      "grad_norm": 0.7673714756965637,
      "learning_rate": 0.00012684036112898582,
      "loss": 3.0034,
      "step": 30050
    },
    {
      "epoch": 1.293363174657829,
      "eval_bleu": 26.91189108380102,
      "eval_gen_len": 27.507,
      "eval_loss": 2.804133176803589,
      "eval_runtime": 58.9588,
      "eval_samples_per_second": 16.961,
      "eval_steps_per_second": 1.069,
      "step": 30050
    },
    {
      "epoch": 1.293793578376517,
      "grad_norm": 0.9648996591567993,
      "learning_rate": 0.00012679559685499218,
      "loss": 2.9771,
      "step": 30060
    },
    {
      "epoch": 1.2942239820952053,
      "grad_norm": 0.8981042504310608,
      "learning_rate": 0.00012675082679549317,
      "loss": 2.8754,
      "step": 30070
    },
    {
      "epoch": 1.2946543858138935,
      "grad_norm": 0.8798837065696716,
      "learning_rate": 0.00012670605096015523,
      "loss": 2.9927,
      "step": 30080
    },
    {
      "epoch": 1.2950847895325817,
      "grad_norm": 0.9279389977455139,
      "learning_rate": 0.00012666126935864598,
      "loss": 3.0475,
      "step": 30090
    },
    {
      "epoch": 1.2955151932512696,
      "grad_norm": 0.8554937243461609,
      "learning_rate": 0.0001266164820006344,
      "loss": 3.0638,
      "step": 30100
    },
    {
      "epoch": 1.2955151932512696,
      "eval_bleu": 26.653972276945893,
      "eval_gen_len": 27.484,
      "eval_loss": 2.8053576946258545,
      "eval_runtime": 59.6053,
      "eval_samples_per_second": 16.777,
      "eval_steps_per_second": 1.057,
      "step": 30100
    },
    {
      "epoch": 1.2959455969699578,
      "grad_norm": 0.7760918140411377,
      "learning_rate": 0.00012657168889579053,
      "loss": 2.9802,
      "step": 30110
    },
    {
      "epoch": 1.296376000688646,
      "grad_norm": 1.0207722187042236,
      "learning_rate": 0.00012652689005378587,
      "loss": 3.0811,
      "step": 30120
    },
    {
      "epoch": 1.296806404407334,
      "grad_norm": 0.8957392573356628,
      "learning_rate": 0.00012648208548429298,
      "loss": 3.0465,
      "step": 30130
    },
    {
      "epoch": 1.2972368081260222,
      "grad_norm": 0.8662420511245728,
      "learning_rate": 0.00012643727519698577,
      "loss": 3.094,
      "step": 30140
    },
    {
      "epoch": 1.2976672118447103,
      "grad_norm": 1.0928670167922974,
      "learning_rate": 0.00012639245920153936,
      "loss": 3.051,
      "step": 30150
    },
    {
      "epoch": 1.2976672118447103,
      "eval_bleu": 26.50144315329265,
      "eval_gen_len": 27.418,
      "eval_loss": 2.8070130348205566,
      "eval_runtime": 58.2358,
      "eval_samples_per_second": 17.172,
      "eval_steps_per_second": 1.082,
      "step": 30150
    },
    {
      "epoch": 1.2980976155633985,
      "grad_norm": 0.9187106490135193,
      "learning_rate": 0.00012634763750763003,
      "loss": 3.0811,
      "step": 30160
    },
    {
      "epoch": 1.2985280192820867,
      "grad_norm": 0.8638982772827148,
      "learning_rate": 0.00012630281012493535,
      "loss": 3.0674,
      "step": 30170
    },
    {
      "epoch": 1.2989584230007747,
      "grad_norm": 0.8059284687042236,
      "learning_rate": 0.0001262579770631342,
      "loss": 3.0232,
      "step": 30180
    },
    {
      "epoch": 1.2993888267194629,
      "grad_norm": 0.9295918345451355,
      "learning_rate": 0.00012621313833190652,
      "loss": 2.9871,
      "step": 30190
    },
    {
      "epoch": 1.299819230438151,
      "grad_norm": 1.009130597114563,
      "learning_rate": 0.00012616829394093354,
      "loss": 3.0175,
      "step": 30200
    },
    {
      "epoch": 1.299819230438151,
      "eval_bleu": 26.845176795265544,
      "eval_gen_len": 27.525,
      "eval_loss": 2.801274299621582,
      "eval_runtime": 58.2526,
      "eval_samples_per_second": 17.167,
      "eval_steps_per_second": 1.081,
      "step": 30200
    },
    {
      "epoch": 1.300249634156839,
      "grad_norm": 0.9509523510932922,
      "learning_rate": 0.00012612344389989778,
      "loss": 3.0533,
      "step": 30210
    },
    {
      "epoch": 1.3006800378755272,
      "grad_norm": 0.8022591471672058,
      "learning_rate": 0.0001260785882184829,
      "loss": 2.9589,
      "step": 30220
    },
    {
      "epoch": 1.3011104415942154,
      "grad_norm": 0.9287350177764893,
      "learning_rate": 0.00012603372690637383,
      "loss": 3.029,
      "step": 30230
    },
    {
      "epoch": 1.3015408453129034,
      "grad_norm": 0.9925172924995422,
      "learning_rate": 0.00012598885997325661,
      "loss": 2.923,
      "step": 30240
    },
    {
      "epoch": 1.3019712490315916,
      "grad_norm": 0.8681062459945679,
      "learning_rate": 0.00012594398742881867,
      "loss": 3.0789,
      "step": 30250
    },
    {
      "epoch": 1.3019712490315916,
      "eval_bleu": 26.608301942103925,
      "eval_gen_len": 27.659,
      "eval_loss": 2.803636312484741,
      "eval_runtime": 58.9231,
      "eval_samples_per_second": 16.971,
      "eval_steps_per_second": 1.069,
      "step": 30250
    },
    {
      "epoch": 1.3024016527502797,
      "grad_norm": 0.987059473991394,
      "learning_rate": 0.00012589910928274852,
      "loss": 3.0733,
      "step": 30260
    },
    {
      "epoch": 1.302832056468968,
      "grad_norm": 0.8638865351676941,
      "learning_rate": 0.00012585422554473591,
      "loss": 3.1301,
      "step": 30270
    },
    {
      "epoch": 1.3032624601876561,
      "grad_norm": 0.8920378684997559,
      "learning_rate": 0.0001258093362244718,
      "loss": 2.938,
      "step": 30280
    },
    {
      "epoch": 1.303692863906344,
      "grad_norm": 0.946753978729248,
      "learning_rate": 0.00012576444133164836,
      "loss": 3.013,
      "step": 30290
    },
    {
      "epoch": 1.3041232676250323,
      "grad_norm": 1.037473440170288,
      "learning_rate": 0.00012571954087595895,
      "loss": 2.9711,
      "step": 30300
    },
    {
      "epoch": 1.3041232676250323,
      "eval_bleu": 27.122514989728952,
      "eval_gen_len": 27.517,
      "eval_loss": 2.8002281188964844,
      "eval_runtime": 59.0006,
      "eval_samples_per_second": 16.949,
      "eval_steps_per_second": 1.068,
      "step": 30300
    },
    {
      "epoch": 1.3045536713437205,
      "grad_norm": 0.8971350193023682,
      "learning_rate": 0.00012567463486709817,
      "loss": 3.0222,
      "step": 30310
    },
    {
      "epoch": 1.3049840750624084,
      "grad_norm": 0.8528273105621338,
      "learning_rate": 0.00012562972331476178,
      "loss": 2.9713,
      "step": 30320
    },
    {
      "epoch": 1.3054144787810966,
      "grad_norm": 0.8354599475860596,
      "learning_rate": 0.0001255848062286467,
      "loss": 2.9415,
      "step": 30330
    },
    {
      "epoch": 1.3058448824997848,
      "grad_norm": 0.9286044239997864,
      "learning_rate": 0.00012553988361845115,
      "loss": 2.9331,
      "step": 30340
    },
    {
      "epoch": 1.306275286218473,
      "grad_norm": 0.8510082364082336,
      "learning_rate": 0.00012549495549387448,
      "loss": 3.0026,
      "step": 30350
    },
    {
      "epoch": 1.306275286218473,
      "eval_bleu": 26.781012819938887,
      "eval_gen_len": 27.444,
      "eval_loss": 2.799243688583374,
      "eval_runtime": 58.695,
      "eval_samples_per_second": 17.037,
      "eval_steps_per_second": 1.073,
      "step": 30350
    },
    {
      "epoch": 1.3067056899371612,
      "grad_norm": 0.9059162735939026,
      "learning_rate": 0.0001254500218646172,
      "loss": 3.0581,
      "step": 30360
    },
    {
      "epoch": 1.3071360936558492,
      "grad_norm": 0.9153282046318054,
      "learning_rate": 0.00012540508274038107,
      "loss": 2.9374,
      "step": 30370
    },
    {
      "epoch": 1.3075664973745373,
      "grad_norm": 0.8664606809616089,
      "learning_rate": 0.00012536013813086905,
      "loss": 2.9557,
      "step": 30380
    },
    {
      "epoch": 1.3079969010932255,
      "grad_norm": 0.9478033185005188,
      "learning_rate": 0.00012531518804578514,
      "loss": 3.0525,
      "step": 30390
    },
    {
      "epoch": 1.3084273048119135,
      "grad_norm": 0.9960343241691589,
      "learning_rate": 0.00012527023249483472,
      "loss": 3.0628,
      "step": 30400
    },
    {
      "epoch": 1.3084273048119135,
      "eval_bleu": 26.737818802102026,
      "eval_gen_len": 27.5,
      "eval_loss": 2.8044660091400146,
      "eval_runtime": 58.8553,
      "eval_samples_per_second": 16.991,
      "eval_steps_per_second": 1.07,
      "step": 30400
    },
    {
      "epoch": 1.3088577085306017,
      "grad_norm": 0.8894104361534119,
      "learning_rate": 0.00012522527148772422,
      "loss": 2.9832,
      "step": 30410
    },
    {
      "epoch": 1.3092881122492899,
      "grad_norm": 0.7723125219345093,
      "learning_rate": 0.0001251803050341613,
      "loss": 2.9558,
      "step": 30420
    },
    {
      "epoch": 1.3097185159679778,
      "grad_norm": 0.9477100372314453,
      "learning_rate": 0.00012513533314385475,
      "loss": 3.0403,
      "step": 30430
    },
    {
      "epoch": 1.310148919686666,
      "grad_norm": 0.8689030408859253,
      "learning_rate": 0.0001250903558265146,
      "loss": 3.0754,
      "step": 30440
    },
    {
      "epoch": 1.3105793234053542,
      "grad_norm": 0.784400999546051,
      "learning_rate": 0.00012504537309185202,
      "loss": 3.034,
      "step": 30450
    },
    {
      "epoch": 1.3105793234053542,
      "eval_bleu": 26.75537252928178,
      "eval_gen_len": 27.404,
      "eval_loss": 2.8041889667510986,
      "eval_runtime": 58.515,
      "eval_samples_per_second": 17.09,
      "eval_steps_per_second": 1.077,
      "step": 30450
    },
    {
      "epoch": 1.3110097271240424,
      "grad_norm": 0.8815661668777466,
      "learning_rate": 0.0001250003849495793,
      "loss": 3.0042,
      "step": 30460
    },
    {
      "epoch": 1.3114401308427306,
      "grad_norm": 0.9316522479057312,
      "learning_rate": 0.00012495539140940998,
      "loss": 3.1296,
      "step": 30470
    },
    {
      "epoch": 1.3118705345614186,
      "grad_norm": 0.8482914566993713,
      "learning_rate": 0.00012491039248105877,
      "loss": 2.9464,
      "step": 30480
    },
    {
      "epoch": 1.3123009382801067,
      "grad_norm": 0.9646399021148682,
      "learning_rate": 0.0001248653881742414,
      "loss": 3.0558,
      "step": 30490
    },
    {
      "epoch": 1.312731341998795,
      "grad_norm": 0.9662866592407227,
      "learning_rate": 0.00012482037849867496,
      "loss": 3.0976,
      "step": 30500
    },
    {
      "epoch": 1.312731341998795,
      "eval_bleu": 27.290363753590537,
      "eval_gen_len": 27.528,
      "eval_loss": 2.800231456756592,
      "eval_runtime": 58.3865,
      "eval_samples_per_second": 17.127,
      "eval_steps_per_second": 1.079,
      "step": 30500
    },
    {
      "epoch": 1.313161745717483,
      "grad_norm": 0.9757670760154724,
      "learning_rate": 0.00012477536346407753,
      "loss": 3.0404,
      "step": 30510
    },
    {
      "epoch": 1.313592149436171,
      "grad_norm": 0.9348326921463013,
      "learning_rate": 0.00012473034308016845,
      "loss": 2.8931,
      "step": 30520
    },
    {
      "epoch": 1.3140225531548593,
      "grad_norm": 0.7991319298744202,
      "learning_rate": 0.0001246853173566682,
      "loss": 3.0734,
      "step": 30530
    },
    {
      "epoch": 1.3144529568735475,
      "grad_norm": 0.843647837638855,
      "learning_rate": 0.00012464028630329842,
      "loss": 2.9283,
      "step": 30540
    },
    {
      "epoch": 1.3148833605922357,
      "grad_norm": 0.8151710629463196,
      "learning_rate": 0.0001245952499297818,
      "loss": 2.9502,
      "step": 30550
    },
    {
      "epoch": 1.3148833605922357,
      "eval_bleu": 26.922758657244668,
      "eval_gen_len": 27.43,
      "eval_loss": 2.8029582500457764,
      "eval_runtime": 58.4221,
      "eval_samples_per_second": 17.117,
      "eval_steps_per_second": 1.078,
      "step": 30550
    },
    {
      "epoch": 1.3153137643109236,
      "grad_norm": 0.9710018634796143,
      "learning_rate": 0.00012455020824584236,
      "loss": 2.9983,
      "step": 30560
    },
    {
      "epoch": 1.3157441680296118,
      "grad_norm": 0.8194023966789246,
      "learning_rate": 0.00012450516126120506,
      "loss": 2.993,
      "step": 30570
    },
    {
      "epoch": 1.3161745717483,
      "grad_norm": 0.9138076901435852,
      "learning_rate": 0.00012446010898559622,
      "loss": 3.0294,
      "step": 30580
    },
    {
      "epoch": 1.316604975466988,
      "grad_norm": 0.8965400457382202,
      "learning_rate": 0.00012441505142874308,
      "loss": 3.0836,
      "step": 30590
    },
    {
      "epoch": 1.3170353791856761,
      "grad_norm": 0.9131149053573608,
      "learning_rate": 0.00012436998860037419,
      "loss": 3.0019,
      "step": 30600
    },
    {
      "epoch": 1.3170353791856761,
      "eval_bleu": 27.095084250723865,
      "eval_gen_len": 27.528,
      "eval_loss": 2.798274517059326,
      "eval_runtime": 58.0277,
      "eval_samples_per_second": 17.233,
      "eval_steps_per_second": 1.086,
      "step": 30600
    },
    {
      "epoch": 1.3174657829043643,
      "grad_norm": 0.9153635501861572,
      "learning_rate": 0.00012432492051021914,
      "loss": 3.0803,
      "step": 30610
    },
    {
      "epoch": 1.3178961866230523,
      "grad_norm": 0.9907704591751099,
      "learning_rate": 0.00012427984716800877,
      "loss": 3.066,
      "step": 30620
    },
    {
      "epoch": 1.3183265903417405,
      "grad_norm": 0.9374400973320007,
      "learning_rate": 0.00012423476858347492,
      "loss": 2.9614,
      "step": 30630
    },
    {
      "epoch": 1.3187569940604287,
      "grad_norm": 0.8912307024002075,
      "learning_rate": 0.00012418968476635064,
      "loss": 3.0647,
      "step": 30640
    },
    {
      "epoch": 1.3191873977791169,
      "grad_norm": 1.0455148220062256,
      "learning_rate": 0.00012414459572637009,
      "loss": 2.9389,
      "step": 30650
    },
    {
      "epoch": 1.3191873977791169,
      "eval_bleu": 27.215020785975067,
      "eval_gen_len": 27.591,
      "eval_loss": 2.7997469902038574,
      "eval_runtime": 59.1041,
      "eval_samples_per_second": 16.919,
      "eval_steps_per_second": 1.066,
      "step": 30650
    },
    {
      "epoch": 1.319617801497805,
      "grad_norm": 0.9920504689216614,
      "learning_rate": 0.00012409950147326856,
      "loss": 3.0432,
      "step": 30660
    },
    {
      "epoch": 1.320048205216493,
      "grad_norm": 1.0375405550003052,
      "learning_rate": 0.00012405440201678248,
      "loss": 3.1038,
      "step": 30670
    },
    {
      "epoch": 1.3204786089351812,
      "grad_norm": 0.8624951243400574,
      "learning_rate": 0.00012400929736664936,
      "loss": 2.9931,
      "step": 30680
    },
    {
      "epoch": 1.3209090126538694,
      "grad_norm": 0.8898484706878662,
      "learning_rate": 0.00012396418753260786,
      "loss": 3.0637,
      "step": 30690
    },
    {
      "epoch": 1.3213394163725574,
      "grad_norm": 0.9477168321609497,
      "learning_rate": 0.0001239190725243978,
      "loss": 3.0692,
      "step": 30700
    },
    {
      "epoch": 1.3213394163725574,
      "eval_bleu": 26.984837512930774,
      "eval_gen_len": 27.363,
      "eval_loss": 2.805187463760376,
      "eval_runtime": 58.3338,
      "eval_samples_per_second": 17.143,
      "eval_steps_per_second": 1.08,
      "step": 30700
    },
    {
      "epoch": 1.3217698200912456,
      "grad_norm": 0.9855997562408447,
      "learning_rate": 0.00012387395235176,
      "loss": 3.0706,
      "step": 30710
    },
    {
      "epoch": 1.3222002238099337,
      "grad_norm": 0.9795461297035217,
      "learning_rate": 0.00012382882702443654,
      "loss": 3.0555,
      "step": 30720
    },
    {
      "epoch": 1.322630627528622,
      "grad_norm": 0.9142932891845703,
      "learning_rate": 0.00012378369655217052,
      "loss": 3.0618,
      "step": 30730
    },
    {
      "epoch": 1.3230610312473101,
      "grad_norm": 0.9299269914627075,
      "learning_rate": 0.00012373856094470619,
      "loss": 3.0343,
      "step": 30740
    },
    {
      "epoch": 1.323491434965998,
      "grad_norm": 0.930400013923645,
      "learning_rate": 0.00012369342021178886,
      "loss": 3.0448,
      "step": 30750
    },
    {
      "epoch": 1.323491434965998,
      "eval_bleu": 26.770306341983083,
      "eval_gen_len": 27.413,
      "eval_loss": 2.806811809539795,
      "eval_runtime": 58.6619,
      "eval_samples_per_second": 17.047,
      "eval_steps_per_second": 1.074,
      "step": 30750
    },
    {
      "epoch": 1.3239218386846863,
      "grad_norm": 0.8727512955665588,
      "learning_rate": 0.00012364827436316502,
      "loss": 3.0632,
      "step": 30760
    },
    {
      "epoch": 1.3243522424033745,
      "grad_norm": 0.9131177067756653,
      "learning_rate": 0.00012360312340858217,
      "loss": 3.0202,
      "step": 30770
    },
    {
      "epoch": 1.3247826461220624,
      "grad_norm": 0.9003177285194397,
      "learning_rate": 0.00012355796735778903,
      "loss": 3.0018,
      "step": 30780
    },
    {
      "epoch": 1.3252130498407506,
      "grad_norm": 0.8704858422279358,
      "learning_rate": 0.00012351280622053534,
      "loss": 3.0747,
      "step": 30790
    },
    {
      "epoch": 1.3256434535594388,
      "grad_norm": 0.9431111216545105,
      "learning_rate": 0.00012346764000657192,
      "loss": 3.1306,
      "step": 30800
    },
    {
      "epoch": 1.3256434535594388,
      "eval_bleu": 26.90415449562611,
      "eval_gen_len": 27.395,
      "eval_loss": 2.8052711486816406,
      "eval_runtime": 58.7261,
      "eval_samples_per_second": 17.028,
      "eval_steps_per_second": 1.073,
      "step": 30800
    },
    {
      "epoch": 1.3260738572781268,
      "grad_norm": 0.8234317302703857,
      "learning_rate": 0.00012342246872565075,
      "loss": 3.1243,
      "step": 30810
    },
    {
      "epoch": 1.326504260996815,
      "grad_norm": 0.8367618918418884,
      "learning_rate": 0.0001233772923875249,
      "loss": 2.9898,
      "step": 30820
    },
    {
      "epoch": 1.3269346647155031,
      "grad_norm": 0.8411340713500977,
      "learning_rate": 0.00012333211100194847,
      "loss": 3.0536,
      "step": 30830
    },
    {
      "epoch": 1.3273650684341913,
      "grad_norm": 0.9203099012374878,
      "learning_rate": 0.00012328692457867668,
      "loss": 3.1346,
      "step": 30840
    },
    {
      "epoch": 1.3277954721528795,
      "grad_norm": 0.8693700432777405,
      "learning_rate": 0.0001232417331274659,
      "loss": 3.0401,
      "step": 30850
    },
    {
      "epoch": 1.3277954721528795,
      "eval_bleu": 27.001549404324997,
      "eval_gen_len": 27.429,
      "eval_loss": 2.8078792095184326,
      "eval_runtime": 58.7005,
      "eval_samples_per_second": 17.036,
      "eval_steps_per_second": 1.073,
      "step": 30850
    },
    {
      "epoch": 1.3282258758715675,
      "grad_norm": 0.9064502120018005,
      "learning_rate": 0.00012319653665807345,
      "loss": 2.9739,
      "step": 30860
    },
    {
      "epoch": 1.3286562795902557,
      "grad_norm": 0.9994974136352539,
      "learning_rate": 0.00012315133518025787,
      "loss": 3.0112,
      "step": 30870
    },
    {
      "epoch": 1.3290866833089439,
      "grad_norm": 1.122563362121582,
      "learning_rate": 0.00012310612870377872,
      "loss": 3.0632,
      "step": 30880
    },
    {
      "epoch": 1.3295170870276318,
      "grad_norm": 0.8678704500198364,
      "learning_rate": 0.00012306091723839665,
      "loss": 3.0664,
      "step": 30890
    },
    {
      "epoch": 1.32994749074632,
      "grad_norm": 0.8524905443191528,
      "learning_rate": 0.0001230157007938734,
      "loss": 2.9905,
      "step": 30900
    },
    {
      "epoch": 1.32994749074632,
      "eval_bleu": 27.11936142403104,
      "eval_gen_len": 27.407,
      "eval_loss": 2.805209159851074,
      "eval_runtime": 58.2942,
      "eval_samples_per_second": 17.154,
      "eval_steps_per_second": 1.081,
      "step": 30900
    },
    {
      "epoch": 1.3303778944650082,
      "grad_norm": 0.8920391201972961,
      "learning_rate": 0.0001229704793799717,
      "loss": 2.9927,
      "step": 30910
    },
    {
      "epoch": 1.3308082981836962,
      "grad_norm": 0.9496549963951111,
      "learning_rate": 0.0001229252530064555,
      "loss": 3.0269,
      "step": 30920
    },
    {
      "epoch": 1.3312387019023844,
      "grad_norm": 1.0112082958221436,
      "learning_rate": 0.00012288002168308964,
      "loss": 3.0632,
      "step": 30930
    },
    {
      "epoch": 1.3316691056210725,
      "grad_norm": 0.8236150145530701,
      "learning_rate": 0.00012283478541964024,
      "loss": 3.0763,
      "step": 30940
    },
    {
      "epoch": 1.3320995093397607,
      "grad_norm": 0.963883638381958,
      "learning_rate": 0.00012278954422587435,
      "loss": 2.9734,
      "step": 30950
    },
    {
      "epoch": 1.3320995093397607,
      "eval_bleu": 27.012338462779848,
      "eval_gen_len": 27.429,
      "eval_loss": 2.8017988204956055,
      "eval_runtime": 58.6037,
      "eval_samples_per_second": 17.064,
      "eval_steps_per_second": 1.075,
      "step": 30950
    },
    {
      "epoch": 1.332529913058449,
      "grad_norm": 0.8038283586502075,
      "learning_rate": 0.00012274429811156003,
      "loss": 2.9437,
      "step": 30960
    },
    {
      "epoch": 1.3329603167771369,
      "grad_norm": 0.9946909546852112,
      "learning_rate": 0.00012269904708646655,
      "loss": 3.0034,
      "step": 30970
    },
    {
      "epoch": 1.333390720495825,
      "grad_norm": 0.865484356880188,
      "learning_rate": 0.00012265379116036418,
      "loss": 3.0505,
      "step": 30980
    },
    {
      "epoch": 1.3338211242145133,
      "grad_norm": 0.8687319755554199,
      "learning_rate": 0.00012260853034302426,
      "loss": 3.0257,
      "step": 30990
    },
    {
      "epoch": 1.3342515279332012,
      "grad_norm": 0.9944605231285095,
      "learning_rate": 0.00012256326464421912,
      "loss": 2.9672,
      "step": 31000
    },
    {
      "epoch": 1.3342515279332012,
      "eval_bleu": 26.753872651934643,
      "eval_gen_len": 27.496,
      "eval_loss": 2.8068392276763916,
      "eval_runtime": 58.662,
      "eval_samples_per_second": 17.047,
      "eval_steps_per_second": 1.074,
      "step": 31000
    },
    {
      "epoch": 1.3346819316518894,
      "grad_norm": 0.8659796118736267,
      "learning_rate": 0.0001225179940737222,
      "loss": 2.97,
      "step": 31010
    },
    {
      "epoch": 1.3351123353705776,
      "grad_norm": 0.946837306022644,
      "learning_rate": 0.000122472718641308,
      "loss": 3.0019,
      "step": 31020
    },
    {
      "epoch": 1.3355427390892658,
      "grad_norm": 0.8260647654533386,
      "learning_rate": 0.00012242743835675203,
      "loss": 3.0732,
      "step": 31030
    },
    {
      "epoch": 1.335973142807954,
      "grad_norm": 0.985305905342102,
      "learning_rate": 0.0001223821532298309,
      "loss": 3.0029,
      "step": 31040
    },
    {
      "epoch": 1.336403546526642,
      "grad_norm": 0.9472570419311523,
      "learning_rate": 0.00012233686327032224,
      "loss": 2.9939,
      "step": 31050
    },
    {
      "epoch": 1.336403546526642,
      "eval_bleu": 26.583151026105416,
      "eval_gen_len": 27.535,
      "eval_loss": 2.802258253097534,
      "eval_runtime": 58.9909,
      "eval_samples_per_second": 16.952,
      "eval_steps_per_second": 1.068,
      "step": 31050
    },
    {
      "epoch": 1.3368339502453301,
      "grad_norm": 0.8852672576904297,
      "learning_rate": 0.00012229156848800468,
      "loss": 3.0316,
      "step": 31060
    },
    {
      "epoch": 1.3372643539640183,
      "grad_norm": 0.762204110622406,
      "learning_rate": 0.00012224626889265796,
      "loss": 3.006,
      "step": 31070
    },
    {
      "epoch": 1.3376947576827063,
      "grad_norm": 0.9793067574501038,
      "learning_rate": 0.0001222009644940628,
      "loss": 3.0591,
      "step": 31080
    },
    {
      "epoch": 1.3381251614013945,
      "grad_norm": 0.8692752718925476,
      "learning_rate": 0.00012215565530200107,
      "loss": 3.0208,
      "step": 31090
    },
    {
      "epoch": 1.3385555651200827,
      "grad_norm": 0.9470565915107727,
      "learning_rate": 0.0001221103413262555,
      "loss": 3.0742,
      "step": 31100
    },
    {
      "epoch": 1.3385555651200827,
      "eval_bleu": 26.894405621735597,
      "eval_gen_len": 27.494,
      "eval_loss": 2.803438663482666,
      "eval_runtime": 58.5462,
      "eval_samples_per_second": 17.081,
      "eval_steps_per_second": 1.076,
      "step": 31100
    },
    {
      "epoch": 1.3389859688387706,
      "grad_norm": 0.9595105648040771,
      "learning_rate": 0.00012206502257661,
      "loss": 3.1519,
      "step": 31110
    },
    {
      "epoch": 1.3394163725574588,
      "grad_norm": 0.9201314449310303,
      "learning_rate": 0.00012201969906284942,
      "loss": 3.0747,
      "step": 31120
    },
    {
      "epoch": 1.339846776276147,
      "grad_norm": 0.9027500748634338,
      "learning_rate": 0.0001219743707947597,
      "loss": 3.1647,
      "step": 31130
    },
    {
      "epoch": 1.3402771799948352,
      "grad_norm": 0.8033584952354431,
      "learning_rate": 0.00012192903778212779,
      "loss": 3.0395,
      "step": 31140
    },
    {
      "epoch": 1.3407075837135234,
      "grad_norm": 0.854394257068634,
      "learning_rate": 0.00012188370003474164,
      "loss": 3.0774,
      "step": 31150
    },
    {
      "epoch": 1.3407075837135234,
      "eval_bleu": 27.291937265735044,
      "eval_gen_len": 27.573,
      "eval_loss": 2.8016135692596436,
      "eval_runtime": 59.0445,
      "eval_samples_per_second": 16.936,
      "eval_steps_per_second": 1.067,
      "step": 31150
    },
    {
      "epoch": 1.3411379874322114,
      "grad_norm": 0.89340740442276,
      "learning_rate": 0.00012183835756239021,
      "loss": 2.9968,
      "step": 31160
    },
    {
      "epoch": 1.3415683911508995,
      "grad_norm": 0.9721964001655579,
      "learning_rate": 0.00012179301037486357,
      "loss": 2.9374,
      "step": 31170
    },
    {
      "epoch": 1.3419987948695877,
      "grad_norm": 0.9822654128074646,
      "learning_rate": 0.00012174765848195269,
      "loss": 2.9869,
      "step": 31180
    },
    {
      "epoch": 1.3424291985882757,
      "grad_norm": 0.955353319644928,
      "learning_rate": 0.00012170230189344966,
      "loss": 3.0838,
      "step": 31190
    },
    {
      "epoch": 1.3428596023069639,
      "grad_norm": 1.006579041481018,
      "learning_rate": 0.00012165694061914751,
      "loss": 3.048,
      "step": 31200
    },
    {
      "epoch": 1.3428596023069639,
      "eval_bleu": 27.439316138909316,
      "eval_gen_len": 27.53,
      "eval_loss": 2.7996647357940674,
      "eval_runtime": 59.1036,
      "eval_samples_per_second": 16.919,
      "eval_steps_per_second": 1.066,
      "step": 31200
    },
    {
      "epoch": 1.343290006025652,
      "grad_norm": 0.8871954083442688,
      "learning_rate": 0.0001216115746688403,
      "loss": 3.0657,
      "step": 31210
    },
    {
      "epoch": 1.3437204097443403,
      "grad_norm": 0.882529079914093,
      "learning_rate": 0.00012156620405232313,
      "loss": 3.003,
      "step": 31220
    },
    {
      "epoch": 1.3441508134630284,
      "grad_norm": 0.8495001792907715,
      "learning_rate": 0.00012152082877939208,
      "loss": 3.0738,
      "step": 31230
    },
    {
      "epoch": 1.3445812171817164,
      "grad_norm": 1.0181609392166138,
      "learning_rate": 0.00012147544885984419,
      "loss": 3.0662,
      "step": 31240
    },
    {
      "epoch": 1.3450116209004046,
      "grad_norm": 0.935958206653595,
      "learning_rate": 0.00012143006430347763,
      "loss": 2.9932,
      "step": 31250
    },
    {
      "epoch": 1.3450116209004046,
      "eval_bleu": 26.69575554299949,
      "eval_gen_len": 27.376,
      "eval_loss": 2.8022220134735107,
      "eval_runtime": 58.5969,
      "eval_samples_per_second": 17.066,
      "eval_steps_per_second": 1.075,
      "step": 31250
    },
    {
      "epoch": 1.3454420246190928,
      "grad_norm": 0.9399764537811279,
      "learning_rate": 0.00012138467512009147,
      "loss": 3.031,
      "step": 31260
    },
    {
      "epoch": 1.3458724283377808,
      "grad_norm": 0.8346148133277893,
      "learning_rate": 0.00012133928131948576,
      "loss": 2.9465,
      "step": 31270
    },
    {
      "epoch": 1.346302832056469,
      "grad_norm": 0.8943520188331604,
      "learning_rate": 0.00012129388291146167,
      "loss": 2.9757,
      "step": 31280
    },
    {
      "epoch": 1.3467332357751571,
      "grad_norm": 0.9367539882659912,
      "learning_rate": 0.00012124847990582122,
      "loss": 3.0045,
      "step": 31290
    },
    {
      "epoch": 1.347163639493845,
      "grad_norm": 0.8113745450973511,
      "learning_rate": 0.00012120307231236752,
      "loss": 2.9898,
      "step": 31300
    },
    {
      "epoch": 1.347163639493845,
      "eval_bleu": 26.958657645507987,
      "eval_gen_len": 27.407,
      "eval_loss": 2.7998528480529785,
      "eval_runtime": 59.176,
      "eval_samples_per_second": 16.899,
      "eval_steps_per_second": 1.065,
      "step": 31300
    },
    {
      "epoch": 1.3475940432125333,
      "grad_norm": 1.022789716720581,
      "learning_rate": 0.00012115766014090462,
      "loss": 3.0804,
      "step": 31310
    },
    {
      "epoch": 1.3480244469312215,
      "grad_norm": 1.0503352880477905,
      "learning_rate": 0.00012111224340123762,
      "loss": 3.0316,
      "step": 31320
    },
    {
      "epoch": 1.3484548506499097,
      "grad_norm": 0.8678846955299377,
      "learning_rate": 0.00012106682210317248,
      "loss": 2.9825,
      "step": 31330
    },
    {
      "epoch": 1.3488852543685979,
      "grad_norm": 0.9016790986061096,
      "learning_rate": 0.00012102139625651627,
      "loss": 2.9724,
      "step": 31340
    },
    {
      "epoch": 1.3493156580872858,
      "grad_norm": 0.8434243202209473,
      "learning_rate": 0.00012097596587107705,
      "loss": 2.9568,
      "step": 31350
    },
    {
      "epoch": 1.3493156580872858,
      "eval_bleu": 26.996897287341838,
      "eval_gen_len": 27.412,
      "eval_loss": 2.7992520332336426,
      "eval_runtime": 58.9298,
      "eval_samples_per_second": 16.969,
      "eval_steps_per_second": 1.069,
      "step": 31350
    },
    {
      "epoch": 1.349746061805974,
      "grad_norm": 0.9886408448219299,
      "learning_rate": 0.00012093053095666378,
      "loss": 3.0801,
      "step": 31360
    },
    {
      "epoch": 1.3501764655246622,
      "grad_norm": 0.8903878927230835,
      "learning_rate": 0.00012088509152308638,
      "loss": 3.1043,
      "step": 31370
    },
    {
      "epoch": 1.3506068692433502,
      "grad_norm": 0.9232689738273621,
      "learning_rate": 0.00012083964758015584,
      "loss": 3.0014,
      "step": 31380
    },
    {
      "epoch": 1.3510372729620383,
      "grad_norm": 0.8860544562339783,
      "learning_rate": 0.00012079419913768407,
      "loss": 2.9946,
      "step": 31390
    },
    {
      "epoch": 1.3514676766807265,
      "grad_norm": 0.9141496419906616,
      "learning_rate": 0.00012074874620548395,
      "loss": 3.0481,
      "step": 31400
    },
    {
      "epoch": 1.3514676766807265,
      "eval_bleu": 26.59338219030018,
      "eval_gen_len": 27.497,
      "eval_loss": 2.7994635105133057,
      "eval_runtime": 58.5358,
      "eval_samples_per_second": 17.084,
      "eval_steps_per_second": 1.076,
      "step": 31400
    },
    {
      "epoch": 1.3518980803994147,
      "grad_norm": 1.02204167842865,
      "learning_rate": 0.00012070328879336936,
      "loss": 2.991,
      "step": 31410
    },
    {
      "epoch": 1.352328484118103,
      "grad_norm": 0.9019383788108826,
      "learning_rate": 0.00012065782691115508,
      "loss": 2.9543,
      "step": 31420
    },
    {
      "epoch": 1.3527588878367909,
      "grad_norm": 0.924152672290802,
      "learning_rate": 0.00012061236056865694,
      "loss": 3.0816,
      "step": 31430
    },
    {
      "epoch": 1.353189291555479,
      "grad_norm": 1.0106265544891357,
      "learning_rate": 0.00012056688977569168,
      "loss": 3.0742,
      "step": 31440
    },
    {
      "epoch": 1.3536196952741673,
      "grad_norm": 0.872541606426239,
      "learning_rate": 0.00012052141454207701,
      "loss": 2.9741,
      "step": 31450
    },
    {
      "epoch": 1.3536196952741673,
      "eval_bleu": 26.88627743169671,
      "eval_gen_len": 27.44,
      "eval_loss": 2.8003976345062256,
      "eval_runtime": 58.4796,
      "eval_samples_per_second": 17.1,
      "eval_steps_per_second": 1.077,
      "step": 31450
    },
    {
      "epoch": 1.3540500989928552,
      "grad_norm": 0.9056153297424316,
      "learning_rate": 0.00012047593487763162,
      "loss": 3.0058,
      "step": 31460
    },
    {
      "epoch": 1.3544805027115434,
      "grad_norm": 0.9155772924423218,
      "learning_rate": 0.00012043045079217514,
      "loss": 3.0243,
      "step": 31470
    },
    {
      "epoch": 1.3549109064302316,
      "grad_norm": 0.8883906602859497,
      "learning_rate": 0.00012038496229552817,
      "loss": 3.0713,
      "step": 31480
    },
    {
      "epoch": 1.3553413101489196,
      "grad_norm": 0.855922520160675,
      "learning_rate": 0.00012033946939751217,
      "loss": 3.1349,
      "step": 31490
    },
    {
      "epoch": 1.3557717138676078,
      "grad_norm": 0.9496233463287354,
      "learning_rate": 0.00012029397210794969,
      "loss": 2.9542,
      "step": 31500
    },
    {
      "epoch": 1.3557717138676078,
      "eval_bleu": 27.27952508907762,
      "eval_gen_len": 27.361,
      "eval_loss": 2.8001890182495117,
      "eval_runtime": 58.6974,
      "eval_samples_per_second": 17.037,
      "eval_steps_per_second": 1.073,
      "step": 31500
    },
    {
      "epoch": 1.356202117586296,
      "grad_norm": 0.999468982219696,
      "learning_rate": 0.00012024847043666416,
      "loss": 3.1131,
      "step": 31510
    },
    {
      "epoch": 1.3566325213049841,
      "grad_norm": 1.03778874874115,
      "learning_rate": 0.00012020296439347994,
      "loss": 2.9397,
      "step": 31520
    },
    {
      "epoch": 1.3570629250236723,
      "grad_norm": 0.987524688243866,
      "learning_rate": 0.00012015745398822238,
      "loss": 2.9348,
      "step": 31530
    },
    {
      "epoch": 1.3574933287423603,
      "grad_norm": 0.9815952777862549,
      "learning_rate": 0.00012011193923071773,
      "loss": 2.9433,
      "step": 31540
    },
    {
      "epoch": 1.3579237324610485,
      "grad_norm": 0.9655483961105347,
      "learning_rate": 0.00012006642013079322,
      "loss": 2.9649,
      "step": 31550
    },
    {
      "epoch": 1.3579237324610485,
      "eval_bleu": 26.9273473187019,
      "eval_gen_len": 27.407,
      "eval_loss": 2.8002262115478516,
      "eval_runtime": 58.6424,
      "eval_samples_per_second": 17.053,
      "eval_steps_per_second": 1.074,
      "step": 31550
    },
    {
      "epoch": 1.3583541361797367,
      "grad_norm": 0.8662206530570984,
      "learning_rate": 0.00012002089669827698,
      "loss": 3.0395,
      "step": 31560
    },
    {
      "epoch": 1.3587845398984246,
      "grad_norm": 0.9518882036209106,
      "learning_rate": 0.0001199753689429981,
      "loss": 3.0437,
      "step": 31570
    },
    {
      "epoch": 1.3592149436171128,
      "grad_norm": 0.9204152822494507,
      "learning_rate": 0.00011992983687478653,
      "loss": 3.0333,
      "step": 31580
    },
    {
      "epoch": 1.359645347335801,
      "grad_norm": 0.8572895526885986,
      "learning_rate": 0.00011988430050347332,
      "loss": 3.1016,
      "step": 31590
    },
    {
      "epoch": 1.3600757510544892,
      "grad_norm": 0.9352472424507141,
      "learning_rate": 0.00011983875983889025,
      "loss": 3.067,
      "step": 31600
    },
    {
      "epoch": 1.3600757510544892,
      "eval_bleu": 27.179758666849178,
      "eval_gen_len": 27.485,
      "eval_loss": 2.7988109588623047,
      "eval_runtime": 58.6989,
      "eval_samples_per_second": 17.036,
      "eval_steps_per_second": 1.073,
      "step": 31600
    },
    {
      "epoch": 1.3605061547731774,
      "grad_norm": 0.8201788067817688,
      "learning_rate": 0.00011979321489087019,
      "loss": 3.0121,
      "step": 31610
    },
    {
      "epoch": 1.3609365584918653,
      "grad_norm": 1.012298822402954,
      "learning_rate": 0.00011974766566924682,
      "loss": 3.0376,
      "step": 31620
    },
    {
      "epoch": 1.3613669622105535,
      "grad_norm": 1.0040805339813232,
      "learning_rate": 0.0001197021121838548,
      "loss": 3.0831,
      "step": 31630
    },
    {
      "epoch": 1.3617973659292417,
      "grad_norm": 0.8805762529373169,
      "learning_rate": 0.00011965655444452975,
      "loss": 3.0177,
      "step": 31640
    },
    {
      "epoch": 1.3622277696479297,
      "grad_norm": 0.9231032729148865,
      "learning_rate": 0.00011961099246110805,
      "loss": 2.9187,
      "step": 31650
    },
    {
      "epoch": 1.3622277696479297,
      "eval_bleu": 26.712037560273902,
      "eval_gen_len": 27.453,
      "eval_loss": 2.800593852996826,
      "eval_runtime": 58.1552,
      "eval_samples_per_second": 17.195,
      "eval_steps_per_second": 1.083,
      "step": 31650
    },
    {
      "epoch": 1.3626581733666179,
      "grad_norm": 0.803605854511261,
      "learning_rate": 0.00011956542624342719,
      "loss": 3.0342,
      "step": 31660
    },
    {
      "epoch": 1.363088577085306,
      "grad_norm": 0.9294893145561218,
      "learning_rate": 0.00011951985580132545,
      "loss": 3.1172,
      "step": 31670
    },
    {
      "epoch": 1.363518980803994,
      "grad_norm": 0.9713932871818542,
      "learning_rate": 0.0001194742811446421,
      "loss": 3.0585,
      "step": 31680
    },
    {
      "epoch": 1.3639493845226822,
      "grad_norm": 0.8418415784835815,
      "learning_rate": 0.00011942870228321723,
      "loss": 3.0082,
      "step": 31690
    },
    {
      "epoch": 1.3643797882413704,
      "grad_norm": 0.9926115870475769,
      "learning_rate": 0.00011938311922689191,
      "loss": 3.0215,
      "step": 31700
    },
    {
      "epoch": 1.3643797882413704,
      "eval_bleu": 26.925318493582182,
      "eval_gen_len": 27.473,
      "eval_loss": 2.799777030944824,
      "eval_runtime": 58.9501,
      "eval_samples_per_second": 16.964,
      "eval_steps_per_second": 1.069,
      "step": 31700
    },
    {
      "epoch": 1.3648101919600586,
      "grad_norm": 0.9999155402183533,
      "learning_rate": 0.00011933753198550805,
      "loss": 3.0559,
      "step": 31710
    },
    {
      "epoch": 1.3652405956787468,
      "grad_norm": 0.8576127886772156,
      "learning_rate": 0.00011929194056890863,
      "loss": 3.1582,
      "step": 31720
    },
    {
      "epoch": 1.3656709993974347,
      "grad_norm": 0.9607735276222229,
      "learning_rate": 0.00011924634498693728,
      "loss": 3.0673,
      "step": 31730
    },
    {
      "epoch": 1.366101403116123,
      "grad_norm": 0.9362366199493408,
      "learning_rate": 0.00011920074524943872,
      "loss": 2.9069,
      "step": 31740
    },
    {
      "epoch": 1.3665318068348111,
      "grad_norm": 0.9448211193084717,
      "learning_rate": 0.00011915514136625847,
      "loss": 2.9584,
      "step": 31750
    },
    {
      "epoch": 1.3665318068348111,
      "eval_bleu": 27.335936074020267,
      "eval_gen_len": 27.456,
      "eval_loss": 2.7981116771698,
      "eval_runtime": 58.2339,
      "eval_samples_per_second": 17.172,
      "eval_steps_per_second": 1.082,
      "step": 31750
    },
    {
      "epoch": 1.366962210553499,
      "grad_norm": 0.9304442405700684,
      "learning_rate": 0.00011910953334724304,
      "loss": 3.149,
      "step": 31760
    },
    {
      "epoch": 1.3673926142721873,
      "grad_norm": 0.9054352641105652,
      "learning_rate": 0.0001190639212022397,
      "loss": 3.0274,
      "step": 31770
    },
    {
      "epoch": 1.3678230179908755,
      "grad_norm": 0.926038920879364,
      "learning_rate": 0.00011901830494109671,
      "loss": 3.0456,
      "step": 31780
    },
    {
      "epoch": 1.3682534217095634,
      "grad_norm": 0.9192468523979187,
      "learning_rate": 0.00011897268457366322,
      "loss": 3.0044,
      "step": 31790
    },
    {
      "epoch": 1.3686838254282516,
      "grad_norm": 0.9604601860046387,
      "learning_rate": 0.00011892706010978922,
      "loss": 2.9872,
      "step": 31800
    },
    {
      "epoch": 1.3686838254282516,
      "eval_bleu": 27.17842206077725,
      "eval_gen_len": 27.447,
      "eval_loss": 2.7974748611450195,
      "eval_runtime": 58.4725,
      "eval_samples_per_second": 17.102,
      "eval_steps_per_second": 1.077,
      "step": 31800
    },
    {
      "epoch": 1.3691142291469398,
      "grad_norm": 1.0899474620819092,
      "learning_rate": 0.0001188814315593256,
      "loss": 2.9958,
      "step": 31810
    },
    {
      "epoch": 1.369544632865628,
      "grad_norm": 1.0052320957183838,
      "learning_rate": 0.00011883579893212414,
      "loss": 3.0326,
      "step": 31820
    },
    {
      "epoch": 1.3699750365843162,
      "grad_norm": 1.0065304040908813,
      "learning_rate": 0.00011879016223803749,
      "loss": 3.0411,
      "step": 31830
    },
    {
      "epoch": 1.3704054403030042,
      "grad_norm": 0.8664762377738953,
      "learning_rate": 0.00011874452148691924,
      "loss": 2.9845,
      "step": 31840
    },
    {
      "epoch": 1.3708358440216923,
      "grad_norm": 0.9579737782478333,
      "learning_rate": 0.0001186988766886237,
      "loss": 2.9605,
      "step": 31850
    },
    {
      "epoch": 1.3708358440216923,
      "eval_bleu": 26.428870520250943,
      "eval_gen_len": 27.376,
      "eval_loss": 2.8003766536712646,
      "eval_runtime": 58.6087,
      "eval_samples_per_second": 17.062,
      "eval_steps_per_second": 1.075,
      "step": 31850
    },
    {
      "epoch": 1.3712662477403805,
      "grad_norm": 0.8054865598678589,
      "learning_rate": 0.00011865322785300621,
      "loss": 2.9602,
      "step": 31860
    },
    {
      "epoch": 1.3716966514590685,
      "grad_norm": 1.0470863580703735,
      "learning_rate": 0.00011860757498992294,
      "loss": 3.0644,
      "step": 31870
    },
    {
      "epoch": 1.3721270551777567,
      "grad_norm": 0.9501314759254456,
      "learning_rate": 0.00011856191810923087,
      "loss": 3.0893,
      "step": 31880
    },
    {
      "epoch": 1.3725574588964449,
      "grad_norm": 0.8262946605682373,
      "learning_rate": 0.00011851625722078797,
      "loss": 3.01,
      "step": 31890
    },
    {
      "epoch": 1.372987862615133,
      "grad_norm": 0.8565290570259094,
      "learning_rate": 0.0001184705923344529,
      "loss": 3.0503,
      "step": 31900
    },
    {
      "epoch": 1.372987862615133,
      "eval_bleu": 26.93937198534699,
      "eval_gen_len": 27.441,
      "eval_loss": 2.800539493560791,
      "eval_runtime": 58.2601,
      "eval_samples_per_second": 17.164,
      "eval_steps_per_second": 1.081,
      "step": 31900
    },
    {
      "epoch": 1.3734182663338212,
      "grad_norm": 0.8894444108009338,
      "learning_rate": 0.00011842492346008535,
      "loss": 3.0399,
      "step": 31910
    },
    {
      "epoch": 1.3738486700525092,
      "grad_norm": 0.995911717414856,
      "learning_rate": 0.00011837925060754578,
      "loss": 3.0225,
      "step": 31920
    },
    {
      "epoch": 1.3742790737711974,
      "grad_norm": 0.8929027915000916,
      "learning_rate": 0.00011833357378669556,
      "loss": 3.1198,
      "step": 31930
    },
    {
      "epoch": 1.3747094774898856,
      "grad_norm": 0.8385956883430481,
      "learning_rate": 0.00011828789300739684,
      "loss": 3.023,
      "step": 31940
    },
    {
      "epoch": 1.3751398812085736,
      "grad_norm": 0.9564369320869446,
      "learning_rate": 0.0001182422082795127,
      "loss": 3.15,
      "step": 31950
    },
    {
      "epoch": 1.3751398812085736,
      "eval_bleu": 27.04777661515837,
      "eval_gen_len": 27.377,
      "eval_loss": 2.7978365421295166,
      "eval_runtime": 58.0633,
      "eval_samples_per_second": 17.223,
      "eval_steps_per_second": 1.085,
      "step": 31950
    },
    {
      "epoch": 1.3755702849272617,
      "grad_norm": 0.9647165536880493,
      "learning_rate": 0.00011819651961290705,
      "loss": 3.0266,
      "step": 31960
    },
    {
      "epoch": 1.37600068864595,
      "grad_norm": 0.8989327549934387,
      "learning_rate": 0.00011815082701744462,
      "loss": 2.9926,
      "step": 31970
    },
    {
      "epoch": 1.376431092364638,
      "grad_norm": 0.9083982110023499,
      "learning_rate": 0.00011810513050299103,
      "loss": 3.0441,
      "step": 31980
    },
    {
      "epoch": 1.376861496083326,
      "grad_norm": 0.8774032592773438,
      "learning_rate": 0.00011805943007941276,
      "loss": 3.0544,
      "step": 31990
    },
    {
      "epoch": 1.3772918998020143,
      "grad_norm": 0.905707597732544,
      "learning_rate": 0.00011801372575657705,
      "loss": 2.9886,
      "step": 32000
    },
    {
      "epoch": 1.3772918998020143,
      "eval_bleu": 26.927531811350757,
      "eval_gen_len": 27.386,
      "eval_loss": 2.7987046241760254,
      "eval_runtime": 57.9608,
      "eval_samples_per_second": 17.253,
      "eval_steps_per_second": 1.087,
      "step": 32000
    },
    {
      "epoch": 1.3777223035207025,
      "grad_norm": 0.865825891494751,
      "learning_rate": 0.00011796801754435211,
      "loss": 2.9666,
      "step": 32010
    },
    {
      "epoch": 1.3781527072393907,
      "grad_norm": 0.9654245376586914,
      "learning_rate": 0.00011792230545260683,
      "loss": 3.0277,
      "step": 32020
    },
    {
      "epoch": 1.3785831109580786,
      "grad_norm": 0.9055874943733215,
      "learning_rate": 0.00011787658949121107,
      "loss": 2.88,
      "step": 32030
    },
    {
      "epoch": 1.3790135146767668,
      "grad_norm": 0.866826593875885,
      "learning_rate": 0.00011783086967003546,
      "loss": 3.1162,
      "step": 32040
    },
    {
      "epoch": 1.379443918395455,
      "grad_norm": 0.9687058925628662,
      "learning_rate": 0.00011778514599895156,
      "loss": 3.0957,
      "step": 32050
    },
    {
      "epoch": 1.379443918395455,
      "eval_bleu": 26.507534890135396,
      "eval_gen_len": 27.386,
      "eval_loss": 2.8014278411865234,
      "eval_runtime": 58.4948,
      "eval_samples_per_second": 17.096,
      "eval_steps_per_second": 1.077,
      "step": 32050
    },
    {
      "epoch": 1.379874322114143,
      "grad_norm": 0.9303504824638367,
      "learning_rate": 0.00011773941848783157,
      "loss": 3.0155,
      "step": 32060
    },
    {
      "epoch": 1.3803047258328311,
      "grad_norm": 0.9346525073051453,
      "learning_rate": 0.00011769368714654865,
      "loss": 3.0478,
      "step": 32070
    },
    {
      "epoch": 1.3807351295515193,
      "grad_norm": 0.8723872303962708,
      "learning_rate": 0.00011764795198497685,
      "loss": 3.0265,
      "step": 32080
    },
    {
      "epoch": 1.3811655332702075,
      "grad_norm": 0.7961164116859436,
      "learning_rate": 0.00011760221301299093,
      "loss": 3.0241,
      "step": 32090
    },
    {
      "epoch": 1.3815959369888957,
      "grad_norm": 0.9546828866004944,
      "learning_rate": 0.00011755647024046645,
      "loss": 3.0595,
      "step": 32100
    },
    {
      "epoch": 1.3815959369888957,
      "eval_bleu": 26.963681478112118,
      "eval_gen_len": 27.441,
      "eval_loss": 2.800851345062256,
      "eval_runtime": 58.0188,
      "eval_samples_per_second": 17.236,
      "eval_steps_per_second": 1.086,
      "step": 32100
    },
    {
      "epoch": 1.3820263407075837,
      "grad_norm": 0.9577372074127197,
      "learning_rate": 0.00011751072367727993,
      "loss": 3.0317,
      "step": 32110
    },
    {
      "epoch": 1.3824567444262719,
      "grad_norm": 0.9909334778785706,
      "learning_rate": 0.00011746497333330858,
      "loss": 2.9757,
      "step": 32120
    },
    {
      "epoch": 1.38288714814496,
      "grad_norm": 0.9989191293716431,
      "learning_rate": 0.00011741921921843049,
      "loss": 3.0352,
      "step": 32130
    },
    {
      "epoch": 1.383317551863648,
      "grad_norm": 0.8791133165359497,
      "learning_rate": 0.00011737346134252454,
      "loss": 3.0421,
      "step": 32140
    },
    {
      "epoch": 1.3837479555823362,
      "grad_norm": 0.9330651164054871,
      "learning_rate": 0.00011732769971547039,
      "loss": 3.074,
      "step": 32150
    },
    {
      "epoch": 1.3837479555823362,
      "eval_bleu": 26.585630730039618,
      "eval_gen_len": 27.439,
      "eval_loss": 2.8047592639923096,
      "eval_runtime": 57.7692,
      "eval_samples_per_second": 17.31,
      "eval_steps_per_second": 1.091,
      "step": 32150
    },
    {
      "epoch": 1.3841783593010244,
      "grad_norm": 1.009198784828186,
      "learning_rate": 0.00011728193434714862,
      "loss": 3.1036,
      "step": 32160
    },
    {
      "epoch": 1.3846087630197124,
      "grad_norm": 0.9587088823318481,
      "learning_rate": 0.00011723616524744053,
      "loss": 3.0753,
      "step": 32170
    },
    {
      "epoch": 1.3850391667384006,
      "grad_norm": 0.8716317415237427,
      "learning_rate": 0.0001171903924262282,
      "loss": 3.0048,
      "step": 32180
    },
    {
      "epoch": 1.3854695704570887,
      "grad_norm": 0.9184819459915161,
      "learning_rate": 0.00011714461589339461,
      "loss": 3.1156,
      "step": 32190
    },
    {
      "epoch": 1.385899974175777,
      "grad_norm": 1.0307093858718872,
      "learning_rate": 0.00011709883565882345,
      "loss": 3.0162,
      "step": 32200
    },
    {
      "epoch": 1.385899974175777,
      "eval_bleu": 27.055803850267598,
      "eval_gen_len": 27.396,
      "eval_loss": 2.8010146617889404,
      "eval_runtime": 58.2908,
      "eval_samples_per_second": 17.155,
      "eval_steps_per_second": 1.081,
      "step": 32200
    },
    {
      "epoch": 1.3863303778944651,
      "grad_norm": 1.0294750928878784,
      "learning_rate": 0.00011705305173239927,
      "loss": 3.0543,
      "step": 32210
    },
    {
      "epoch": 1.386760781613153,
      "grad_norm": 0.8590465188026428,
      "learning_rate": 0.00011700726412400736,
      "loss": 3.0024,
      "step": 32220
    },
    {
      "epoch": 1.3871911853318413,
      "grad_norm": 0.9653800129890442,
      "learning_rate": 0.00011696147284353387,
      "loss": 2.969,
      "step": 32230
    },
    {
      "epoch": 1.3876215890505295,
      "grad_norm": 0.9891050457954407,
      "learning_rate": 0.0001169156779008657,
      "loss": 2.9975,
      "step": 32240
    },
    {
      "epoch": 1.3880519927692174,
      "grad_norm": 0.8778578639030457,
      "learning_rate": 0.00011686987930589057,
      "loss": 3.0327,
      "step": 32250
    },
    {
      "epoch": 1.3880519927692174,
      "eval_bleu": 26.887696293488755,
      "eval_gen_len": 27.527,
      "eval_loss": 2.800569534301758,
      "eval_runtime": 58.5027,
      "eval_samples_per_second": 17.093,
      "eval_steps_per_second": 1.077,
      "step": 32250
    },
    {
      "epoch": 1.3884823964879056,
      "grad_norm": 0.8887085318565369,
      "learning_rate": 0.00011682407706849693,
      "loss": 2.99,
      "step": 32260
    },
    {
      "epoch": 1.3889128002065938,
      "grad_norm": 0.954146146774292,
      "learning_rate": 0.0001167782711985741,
      "loss": 3.0915,
      "step": 32270
    },
    {
      "epoch": 1.389343203925282,
      "grad_norm": 0.920113742351532,
      "learning_rate": 0.00011673246170601213,
      "loss": 2.9104,
      "step": 32280
    },
    {
      "epoch": 1.3897736076439702,
      "grad_norm": 0.983980119228363,
      "learning_rate": 0.00011668664860070186,
      "loss": 3.0377,
      "step": 32290
    },
    {
      "epoch": 1.3902040113626581,
      "grad_norm": 1.0519604682922363,
      "learning_rate": 0.00011664083189253491,
      "loss": 2.9416,
      "step": 32300
    },
    {
      "epoch": 1.3902040113626581,
      "eval_bleu": 27.1001218559321,
      "eval_gen_len": 27.378,
      "eval_loss": 2.799473285675049,
      "eval_runtime": 58.4316,
      "eval_samples_per_second": 17.114,
      "eval_steps_per_second": 1.078,
      "step": 32300
    },
    {
      "epoch": 1.3906344150813463,
      "grad_norm": 0.9080499410629272,
      "learning_rate": 0.00011659501159140366,
      "loss": 3.0326,
      "step": 32310
    },
    {
      "epoch": 1.3910648188000345,
      "grad_norm": 0.8747770190238953,
      "learning_rate": 0.00011654918770720136,
      "loss": 3.057,
      "step": 32320
    },
    {
      "epoch": 1.3914952225187225,
      "grad_norm": 0.8533696532249451,
      "learning_rate": 0.0001165033602498219,
      "loss": 3.0314,
      "step": 32330
    },
    {
      "epoch": 1.3919256262374107,
      "grad_norm": 0.9432613849639893,
      "learning_rate": 0.00011645752922915998,
      "loss": 3.0559,
      "step": 32340
    },
    {
      "epoch": 1.3923560299560989,
      "grad_norm": 0.9653133153915405,
      "learning_rate": 0.00011641169465511115,
      "loss": 3.0361,
      "step": 32350
    },
    {
      "epoch": 1.3923560299560989,
      "eval_bleu": 27.488393769104377,
      "eval_gen_len": 27.552,
      "eval_loss": 2.798213481903076,
      "eval_runtime": 58.9759,
      "eval_samples_per_second": 16.956,
      "eval_steps_per_second": 1.068,
      "step": 32350
    },
    {
      "epoch": 1.3927864336747868,
      "grad_norm": 0.888727605342865,
      "learning_rate": 0.00011636585653757164,
      "loss": 3.0109,
      "step": 32360
    },
    {
      "epoch": 1.393216837393475,
      "grad_norm": 0.850906252861023,
      "learning_rate": 0.00011632001488643852,
      "loss": 2.9431,
      "step": 32370
    },
    {
      "epoch": 1.3936472411121632,
      "grad_norm": 0.8928710222244263,
      "learning_rate": 0.00011627416971160952,
      "loss": 2.9516,
      "step": 32380
    },
    {
      "epoch": 1.3940776448308514,
      "grad_norm": 0.8458356857299805,
      "learning_rate": 0.00011622832102298318,
      "loss": 3.039,
      "step": 32390
    },
    {
      "epoch": 1.3945080485495396,
      "grad_norm": 0.9565811157226562,
      "learning_rate": 0.00011618246883045886,
      "loss": 3.0393,
      "step": 32400
    },
    {
      "epoch": 1.3945080485495396,
      "eval_bleu": 26.468177963492813,
      "eval_gen_len": 27.521,
      "eval_loss": 2.8020408153533936,
      "eval_runtime": 58.7222,
      "eval_samples_per_second": 17.029,
      "eval_steps_per_second": 1.073,
      "step": 32400
    },
    {
      "epoch": 1.3949384522682275,
      "grad_norm": 0.9348978400230408,
      "learning_rate": 0.0001161366131439366,
      "loss": 3.0763,
      "step": 32410
    },
    {
      "epoch": 1.3953688559869157,
      "grad_norm": 0.8660028576850891,
      "learning_rate": 0.0001160907539733172,
      "loss": 2.9494,
      "step": 32420
    },
    {
      "epoch": 1.395799259705604,
      "grad_norm": 0.9983394145965576,
      "learning_rate": 0.00011604489132850227,
      "loss": 3.0319,
      "step": 32430
    },
    {
      "epoch": 1.396229663424292,
      "grad_norm": 0.932649552822113,
      "learning_rate": 0.00011599902521939405,
      "loss": 3.0118,
      "step": 32440
    },
    {
      "epoch": 1.39666006714298,
      "grad_norm": 0.8851704597473145,
      "learning_rate": 0.00011595315565589573,
      "loss": 3.021,
      "step": 32450
    },
    {
      "epoch": 1.39666006714298,
      "eval_bleu": 26.93644398560778,
      "eval_gen_len": 27.458,
      "eval_loss": 2.8011085987091064,
      "eval_runtime": 58.8375,
      "eval_samples_per_second": 16.996,
      "eval_steps_per_second": 1.071,
      "step": 32450
    },
    {
      "epoch": 1.3970904708616683,
      "grad_norm": 0.8306021690368652,
      "learning_rate": 0.00011590728264791102,
      "loss": 3.0164,
      "step": 32460
    },
    {
      "epoch": 1.3975208745803565,
      "grad_norm": 0.940751850605011,
      "learning_rate": 0.00011586140620534451,
      "loss": 3.0351,
      "step": 32470
    },
    {
      "epoch": 1.3979512782990446,
      "grad_norm": 0.8946791887283325,
      "learning_rate": 0.00011581552633810154,
      "loss": 2.9628,
      "step": 32480
    },
    {
      "epoch": 1.3983816820177326,
      "grad_norm": 0.9250608682632446,
      "learning_rate": 0.00011576964305608811,
      "loss": 3.0608,
      "step": 32490
    },
    {
      "epoch": 1.3988120857364208,
      "grad_norm": 1.004014015197754,
      "learning_rate": 0.00011572375636921097,
      "loss": 3.061,
      "step": 32500
    },
    {
      "epoch": 1.3988120857364208,
      "eval_bleu": 26.979740483613593,
      "eval_gen_len": 27.522,
      "eval_loss": 2.7984821796417236,
      "eval_runtime": 58.3585,
      "eval_samples_per_second": 17.135,
      "eval_steps_per_second": 1.08,
      "step": 32500
    },
    {
      "epoch": 1.399242489455109,
      "grad_norm": 0.9037055969238281,
      "learning_rate": 0.00011567786628737767,
      "loss": 3.0285,
      "step": 32510
    },
    {
      "epoch": 1.399672893173797,
      "grad_norm": 0.8486781120300293,
      "learning_rate": 0.00011563197282049643,
      "loss": 2.9354,
      "step": 32520
    },
    {
      "epoch": 1.4001032968924851,
      "grad_norm": 0.89382004737854,
      "learning_rate": 0.00011558607597847626,
      "loss": 3.072,
      "step": 32530
    },
    {
      "epoch": 1.4005337006111733,
      "grad_norm": 0.9144525527954102,
      "learning_rate": 0.00011554017577122685,
      "loss": 3.0971,
      "step": 32540
    },
    {
      "epoch": 1.4009641043298613,
      "grad_norm": 1.0309182405471802,
      "learning_rate": 0.00011549427220865858,
      "loss": 3.022,
      "step": 32550
    },
    {
      "epoch": 1.4009641043298613,
      "eval_bleu": 26.984954890288524,
      "eval_gen_len": 27.391,
      "eval_loss": 2.7987637519836426,
      "eval_runtime": 58.5539,
      "eval_samples_per_second": 17.078,
      "eval_steps_per_second": 1.076,
      "step": 32550
    },
    {
      "epoch": 1.4013945080485495,
      "grad_norm": 0.8729045987129211,
      "learning_rate": 0.00011544836530068268,
      "loss": 2.9697,
      "step": 32560
    },
    {
      "epoch": 1.4018249117672377,
      "grad_norm": 0.9271597862243652,
      "learning_rate": 0.00011540245505721099,
      "loss": 2.9923,
      "step": 32570
    },
    {
      "epoch": 1.4022553154859259,
      "grad_norm": 1.0368624925613403,
      "learning_rate": 0.00011535654148815615,
      "loss": 3.0199,
      "step": 32580
    },
    {
      "epoch": 1.402685719204614,
      "grad_norm": 0.9027074575424194,
      "learning_rate": 0.0001153106246034314,
      "loss": 3.0152,
      "step": 32590
    },
    {
      "epoch": 1.403116122923302,
      "grad_norm": 0.9501023292541504,
      "learning_rate": 0.00011526470441295081,
      "loss": 3.1435,
      "step": 32600
    },
    {
      "epoch": 1.403116122923302,
      "eval_bleu": 27.307348879655,
      "eval_gen_len": 27.54,
      "eval_loss": 2.7938547134399414,
      "eval_runtime": 58.7848,
      "eval_samples_per_second": 17.011,
      "eval_steps_per_second": 1.072,
      "step": 32600
    },
    {
      "epoch": 1.4035465266419902,
      "grad_norm": 0.8944685459136963,
      "learning_rate": 0.00011521878092662912,
      "loss": 3.0397,
      "step": 32610
    },
    {
      "epoch": 1.4039769303606784,
      "grad_norm": 0.7788255214691162,
      "learning_rate": 0.00011517285415438179,
      "loss": 3.0473,
      "step": 32620
    },
    {
      "epoch": 1.4044073340793664,
      "grad_norm": 0.9440473914146423,
      "learning_rate": 0.000115126924106125,
      "loss": 3.0368,
      "step": 32630
    },
    {
      "epoch": 1.4048377377980545,
      "grad_norm": 0.8968331813812256,
      "learning_rate": 0.00011508099079177558,
      "loss": 3.0672,
      "step": 32640
    },
    {
      "epoch": 1.4052681415167427,
      "grad_norm": 0.8387996554374695,
      "learning_rate": 0.00011503505422125119,
      "loss": 3.0094,
      "step": 32650
    },
    {
      "epoch": 1.4052681415167427,
      "eval_bleu": 26.661782328071986,
      "eval_gen_len": 27.34,
      "eval_loss": 2.8012797832489014,
      "eval_runtime": 58.5439,
      "eval_samples_per_second": 17.081,
      "eval_steps_per_second": 1.076,
      "step": 32650
    },
    {
      "epoch": 1.4056985452354307,
      "grad_norm": 0.7616989016532898,
      "learning_rate": 0.00011498911440447005,
      "loss": 3.1003,
      "step": 32660
    },
    {
      "epoch": 1.4061289489541189,
      "grad_norm": 0.9293423891067505,
      "learning_rate": 0.0001149431713513511,
      "loss": 3.1639,
      "step": 32670
    },
    {
      "epoch": 1.406559352672807,
      "grad_norm": 0.9456495642662048,
      "learning_rate": 0.00011489722507181411,
      "loss": 2.9392,
      "step": 32680
    },
    {
      "epoch": 1.4069897563914953,
      "grad_norm": 0.900132954120636,
      "learning_rate": 0.00011485127557577942,
      "loss": 2.992,
      "step": 32690
    },
    {
      "epoch": 1.4074201601101834,
      "grad_norm": 0.9443192481994629,
      "learning_rate": 0.0001148053228731681,
      "loss": 2.9845,
      "step": 32700
    },
    {
      "epoch": 1.4074201601101834,
      "eval_bleu": 26.78034973089285,
      "eval_gen_len": 27.38,
      "eval_loss": 2.7996609210968018,
      "eval_runtime": 58.2792,
      "eval_samples_per_second": 17.159,
      "eval_steps_per_second": 1.081,
      "step": 32700
    },
    {
      "epoch": 1.4078505638288714,
      "grad_norm": 0.911862313747406,
      "learning_rate": 0.00011475936697390193,
      "loss": 2.9177,
      "step": 32710
    },
    {
      "epoch": 1.4082809675475596,
      "grad_norm": 0.9283809661865234,
      "learning_rate": 0.00011471340788790334,
      "loss": 3.089,
      "step": 32720
    },
    {
      "epoch": 1.4087113712662478,
      "grad_norm": 0.9029487371444702,
      "learning_rate": 0.00011466744562509548,
      "loss": 2.9368,
      "step": 32730
    },
    {
      "epoch": 1.4091417749849358,
      "grad_norm": 0.9426801204681396,
      "learning_rate": 0.00011462148019540223,
      "loss": 3.0608,
      "step": 32740
    },
    {
      "epoch": 1.409572178703624,
      "grad_norm": 0.9617746472358704,
      "learning_rate": 0.00011457551160874802,
      "loss": 3.0405,
      "step": 32750
    },
    {
      "epoch": 1.409572178703624,
      "eval_bleu": 27.107243766871267,
      "eval_gen_len": 27.325,
      "eval_loss": 2.8019089698791504,
      "eval_runtime": 57.7706,
      "eval_samples_per_second": 17.31,
      "eval_steps_per_second": 1.091,
      "step": 32750
    },
    {
      "epoch": 1.4100025824223121,
      "grad_norm": 0.9316317439079285,
      "learning_rate": 0.00011452953987505808,
      "loss": 3.0093,
      "step": 32760
    },
    {
      "epoch": 1.4104329861410003,
      "grad_norm": 0.9495084881782532,
      "learning_rate": 0.0001144835650042583,
      "loss": 3.0229,
      "step": 32770
    },
    {
      "epoch": 1.4108633898596885,
      "grad_norm": 0.9170530438423157,
      "learning_rate": 0.00011443758700627523,
      "loss": 2.9276,
      "step": 32780
    },
    {
      "epoch": 1.4112937935783765,
      "grad_norm": 1.0208346843719482,
      "learning_rate": 0.00011439160589103606,
      "loss": 3.1181,
      "step": 32790
    },
    {
      "epoch": 1.4117241972970647,
      "grad_norm": 0.9179314970970154,
      "learning_rate": 0.0001143456216684687,
      "loss": 3.1399,
      "step": 32800
    },
    {
      "epoch": 1.4117241972970647,
      "eval_bleu": 26.695921310403683,
      "eval_gen_len": 27.408,
      "eval_loss": 2.800661563873291,
      "eval_runtime": 58.5848,
      "eval_samples_per_second": 17.069,
      "eval_steps_per_second": 1.075,
      "step": 32800
    },
    {
      "epoch": 1.4121546010157529,
      "grad_norm": 0.9318320751190186,
      "learning_rate": 0.00011429963434850173,
      "loss": 2.9882,
      "step": 32810
    },
    {
      "epoch": 1.4125850047344408,
      "grad_norm": 0.8666809797286987,
      "learning_rate": 0.00011425364394106443,
      "loss": 2.9976,
      "step": 32820
    },
    {
      "epoch": 1.413015408453129,
      "grad_norm": 0.7676361203193665,
      "learning_rate": 0.00011420765045608666,
      "loss": 3.0032,
      "step": 32830
    },
    {
      "epoch": 1.4134458121718172,
      "grad_norm": 0.9802048206329346,
      "learning_rate": 0.00011416165390349898,
      "loss": 2.9586,
      "step": 32840
    },
    {
      "epoch": 1.4138762158905052,
      "grad_norm": 0.9839703440666199,
      "learning_rate": 0.00011411565429323266,
      "loss": 3.042,
      "step": 32850
    },
    {
      "epoch": 1.4138762158905052,
      "eval_bleu": 26.7673014294092,
      "eval_gen_len": 27.432,
      "eval_loss": 2.803121328353882,
      "eval_runtime": 58.7376,
      "eval_samples_per_second": 17.025,
      "eval_steps_per_second": 1.073,
      "step": 32850
    },
    {
      "epoch": 1.4143066196091933,
      "grad_norm": 0.8874682784080505,
      "learning_rate": 0.00011406965163521959,
      "loss": 2.8884,
      "step": 32860
    },
    {
      "epoch": 1.4147370233278815,
      "grad_norm": 0.912245512008667,
      "learning_rate": 0.00011402364593939225,
      "loss": 2.9107,
      "step": 32870
    },
    {
      "epoch": 1.4151674270465697,
      "grad_norm": 0.8764493465423584,
      "learning_rate": 0.00011397763721568393,
      "loss": 2.8746,
      "step": 32880
    },
    {
      "epoch": 1.415597830765258,
      "grad_norm": 0.9206176400184631,
      "learning_rate": 0.00011393162547402846,
      "loss": 3.034,
      "step": 32890
    },
    {
      "epoch": 1.4160282344839459,
      "grad_norm": 0.9454667568206787,
      "learning_rate": 0.00011388561072436035,
      "loss": 2.9736,
      "step": 32900
    },
    {
      "epoch": 1.4160282344839459,
      "eval_bleu": 26.915131788066375,
      "eval_gen_len": 27.399,
      "eval_loss": 2.7997539043426514,
      "eval_runtime": 59.0521,
      "eval_samples_per_second": 16.934,
      "eval_steps_per_second": 1.067,
      "step": 32900
    },
    {
      "epoch": 1.416458638202634,
      "grad_norm": 0.9011741280555725,
      "learning_rate": 0.00011383959297661477,
      "loss": 3.0409,
      "step": 32910
    },
    {
      "epoch": 1.4168890419213223,
      "grad_norm": 0.8086898922920227,
      "learning_rate": 0.00011379357224072751,
      "loss": 2.9447,
      "step": 32920
    },
    {
      "epoch": 1.4173194456400102,
      "grad_norm": 1.0340408086776733,
      "learning_rate": 0.00011374754852663505,
      "loss": 3.0696,
      "step": 32930
    },
    {
      "epoch": 1.4177498493586984,
      "grad_norm": 0.9644410610198975,
      "learning_rate": 0.0001137015218442745,
      "loss": 2.9851,
      "step": 32940
    },
    {
      "epoch": 1.4181802530773866,
      "grad_norm": 0.9674262404441833,
      "learning_rate": 0.00011365549220358354,
      "loss": 3.1352,
      "step": 32950
    },
    {
      "epoch": 1.4181802530773866,
      "eval_bleu": 26.634502039972755,
      "eval_gen_len": 27.388,
      "eval_loss": 2.799062490463257,
      "eval_runtime": 58.6027,
      "eval_samples_per_second": 17.064,
      "eval_steps_per_second": 1.075,
      "step": 32950
    },
    {
      "epoch": 1.4186106567960748,
      "grad_norm": 0.9401736259460449,
      "learning_rate": 0.00011360945961450058,
      "loss": 2.9894,
      "step": 32960
    },
    {
      "epoch": 1.419041060514763,
      "grad_norm": 0.9766166806221008,
      "learning_rate": 0.00011356342408696463,
      "loss": 3.019,
      "step": 32970
    },
    {
      "epoch": 1.419471464233451,
      "grad_norm": 0.9552183151245117,
      "learning_rate": 0.00011351738563091533,
      "loss": 3.0166,
      "step": 32980
    },
    {
      "epoch": 1.4199018679521391,
      "grad_norm": 0.9296891093254089,
      "learning_rate": 0.000113471344256293,
      "loss": 3.0225,
      "step": 32990
    },
    {
      "epoch": 1.4203322716708273,
      "grad_norm": 1.0304545164108276,
      "learning_rate": 0.00011342529997303848,
      "loss": 3.084,
      "step": 33000
    },
    {
      "epoch": 1.4203322716708273,
      "eval_bleu": 26.810217487838155,
      "eval_gen_len": 27.409,
      "eval_loss": 2.801915168762207,
      "eval_runtime": 58.514,
      "eval_samples_per_second": 17.09,
      "eval_steps_per_second": 1.077,
      "step": 33000
    },
    {
      "epoch": 1.4207626753895153,
      "grad_norm": 0.9612839818000793,
      "learning_rate": 0.00011337925279109338,
      "loss": 3.0682,
      "step": 33010
    },
    {
      "epoch": 1.4211930791082035,
      "grad_norm": 0.890178382396698,
      "learning_rate": 0.00011333320272039984,
      "loss": 3.1145,
      "step": 33020
    },
    {
      "epoch": 1.4216234828268917,
      "grad_norm": 0.8962496519088745,
      "learning_rate": 0.00011328714977090063,
      "loss": 3.055,
      "step": 33030
    },
    {
      "epoch": 1.4220538865455796,
      "grad_norm": 0.9364532232284546,
      "learning_rate": 0.00011324109395253914,
      "loss": 2.9677,
      "step": 33040
    },
    {
      "epoch": 1.4224842902642678,
      "grad_norm": 0.9969487190246582,
      "learning_rate": 0.00011319503527525946,
      "loss": 2.9859,
      "step": 33050
    },
    {
      "epoch": 1.4224842902642678,
      "eval_bleu": 26.721003591143624,
      "eval_gen_len": 27.505,
      "eval_loss": 2.8024990558624268,
      "eval_runtime": 58.7289,
      "eval_samples_per_second": 17.027,
      "eval_steps_per_second": 1.073,
      "step": 33050
    },
    {
      "epoch": 1.422914693982956,
      "grad_norm": 0.9086958169937134,
      "learning_rate": 0.00011314897374900621,
      "loss": 3.0435,
      "step": 33060
    },
    {
      "epoch": 1.4233450977016442,
      "grad_norm": 0.8015779256820679,
      "learning_rate": 0.00011310290938372459,
      "loss": 2.9135,
      "step": 33070
    },
    {
      "epoch": 1.4237755014203324,
      "grad_norm": 0.9337118268013,
      "learning_rate": 0.00011305684218936056,
      "loss": 3.0001,
      "step": 33080
    },
    {
      "epoch": 1.4242059051390203,
      "grad_norm": 0.8237538933753967,
      "learning_rate": 0.00011301077217586058,
      "loss": 3.1103,
      "step": 33090
    },
    {
      "epoch": 1.4246363088577085,
      "grad_norm": 0.8790501356124878,
      "learning_rate": 0.00011296469935317175,
      "loss": 2.9802,
      "step": 33100
    },
    {
      "epoch": 1.4246363088577085,
      "eval_bleu": 26.08200519982695,
      "eval_gen_len": 27.369,
      "eval_loss": 2.8032724857330322,
      "eval_runtime": 57.8136,
      "eval_samples_per_second": 17.297,
      "eval_steps_per_second": 1.09,
      "step": 33100
    },
    {
      "epoch": 1.4250667125763967,
      "grad_norm": 0.8685802221298218,
      "learning_rate": 0.00011291862373124175,
      "loss": 2.961,
      "step": 33110
    },
    {
      "epoch": 1.4254971162950847,
      "grad_norm": 0.9196025133132935,
      "learning_rate": 0.00011287254532001888,
      "loss": 2.8918,
      "step": 33120
    },
    {
      "epoch": 1.4259275200137729,
      "grad_norm": 0.8909507393836975,
      "learning_rate": 0.00011282646412945205,
      "loss": 2.9728,
      "step": 33130
    },
    {
      "epoch": 1.426357923732461,
      "grad_norm": 0.8449025750160217,
      "learning_rate": 0.00011278038016949082,
      "loss": 2.978,
      "step": 33140
    },
    {
      "epoch": 1.4267883274511493,
      "grad_norm": 0.9468787312507629,
      "learning_rate": 0.00011273429345008522,
      "loss": 2.9929,
      "step": 33150
    },
    {
      "epoch": 1.4267883274511493,
      "eval_bleu": 26.348708632061527,
      "eval_gen_len": 27.377,
      "eval_loss": 2.802471876144409,
      "eval_runtime": 58.334,
      "eval_samples_per_second": 17.143,
      "eval_steps_per_second": 1.08,
      "step": 33150
    },
    {
      "epoch": 1.4272187311698374,
      "grad_norm": 1.0070217847824097,
      "learning_rate": 0.00011268820398118598,
      "loss": 3.0182,
      "step": 33160
    },
    {
      "epoch": 1.4276491348885254,
      "grad_norm": 0.8459610939025879,
      "learning_rate": 0.00011264211177274438,
      "loss": 3.1273,
      "step": 33170
    },
    {
      "epoch": 1.4280795386072136,
      "grad_norm": 0.9224976897239685,
      "learning_rate": 0.00011259601683471235,
      "loss": 3.0268,
      "step": 33180
    },
    {
      "epoch": 1.4285099423259018,
      "grad_norm": 0.8116521239280701,
      "learning_rate": 0.00011254991917704232,
      "loss": 3.0742,
      "step": 33190
    },
    {
      "epoch": 1.4289403460445897,
      "grad_norm": 0.8861279487609863,
      "learning_rate": 0.00011250381880968736,
      "loss": 2.9672,
      "step": 33200
    },
    {
      "epoch": 1.4289403460445897,
      "eval_bleu": 26.414867631961318,
      "eval_gen_len": 27.354,
      "eval_loss": 2.7999465465545654,
      "eval_runtime": 57.8414,
      "eval_samples_per_second": 17.289,
      "eval_steps_per_second": 1.089,
      "step": 33200
    },
    {
      "epoch": 1.429370749763278,
      "grad_norm": 0.9325332641601562,
      "learning_rate": 0.00011245771574260116,
      "loss": 3.0325,
      "step": 33210
    },
    {
      "epoch": 1.4298011534819661,
      "grad_norm": 0.8930558562278748,
      "learning_rate": 0.00011241160998573787,
      "loss": 3.0668,
      "step": 33220
    },
    {
      "epoch": 1.430231557200654,
      "grad_norm": 0.8768888115882874,
      "learning_rate": 0.00011236550154905241,
      "loss": 3.0458,
      "step": 33230
    },
    {
      "epoch": 1.4306619609193423,
      "grad_norm": 0.8691657781600952,
      "learning_rate": 0.00011231939044250006,
      "loss": 2.9666,
      "step": 33240
    },
    {
      "epoch": 1.4310923646380305,
      "grad_norm": 0.8705754280090332,
      "learning_rate": 0.00011227327667603685,
      "loss": 2.9957,
      "step": 33250
    },
    {
      "epoch": 1.4310923646380305,
      "eval_bleu": 27.10049132594899,
      "eval_gen_len": 27.434,
      "eval_loss": 2.7977547645568848,
      "eval_runtime": 57.7352,
      "eval_samples_per_second": 17.32,
      "eval_steps_per_second": 1.091,
      "step": 33250
    },
    {
      "epoch": 1.4315227683567187,
      "grad_norm": 1.0294772386550903,
      "learning_rate": 0.00011222716025961928,
      "loss": 3.1222,
      "step": 33260
    },
    {
      "epoch": 1.4319531720754068,
      "grad_norm": 0.8313285112380981,
      "learning_rate": 0.00011218104120320449,
      "loss": 3.0266,
      "step": 33270
    },
    {
      "epoch": 1.4323835757940948,
      "grad_norm": 0.8363235592842102,
      "learning_rate": 0.00011213491951675017,
      "loss": 3.0559,
      "step": 33280
    },
    {
      "epoch": 1.432813979512783,
      "grad_norm": 0.9724888801574707,
      "learning_rate": 0.00011208879521021456,
      "loss": 3.0863,
      "step": 33290
    },
    {
      "epoch": 1.4332443832314712,
      "grad_norm": 0.893961489200592,
      "learning_rate": 0.00011204266829355648,
      "loss": 2.9567,
      "step": 33300
    },
    {
      "epoch": 1.4332443832314712,
      "eval_bleu": 26.661111994044166,
      "eval_gen_len": 27.475,
      "eval_loss": 2.8011512756347656,
      "eval_runtime": 58.3937,
      "eval_samples_per_second": 17.125,
      "eval_steps_per_second": 1.079,
      "step": 33300
    },
    {
      "epoch": 1.4336747869501592,
      "grad_norm": 0.9196439385414124,
      "learning_rate": 0.00011199653877673533,
      "loss": 3.1472,
      "step": 33310
    },
    {
      "epoch": 1.4341051906688473,
      "grad_norm": 0.8927867412567139,
      "learning_rate": 0.00011195040666971098,
      "loss": 3.0738,
      "step": 33320
    },
    {
      "epoch": 1.4345355943875355,
      "grad_norm": 0.9374719262123108,
      "learning_rate": 0.000111904271982444,
      "loss": 3.1125,
      "step": 33330
    },
    {
      "epoch": 1.4349659981062237,
      "grad_norm": 0.8987042307853699,
      "learning_rate": 0.00011185813472489541,
      "loss": 2.9162,
      "step": 33340
    },
    {
      "epoch": 1.435396401824912,
      "grad_norm": 0.9600557684898376,
      "learning_rate": 0.00011181199490702683,
      "loss": 3.1343,
      "step": 33350
    },
    {
      "epoch": 1.435396401824912,
      "eval_bleu": 26.751208744758152,
      "eval_gen_len": 27.455,
      "eval_loss": 2.798060417175293,
      "eval_runtime": 58.1984,
      "eval_samples_per_second": 17.183,
      "eval_steps_per_second": 1.083,
      "step": 33350
    },
    {
      "epoch": 1.4358268055435999,
      "grad_norm": 0.8169838190078735,
      "learning_rate": 0.00011176585253880046,
      "loss": 3.0669,
      "step": 33360
    },
    {
      "epoch": 1.436257209262288,
      "grad_norm": 0.873589038848877,
      "learning_rate": 0.00011171970763017896,
      "loss": 3.0576,
      "step": 33370
    },
    {
      "epoch": 1.4366876129809762,
      "grad_norm": 0.9987390041351318,
      "learning_rate": 0.00011167356019112562,
      "loss": 2.9889,
      "step": 33380
    },
    {
      "epoch": 1.4371180166996642,
      "grad_norm": 0.9516214728355408,
      "learning_rate": 0.0001116274102316043,
      "loss": 3.0198,
      "step": 33390
    },
    {
      "epoch": 1.4375484204183524,
      "grad_norm": 0.9362028241157532,
      "learning_rate": 0.00011158125776157928,
      "loss": 3.157,
      "step": 33400
    },
    {
      "epoch": 1.4375484204183524,
      "eval_bleu": 26.576748919892186,
      "eval_gen_len": 27.363,
      "eval_loss": 2.8014702796936035,
      "eval_runtime": 57.7683,
      "eval_samples_per_second": 17.311,
      "eval_steps_per_second": 1.091,
      "step": 33400
    },
    {
      "epoch": 1.4379788241370406,
      "grad_norm": 0.8650452494621277,
      "learning_rate": 0.00011153510279101547,
      "loss": 2.9935,
      "step": 33410
    },
    {
      "epoch": 1.4384092278557286,
      "grad_norm": 1.0137383937835693,
      "learning_rate": 0.00011148894532987833,
      "loss": 3.0209,
      "step": 33420
    },
    {
      "epoch": 1.4388396315744167,
      "grad_norm": 0.8193219900131226,
      "learning_rate": 0.00011144278538813384,
      "loss": 2.943,
      "step": 33430
    },
    {
      "epoch": 1.439270035293105,
      "grad_norm": 0.8730712532997131,
      "learning_rate": 0.00011139662297574846,
      "loss": 2.9856,
      "step": 33440
    },
    {
      "epoch": 1.4397004390117931,
      "grad_norm": 0.8018248081207275,
      "learning_rate": 0.00011135045810268931,
      "loss": 3.0117,
      "step": 33450
    },
    {
      "epoch": 1.4397004390117931,
      "eval_bleu": 26.75922363195293,
      "eval_gen_len": 27.455,
      "eval_loss": 2.801361560821533,
      "eval_runtime": 58.5877,
      "eval_samples_per_second": 17.068,
      "eval_steps_per_second": 1.075,
      "step": 33450
    },
    {
      "epoch": 1.4401308427304813,
      "grad_norm": 0.9325774908065796,
      "learning_rate": 0.0001113042907789239,
      "loss": 2.9771,
      "step": 33460
    },
    {
      "epoch": 1.4405612464491693,
      "grad_norm": 0.8541513085365295,
      "learning_rate": 0.00011125812101442039,
      "loss": 3.0004,
      "step": 33470
    },
    {
      "epoch": 1.4409916501678575,
      "grad_norm": 0.9085054397583008,
      "learning_rate": 0.00011121194881914736,
      "loss": 3.0496,
      "step": 33480
    },
    {
      "epoch": 1.4414220538865457,
      "grad_norm": 0.9358139038085938,
      "learning_rate": 0.00011116577420307399,
      "loss": 3.0747,
      "step": 33490
    },
    {
      "epoch": 1.4418524576052336,
      "grad_norm": 1.0264136791229248,
      "learning_rate": 0.00011111959717616996,
      "loss": 3.0863,
      "step": 33500
    },
    {
      "epoch": 1.4418524576052336,
      "eval_bleu": 26.93091542367636,
      "eval_gen_len": 27.535,
      "eval_loss": 2.800109386444092,
      "eval_runtime": 58.195,
      "eval_samples_per_second": 17.184,
      "eval_steps_per_second": 1.083,
      "step": 33500
    },
    {
      "epoch": 1.4422828613239218,
      "grad_norm": 0.857130229473114,
      "learning_rate": 0.00011107341774840545,
      "loss": 3.0594,
      "step": 33510
    },
    {
      "epoch": 1.44271326504261,
      "grad_norm": 0.9742320775985718,
      "learning_rate": 0.00011102723592975122,
      "loss": 3.1053,
      "step": 33520
    },
    {
      "epoch": 1.443143668761298,
      "grad_norm": 0.9363448619842529,
      "learning_rate": 0.00011098105173017844,
      "loss": 3.0274,
      "step": 33530
    },
    {
      "epoch": 1.4435740724799861,
      "grad_norm": 0.8778446316719055,
      "learning_rate": 0.00011093486515965887,
      "loss": 3.0353,
      "step": 33540
    },
    {
      "epoch": 1.4440044761986743,
      "grad_norm": 0.8943845629692078,
      "learning_rate": 0.00011088867622816485,
      "loss": 3.0497,
      "step": 33550
    },
    {
      "epoch": 1.4440044761986743,
      "eval_bleu": 26.85892073984732,
      "eval_gen_len": 27.339,
      "eval_loss": 2.7978150844573975,
      "eval_runtime": 58.3908,
      "eval_samples_per_second": 17.126,
      "eval_steps_per_second": 1.079,
      "step": 33550
    },
    {
      "epoch": 1.4444348799173625,
      "grad_norm": 0.9679926633834839,
      "learning_rate": 0.00011084248494566909,
      "loss": 3.1178,
      "step": 33560
    },
    {
      "epoch": 1.4448652836360507,
      "grad_norm": 0.9146668314933777,
      "learning_rate": 0.00011079629132214483,
      "loss": 3.0241,
      "step": 33570
    },
    {
      "epoch": 1.4452956873547387,
      "grad_norm": 0.9318057894706726,
      "learning_rate": 0.00011075009536756593,
      "loss": 3.1096,
      "step": 33580
    },
    {
      "epoch": 1.4457260910734269,
      "grad_norm": 0.8633138537406921,
      "learning_rate": 0.00011070389709190663,
      "loss": 3.0486,
      "step": 33590
    },
    {
      "epoch": 1.446156494792115,
      "grad_norm": 0.8844267725944519,
      "learning_rate": 0.00011065769650514172,
      "loss": 3.0146,
      "step": 33600
    },
    {
      "epoch": 1.446156494792115,
      "eval_bleu": 26.65833223945518,
      "eval_gen_len": 27.456,
      "eval_loss": 2.7977850437164307,
      "eval_runtime": 58.1094,
      "eval_samples_per_second": 17.209,
      "eval_steps_per_second": 1.084,
      "step": 33600
    },
    {
      "epoch": 1.446586898510803,
      "grad_norm": 0.9292277097702026,
      "learning_rate": 0.0001106114936172465,
      "loss": 3.0193,
      "step": 33610
    },
    {
      "epoch": 1.4470173022294912,
      "grad_norm": 0.9203578233718872,
      "learning_rate": 0.00011056528843819672,
      "loss": 2.9572,
      "step": 33620
    },
    {
      "epoch": 1.4474477059481794,
      "grad_norm": 0.9444706439971924,
      "learning_rate": 0.0001105190809779687,
      "loss": 3.0574,
      "step": 33630
    },
    {
      "epoch": 1.4478781096668676,
      "grad_norm": 0.9186599850654602,
      "learning_rate": 0.00011047287124653918,
      "loss": 3.032,
      "step": 33640
    },
    {
      "epoch": 1.4483085133855558,
      "grad_norm": 0.7893596291542053,
      "learning_rate": 0.00011042665925388544,
      "loss": 3.0477,
      "step": 33650
    },
    {
      "epoch": 1.4483085133855558,
      "eval_bleu": 26.833648513757513,
      "eval_gen_len": 27.422,
      "eval_loss": 2.801124095916748,
      "eval_runtime": 58.4969,
      "eval_samples_per_second": 17.095,
      "eval_steps_per_second": 1.077,
      "step": 33650
    },
    {
      "epoch": 1.4487389171042437,
      "grad_norm": 0.8831990361213684,
      "learning_rate": 0.00011038044500998521,
      "loss": 2.9725,
      "step": 33660
    },
    {
      "epoch": 1.449169320822932,
      "grad_norm": 0.8510721325874329,
      "learning_rate": 0.00011033422852481676,
      "loss": 2.9606,
      "step": 33670
    },
    {
      "epoch": 1.4495997245416201,
      "grad_norm": 0.9503365159034729,
      "learning_rate": 0.00011028800980835878,
      "loss": 2.9555,
      "step": 33680
    },
    {
      "epoch": 1.450030128260308,
      "grad_norm": 0.9112938046455383,
      "learning_rate": 0.00011024178887059046,
      "loss": 3.0491,
      "step": 33690
    },
    {
      "epoch": 1.4504605319789963,
      "grad_norm": 0.8338820934295654,
      "learning_rate": 0.0001101955657214915,
      "loss": 2.9816,
      "step": 33700
    },
    {
      "epoch": 1.4504605319789963,
      "eval_bleu": 26.83924543852609,
      "eval_gen_len": 27.395,
      "eval_loss": 2.798773765563965,
      "eval_runtime": 58.6947,
      "eval_samples_per_second": 17.037,
      "eval_steps_per_second": 1.073,
      "step": 33700
    },
    {
      "epoch": 1.4508909356976845,
      "grad_norm": 0.9776566624641418,
      "learning_rate": 0.00011014934037104205,
      "loss": 3.0042,
      "step": 33710
    },
    {
      "epoch": 1.4513213394163724,
      "grad_norm": 0.9807071089744568,
      "learning_rate": 0.00011010311282922274,
      "loss": 2.9644,
      "step": 33720
    },
    {
      "epoch": 1.4517517431350606,
      "grad_norm": 0.9989790320396423,
      "learning_rate": 0.00011005688310601467,
      "loss": 3.0658,
      "step": 33730
    },
    {
      "epoch": 1.4521821468537488,
      "grad_norm": 0.9688867330551147,
      "learning_rate": 0.00011001065121139946,
      "loss": 2.933,
      "step": 33740
    },
    {
      "epoch": 1.452612550572437,
      "grad_norm": 0.8111706972122192,
      "learning_rate": 0.00010996441715535912,
      "loss": 3.0089,
      "step": 33750
    },
    {
      "epoch": 1.452612550572437,
      "eval_bleu": 26.58326581216453,
      "eval_gen_len": 27.403,
      "eval_loss": 2.7994916439056396,
      "eval_runtime": 58.5093,
      "eval_samples_per_second": 17.091,
      "eval_steps_per_second": 1.077,
      "step": 33750
    },
    {
      "epoch": 1.4530429542911252,
      "grad_norm": 0.9194016456604004,
      "learning_rate": 0.00010991818094787616,
      "loss": 3.019,
      "step": 33760
    },
    {
      "epoch": 1.4534733580098131,
      "grad_norm": 0.9344696998596191,
      "learning_rate": 0.00010987194259893356,
      "loss": 3.1121,
      "step": 33770
    },
    {
      "epoch": 1.4539037617285013,
      "grad_norm": 0.8964006900787354,
      "learning_rate": 0.00010982570211851475,
      "loss": 3.0779,
      "step": 33780
    },
    {
      "epoch": 1.4543341654471895,
      "grad_norm": 0.8108524084091187,
      "learning_rate": 0.00010977945951660369,
      "loss": 3.0345,
      "step": 33790
    },
    {
      "epoch": 1.4547645691658775,
      "grad_norm": 0.8411178588867188,
      "learning_rate": 0.00010973321480318461,
      "loss": 2.9283,
      "step": 33800
    },
    {
      "epoch": 1.4547645691658775,
      "eval_bleu": 26.63658726251135,
      "eval_gen_len": 27.39,
      "eval_loss": 2.801492929458618,
      "eval_runtime": 58.7648,
      "eval_samples_per_second": 17.017,
      "eval_steps_per_second": 1.072,
      "step": 33800
    },
    {
      "epoch": 1.4551949728845657,
      "grad_norm": 1.0091776847839355,
      "learning_rate": 0.00010968696798824245,
      "loss": 3.0151,
      "step": 33810
    },
    {
      "epoch": 1.4556253766032539,
      "grad_norm": 0.9478501081466675,
      "learning_rate": 0.00010964071908176244,
      "loss": 2.8994,
      "step": 33820
    },
    {
      "epoch": 1.456055780321942,
      "grad_norm": 0.9132391810417175,
      "learning_rate": 0.00010959446809373029,
      "loss": 2.957,
      "step": 33830
    },
    {
      "epoch": 1.4564861840406302,
      "grad_norm": 0.992348313331604,
      "learning_rate": 0.00010954821503413214,
      "loss": 3.0314,
      "step": 33840
    },
    {
      "epoch": 1.4569165877593182,
      "grad_norm": 0.9409032464027405,
      "learning_rate": 0.00010950195991295465,
      "loss": 3.0186,
      "step": 33850
    },
    {
      "epoch": 1.4569165877593182,
      "eval_bleu": 26.60434497963748,
      "eval_gen_len": 27.38,
      "eval_loss": 2.7978947162628174,
      "eval_runtime": 58.1514,
      "eval_samples_per_second": 17.196,
      "eval_steps_per_second": 1.083,
      "step": 33850
    },
    {
      "epoch": 1.4573469914780064,
      "grad_norm": 0.9058597683906555,
      "learning_rate": 0.00010945570274018487,
      "loss": 2.8036,
      "step": 33860
    },
    {
      "epoch": 1.4577773951966946,
      "grad_norm": 0.8841320276260376,
      "learning_rate": 0.00010940944352581029,
      "loss": 3.0061,
      "step": 33870
    },
    {
      "epoch": 1.4582077989153825,
      "grad_norm": 0.8907173871994019,
      "learning_rate": 0.00010936318227981887,
      "loss": 3.0772,
      "step": 33880
    },
    {
      "epoch": 1.4586382026340707,
      "grad_norm": 0.8328989148139954,
      "learning_rate": 0.00010931691901219898,
      "loss": 3.068,
      "step": 33890
    },
    {
      "epoch": 1.459068606352759,
      "grad_norm": 0.8999397158622742,
      "learning_rate": 0.00010927065373293941,
      "loss": 3.0669,
      "step": 33900
    },
    {
      "epoch": 1.459068606352759,
      "eval_bleu": 27.02313402717425,
      "eval_gen_len": 27.354,
      "eval_loss": 2.7999956607818604,
      "eval_runtime": 58.8664,
      "eval_samples_per_second": 16.988,
      "eval_steps_per_second": 1.07,
      "step": 33900
    },
    {
      "epoch": 1.459499010071447,
      "grad_norm": 0.8914393782615662,
      "learning_rate": 0.00010922438645202949,
      "loss": 3.0182,
      "step": 33910
    },
    {
      "epoch": 1.459929413790135,
      "grad_norm": 0.8036893010139465,
      "learning_rate": 0.00010917811717945888,
      "loss": 3.0336,
      "step": 33920
    },
    {
      "epoch": 1.4603598175088233,
      "grad_norm": 1.0355976819992065,
      "learning_rate": 0.00010913184592521763,
      "loss": 2.9641,
      "step": 33930
    },
    {
      "epoch": 1.4607902212275115,
      "grad_norm": 0.849280059337616,
      "learning_rate": 0.00010908557269929636,
      "loss": 3.0176,
      "step": 33940
    },
    {
      "epoch": 1.4612206249461996,
      "grad_norm": 0.9539756774902344,
      "learning_rate": 0.00010903929751168602,
      "loss": 3.1026,
      "step": 33950
    },
    {
      "epoch": 1.4612206249461996,
      "eval_bleu": 27.00781408184892,
      "eval_gen_len": 27.489,
      "eval_loss": 2.7976393699645996,
      "eval_runtime": 58.7303,
      "eval_samples_per_second": 17.027,
      "eval_steps_per_second": 1.073,
      "step": 33950
    },
    {
      "epoch": 1.4616510286648876,
      "grad_norm": 0.8205636739730835,
      "learning_rate": 0.00010899302037237802,
      "loss": 2.9109,
      "step": 33960
    },
    {
      "epoch": 1.4620814323835758,
      "grad_norm": 0.9605591297149658,
      "learning_rate": 0.0001089467412913641,
      "loss": 2.9641,
      "step": 33970
    },
    {
      "epoch": 1.462511836102264,
      "grad_norm": 0.8913446068763733,
      "learning_rate": 0.00010890046027863658,
      "loss": 3.0615,
      "step": 33980
    },
    {
      "epoch": 1.462942239820952,
      "grad_norm": 0.8814638257026672,
      "learning_rate": 0.00010885417734418808,
      "loss": 3.0603,
      "step": 33990
    },
    {
      "epoch": 1.4633726435396401,
      "grad_norm": 0.9346630573272705,
      "learning_rate": 0.00010880789249801164,
      "loss": 3.0284,
      "step": 34000
    },
    {
      "epoch": 1.4633726435396401,
      "eval_bleu": 26.601033079728783,
      "eval_gen_len": 27.458,
      "eval_loss": 2.8018429279327393,
      "eval_runtime": 58.609,
      "eval_samples_per_second": 17.062,
      "eval_steps_per_second": 1.075,
      "step": 34000
    },
    {
      "epoch": 1.4638030472583283,
      "grad_norm": 0.8815158605575562,
      "learning_rate": 0.00010876160575010077,
      "loss": 2.9679,
      "step": 34010
    },
    {
      "epoch": 1.4642334509770165,
      "grad_norm": 0.8276475071907043,
      "learning_rate": 0.00010871531711044935,
      "loss": 2.9846,
      "step": 34020
    },
    {
      "epoch": 1.4646638546957047,
      "grad_norm": 0.9076135754585266,
      "learning_rate": 0.00010866902658905169,
      "loss": 3.01,
      "step": 34030
    },
    {
      "epoch": 1.4650942584143927,
      "grad_norm": 0.9554873704910278,
      "learning_rate": 0.0001086227341959025,
      "loss": 3.0016,
      "step": 34040
    },
    {
      "epoch": 1.4655246621330809,
      "grad_norm": 0.8278958797454834,
      "learning_rate": 0.00010857643994099684,
      "loss": 3.0492,
      "step": 34050
    },
    {
      "epoch": 1.4655246621330809,
      "eval_bleu": 27.05899492615323,
      "eval_gen_len": 27.507,
      "eval_loss": 2.798983097076416,
      "eval_runtime": 58.8679,
      "eval_samples_per_second": 16.987,
      "eval_steps_per_second": 1.07,
      "step": 34050
    },
    {
      "epoch": 1.465955065851769,
      "grad_norm": 0.8811746835708618,
      "learning_rate": 0.00010853014383433026,
      "loss": 3.0633,
      "step": 34060
    },
    {
      "epoch": 1.466385469570457,
      "grad_norm": 0.888992190361023,
      "learning_rate": 0.00010848384588589868,
      "loss": 3.0427,
      "step": 34070
    },
    {
      "epoch": 1.4668158732891452,
      "grad_norm": 0.8243176937103271,
      "learning_rate": 0.00010843754610569836,
      "loss": 3.0576,
      "step": 34080
    },
    {
      "epoch": 1.4672462770078334,
      "grad_norm": 0.8862220048904419,
      "learning_rate": 0.00010839124450372604,
      "loss": 3.0225,
      "step": 34090
    },
    {
      "epoch": 1.4676766807265214,
      "grad_norm": 0.9410406351089478,
      "learning_rate": 0.00010834494108997882,
      "loss": 2.9636,
      "step": 34100
    },
    {
      "epoch": 1.4676766807265214,
      "eval_bleu": 26.93872668930492,
      "eval_gen_len": 27.34,
      "eval_loss": 2.7989702224731445,
      "eval_runtime": 57.8854,
      "eval_samples_per_second": 17.276,
      "eval_steps_per_second": 1.088,
      "step": 34100
    },
    {
      "epoch": 1.4681070844452095,
      "grad_norm": 0.8615683913230896,
      "learning_rate": 0.00010829863587445416,
      "loss": 3.0162,
      "step": 34110
    },
    {
      "epoch": 1.4685374881638977,
      "grad_norm": 0.9967538714408875,
      "learning_rate": 0.00010825232886714998,
      "loss": 3.0968,
      "step": 34120
    },
    {
      "epoch": 1.468967891882586,
      "grad_norm": 0.9513347744941711,
      "learning_rate": 0.00010820602007806451,
      "loss": 3.0192,
      "step": 34130
    },
    {
      "epoch": 1.469398295601274,
      "grad_norm": 0.976712703704834,
      "learning_rate": 0.00010815970951719638,
      "loss": 3.1512,
      "step": 34140
    },
    {
      "epoch": 1.469828699319962,
      "grad_norm": 0.8476244211196899,
      "learning_rate": 0.00010811339719454467,
      "loss": 3.0004,
      "step": 34150
    },
    {
      "epoch": 1.469828699319962,
      "eval_bleu": 26.793368727564772,
      "eval_gen_len": 27.351,
      "eval_loss": 2.801713466644287,
      "eval_runtime": 57.6945,
      "eval_samples_per_second": 17.333,
      "eval_steps_per_second": 1.092,
      "step": 34150
    },
    {
      "epoch": 1.4702591030386503,
      "grad_norm": 0.8858454823493958,
      "learning_rate": 0.00010806708312010878,
      "loss": 3.0607,
      "step": 34160
    },
    {
      "epoch": 1.4706895067573384,
      "grad_norm": 0.846728503704071,
      "learning_rate": 0.00010802076730388844,
      "loss": 2.9798,
      "step": 34170
    },
    {
      "epoch": 1.4711199104760264,
      "grad_norm": 0.9456939101219177,
      "learning_rate": 0.00010797444975588387,
      "loss": 2.9999,
      "step": 34180
    },
    {
      "epoch": 1.4715503141947146,
      "grad_norm": 0.898419201374054,
      "learning_rate": 0.00010792813048609563,
      "loss": 3.0567,
      "step": 34190
    },
    {
      "epoch": 1.4719807179134028,
      "grad_norm": 0.8888066411018372,
      "learning_rate": 0.0001078818095045246,
      "loss": 2.9464,
      "step": 34200
    },
    {
      "epoch": 1.4719807179134028,
      "eval_bleu": 26.979261207280526,
      "eval_gen_len": 27.34,
      "eval_loss": 2.798920154571533,
      "eval_runtime": 58.3074,
      "eval_samples_per_second": 17.15,
      "eval_steps_per_second": 1.08,
      "step": 34200
    },
    {
      "epoch": 1.472411121632091,
      "grad_norm": 0.8168314099311829,
      "learning_rate": 0.00010783548682117204,
      "loss": 2.9412,
      "step": 34210
    },
    {
      "epoch": 1.4728415253507792,
      "grad_norm": 0.929517388343811,
      "learning_rate": 0.00010778916244603965,
      "loss": 3.029,
      "step": 34220
    },
    {
      "epoch": 1.4732719290694671,
      "grad_norm": 1.0296956300735474,
      "learning_rate": 0.00010774283638912938,
      "loss": 2.9331,
      "step": 34230
    },
    {
      "epoch": 1.4737023327881553,
      "grad_norm": 0.8729868531227112,
      "learning_rate": 0.0001076965086604437,
      "loss": 3.1043,
      "step": 34240
    },
    {
      "epoch": 1.4741327365068435,
      "grad_norm": 1.0042450428009033,
      "learning_rate": 0.00010765017926998524,
      "loss": 2.9847,
      "step": 34250
    },
    {
      "epoch": 1.4741327365068435,
      "eval_bleu": 26.552397264496495,
      "eval_gen_len": 27.431,
      "eval_loss": 2.8036718368530273,
      "eval_runtime": 58.4097,
      "eval_samples_per_second": 17.12,
      "eval_steps_per_second": 1.079,
      "step": 34250
    },
    {
      "epoch": 1.4745631402255315,
      "grad_norm": 0.9226530194282532,
      "learning_rate": 0.00010760384822775714,
      "loss": 2.9535,
      "step": 34260
    },
    {
      "epoch": 1.4749935439442197,
      "grad_norm": 0.988858699798584,
      "learning_rate": 0.00010755751554376286,
      "loss": 2.9493,
      "step": 34270
    },
    {
      "epoch": 1.4754239476629079,
      "grad_norm": 0.9038745164871216,
      "learning_rate": 0.00010751118122800623,
      "loss": 3.0884,
      "step": 34280
    },
    {
      "epoch": 1.4758543513815958,
      "grad_norm": 1.044633388519287,
      "learning_rate": 0.00010746484529049137,
      "loss": 3.0266,
      "step": 34290
    },
    {
      "epoch": 1.476284755100284,
      "grad_norm": 0.9083157181739807,
      "learning_rate": 0.00010741850774122281,
      "loss": 2.9456,
      "step": 34300
    },
    {
      "epoch": 1.476284755100284,
      "eval_bleu": 26.89971115938062,
      "eval_gen_len": 27.372,
      "eval_loss": 2.8011295795440674,
      "eval_runtime": 58.0576,
      "eval_samples_per_second": 17.224,
      "eval_steps_per_second": 1.085,
      "step": 34300
    },
    {
      "epoch": 1.4767151588189722,
      "grad_norm": 0.9845211505889893,
      "learning_rate": 0.0001073721685902054,
      "loss": 3.0272,
      "step": 34310
    },
    {
      "epoch": 1.4771455625376604,
      "grad_norm": 0.8953176736831665,
      "learning_rate": 0.00010732582784744436,
      "loss": 3.04,
      "step": 34320
    },
    {
      "epoch": 1.4775759662563486,
      "grad_norm": 0.9182773232460022,
      "learning_rate": 0.00010727948552294523,
      "loss": 3.0087,
      "step": 34330
    },
    {
      "epoch": 1.4780063699750365,
      "grad_norm": 1.0422639846801758,
      "learning_rate": 0.00010723314162671388,
      "loss": 3.0832,
      "step": 34340
    },
    {
      "epoch": 1.4784367736937247,
      "grad_norm": 0.887238621711731,
      "learning_rate": 0.00010718679616875653,
      "loss": 3.1265,
      "step": 34350
    },
    {
      "epoch": 1.4784367736937247,
      "eval_bleu": 27.238315493065993,
      "eval_gen_len": 27.488,
      "eval_loss": 2.7966063022613525,
      "eval_runtime": 58.4597,
      "eval_samples_per_second": 17.106,
      "eval_steps_per_second": 1.078,
      "step": 34350
    },
    {
      "epoch": 1.478867177412413,
      "grad_norm": 1.0295037031173706,
      "learning_rate": 0.0001071404491590798,
      "loss": 2.9731,
      "step": 34360
    },
    {
      "epoch": 1.4792975811311009,
      "grad_norm": 0.8764021396636963,
      "learning_rate": 0.00010709410060769054,
      "loss": 3.0888,
      "step": 34370
    },
    {
      "epoch": 1.479727984849789,
      "grad_norm": 0.8856255412101746,
      "learning_rate": 0.000107047750524596,
      "loss": 2.9886,
      "step": 34380
    },
    {
      "epoch": 1.4801583885684773,
      "grad_norm": 0.9968101978302002,
      "learning_rate": 0.00010700139891980374,
      "loss": 3.0177,
      "step": 34390
    },
    {
      "epoch": 1.4805887922871652,
      "grad_norm": 0.9084194898605347,
      "learning_rate": 0.0001069550458033217,
      "loss": 3.0418,
      "step": 34400
    },
    {
      "epoch": 1.4805887922871652,
      "eval_bleu": 27.068598072654453,
      "eval_gen_len": 27.375,
      "eval_loss": 2.7976949214935303,
      "eval_runtime": 58.0184,
      "eval_samples_per_second": 17.236,
      "eval_steps_per_second": 1.086,
      "step": 34400
    },
    {
      "epoch": 1.4810191960058534,
      "grad_norm": 1.1864023208618164,
      "learning_rate": 0.00010690869118515803,
      "loss": 3.0612,
      "step": 34410
    },
    {
      "epoch": 1.4814495997245416,
      "grad_norm": 0.963652491569519,
      "learning_rate": 0.00010686233507532131,
      "loss": 3.069,
      "step": 34420
    },
    {
      "epoch": 1.4818800034432298,
      "grad_norm": 0.9068645238876343,
      "learning_rate": 0.00010681597748382037,
      "loss": 3.061,
      "step": 34430
    },
    {
      "epoch": 1.482310407161918,
      "grad_norm": 0.8339937329292297,
      "learning_rate": 0.00010676961842066444,
      "loss": 2.9825,
      "step": 34440
    },
    {
      "epoch": 1.482740810880606,
      "grad_norm": 0.9937971234321594,
      "learning_rate": 0.00010672325789586299,
      "loss": 3.0268,
      "step": 34450
    },
    {
      "epoch": 1.482740810880606,
      "eval_bleu": 27.202242922348304,
      "eval_gen_len": 27.412,
      "eval_loss": 2.7956552505493164,
      "eval_runtime": 59.3035,
      "eval_samples_per_second": 16.862,
      "eval_steps_per_second": 1.062,
      "step": 34450
    },
    {
      "epoch": 1.4831712145992941,
      "grad_norm": 0.9697773456573486,
      "learning_rate": 0.00010667689591942587,
      "loss": 3.0046,
      "step": 34460
    },
    {
      "epoch": 1.4836016183179823,
      "grad_norm": 0.9419563412666321,
      "learning_rate": 0.0001066305325013632,
      "loss": 3.1085,
      "step": 34470
    },
    {
      "epoch": 1.4840320220366703,
      "grad_norm": 1.0262868404388428,
      "learning_rate": 0.00010658416765168542,
      "loss": 2.984,
      "step": 34480
    },
    {
      "epoch": 1.4844624257553585,
      "grad_norm": 1.0016297101974487,
      "learning_rate": 0.00010653780138040325,
      "loss": 3.0868,
      "step": 34490
    },
    {
      "epoch": 1.4848928294740467,
      "grad_norm": 0.7992796301841736,
      "learning_rate": 0.00010649143369752781,
      "loss": 2.997,
      "step": 34500
    },
    {
      "epoch": 1.4848928294740467,
      "eval_bleu": 26.925649466519552,
      "eval_gen_len": 27.392,
      "eval_loss": 2.8003687858581543,
      "eval_runtime": 59.0903,
      "eval_samples_per_second": 16.923,
      "eval_steps_per_second": 1.066,
      "step": 34500
    },
    {
      "epoch": 1.4853232331927348,
      "grad_norm": 0.861501157283783,
      "learning_rate": 0.00010644506461307042,
      "loss": 2.9941,
      "step": 34510
    },
    {
      "epoch": 1.485753636911423,
      "grad_norm": 0.7832468748092651,
      "learning_rate": 0.00010639869413704277,
      "loss": 3.0869,
      "step": 34520
    },
    {
      "epoch": 1.486184040630111,
      "grad_norm": 0.9920380115509033,
      "learning_rate": 0.00010635232227945681,
      "loss": 3.0096,
      "step": 34530
    },
    {
      "epoch": 1.4866144443487992,
      "grad_norm": 0.9188676476478577,
      "learning_rate": 0.00010630594905032482,
      "loss": 3.0128,
      "step": 34540
    },
    {
      "epoch": 1.4870448480674874,
      "grad_norm": 0.9318972229957581,
      "learning_rate": 0.00010625957445965937,
      "loss": 2.8998,
      "step": 34550
    },
    {
      "epoch": 1.4870448480674874,
      "eval_bleu": 26.87044892014355,
      "eval_gen_len": 27.466,
      "eval_loss": 2.797780990600586,
      "eval_runtime": 58.6086,
      "eval_samples_per_second": 17.062,
      "eval_steps_per_second": 1.075,
      "step": 34550
    },
    {
      "epoch": 1.4874752517861753,
      "grad_norm": 0.8913953900337219,
      "learning_rate": 0.00010621319851747329,
      "loss": 3.0968,
      "step": 34560
    },
    {
      "epoch": 1.4879056555048635,
      "grad_norm": 0.9678893089294434,
      "learning_rate": 0.00010616682123377975,
      "loss": 3.0585,
      "step": 34570
    },
    {
      "epoch": 1.4883360592235517,
      "grad_norm": 0.9178406596183777,
      "learning_rate": 0.00010612044261859215,
      "loss": 3.064,
      "step": 34580
    },
    {
      "epoch": 1.4887664629422397,
      "grad_norm": 0.9433705806732178,
      "learning_rate": 0.00010607406268192425,
      "loss": 3.0827,
      "step": 34590
    },
    {
      "epoch": 1.4891968666609279,
      "grad_norm": 0.908729612827301,
      "learning_rate": 0.00010602768143379004,
      "loss": 2.9318,
      "step": 34600
    },
    {
      "epoch": 1.4891968666609279,
      "eval_bleu": 27.561998353584208,
      "eval_gen_len": 27.546,
      "eval_loss": 2.796293258666992,
      "eval_runtime": 58.7468,
      "eval_samples_per_second": 17.022,
      "eval_steps_per_second": 1.072,
      "step": 34600
    },
    {
      "epoch": 1.489627270379616,
      "grad_norm": 0.9703353047370911,
      "learning_rate": 0.00010598129888420387,
      "loss": 2.9989,
      "step": 34610
    },
    {
      "epoch": 1.4900576740983043,
      "grad_norm": 0.9956719875335693,
      "learning_rate": 0.00010593491504318024,
      "loss": 3.0279,
      "step": 34620
    },
    {
      "epoch": 1.4904880778169924,
      "grad_norm": 0.931026816368103,
      "learning_rate": 0.00010588852992073402,
      "loss": 2.9953,
      "step": 34630
    },
    {
      "epoch": 1.4909184815356804,
      "grad_norm": 0.8969464302062988,
      "learning_rate": 0.00010584214352688033,
      "loss": 2.976,
      "step": 34640
    },
    {
      "epoch": 1.4913488852543686,
      "grad_norm": 0.8718146681785583,
      "learning_rate": 0.00010579575587163464,
      "loss": 2.9764,
      "step": 34650
    },
    {
      "epoch": 1.4913488852543686,
      "eval_bleu": 27.651649099994195,
      "eval_gen_len": 27.481,
      "eval_loss": 2.7950780391693115,
      "eval_runtime": 58.4581,
      "eval_samples_per_second": 17.106,
      "eval_steps_per_second": 1.078,
      "step": 34650
    },
    {
      "epoch": 1.4917792889730568,
      "grad_norm": 0.9389508962631226,
      "learning_rate": 0.00010574936696501257,
      "loss": 3.0471,
      "step": 34660
    },
    {
      "epoch": 1.4922096926917447,
      "grad_norm": 0.855107843875885,
      "learning_rate": 0.00010570297681703005,
      "loss": 3.1073,
      "step": 34670
    },
    {
      "epoch": 1.492640096410433,
      "grad_norm": 0.9285683631896973,
      "learning_rate": 0.00010565658543770335,
      "loss": 3.074,
      "step": 34680
    },
    {
      "epoch": 1.4930705001291211,
      "grad_norm": 0.9127699732780457,
      "learning_rate": 0.00010561019283704894,
      "loss": 3.0227,
      "step": 34690
    },
    {
      "epoch": 1.4935009038478093,
      "grad_norm": 1.0895960330963135,
      "learning_rate": 0.0001055637990250835,
      "loss": 3.0277,
      "step": 34700
    },
    {
      "epoch": 1.4935009038478093,
      "eval_bleu": 27.060836706952493,
      "eval_gen_len": 27.576,
      "eval_loss": 2.7999351024627686,
      "eval_runtime": 58.5926,
      "eval_samples_per_second": 17.067,
      "eval_steps_per_second": 1.075,
      "step": 34700
    },
    {
      "epoch": 1.4939313075664975,
      "grad_norm": 0.8507838845252991,
      "learning_rate": 0.0001055174040118241,
      "loss": 3.0303,
      "step": 34710
    },
    {
      "epoch": 1.4943617112851855,
      "grad_norm": 0.8703678846359253,
      "learning_rate": 0.000105471007807288,
      "loss": 3.0659,
      "step": 34720
    },
    {
      "epoch": 1.4947921150038737,
      "grad_norm": 0.9373616576194763,
      "learning_rate": 0.0001054246104214927,
      "loss": 3.2004,
      "step": 34730
    },
    {
      "epoch": 1.4952225187225618,
      "grad_norm": 0.9287047386169434,
      "learning_rate": 0.000105378211864456,
      "loss": 3.0161,
      "step": 34740
    },
    {
      "epoch": 1.4956529224412498,
      "grad_norm": 0.9039446115493774,
      "learning_rate": 0.0001053318121461959,
      "loss": 2.8291,
      "step": 34750
    },
    {
      "epoch": 1.4956529224412498,
      "eval_bleu": 27.139736575736542,
      "eval_gen_len": 27.41,
      "eval_loss": 2.7982444763183594,
      "eval_runtime": 59.0046,
      "eval_samples_per_second": 16.948,
      "eval_steps_per_second": 1.068,
      "step": 34750
    },
    {
      "epoch": 1.496083326159938,
      "grad_norm": 0.8839457631111145,
      "learning_rate": 0.00010528541127673071,
      "loss": 3.0264,
      "step": 34760
    },
    {
      "epoch": 1.4965137298786262,
      "grad_norm": 0.9742242693901062,
      "learning_rate": 0.00010523900926607895,
      "loss": 2.9502,
      "step": 34770
    },
    {
      "epoch": 1.4969441335973142,
      "grad_norm": 0.8769932389259338,
      "learning_rate": 0.00010519260612425939,
      "loss": 3.0732,
      "step": 34780
    },
    {
      "epoch": 1.4973745373160023,
      "grad_norm": 0.884306788444519,
      "learning_rate": 0.00010514620186129106,
      "loss": 2.9092,
      "step": 34790
    },
    {
      "epoch": 1.4978049410346905,
      "grad_norm": 0.9552370309829712,
      "learning_rate": 0.0001050997964871932,
      "loss": 3.0329,
      "step": 34800
    },
    {
      "epoch": 1.4978049410346905,
      "eval_bleu": 27.119919938900146,
      "eval_gen_len": 27.433,
      "eval_loss": 2.7963740825653076,
      "eval_runtime": 58.613,
      "eval_samples_per_second": 17.061,
      "eval_steps_per_second": 1.075,
      "step": 34800
    },
    {
      "epoch": 1.4982353447533787,
      "grad_norm": 0.9856463074684143,
      "learning_rate": 0.00010505339001198533,
      "loss": 3.0299,
      "step": 34810
    },
    {
      "epoch": 1.498665748472067,
      "grad_norm": 0.9143463373184204,
      "learning_rate": 0.00010500698244568719,
      "loss": 2.9934,
      "step": 34820
    },
    {
      "epoch": 1.4990961521907549,
      "grad_norm": 0.7600686550140381,
      "learning_rate": 0.00010496057379831877,
      "loss": 3.074,
      "step": 34830
    },
    {
      "epoch": 1.499526555909443,
      "grad_norm": 1.0364741086959839,
      "learning_rate": 0.00010491416407990024,
      "loss": 3.0708,
      "step": 34840
    },
    {
      "epoch": 1.4999569596281312,
      "grad_norm": 1.034264326095581,
      "learning_rate": 0.00010486775330045211,
      "loss": 3.0287,
      "step": 34850
    },
    {
      "epoch": 1.4999569596281312,
      "eval_bleu": 27.08462134972314,
      "eval_gen_len": 27.509,
      "eval_loss": 2.796142101287842,
      "eval_runtime": 58.4671,
      "eval_samples_per_second": 17.104,
      "eval_steps_per_second": 1.078,
      "step": 34850
    },
    {
      "epoch": 1.5003873633468192,
      "grad_norm": 0.9328961968421936,
      "learning_rate": 0.00010482134146999496,
      "loss": 3.0893,
      "step": 34860
    },
    {
      "epoch": 1.5008177670655074,
      "grad_norm": 0.8605321645736694,
      "learning_rate": 0.00010477492859854974,
      "loss": 2.932,
      "step": 34870
    },
    {
      "epoch": 1.5012481707841956,
      "grad_norm": 0.9227759838104248,
      "learning_rate": 0.00010472851469613756,
      "loss": 3.1178,
      "step": 34880
    },
    {
      "epoch": 1.5016785745028836,
      "grad_norm": 0.856457531452179,
      "learning_rate": 0.00010468209977277979,
      "loss": 2.9441,
      "step": 34890
    },
    {
      "epoch": 1.502108978221572,
      "grad_norm": 0.8606597185134888,
      "learning_rate": 0.00010463568383849792,
      "loss": 3.0178,
      "step": 34900
    },
    {
      "epoch": 1.502108978221572,
      "eval_bleu": 27.30879583854434,
      "eval_gen_len": 27.571,
      "eval_loss": 2.795147657394409,
      "eval_runtime": 58.3625,
      "eval_samples_per_second": 17.134,
      "eval_steps_per_second": 1.079,
      "step": 34900
    },
    {
      "epoch": 1.50253938194026,
      "grad_norm": 0.8684816360473633,
      "learning_rate": 0.00010458926690331379,
      "loss": 3.0635,
      "step": 34910
    },
    {
      "epoch": 1.5029697856589481,
      "grad_norm": 0.969932496547699,
      "learning_rate": 0.0001045428489772494,
      "loss": 3.0082,
      "step": 34920
    },
    {
      "epoch": 1.5034001893776363,
      "grad_norm": 1.0016835927963257,
      "learning_rate": 0.00010449643007032696,
      "loss": 3.0465,
      "step": 34930
    },
    {
      "epoch": 1.5038305930963243,
      "grad_norm": 0.8237992525100708,
      "learning_rate": 0.00010445001019256885,
      "loss": 3.0401,
      "step": 34940
    },
    {
      "epoch": 1.5042609968150125,
      "grad_norm": 0.8873575329780579,
      "learning_rate": 0.00010440358935399777,
      "loss": 3.075,
      "step": 34950
    },
    {
      "epoch": 1.5042609968150125,
      "eval_bleu": 26.997163867185243,
      "eval_gen_len": 27.458,
      "eval_loss": 2.7989399433135986,
      "eval_runtime": 58.1803,
      "eval_samples_per_second": 17.188,
      "eval_steps_per_second": 1.083,
      "step": 34950
    },
    {
      "epoch": 1.5046914005337007,
      "grad_norm": 0.8790655732154846,
      "learning_rate": 0.00010435716756463651,
      "loss": 2.9631,
      "step": 34960
    },
    {
      "epoch": 1.5051218042523886,
      "grad_norm": 0.9596037268638611,
      "learning_rate": 0.00010431074483450818,
      "loss": 2.9783,
      "step": 34970
    },
    {
      "epoch": 1.505552207971077,
      "grad_norm": 0.9306361079216003,
      "learning_rate": 0.00010426432117363593,
      "loss": 2.9925,
      "step": 34980
    },
    {
      "epoch": 1.505982611689765,
      "grad_norm": 1.0231627225875854,
      "learning_rate": 0.00010421789659204331,
      "loss": 3.0893,
      "step": 34990
    },
    {
      "epoch": 1.5064130154084532,
      "grad_norm": 0.9962162375450134,
      "learning_rate": 0.00010417147109975387,
      "loss": 3.0424,
      "step": 35000
    },
    {
      "epoch": 1.5064130154084532,
      "eval_bleu": 27.100044777812357,
      "eval_gen_len": 27.575,
      "eval_loss": 2.7960617542266846,
      "eval_runtime": 58.8034,
      "eval_samples_per_second": 17.006,
      "eval_steps_per_second": 1.071,
      "step": 35000
    },
    {
      "epoch": 1.5068434191271414,
      "grad_norm": 0.8672740459442139,
      "learning_rate": 0.00010412504470679157,
      "loss": 2.9587,
      "step": 35010
    },
    {
      "epoch": 1.5072738228458293,
      "grad_norm": 0.9639049768447876,
      "learning_rate": 0.00010407861742318035,
      "loss": 3.023,
      "step": 35020
    },
    {
      "epoch": 1.5077042265645175,
      "grad_norm": 1.0286359786987305,
      "learning_rate": 0.00010403218925894449,
      "loss": 2.9938,
      "step": 35030
    },
    {
      "epoch": 1.5081346302832057,
      "grad_norm": 0.8542589545249939,
      "learning_rate": 0.00010398576022410842,
      "loss": 2.8923,
      "step": 35040
    },
    {
      "epoch": 1.5085650340018937,
      "grad_norm": 0.8364506959915161,
      "learning_rate": 0.00010393933032869676,
      "loss": 2.9377,
      "step": 35050
    },
    {
      "epoch": 1.5085650340018937,
      "eval_bleu": 27.242918184613465,
      "eval_gen_len": 27.523,
      "eval_loss": 2.7959885597229004,
      "eval_runtime": 58.575,
      "eval_samples_per_second": 17.072,
      "eval_steps_per_second": 1.076,
      "step": 35050
    },
    {
      "epoch": 1.5089954377205819,
      "grad_norm": 0.9773814082145691,
      "learning_rate": 0.00010389289958273425,
      "loss": 2.9664,
      "step": 35060
    },
    {
      "epoch": 1.50942584143927,
      "grad_norm": 0.863321840763092,
      "learning_rate": 0.0001038464679962459,
      "loss": 2.9772,
      "step": 35070
    },
    {
      "epoch": 1.509856245157958,
      "grad_norm": 0.9070523977279663,
      "learning_rate": 0.00010380003557925688,
      "loss": 3.0379,
      "step": 35080
    },
    {
      "epoch": 1.5102866488766464,
      "grad_norm": 0.8952091932296753,
      "learning_rate": 0.00010375360234179254,
      "loss": 3.1025,
      "step": 35090
    },
    {
      "epoch": 1.5107170525953344,
      "grad_norm": 0.9127327799797058,
      "learning_rate": 0.00010370716829387839,
      "loss": 2.9954,
      "step": 35100
    },
    {
      "epoch": 1.5107170525953344,
      "eval_bleu": 27.244273869178606,
      "eval_gen_len": 27.519,
      "eval_loss": 2.79788875579834,
      "eval_runtime": 58.6287,
      "eval_samples_per_second": 17.056,
      "eval_steps_per_second": 1.075,
      "step": 35100
    },
    {
      "epoch": 1.5111474563140226,
      "grad_norm": 0.9757485389709473,
      "learning_rate": 0.00010366073344554011,
      "loss": 2.9755,
      "step": 35110
    },
    {
      "epoch": 1.5115778600327108,
      "grad_norm": 0.8641476035118103,
      "learning_rate": 0.00010361429780680356,
      "loss": 2.9186,
      "step": 35120
    },
    {
      "epoch": 1.5120082637513987,
      "grad_norm": 0.8501383066177368,
      "learning_rate": 0.00010356786138769481,
      "loss": 2.9835,
      "step": 35130
    },
    {
      "epoch": 1.512438667470087,
      "grad_norm": 0.9646658897399902,
      "learning_rate": 0.00010352142419824005,
      "loss": 3.0453,
      "step": 35140
    },
    {
      "epoch": 1.5128690711887751,
      "grad_norm": 0.8973153233528137,
      "learning_rate": 0.00010347498624846566,
      "loss": 2.9587,
      "step": 35150
    },
    {
      "epoch": 1.5128690711887751,
      "eval_bleu": 27.071022226489177,
      "eval_gen_len": 27.376,
      "eval_loss": 2.7967660427093506,
      "eval_runtime": 58.1675,
      "eval_samples_per_second": 17.192,
      "eval_steps_per_second": 1.083,
      "step": 35150
    },
    {
      "epoch": 1.513299474907463,
      "grad_norm": 1.0189231634140015,
      "learning_rate": 0.00010342854754839813,
      "loss": 2.9191,
      "step": 35160
    },
    {
      "epoch": 1.5137298786261515,
      "grad_norm": 0.9120556116104126,
      "learning_rate": 0.00010338210810806422,
      "loss": 3.0459,
      "step": 35170
    },
    {
      "epoch": 1.5141602823448395,
      "grad_norm": 0.8588502407073975,
      "learning_rate": 0.00010333566793749072,
      "loss": 2.9166,
      "step": 35180
    },
    {
      "epoch": 1.5145906860635274,
      "grad_norm": 1.0002012252807617,
      "learning_rate": 0.00010328922704670471,
      "loss": 3.1686,
      "step": 35190
    },
    {
      "epoch": 1.5150210897822158,
      "grad_norm": 0.8742557168006897,
      "learning_rate": 0.00010324278544573334,
      "loss": 2.9692,
      "step": 35200
    },
    {
      "epoch": 1.5150210897822158,
      "eval_bleu": 27.465288083513837,
      "eval_gen_len": 27.514,
      "eval_loss": 2.7967851161956787,
      "eval_runtime": 58.8279,
      "eval_samples_per_second": 16.999,
      "eval_steps_per_second": 1.071,
      "step": 35200
    },
    {
      "epoch": 1.5154514935009038,
      "grad_norm": 1.0025737285614014,
      "learning_rate": 0.00010319634314460391,
      "loss": 2.9675,
      "step": 35210
    },
    {
      "epoch": 1.515881897219592,
      "grad_norm": 0.9799866080284119,
      "learning_rate": 0.00010314990015334396,
      "loss": 2.9593,
      "step": 35220
    },
    {
      "epoch": 1.5163123009382802,
      "grad_norm": 0.9613295197486877,
      "learning_rate": 0.00010310345648198103,
      "loss": 2.9499,
      "step": 35230
    },
    {
      "epoch": 1.5167427046569681,
      "grad_norm": 0.8395183682441711,
      "learning_rate": 0.00010305701214054292,
      "loss": 2.9394,
      "step": 35240
    },
    {
      "epoch": 1.5171731083756563,
      "grad_norm": 0.8904535174369812,
      "learning_rate": 0.00010301056713905759,
      "loss": 3.0226,
      "step": 35250
    },
    {
      "epoch": 1.5171731083756563,
      "eval_bleu": 27.271531123686277,
      "eval_gen_len": 27.492,
      "eval_loss": 2.793680429458618,
      "eval_runtime": 58.6585,
      "eval_samples_per_second": 17.048,
      "eval_steps_per_second": 1.074,
      "step": 35250
    },
    {
      "epoch": 1.5176035120943445,
      "grad_norm": 1.0036956071853638,
      "learning_rate": 0.00010296412148755306,
      "loss": 2.9748,
      "step": 35260
    },
    {
      "epoch": 1.5180339158130325,
      "grad_norm": 0.8805891871452332,
      "learning_rate": 0.0001029176751960575,
      "loss": 2.9688,
      "step": 35270
    },
    {
      "epoch": 1.518464319531721,
      "grad_norm": 0.9540758728981018,
      "learning_rate": 0.0001028712282745993,
      "loss": 2.9989,
      "step": 35280
    },
    {
      "epoch": 1.5188947232504089,
      "grad_norm": 0.9086909294128418,
      "learning_rate": 0.00010282478073320689,
      "loss": 3.0914,
      "step": 35290
    },
    {
      "epoch": 1.519325126969097,
      "grad_norm": 0.8657249212265015,
      "learning_rate": 0.00010277833258190894,
      "loss": 2.9109,
      "step": 35300
    },
    {
      "epoch": 1.519325126969097,
      "eval_bleu": 27.173978115104656,
      "eval_gen_len": 27.495,
      "eval_loss": 2.796992540359497,
      "eval_runtime": 58.3598,
      "eval_samples_per_second": 17.135,
      "eval_steps_per_second": 1.08,
      "step": 35300
    },
    {
      "epoch": 1.5197555306877852,
      "grad_norm": 0.9425958395004272,
      "learning_rate": 0.00010273188383073411,
      "loss": 2.9969,
      "step": 35310
    },
    {
      "epoch": 1.5201859344064732,
      "grad_norm": 0.8734353184700012,
      "learning_rate": 0.00010268543448971132,
      "loss": 2.9517,
      "step": 35320
    },
    {
      "epoch": 1.5206163381251614,
      "grad_norm": 0.8450024724006653,
      "learning_rate": 0.00010263898456886954,
      "loss": 3.0452,
      "step": 35330
    },
    {
      "epoch": 1.5210467418438496,
      "grad_norm": 0.9714759588241577,
      "learning_rate": 0.00010259253407823792,
      "loss": 3.0018,
      "step": 35340
    },
    {
      "epoch": 1.5214771455625375,
      "grad_norm": 0.8691667318344116,
      "learning_rate": 0.00010254608302784567,
      "loss": 3.1026,
      "step": 35350
    },
    {
      "epoch": 1.5214771455625375,
      "eval_bleu": 26.788571111219795,
      "eval_gen_len": 27.483,
      "eval_loss": 2.7973721027374268,
      "eval_runtime": 58.572,
      "eval_samples_per_second": 17.073,
      "eval_steps_per_second": 1.076,
      "step": 35350
    },
    {
      "epoch": 1.5219075492812257,
      "grad_norm": 0.8664287328720093,
      "learning_rate": 0.00010249963142772217,
      "loss": 3.024,
      "step": 35360
    },
    {
      "epoch": 1.522337952999914,
      "grad_norm": 0.8947293162345886,
      "learning_rate": 0.00010245317928789686,
      "loss": 2.9874,
      "step": 35370
    },
    {
      "epoch": 1.522768356718602,
      "grad_norm": 0.9772366881370544,
      "learning_rate": 0.00010240672661839945,
      "loss": 3.0011,
      "step": 35380
    },
    {
      "epoch": 1.5231987604372903,
      "grad_norm": 0.7970262169837952,
      "learning_rate": 0.00010236027342925953,
      "loss": 2.9483,
      "step": 35390
    },
    {
      "epoch": 1.5236291641559783,
      "grad_norm": 0.8959667086601257,
      "learning_rate": 0.000102313819730507,
      "loss": 2.9854,
      "step": 35400
    },
    {
      "epoch": 1.5236291641559783,
      "eval_bleu": 27.083722802429676,
      "eval_gen_len": 27.452,
      "eval_loss": 2.7961795330047607,
      "eval_runtime": 58.5605,
      "eval_samples_per_second": 17.076,
      "eval_steps_per_second": 1.076,
      "step": 35400
    },
    {
      "epoch": 1.5240595678746665,
      "grad_norm": 0.8741873502731323,
      "learning_rate": 0.00010226736553217178,
      "loss": 2.9851,
      "step": 35410
    },
    {
      "epoch": 1.5244899715933546,
      "grad_norm": 0.8115756511688232,
      "learning_rate": 0.00010222091084428393,
      "loss": 2.9774,
      "step": 35420
    },
    {
      "epoch": 1.5249203753120426,
      "grad_norm": 0.9866371154785156,
      "learning_rate": 0.00010217445567687354,
      "loss": 2.9812,
      "step": 35430
    },
    {
      "epoch": 1.5253507790307308,
      "grad_norm": 0.8860262632369995,
      "learning_rate": 0.00010212800003997091,
      "loss": 3.0355,
      "step": 35440
    },
    {
      "epoch": 1.525781182749419,
      "grad_norm": 0.8657403588294983,
      "learning_rate": 0.00010208154394360641,
      "loss": 2.9638,
      "step": 35450
    },
    {
      "epoch": 1.525781182749419,
      "eval_bleu": 26.822229423035257,
      "eval_gen_len": 27.452,
      "eval_loss": 2.799971103668213,
      "eval_runtime": 58.6309,
      "eval_samples_per_second": 17.056,
      "eval_steps_per_second": 1.075,
      "step": 35450
    },
    {
      "epoch": 1.526211586468107,
      "grad_norm": 0.9371843338012695,
      "learning_rate": 0.00010203508739781045,
      "loss": 3.035,
      "step": 35460
    },
    {
      "epoch": 1.5266419901867954,
      "grad_norm": 1.0168533325195312,
      "learning_rate": 0.00010198863041261359,
      "loss": 2.9376,
      "step": 35470
    },
    {
      "epoch": 1.5270723939054833,
      "grad_norm": 0.9349671602249146,
      "learning_rate": 0.00010194217299804652,
      "loss": 2.96,
      "step": 35480
    },
    {
      "epoch": 1.5275027976241715,
      "grad_norm": 0.8636351227760315,
      "learning_rate": 0.00010189571516413992,
      "loss": 2.9931,
      "step": 35490
    },
    {
      "epoch": 1.5279332013428597,
      "grad_norm": 0.9089802503585815,
      "learning_rate": 0.00010184925692092466,
      "loss": 3.0892,
      "step": 35500
    },
    {
      "epoch": 1.5279332013428597,
      "eval_bleu": 27.369478201776936,
      "eval_gen_len": 27.512,
      "eval_loss": 2.7958388328552246,
      "eval_runtime": 58.3543,
      "eval_samples_per_second": 17.137,
      "eval_steps_per_second": 1.08,
      "step": 35500
    },
    {
      "epoch": 1.5283636050615477,
      "grad_norm": 0.9335495829582214,
      "learning_rate": 0.00010180279827843164,
      "loss": 3.0375,
      "step": 35510
    },
    {
      "epoch": 1.5287940087802359,
      "grad_norm": 0.8539376258850098,
      "learning_rate": 0.00010175633924669186,
      "loss": 2.9964,
      "step": 35520
    },
    {
      "epoch": 1.529224412498924,
      "grad_norm": 0.9011024832725525,
      "learning_rate": 0.00010170987983573641,
      "loss": 2.9614,
      "step": 35530
    },
    {
      "epoch": 1.529654816217612,
      "grad_norm": 1.0084937810897827,
      "learning_rate": 0.00010166342005559646,
      "loss": 2.9907,
      "step": 35540
    },
    {
      "epoch": 1.5300852199363002,
      "grad_norm": 0.9420719146728516,
      "learning_rate": 0.00010161695991630326,
      "loss": 2.9726,
      "step": 35550
    },
    {
      "epoch": 1.5300852199363002,
      "eval_bleu": 26.852907817635113,
      "eval_gen_len": 27.475,
      "eval_loss": 2.80023193359375,
      "eval_runtime": 58.0803,
      "eval_samples_per_second": 17.218,
      "eval_steps_per_second": 1.085,
      "step": 35550
    },
    {
      "epoch": 1.5305156236549884,
      "grad_norm": 0.877372682094574,
      "learning_rate": 0.00010157049942788814,
      "loss": 3.0057,
      "step": 35560
    },
    {
      "epoch": 1.5309460273736764,
      "grad_norm": 0.9833574295043945,
      "learning_rate": 0.0001015240386003825,
      "loss": 2.9332,
      "step": 35570
    },
    {
      "epoch": 1.5313764310923648,
      "grad_norm": 0.8862223029136658,
      "learning_rate": 0.00010147757744381785,
      "loss": 3.0936,
      "step": 35580
    },
    {
      "epoch": 1.5318068348110527,
      "grad_norm": 0.9941061735153198,
      "learning_rate": 0.00010143111596822568,
      "loss": 3.1013,
      "step": 35590
    },
    {
      "epoch": 1.532237238529741,
      "grad_norm": 0.9545479416847229,
      "learning_rate": 0.0001013846541836376,
      "loss": 3.0372,
      "step": 35600
    },
    {
      "epoch": 1.532237238529741,
      "eval_bleu": 27.274615334481876,
      "eval_gen_len": 27.571,
      "eval_loss": 2.7989795207977295,
      "eval_runtime": 58.8237,
      "eval_samples_per_second": 17.0,
      "eval_steps_per_second": 1.071,
      "step": 35600
    },
    {
      "epoch": 1.532667642248429,
      "grad_norm": 0.8607739806175232,
      "learning_rate": 0.00010133819210008535,
      "loss": 3.0077,
      "step": 35610
    },
    {
      "epoch": 1.533098045967117,
      "grad_norm": 0.9077823162078857,
      "learning_rate": 0.00010129172972760064,
      "loss": 3.0104,
      "step": 35620
    },
    {
      "epoch": 1.5335284496858053,
      "grad_norm": 0.9655500650405884,
      "learning_rate": 0.00010124526707621527,
      "loss": 3.0172,
      "step": 35630
    },
    {
      "epoch": 1.5339588534044934,
      "grad_norm": 1.017501711845398,
      "learning_rate": 0.0001011988041559611,
      "loss": 3.0843,
      "step": 35640
    },
    {
      "epoch": 1.5343892571231814,
      "grad_norm": 0.9430465698242188,
      "learning_rate": 0.00010115234097687012,
      "loss": 3.0205,
      "step": 35650
    },
    {
      "epoch": 1.5343892571231814,
      "eval_bleu": 27.546692606192966,
      "eval_gen_len": 27.556,
      "eval_loss": 2.793980121612549,
      "eval_runtime": 58.5735,
      "eval_samples_per_second": 17.073,
      "eval_steps_per_second": 1.076,
      "step": 35650
    },
    {
      "epoch": 1.5348196608418698,
      "grad_norm": 0.8790614604949951,
      "learning_rate": 0.0001011058775489743,
      "loss": 3.0334,
      "step": 35660
    },
    {
      "epoch": 1.5352500645605578,
      "grad_norm": 0.9106636643409729,
      "learning_rate": 0.0001010594138823056,
      "loss": 3.1262,
      "step": 35670
    },
    {
      "epoch": 1.535680468279246,
      "grad_norm": 0.8671198487281799,
      "learning_rate": 0.00010101294998689617,
      "loss": 3.0658,
      "step": 35680
    },
    {
      "epoch": 1.5361108719979342,
      "grad_norm": 0.9829419851303101,
      "learning_rate": 0.00010096648587277812,
      "loss": 3.0296,
      "step": 35690
    },
    {
      "epoch": 1.5365412757166221,
      "grad_norm": 0.9319075345993042,
      "learning_rate": 0.0001009200215499837,
      "loss": 2.9511,
      "step": 35700
    },
    {
      "epoch": 1.5365412757166221,
      "eval_bleu": 27.587038130935923,
      "eval_gen_len": 27.441,
      "eval_loss": 2.7935500144958496,
      "eval_runtime": 57.9537,
      "eval_samples_per_second": 17.255,
      "eval_steps_per_second": 1.087,
      "step": 35700
    },
    {
      "epoch": 1.5369716794353103,
      "grad_norm": 1.1026544570922852,
      "learning_rate": 0.00010087355702854504,
      "loss": 3.0177,
      "step": 35710
    },
    {
      "epoch": 1.5374020831539985,
      "grad_norm": 0.9320417046546936,
      "learning_rate": 0.0001008270923184945,
      "loss": 2.9996,
      "step": 35720
    },
    {
      "epoch": 1.5378324868726865,
      "grad_norm": 0.8958282470703125,
      "learning_rate": 0.0001007806274298643,
      "loss": 2.967,
      "step": 35730
    },
    {
      "epoch": 1.5382628905913747,
      "grad_norm": 0.952756404876709,
      "learning_rate": 0.00010073416237268691,
      "loss": 3.0401,
      "step": 35740
    },
    {
      "epoch": 1.5386932943100629,
      "grad_norm": 0.9085094928741455,
      "learning_rate": 0.00010068769715699464,
      "loss": 3.1177,
      "step": 35750
    },
    {
      "epoch": 1.5386932943100629,
      "eval_bleu": 27.508269230804352,
      "eval_gen_len": 27.555,
      "eval_loss": 2.798600912094116,
      "eval_runtime": 58.6462,
      "eval_samples_per_second": 17.051,
      "eval_steps_per_second": 1.074,
      "step": 35750
    },
    {
      "epoch": 1.5391236980287508,
      "grad_norm": 0.9055695533752441,
      "learning_rate": 0.00010064123179281992,
      "loss": 3.011,
      "step": 35760
    },
    {
      "epoch": 1.5395541017474392,
      "grad_norm": 0.8850072622299194,
      "learning_rate": 0.00010059476629019522,
      "loss": 3.0101,
      "step": 35770
    },
    {
      "epoch": 1.5399845054661272,
      "grad_norm": 1.014923095703125,
      "learning_rate": 0.00010054830065915301,
      "loss": 3.0337,
      "step": 35780
    },
    {
      "epoch": 1.5404149091848154,
      "grad_norm": 0.8756835460662842,
      "learning_rate": 0.00010050183490972585,
      "loss": 3.0221,
      "step": 35790
    },
    {
      "epoch": 1.5408453129035036,
      "grad_norm": 0.9013705849647522,
      "learning_rate": 0.00010045536905194622,
      "loss": 2.9286,
      "step": 35800
    },
    {
      "epoch": 1.5408453129035036,
      "eval_bleu": 26.87701947068724,
      "eval_gen_len": 27.337,
      "eval_loss": 2.8006794452667236,
      "eval_runtime": 58.4748,
      "eval_samples_per_second": 17.101,
      "eval_steps_per_second": 1.077,
      "step": 35800
    },
    {
      "epoch": 1.5412757166221915,
      "grad_norm": 0.9031347036361694,
      "learning_rate": 0.00010040890309584667,
      "loss": 2.9943,
      "step": 35810
    },
    {
      "epoch": 1.5417061203408797,
      "grad_norm": 0.92796391248703,
      "learning_rate": 0.00010036243705145984,
      "loss": 2.9562,
      "step": 35820
    },
    {
      "epoch": 1.542136524059568,
      "grad_norm": 0.8984587788581848,
      "learning_rate": 0.0001003159709288183,
      "loss": 2.9416,
      "step": 35830
    },
    {
      "epoch": 1.5425669277782559,
      "grad_norm": 0.8595590591430664,
      "learning_rate": 0.00010026950473795469,
      "loss": 2.9645,
      "step": 35840
    },
    {
      "epoch": 1.5429973314969443,
      "grad_norm": 0.92461097240448,
      "learning_rate": 0.00010022303848890162,
      "loss": 3.1003,
      "step": 35850
    },
    {
      "epoch": 1.5429973314969443,
      "eval_bleu": 27.231322309713313,
      "eval_gen_len": 27.404,
      "eval_loss": 2.7963311672210693,
      "eval_runtime": 58.5541,
      "eval_samples_per_second": 17.078,
      "eval_steps_per_second": 1.076,
      "step": 35850
    },
    {
      "epoch": 1.5434277352156323,
      "grad_norm": 0.9201928377151489,
      "learning_rate": 0.00010017657219169172,
      "loss": 3.0494,
      "step": 35860
    },
    {
      "epoch": 1.5438581389343204,
      "grad_norm": 0.8906475305557251,
      "learning_rate": 0.00010013010585635772,
      "loss": 3.0416,
      "step": 35870
    },
    {
      "epoch": 1.5442885426530086,
      "grad_norm": 0.961537778377533,
      "learning_rate": 0.0001000836394929322,
      "loss": 3.0084,
      "step": 35880
    },
    {
      "epoch": 1.5447189463716966,
      "grad_norm": 0.9115728139877319,
      "learning_rate": 0.00010003717311144787,
      "loss": 3.0451,
      "step": 35890
    },
    {
      "epoch": 1.5451493500903848,
      "grad_norm": 0.9143688678741455,
      "learning_rate": 9.999070672193738e-05,
      "loss": 2.9764,
      "step": 35900
    },
    {
      "epoch": 1.5451493500903848,
      "eval_bleu": 27.771501831378007,
      "eval_gen_len": 27.455,
      "eval_loss": 2.7951509952545166,
      "eval_runtime": 58.9534,
      "eval_samples_per_second": 16.963,
      "eval_steps_per_second": 1.069,
      "step": 35900
    },
    {
      "epoch": 1.545579753809073,
      "grad_norm": 0.967661440372467,
      "learning_rate": 9.994424033443346e-05,
      "loss": 3.0484,
      "step": 35910
    },
    {
      "epoch": 1.546010157527761,
      "grad_norm": 0.8479234576225281,
      "learning_rate": 9.989777395896873e-05,
      "loss": 3.0572,
      "step": 35920
    },
    {
      "epoch": 1.5464405612464491,
      "grad_norm": 1.0834535360336304,
      "learning_rate": 9.98513076055759e-05,
      "loss": 3.0195,
      "step": 35930
    },
    {
      "epoch": 1.5468709649651373,
      "grad_norm": 0.864662766456604,
      "learning_rate": 9.98048412842876e-05,
      "loss": 3.0904,
      "step": 35940
    },
    {
      "epoch": 1.5473013686838253,
      "grad_norm": 0.9068751931190491,
      "learning_rate": 9.975837500513652e-05,
      "loss": 3.0418,
      "step": 35950
    },
    {
      "epoch": 1.5473013686838253,
      "eval_bleu": 27.467448827764002,
      "eval_gen_len": 27.438,
      "eval_loss": 2.797758102416992,
      "eval_runtime": 58.8048,
      "eval_samples_per_second": 17.005,
      "eval_steps_per_second": 1.071,
      "step": 35950
    },
    {
      "epoch": 1.5477317724025137,
      "grad_norm": 0.9236431121826172,
      "learning_rate": 9.971190877815532e-05,
      "loss": 3.0612,
      "step": 35960
    },
    {
      "epoch": 1.5481621761212017,
      "grad_norm": 0.9248533248901367,
      "learning_rate": 9.966544261337662e-05,
      "loss": 3.0268,
      "step": 35970
    },
    {
      "epoch": 1.5485925798398898,
      "grad_norm": 0.909890353679657,
      "learning_rate": 9.961897652083305e-05,
      "loss": 3.0662,
      "step": 35980
    },
    {
      "epoch": 1.549022983558578,
      "grad_norm": 0.9132055044174194,
      "learning_rate": 9.957251051055722e-05,
      "loss": 2.9631,
      "step": 35990
    },
    {
      "epoch": 1.549453387277266,
      "grad_norm": 0.8528622984886169,
      "learning_rate": 9.952604459258175e-05,
      "loss": 3.0754,
      "step": 36000
    },
    {
      "epoch": 1.549453387277266,
      "eval_bleu": 27.22204988419309,
      "eval_gen_len": 27.415,
      "eval_loss": 2.797617197036743,
      "eval_runtime": 58.8127,
      "eval_samples_per_second": 17.003,
      "eval_steps_per_second": 1.071,
      "step": 36000
    },
    {
      "epoch": 1.5498837909959542,
      "grad_norm": 0.8545626401901245,
      "learning_rate": 9.947957877693919e-05,
      "loss": 2.9925,
      "step": 36010
    },
    {
      "epoch": 1.5503141947146424,
      "grad_norm": 0.8163148760795593,
      "learning_rate": 9.943311307366211e-05,
      "loss": 2.8964,
      "step": 36020
    },
    {
      "epoch": 1.5507445984333303,
      "grad_norm": 0.9856525659561157,
      "learning_rate": 9.9386647492783e-05,
      "loss": 3.0404,
      "step": 36030
    },
    {
      "epoch": 1.5511750021520188,
      "grad_norm": 0.9429842233657837,
      "learning_rate": 9.93401820443344e-05,
      "loss": 3.0283,
      "step": 36040
    },
    {
      "epoch": 1.5516054058707067,
      "grad_norm": 0.9404012560844421,
      "learning_rate": 9.929371673834877e-05,
      "loss": 2.9626,
      "step": 36050
    },
    {
      "epoch": 1.5516054058707067,
      "eval_bleu": 27.468363384261195,
      "eval_gen_len": 27.494,
      "eval_loss": 2.799743175506592,
      "eval_runtime": 58.4928,
      "eval_samples_per_second": 17.096,
      "eval_steps_per_second": 1.077,
      "step": 36050
    },
    {
      "epoch": 1.5520358095893947,
      "grad_norm": 0.8617222905158997,
      "learning_rate": 9.924725158485854e-05,
      "loss": 2.9981,
      "step": 36060
    },
    {
      "epoch": 1.552466213308083,
      "grad_norm": 1.0190460681915283,
      "learning_rate": 9.920078659389615e-05,
      "loss": 3.047,
      "step": 36070
    },
    {
      "epoch": 1.552896617026771,
      "grad_norm": 0.9652825593948364,
      "learning_rate": 9.915432177549394e-05,
      "loss": 3.0497,
      "step": 36080
    },
    {
      "epoch": 1.5533270207454593,
      "grad_norm": 0.9157395362854004,
      "learning_rate": 9.91078571396843e-05,
      "loss": 3.0142,
      "step": 36090
    },
    {
      "epoch": 1.5537574244641474,
      "grad_norm": 0.8787888288497925,
      "learning_rate": 9.906139269649946e-05,
      "loss": 3.023,
      "step": 36100
    },
    {
      "epoch": 1.5537574244641474,
      "eval_bleu": 27.516853799337206,
      "eval_gen_len": 27.558,
      "eval_loss": 2.7981560230255127,
      "eval_runtime": 58.4891,
      "eval_samples_per_second": 17.097,
      "eval_steps_per_second": 1.077,
      "step": 36100
    },
    {
      "epoch": 1.5541878281828354,
      "grad_norm": 0.9516724944114685,
      "learning_rate": 9.901492845597172e-05,
      "loss": 2.9819,
      "step": 36110
    },
    {
      "epoch": 1.5546182319015236,
      "grad_norm": 1.0320695638656616,
      "learning_rate": 9.896846442813326e-05,
      "loss": 3.0489,
      "step": 36120
    },
    {
      "epoch": 1.5550486356202118,
      "grad_norm": 0.8798456788063049,
      "learning_rate": 9.892200062301626e-05,
      "loss": 2.9861,
      "step": 36130
    },
    {
      "epoch": 1.5554790393388997,
      "grad_norm": 0.8628877401351929,
      "learning_rate": 9.887553705065285e-05,
      "loss": 3.0254,
      "step": 36140
    },
    {
      "epoch": 1.5559094430575882,
      "grad_norm": 0.8756687641143799,
      "learning_rate": 9.88290737210751e-05,
      "loss": 2.9891,
      "step": 36150
    },
    {
      "epoch": 1.5559094430575882,
      "eval_bleu": 27.44974894081202,
      "eval_gen_len": 27.446,
      "eval_loss": 2.7972042560577393,
      "eval_runtime": 58.6542,
      "eval_samples_per_second": 17.049,
      "eval_steps_per_second": 1.074,
      "step": 36150
    },
    {
      "epoch": 1.5563398467762761,
      "grad_norm": 0.9438552856445312,
      "learning_rate": 9.878261064431502e-05,
      "loss": 2.9848,
      "step": 36160
    },
    {
      "epoch": 1.5567702504949643,
      "grad_norm": 0.9422898292541504,
      "learning_rate": 9.873614783040459e-05,
      "loss": 3.0384,
      "step": 36170
    },
    {
      "epoch": 1.5572006542136525,
      "grad_norm": 0.919774055480957,
      "learning_rate": 9.868968528937565e-05,
      "loss": 3.033,
      "step": 36180
    },
    {
      "epoch": 1.5576310579323405,
      "grad_norm": 0.865671694278717,
      "learning_rate": 9.86432230312601e-05,
      "loss": 3.0599,
      "step": 36190
    },
    {
      "epoch": 1.5580614616510287,
      "grad_norm": 0.9705949425697327,
      "learning_rate": 9.859676106608971e-05,
      "loss": 3.0916,
      "step": 36200
    },
    {
      "epoch": 1.5580614616510287,
      "eval_bleu": 27.327526206488695,
      "eval_gen_len": 27.46,
      "eval_loss": 2.7958149909973145,
      "eval_runtime": 58.3401,
      "eval_samples_per_second": 17.141,
      "eval_steps_per_second": 1.08,
      "step": 36200
    },
    {
      "epoch": 1.5584918653697168,
      "grad_norm": 0.9009813070297241,
      "learning_rate": 9.85502994038962e-05,
      "loss": 3.005,
      "step": 36210
    },
    {
      "epoch": 1.5589222690884048,
      "grad_norm": 0.9203600287437439,
      "learning_rate": 9.850383805471123e-05,
      "loss": 3.0219,
      "step": 36220
    },
    {
      "epoch": 1.559352672807093,
      "grad_norm": 0.9788460731506348,
      "learning_rate": 9.845737702856639e-05,
      "loss": 2.9483,
      "step": 36230
    },
    {
      "epoch": 1.5597830765257812,
      "grad_norm": 0.9701011776924133,
      "learning_rate": 9.841091633549319e-05,
      "loss": 3.0151,
      "step": 36240
    },
    {
      "epoch": 1.5602134802444692,
      "grad_norm": 0.9313858151435852,
      "learning_rate": 9.836445598552311e-05,
      "loss": 2.9975,
      "step": 36250
    },
    {
      "epoch": 1.5602134802444692,
      "eval_bleu": 27.282948728822955,
      "eval_gen_len": 27.524,
      "eval_loss": 2.796232223510742,
      "eval_runtime": 58.6999,
      "eval_samples_per_second": 17.036,
      "eval_steps_per_second": 1.073,
      "step": 36250
    },
    {
      "epoch": 1.5606438839631576,
      "grad_norm": 1.0565468072891235,
      "learning_rate": 9.831799598868744e-05,
      "loss": 3.0047,
      "step": 36260
    },
    {
      "epoch": 1.5610742876818455,
      "grad_norm": 0.9180564284324646,
      "learning_rate": 9.827153635501755e-05,
      "loss": 2.9562,
      "step": 36270
    },
    {
      "epoch": 1.5615046914005337,
      "grad_norm": 0.8916864991188049,
      "learning_rate": 9.822507709454463e-05,
      "loss": 3.0147,
      "step": 36280
    },
    {
      "epoch": 1.561935095119222,
      "grad_norm": 0.8316522240638733,
      "learning_rate": 9.817861821729983e-05,
      "loss": 2.9748,
      "step": 36290
    },
    {
      "epoch": 1.5623654988379099,
      "grad_norm": 0.977293074131012,
      "learning_rate": 9.813215973331418e-05,
      "loss": 3.0778,
      "step": 36300
    },
    {
      "epoch": 1.5623654988379099,
      "eval_bleu": 27.456731612001654,
      "eval_gen_len": 27.48,
      "eval_loss": 2.7967402935028076,
      "eval_runtime": 58.3357,
      "eval_samples_per_second": 17.142,
      "eval_steps_per_second": 1.08,
      "step": 36300
    },
    {
      "epoch": 1.562795902556598,
      "grad_norm": 0.8834517598152161,
      "learning_rate": 9.808570165261868e-05,
      "loss": 3.043,
      "step": 36310
    },
    {
      "epoch": 1.5632263062752862,
      "grad_norm": 0.8420678973197937,
      "learning_rate": 9.803924398524419e-05,
      "loss": 3.0158,
      "step": 36320
    },
    {
      "epoch": 1.5636567099939742,
      "grad_norm": 0.9068375825881958,
      "learning_rate": 9.799278674122156e-05,
      "loss": 3.0751,
      "step": 36330
    },
    {
      "epoch": 1.5640871137126626,
      "grad_norm": 0.9847586154937744,
      "learning_rate": 9.79463299305814e-05,
      "loss": 3.06,
      "step": 36340
    },
    {
      "epoch": 1.5645175174313506,
      "grad_norm": 0.9118249416351318,
      "learning_rate": 9.789987356335436e-05,
      "loss": 2.9485,
      "step": 36350
    },
    {
      "epoch": 1.5645175174313506,
      "eval_bleu": 27.373751590651562,
      "eval_gen_len": 27.431,
      "eval_loss": 2.7989001274108887,
      "eval_runtime": 58.2756,
      "eval_samples_per_second": 17.16,
      "eval_steps_per_second": 1.081,
      "step": 36350
    },
    {
      "epoch": 1.5649479211500388,
      "grad_norm": 0.9712083339691162,
      "learning_rate": 9.785341764957095e-05,
      "loss": 3.0062,
      "step": 36360
    },
    {
      "epoch": 1.565378324868727,
      "grad_norm": 0.935463011264801,
      "learning_rate": 9.780696219926156e-05,
      "loss": 3.0187,
      "step": 36370
    },
    {
      "epoch": 1.565808728587415,
      "grad_norm": 0.9034982919692993,
      "learning_rate": 9.776050722245655e-05,
      "loss": 3.0012,
      "step": 36380
    },
    {
      "epoch": 1.5662391323061031,
      "grad_norm": 0.9460498690605164,
      "learning_rate": 9.771405272918612e-05,
      "loss": 3.0681,
      "step": 36390
    },
    {
      "epoch": 1.5666695360247913,
      "grad_norm": 0.9639667868614197,
      "learning_rate": 9.766759872948038e-05,
      "loss": 3.0207,
      "step": 36400
    },
    {
      "epoch": 1.5666695360247913,
      "eval_bleu": 27.333759149489172,
      "eval_gen_len": 27.355,
      "eval_loss": 2.7974188327789307,
      "eval_runtime": 58.3396,
      "eval_samples_per_second": 17.141,
      "eval_steps_per_second": 1.08,
      "step": 36400
    },
    {
      "epoch": 1.5670999397434793,
      "grad_norm": 0.9558165073394775,
      "learning_rate": 9.762114523336935e-05,
      "loss": 3.0331,
      "step": 36410
    },
    {
      "epoch": 1.5675303434621675,
      "grad_norm": 0.9023168087005615,
      "learning_rate": 9.757469225088286e-05,
      "loss": 2.9618,
      "step": 36420
    },
    {
      "epoch": 1.5679607471808557,
      "grad_norm": 0.9074656367301941,
      "learning_rate": 9.752823979205072e-05,
      "loss": 3.0184,
      "step": 36430
    },
    {
      "epoch": 1.5683911508995436,
      "grad_norm": 0.8813663721084595,
      "learning_rate": 9.74817878669026e-05,
      "loss": 2.9776,
      "step": 36440
    },
    {
      "epoch": 1.568821554618232,
      "grad_norm": 1.0329517126083374,
      "learning_rate": 9.743533648546806e-05,
      "loss": 3.2095,
      "step": 36450
    },
    {
      "epoch": 1.568821554618232,
      "eval_bleu": 27.29720864359964,
      "eval_gen_len": 27.345,
      "eval_loss": 2.799008369445801,
      "eval_runtime": 58.5527,
      "eval_samples_per_second": 17.079,
      "eval_steps_per_second": 1.076,
      "step": 36450
    },
    {
      "epoch": 1.56925195833692,
      "grad_norm": 1.044316291809082,
      "learning_rate": 9.738888565777654e-05,
      "loss": 3.0146,
      "step": 36460
    },
    {
      "epoch": 1.5696823620556082,
      "grad_norm": 0.9661679863929749,
      "learning_rate": 9.734243539385732e-05,
      "loss": 3.0206,
      "step": 36470
    },
    {
      "epoch": 1.5701127657742964,
      "grad_norm": 0.8447802662849426,
      "learning_rate": 9.729598570373966e-05,
      "loss": 3.1067,
      "step": 36480
    },
    {
      "epoch": 1.5705431694929843,
      "grad_norm": 0.87868732213974,
      "learning_rate": 9.724953659745258e-05,
      "loss": 3.0454,
      "step": 36490
    },
    {
      "epoch": 1.5709735732116725,
      "grad_norm": 0.9120705723762512,
      "learning_rate": 9.720308808502508e-05,
      "loss": 2.9724,
      "step": 36500
    },
    {
      "epoch": 1.5709735732116725,
      "eval_bleu": 27.241552232433627,
      "eval_gen_len": 27.38,
      "eval_loss": 2.7965993881225586,
      "eval_runtime": 58.5206,
      "eval_samples_per_second": 17.088,
      "eval_steps_per_second": 1.077,
      "step": 36500
    },
    {
      "epoch": 1.5714039769303607,
      "grad_norm": 1.0076748132705688,
      "learning_rate": 9.71566401764859e-05,
      "loss": 3.0021,
      "step": 36510
    },
    {
      "epoch": 1.5718343806490487,
      "grad_norm": 0.926572322845459,
      "learning_rate": 9.711019288186374e-05,
      "loss": 2.9513,
      "step": 36520
    },
    {
      "epoch": 1.572264784367737,
      "grad_norm": 0.9689487814903259,
      "learning_rate": 9.70637462111872e-05,
      "loss": 2.9932,
      "step": 36530
    },
    {
      "epoch": 1.572695188086425,
      "grad_norm": 0.8514882922172546,
      "learning_rate": 9.701730017448466e-05,
      "loss": 2.9833,
      "step": 36540
    },
    {
      "epoch": 1.5731255918051132,
      "grad_norm": 0.8355059623718262,
      "learning_rate": 9.697085478178442e-05,
      "loss": 2.9748,
      "step": 36550
    },
    {
      "epoch": 1.5731255918051132,
      "eval_bleu": 27.221061321092563,
      "eval_gen_len": 27.443,
      "eval_loss": 2.795081615447998,
      "eval_runtime": 58.2809,
      "eval_samples_per_second": 17.158,
      "eval_steps_per_second": 1.081,
      "step": 36550
    },
    {
      "epoch": 1.5735559955238014,
      "grad_norm": 0.8924623131752014,
      "learning_rate": 9.692441004311461e-05,
      "loss": 3.0421,
      "step": 36560
    },
    {
      "epoch": 1.5739863992424894,
      "grad_norm": 0.9477713704109192,
      "learning_rate": 9.687796596850321e-05,
      "loss": 3.0485,
      "step": 36570
    },
    {
      "epoch": 1.5744168029611776,
      "grad_norm": 1.0301318168640137,
      "learning_rate": 9.683152256797818e-05,
      "loss": 3.0816,
      "step": 36580
    },
    {
      "epoch": 1.5748472066798658,
      "grad_norm": 0.9508915543556213,
      "learning_rate": 9.678507985156712e-05,
      "loss": 2.9929,
      "step": 36590
    },
    {
      "epoch": 1.5752776103985537,
      "grad_norm": 1.0302085876464844,
      "learning_rate": 9.673863782929763e-05,
      "loss": 2.9942,
      "step": 36600
    },
    {
      "epoch": 1.5752776103985537,
      "eval_bleu": 26.847719891595894,
      "eval_gen_len": 27.401,
      "eval_loss": 2.7961792945861816,
      "eval_runtime": 57.9018,
      "eval_samples_per_second": 17.271,
      "eval_steps_per_second": 1.088,
      "step": 36600
    },
    {
      "epoch": 1.575708014117242,
      "grad_norm": 0.994822084903717,
      "learning_rate": 9.669219651119713e-05,
      "loss": 3.0584,
      "step": 36610
    },
    {
      "epoch": 1.5761384178359301,
      "grad_norm": 0.997151255607605,
      "learning_rate": 9.664575590729288e-05,
      "loss": 3.025,
      "step": 36620
    },
    {
      "epoch": 1.576568821554618,
      "grad_norm": 0.7957754135131836,
      "learning_rate": 9.6599316027612e-05,
      "loss": 2.9393,
      "step": 36630
    },
    {
      "epoch": 1.5769992252733065,
      "grad_norm": 0.9521984457969666,
      "learning_rate": 9.655287688218142e-05,
      "loss": 3.0171,
      "step": 36640
    },
    {
      "epoch": 1.5774296289919945,
      "grad_norm": 0.9266390800476074,
      "learning_rate": 9.650643848102795e-05,
      "loss": 3.0206,
      "step": 36650
    },
    {
      "epoch": 1.5774296289919945,
      "eval_bleu": 27.244464380868273,
      "eval_gen_len": 27.443,
      "eval_loss": 2.7954282760620117,
      "eval_runtime": 58.1152,
      "eval_samples_per_second": 17.207,
      "eval_steps_per_second": 1.084,
      "step": 36650
    },
    {
      "epoch": 1.5778600327106826,
      "grad_norm": 1.089720606803894,
      "learning_rate": 9.646000083417825e-05,
      "loss": 3.0165,
      "step": 36660
    },
    {
      "epoch": 1.5782904364293708,
      "grad_norm": 0.7583080530166626,
      "learning_rate": 9.641356395165873e-05,
      "loss": 3.1137,
      "step": 36670
    },
    {
      "epoch": 1.5787208401480588,
      "grad_norm": 0.9354990124702454,
      "learning_rate": 9.636712784349573e-05,
      "loss": 3.0519,
      "step": 36680
    },
    {
      "epoch": 1.579151243866747,
      "grad_norm": 0.9418371915817261,
      "learning_rate": 9.632069251971537e-05,
      "loss": 3.0539,
      "step": 36690
    },
    {
      "epoch": 1.5795816475854352,
      "grad_norm": 0.8535428047180176,
      "learning_rate": 9.627425799034364e-05,
      "loss": 3.0122,
      "step": 36700
    },
    {
      "epoch": 1.5795816475854352,
      "eval_bleu": 27.47855137933241,
      "eval_gen_len": 27.5,
      "eval_loss": 2.7951149940490723,
      "eval_runtime": 58.3192,
      "eval_samples_per_second": 17.147,
      "eval_steps_per_second": 1.08,
      "step": 36700
    },
    {
      "epoch": 1.5800120513041231,
      "grad_norm": 0.8467771410942078,
      "learning_rate": 9.622782426540634e-05,
      "loss": 3.0357,
      "step": 36710
    },
    {
      "epoch": 1.5804424550228116,
      "grad_norm": 0.871921181678772,
      "learning_rate": 9.618139135492906e-05,
      "loss": 3.0029,
      "step": 36720
    },
    {
      "epoch": 1.5808728587414995,
      "grad_norm": 1.0432848930358887,
      "learning_rate": 9.613495926893729e-05,
      "loss": 3.0816,
      "step": 36730
    },
    {
      "epoch": 1.5813032624601877,
      "grad_norm": 0.917994499206543,
      "learning_rate": 9.608852801745629e-05,
      "loss": 3.0175,
      "step": 36740
    },
    {
      "epoch": 1.581733666178876,
      "grad_norm": 0.944989025592804,
      "learning_rate": 9.604209761051113e-05,
      "loss": 3.0032,
      "step": 36750
    },
    {
      "epoch": 1.581733666178876,
      "eval_bleu": 27.019925589500904,
      "eval_gen_len": 27.483,
      "eval_loss": 2.7960495948791504,
      "eval_runtime": 58.5427,
      "eval_samples_per_second": 17.082,
      "eval_steps_per_second": 1.076,
      "step": 36750
    },
    {
      "epoch": 1.5821640698975639,
      "grad_norm": 1.0775724649429321,
      "learning_rate": 9.599566805812671e-05,
      "loss": 3.0764,
      "step": 36760
    },
    {
      "epoch": 1.582594473616252,
      "grad_norm": 0.9553488492965698,
      "learning_rate": 9.594923937032778e-05,
      "loss": 2.9727,
      "step": 36770
    },
    {
      "epoch": 1.5830248773349402,
      "grad_norm": 0.9317495226860046,
      "learning_rate": 9.590281155713888e-05,
      "loss": 3.0288,
      "step": 36780
    },
    {
      "epoch": 1.5834552810536282,
      "grad_norm": 0.9714430570602417,
      "learning_rate": 9.585638462858431e-05,
      "loss": 3.0309,
      "step": 36790
    },
    {
      "epoch": 1.5838856847723164,
      "grad_norm": 1.174664855003357,
      "learning_rate": 9.580995859468828e-05,
      "loss": 3.0801,
      "step": 36800
    },
    {
      "epoch": 1.5838856847723164,
      "eval_bleu": 27.20945280486299,
      "eval_gen_len": 27.391,
      "eval_loss": 2.797966957092285,
      "eval_runtime": 58.7118,
      "eval_samples_per_second": 17.032,
      "eval_steps_per_second": 1.073,
      "step": 36800
    },
    {
      "epoch": 1.5843160884910046,
      "grad_norm": 0.8829585909843445,
      "learning_rate": 9.576353346547471e-05,
      "loss": 2.9723,
      "step": 36810
    },
    {
      "epoch": 1.5847464922096925,
      "grad_norm": 0.8754271268844604,
      "learning_rate": 9.571710925096744e-05,
      "loss": 2.9933,
      "step": 36820
    },
    {
      "epoch": 1.585176895928381,
      "grad_norm": 1.0515773296356201,
      "learning_rate": 9.567068596118996e-05,
      "loss": 3.0664,
      "step": 36830
    },
    {
      "epoch": 1.585607299647069,
      "grad_norm": 0.8288939595222473,
      "learning_rate": 9.562426360616565e-05,
      "loss": 2.9622,
      "step": 36840
    },
    {
      "epoch": 1.5860377033657571,
      "grad_norm": 1.0278133153915405,
      "learning_rate": 9.557784219591771e-05,
      "loss": 3.0107,
      "step": 36850
    },
    {
      "epoch": 1.5860377033657571,
      "eval_bleu": 26.84533755596492,
      "eval_gen_len": 27.47,
      "eval_loss": 2.7994892597198486,
      "eval_runtime": 58.4863,
      "eval_samples_per_second": 17.098,
      "eval_steps_per_second": 1.077,
      "step": 36850
    },
    {
      "epoch": 1.5864681070844453,
      "grad_norm": 0.9983667731285095,
      "learning_rate": 9.553142174046909e-05,
      "loss": 3.0193,
      "step": 36860
    },
    {
      "epoch": 1.5868985108031333,
      "grad_norm": 0.9206565022468567,
      "learning_rate": 9.548500224984255e-05,
      "loss": 2.9996,
      "step": 36870
    },
    {
      "epoch": 1.5873289145218215,
      "grad_norm": 1.0027450323104858,
      "learning_rate": 9.543858373406064e-05,
      "loss": 3.0617,
      "step": 36880
    },
    {
      "epoch": 1.5877593182405096,
      "grad_norm": 0.9825714230537415,
      "learning_rate": 9.53921662031457e-05,
      "loss": 2.9838,
      "step": 36890
    },
    {
      "epoch": 1.5881897219591976,
      "grad_norm": 0.9531246423721313,
      "learning_rate": 9.534574966711987e-05,
      "loss": 3.147,
      "step": 36900
    },
    {
      "epoch": 1.5881897219591976,
      "eval_bleu": 26.925283480416883,
      "eval_gen_len": 27.55,
      "eval_loss": 2.798159599304199,
      "eval_runtime": 58.2414,
      "eval_samples_per_second": 17.17,
      "eval_steps_per_second": 1.082,
      "step": 36900
    },
    {
      "epoch": 1.588620125677886,
      "grad_norm": 0.9566042423248291,
      "learning_rate": 9.529933413600505e-05,
      "loss": 2.9951,
      "step": 36910
    },
    {
      "epoch": 1.589050529396574,
      "grad_norm": 0.9989300966262817,
      "learning_rate": 9.525291961982292e-05,
      "loss": 3.0345,
      "step": 36920
    },
    {
      "epoch": 1.589480933115262,
      "grad_norm": 0.8625057935714722,
      "learning_rate": 9.520650612859498e-05,
      "loss": 2.9811,
      "step": 36930
    },
    {
      "epoch": 1.5899113368339504,
      "grad_norm": 0.9331847429275513,
      "learning_rate": 9.516009367234246e-05,
      "loss": 2.982,
      "step": 36940
    },
    {
      "epoch": 1.5903417405526383,
      "grad_norm": 0.9624996781349182,
      "learning_rate": 9.511368226108641e-05,
      "loss": 2.9766,
      "step": 36950
    },
    {
      "epoch": 1.5903417405526383,
      "eval_bleu": 26.84494634769267,
      "eval_gen_len": 27.368,
      "eval_loss": 2.797187089920044,
      "eval_runtime": 58.2366,
      "eval_samples_per_second": 17.171,
      "eval_steps_per_second": 1.082,
      "step": 36950
    },
    {
      "epoch": 1.5907721442713265,
      "grad_norm": 0.9437881112098694,
      "learning_rate": 9.506727190484764e-05,
      "loss": 2.985,
      "step": 36960
    },
    {
      "epoch": 1.5912025479900147,
      "grad_norm": 0.957286536693573,
      "learning_rate": 9.502086261364673e-05,
      "loss": 3.1655,
      "step": 36970
    },
    {
      "epoch": 1.5916329517087027,
      "grad_norm": 0.9788032174110413,
      "learning_rate": 9.497445439750403e-05,
      "loss": 2.979,
      "step": 36980
    },
    {
      "epoch": 1.5920633554273909,
      "grad_norm": 0.9388691186904907,
      "learning_rate": 9.492804726643962e-05,
      "loss": 3.0873,
      "step": 36990
    },
    {
      "epoch": 1.592493759146079,
      "grad_norm": 0.8275941014289856,
      "learning_rate": 9.488164123047338e-05,
      "loss": 2.9916,
      "step": 37000
    },
    {
      "epoch": 1.592493759146079,
      "eval_bleu": 27.024800709454954,
      "eval_gen_len": 27.56,
      "eval_loss": 2.7957241535186768,
      "eval_runtime": 59.0044,
      "eval_samples_per_second": 16.948,
      "eval_steps_per_second": 1.068,
      "step": 37000
    },
    {
      "epoch": 1.592924162864767,
      "grad_norm": 0.927422285079956,
      "learning_rate": 9.483523629962502e-05,
      "loss": 2.9548,
      "step": 37010
    },
    {
      "epoch": 1.5933545665834554,
      "grad_norm": 0.9101755619049072,
      "learning_rate": 9.478883248391388e-05,
      "loss": 3.0108,
      "step": 37020
    },
    {
      "epoch": 1.5937849703021434,
      "grad_norm": 0.9876440167427063,
      "learning_rate": 9.474242979335917e-05,
      "loss": 2.912,
      "step": 37030
    },
    {
      "epoch": 1.5942153740208316,
      "grad_norm": 0.9030848741531372,
      "learning_rate": 9.46960282379798e-05,
      "loss": 2.9575,
      "step": 37040
    },
    {
      "epoch": 1.5946457777395198,
      "grad_norm": 0.8866010308265686,
      "learning_rate": 9.464962782779443e-05,
      "loss": 3.0326,
      "step": 37050
    },
    {
      "epoch": 1.5946457777395198,
      "eval_bleu": 27.03474296539532,
      "eval_gen_len": 27.501,
      "eval_loss": 2.7931978702545166,
      "eval_runtime": 58.687,
      "eval_samples_per_second": 17.04,
      "eval_steps_per_second": 1.073,
      "step": 37050
    },
    {
      "epoch": 1.5950761814582077,
      "grad_norm": 0.8869181275367737,
      "learning_rate": 9.46032285728215e-05,
      "loss": 3.0,
      "step": 37060
    },
    {
      "epoch": 1.595506585176896,
      "grad_norm": 0.9013120532035828,
      "learning_rate": 9.455683048307925e-05,
      "loss": 3.0316,
      "step": 37070
    },
    {
      "epoch": 1.595936988895584,
      "grad_norm": 1.0397404432296753,
      "learning_rate": 9.451043356858551e-05,
      "loss": 3.0859,
      "step": 37080
    },
    {
      "epoch": 1.596367392614272,
      "grad_norm": 0.8491998910903931,
      "learning_rate": 9.446403783935799e-05,
      "loss": 2.9839,
      "step": 37090
    },
    {
      "epoch": 1.5967977963329603,
      "grad_norm": 1.0116978883743286,
      "learning_rate": 9.441764330541411e-05,
      "loss": 3.0826,
      "step": 37100
    },
    {
      "epoch": 1.5967977963329603,
      "eval_bleu": 27.494420267997885,
      "eval_gen_len": 27.502,
      "eval_loss": 2.79683780670166,
      "eval_runtime": 58.3631,
      "eval_samples_per_second": 17.134,
      "eval_steps_per_second": 1.079,
      "step": 37100
    },
    {
      "epoch": 1.5972282000516485,
      "grad_norm": 0.9265870451927185,
      "learning_rate": 9.437124997677105e-05,
      "loss": 3.0649,
      "step": 37110
    },
    {
      "epoch": 1.5976586037703364,
      "grad_norm": 0.8427074551582336,
      "learning_rate": 9.43248578634457e-05,
      "loss": 2.9579,
      "step": 37120
    },
    {
      "epoch": 1.5980890074890248,
      "grad_norm": 0.9426314830780029,
      "learning_rate": 9.427846697545472e-05,
      "loss": 2.8784,
      "step": 37130
    },
    {
      "epoch": 1.5985194112077128,
      "grad_norm": 0.8753132224082947,
      "learning_rate": 9.423207732281445e-05,
      "loss": 2.9825,
      "step": 37140
    },
    {
      "epoch": 1.598949814926401,
      "grad_norm": 0.9474716186523438,
      "learning_rate": 9.418568891554106e-05,
      "loss": 2.981,
      "step": 37150
    },
    {
      "epoch": 1.598949814926401,
      "eval_bleu": 26.9059150007799,
      "eval_gen_len": 27.436,
      "eval_loss": 2.7975356578826904,
      "eval_runtime": 58.0208,
      "eval_samples_per_second": 17.235,
      "eval_steps_per_second": 1.086,
      "step": 37150
    },
    {
      "epoch": 1.5993802186450892,
      "grad_norm": 1.0301586389541626,
      "learning_rate": 9.41393017636503e-05,
      "loss": 3.0555,
      "step": 37160
    },
    {
      "epoch": 1.5998106223637771,
      "grad_norm": 0.9741556644439697,
      "learning_rate": 9.409291587715779e-05,
      "loss": 3.1284,
      "step": 37170
    },
    {
      "epoch": 1.6002410260824653,
      "grad_norm": 0.8485009670257568,
      "learning_rate": 9.404653126607879e-05,
      "loss": 2.9883,
      "step": 37180
    },
    {
      "epoch": 1.6006714298011535,
      "grad_norm": 0.8325726389884949,
      "learning_rate": 9.400014794042838e-05,
      "loss": 2.9845,
      "step": 37190
    },
    {
      "epoch": 1.6011018335198415,
      "grad_norm": 0.9430384039878845,
      "learning_rate": 9.395376591022122e-05,
      "loss": 2.9871,
      "step": 37200
    },
    {
      "epoch": 1.6011018335198415,
      "eval_bleu": 27.04027314067152,
      "eval_gen_len": 27.562,
      "eval_loss": 2.796994924545288,
      "eval_runtime": 59.0871,
      "eval_samples_per_second": 16.924,
      "eval_steps_per_second": 1.066,
      "step": 37200
    },
    {
      "epoch": 1.6015322372385299,
      "grad_norm": 0.8856887817382812,
      "learning_rate": 9.390738518547184e-05,
      "loss": 3.0178,
      "step": 37210
    },
    {
      "epoch": 1.6019626409572179,
      "grad_norm": 1.0205023288726807,
      "learning_rate": 9.38610057761944e-05,
      "loss": 3.097,
      "step": 37220
    },
    {
      "epoch": 1.602393044675906,
      "grad_norm": 0.8636590242385864,
      "learning_rate": 9.381462769240284e-05,
      "loss": 3.0054,
      "step": 37230
    },
    {
      "epoch": 1.6028234483945942,
      "grad_norm": 0.9851823449134827,
      "learning_rate": 9.376825094411067e-05,
      "loss": 3.0283,
      "step": 37240
    },
    {
      "epoch": 1.6032538521132822,
      "grad_norm": 0.9097790122032166,
      "learning_rate": 9.372187554133127e-05,
      "loss": 3.0388,
      "step": 37250
    },
    {
      "epoch": 1.6032538521132822,
      "eval_bleu": 27.365062536190454,
      "eval_gen_len": 27.42,
      "eval_loss": 2.7968297004699707,
      "eval_runtime": 58.3266,
      "eval_samples_per_second": 17.145,
      "eval_steps_per_second": 1.08,
      "step": 37250
    },
    {
      "epoch": 1.6036842558319704,
      "grad_norm": 0.8148236274719238,
      "learning_rate": 9.367550149407767e-05,
      "loss": 3.0317,
      "step": 37260
    },
    {
      "epoch": 1.6041146595506586,
      "grad_norm": 0.8449920415878296,
      "learning_rate": 9.36291288123626e-05,
      "loss": 3.0307,
      "step": 37270
    },
    {
      "epoch": 1.6045450632693465,
      "grad_norm": 0.8348536491394043,
      "learning_rate": 9.358275750619851e-05,
      "loss": 3.1365,
      "step": 37280
    },
    {
      "epoch": 1.6049754669880347,
      "grad_norm": 0.8806031942367554,
      "learning_rate": 9.353638758559753e-05,
      "loss": 2.9983,
      "step": 37290
    },
    {
      "epoch": 1.605405870706723,
      "grad_norm": 0.8699522614479065,
      "learning_rate": 9.349001906057154e-05,
      "loss": 3.0565,
      "step": 37300
    },
    {
      "epoch": 1.605405870706723,
      "eval_bleu": 26.90015446934902,
      "eval_gen_len": 27.446,
      "eval_loss": 2.7996881008148193,
      "eval_runtime": 58.3273,
      "eval_samples_per_second": 17.145,
      "eval_steps_per_second": 1.08,
      "step": 37300
    },
    {
      "epoch": 1.6058362744254109,
      "grad_norm": 0.8698040246963501,
      "learning_rate": 9.34436519411321e-05,
      "loss": 3.0957,
      "step": 37310
    },
    {
      "epoch": 1.6062666781440993,
      "grad_norm": 0.8964674472808838,
      "learning_rate": 9.339728623729037e-05,
      "loss": 2.9723,
      "step": 37320
    },
    {
      "epoch": 1.6066970818627873,
      "grad_norm": 1.0204527378082275,
      "learning_rate": 9.335092195905736e-05,
      "loss": 2.9297,
      "step": 37330
    },
    {
      "epoch": 1.6071274855814754,
      "grad_norm": 0.9487267732620239,
      "learning_rate": 9.330455911644365e-05,
      "loss": 3.0398,
      "step": 37340
    },
    {
      "epoch": 1.6075578893001636,
      "grad_norm": 0.9007989168167114,
      "learning_rate": 9.32581977194596e-05,
      "loss": 2.9511,
      "step": 37350
    },
    {
      "epoch": 1.6075578893001636,
      "eval_bleu": 26.97365478547376,
      "eval_gen_len": 27.433,
      "eval_loss": 2.796680212020874,
      "eval_runtime": 58.5826,
      "eval_samples_per_second": 17.07,
      "eval_steps_per_second": 1.075,
      "step": 37350
    },
    {
      "epoch": 1.6079882930188516,
      "grad_norm": 0.95316082239151,
      "learning_rate": 9.32118377781152e-05,
      "loss": 3.072,
      "step": 37360
    },
    {
      "epoch": 1.6084186967375398,
      "grad_norm": 0.9899793863296509,
      "learning_rate": 9.316547930242016e-05,
      "loss": 3.0848,
      "step": 37370
    },
    {
      "epoch": 1.608849100456228,
      "grad_norm": 0.9536272883415222,
      "learning_rate": 9.311912230238382e-05,
      "loss": 3.0245,
      "step": 37380
    },
    {
      "epoch": 1.609279504174916,
      "grad_norm": 0.9266905784606934,
      "learning_rate": 9.307276678801529e-05,
      "loss": 3.0337,
      "step": 37390
    },
    {
      "epoch": 1.6097099078936044,
      "grad_norm": 0.9496676325798035,
      "learning_rate": 9.302641276932325e-05,
      "loss": 3.0927,
      "step": 37400
    },
    {
      "epoch": 1.6097099078936044,
      "eval_bleu": 27.11753847211658,
      "eval_gen_len": 27.528,
      "eval_loss": 2.79794979095459,
      "eval_runtime": 58.3622,
      "eval_samples_per_second": 17.134,
      "eval_steps_per_second": 1.079,
      "step": 37400
    },
    {
      "epoch": 1.6101403116122923,
      "grad_norm": 1.011825442314148,
      "learning_rate": 9.298006025631614e-05,
      "loss": 2.9963,
      "step": 37410
    },
    {
      "epoch": 1.6105707153309805,
      "grad_norm": 0.9100791215896606,
      "learning_rate": 9.293370925900206e-05,
      "loss": 3.0364,
      "step": 37420
    },
    {
      "epoch": 1.6110011190496687,
      "grad_norm": 0.9750899076461792,
      "learning_rate": 9.288735978738875e-05,
      "loss": 3.0149,
      "step": 37430
    },
    {
      "epoch": 1.6114315227683567,
      "grad_norm": 0.8557119369506836,
      "learning_rate": 9.284101185148364e-05,
      "loss": 2.9894,
      "step": 37440
    },
    {
      "epoch": 1.6118619264870448,
      "grad_norm": 0.9059914946556091,
      "learning_rate": 9.279466546129385e-05,
      "loss": 2.9949,
      "step": 37450
    },
    {
      "epoch": 1.6118619264870448,
      "eval_bleu": 26.7682042702971,
      "eval_gen_len": 27.543,
      "eval_loss": 2.796025037765503,
      "eval_runtime": 59.0579,
      "eval_samples_per_second": 16.933,
      "eval_steps_per_second": 1.067,
      "step": 37450
    },
    {
      "epoch": 1.612292330205733,
      "grad_norm": 0.8765166401863098,
      "learning_rate": 9.274832062682613e-05,
      "loss": 3.0496,
      "step": 37460
    },
    {
      "epoch": 1.612722733924421,
      "grad_norm": 0.7836165428161621,
      "learning_rate": 9.270197735808696e-05,
      "loss": 2.8741,
      "step": 37470
    },
    {
      "epoch": 1.6131531376431092,
      "grad_norm": 0.8882480263710022,
      "learning_rate": 9.265563566508237e-05,
      "loss": 2.9912,
      "step": 37480
    },
    {
      "epoch": 1.6135835413617974,
      "grad_norm": 0.9240492582321167,
      "learning_rate": 9.260929555781812e-05,
      "loss": 3.0526,
      "step": 37490
    },
    {
      "epoch": 1.6140139450804853,
      "grad_norm": 1.007427453994751,
      "learning_rate": 9.256295704629964e-05,
      "loss": 2.9404,
      "step": 37500
    },
    {
      "epoch": 1.6140139450804853,
      "eval_bleu": 26.780431296856523,
      "eval_gen_len": 27.441,
      "eval_loss": 2.7979509830474854,
      "eval_runtime": 58.5069,
      "eval_samples_per_second": 17.092,
      "eval_steps_per_second": 1.077,
      "step": 37500
    },
    {
      "epoch": 1.6144443487991738,
      "grad_norm": 0.8849697113037109,
      "learning_rate": 9.2516620140532e-05,
      "loss": 3.03,
      "step": 37510
    },
    {
      "epoch": 1.6148747525178617,
      "grad_norm": 0.9386656880378723,
      "learning_rate": 9.247028485051991e-05,
      "loss": 3.0564,
      "step": 37520
    },
    {
      "epoch": 1.61530515623655,
      "grad_norm": 0.7948472499847412,
      "learning_rate": 9.242395118626774e-05,
      "loss": 3.0995,
      "step": 37530
    },
    {
      "epoch": 1.615735559955238,
      "grad_norm": 0.9460822343826294,
      "learning_rate": 9.23776191577795e-05,
      "loss": 3.0653,
      "step": 37540
    },
    {
      "epoch": 1.616165963673926,
      "grad_norm": 0.9617299437522888,
      "learning_rate": 9.23312887750589e-05,
      "loss": 3.0446,
      "step": 37550
    },
    {
      "epoch": 1.616165963673926,
      "eval_bleu": 26.60411963778292,
      "eval_gen_len": 27.494,
      "eval_loss": 2.796696662902832,
      "eval_runtime": 58.6016,
      "eval_samples_per_second": 17.064,
      "eval_steps_per_second": 1.075,
      "step": 37550
    },
    {
      "epoch": 1.6165963673926143,
      "grad_norm": 0.8919495940208435,
      "learning_rate": 9.228496004810918e-05,
      "loss": 3.046,
      "step": 37560
    },
    {
      "epoch": 1.6170267711113024,
      "grad_norm": 0.9310466647148132,
      "learning_rate": 9.223863298693334e-05,
      "loss": 3.089,
      "step": 37570
    },
    {
      "epoch": 1.6174571748299904,
      "grad_norm": 0.864059329032898,
      "learning_rate": 9.219230760153395e-05,
      "loss": 2.9625,
      "step": 37580
    },
    {
      "epoch": 1.6178875785486788,
      "grad_norm": 0.851668655872345,
      "learning_rate": 9.214598390191326e-05,
      "loss": 2.9257,
      "step": 37590
    },
    {
      "epoch": 1.6183179822673668,
      "grad_norm": 0.9044826030731201,
      "learning_rate": 9.209966189807314e-05,
      "loss": 2.9894,
      "step": 37600
    },
    {
      "epoch": 1.6183179822673668,
      "eval_bleu": 26.456868339832752,
      "eval_gen_len": 27.48,
      "eval_loss": 2.795806407928467,
      "eval_runtime": 58.8284,
      "eval_samples_per_second": 16.999,
      "eval_steps_per_second": 1.071,
      "step": 37600
    },
    {
      "epoch": 1.618748385986055,
      "grad_norm": 0.9468000531196594,
      "learning_rate": 9.205334160001509e-05,
      "loss": 3.0678,
      "step": 37610
    },
    {
      "epoch": 1.6191787897047432,
      "grad_norm": 0.8480433821678162,
      "learning_rate": 9.200702301774022e-05,
      "loss": 3.0062,
      "step": 37620
    },
    {
      "epoch": 1.6196091934234311,
      "grad_norm": 0.9858243465423584,
      "learning_rate": 9.196070616124933e-05,
      "loss": 3.0107,
      "step": 37630
    },
    {
      "epoch": 1.6200395971421193,
      "grad_norm": 0.9241572618484497,
      "learning_rate": 9.191439104054278e-05,
      "loss": 2.9841,
      "step": 37640
    },
    {
      "epoch": 1.6204700008608075,
      "grad_norm": 0.9835726618766785,
      "learning_rate": 9.18680776656206e-05,
      "loss": 2.946,
      "step": 37650
    },
    {
      "epoch": 1.6204700008608075,
      "eval_bleu": 26.79387478104572,
      "eval_gen_len": 27.543,
      "eval_loss": 2.796434164047241,
      "eval_runtime": 59.1711,
      "eval_samples_per_second": 16.9,
      "eval_steps_per_second": 1.065,
      "step": 37650
    },
    {
      "epoch": 1.6209004045794955,
      "grad_norm": 0.9416399598121643,
      "learning_rate": 9.18217660464824e-05,
      "loss": 3.0078,
      "step": 37660
    },
    {
      "epoch": 1.6213308082981837,
      "grad_norm": 0.9084247946739197,
      "learning_rate": 9.177545619312747e-05,
      "loss": 2.9858,
      "step": 37670
    },
    {
      "epoch": 1.6217612120168718,
      "grad_norm": 0.8975868225097656,
      "learning_rate": 9.172914811555468e-05,
      "loss": 3.0688,
      "step": 37680
    },
    {
      "epoch": 1.6221916157355598,
      "grad_norm": 0.9113054275512695,
      "learning_rate": 9.168284182376255e-05,
      "loss": 2.9579,
      "step": 37690
    },
    {
      "epoch": 1.6226220194542482,
      "grad_norm": 0.8641481995582581,
      "learning_rate": 9.163653732774912e-05,
      "loss": 3.1147,
      "step": 37700
    },
    {
      "epoch": 1.6226220194542482,
      "eval_bleu": 26.879856289831473,
      "eval_gen_len": 27.539,
      "eval_loss": 2.796262741088867,
      "eval_runtime": 58.3274,
      "eval_samples_per_second": 17.145,
      "eval_steps_per_second": 1.08,
      "step": 37700
    },
    {
      "epoch": 1.6230524231729362,
      "grad_norm": 0.8441599607467651,
      "learning_rate": 9.15902346375122e-05,
      "loss": 2.9752,
      "step": 37710
    },
    {
      "epoch": 1.6234828268916244,
      "grad_norm": 0.8910293579101562,
      "learning_rate": 9.154393376304909e-05,
      "loss": 3.0844,
      "step": 37720
    },
    {
      "epoch": 1.6239132306103126,
      "grad_norm": 0.9020800590515137,
      "learning_rate": 9.149763471435666e-05,
      "loss": 2.9759,
      "step": 37730
    },
    {
      "epoch": 1.6243436343290005,
      "grad_norm": 0.9853624105453491,
      "learning_rate": 9.145133750143154e-05,
      "loss": 3.0489,
      "step": 37740
    },
    {
      "epoch": 1.6247740380476887,
      "grad_norm": 0.9000896215438843,
      "learning_rate": 9.140504213426984e-05,
      "loss": 2.9427,
      "step": 37750
    },
    {
      "epoch": 1.6247740380476887,
      "eval_bleu": 26.5884877933105,
      "eval_gen_len": 27.416,
      "eval_loss": 2.7953529357910156,
      "eval_runtime": 58.5897,
      "eval_samples_per_second": 17.068,
      "eval_steps_per_second": 1.075,
      "step": 37750
    },
    {
      "epoch": 1.625204441766377,
      "grad_norm": 0.9549561142921448,
      "learning_rate": 9.135874862286733e-05,
      "loss": 2.97,
      "step": 37760
    },
    {
      "epoch": 1.6256348454850649,
      "grad_norm": 0.808867871761322,
      "learning_rate": 9.131245697721934e-05,
      "loss": 3.0382,
      "step": 37770
    },
    {
      "epoch": 1.6260652492037533,
      "grad_norm": 0.8556857705116272,
      "learning_rate": 9.126616720732083e-05,
      "loss": 3.0357,
      "step": 37780
    },
    {
      "epoch": 1.6264956529224412,
      "grad_norm": 0.914645254611969,
      "learning_rate": 9.121987932316635e-05,
      "loss": 3.029,
      "step": 37790
    },
    {
      "epoch": 1.6269260566411292,
      "grad_norm": 0.9537985920906067,
      "learning_rate": 9.117359333475005e-05,
      "loss": 2.9735,
      "step": 37800
    },
    {
      "epoch": 1.6269260566411292,
      "eval_bleu": 26.818345860451647,
      "eval_gen_len": 27.426,
      "eval_loss": 2.793656587600708,
      "eval_runtime": 58.7316,
      "eval_samples_per_second": 17.027,
      "eval_steps_per_second": 1.073,
      "step": 37800
    },
    {
      "epoch": 1.6273564603598176,
      "grad_norm": 0.9606844782829285,
      "learning_rate": 9.112730925206559e-05,
      "loss": 2.9617,
      "step": 37810
    },
    {
      "epoch": 1.6277868640785056,
      "grad_norm": 0.9060320258140564,
      "learning_rate": 9.108102708510632e-05,
      "loss": 3.0351,
      "step": 37820
    },
    {
      "epoch": 1.6282172677971938,
      "grad_norm": 0.9668227434158325,
      "learning_rate": 9.103474684386514e-05,
      "loss": 3.0392,
      "step": 37830
    },
    {
      "epoch": 1.628647671515882,
      "grad_norm": 1.0632582902908325,
      "learning_rate": 9.098846853833454e-05,
      "loss": 2.9756,
      "step": 37840
    },
    {
      "epoch": 1.62907807523457,
      "grad_norm": 0.9326307773590088,
      "learning_rate": 9.094219217850659e-05,
      "loss": 3.0919,
      "step": 37850
    },
    {
      "epoch": 1.62907807523457,
      "eval_bleu": 26.99671355082689,
      "eval_gen_len": 27.443,
      "eval_loss": 2.794769048690796,
      "eval_runtime": 59.5001,
      "eval_samples_per_second": 16.807,
      "eval_steps_per_second": 1.059,
      "step": 37850
    },
    {
      "epoch": 1.6295084789532581,
      "grad_norm": 0.8785969614982605,
      "learning_rate": 9.089591777437293e-05,
      "loss": 3.0392,
      "step": 37860
    },
    {
      "epoch": 1.6299388826719463,
      "grad_norm": 1.0215259790420532,
      "learning_rate": 9.084964533592479e-05,
      "loss": 3.0802,
      "step": 37870
    },
    {
      "epoch": 1.6303692863906343,
      "grad_norm": 0.9877642393112183,
      "learning_rate": 9.0803374873153e-05,
      "loss": 2.9853,
      "step": 37880
    },
    {
      "epoch": 1.6307996901093227,
      "grad_norm": 0.902448296546936,
      "learning_rate": 9.075710639604785e-05,
      "loss": 2.9197,
      "step": 37890
    },
    {
      "epoch": 1.6312300938280107,
      "grad_norm": 1.038532018661499,
      "learning_rate": 9.071083991459934e-05,
      "loss": 3.0583,
      "step": 37900
    },
    {
      "epoch": 1.6312300938280107,
      "eval_bleu": 26.770983556715624,
      "eval_gen_len": 27.476,
      "eval_loss": 2.796640634536743,
      "eval_runtime": 58.6923,
      "eval_samples_per_second": 17.038,
      "eval_steps_per_second": 1.073,
      "step": 37900
    },
    {
      "epoch": 1.6316604975466988,
      "grad_norm": 0.917021632194519,
      "learning_rate": 9.066457543879697e-05,
      "loss": 2.9429,
      "step": 37910
    },
    {
      "epoch": 1.632090901265387,
      "grad_norm": 1.0688263177871704,
      "learning_rate": 9.061831297862982e-05,
      "loss": 3.0832,
      "step": 37920
    },
    {
      "epoch": 1.632521304984075,
      "grad_norm": 0.9246668219566345,
      "learning_rate": 9.057205254408653e-05,
      "loss": 3.067,
      "step": 37930
    },
    {
      "epoch": 1.6329517087027632,
      "grad_norm": 1.012229323387146,
      "learning_rate": 9.052579414515533e-05,
      "loss": 2.8445,
      "step": 37940
    },
    {
      "epoch": 1.6333821124214514,
      "grad_norm": 0.9466774463653564,
      "learning_rate": 9.047953779182398e-05,
      "loss": 3.0161,
      "step": 37950
    },
    {
      "epoch": 1.6333821124214514,
      "eval_bleu": 26.572363285113646,
      "eval_gen_len": 27.42,
      "eval_loss": 2.8009793758392334,
      "eval_runtime": 57.9731,
      "eval_samples_per_second": 17.249,
      "eval_steps_per_second": 1.087,
      "step": 37950
    },
    {
      "epoch": 1.6338125161401393,
      "grad_norm": 0.9642953872680664,
      "learning_rate": 9.043328349407986e-05,
      "loss": 3.1055,
      "step": 37960
    },
    {
      "epoch": 1.6342429198588275,
      "grad_norm": 0.9626668691635132,
      "learning_rate": 9.038703126190974e-05,
      "loss": 2.9367,
      "step": 37970
    },
    {
      "epoch": 1.6346733235775157,
      "grad_norm": 0.9303849339485168,
      "learning_rate": 9.034078110530012e-05,
      "loss": 3.0258,
      "step": 37980
    },
    {
      "epoch": 1.6351037272962037,
      "grad_norm": 0.895357608795166,
      "learning_rate": 9.029453303423697e-05,
      "loss": 2.9909,
      "step": 37990
    },
    {
      "epoch": 1.635534131014892,
      "grad_norm": 0.9605907797813416,
      "learning_rate": 9.024828705870585e-05,
      "loss": 2.9437,
      "step": 38000
    },
    {
      "epoch": 1.635534131014892,
      "eval_bleu": 27.315856479219118,
      "eval_gen_len": 27.393,
      "eval_loss": 2.7921199798583984,
      "eval_runtime": 58.2728,
      "eval_samples_per_second": 17.161,
      "eval_steps_per_second": 1.081,
      "step": 38000
    },
    {
      "epoch": 1.63596453473358,
      "grad_norm": 0.9082257747650146,
      "learning_rate": 9.020204318869183e-05,
      "loss": 3.0045,
      "step": 38010
    },
    {
      "epoch": 1.6363949384522682,
      "grad_norm": 0.9553586840629578,
      "learning_rate": 9.015580143417957e-05,
      "loss": 3.0634,
      "step": 38020
    },
    {
      "epoch": 1.6368253421709564,
      "grad_norm": 0.8951240181922913,
      "learning_rate": 9.010956180515318e-05,
      "loss": 3.0144,
      "step": 38030
    },
    {
      "epoch": 1.6372557458896444,
      "grad_norm": 0.9411068558692932,
      "learning_rate": 9.006332431159648e-05,
      "loss": 3.0575,
      "step": 38040
    },
    {
      "epoch": 1.6376861496083326,
      "grad_norm": 0.8503658175468445,
      "learning_rate": 9.001708896349264e-05,
      "loss": 2.9728,
      "step": 38050
    },
    {
      "epoch": 1.6376861496083326,
      "eval_bleu": 27.105994459862348,
      "eval_gen_len": 27.43,
      "eval_loss": 2.7950336933135986,
      "eval_runtime": 59.2721,
      "eval_samples_per_second": 16.871,
      "eval_steps_per_second": 1.063,
      "step": 38050
    },
    {
      "epoch": 1.6381165533270208,
      "grad_norm": 0.9943583607673645,
      "learning_rate": 8.997085577082446e-05,
      "loss": 2.9822,
      "step": 38060
    },
    {
      "epoch": 1.6385469570457087,
      "grad_norm": 0.9277779459953308,
      "learning_rate": 8.992462474357429e-05,
      "loss": 3.0299,
      "step": 38070
    },
    {
      "epoch": 1.6389773607643972,
      "grad_norm": 0.9299803376197815,
      "learning_rate": 8.987839589172395e-05,
      "loss": 3.0606,
      "step": 38080
    },
    {
      "epoch": 1.6394077644830851,
      "grad_norm": 0.9847232699394226,
      "learning_rate": 8.983216922525489e-05,
      "loss": 3.0062,
      "step": 38090
    },
    {
      "epoch": 1.6398381682017733,
      "grad_norm": 0.9654237627983093,
      "learning_rate": 8.978594475414798e-05,
      "loss": 3.0473,
      "step": 38100
    },
    {
      "epoch": 1.6398381682017733,
      "eval_bleu": 27.03269590224328,
      "eval_gen_len": 27.453,
      "eval_loss": 2.7924067974090576,
      "eval_runtime": 58.1736,
      "eval_samples_per_second": 17.19,
      "eval_steps_per_second": 1.083,
      "step": 38100
    },
    {
      "epoch": 1.6402685719204615,
      "grad_norm": 0.9699733257293701,
      "learning_rate": 8.973972248838368e-05,
      "loss": 3.0249,
      "step": 38110
    },
    {
      "epoch": 1.6406989756391495,
      "grad_norm": 0.887482762336731,
      "learning_rate": 8.969350243794198e-05,
      "loss": 3.0544,
      "step": 38120
    },
    {
      "epoch": 1.6411293793578376,
      "grad_norm": 0.8973392248153687,
      "learning_rate": 8.964728461280232e-05,
      "loss": 2.9812,
      "step": 38130
    },
    {
      "epoch": 1.6415597830765258,
      "grad_norm": 0.9699341654777527,
      "learning_rate": 8.960106902294374e-05,
      "loss": 3.0644,
      "step": 38140
    },
    {
      "epoch": 1.6419901867952138,
      "grad_norm": 0.8902912735939026,
      "learning_rate": 8.955485567834474e-05,
      "loss": 3.1649,
      "step": 38150
    },
    {
      "epoch": 1.6419901867952138,
      "eval_bleu": 27.439975669945767,
      "eval_gen_len": 27.514,
      "eval_loss": 2.7922749519348145,
      "eval_runtime": 58.4287,
      "eval_samples_per_second": 17.115,
      "eval_steps_per_second": 1.078,
      "step": 38150
    },
    {
      "epoch": 1.642420590513902,
      "grad_norm": 0.8843240141868591,
      "learning_rate": 8.95086445889834e-05,
      "loss": 2.9569,
      "step": 38160
    },
    {
      "epoch": 1.6428509942325902,
      "grad_norm": 0.9966045022010803,
      "learning_rate": 8.946243576483722e-05,
      "loss": 2.9442,
      "step": 38170
    },
    {
      "epoch": 1.6432813979512781,
      "grad_norm": 0.8738803267478943,
      "learning_rate": 8.941622921588332e-05,
      "loss": 2.952,
      "step": 38180
    },
    {
      "epoch": 1.6437118016699666,
      "grad_norm": 0.8645836710929871,
      "learning_rate": 8.937002495209824e-05,
      "loss": 3.0214,
      "step": 38190
    },
    {
      "epoch": 1.6441422053886545,
      "grad_norm": 0.9736739993095398,
      "learning_rate": 8.93238229834581e-05,
      "loss": 2.8912,
      "step": 38200
    },
    {
      "epoch": 1.6441422053886545,
      "eval_bleu": 27.02708549312449,
      "eval_gen_len": 27.483,
      "eval_loss": 2.795708656311035,
      "eval_runtime": 58.7631,
      "eval_samples_per_second": 17.017,
      "eval_steps_per_second": 1.072,
      "step": 38200
    },
    {
      "epoch": 1.6445726091073427,
      "grad_norm": 0.943228006362915,
      "learning_rate": 8.927762331993841e-05,
      "loss": 2.9487,
      "step": 38210
    },
    {
      "epoch": 1.645003012826031,
      "grad_norm": 0.8640552759170532,
      "learning_rate": 8.923142597151431e-05,
      "loss": 3.0704,
      "step": 38220
    },
    {
      "epoch": 1.6454334165447189,
      "grad_norm": 0.9724634885787964,
      "learning_rate": 8.918523094816038e-05,
      "loss": 2.9655,
      "step": 38230
    },
    {
      "epoch": 1.645863820263407,
      "grad_norm": 0.9200745820999146,
      "learning_rate": 8.913903825985069e-05,
      "loss": 3.1061,
      "step": 38240
    },
    {
      "epoch": 1.6462942239820952,
      "grad_norm": 0.7926322817802429,
      "learning_rate": 8.909284791655886e-05,
      "loss": 3.0283,
      "step": 38250
    },
    {
      "epoch": 1.6462942239820952,
      "eval_bleu": 26.613896985142876,
      "eval_gen_len": 27.492,
      "eval_loss": 2.796314001083374,
      "eval_runtime": 58.1577,
      "eval_samples_per_second": 17.195,
      "eval_steps_per_second": 1.083,
      "step": 38250
    },
    {
      "epoch": 1.6467246277007832,
      "grad_norm": 0.8881471753120422,
      "learning_rate": 8.90466599282579e-05,
      "loss": 3.0295,
      "step": 38260
    },
    {
      "epoch": 1.6471550314194716,
      "grad_norm": 1.0167906284332275,
      "learning_rate": 8.900047430492043e-05,
      "loss": 3.0588,
      "step": 38270
    },
    {
      "epoch": 1.6475854351381596,
      "grad_norm": 0.9945885539054871,
      "learning_rate": 8.895429105651852e-05,
      "loss": 3.0296,
      "step": 38280
    },
    {
      "epoch": 1.6480158388568478,
      "grad_norm": 0.7846221327781677,
      "learning_rate": 8.890811019302365e-05,
      "loss": 2.9948,
      "step": 38290
    },
    {
      "epoch": 1.648446242575536,
      "grad_norm": 0.8997374773025513,
      "learning_rate": 8.886193172440687e-05,
      "loss": 2.9704,
      "step": 38300
    },
    {
      "epoch": 1.648446242575536,
      "eval_bleu": 26.938936133548538,
      "eval_gen_len": 27.476,
      "eval_loss": 2.7946200370788574,
      "eval_runtime": 58.4583,
      "eval_samples_per_second": 17.106,
      "eval_steps_per_second": 1.078,
      "step": 38300
    },
    {
      "epoch": 1.648876646294224,
      "grad_norm": 0.8886262774467468,
      "learning_rate": 8.881575566063869e-05,
      "loss": 2.9357,
      "step": 38310
    },
    {
      "epoch": 1.6493070500129121,
      "grad_norm": 0.9233151078224182,
      "learning_rate": 8.876958201168912e-05,
      "loss": 3.1348,
      "step": 38320
    },
    {
      "epoch": 1.6497374537316003,
      "grad_norm": 0.9286869168281555,
      "learning_rate": 8.872341078752762e-05,
      "loss": 3.0206,
      "step": 38330
    },
    {
      "epoch": 1.6501678574502883,
      "grad_norm": 0.8529872298240662,
      "learning_rate": 8.867724199812314e-05,
      "loss": 2.9705,
      "step": 38340
    },
    {
      "epoch": 1.6505982611689765,
      "grad_norm": 0.8447095155715942,
      "learning_rate": 8.863107565344408e-05,
      "loss": 2.9672,
      "step": 38350
    },
    {
      "epoch": 1.6505982611689765,
      "eval_bleu": 26.974699555916246,
      "eval_gen_len": 27.497,
      "eval_loss": 2.7945220470428467,
      "eval_runtime": 59.0645,
      "eval_samples_per_second": 16.931,
      "eval_steps_per_second": 1.067,
      "step": 38350
    },
    {
      "epoch": 1.6510286648876646,
      "grad_norm": 0.8939136266708374,
      "learning_rate": 8.858491176345837e-05,
      "loss": 3.081,
      "step": 38360
    },
    {
      "epoch": 1.6514590686063526,
      "grad_norm": 0.9653578996658325,
      "learning_rate": 8.853875033813335e-05,
      "loss": 2.9403,
      "step": 38370
    },
    {
      "epoch": 1.651889472325041,
      "grad_norm": 1.024455189704895,
      "learning_rate": 8.849259138743584e-05,
      "loss": 3.0728,
      "step": 38380
    },
    {
      "epoch": 1.652319876043729,
      "grad_norm": 0.943034827709198,
      "learning_rate": 8.844643492133216e-05,
      "loss": 3.0107,
      "step": 38390
    },
    {
      "epoch": 1.6527502797624172,
      "grad_norm": 0.9603413343429565,
      "learning_rate": 8.840028094978805e-05,
      "loss": 3.0534,
      "step": 38400
    },
    {
      "epoch": 1.6527502797624172,
      "eval_bleu": 26.910063745084408,
      "eval_gen_len": 27.425,
      "eval_loss": 2.794433355331421,
      "eval_runtime": 58.4303,
      "eval_samples_per_second": 17.114,
      "eval_steps_per_second": 1.078,
      "step": 38400
    },
    {
      "epoch": 1.6531806834811054,
      "grad_norm": 0.8492188453674316,
      "learning_rate": 8.835412948276872e-05,
      "loss": 2.9535,
      "step": 38410
    },
    {
      "epoch": 1.6536110871997933,
      "grad_norm": 0.8573415279388428,
      "learning_rate": 8.830798053023889e-05,
      "loss": 2.9916,
      "step": 38420
    },
    {
      "epoch": 1.6540414909184815,
      "grad_norm": 0.9133339524269104,
      "learning_rate": 8.826183410216267e-05,
      "loss": 2.9397,
      "step": 38430
    },
    {
      "epoch": 1.6544718946371697,
      "grad_norm": 0.9168775081634521,
      "learning_rate": 8.821569020850365e-05,
      "loss": 3.0475,
      "step": 38440
    },
    {
      "epoch": 1.6549022983558577,
      "grad_norm": 1.0186378955841064,
      "learning_rate": 8.816954885922494e-05,
      "loss": 3.0496,
      "step": 38450
    },
    {
      "epoch": 1.6549022983558577,
      "eval_bleu": 27.2804371981293,
      "eval_gen_len": 27.384,
      "eval_loss": 2.793227195739746,
      "eval_runtime": 58.0404,
      "eval_samples_per_second": 17.229,
      "eval_steps_per_second": 1.085,
      "step": 38450
    },
    {
      "epoch": 1.655332702074546,
      "grad_norm": 0.9971252679824829,
      "learning_rate": 8.812341006428893e-05,
      "loss": 3.0228,
      "step": 38460
    },
    {
      "epoch": 1.655763105793234,
      "grad_norm": 0.8844805359840393,
      "learning_rate": 8.807727383365762e-05,
      "loss": 2.8396,
      "step": 38470
    },
    {
      "epoch": 1.6561935095119222,
      "grad_norm": 0.8390858173370361,
      "learning_rate": 8.803114017729239e-05,
      "loss": 2.9679,
      "step": 38480
    },
    {
      "epoch": 1.6566239132306104,
      "grad_norm": 0.9190487861633301,
      "learning_rate": 8.798500910515408e-05,
      "loss": 2.9903,
      "step": 38490
    },
    {
      "epoch": 1.6570543169492984,
      "grad_norm": 0.8573164939880371,
      "learning_rate": 8.793888062720298e-05,
      "loss": 2.9913,
      "step": 38500
    },
    {
      "epoch": 1.6570543169492984,
      "eval_bleu": 27.15297448656856,
      "eval_gen_len": 27.57,
      "eval_loss": 2.793694257736206,
      "eval_runtime": 58.6828,
      "eval_samples_per_second": 17.041,
      "eval_steps_per_second": 1.074,
      "step": 38500
    },
    {
      "epoch": 1.6574847206679866,
      "grad_norm": 0.9581708908081055,
      "learning_rate": 8.789275475339878e-05,
      "loss": 3.0251,
      "step": 38510
    },
    {
      "epoch": 1.6579151243866748,
      "grad_norm": 0.8939084410667419,
      "learning_rate": 8.784663149370066e-05,
      "loss": 3.0186,
      "step": 38520
    },
    {
      "epoch": 1.6583455281053627,
      "grad_norm": 0.9171424508094788,
      "learning_rate": 8.780051085806724e-05,
      "loss": 3.003,
      "step": 38530
    },
    {
      "epoch": 1.658775931824051,
      "grad_norm": 0.9077587127685547,
      "learning_rate": 8.775439285645646e-05,
      "loss": 2.9929,
      "step": 38540
    },
    {
      "epoch": 1.659206335542739,
      "grad_norm": 0.9194114804267883,
      "learning_rate": 8.770827749882582e-05,
      "loss": 3.0007,
      "step": 38550
    },
    {
      "epoch": 1.659206335542739,
      "eval_bleu": 26.7876966496229,
      "eval_gen_len": 27.523,
      "eval_loss": 2.794874906539917,
      "eval_runtime": 58.6757,
      "eval_samples_per_second": 17.043,
      "eval_steps_per_second": 1.074,
      "step": 38550
    },
    {
      "epoch": 1.659636739261427,
      "grad_norm": 0.8204412460327148,
      "learning_rate": 8.766216479513217e-05,
      "loss": 3.0011,
      "step": 38560
    },
    {
      "epoch": 1.6600671429801155,
      "grad_norm": 0.8866704106330872,
      "learning_rate": 8.761605475533188e-05,
      "loss": 3.0281,
      "step": 38570
    },
    {
      "epoch": 1.6604975466988035,
      "grad_norm": 0.9419633746147156,
      "learning_rate": 8.756994738938066e-05,
      "loss": 2.9804,
      "step": 38580
    },
    {
      "epoch": 1.6609279504174916,
      "grad_norm": 0.9359315037727356,
      "learning_rate": 8.752384270723367e-05,
      "loss": 2.994,
      "step": 38590
    },
    {
      "epoch": 1.6613583541361798,
      "grad_norm": 0.9192055463790894,
      "learning_rate": 8.747774071884548e-05,
      "loss": 3.054,
      "step": 38600
    },
    {
      "epoch": 1.6613583541361798,
      "eval_bleu": 27.33430077619784,
      "eval_gen_len": 27.518,
      "eval_loss": 2.792858362197876,
      "eval_runtime": 58.7032,
      "eval_samples_per_second": 17.035,
      "eval_steps_per_second": 1.073,
      "step": 38600
    },
    {
      "epoch": 1.6617887578548678,
      "grad_norm": 0.8560366630554199,
      "learning_rate": 8.743164143417013e-05,
      "loss": 2.9545,
      "step": 38610
    },
    {
      "epoch": 1.662219161573556,
      "grad_norm": 0.8564701080322266,
      "learning_rate": 8.738554486316096e-05,
      "loss": 2.9637,
      "step": 38620
    },
    {
      "epoch": 1.6626495652922442,
      "grad_norm": 0.902252733707428,
      "learning_rate": 8.733945101577083e-05,
      "loss": 2.9923,
      "step": 38630
    },
    {
      "epoch": 1.6630799690109321,
      "grad_norm": 0.9435168504714966,
      "learning_rate": 8.7293359901952e-05,
      "loss": 3.0715,
      "step": 38640
    },
    {
      "epoch": 1.6635103727296205,
      "grad_norm": 1.012237787246704,
      "learning_rate": 8.72472715316561e-05,
      "loss": 3.0323,
      "step": 38650
    },
    {
      "epoch": 1.6635103727296205,
      "eval_bleu": 27.079556709708367,
      "eval_gen_len": 27.501,
      "eval_loss": 2.792279005050659,
      "eval_runtime": 58.7442,
      "eval_samples_per_second": 17.023,
      "eval_steps_per_second": 1.072,
      "step": 38650
    },
    {
      "epoch": 1.6639407764483085,
      "grad_norm": 0.9585018157958984,
      "learning_rate": 8.720118591483415e-05,
      "loss": 2.9912,
      "step": 38660
    },
    {
      "epoch": 1.6643711801669965,
      "grad_norm": 0.9116638898849487,
      "learning_rate": 8.715510306143668e-05,
      "loss": 2.9785,
      "step": 38670
    },
    {
      "epoch": 1.6648015838856849,
      "grad_norm": 0.9311240911483765,
      "learning_rate": 8.710902298141355e-05,
      "loss": 3.0168,
      "step": 38680
    },
    {
      "epoch": 1.6652319876043729,
      "grad_norm": 0.9005192518234253,
      "learning_rate": 8.706294568471402e-05,
      "loss": 2.9942,
      "step": 38690
    },
    {
      "epoch": 1.665662391323061,
      "grad_norm": 0.8080845475196838,
      "learning_rate": 8.701687118128672e-05,
      "loss": 3.0889,
      "step": 38700
    },
    {
      "epoch": 1.665662391323061,
      "eval_bleu": 26.78761012372461,
      "eval_gen_len": 27.565,
      "eval_loss": 2.7937467098236084,
      "eval_runtime": 58.8923,
      "eval_samples_per_second": 16.98,
      "eval_steps_per_second": 1.07,
      "step": 38700
    },
    {
      "epoch": 1.6660927950417492,
      "grad_norm": 0.9385150074958801,
      "learning_rate": 8.697079948107973e-05,
      "loss": 2.9496,
      "step": 38710
    },
    {
      "epoch": 1.6665231987604372,
      "grad_norm": 0.7561281323432922,
      "learning_rate": 8.692473059404052e-05,
      "loss": 2.9095,
      "step": 38720
    },
    {
      "epoch": 1.6669536024791254,
      "grad_norm": 1.020294427871704,
      "learning_rate": 8.687866453011592e-05,
      "loss": 2.9988,
      "step": 38730
    },
    {
      "epoch": 1.6673840061978136,
      "grad_norm": 0.8254854679107666,
      "learning_rate": 8.68326012992522e-05,
      "loss": 2.939,
      "step": 38740
    },
    {
      "epoch": 1.6678144099165015,
      "grad_norm": 0.8704733848571777,
      "learning_rate": 8.678654091139496e-05,
      "loss": 2.9797,
      "step": 38750
    },
    {
      "epoch": 1.6678144099165015,
      "eval_bleu": 26.577486237563328,
      "eval_gen_len": 27.402,
      "eval_loss": 2.7940680980682373,
      "eval_runtime": 58.289,
      "eval_samples_per_second": 17.156,
      "eval_steps_per_second": 1.081,
      "step": 38750
    },
    {
      "epoch": 1.66824481363519,
      "grad_norm": 0.8605266213417053,
      "learning_rate": 8.67404833764892e-05,
      "loss": 3.0389,
      "step": 38760
    },
    {
      "epoch": 1.668675217353878,
      "grad_norm": 0.9892756938934326,
      "learning_rate": 8.669442870447942e-05,
      "loss": 2.957,
      "step": 38770
    },
    {
      "epoch": 1.669105621072566,
      "grad_norm": 0.9458538889884949,
      "learning_rate": 8.664837690530929e-05,
      "loss": 2.97,
      "step": 38780
    },
    {
      "epoch": 1.6695360247912543,
      "grad_norm": 1.035994529724121,
      "learning_rate": 8.6602327988922e-05,
      "loss": 2.999,
      "step": 38790
    },
    {
      "epoch": 1.6699664285099423,
      "grad_norm": 0.9246497750282288,
      "learning_rate": 8.655628196526012e-05,
      "loss": 3.0998,
      "step": 38800
    },
    {
      "epoch": 1.6699664285099423,
      "eval_bleu": 27.089674998744094,
      "eval_gen_len": 27.569,
      "eval_loss": 2.7924742698669434,
      "eval_runtime": 58.6749,
      "eval_samples_per_second": 17.043,
      "eval_steps_per_second": 1.074,
      "step": 38800
    },
    {
      "epoch": 1.6703968322286304,
      "grad_norm": 0.8657500743865967,
      "learning_rate": 8.651023884426553e-05,
      "loss": 2.9111,
      "step": 38810
    },
    {
      "epoch": 1.6708272359473186,
      "grad_norm": 0.8844425678253174,
      "learning_rate": 8.646419863587953e-05,
      "loss": 3.0651,
      "step": 38820
    },
    {
      "epoch": 1.6712576396660066,
      "grad_norm": 0.9255743622779846,
      "learning_rate": 8.641816135004278e-05,
      "loss": 3.0875,
      "step": 38830
    },
    {
      "epoch": 1.6716880433846948,
      "grad_norm": 0.9573997855186462,
      "learning_rate": 8.63721269966953e-05,
      "loss": 3.0664,
      "step": 38840
    },
    {
      "epoch": 1.672118447103383,
      "grad_norm": 0.9096348881721497,
      "learning_rate": 8.632609558577652e-05,
      "loss": 3.0738,
      "step": 38850
    },
    {
      "epoch": 1.672118447103383,
      "eval_bleu": 27.350478366460575,
      "eval_gen_len": 27.444,
      "eval_loss": 2.790395975112915,
      "eval_runtime": 58.1124,
      "eval_samples_per_second": 17.208,
      "eval_steps_per_second": 1.084,
      "step": 38850
    },
    {
      "epoch": 1.672548850822071,
      "grad_norm": 0.8559126853942871,
      "learning_rate": 8.628006712722515e-05,
      "loss": 3.0001,
      "step": 38860
    },
    {
      "epoch": 1.6729792545407594,
      "grad_norm": 0.9561514258384705,
      "learning_rate": 8.623404163097932e-05,
      "loss": 2.9662,
      "step": 38870
    },
    {
      "epoch": 1.6734096582594473,
      "grad_norm": 0.9380283951759338,
      "learning_rate": 8.618801910697652e-05,
      "loss": 3.0076,
      "step": 38880
    },
    {
      "epoch": 1.6738400619781355,
      "grad_norm": 0.8766956329345703,
      "learning_rate": 8.61419995651536e-05,
      "loss": 2.9801,
      "step": 38890
    },
    {
      "epoch": 1.6742704656968237,
      "grad_norm": 0.863375723361969,
      "learning_rate": 8.609598301544675e-05,
      "loss": 2.9812,
      "step": 38900
    },
    {
      "epoch": 1.6742704656968237,
      "eval_bleu": 26.97270974368155,
      "eval_gen_len": 27.506,
      "eval_loss": 2.793569803237915,
      "eval_runtime": 58.6251,
      "eval_samples_per_second": 17.058,
      "eval_steps_per_second": 1.075,
      "step": 38900
    },
    {
      "epoch": 1.6747008694155117,
      "grad_norm": 0.995894193649292,
      "learning_rate": 8.60499694677915e-05,
      "loss": 3.0823,
      "step": 38910
    },
    {
      "epoch": 1.6751312731341998,
      "grad_norm": 0.9239029884338379,
      "learning_rate": 8.600395893212279e-05,
      "loss": 3.0207,
      "step": 38920
    },
    {
      "epoch": 1.675561676852888,
      "grad_norm": 1.057134985923767,
      "learning_rate": 8.595795141837486e-05,
      "loss": 2.9892,
      "step": 38930
    },
    {
      "epoch": 1.675992080571576,
      "grad_norm": 0.8294814825057983,
      "learning_rate": 8.591194693648128e-05,
      "loss": 3.0423,
      "step": 38940
    },
    {
      "epoch": 1.6764224842902644,
      "grad_norm": 0.9361960887908936,
      "learning_rate": 8.586594549637502e-05,
      "loss": 3.081,
      "step": 38950
    },
    {
      "epoch": 1.6764224842902644,
      "eval_bleu": 26.78413692758841,
      "eval_gen_len": 27.621,
      "eval_loss": 2.7938244342803955,
      "eval_runtime": 60.8394,
      "eval_samples_per_second": 16.437,
      "eval_steps_per_second": 1.036,
      "step": 38950
    },
    {
      "epoch": 1.6768528880089524,
      "grad_norm": 0.8821694850921631,
      "learning_rate": 8.581994710798836e-05,
      "loss": 2.9975,
      "step": 38960
    },
    {
      "epoch": 1.6772832917276406,
      "grad_norm": 0.9773168563842773,
      "learning_rate": 8.577395178125294e-05,
      "loss": 2.9961,
      "step": 38970
    },
    {
      "epoch": 1.6777136954463288,
      "grad_norm": 0.8381386399269104,
      "learning_rate": 8.572795952609972e-05,
      "loss": 2.9496,
      "step": 38980
    },
    {
      "epoch": 1.6781440991650167,
      "grad_norm": 0.8763985633850098,
      "learning_rate": 8.568197035245898e-05,
      "loss": 2.9724,
      "step": 38990
    },
    {
      "epoch": 1.678574502883705,
      "grad_norm": 0.8805927038192749,
      "learning_rate": 8.56359842702604e-05,
      "loss": 2.8125,
      "step": 39000
    },
    {
      "epoch": 1.678574502883705,
      "eval_bleu": 26.907833659842144,
      "eval_gen_len": 27.413,
      "eval_loss": 2.7910265922546387,
      "eval_runtime": 58.8094,
      "eval_samples_per_second": 17.004,
      "eval_steps_per_second": 1.071,
      "step": 39000
    },
    {
      "epoch": 1.679004906602393,
      "grad_norm": 0.852670431137085,
      "learning_rate": 8.559000128943294e-05,
      "loss": 3.0317,
      "step": 39010
    },
    {
      "epoch": 1.679435310321081,
      "grad_norm": 0.9319770336151123,
      "learning_rate": 8.554402141990492e-05,
      "loss": 3.091,
      "step": 39020
    },
    {
      "epoch": 1.6798657140397693,
      "grad_norm": 0.9821227192878723,
      "learning_rate": 8.549804467160391e-05,
      "loss": 3.0472,
      "step": 39030
    },
    {
      "epoch": 1.6802961177584574,
      "grad_norm": 0.841502845287323,
      "learning_rate": 8.545207105445692e-05,
      "loss": 3.0394,
      "step": 39040
    },
    {
      "epoch": 1.6807265214771454,
      "grad_norm": 0.9826511144638062,
      "learning_rate": 8.540610057839021e-05,
      "loss": 3.0841,
      "step": 39050
    },
    {
      "epoch": 1.6807265214771454,
      "eval_bleu": 27.04366883474294,
      "eval_gen_len": 27.508,
      "eval_loss": 2.794375419616699,
      "eval_runtime": 58.896,
      "eval_samples_per_second": 16.979,
      "eval_steps_per_second": 1.07,
      "step": 39050
    },
    {
      "epoch": 1.6811569251958338,
      "grad_norm": 0.8702561855316162,
      "learning_rate": 8.536013325332939e-05,
      "loss": 3.0279,
      "step": 39060
    },
    {
      "epoch": 1.6815873289145218,
      "grad_norm": 0.9315512776374817,
      "learning_rate": 8.531416908919936e-05,
      "loss": 2.9912,
      "step": 39070
    },
    {
      "epoch": 1.68201773263321,
      "grad_norm": 0.9487889409065247,
      "learning_rate": 8.52682080959244e-05,
      "loss": 3.0239,
      "step": 39080
    },
    {
      "epoch": 1.6824481363518982,
      "grad_norm": 0.913292407989502,
      "learning_rate": 8.522225028342803e-05,
      "loss": 3.0157,
      "step": 39090
    },
    {
      "epoch": 1.6828785400705861,
      "grad_norm": 0.9309475421905518,
      "learning_rate": 8.517629566163317e-05,
      "loss": 3.0334,
      "step": 39100
    },
    {
      "epoch": 1.6828785400705861,
      "eval_bleu": 27.22488293807112,
      "eval_gen_len": 27.478,
      "eval_loss": 2.7933497428894043,
      "eval_runtime": 58.8433,
      "eval_samples_per_second": 16.994,
      "eval_steps_per_second": 1.071,
      "step": 39100
    },
    {
      "epoch": 1.6833089437892743,
      "grad_norm": 0.9112812876701355,
      "learning_rate": 8.513034424046193e-05,
      "loss": 2.9772,
      "step": 39110
    },
    {
      "epoch": 1.6837393475079625,
      "grad_norm": 0.8574956059455872,
      "learning_rate": 8.508439602983582e-05,
      "loss": 2.9318,
      "step": 39120
    },
    {
      "epoch": 1.6841697512266505,
      "grad_norm": 1.0239287614822388,
      "learning_rate": 8.503845103967566e-05,
      "loss": 3.0642,
      "step": 39130
    },
    {
      "epoch": 1.6846001549453389,
      "grad_norm": 0.9254935383796692,
      "learning_rate": 8.499250927990151e-05,
      "loss": 3.0018,
      "step": 39140
    },
    {
      "epoch": 1.6850305586640268,
      "grad_norm": 0.9622607827186584,
      "learning_rate": 8.494657076043281e-05,
      "loss": 3.0441,
      "step": 39150
    },
    {
      "epoch": 1.6850305586640268,
      "eval_bleu": 26.954090602126932,
      "eval_gen_len": 27.533,
      "eval_loss": 2.792952060699463,
      "eval_runtime": 58.8151,
      "eval_samples_per_second": 17.002,
      "eval_steps_per_second": 1.071,
      "step": 39150
    },
    {
      "epoch": 1.685460962382715,
      "grad_norm": 0.9574269652366638,
      "learning_rate": 8.490063549118824e-05,
      "loss": 3.0047,
      "step": 39160
    },
    {
      "epoch": 1.6858913661014032,
      "grad_norm": 0.9710279703140259,
      "learning_rate": 8.485470348208581e-05,
      "loss": 2.9017,
      "step": 39170
    },
    {
      "epoch": 1.6863217698200912,
      "grad_norm": 0.964347243309021,
      "learning_rate": 8.480877474304286e-05,
      "loss": 3.0389,
      "step": 39180
    },
    {
      "epoch": 1.6867521735387794,
      "grad_norm": 0.9045149683952332,
      "learning_rate": 8.476284928397587e-05,
      "loss": 3.0707,
      "step": 39190
    },
    {
      "epoch": 1.6871825772574676,
      "grad_norm": 0.8033669590950012,
      "learning_rate": 8.47169271148008e-05,
      "loss": 3.0609,
      "step": 39200
    },
    {
      "epoch": 1.6871825772574676,
      "eval_bleu": 27.231842071308822,
      "eval_gen_len": 27.52,
      "eval_loss": 2.793181896209717,
      "eval_runtime": 58.5021,
      "eval_samples_per_second": 17.093,
      "eval_steps_per_second": 1.077,
      "step": 39200
    },
    {
      "epoch": 1.6876129809761555,
      "grad_norm": 0.7916748523712158,
      "learning_rate": 8.467100824543282e-05,
      "loss": 2.9744,
      "step": 39210
    },
    {
      "epoch": 1.6880433846948437,
      "grad_norm": 0.9549082517623901,
      "learning_rate": 8.462509268578638e-05,
      "loss": 2.9441,
      "step": 39220
    },
    {
      "epoch": 1.688473788413532,
      "grad_norm": 0.9188190698623657,
      "learning_rate": 8.457918044577522e-05,
      "loss": 2.9622,
      "step": 39230
    },
    {
      "epoch": 1.6889041921322199,
      "grad_norm": 0.8019591569900513,
      "learning_rate": 8.453327153531238e-05,
      "loss": 2.9865,
      "step": 39240
    },
    {
      "epoch": 1.6893345958509083,
      "grad_norm": 0.9070681929588318,
      "learning_rate": 8.448736596431015e-05,
      "loss": 3.0793,
      "step": 39250
    },
    {
      "epoch": 1.6893345958509083,
      "eval_bleu": 26.844217554061633,
      "eval_gen_len": 27.388,
      "eval_loss": 2.7930476665496826,
      "eval_runtime": 57.5714,
      "eval_samples_per_second": 17.37,
      "eval_steps_per_second": 1.094,
      "step": 39250
    },
    {
      "epoch": 1.6897649995695962,
      "grad_norm": 0.8403677940368652,
      "learning_rate": 8.444146374268019e-05,
      "loss": 2.9741,
      "step": 39260
    },
    {
      "epoch": 1.6901954032882844,
      "grad_norm": 0.9354678988456726,
      "learning_rate": 8.439556488033324e-05,
      "loss": 3.1321,
      "step": 39270
    },
    {
      "epoch": 1.6906258070069726,
      "grad_norm": 0.8277170062065125,
      "learning_rate": 8.434966938717952e-05,
      "loss": 2.9424,
      "step": 39280
    },
    {
      "epoch": 1.6910562107256606,
      "grad_norm": 0.8938975930213928,
      "learning_rate": 8.43037772731284e-05,
      "loss": 3.08,
      "step": 39290
    },
    {
      "epoch": 1.6914866144443488,
      "grad_norm": 0.9017519354820251,
      "learning_rate": 8.425788854808863e-05,
      "loss": 2.9293,
      "step": 39300
    },
    {
      "epoch": 1.6914866144443488,
      "eval_bleu": 26.94202565166225,
      "eval_gen_len": 27.485,
      "eval_loss": 2.7941110134124756,
      "eval_runtime": 58.3391,
      "eval_samples_per_second": 17.141,
      "eval_steps_per_second": 1.08,
      "step": 39300
    },
    {
      "epoch": 1.691917018163037,
      "grad_norm": 0.8910169005393982,
      "learning_rate": 8.42120032219681e-05,
      "loss": 2.9793,
      "step": 39310
    },
    {
      "epoch": 1.692347421881725,
      "grad_norm": 0.9001073241233826,
      "learning_rate": 8.416612130467406e-05,
      "loss": 3.0777,
      "step": 39320
    },
    {
      "epoch": 1.6927778256004133,
      "grad_norm": 0.9808313846588135,
      "learning_rate": 8.412024280611299e-05,
      "loss": 3.0436,
      "step": 39330
    },
    {
      "epoch": 1.6932082293191013,
      "grad_norm": 0.8515572547912598,
      "learning_rate": 8.407436773619066e-05,
      "loss": 3.0446,
      "step": 39340
    },
    {
      "epoch": 1.6936386330377895,
      "grad_norm": 0.9492397308349609,
      "learning_rate": 8.402849610481198e-05,
      "loss": 3.0295,
      "step": 39350
    },
    {
      "epoch": 1.6936386330377895,
      "eval_bleu": 27.01251342515948,
      "eval_gen_len": 27.545,
      "eval_loss": 2.796855926513672,
      "eval_runtime": 58.4845,
      "eval_samples_per_second": 17.099,
      "eval_steps_per_second": 1.077,
      "step": 39350
    },
    {
      "epoch": 1.6940690367564777,
      "grad_norm": 0.928286612033844,
      "learning_rate": 8.398262792188129e-05,
      "loss": 2.9966,
      "step": 39360
    },
    {
      "epoch": 1.6944994404751657,
      "grad_norm": 0.8519244194030762,
      "learning_rate": 8.393676319730207e-05,
      "loss": 2.9773,
      "step": 39370
    },
    {
      "epoch": 1.6949298441938538,
      "grad_norm": 0.7702935338020325,
      "learning_rate": 8.38909019409771e-05,
      "loss": 2.9793,
      "step": 39380
    },
    {
      "epoch": 1.695360247912542,
      "grad_norm": 0.9075556397438049,
      "learning_rate": 8.38450441628084e-05,
      "loss": 3.0787,
      "step": 39390
    },
    {
      "epoch": 1.69579065163123,
      "grad_norm": 0.8813928961753845,
      "learning_rate": 8.379918987269724e-05,
      "loss": 2.951,
      "step": 39400
    },
    {
      "epoch": 1.69579065163123,
      "eval_bleu": 27.064158056316554,
      "eval_gen_len": 27.547,
      "eval_loss": 2.7928481101989746,
      "eval_runtime": 58.4391,
      "eval_samples_per_second": 17.112,
      "eval_steps_per_second": 1.078,
      "step": 39400
    },
    {
      "epoch": 1.6962210553499182,
      "grad_norm": 0.8800502419471741,
      "learning_rate": 8.375333908054414e-05,
      "loss": 2.9562,
      "step": 39410
    },
    {
      "epoch": 1.6966514590686064,
      "grad_norm": 0.9296645522117615,
      "learning_rate": 8.370749179624891e-05,
      "loss": 2.9381,
      "step": 39420
    },
    {
      "epoch": 1.6970818627872943,
      "grad_norm": 0.8698021173477173,
      "learning_rate": 8.366164802971047e-05,
      "loss": 2.9769,
      "step": 39430
    },
    {
      "epoch": 1.6975122665059827,
      "grad_norm": 0.8396966457366943,
      "learning_rate": 8.361580779082709e-05,
      "loss": 2.9308,
      "step": 39440
    },
    {
      "epoch": 1.6979426702246707,
      "grad_norm": 0.835221529006958,
      "learning_rate": 8.356997108949625e-05,
      "loss": 2.9717,
      "step": 39450
    },
    {
      "epoch": 1.6979426702246707,
      "eval_bleu": 27.060228246669116,
      "eval_gen_len": 27.377,
      "eval_loss": 2.7908692359924316,
      "eval_runtime": 57.9997,
      "eval_samples_per_second": 17.241,
      "eval_steps_per_second": 1.086,
      "step": 39450
    },
    {
      "epoch": 1.698373073943359,
      "grad_norm": 0.9716796278953552,
      "learning_rate": 8.35241379356147e-05,
      "loss": 2.9572,
      "step": 39460
    },
    {
      "epoch": 1.698803477662047,
      "grad_norm": 0.992746889591217,
      "learning_rate": 8.347830833907835e-05,
      "loss": 3.0958,
      "step": 39470
    },
    {
      "epoch": 1.699233881380735,
      "grad_norm": 0.9057164788246155,
      "learning_rate": 8.34324823097824e-05,
      "loss": 2.9261,
      "step": 39480
    },
    {
      "epoch": 1.6996642850994232,
      "grad_norm": 1.0126110315322876,
      "learning_rate": 8.338665985762128e-05,
      "loss": 2.9989,
      "step": 39490
    },
    {
      "epoch": 1.7000946888181114,
      "grad_norm": 0.886947512626648,
      "learning_rate": 8.334084099248865e-05,
      "loss": 2.9127,
      "step": 39500
    },
    {
      "epoch": 1.7000946888181114,
      "eval_bleu": 27.30759159559621,
      "eval_gen_len": 27.531,
      "eval_loss": 2.7906441688537598,
      "eval_runtime": 58.5502,
      "eval_samples_per_second": 17.079,
      "eval_steps_per_second": 1.076,
      "step": 39500
    },
    {
      "epoch": 1.7005250925367994,
      "grad_norm": 1.030900001525879,
      "learning_rate": 8.329502572427732e-05,
      "loss": 3.0751,
      "step": 39510
    },
    {
      "epoch": 1.7009554962554878,
      "grad_norm": 0.9230133891105652,
      "learning_rate": 8.324921406287942e-05,
      "loss": 3.0221,
      "step": 39520
    },
    {
      "epoch": 1.7013858999741758,
      "grad_norm": 0.8312470316886902,
      "learning_rate": 8.320340601818623e-05,
      "loss": 3.0105,
      "step": 39530
    },
    {
      "epoch": 1.7018163036928637,
      "grad_norm": 1.0343992710113525,
      "learning_rate": 8.315760160008833e-05,
      "loss": 2.9872,
      "step": 39540
    },
    {
      "epoch": 1.7022467074115522,
      "grad_norm": 0.9462260007858276,
      "learning_rate": 8.311180081847541e-05,
      "loss": 3.0344,
      "step": 39550
    },
    {
      "epoch": 1.7022467074115522,
      "eval_bleu": 26.875946790355158,
      "eval_gen_len": 27.561,
      "eval_loss": 2.7945609092712402,
      "eval_runtime": 59.3534,
      "eval_samples_per_second": 16.848,
      "eval_steps_per_second": 1.061,
      "step": 39550
    },
    {
      "epoch": 1.7026771111302401,
      "grad_norm": 0.9154779314994812,
      "learning_rate": 8.306600368323648e-05,
      "loss": 3.0853,
      "step": 39560
    },
    {
      "epoch": 1.7031075148489283,
      "grad_norm": 0.8502573370933533,
      "learning_rate": 8.302021020425971e-05,
      "loss": 3.037,
      "step": 39570
    },
    {
      "epoch": 1.7035379185676165,
      "grad_norm": 0.8256665468215942,
      "learning_rate": 8.297442039143249e-05,
      "loss": 3.0142,
      "step": 39580
    },
    {
      "epoch": 1.7039683222863045,
      "grad_norm": 0.9278237223625183,
      "learning_rate": 8.292863425464138e-05,
      "loss": 2.953,
      "step": 39590
    },
    {
      "epoch": 1.7043987260049926,
      "grad_norm": 1.1080968379974365,
      "learning_rate": 8.28828518037722e-05,
      "loss": 3.0191,
      "step": 39600
    },
    {
      "epoch": 1.7043987260049926,
      "eval_bleu": 27.24593391416123,
      "eval_gen_len": 27.486,
      "eval_loss": 2.7939796447753906,
      "eval_runtime": 58.6125,
      "eval_samples_per_second": 17.061,
      "eval_steps_per_second": 1.075,
      "step": 39600
    },
    {
      "epoch": 1.7048291297236808,
      "grad_norm": 0.8475717306137085,
      "learning_rate": 8.283707304870996e-05,
      "loss": 3.0534,
      "step": 39610
    },
    {
      "epoch": 1.7052595334423688,
      "grad_norm": 0.8980578184127808,
      "learning_rate": 8.279129799933887e-05,
      "loss": 2.9896,
      "step": 39620
    },
    {
      "epoch": 1.7056899371610572,
      "grad_norm": 0.889714241027832,
      "learning_rate": 8.274552666554234e-05,
      "loss": 3.0175,
      "step": 39630
    },
    {
      "epoch": 1.7061203408797452,
      "grad_norm": 0.860345184803009,
      "learning_rate": 8.269975905720296e-05,
      "loss": 2.995,
      "step": 39640
    },
    {
      "epoch": 1.7065507445984334,
      "grad_norm": 0.8845494389533997,
      "learning_rate": 8.265399518420253e-05,
      "loss": 3.0531,
      "step": 39650
    },
    {
      "epoch": 1.7065507445984334,
      "eval_bleu": 27.588790386958227,
      "eval_gen_len": 27.539,
      "eval_loss": 2.789738893508911,
      "eval_runtime": 59.1253,
      "eval_samples_per_second": 16.913,
      "eval_steps_per_second": 1.066,
      "step": 39650
    },
    {
      "epoch": 1.7069811483171216,
      "grad_norm": 0.7965278029441833,
      "learning_rate": 8.260823505642206e-05,
      "loss": 3.0151,
      "step": 39660
    },
    {
      "epoch": 1.7074115520358095,
      "grad_norm": 0.8111923933029175,
      "learning_rate": 8.256247868374173e-05,
      "loss": 3.0648,
      "step": 39670
    },
    {
      "epoch": 1.7078419557544977,
      "grad_norm": 1.0543651580810547,
      "learning_rate": 8.25167260760409e-05,
      "loss": 3.0569,
      "step": 39680
    },
    {
      "epoch": 1.708272359473186,
      "grad_norm": 0.944213330745697,
      "learning_rate": 8.247097724319816e-05,
      "loss": 2.9211,
      "step": 39690
    },
    {
      "epoch": 1.7087027631918739,
      "grad_norm": 0.9959298372268677,
      "learning_rate": 8.242523219509122e-05,
      "loss": 3.0694,
      "step": 39700
    },
    {
      "epoch": 1.7087027631918739,
      "eval_bleu": 27.68580691426772,
      "eval_gen_len": 27.44,
      "eval_loss": 2.7888023853302,
      "eval_runtime": 58.1606,
      "eval_samples_per_second": 17.194,
      "eval_steps_per_second": 1.083,
      "step": 39700
    },
    {
      "epoch": 1.7091331669105623,
      "grad_norm": 0.9235249757766724,
      "learning_rate": 8.237949094159705e-05,
      "loss": 2.9765,
      "step": 39710
    },
    {
      "epoch": 1.7095635706292502,
      "grad_norm": 0.9030215740203857,
      "learning_rate": 8.233375349259172e-05,
      "loss": 3.0647,
      "step": 39720
    },
    {
      "epoch": 1.7099939743479382,
      "grad_norm": 0.8751258254051208,
      "learning_rate": 8.228801985795057e-05,
      "loss": 3.08,
      "step": 39730
    },
    {
      "epoch": 1.7104243780666266,
      "grad_norm": 0.9388160109519958,
      "learning_rate": 8.2242290047548e-05,
      "loss": 3.0558,
      "step": 39740
    },
    {
      "epoch": 1.7108547817853146,
      "grad_norm": 0.8917585611343384,
      "learning_rate": 8.21965640712577e-05,
      "loss": 3.1062,
      "step": 39750
    },
    {
      "epoch": 1.7108547817853146,
      "eval_bleu": 27.262637562876343,
      "eval_gen_len": 27.444,
      "eval_loss": 2.79135799407959,
      "eval_runtime": 58.5131,
      "eval_samples_per_second": 17.09,
      "eval_steps_per_second": 1.077,
      "step": 39750
    },
    {
      "epoch": 1.7112851855040028,
      "grad_norm": 0.9178879261016846,
      "learning_rate": 8.215084193895248e-05,
      "loss": 2.9943,
      "step": 39760
    },
    {
      "epoch": 1.711715589222691,
      "grad_norm": 1.035420536994934,
      "learning_rate": 8.21051236605043e-05,
      "loss": 3.04,
      "step": 39770
    },
    {
      "epoch": 1.712145992941379,
      "grad_norm": 0.931664228439331,
      "learning_rate": 8.20594092457843e-05,
      "loss": 3.013,
      "step": 39780
    },
    {
      "epoch": 1.7125763966600671,
      "grad_norm": 0.8811579942703247,
      "learning_rate": 8.20136987046628e-05,
      "loss": 3.0756,
      "step": 39790
    },
    {
      "epoch": 1.7130068003787553,
      "grad_norm": 0.8954212665557861,
      "learning_rate": 8.196799204700932e-05,
      "loss": 3.059,
      "step": 39800
    },
    {
      "epoch": 1.7130068003787553,
      "eval_bleu": 27.446898312094234,
      "eval_gen_len": 27.519,
      "eval_loss": 2.7924344539642334,
      "eval_runtime": 58.6057,
      "eval_samples_per_second": 17.063,
      "eval_steps_per_second": 1.075,
      "step": 39800
    },
    {
      "epoch": 1.7134372040974433,
      "grad_norm": 0.971052348613739,
      "learning_rate": 8.192228928269245e-05,
      "loss": 2.9915,
      "step": 39810
    },
    {
      "epoch": 1.7138676078161317,
      "grad_norm": 0.8754108548164368,
      "learning_rate": 8.187659042158002e-05,
      "loss": 3.0013,
      "step": 39820
    },
    {
      "epoch": 1.7142980115348196,
      "grad_norm": 0.8288225531578064,
      "learning_rate": 8.1830895473539e-05,
      "loss": 2.991,
      "step": 39830
    },
    {
      "epoch": 1.7147284152535078,
      "grad_norm": 0.8838769197463989,
      "learning_rate": 8.178520444843545e-05,
      "loss": 3.0734,
      "step": 39840
    },
    {
      "epoch": 1.715158818972196,
      "grad_norm": 0.791283130645752,
      "learning_rate": 8.173951735613467e-05,
      "loss": 2.9419,
      "step": 39850
    },
    {
      "epoch": 1.715158818972196,
      "eval_bleu": 27.190077349650682,
      "eval_gen_len": 27.502,
      "eval_loss": 2.7917227745056152,
      "eval_runtime": 58.2958,
      "eval_samples_per_second": 17.154,
      "eval_steps_per_second": 1.081,
      "step": 39850
    },
    {
      "epoch": 1.715589222690884,
      "grad_norm": 0.9166673421859741,
      "learning_rate": 8.169383420650108e-05,
      "loss": 3.0928,
      "step": 39860
    },
    {
      "epoch": 1.7160196264095722,
      "grad_norm": 0.931338369846344,
      "learning_rate": 8.164815500939824e-05,
      "loss": 2.9848,
      "step": 39870
    },
    {
      "epoch": 1.7164500301282604,
      "grad_norm": 0.9729681015014648,
      "learning_rate": 8.160247977468886e-05,
      "loss": 3.0021,
      "step": 39880
    },
    {
      "epoch": 1.7168804338469483,
      "grad_norm": 0.8534730672836304,
      "learning_rate": 8.155680851223477e-05,
      "loss": 2.8683,
      "step": 39890
    },
    {
      "epoch": 1.7173108375656365,
      "grad_norm": 0.8622381687164307,
      "learning_rate": 8.151114123189701e-05,
      "loss": 2.9246,
      "step": 39900
    },
    {
      "epoch": 1.7173108375656365,
      "eval_bleu": 27.227798266781914,
      "eval_gen_len": 27.497,
      "eval_loss": 2.7900850772857666,
      "eval_runtime": 59.1999,
      "eval_samples_per_second": 16.892,
      "eval_steps_per_second": 1.064,
      "step": 39900
    },
    {
      "epoch": 1.7177412412843247,
      "grad_norm": 0.872033953666687,
      "learning_rate": 8.146547794353575e-05,
      "loss": 3.0177,
      "step": 39910
    },
    {
      "epoch": 1.7181716450030127,
      "grad_norm": 1.0078052282333374,
      "learning_rate": 8.141981865701017e-05,
      "loss": 3.0397,
      "step": 39920
    },
    {
      "epoch": 1.718602048721701,
      "grad_norm": 0.9765791296958923,
      "learning_rate": 8.13741633821787e-05,
      "loss": 2.9707,
      "step": 39930
    },
    {
      "epoch": 1.719032452440389,
      "grad_norm": 0.8316674828529358,
      "learning_rate": 8.132851212889894e-05,
      "loss": 3.1242,
      "step": 39940
    },
    {
      "epoch": 1.7194628561590772,
      "grad_norm": 0.9769631028175354,
      "learning_rate": 8.128286490702756e-05,
      "loss": 2.9715,
      "step": 39950
    },
    {
      "epoch": 1.7194628561590772,
      "eval_bleu": 26.886452929898198,
      "eval_gen_len": 27.421,
      "eval_loss": 2.793283700942993,
      "eval_runtime": 58.6949,
      "eval_samples_per_second": 17.037,
      "eval_steps_per_second": 1.073,
      "step": 39950
    },
    {
      "epoch": 1.7198932598777654,
      "grad_norm": 0.995446503162384,
      "learning_rate": 8.123722172642034e-05,
      "loss": 2.9644,
      "step": 39960
    },
    {
      "epoch": 1.7203236635964534,
      "grad_norm": 0.8001702427864075,
      "learning_rate": 8.119158259693222e-05,
      "loss": 3.0216,
      "step": 39970
    },
    {
      "epoch": 1.7207540673151416,
      "grad_norm": 0.9616327881813049,
      "learning_rate": 8.114594752841728e-05,
      "loss": 3.0298,
      "step": 39980
    },
    {
      "epoch": 1.7211844710338298,
      "grad_norm": 0.8140016794204712,
      "learning_rate": 8.110031653072873e-05,
      "loss": 3.0538,
      "step": 39990
    },
    {
      "epoch": 1.7216148747525177,
      "grad_norm": 0.9177713990211487,
      "learning_rate": 8.10546896137188e-05,
      "loss": 2.9808,
      "step": 40000
    },
    {
      "epoch": 1.7216148747525177,
      "eval_bleu": 26.993834306675588,
      "eval_gen_len": 27.492,
      "eval_loss": 2.7911629676818848,
      "eval_runtime": 58.2123,
      "eval_samples_per_second": 17.178,
      "eval_steps_per_second": 1.082,
      "step": 40000
    },
    {
      "epoch": 1.7220452784712061,
      "grad_norm": 1.0309065580368042,
      "learning_rate": 8.100906678723894e-05,
      "loss": 2.9982,
      "step": 40010
    },
    {
      "epoch": 1.722475682189894,
      "grad_norm": 0.9326104521751404,
      "learning_rate": 8.096344806113971e-05,
      "loss": 3.0035,
      "step": 40020
    },
    {
      "epoch": 1.7229060859085823,
      "grad_norm": 0.9170008897781372,
      "learning_rate": 8.091783344527072e-05,
      "loss": 3.1186,
      "step": 40030
    },
    {
      "epoch": 1.7233364896272705,
      "grad_norm": 0.9312724471092224,
      "learning_rate": 8.08722229494808e-05,
      "loss": 2.9985,
      "step": 40040
    },
    {
      "epoch": 1.7237668933459585,
      "grad_norm": 0.931178629398346,
      "learning_rate": 8.082661658361778e-05,
      "loss": 2.9645,
      "step": 40050
    },
    {
      "epoch": 1.7237668933459585,
      "eval_bleu": 27.294649118149685,
      "eval_gen_len": 27.513,
      "eval_loss": 2.7917988300323486,
      "eval_runtime": 58.6546,
      "eval_samples_per_second": 17.049,
      "eval_steps_per_second": 1.074,
      "step": 40050
    },
    {
      "epoch": 1.7241972970646466,
      "grad_norm": 0.8867581486701965,
      "learning_rate": 8.07810143575287e-05,
      "loss": 3.0096,
      "step": 40060
    },
    {
      "epoch": 1.7246277007833348,
      "grad_norm": 0.9839915037155151,
      "learning_rate": 8.073541628105964e-05,
      "loss": 3.0479,
      "step": 40070
    },
    {
      "epoch": 1.7250581045020228,
      "grad_norm": 0.9454226493835449,
      "learning_rate": 8.068982236405574e-05,
      "loss": 2.9961,
      "step": 40080
    },
    {
      "epoch": 1.725488508220711,
      "grad_norm": 0.9238882660865784,
      "learning_rate": 8.064423261636134e-05,
      "loss": 2.9439,
      "step": 40090
    },
    {
      "epoch": 1.7259189119393992,
      "grad_norm": 0.9219294190406799,
      "learning_rate": 8.059864704781981e-05,
      "loss": 3.0838,
      "step": 40100
    },
    {
      "epoch": 1.7259189119393992,
      "eval_bleu": 26.941943054846874,
      "eval_gen_len": 27.51,
      "eval_loss": 2.793611764907837,
      "eval_runtime": 58.3896,
      "eval_samples_per_second": 17.126,
      "eval_steps_per_second": 1.079,
      "step": 40100
    },
    {
      "epoch": 1.7263493156580871,
      "grad_norm": 0.9261506199836731,
      "learning_rate": 8.055306566827369e-05,
      "loss": 3.0625,
      "step": 40110
    },
    {
      "epoch": 1.7267797193767755,
      "grad_norm": 0.8744235038757324,
      "learning_rate": 8.050748848756455e-05,
      "loss": 3.0984,
      "step": 40120
    },
    {
      "epoch": 1.7272101230954635,
      "grad_norm": 0.9620217680931091,
      "learning_rate": 8.046191551553304e-05,
      "loss": 2.9435,
      "step": 40130
    },
    {
      "epoch": 1.7276405268141517,
      "grad_norm": 1.0042325258255005,
      "learning_rate": 8.041634676201898e-05,
      "loss": 2.9828,
      "step": 40140
    },
    {
      "epoch": 1.7280709305328399,
      "grad_norm": 0.8718637824058533,
      "learning_rate": 8.03707822368613e-05,
      "loss": 2.9826,
      "step": 40150
    },
    {
      "epoch": 1.7280709305328399,
      "eval_bleu": 27.428493310950994,
      "eval_gen_len": 27.539,
      "eval_loss": 2.7904813289642334,
      "eval_runtime": 58.6261,
      "eval_samples_per_second": 17.057,
      "eval_steps_per_second": 1.075,
      "step": 40150
    },
    {
      "epoch": 1.7285013342515279,
      "grad_norm": 0.8296270370483398,
      "learning_rate": 8.03252219498978e-05,
      "loss": 2.9636,
      "step": 40160
    },
    {
      "epoch": 1.728931737970216,
      "grad_norm": 1.0059126615524292,
      "learning_rate": 8.027966591096563e-05,
      "loss": 3.1155,
      "step": 40170
    },
    {
      "epoch": 1.7293621416889042,
      "grad_norm": 0.9875809550285339,
      "learning_rate": 8.023411412990085e-05,
      "loss": 3.0106,
      "step": 40180
    },
    {
      "epoch": 1.7297925454075922,
      "grad_norm": 0.9587978720664978,
      "learning_rate": 8.01885666165387e-05,
      "loss": 3.0197,
      "step": 40190
    },
    {
      "epoch": 1.7302229491262806,
      "grad_norm": 0.9139197468757629,
      "learning_rate": 8.014302338071343e-05,
      "loss": 3.0866,
      "step": 40200
    },
    {
      "epoch": 1.7302229491262806,
      "eval_bleu": 27.161799834513854,
      "eval_gen_len": 27.542,
      "eval_loss": 2.7915101051330566,
      "eval_runtime": 58.2954,
      "eval_samples_per_second": 17.154,
      "eval_steps_per_second": 1.081,
      "step": 40200
    },
    {
      "epoch": 1.7306533528449686,
      "grad_norm": 0.8903390169143677,
      "learning_rate": 8.009748443225843e-05,
      "loss": 2.9788,
      "step": 40210
    },
    {
      "epoch": 1.7310837565636568,
      "grad_norm": 0.7661044001579285,
      "learning_rate": 8.005194978100609e-05,
      "loss": 3.0133,
      "step": 40220
    },
    {
      "epoch": 1.731514160282345,
      "grad_norm": 0.8852579593658447,
      "learning_rate": 8.000641943678797e-05,
      "loss": 2.9377,
      "step": 40230
    },
    {
      "epoch": 1.731944564001033,
      "grad_norm": 0.8380863070487976,
      "learning_rate": 7.996089340943458e-05,
      "loss": 3.0237,
      "step": 40240
    },
    {
      "epoch": 1.732374967719721,
      "grad_norm": 1.0261743068695068,
      "learning_rate": 7.991537170877559e-05,
      "loss": 3.0565,
      "step": 40250
    },
    {
      "epoch": 1.732374967719721,
      "eval_bleu": 26.923485510909728,
      "eval_gen_len": 27.49,
      "eval_loss": 2.7933170795440674,
      "eval_runtime": 58.2988,
      "eval_samples_per_second": 17.153,
      "eval_steps_per_second": 1.081,
      "step": 40250
    },
    {
      "epoch": 1.7328053714384093,
      "grad_norm": 0.9395238161087036,
      "learning_rate": 7.986985434463969e-05,
      "loss": 3.0325,
      "step": 40260
    },
    {
      "epoch": 1.7332357751570973,
      "grad_norm": 0.8702926635742188,
      "learning_rate": 7.982434132685468e-05,
      "loss": 3.0312,
      "step": 40270
    },
    {
      "epoch": 1.7336661788757854,
      "grad_norm": 0.8444344401359558,
      "learning_rate": 7.977883266524735e-05,
      "loss": 2.978,
      "step": 40280
    },
    {
      "epoch": 1.7340965825944736,
      "grad_norm": 0.8224244713783264,
      "learning_rate": 7.973332836964363e-05,
      "loss": 2.9648,
      "step": 40290
    },
    {
      "epoch": 1.7345269863131616,
      "grad_norm": 1.008542776107788,
      "learning_rate": 7.968782844986844e-05,
      "loss": 2.9601,
      "step": 40300
    },
    {
      "epoch": 1.7345269863131616,
      "eval_bleu": 27.19716567089626,
      "eval_gen_len": 27.449,
      "eval_loss": 2.7921252250671387,
      "eval_runtime": 58.1793,
      "eval_samples_per_second": 17.188,
      "eval_steps_per_second": 1.083,
      "step": 40300
    },
    {
      "epoch": 1.73495739003185,
      "grad_norm": 1.02862548828125,
      "learning_rate": 7.96423329157458e-05,
      "loss": 2.9644,
      "step": 40310
    },
    {
      "epoch": 1.735387793750538,
      "grad_norm": 0.9819424748420715,
      "learning_rate": 7.959684177709878e-05,
      "loss": 2.9786,
      "step": 40320
    },
    {
      "epoch": 1.7358181974692262,
      "grad_norm": 0.8966919779777527,
      "learning_rate": 7.955135504374944e-05,
      "loss": 3.0019,
      "step": 40330
    },
    {
      "epoch": 1.7362486011879144,
      "grad_norm": 0.7941909432411194,
      "learning_rate": 7.950587272551899e-05,
      "loss": 3.0523,
      "step": 40340
    },
    {
      "epoch": 1.7366790049066023,
      "grad_norm": 0.9843304753303528,
      "learning_rate": 7.946039483222758e-05,
      "loss": 3.0408,
      "step": 40350
    },
    {
      "epoch": 1.7366790049066023,
      "eval_bleu": 27.233334590046514,
      "eval_gen_len": 27.484,
      "eval_loss": 2.791482448577881,
      "eval_runtime": 59.0037,
      "eval_samples_per_second": 16.948,
      "eval_steps_per_second": 1.068,
      "step": 40350
    },
    {
      "epoch": 1.7371094086252905,
      "grad_norm": 0.9126740097999573,
      "learning_rate": 7.941492137369449e-05,
      "loss": 2.9666,
      "step": 40360
    },
    {
      "epoch": 1.7375398123439787,
      "grad_norm": 0.8875526785850525,
      "learning_rate": 7.936945235973801e-05,
      "loss": 3.0286,
      "step": 40370
    },
    {
      "epoch": 1.7379702160626667,
      "grad_norm": 0.8446968793869019,
      "learning_rate": 7.932398780017546e-05,
      "loss": 3.0094,
      "step": 40380
    },
    {
      "epoch": 1.738400619781355,
      "grad_norm": 0.9379761219024658,
      "learning_rate": 7.927852770482321e-05,
      "loss": 3.0368,
      "step": 40390
    },
    {
      "epoch": 1.738831023500043,
      "grad_norm": 0.8795214891433716,
      "learning_rate": 7.92330720834967e-05,
      "loss": 3.1101,
      "step": 40400
    },
    {
      "epoch": 1.738831023500043,
      "eval_bleu": 27.370547088813076,
      "eval_gen_len": 27.491,
      "eval_loss": 2.7919514179229736,
      "eval_runtime": 58.5485,
      "eval_samples_per_second": 17.08,
      "eval_steps_per_second": 1.076,
      "step": 40400
    },
    {
      "epoch": 1.739261427218731,
      "grad_norm": 0.8601506352424622,
      "learning_rate": 7.918762094601031e-05,
      "loss": 3.0249,
      "step": 40410
    },
    {
      "epoch": 1.7396918309374194,
      "grad_norm": 0.9116892218589783,
      "learning_rate": 7.914217430217753e-05,
      "loss": 3.0306,
      "step": 40420
    },
    {
      "epoch": 1.7401222346561074,
      "grad_norm": 0.9867153167724609,
      "learning_rate": 7.909673216181088e-05,
      "loss": 2.9845,
      "step": 40430
    },
    {
      "epoch": 1.7405526383747956,
      "grad_norm": 0.9685814380645752,
      "learning_rate": 7.905129453472186e-05,
      "loss": 2.9847,
      "step": 40440
    },
    {
      "epoch": 1.7409830420934838,
      "grad_norm": 0.9394048452377319,
      "learning_rate": 7.900586143072105e-05,
      "loss": 3.0278,
      "step": 40450
    },
    {
      "epoch": 1.7409830420934838,
      "eval_bleu": 27.027120880177133,
      "eval_gen_len": 27.47,
      "eval_loss": 2.7930045127868652,
      "eval_runtime": 58.5275,
      "eval_samples_per_second": 17.086,
      "eval_steps_per_second": 1.076,
      "step": 40450
    },
    {
      "epoch": 1.7414134458121717,
      "grad_norm": 0.976654589176178,
      "learning_rate": 7.896043285961801e-05,
      "loss": 2.938,
      "step": 40460
    },
    {
      "epoch": 1.74184384953086,
      "grad_norm": 0.8807063102722168,
      "learning_rate": 7.891500883122134e-05,
      "loss": 2.9902,
      "step": 40470
    },
    {
      "epoch": 1.742274253249548,
      "grad_norm": 0.9540477991104126,
      "learning_rate": 7.88695893553387e-05,
      "loss": 3.0724,
      "step": 40480
    },
    {
      "epoch": 1.742704656968236,
      "grad_norm": 0.9480603933334351,
      "learning_rate": 7.882417444177665e-05,
      "loss": 3.045,
      "step": 40490
    },
    {
      "epoch": 1.7431350606869245,
      "grad_norm": 0.899657666683197,
      "learning_rate": 7.877876410034086e-05,
      "loss": 2.9453,
      "step": 40500
    },
    {
      "epoch": 1.7431350606869245,
      "eval_bleu": 26.983419264778874,
      "eval_gen_len": 27.391,
      "eval_loss": 2.792999744415283,
      "eval_runtime": 58.4097,
      "eval_samples_per_second": 17.12,
      "eval_steps_per_second": 1.079,
      "step": 40500
    },
    {
      "epoch": 1.7435654644056124,
      "grad_norm": 0.9291548728942871,
      "learning_rate": 7.873335834083604e-05,
      "loss": 3.0204,
      "step": 40510
    },
    {
      "epoch": 1.7439958681243006,
      "grad_norm": 0.9741307497024536,
      "learning_rate": 7.868795717306581e-05,
      "loss": 3.0906,
      "step": 40520
    },
    {
      "epoch": 1.7444262718429888,
      "grad_norm": 0.8778566718101501,
      "learning_rate": 7.864256060683287e-05,
      "loss": 2.962,
      "step": 40530
    },
    {
      "epoch": 1.7448566755616768,
      "grad_norm": 0.8988713622093201,
      "learning_rate": 7.859716865193891e-05,
      "loss": 2.9788,
      "step": 40540
    },
    {
      "epoch": 1.745287079280365,
      "grad_norm": 0.9402076005935669,
      "learning_rate": 7.855178131818463e-05,
      "loss": 3.1321,
      "step": 40550
    },
    {
      "epoch": 1.745287079280365,
      "eval_bleu": 27.12831334779064,
      "eval_gen_len": 27.512,
      "eval_loss": 2.7909319400787354,
      "eval_runtime": 58.458,
      "eval_samples_per_second": 17.106,
      "eval_steps_per_second": 1.078,
      "step": 40550
    },
    {
      "epoch": 1.7457174829990532,
      "grad_norm": 0.910052478313446,
      "learning_rate": 7.850639861536973e-05,
      "loss": 2.9784,
      "step": 40560
    },
    {
      "epoch": 1.7461478867177411,
      "grad_norm": 0.838778018951416,
      "learning_rate": 7.846102055329287e-05,
      "loss": 2.9861,
      "step": 40570
    },
    {
      "epoch": 1.7465782904364295,
      "grad_norm": 0.9413775205612183,
      "learning_rate": 7.841564714175175e-05,
      "loss": 3.0473,
      "step": 40580
    },
    {
      "epoch": 1.7470086941551175,
      "grad_norm": 0.7938209176063538,
      "learning_rate": 7.837027839054309e-05,
      "loss": 3.0102,
      "step": 40590
    },
    {
      "epoch": 1.7474390978738055,
      "grad_norm": 1.006508231163025,
      "learning_rate": 7.832491430946255e-05,
      "loss": 3.0159,
      "step": 40600
    },
    {
      "epoch": 1.7474390978738055,
      "eval_bleu": 27.327820336545102,
      "eval_gen_len": 27.436,
      "eval_loss": 2.7931363582611084,
      "eval_runtime": 58.3614,
      "eval_samples_per_second": 17.135,
      "eval_steps_per_second": 1.079,
      "step": 40600
    },
    {
      "epoch": 1.7478695015924939,
      "grad_norm": 0.8765263557434082,
      "learning_rate": 7.827955490830481e-05,
      "loss": 3.0083,
      "step": 40610
    },
    {
      "epoch": 1.7482999053111818,
      "grad_norm": 0.942058265209198,
      "learning_rate": 7.823420019686352e-05,
      "loss": 3.0127,
      "step": 40620
    },
    {
      "epoch": 1.74873030902987,
      "grad_norm": 0.956973135471344,
      "learning_rate": 7.818885018493134e-05,
      "loss": 3.0263,
      "step": 40630
    },
    {
      "epoch": 1.7491607127485582,
      "grad_norm": 0.9200642108917236,
      "learning_rate": 7.814350488229996e-05,
      "loss": 3.0331,
      "step": 40640
    },
    {
      "epoch": 1.7495911164672462,
      "grad_norm": 0.9040319323539734,
      "learning_rate": 7.809816429875991e-05,
      "loss": 3.013,
      "step": 40650
    },
    {
      "epoch": 1.7495911164672462,
      "eval_bleu": 27.211204336689214,
      "eval_gen_len": 27.441,
      "eval_loss": 2.794506311416626,
      "eval_runtime": 58.3272,
      "eval_samples_per_second": 17.145,
      "eval_steps_per_second": 1.08,
      "step": 40650
    },
    {
      "epoch": 1.7500215201859344,
      "grad_norm": 0.9083613157272339,
      "learning_rate": 7.80528284441008e-05,
      "loss": 3.0533,
      "step": 40660
    },
    {
      "epoch": 1.7504519239046226,
      "grad_norm": 0.9883180856704712,
      "learning_rate": 7.800749732811127e-05,
      "loss": 2.9922,
      "step": 40670
    },
    {
      "epoch": 1.7508823276233105,
      "grad_norm": 0.9140205383300781,
      "learning_rate": 7.796217096057883e-05,
      "loss": 3.0608,
      "step": 40680
    },
    {
      "epoch": 1.751312731341999,
      "grad_norm": 1.0063927173614502,
      "learning_rate": 7.791684935129003e-05,
      "loss": 3.0463,
      "step": 40690
    },
    {
      "epoch": 1.751743135060687,
      "grad_norm": 0.9454504251480103,
      "learning_rate": 7.787153251003036e-05,
      "loss": 3.0602,
      "step": 40700
    },
    {
      "epoch": 1.751743135060687,
      "eval_bleu": 27.114146160308007,
      "eval_gen_len": 27.475,
      "eval_loss": 2.793858051300049,
      "eval_runtime": 58.3709,
      "eval_samples_per_second": 17.132,
      "eval_steps_per_second": 1.079,
      "step": 40700
    },
    {
      "epoch": 1.752173538779375,
      "grad_norm": 1.0844802856445312,
      "learning_rate": 7.782622044658432e-05,
      "loss": 3.0454,
      "step": 40710
    },
    {
      "epoch": 1.7526039424980633,
      "grad_norm": 0.9179248809814453,
      "learning_rate": 7.778091317073538e-05,
      "loss": 3.0107,
      "step": 40720
    },
    {
      "epoch": 1.7530343462167512,
      "grad_norm": 0.9415230751037598,
      "learning_rate": 7.773561069226585e-05,
      "loss": 2.9665,
      "step": 40730
    },
    {
      "epoch": 1.7534647499354394,
      "grad_norm": 0.8874133229255676,
      "learning_rate": 7.769031302095716e-05,
      "loss": 3.0156,
      "step": 40740
    },
    {
      "epoch": 1.7538951536541276,
      "grad_norm": 0.8391112089157104,
      "learning_rate": 7.764502016658965e-05,
      "loss": 3.0479,
      "step": 40750
    },
    {
      "epoch": 1.7538951536541276,
      "eval_bleu": 27.292276867205896,
      "eval_gen_len": 27.436,
      "eval_loss": 2.7929775714874268,
      "eval_runtime": 58.4153,
      "eval_samples_per_second": 17.119,
      "eval_steps_per_second": 1.078,
      "step": 40750
    },
    {
      "epoch": 1.7543255573728156,
      "grad_norm": 0.9575840830802917,
      "learning_rate": 7.759973213894258e-05,
      "loss": 2.9743,
      "step": 40760
    },
    {
      "epoch": 1.7547559610915038,
      "grad_norm": 0.8726955652236938,
      "learning_rate": 7.755444894779426e-05,
      "loss": 3.0197,
      "step": 40770
    },
    {
      "epoch": 1.755186364810192,
      "grad_norm": 0.8729320168495178,
      "learning_rate": 7.750917060292186e-05,
      "loss": 2.9497,
      "step": 40780
    },
    {
      "epoch": 1.75561676852888,
      "grad_norm": 0.9478968381881714,
      "learning_rate": 7.746389711410157e-05,
      "loss": 2.978,
      "step": 40790
    },
    {
      "epoch": 1.7560471722475683,
      "grad_norm": 0.8885917067527771,
      "learning_rate": 7.741862849110852e-05,
      "loss": 2.997,
      "step": 40800
    },
    {
      "epoch": 1.7560471722475683,
      "eval_bleu": 27.034356183653998,
      "eval_gen_len": 27.472,
      "eval_loss": 2.795724630355835,
      "eval_runtime": 58.4036,
      "eval_samples_per_second": 17.122,
      "eval_steps_per_second": 1.079,
      "step": 40800
    },
    {
      "epoch": 1.7564775759662563,
      "grad_norm": 1.0822278261184692,
      "learning_rate": 7.737336474371671e-05,
      "loss": 3.0115,
      "step": 40810
    },
    {
      "epoch": 1.7569079796849445,
      "grad_norm": 1.0775505304336548,
      "learning_rate": 7.732810588169916e-05,
      "loss": 3.0468,
      "step": 40820
    },
    {
      "epoch": 1.7573383834036327,
      "grad_norm": 0.8951724767684937,
      "learning_rate": 7.728285191482785e-05,
      "loss": 2.9991,
      "step": 40830
    },
    {
      "epoch": 1.7577687871223207,
      "grad_norm": 0.9121776819229126,
      "learning_rate": 7.723760285287369e-05,
      "loss": 2.9904,
      "step": 40840
    },
    {
      "epoch": 1.7581991908410088,
      "grad_norm": 0.899269163608551,
      "learning_rate": 7.71923587056065e-05,
      "loss": 3.0949,
      "step": 40850
    },
    {
      "epoch": 1.7581991908410088,
      "eval_bleu": 26.6329037642531,
      "eval_gen_len": 27.452,
      "eval_loss": 2.794463634490967,
      "eval_runtime": 58.4595,
      "eval_samples_per_second": 17.106,
      "eval_steps_per_second": 1.078,
      "step": 40850
    },
    {
      "epoch": 1.758629594559697,
      "grad_norm": 0.9557499885559082,
      "learning_rate": 7.714711948279502e-05,
      "loss": 2.9922,
      "step": 40860
    },
    {
      "epoch": 1.759059998278385,
      "grad_norm": 0.8452633619308472,
      "learning_rate": 7.710188519420707e-05,
      "loss": 2.9857,
      "step": 40870
    },
    {
      "epoch": 1.7594904019970734,
      "grad_norm": 0.8506264090538025,
      "learning_rate": 7.705665584960926e-05,
      "loss": 2.9893,
      "step": 40880
    },
    {
      "epoch": 1.7599208057157614,
      "grad_norm": 0.8582025170326233,
      "learning_rate": 7.701143145876711e-05,
      "loss": 3.0508,
      "step": 40890
    },
    {
      "epoch": 1.7603512094344496,
      "grad_norm": 0.9114422798156738,
      "learning_rate": 7.696621203144518e-05,
      "loss": 3.0214,
      "step": 40900
    },
    {
      "epoch": 1.7603512094344496,
      "eval_bleu": 27.090930263242377,
      "eval_gen_len": 27.524,
      "eval_loss": 2.792053461074829,
      "eval_runtime": 58.2969,
      "eval_samples_per_second": 17.154,
      "eval_steps_per_second": 1.081,
      "step": 40900
    },
    {
      "epoch": 1.7607816131531377,
      "grad_norm": 0.8277071118354797,
      "learning_rate": 7.69209975774069e-05,
      "loss": 2.9432,
      "step": 40910
    },
    {
      "epoch": 1.7612120168718257,
      "grad_norm": 0.9670828580856323,
      "learning_rate": 7.687578810641465e-05,
      "loss": 3.0033,
      "step": 40920
    },
    {
      "epoch": 1.761642420590514,
      "grad_norm": 0.995621919631958,
      "learning_rate": 7.683058362822972e-05,
      "loss": 3.0609,
      "step": 40930
    },
    {
      "epoch": 1.762072824309202,
      "grad_norm": 0.8629159927368164,
      "learning_rate": 7.678538415261233e-05,
      "loss": 2.9413,
      "step": 40940
    },
    {
      "epoch": 1.76250322802789,
      "grad_norm": 0.9297567009925842,
      "learning_rate": 7.674018968932158e-05,
      "loss": 3.135,
      "step": 40950
    },
    {
      "epoch": 1.76250322802789,
      "eval_bleu": 27.268675112615593,
      "eval_gen_len": 27.5,
      "eval_loss": 2.791766405105591,
      "eval_runtime": 58.5154,
      "eval_samples_per_second": 17.09,
      "eval_steps_per_second": 1.077,
      "step": 40950
    },
    {
      "epoch": 1.7629336317465782,
      "grad_norm": 0.8677058219909668,
      "learning_rate": 7.669500024811554e-05,
      "loss": 3.0678,
      "step": 40960
    },
    {
      "epoch": 1.7633640354652664,
      "grad_norm": 0.8749167323112488,
      "learning_rate": 7.664981583875124e-05,
      "loss": 3.006,
      "step": 40970
    },
    {
      "epoch": 1.7637944391839544,
      "grad_norm": 1.0624425411224365,
      "learning_rate": 7.660463647098446e-05,
      "loss": 3.0059,
      "step": 40980
    },
    {
      "epoch": 1.7642248429026428,
      "grad_norm": 0.817986786365509,
      "learning_rate": 7.655946215457004e-05,
      "loss": 2.8812,
      "step": 40990
    },
    {
      "epoch": 1.7646552466213308,
      "grad_norm": 0.9023352861404419,
      "learning_rate": 7.651429289926168e-05,
      "loss": 3.0123,
      "step": 41000
    },
    {
      "epoch": 1.7646552466213308,
      "eval_bleu": 26.89555547829999,
      "eval_gen_len": 27.459,
      "eval_loss": 2.790907144546509,
      "eval_runtime": 58.4119,
      "eval_samples_per_second": 17.12,
      "eval_steps_per_second": 1.079,
      "step": 41000
    },
    {
      "epoch": 1.765085650340019,
      "grad_norm": 0.8951184749603271,
      "learning_rate": 7.646912871481198e-05,
      "loss": 2.9025,
      "step": 41010
    },
    {
      "epoch": 1.7655160540587072,
      "grad_norm": 0.8465605974197388,
      "learning_rate": 7.642396961097244e-05,
      "loss": 3.0636,
      "step": 41020
    },
    {
      "epoch": 1.7659464577773951,
      "grad_norm": 0.8658882975578308,
      "learning_rate": 7.637881559749352e-05,
      "loss": 3.0717,
      "step": 41030
    },
    {
      "epoch": 1.7663768614960833,
      "grad_norm": 0.9041150808334351,
      "learning_rate": 7.63336666841245e-05,
      "loss": 3.0397,
      "step": 41040
    },
    {
      "epoch": 1.7668072652147715,
      "grad_norm": 0.816730260848999,
      "learning_rate": 7.628852288061363e-05,
      "loss": 3.009,
      "step": 41050
    },
    {
      "epoch": 1.7668072652147715,
      "eval_bleu": 26.903070488414624,
      "eval_gen_len": 27.427,
      "eval_loss": 2.7913730144500732,
      "eval_runtime": 58.3265,
      "eval_samples_per_second": 17.145,
      "eval_steps_per_second": 1.08,
      "step": 41050
    },
    {
      "epoch": 1.7672376689334595,
      "grad_norm": 0.9401534199714661,
      "learning_rate": 7.624338419670798e-05,
      "loss": 3.0367,
      "step": 41060
    },
    {
      "epoch": 1.7676680726521479,
      "grad_norm": 0.863897442817688,
      "learning_rate": 7.61982506421536e-05,
      "loss": 2.9703,
      "step": 41070
    },
    {
      "epoch": 1.7680984763708358,
      "grad_norm": 0.8211594223976135,
      "learning_rate": 7.615312222669535e-05,
      "loss": 2.9962,
      "step": 41080
    },
    {
      "epoch": 1.768528880089524,
      "grad_norm": 0.882498025894165,
      "learning_rate": 7.610799896007705e-05,
      "loss": 2.9647,
      "step": 41090
    },
    {
      "epoch": 1.7689592838082122,
      "grad_norm": 0.8429176807403564,
      "learning_rate": 7.606288085204138e-05,
      "loss": 3.0201,
      "step": 41100
    },
    {
      "epoch": 1.7689592838082122,
      "eval_bleu": 27.126665932379762,
      "eval_gen_len": 27.507,
      "eval_loss": 2.7909419536590576,
      "eval_runtime": 58.7316,
      "eval_samples_per_second": 17.027,
      "eval_steps_per_second": 1.073,
      "step": 41100
    },
    {
      "epoch": 1.7693896875269002,
      "grad_norm": 0.9045215249061584,
      "learning_rate": 7.601776791232989e-05,
      "loss": 3.0753,
      "step": 41110
    },
    {
      "epoch": 1.7698200912455884,
      "grad_norm": 0.8825000524520874,
      "learning_rate": 7.597266015068302e-05,
      "loss": 3.025,
      "step": 41120
    },
    {
      "epoch": 1.7702504949642766,
      "grad_norm": 0.9552964568138123,
      "learning_rate": 7.592755757684015e-05,
      "loss": 3.0354,
      "step": 41130
    },
    {
      "epoch": 1.7706808986829645,
      "grad_norm": 0.9182326197624207,
      "learning_rate": 7.588246020053944e-05,
      "loss": 3.0246,
      "step": 41140
    },
    {
      "epoch": 1.7711113024016527,
      "grad_norm": 0.9571502804756165,
      "learning_rate": 7.5837368031518e-05,
      "loss": 3.0259,
      "step": 41150
    },
    {
      "epoch": 1.7711113024016527,
      "eval_bleu": 26.73737879564165,
      "eval_gen_len": 27.401,
      "eval_loss": 2.7937729358673096,
      "eval_runtime": 59.0783,
      "eval_samples_per_second": 16.927,
      "eval_steps_per_second": 1.066,
      "step": 41150
    },
    {
      "epoch": 1.771541706120341,
      "grad_norm": 0.8652532696723938,
      "learning_rate": 7.579228107951178e-05,
      "loss": 2.9304,
      "step": 41160
    },
    {
      "epoch": 1.7719721098390289,
      "grad_norm": 0.9359055161476135,
      "learning_rate": 7.574719935425563e-05,
      "loss": 3.0222,
      "step": 41170
    },
    {
      "epoch": 1.7724025135577173,
      "grad_norm": 1.0298670530319214,
      "learning_rate": 7.570212286548328e-05,
      "loss": 2.9869,
      "step": 41180
    },
    {
      "epoch": 1.7728329172764052,
      "grad_norm": 1.0355899333953857,
      "learning_rate": 7.565705162292727e-05,
      "loss": 3.0102,
      "step": 41190
    },
    {
      "epoch": 1.7732633209950934,
      "grad_norm": 0.9005365967750549,
      "learning_rate": 7.561198563631905e-05,
      "loss": 3.0392,
      "step": 41200
    },
    {
      "epoch": 1.7732633209950934,
      "eval_bleu": 26.981400333332445,
      "eval_gen_len": 27.436,
      "eval_loss": 2.7913053035736084,
      "eval_runtime": 58.0071,
      "eval_samples_per_second": 17.239,
      "eval_steps_per_second": 1.086,
      "step": 41200
    },
    {
      "epoch": 1.7736937247137816,
      "grad_norm": 0.8111270070075989,
      "learning_rate": 7.5566924915389e-05,
      "loss": 3.0515,
      "step": 41210
    },
    {
      "epoch": 1.7741241284324696,
      "grad_norm": 0.8651007413864136,
      "learning_rate": 7.552186946986622e-05,
      "loss": 2.9353,
      "step": 41220
    },
    {
      "epoch": 1.7745545321511578,
      "grad_norm": 0.9783474206924438,
      "learning_rate": 7.547681930947875e-05,
      "loss": 3.0127,
      "step": 41230
    },
    {
      "epoch": 1.774984935869846,
      "grad_norm": 0.899607241153717,
      "learning_rate": 7.543177444395352e-05,
      "loss": 2.9669,
      "step": 41240
    },
    {
      "epoch": 1.775415339588534,
      "grad_norm": 0.8466587066650391,
      "learning_rate": 7.538673488301624e-05,
      "loss": 3.086,
      "step": 41250
    },
    {
      "epoch": 1.775415339588534,
      "eval_bleu": 27.01926608643453,
      "eval_gen_len": 27.41,
      "eval_loss": 2.78904128074646,
      "eval_runtime": 58.2705,
      "eval_samples_per_second": 17.161,
      "eval_steps_per_second": 1.081,
      "step": 41250
    },
    {
      "epoch": 1.7758457433072223,
      "grad_norm": 0.9642648100852966,
      "learning_rate": 7.534170063639156e-05,
      "loss": 3.0138,
      "step": 41260
    },
    {
      "epoch": 1.7762761470259103,
      "grad_norm": 0.800114095211029,
      "learning_rate": 7.529667171380291e-05,
      "loss": 2.9603,
      "step": 41270
    },
    {
      "epoch": 1.7767065507445983,
      "grad_norm": 0.8944106101989746,
      "learning_rate": 7.525164812497261e-05,
      "loss": 3.0044,
      "step": 41280
    },
    {
      "epoch": 1.7771369544632867,
      "grad_norm": 0.9075762033462524,
      "learning_rate": 7.520662987962183e-05,
      "loss": 2.9771,
      "step": 41290
    },
    {
      "epoch": 1.7775673581819746,
      "grad_norm": 0.898905873298645,
      "learning_rate": 7.516161698747055e-05,
      "loss": 2.9809,
      "step": 41300
    },
    {
      "epoch": 1.7775673581819746,
      "eval_bleu": 27.130965948325446,
      "eval_gen_len": 27.5,
      "eval_loss": 2.793592691421509,
      "eval_runtime": 58.5648,
      "eval_samples_per_second": 17.075,
      "eval_steps_per_second": 1.076,
      "step": 41300
    },
    {
      "epoch": 1.7779977619006628,
      "grad_norm": 0.9045637249946594,
      "learning_rate": 7.511660945823762e-05,
      "loss": 2.9927,
      "step": 41310
    },
    {
      "epoch": 1.778428165619351,
      "grad_norm": 0.8858245611190796,
      "learning_rate": 7.507160730164073e-05,
      "loss": 2.9833,
      "step": 41320
    },
    {
      "epoch": 1.778858569338039,
      "grad_norm": 0.8469208478927612,
      "learning_rate": 7.502661052739642e-05,
      "loss": 3.0881,
      "step": 41330
    },
    {
      "epoch": 1.7792889730567272,
      "grad_norm": 0.889315128326416,
      "learning_rate": 7.498161914522004e-05,
      "loss": 3.178,
      "step": 41340
    },
    {
      "epoch": 1.7797193767754154,
      "grad_norm": 0.8711661696434021,
      "learning_rate": 7.493663316482582e-05,
      "loss": 2.9702,
      "step": 41350
    },
    {
      "epoch": 1.7797193767754154,
      "eval_bleu": 27.20992282163603,
      "eval_gen_len": 27.385,
      "eval_loss": 2.790781021118164,
      "eval_runtime": 58.6569,
      "eval_samples_per_second": 17.048,
      "eval_steps_per_second": 1.074,
      "step": 41350
    },
    {
      "epoch": 1.7801497804941033,
      "grad_norm": 0.8380757570266724,
      "learning_rate": 7.489165259592679e-05,
      "loss": 2.9854,
      "step": 41360
    },
    {
      "epoch": 1.7805801842127917,
      "grad_norm": 0.9394165277481079,
      "learning_rate": 7.484667744823486e-05,
      "loss": 2.9247,
      "step": 41370
    },
    {
      "epoch": 1.7810105879314797,
      "grad_norm": 0.8298267722129822,
      "learning_rate": 7.480170773146063e-05,
      "loss": 3.0057,
      "step": 41380
    },
    {
      "epoch": 1.781440991650168,
      "grad_norm": 0.892787754535675,
      "learning_rate": 7.475674345531364e-05,
      "loss": 2.9959,
      "step": 41390
    },
    {
      "epoch": 1.781871395368856,
      "grad_norm": 1.019873023033142,
      "learning_rate": 7.471178462950232e-05,
      "loss": 3.0002,
      "step": 41400
    },
    {
      "epoch": 1.781871395368856,
      "eval_bleu": 26.63676706341943,
      "eval_gen_len": 27.469,
      "eval_loss": 2.790917158126831,
      "eval_runtime": 57.9975,
      "eval_samples_per_second": 17.242,
      "eval_steps_per_second": 1.086,
      "step": 41400
    },
    {
      "epoch": 1.782301799087544,
      "grad_norm": 0.9392958879470825,
      "learning_rate": 7.46668312637338e-05,
      "loss": 3.0546,
      "step": 41410
    },
    {
      "epoch": 1.7827322028062322,
      "grad_norm": 0.8740213513374329,
      "learning_rate": 7.462188336771408e-05,
      "loss": 3.0345,
      "step": 41420
    },
    {
      "epoch": 1.7831626065249204,
      "grad_norm": 0.918035626411438,
      "learning_rate": 7.457694095114797e-05,
      "loss": 3.0325,
      "step": 41430
    },
    {
      "epoch": 1.7835930102436084,
      "grad_norm": 0.8683238625526428,
      "learning_rate": 7.45320040237391e-05,
      "loss": 3.0725,
      "step": 41440
    },
    {
      "epoch": 1.7840234139622968,
      "grad_norm": 0.8538182973861694,
      "learning_rate": 7.448707259518997e-05,
      "loss": 2.9956,
      "step": 41450
    },
    {
      "epoch": 1.7840234139622968,
      "eval_bleu": 27.106853250709623,
      "eval_gen_len": 27.449,
      "eval_loss": 2.7907612323760986,
      "eval_runtime": 58.8859,
      "eval_samples_per_second": 16.982,
      "eval_steps_per_second": 1.07,
      "step": 41450
    },
    {
      "epoch": 1.7844538176809848,
      "grad_norm": 0.8542734980583191,
      "learning_rate": 7.444214667520175e-05,
      "loss": 3.0509,
      "step": 41460
    },
    {
      "epoch": 1.7848842213996727,
      "grad_norm": 0.8522211909294128,
      "learning_rate": 7.439722627347453e-05,
      "loss": 2.9405,
      "step": 41470
    },
    {
      "epoch": 1.7853146251183611,
      "grad_norm": 0.9842168092727661,
      "learning_rate": 7.435231139970722e-05,
      "loss": 2.9695,
      "step": 41480
    },
    {
      "epoch": 1.785745028837049,
      "grad_norm": 0.8509664535522461,
      "learning_rate": 7.430740206359747e-05,
      "loss": 3.0027,
      "step": 41490
    },
    {
      "epoch": 1.7861754325557373,
      "grad_norm": 0.8942984938621521,
      "learning_rate": 7.42624982748418e-05,
      "loss": 3.0421,
      "step": 41500
    },
    {
      "epoch": 1.7861754325557373,
      "eval_bleu": 26.89768973568126,
      "eval_gen_len": 27.435,
      "eval_loss": 2.790923595428467,
      "eval_runtime": 58.4751,
      "eval_samples_per_second": 17.101,
      "eval_steps_per_second": 1.077,
      "step": 41500
    },
    {
      "epoch": 1.7866058362744255,
      "grad_norm": 0.9516810774803162,
      "learning_rate": 7.42176000431355e-05,
      "loss": 2.9593,
      "step": 41510
    },
    {
      "epoch": 1.7870362399931135,
      "grad_norm": 0.9881727695465088,
      "learning_rate": 7.417270737817265e-05,
      "loss": 3.0302,
      "step": 41520
    },
    {
      "epoch": 1.7874666437118016,
      "grad_norm": 0.9262827038764954,
      "learning_rate": 7.412782028964618e-05,
      "loss": 3.0484,
      "step": 41530
    },
    {
      "epoch": 1.7878970474304898,
      "grad_norm": 0.9413983225822449,
      "learning_rate": 7.40829387872477e-05,
      "loss": 3.0438,
      "step": 41540
    },
    {
      "epoch": 1.7883274511491778,
      "grad_norm": 0.9793381690979004,
      "learning_rate": 7.403806288066773e-05,
      "loss": 3.0349,
      "step": 41550
    },
    {
      "epoch": 1.7883274511491778,
      "eval_bleu": 26.991170840290074,
      "eval_gen_len": 27.414,
      "eval_loss": 2.789264440536499,
      "eval_runtime": 58.974,
      "eval_samples_per_second": 16.957,
      "eval_steps_per_second": 1.068,
      "step": 41550
    },
    {
      "epoch": 1.7887578548678662,
      "grad_norm": 0.8686217069625854,
      "learning_rate": 7.399319257959552e-05,
      "loss": 3.0169,
      "step": 41560
    },
    {
      "epoch": 1.7891882585865542,
      "grad_norm": 0.8293612599372864,
      "learning_rate": 7.394832789371917e-05,
      "loss": 3.0104,
      "step": 41570
    },
    {
      "epoch": 1.7896186623052424,
      "grad_norm": 0.8692840337753296,
      "learning_rate": 7.390346883272548e-05,
      "loss": 3.0309,
      "step": 41580
    },
    {
      "epoch": 1.7900490660239305,
      "grad_norm": 0.7915934920310974,
      "learning_rate": 7.385861540630011e-05,
      "loss": 3.0259,
      "step": 41590
    },
    {
      "epoch": 1.7904794697426185,
      "grad_norm": 0.8705947995185852,
      "learning_rate": 7.381376762412748e-05,
      "loss": 2.985,
      "step": 41600
    },
    {
      "epoch": 1.7904794697426185,
      "eval_bleu": 27.082222187445698,
      "eval_gen_len": 27.386,
      "eval_loss": 2.789228916168213,
      "eval_runtime": 58.9897,
      "eval_samples_per_second": 16.952,
      "eval_steps_per_second": 1.068,
      "step": 41600
    },
    {
      "epoch": 1.7909098734613067,
      "grad_norm": 0.8399792313575745,
      "learning_rate": 7.37689254958908e-05,
      "loss": 2.9328,
      "step": 41610
    },
    {
      "epoch": 1.7913402771799949,
      "grad_norm": 0.8585055470466614,
      "learning_rate": 7.372408903127206e-05,
      "loss": 2.9995,
      "step": 41620
    },
    {
      "epoch": 1.7917706808986829,
      "grad_norm": 0.9006863236427307,
      "learning_rate": 7.367925823995196e-05,
      "loss": 2.9577,
      "step": 41630
    },
    {
      "epoch": 1.792201084617371,
      "grad_norm": 0.9347403645515442,
      "learning_rate": 7.363443313161005e-05,
      "loss": 3.0585,
      "step": 41640
    },
    {
      "epoch": 1.7926314883360592,
      "grad_norm": 0.8663132786750793,
      "learning_rate": 7.358961371592464e-05,
      "loss": 3.0068,
      "step": 41650
    },
    {
      "epoch": 1.7926314883360592,
      "eval_bleu": 27.029034130509903,
      "eval_gen_len": 27.442,
      "eval_loss": 2.789464235305786,
      "eval_runtime": 58.2343,
      "eval_samples_per_second": 17.172,
      "eval_steps_per_second": 1.082,
      "step": 41650
    },
    {
      "epoch": 1.7930618920547472,
      "grad_norm": 0.8445270657539368,
      "learning_rate": 7.354480000257281e-05,
      "loss": 2.9592,
      "step": 41660
    },
    {
      "epoch": 1.7934922957734356,
      "grad_norm": 0.9261611700057983,
      "learning_rate": 7.349999200123038e-05,
      "loss": 3.1135,
      "step": 41670
    },
    {
      "epoch": 1.7939226994921236,
      "grad_norm": 0.9286502003669739,
      "learning_rate": 7.345518972157201e-05,
      "loss": 2.9932,
      "step": 41680
    },
    {
      "epoch": 1.7943531032108118,
      "grad_norm": 0.8446337580680847,
      "learning_rate": 7.3410393173271e-05,
      "loss": 3.012,
      "step": 41690
    },
    {
      "epoch": 1.7947835069295,
      "grad_norm": 0.9630645513534546,
      "learning_rate": 7.336560236599958e-05,
      "loss": 3.0202,
      "step": 41700
    },
    {
      "epoch": 1.7947835069295,
      "eval_bleu": 26.935721278698125,
      "eval_gen_len": 27.378,
      "eval_loss": 2.7915825843811035,
      "eval_runtime": 58.4757,
      "eval_samples_per_second": 17.101,
      "eval_steps_per_second": 1.077,
      "step": 41700
    },
    {
      "epoch": 1.795213910648188,
      "grad_norm": 0.8847143650054932,
      "learning_rate": 7.332081730942857e-05,
      "loss": 2.9795,
      "step": 41710
    },
    {
      "epoch": 1.795644314366876,
      "grad_norm": 0.9898727536201477,
      "learning_rate": 7.327603801322764e-05,
      "loss": 2.9834,
      "step": 41720
    },
    {
      "epoch": 1.7960747180855643,
      "grad_norm": 0.9501763582229614,
      "learning_rate": 7.323126448706521e-05,
      "loss": 2.9672,
      "step": 41730
    },
    {
      "epoch": 1.7965051218042523,
      "grad_norm": 0.9255414009094238,
      "learning_rate": 7.318649674060846e-05,
      "loss": 3.1504,
      "step": 41740
    },
    {
      "epoch": 1.7969355255229407,
      "grad_norm": 0.9261922240257263,
      "learning_rate": 7.314173478352329e-05,
      "loss": 3.0471,
      "step": 41750
    },
    {
      "epoch": 1.7969355255229407,
      "eval_bleu": 27.2269694144658,
      "eval_gen_len": 27.555,
      "eval_loss": 2.790148973464966,
      "eval_runtime": 58.4604,
      "eval_samples_per_second": 17.106,
      "eval_steps_per_second": 1.078,
      "step": 41750
    },
    {
      "epoch": 1.7973659292416286,
      "grad_norm": 0.8738642334938049,
      "learning_rate": 7.309697862547435e-05,
      "loss": 3.0272,
      "step": 41760
    },
    {
      "epoch": 1.7977963329603168,
      "grad_norm": 0.9426547884941101,
      "learning_rate": 7.30522282761251e-05,
      "loss": 3.0148,
      "step": 41770
    },
    {
      "epoch": 1.798226736679005,
      "grad_norm": 0.9573339819908142,
      "learning_rate": 7.300748374513771e-05,
      "loss": 2.9469,
      "step": 41780
    },
    {
      "epoch": 1.798657140397693,
      "grad_norm": 0.9480514526367188,
      "learning_rate": 7.296274504217301e-05,
      "loss": 3.0718,
      "step": 41790
    },
    {
      "epoch": 1.7990875441163812,
      "grad_norm": 0.8722368478775024,
      "learning_rate": 7.291801217689072e-05,
      "loss": 3.0628,
      "step": 41800
    },
    {
      "epoch": 1.7990875441163812,
      "eval_bleu": 27.05027542112479,
      "eval_gen_len": 27.505,
      "eval_loss": 2.7912631034851074,
      "eval_runtime": 59.0074,
      "eval_samples_per_second": 16.947,
      "eval_steps_per_second": 1.068,
      "step": 41800
    },
    {
      "epoch": 1.7995179478350694,
      "grad_norm": 0.9126262068748474,
      "learning_rate": 7.287328515894917e-05,
      "loss": 3.0078,
      "step": 41810
    },
    {
      "epoch": 1.7999483515537573,
      "grad_norm": 0.9069448113441467,
      "learning_rate": 7.282856399800553e-05,
      "loss": 3.0744,
      "step": 41820
    },
    {
      "epoch": 1.8003787552724455,
      "grad_norm": 0.9855126738548279,
      "learning_rate": 7.278384870371563e-05,
      "loss": 3.0406,
      "step": 41830
    },
    {
      "epoch": 1.8008091589911337,
      "grad_norm": 0.908967912197113,
      "learning_rate": 7.273913928573408e-05,
      "loss": 2.9632,
      "step": 41840
    },
    {
      "epoch": 1.8012395627098217,
      "grad_norm": 0.9343754649162292,
      "learning_rate": 7.269443575371419e-05,
      "loss": 3.0534,
      "step": 41850
    },
    {
      "epoch": 1.8012395627098217,
      "eval_bleu": 27.232184245698623,
      "eval_gen_len": 27.492,
      "eval_loss": 2.7908291816711426,
      "eval_runtime": 58.4161,
      "eval_samples_per_second": 17.119,
      "eval_steps_per_second": 1.078,
      "step": 41850
    },
    {
      "epoch": 1.80166996642851,
      "grad_norm": 0.9892786145210266,
      "learning_rate": 7.264973811730807e-05,
      "loss": 3.0416,
      "step": 41860
    },
    {
      "epoch": 1.802100370147198,
      "grad_norm": 0.9175468683242798,
      "learning_rate": 7.26050463861664e-05,
      "loss": 3.053,
      "step": 41870
    },
    {
      "epoch": 1.8025307738658862,
      "grad_norm": 0.9657339453697205,
      "learning_rate": 7.256036056993876e-05,
      "loss": 2.8958,
      "step": 41880
    },
    {
      "epoch": 1.8029611775845744,
      "grad_norm": 0.9557183384895325,
      "learning_rate": 7.251568067827334e-05,
      "loss": 3.0502,
      "step": 41890
    },
    {
      "epoch": 1.8033915813032624,
      "grad_norm": 1.004879117012024,
      "learning_rate": 7.24710067208171e-05,
      "loss": 3.0725,
      "step": 41900
    },
    {
      "epoch": 1.8033915813032624,
      "eval_bleu": 27.506709268721092,
      "eval_gen_len": 27.474,
      "eval_loss": 2.7914538383483887,
      "eval_runtime": 58.4121,
      "eval_samples_per_second": 17.12,
      "eval_steps_per_second": 1.079,
      "step": 41900
    },
    {
      "epoch": 1.8038219850219506,
      "grad_norm": 0.9650246500968933,
      "learning_rate": 7.242633870721573e-05,
      "loss": 3.0092,
      "step": 41910
    },
    {
      "epoch": 1.8042523887406388,
      "grad_norm": 0.9727033376693726,
      "learning_rate": 7.23816766471136e-05,
      "loss": 3.0221,
      "step": 41920
    },
    {
      "epoch": 1.8046827924593267,
      "grad_norm": 0.9523324370384216,
      "learning_rate": 7.233702055015379e-05,
      "loss": 3.0827,
      "step": 41930
    },
    {
      "epoch": 1.8051131961780151,
      "grad_norm": 0.9914698600769043,
      "learning_rate": 7.229237042597815e-05,
      "loss": 2.96,
      "step": 41940
    },
    {
      "epoch": 1.805543599896703,
      "grad_norm": 0.9739410877227783,
      "learning_rate": 7.224772628422715e-05,
      "loss": 2.9428,
      "step": 41950
    },
    {
      "epoch": 1.805543599896703,
      "eval_bleu": 26.855345348332087,
      "eval_gen_len": 27.532,
      "eval_loss": 2.7925891876220703,
      "eval_runtime": 59.0573,
      "eval_samples_per_second": 16.933,
      "eval_steps_per_second": 1.067,
      "step": 41950
    },
    {
      "epoch": 1.8059740036153913,
      "grad_norm": 0.8977500200271606,
      "learning_rate": 7.220308813454006e-05,
      "loss": 3.0201,
      "step": 41960
    },
    {
      "epoch": 1.8064044073340795,
      "grad_norm": 0.9164438247680664,
      "learning_rate": 7.21584559865548e-05,
      "loss": 3.041,
      "step": 41970
    },
    {
      "epoch": 1.8068348110527674,
      "grad_norm": 0.7447214126586914,
      "learning_rate": 7.2113829849908e-05,
      "loss": 2.9215,
      "step": 41980
    },
    {
      "epoch": 1.8072652147714556,
      "grad_norm": 0.8795885443687439,
      "learning_rate": 7.206920973423503e-05,
      "loss": 2.9182,
      "step": 41990
    },
    {
      "epoch": 1.8076956184901438,
      "grad_norm": 0.8535650372505188,
      "learning_rate": 7.202459564916992e-05,
      "loss": 3.099,
      "step": 42000
    },
    {
      "epoch": 1.8076956184901438,
      "eval_bleu": 26.942149696864714,
      "eval_gen_len": 27.561,
      "eval_loss": 2.7921605110168457,
      "eval_runtime": 58.6998,
      "eval_samples_per_second": 17.036,
      "eval_steps_per_second": 1.073,
      "step": 42000
    },
    {
      "epoch": 1.8081260222088318,
      "grad_norm": 0.9849148392677307,
      "learning_rate": 7.197998760434541e-05,
      "loss": 3.0147,
      "step": 42010
    },
    {
      "epoch": 1.80855642592752,
      "grad_norm": 0.8287355303764343,
      "learning_rate": 7.193538560939296e-05,
      "loss": 3.0281,
      "step": 42020
    },
    {
      "epoch": 1.8089868296462082,
      "grad_norm": 1.0223952531814575,
      "learning_rate": 7.189078967394266e-05,
      "loss": 2.9887,
      "step": 42030
    },
    {
      "epoch": 1.8094172333648961,
      "grad_norm": 0.8677305579185486,
      "learning_rate": 7.184619980762334e-05,
      "loss": 3.11,
      "step": 42040
    },
    {
      "epoch": 1.8098476370835845,
      "grad_norm": 0.9013069272041321,
      "learning_rate": 7.180161602006253e-05,
      "loss": 2.9469,
      "step": 42050
    },
    {
      "epoch": 1.8098476370835845,
      "eval_bleu": 27.100897503813346,
      "eval_gen_len": 27.471,
      "eval_loss": 2.789565324783325,
      "eval_runtime": 58.733,
      "eval_samples_per_second": 17.026,
      "eval_steps_per_second": 1.073,
      "step": 42050
    },
    {
      "epoch": 1.8102780408022725,
      "grad_norm": 1.0164833068847656,
      "learning_rate": 7.175703832088639e-05,
      "loss": 2.9779,
      "step": 42060
    },
    {
      "epoch": 1.8107084445209607,
      "grad_norm": 0.8950240015983582,
      "learning_rate": 7.171246671971985e-05,
      "loss": 3.0389,
      "step": 42070
    },
    {
      "epoch": 1.8111388482396489,
      "grad_norm": 0.9665903449058533,
      "learning_rate": 7.166790122618647e-05,
      "loss": 2.9918,
      "step": 42080
    },
    {
      "epoch": 1.8115692519583368,
      "grad_norm": 0.978135347366333,
      "learning_rate": 7.162334184990846e-05,
      "loss": 2.9491,
      "step": 42090
    },
    {
      "epoch": 1.811999655677025,
      "grad_norm": 0.9935396909713745,
      "learning_rate": 7.157878860050685e-05,
      "loss": 3.0107,
      "step": 42100
    },
    {
      "epoch": 1.811999655677025,
      "eval_bleu": 26.60185478025725,
      "eval_gen_len": 27.367,
      "eval_loss": 2.7926974296569824,
      "eval_runtime": 58.1795,
      "eval_samples_per_second": 17.188,
      "eval_steps_per_second": 1.083,
      "step": 42100
    },
    {
      "epoch": 1.8124300593957132,
      "grad_norm": 0.9559932351112366,
      "learning_rate": 7.153424148760111e-05,
      "loss": 3.0573,
      "step": 42110
    },
    {
      "epoch": 1.8128604631144012,
      "grad_norm": 0.9743020534515381,
      "learning_rate": 7.148970052080958e-05,
      "loss": 2.9414,
      "step": 42120
    },
    {
      "epoch": 1.8132908668330896,
      "grad_norm": 0.9404397010803223,
      "learning_rate": 7.144516570974922e-05,
      "loss": 2.9712,
      "step": 42130
    },
    {
      "epoch": 1.8137212705517776,
      "grad_norm": 0.8953229784965515,
      "learning_rate": 7.140063706403565e-05,
      "loss": 3.002,
      "step": 42140
    },
    {
      "epoch": 1.8141516742704655,
      "grad_norm": 0.7998114228248596,
      "learning_rate": 7.135611459328317e-05,
      "loss": 2.8833,
      "step": 42150
    },
    {
      "epoch": 1.8141516742704655,
      "eval_bleu": 26.92141544227786,
      "eval_gen_len": 27.529,
      "eval_loss": 2.792318105697632,
      "eval_runtime": 58.3652,
      "eval_samples_per_second": 17.133,
      "eval_steps_per_second": 1.079,
      "step": 42150
    },
    {
      "epoch": 1.814582077989154,
      "grad_norm": 0.9292083382606506,
      "learning_rate": 7.131159830710473e-05,
      "loss": 3.0584,
      "step": 42160
    },
    {
      "epoch": 1.815012481707842,
      "grad_norm": 0.8422597050666809,
      "learning_rate": 7.126708821511197e-05,
      "loss": 3.0989,
      "step": 42170
    },
    {
      "epoch": 1.81544288542653,
      "grad_norm": 0.8660051822662354,
      "learning_rate": 7.122258432691517e-05,
      "loss": 3.0502,
      "step": 42180
    },
    {
      "epoch": 1.8158732891452183,
      "grad_norm": 0.8572394251823425,
      "learning_rate": 7.117808665212326e-05,
      "loss": 2.9881,
      "step": 42190
    },
    {
      "epoch": 1.8163036928639062,
      "grad_norm": 0.8802968263626099,
      "learning_rate": 7.113359520034386e-05,
      "loss": 3.0069,
      "step": 42200
    },
    {
      "epoch": 1.8163036928639062,
      "eval_bleu": 26.75184083975789,
      "eval_gen_len": 27.473,
      "eval_loss": 2.793541431427002,
      "eval_runtime": 58.2558,
      "eval_samples_per_second": 17.166,
      "eval_steps_per_second": 1.081,
      "step": 42200
    },
    {
      "epoch": 1.8167340965825944,
      "grad_norm": 0.8064044713973999,
      "learning_rate": 7.108910998118321e-05,
      "loss": 3.0534,
      "step": 42210
    },
    {
      "epoch": 1.8171645003012826,
      "grad_norm": 1.0477031469345093,
      "learning_rate": 7.104463100424623e-05,
      "loss": 2.902,
      "step": 42220
    },
    {
      "epoch": 1.8175949040199706,
      "grad_norm": 0.95048588514328,
      "learning_rate": 7.100015827913655e-05,
      "loss": 2.9765,
      "step": 42230
    },
    {
      "epoch": 1.818025307738659,
      "grad_norm": 0.9113935232162476,
      "learning_rate": 7.095569181545631e-05,
      "loss": 3.0658,
      "step": 42240
    },
    {
      "epoch": 1.818455711457347,
      "grad_norm": 0.9799102544784546,
      "learning_rate": 7.091123162280642e-05,
      "loss": 2.9882,
      "step": 42250
    },
    {
      "epoch": 1.818455711457347,
      "eval_bleu": 26.81327531102123,
      "eval_gen_len": 27.578,
      "eval_loss": 2.791760206222534,
      "eval_runtime": 59.0843,
      "eval_samples_per_second": 16.925,
      "eval_steps_per_second": 1.066,
      "step": 42250
    },
    {
      "epoch": 1.8188861151760352,
      "grad_norm": 0.8424019813537598,
      "learning_rate": 7.08667777107864e-05,
      "loss": 3.0459,
      "step": 42260
    },
    {
      "epoch": 1.8193165188947233,
      "grad_norm": 0.8962360620498657,
      "learning_rate": 7.082233008899442e-05,
      "loss": 2.9537,
      "step": 42270
    },
    {
      "epoch": 1.8197469226134113,
      "grad_norm": 0.8914596438407898,
      "learning_rate": 7.077788876702722e-05,
      "loss": 3.0497,
      "step": 42280
    },
    {
      "epoch": 1.8201773263320995,
      "grad_norm": 0.8454297184944153,
      "learning_rate": 7.073345375448027e-05,
      "loss": 3.0205,
      "step": 42290
    },
    {
      "epoch": 1.8206077300507877,
      "grad_norm": 0.92315274477005,
      "learning_rate": 7.068902506094763e-05,
      "loss": 3.0452,
      "step": 42300
    },
    {
      "epoch": 1.8206077300507877,
      "eval_bleu": 27.029356663221495,
      "eval_gen_len": 27.624,
      "eval_loss": 2.7913875579833984,
      "eval_runtime": 58.9502,
      "eval_samples_per_second": 16.963,
      "eval_steps_per_second": 1.069,
      "step": 42300
    },
    {
      "epoch": 1.8210381337694757,
      "grad_norm": 0.9153024554252625,
      "learning_rate": 7.064460269602203e-05,
      "loss": 2.9287,
      "step": 42310
    },
    {
      "epoch": 1.821468537488164,
      "grad_norm": 0.9628461599349976,
      "learning_rate": 7.060018666929482e-05,
      "loss": 3.0665,
      "step": 42320
    },
    {
      "epoch": 1.821898941206852,
      "grad_norm": 0.8400510549545288,
      "learning_rate": 7.055577699035594e-05,
      "loss": 3.0451,
      "step": 42330
    },
    {
      "epoch": 1.82232934492554,
      "grad_norm": 0.8289197683334351,
      "learning_rate": 7.051137366879406e-05,
      "loss": 3.0039,
      "step": 42340
    },
    {
      "epoch": 1.8227597486442284,
      "grad_norm": 0.885750949382782,
      "learning_rate": 7.046697671419642e-05,
      "loss": 3.0301,
      "step": 42350
    },
    {
      "epoch": 1.8227597486442284,
      "eval_bleu": 26.77492877860603,
      "eval_gen_len": 27.535,
      "eval_loss": 2.7927660942077637,
      "eval_runtime": 58.9158,
      "eval_samples_per_second": 16.973,
      "eval_steps_per_second": 1.069,
      "step": 42350
    },
    {
      "epoch": 1.8231901523629164,
      "grad_norm": 0.918282687664032,
      "learning_rate": 7.04225861361488e-05,
      "loss": 3.0548,
      "step": 42360
    },
    {
      "epoch": 1.8236205560816046,
      "grad_norm": 1.043682336807251,
      "learning_rate": 7.037820194423572e-05,
      "loss": 3.1048,
      "step": 42370
    },
    {
      "epoch": 1.8240509598002927,
      "grad_norm": 0.9492812752723694,
      "learning_rate": 7.033382414804028e-05,
      "loss": 3.0471,
      "step": 42380
    },
    {
      "epoch": 1.8244813635189807,
      "grad_norm": 0.9014675617218018,
      "learning_rate": 7.02894527571442e-05,
      "loss": 2.9664,
      "step": 42390
    },
    {
      "epoch": 1.824911767237669,
      "grad_norm": 0.9072588682174683,
      "learning_rate": 7.024508778112786e-05,
      "loss": 2.9648,
      "step": 42400
    },
    {
      "epoch": 1.824911767237669,
      "eval_bleu": 26.968708933251904,
      "eval_gen_len": 27.503,
      "eval_loss": 2.7888951301574707,
      "eval_runtime": 58.1257,
      "eval_samples_per_second": 17.204,
      "eval_steps_per_second": 1.084,
      "step": 42400
    },
    {
      "epoch": 1.825342170956357,
      "grad_norm": 0.9394837021827698,
      "learning_rate": 7.020072922957015e-05,
      "loss": 3.014,
      "step": 42410
    },
    {
      "epoch": 1.825772574675045,
      "grad_norm": 0.9468013048171997,
      "learning_rate": 7.01563771120487e-05,
      "loss": 3.002,
      "step": 42420
    },
    {
      "epoch": 1.8262029783937335,
      "grad_norm": 1.0692132711410522,
      "learning_rate": 7.011203143813966e-05,
      "loss": 2.9916,
      "step": 42430
    },
    {
      "epoch": 1.8266333821124214,
      "grad_norm": 0.9055489897727966,
      "learning_rate": 7.00676922174178e-05,
      "loss": 3.0308,
      "step": 42440
    },
    {
      "epoch": 1.8270637858311096,
      "grad_norm": 0.9272866249084473,
      "learning_rate": 7.002335945945653e-05,
      "loss": 3.0921,
      "step": 42450
    },
    {
      "epoch": 1.8270637858311096,
      "eval_bleu": 26.816574311353513,
      "eval_gen_len": 27.443,
      "eval_loss": 2.7914609909057617,
      "eval_runtime": 58.1207,
      "eval_samples_per_second": 17.206,
      "eval_steps_per_second": 1.084,
      "step": 42450
    },
    {
      "epoch": 1.8274941895497978,
      "grad_norm": 0.9001471996307373,
      "learning_rate": 6.997903317382784e-05,
      "loss": 3.0381,
      "step": 42460
    },
    {
      "epoch": 1.8279245932684858,
      "grad_norm": 0.8336957097053528,
      "learning_rate": 6.993471337010235e-05,
      "loss": 2.9443,
      "step": 42470
    },
    {
      "epoch": 1.828354996987174,
      "grad_norm": 0.9433786869049072,
      "learning_rate": 6.989040005784924e-05,
      "loss": 3.0063,
      "step": 42480
    },
    {
      "epoch": 1.8287854007058622,
      "grad_norm": 0.9662700891494751,
      "learning_rate": 6.984609324663633e-05,
      "loss": 3.072,
      "step": 42490
    },
    {
      "epoch": 1.8292158044245501,
      "grad_norm": 0.9463089108467102,
      "learning_rate": 6.980179294603e-05,
      "loss": 2.973,
      "step": 42500
    },
    {
      "epoch": 1.8292158044245501,
      "eval_bleu": 27.317552517435885,
      "eval_gen_len": 27.516,
      "eval_loss": 2.7938668727874756,
      "eval_runtime": 58.6322,
      "eval_samples_per_second": 17.055,
      "eval_steps_per_second": 1.074,
      "step": 42500
    },
    {
      "epoch": 1.8296462081432383,
      "grad_norm": 0.9168769121170044,
      "learning_rate": 6.975749916559528e-05,
      "loss": 3.0393,
      "step": 42510
    },
    {
      "epoch": 1.8300766118619265,
      "grad_norm": 0.9427050948143005,
      "learning_rate": 6.971321191489568e-05,
      "loss": 3.0179,
      "step": 42520
    },
    {
      "epoch": 1.8305070155806145,
      "grad_norm": 0.9266546368598938,
      "learning_rate": 6.966893120349342e-05,
      "loss": 2.9725,
      "step": 42530
    },
    {
      "epoch": 1.8309374192993029,
      "grad_norm": 1.0040632486343384,
      "learning_rate": 6.962465704094926e-05,
      "loss": 2.9985,
      "step": 42540
    },
    {
      "epoch": 1.8313678230179908,
      "grad_norm": 0.8986079096794128,
      "learning_rate": 6.958038943682253e-05,
      "loss": 3.0173,
      "step": 42550
    },
    {
      "epoch": 1.8313678230179908,
      "eval_bleu": 27.186644849961603,
      "eval_gen_len": 27.595,
      "eval_loss": 2.7926552295684814,
      "eval_runtime": 58.5994,
      "eval_samples_per_second": 17.065,
      "eval_steps_per_second": 1.075,
      "step": 42550
    },
    {
      "epoch": 1.831798226736679,
      "grad_norm": 0.9314846992492676,
      "learning_rate": 6.953612840067119e-05,
      "loss": 2.9381,
      "step": 42560
    },
    {
      "epoch": 1.8322286304553672,
      "grad_norm": 0.9151734113693237,
      "learning_rate": 6.94918739420517e-05,
      "loss": 2.9678,
      "step": 42570
    },
    {
      "epoch": 1.8326590341740552,
      "grad_norm": 0.8619389533996582,
      "learning_rate": 6.944762607051921e-05,
      "loss": 3.0383,
      "step": 42580
    },
    {
      "epoch": 1.8330894378927434,
      "grad_norm": 0.9131718277931213,
      "learning_rate": 6.940338479562738e-05,
      "loss": 3.0695,
      "step": 42590
    },
    {
      "epoch": 1.8335198416114316,
      "grad_norm": 0.7319754958152771,
      "learning_rate": 6.935915012692842e-05,
      "loss": 3.0219,
      "step": 42600
    },
    {
      "epoch": 1.8335198416114316,
      "eval_bleu": 26.953123018750475,
      "eval_gen_len": 27.534,
      "eval_loss": 2.7953944206237793,
      "eval_runtime": 58.5813,
      "eval_samples_per_second": 17.07,
      "eval_steps_per_second": 1.075,
      "step": 42600
    },
    {
      "epoch": 1.8339502453301195,
      "grad_norm": 0.9163240790367126,
      "learning_rate": 6.931492207397319e-05,
      "loss": 2.9627,
      "step": 42610
    },
    {
      "epoch": 1.834380649048808,
      "grad_norm": 0.911390483379364,
      "learning_rate": 6.927070064631104e-05,
      "loss": 2.9544,
      "step": 42620
    },
    {
      "epoch": 1.834811052767496,
      "grad_norm": 0.8559903502464294,
      "learning_rate": 6.922648585348996e-05,
      "loss": 2.9235,
      "step": 42630
    },
    {
      "epoch": 1.835241456486184,
      "grad_norm": 0.8594174385070801,
      "learning_rate": 6.918227770505648e-05,
      "loss": 2.9821,
      "step": 42640
    },
    {
      "epoch": 1.8356718602048723,
      "grad_norm": 0.9883577227592468,
      "learning_rate": 6.913807621055566e-05,
      "loss": 3.0482,
      "step": 42650
    },
    {
      "epoch": 1.8356718602048723,
      "eval_bleu": 27.43134648847344,
      "eval_gen_len": 27.475,
      "eval_loss": 2.789954900741577,
      "eval_runtime": 58.5695,
      "eval_samples_per_second": 17.074,
      "eval_steps_per_second": 1.076,
      "step": 42650
    },
    {
      "epoch": 1.8361022639235602,
      "grad_norm": 0.8679730296134949,
      "learning_rate": 6.90938813795312e-05,
      "loss": 3.0446,
      "step": 42660
    },
    {
      "epoch": 1.8365326676422484,
      "grad_norm": 0.9264604449272156,
      "learning_rate": 6.904969322152533e-05,
      "loss": 3.0504,
      "step": 42670
    },
    {
      "epoch": 1.8369630713609366,
      "grad_norm": 1.0019398927688599,
      "learning_rate": 6.900551174607878e-05,
      "loss": 2.8535,
      "step": 42680
    },
    {
      "epoch": 1.8373934750796246,
      "grad_norm": 0.8918101787567139,
      "learning_rate": 6.896133696273088e-05,
      "loss": 3.0572,
      "step": 42690
    },
    {
      "epoch": 1.8378238787983128,
      "grad_norm": 0.980911374092102,
      "learning_rate": 6.891716888101957e-05,
      "loss": 3.0665,
      "step": 42700
    },
    {
      "epoch": 1.8378238787983128,
      "eval_bleu": 26.853354286071777,
      "eval_gen_len": 27.397,
      "eval_loss": 2.793956756591797,
      "eval_runtime": 58.3408,
      "eval_samples_per_second": 17.141,
      "eval_steps_per_second": 1.08,
      "step": 42700
    },
    {
      "epoch": 1.838254282517001,
      "grad_norm": 0.8786029815673828,
      "learning_rate": 6.887300751048125e-05,
      "loss": 2.9546,
      "step": 42710
    },
    {
      "epoch": 1.838684686235689,
      "grad_norm": 0.9525610208511353,
      "learning_rate": 6.882885286065093e-05,
      "loss": 3.0377,
      "step": 42720
    },
    {
      "epoch": 1.8391150899543773,
      "grad_norm": 0.9616753458976746,
      "learning_rate": 6.878470494106215e-05,
      "loss": 3.0114,
      "step": 42730
    },
    {
      "epoch": 1.8395454936730653,
      "grad_norm": 0.803525447845459,
      "learning_rate": 6.8740563761247e-05,
      "loss": 3.0122,
      "step": 42740
    },
    {
      "epoch": 1.8399758973917535,
      "grad_norm": 0.9236412048339844,
      "learning_rate": 6.869642933073614e-05,
      "loss": 3.0196,
      "step": 42750
    },
    {
      "epoch": 1.8399758973917535,
      "eval_bleu": 27.20606073988462,
      "eval_gen_len": 27.454,
      "eval_loss": 2.792682409286499,
      "eval_runtime": 59.2873,
      "eval_samples_per_second": 16.867,
      "eval_steps_per_second": 1.063,
      "step": 42750
    },
    {
      "epoch": 1.8404063011104417,
      "grad_norm": 0.8602204322814941,
      "learning_rate": 6.865230165905869e-05,
      "loss": 3.0099,
      "step": 42760
    },
    {
      "epoch": 1.8408367048291296,
      "grad_norm": 0.9392113089561462,
      "learning_rate": 6.860818075574241e-05,
      "loss": 3.02,
      "step": 42770
    },
    {
      "epoch": 1.8412671085478178,
      "grad_norm": 0.8777236938476562,
      "learning_rate": 6.856406663031355e-05,
      "loss": 3.0011,
      "step": 42780
    },
    {
      "epoch": 1.841697512266506,
      "grad_norm": 0.9700130224227905,
      "learning_rate": 6.851995929229688e-05,
      "loss": 2.9475,
      "step": 42790
    },
    {
      "epoch": 1.842127915985194,
      "grad_norm": 0.837063193321228,
      "learning_rate": 6.847585875121576e-05,
      "loss": 2.923,
      "step": 42800
    },
    {
      "epoch": 1.842127915985194,
      "eval_bleu": 27.223607855565394,
      "eval_gen_len": 27.519,
      "eval_loss": 2.791440010070801,
      "eval_runtime": 58.4939,
      "eval_samples_per_second": 17.096,
      "eval_steps_per_second": 1.077,
      "step": 42800
    },
    {
      "epoch": 1.8425583197038824,
      "grad_norm": 0.9417898654937744,
      "learning_rate": 6.843176501659205e-05,
      "loss": 3.0244,
      "step": 42810
    },
    {
      "epoch": 1.8429887234225704,
      "grad_norm": 0.873471736907959,
      "learning_rate": 6.83876780979461e-05,
      "loss": 2.996,
      "step": 42820
    },
    {
      "epoch": 1.8434191271412586,
      "grad_norm": 1.026356816291809,
      "learning_rate": 6.834359800479693e-05,
      "loss": 3.0723,
      "step": 42830
    },
    {
      "epoch": 1.8438495308599467,
      "grad_norm": 0.9434371590614319,
      "learning_rate": 6.829952474666183e-05,
      "loss": 3.0079,
      "step": 42840
    },
    {
      "epoch": 1.8442799345786347,
      "grad_norm": 0.9695672988891602,
      "learning_rate": 6.825545833305687e-05,
      "loss": 3.0323,
      "step": 42850
    },
    {
      "epoch": 1.8442799345786347,
      "eval_bleu": 27.430561723707942,
      "eval_gen_len": 27.485,
      "eval_loss": 2.788853168487549,
      "eval_runtime": 58.2697,
      "eval_samples_per_second": 17.162,
      "eval_steps_per_second": 1.081,
      "step": 42850
    },
    {
      "epoch": 1.844710338297323,
      "grad_norm": 0.9240273237228394,
      "learning_rate": 6.82113987734965e-05,
      "loss": 2.9464,
      "step": 42860
    },
    {
      "epoch": 1.845140742016011,
      "grad_norm": 0.9905587434768677,
      "learning_rate": 6.816734607749377e-05,
      "loss": 3.086,
      "step": 42870
    },
    {
      "epoch": 1.845571145734699,
      "grad_norm": 0.8980106711387634,
      "learning_rate": 6.812330025456019e-05,
      "loss": 3.0241,
      "step": 42880
    },
    {
      "epoch": 1.8460015494533872,
      "grad_norm": 1.0059397220611572,
      "learning_rate": 6.80792613142058e-05,
      "loss": 3.0739,
      "step": 42890
    },
    {
      "epoch": 1.8464319531720754,
      "grad_norm": 0.9954302310943604,
      "learning_rate": 6.803522926593917e-05,
      "loss": 2.9917,
      "step": 42900
    },
    {
      "epoch": 1.8464319531720754,
      "eval_bleu": 27.430600945789827,
      "eval_gen_len": 27.605,
      "eval_loss": 2.7918128967285156,
      "eval_runtime": 58.5552,
      "eval_samples_per_second": 17.078,
      "eval_steps_per_second": 1.076,
      "step": 42900
    },
    {
      "epoch": 1.8468623568907634,
      "grad_norm": 0.8405488729476929,
      "learning_rate": 6.799120411926735e-05,
      "loss": 2.9222,
      "step": 42910
    },
    {
      "epoch": 1.8472927606094518,
      "grad_norm": 0.881083607673645,
      "learning_rate": 6.794718588369601e-05,
      "loss": 2.8727,
      "step": 42920
    },
    {
      "epoch": 1.8477231643281398,
      "grad_norm": 0.9511509537696838,
      "learning_rate": 6.790317456872912e-05,
      "loss": 3.0451,
      "step": 42930
    },
    {
      "epoch": 1.848153568046828,
      "grad_norm": 0.8877004981040955,
      "learning_rate": 6.785917018386932e-05,
      "loss": 3.0667,
      "step": 42940
    },
    {
      "epoch": 1.8485839717655161,
      "grad_norm": 0.9088542461395264,
      "learning_rate": 6.781517273861771e-05,
      "loss": 3.0205,
      "step": 42950
    },
    {
      "epoch": 1.8485839717655161,
      "eval_bleu": 27.254702746448157,
      "eval_gen_len": 27.552,
      "eval_loss": 2.7937982082366943,
      "eval_runtime": 58.1737,
      "eval_samples_per_second": 17.19,
      "eval_steps_per_second": 1.083,
      "step": 42950
    },
    {
      "epoch": 1.849014375484204,
      "grad_norm": 0.9128000140190125,
      "learning_rate": 6.777118224247385e-05,
      "loss": 2.9488,
      "step": 42960
    },
    {
      "epoch": 1.8494447792028923,
      "grad_norm": 0.9877251982688904,
      "learning_rate": 6.772719870493593e-05,
      "loss": 3.0487,
      "step": 42970
    },
    {
      "epoch": 1.8498751829215805,
      "grad_norm": 0.9423259496688843,
      "learning_rate": 6.768322213550047e-05,
      "loss": 3.1038,
      "step": 42980
    },
    {
      "epoch": 1.8503055866402685,
      "grad_norm": 0.9756196737289429,
      "learning_rate": 6.763925254366261e-05,
      "loss": 3.0934,
      "step": 42990
    },
    {
      "epoch": 1.8507359903589569,
      "grad_norm": 0.9314711093902588,
      "learning_rate": 6.759528993891597e-05,
      "loss": 3.1058,
      "step": 43000
    },
    {
      "epoch": 1.8507359903589569,
      "eval_bleu": 27.251775143780865,
      "eval_gen_len": 27.6,
      "eval_loss": 2.790689706802368,
      "eval_runtime": 58.6512,
      "eval_samples_per_second": 17.05,
      "eval_steps_per_second": 1.074,
      "step": 43000
    },
    {
      "epoch": 1.8511663940776448,
      "grad_norm": 0.8983038663864136,
      "learning_rate": 6.755133433075251e-05,
      "loss": 3.0569,
      "step": 43010
    },
    {
      "epoch": 1.8515967977963328,
      "grad_norm": 0.9523520469665527,
      "learning_rate": 6.750738572866287e-05,
      "loss": 3.0652,
      "step": 43020
    },
    {
      "epoch": 1.8520272015150212,
      "grad_norm": 0.8695054650306702,
      "learning_rate": 6.74634441421361e-05,
      "loss": 3.0784,
      "step": 43030
    },
    {
      "epoch": 1.8524576052337092,
      "grad_norm": 0.930590033531189,
      "learning_rate": 6.741950958065972e-05,
      "loss": 3.004,
      "step": 43040
    },
    {
      "epoch": 1.8528880089523974,
      "grad_norm": 0.9153612852096558,
      "learning_rate": 6.737558205371978e-05,
      "loss": 2.9754,
      "step": 43050
    },
    {
      "epoch": 1.8528880089523974,
      "eval_bleu": 27.422160966152234,
      "eval_gen_len": 27.565,
      "eval_loss": 2.7898311614990234,
      "eval_runtime": 59.0965,
      "eval_samples_per_second": 16.921,
      "eval_steps_per_second": 1.066,
      "step": 43050
    },
    {
      "epoch": 1.8533184126710855,
      "grad_norm": 0.9501127004623413,
      "learning_rate": 6.733166157080076e-05,
      "loss": 3.0899,
      "step": 43060
    },
    {
      "epoch": 1.8537488163897735,
      "grad_norm": 0.9079563021659851,
      "learning_rate": 6.728774814138566e-05,
      "loss": 3.0985,
      "step": 43070
    },
    {
      "epoch": 1.8541792201084617,
      "grad_norm": 0.9576320648193359,
      "learning_rate": 6.724384177495598e-05,
      "loss": 2.9777,
      "step": 43080
    },
    {
      "epoch": 1.85460962382715,
      "grad_norm": 0.8694924116134644,
      "learning_rate": 6.719994248099157e-05,
      "loss": 3.0245,
      "step": 43090
    },
    {
      "epoch": 1.8550400275458379,
      "grad_norm": 1.057443380355835,
      "learning_rate": 6.715605026897089e-05,
      "loss": 2.9991,
      "step": 43100
    },
    {
      "epoch": 1.8550400275458379,
      "eval_bleu": 27.246887261608617,
      "eval_gen_len": 27.584,
      "eval_loss": 2.791470766067505,
      "eval_runtime": 58.8125,
      "eval_samples_per_second": 17.003,
      "eval_steps_per_second": 1.071,
      "step": 43100
    },
    {
      "epoch": 1.8554704312645263,
      "grad_norm": 0.8554757237434387,
      "learning_rate": 6.71121651483708e-05,
      "loss": 2.9762,
      "step": 43110
    },
    {
      "epoch": 1.8559008349832142,
      "grad_norm": 1.109671950340271,
      "learning_rate": 6.706828712866664e-05,
      "loss": 3.0139,
      "step": 43120
    },
    {
      "epoch": 1.8563312387019024,
      "grad_norm": 0.84861820936203,
      "learning_rate": 6.702441621933226e-05,
      "loss": 2.9592,
      "step": 43130
    },
    {
      "epoch": 1.8567616424205906,
      "grad_norm": 0.9916030764579773,
      "learning_rate": 6.698055242983991e-05,
      "loss": 2.9762,
      "step": 43140
    },
    {
      "epoch": 1.8571920461392786,
      "grad_norm": 0.9438040256500244,
      "learning_rate": 6.693669576966034e-05,
      "loss": 3.0106,
      "step": 43150
    },
    {
      "epoch": 1.8571920461392786,
      "eval_bleu": 26.82675125288301,
      "eval_gen_len": 27.484,
      "eval_loss": 2.793290615081787,
      "eval_runtime": 58.6084,
      "eval_samples_per_second": 17.062,
      "eval_steps_per_second": 1.075,
      "step": 43150
    },
    {
      "epoch": 1.8576224498579668,
      "grad_norm": 0.8358527421951294,
      "learning_rate": 6.689284624826277e-05,
      "loss": 3.0437,
      "step": 43160
    },
    {
      "epoch": 1.858052853576655,
      "grad_norm": 0.874862015247345,
      "learning_rate": 6.684900387511484e-05,
      "loss": 2.9861,
      "step": 43170
    },
    {
      "epoch": 1.858483257295343,
      "grad_norm": 0.889656662940979,
      "learning_rate": 6.680516865968268e-05,
      "loss": 3.0257,
      "step": 43180
    },
    {
      "epoch": 1.8589136610140313,
      "grad_norm": 0.9594222903251648,
      "learning_rate": 6.676134061143083e-05,
      "loss": 3.0948,
      "step": 43190
    },
    {
      "epoch": 1.8593440647327193,
      "grad_norm": 0.9013717174530029,
      "learning_rate": 6.671751973982237e-05,
      "loss": 3.018,
      "step": 43200
    },
    {
      "epoch": 1.8593440647327193,
      "eval_bleu": 27.22285052456047,
      "eval_gen_len": 27.534,
      "eval_loss": 2.790203809738159,
      "eval_runtime": 58.4635,
      "eval_samples_per_second": 17.105,
      "eval_steps_per_second": 1.078,
      "step": 43200
    },
    {
      "epoch": 1.8597744684514073,
      "grad_norm": 0.8459976315498352,
      "learning_rate": 6.667370605431872e-05,
      "loss": 2.9821,
      "step": 43210
    },
    {
      "epoch": 1.8602048721700957,
      "grad_norm": 0.8342303037643433,
      "learning_rate": 6.662989956437984e-05,
      "loss": 2.9473,
      "step": 43220
    },
    {
      "epoch": 1.8606352758887836,
      "grad_norm": 0.9285160899162292,
      "learning_rate": 6.65861002794641e-05,
      "loss": 3.1235,
      "step": 43230
    },
    {
      "epoch": 1.8610656796074718,
      "grad_norm": 0.8869709372520447,
      "learning_rate": 6.654230820902833e-05,
      "loss": 2.9644,
      "step": 43240
    },
    {
      "epoch": 1.86149608332616,
      "grad_norm": 0.922981321811676,
      "learning_rate": 6.649852336252773e-05,
      "loss": 3.0459,
      "step": 43250
    },
    {
      "epoch": 1.86149608332616,
      "eval_bleu": 27.077251001767802,
      "eval_gen_len": 27.449,
      "eval_loss": 2.7909934520721436,
      "eval_runtime": 58.6441,
      "eval_samples_per_second": 17.052,
      "eval_steps_per_second": 1.074,
      "step": 43250
    },
    {
      "epoch": 1.861926487044848,
      "grad_norm": 0.9932490587234497,
      "learning_rate": 6.645474574941603e-05,
      "loss": 3.0279,
      "step": 43260
    },
    {
      "epoch": 1.8623568907635362,
      "grad_norm": 0.8837926983833313,
      "learning_rate": 6.641097537914538e-05,
      "loss": 2.9992,
      "step": 43270
    },
    {
      "epoch": 1.8627872944822244,
      "grad_norm": 0.9069603085517883,
      "learning_rate": 6.636721226116634e-05,
      "loss": 3.1108,
      "step": 43280
    },
    {
      "epoch": 1.8632176982009123,
      "grad_norm": 0.889778196811676,
      "learning_rate": 6.632345640492791e-05,
      "loss": 2.9741,
      "step": 43290
    },
    {
      "epoch": 1.8636481019196007,
      "grad_norm": 0.8801778554916382,
      "learning_rate": 6.627970781987753e-05,
      "loss": 2.994,
      "step": 43300
    },
    {
      "epoch": 1.8636481019196007,
      "eval_bleu": 27.222700853364096,
      "eval_gen_len": 27.504,
      "eval_loss": 2.792705774307251,
      "eval_runtime": 58.3316,
      "eval_samples_per_second": 17.143,
      "eval_steps_per_second": 1.08,
      "step": 43300
    },
    {
      "epoch": 1.8640785056382887,
      "grad_norm": 0.937111496925354,
      "learning_rate": 6.623596651546107e-05,
      "loss": 3.0653,
      "step": 43310
    },
    {
      "epoch": 1.8645089093569769,
      "grad_norm": 0.9225414991378784,
      "learning_rate": 6.619223250112285e-05,
      "loss": 3.0618,
      "step": 43320
    },
    {
      "epoch": 1.864939313075665,
      "grad_norm": 0.9340476393699646,
      "learning_rate": 6.614850578630556e-05,
      "loss": 3.0774,
      "step": 43330
    },
    {
      "epoch": 1.865369716794353,
      "grad_norm": 0.8087112307548523,
      "learning_rate": 6.610478638045034e-05,
      "loss": 2.9641,
      "step": 43340
    },
    {
      "epoch": 1.8658001205130412,
      "grad_norm": 0.9073557257652283,
      "learning_rate": 6.606107429299677e-05,
      "loss": 3.047,
      "step": 43350
    },
    {
      "epoch": 1.8658001205130412,
      "eval_bleu": 27.486131091023022,
      "eval_gen_len": 27.586,
      "eval_loss": 2.7913849353790283,
      "eval_runtime": 58.4671,
      "eval_samples_per_second": 17.104,
      "eval_steps_per_second": 1.078,
      "step": 43350
    },
    {
      "epoch": 1.8662305242317294,
      "grad_norm": 0.9557740092277527,
      "learning_rate": 6.601736953338286e-05,
      "loss": 3.0185,
      "step": 43360
    },
    {
      "epoch": 1.8666609279504174,
      "grad_norm": 0.9859885573387146,
      "learning_rate": 6.597367211104499e-05,
      "loss": 2.9903,
      "step": 43370
    },
    {
      "epoch": 1.8670913316691056,
      "grad_norm": 0.8236739039421082,
      "learning_rate": 6.592998203541798e-05,
      "loss": 2.9547,
      "step": 43380
    },
    {
      "epoch": 1.8675217353877938,
      "grad_norm": 1.1408830881118774,
      "learning_rate": 6.588629931593507e-05,
      "loss": 3.0221,
      "step": 43390
    },
    {
      "epoch": 1.8679521391064817,
      "grad_norm": 0.9710270166397095,
      "learning_rate": 6.584262396202794e-05,
      "loss": 2.9518,
      "step": 43400
    },
    {
      "epoch": 1.8679521391064817,
      "eval_bleu": 27.427320973288058,
      "eval_gen_len": 27.435,
      "eval_loss": 2.7899839878082275,
      "eval_runtime": 57.7852,
      "eval_samples_per_second": 17.305,
      "eval_steps_per_second": 1.09,
      "step": 43400
    },
    {
      "epoch": 1.8683825428251701,
      "grad_norm": 0.8945155143737793,
      "learning_rate": 6.57989559831266e-05,
      "loss": 3.0251,
      "step": 43410
    },
    {
      "epoch": 1.868812946543858,
      "grad_norm": 0.9527918696403503,
      "learning_rate": 6.575529538865952e-05,
      "loss": 2.9686,
      "step": 43420
    },
    {
      "epoch": 1.8692433502625463,
      "grad_norm": 0.8785478472709656,
      "learning_rate": 6.571164218805358e-05,
      "loss": 3.0218,
      "step": 43430
    },
    {
      "epoch": 1.8696737539812345,
      "grad_norm": 0.9753687381744385,
      "learning_rate": 6.566799639073406e-05,
      "loss": 2.9617,
      "step": 43440
    },
    {
      "epoch": 1.8701041576999224,
      "grad_norm": 1.0860692262649536,
      "learning_rate": 6.562435800612463e-05,
      "loss": 2.9697,
      "step": 43450
    },
    {
      "epoch": 1.8701041576999224,
      "eval_bleu": 27.411224541405776,
      "eval_gen_len": 27.565,
      "eval_loss": 2.7906301021575928,
      "eval_runtime": 59.287,
      "eval_samples_per_second": 16.867,
      "eval_steps_per_second": 1.063,
      "step": 43450
    },
    {
      "epoch": 1.8705345614186106,
      "grad_norm": 0.9715517163276672,
      "learning_rate": 6.558072704364738e-05,
      "loss": 3.0568,
      "step": 43460
    },
    {
      "epoch": 1.8709649651372988,
      "grad_norm": 0.8947101831436157,
      "learning_rate": 6.553710351272273e-05,
      "loss": 2.9664,
      "step": 43470
    },
    {
      "epoch": 1.8713953688559868,
      "grad_norm": 1.0115712881088257,
      "learning_rate": 6.549348742276964e-05,
      "loss": 3.0569,
      "step": 43480
    },
    {
      "epoch": 1.8718257725746752,
      "grad_norm": 0.8964008688926697,
      "learning_rate": 6.544987878320527e-05,
      "loss": 3.0328,
      "step": 43490
    },
    {
      "epoch": 1.8722561762933632,
      "grad_norm": 0.8532477021217346,
      "learning_rate": 6.540627760344531e-05,
      "loss": 3.0585,
      "step": 43500
    },
    {
      "epoch": 1.8722561762933632,
      "eval_bleu": 27.098226364353046,
      "eval_gen_len": 27.444,
      "eval_loss": 2.7882637977600098,
      "eval_runtime": 58.1506,
      "eval_samples_per_second": 17.197,
      "eval_steps_per_second": 1.083,
      "step": 43500
    },
    {
      "epoch": 1.8726865800120513,
      "grad_norm": 0.8403991460800171,
      "learning_rate": 6.536268389290382e-05,
      "loss": 3.0164,
      "step": 43510
    },
    {
      "epoch": 1.8731169837307395,
      "grad_norm": 0.8799986839294434,
      "learning_rate": 6.531909766099323e-05,
      "loss": 3.0034,
      "step": 43520
    },
    {
      "epoch": 1.8735473874494275,
      "grad_norm": 0.9081835746765137,
      "learning_rate": 6.527551891712432e-05,
      "loss": 2.9857,
      "step": 43530
    },
    {
      "epoch": 1.8739777911681157,
      "grad_norm": 0.7825701236724854,
      "learning_rate": 6.523194767070631e-05,
      "loss": 2.9385,
      "step": 43540
    },
    {
      "epoch": 1.8744081948868039,
      "grad_norm": 0.8823920488357544,
      "learning_rate": 6.518838393114676e-05,
      "loss": 2.9707,
      "step": 43550
    },
    {
      "epoch": 1.8744081948868039,
      "eval_bleu": 27.20584184243293,
      "eval_gen_len": 27.463,
      "eval_loss": 2.790799617767334,
      "eval_runtime": 58.9802,
      "eval_samples_per_second": 16.955,
      "eval_steps_per_second": 1.068,
      "step": 43550
    },
    {
      "epoch": 1.8748385986054918,
      "grad_norm": 0.9048240780830383,
      "learning_rate": 6.514482770785167e-05,
      "loss": 3.0246,
      "step": 43560
    },
    {
      "epoch": 1.87526900232418,
      "grad_norm": 0.8919476270675659,
      "learning_rate": 6.510127901022538e-05,
      "loss": 2.938,
      "step": 43570
    },
    {
      "epoch": 1.8756994060428682,
      "grad_norm": 0.9232339859008789,
      "learning_rate": 6.505773784767053e-05,
      "loss": 3.0285,
      "step": 43580
    },
    {
      "epoch": 1.8761298097615562,
      "grad_norm": 0.9816774129867554,
      "learning_rate": 6.501420422958822e-05,
      "loss": 2.9789,
      "step": 43590
    },
    {
      "epoch": 1.8765602134802446,
      "grad_norm": 0.857042670249939,
      "learning_rate": 6.497067816537794e-05,
      "loss": 2.9785,
      "step": 43600
    },
    {
      "epoch": 1.8765602134802446,
      "eval_bleu": 27.110072611212484,
      "eval_gen_len": 27.559,
      "eval_loss": 2.7916886806488037,
      "eval_runtime": 58.6343,
      "eval_samples_per_second": 17.055,
      "eval_steps_per_second": 1.074,
      "step": 43600
    },
    {
      "epoch": 1.8769906171989326,
      "grad_norm": 1.0674232244491577,
      "learning_rate": 6.49271596644375e-05,
      "loss": 3.0561,
      "step": 43610
    },
    {
      "epoch": 1.8774210209176208,
      "grad_norm": 0.862714409828186,
      "learning_rate": 6.488364873616308e-05,
      "loss": 3.0145,
      "step": 43620
    },
    {
      "epoch": 1.877851424636309,
      "grad_norm": 0.9566070437431335,
      "learning_rate": 6.484014538994925e-05,
      "loss": 3.1336,
      "step": 43630
    },
    {
      "epoch": 1.878281828354997,
      "grad_norm": 0.9304361343383789,
      "learning_rate": 6.479664963518893e-05,
      "loss": 3.0191,
      "step": 43640
    },
    {
      "epoch": 1.878712232073685,
      "grad_norm": 0.9735286235809326,
      "learning_rate": 6.475316148127342e-05,
      "loss": 2.8866,
      "step": 43650
    },
    {
      "epoch": 1.878712232073685,
      "eval_bleu": 27.43774510922656,
      "eval_gen_len": 27.585,
      "eval_loss": 2.788553237915039,
      "eval_runtime": 58.4173,
      "eval_samples_per_second": 17.118,
      "eval_steps_per_second": 1.078,
      "step": 43650
    },
    {
      "epoch": 1.8791426357923733,
      "grad_norm": 0.8984510898590088,
      "learning_rate": 6.470968093759229e-05,
      "loss": 2.8759,
      "step": 43660
    },
    {
      "epoch": 1.8795730395110612,
      "grad_norm": 0.8884994983673096,
      "learning_rate": 6.466620801353357e-05,
      "loss": 3.0124,
      "step": 43670
    },
    {
      "epoch": 1.8800034432297497,
      "grad_norm": 0.8261617422103882,
      "learning_rate": 6.46227427184836e-05,
      "loss": 3.0116,
      "step": 43680
    },
    {
      "epoch": 1.8804338469484376,
      "grad_norm": 0.9876847863197327,
      "learning_rate": 6.457928506182711e-05,
      "loss": 3.064,
      "step": 43690
    },
    {
      "epoch": 1.8808642506671258,
      "grad_norm": 0.9253864288330078,
      "learning_rate": 6.453583505294714e-05,
      "loss": 3.0171,
      "step": 43700
    },
    {
      "epoch": 1.8808642506671258,
      "eval_bleu": 27.40336193575267,
      "eval_gen_len": 27.565,
      "eval_loss": 2.789151191711426,
      "eval_runtime": 58.6151,
      "eval_samples_per_second": 17.06,
      "eval_steps_per_second": 1.075,
      "step": 43700
    },
    {
      "epoch": 1.881294654385814,
      "grad_norm": 0.8779841065406799,
      "learning_rate": 6.449239270122507e-05,
      "loss": 3.0329,
      "step": 43710
    },
    {
      "epoch": 1.881725058104502,
      "grad_norm": 0.853253960609436,
      "learning_rate": 6.44489580160407e-05,
      "loss": 3.0193,
      "step": 43720
    },
    {
      "epoch": 1.8821554618231902,
      "grad_norm": 0.8312240242958069,
      "learning_rate": 6.44055310067721e-05,
      "loss": 2.985,
      "step": 43730
    },
    {
      "epoch": 1.8825858655418783,
      "grad_norm": 0.8731015920639038,
      "learning_rate": 6.436211168279567e-05,
      "loss": 3.0865,
      "step": 43740
    },
    {
      "epoch": 1.8830162692605663,
      "grad_norm": 0.9497819542884827,
      "learning_rate": 6.431870005348621e-05,
      "loss": 2.9539,
      "step": 43750
    },
    {
      "epoch": 1.8830162692605663,
      "eval_bleu": 27.266141337748163,
      "eval_gen_len": 27.429,
      "eval_loss": 2.79109263420105,
      "eval_runtime": 58.418,
      "eval_samples_per_second": 17.118,
      "eval_steps_per_second": 1.078,
      "step": 43750
    },
    {
      "epoch": 1.8834466729792545,
      "grad_norm": 0.8899874091148376,
      "learning_rate": 6.427529612821684e-05,
      "loss": 2.951,
      "step": 43760
    },
    {
      "epoch": 1.8838770766979427,
      "grad_norm": 0.9542802572250366,
      "learning_rate": 6.4231899916359e-05,
      "loss": 3.0574,
      "step": 43770
    },
    {
      "epoch": 1.8843074804166307,
      "grad_norm": 0.8898361921310425,
      "learning_rate": 6.418851142728251e-05,
      "loss": 3.1083,
      "step": 43780
    },
    {
      "epoch": 1.884737884135319,
      "grad_norm": 0.9366046786308289,
      "learning_rate": 6.414513067035544e-05,
      "loss": 2.912,
      "step": 43790
    },
    {
      "epoch": 1.885168287854007,
      "grad_norm": 0.7851076722145081,
      "learning_rate": 6.410175765494426e-05,
      "loss": 3.0868,
      "step": 43800
    },
    {
      "epoch": 1.885168287854007,
      "eval_bleu": 27.305920852225707,
      "eval_gen_len": 27.706,
      "eval_loss": 2.790348529815674,
      "eval_runtime": 61.4312,
      "eval_samples_per_second": 16.278,
      "eval_steps_per_second": 1.026,
      "step": 43800
    },
    {
      "epoch": 1.8855986915726952,
      "grad_norm": 0.8107263445854187,
      "learning_rate": 6.405839239041381e-05,
      "loss": 2.9929,
      "step": 43810
    },
    {
      "epoch": 1.8860290952913834,
      "grad_norm": 0.9287346601486206,
      "learning_rate": 6.40150348861271e-05,
      "loss": 3.0491,
      "step": 43820
    },
    {
      "epoch": 1.8864594990100714,
      "grad_norm": 0.8324617743492126,
      "learning_rate": 6.397168515144558e-05,
      "loss": 3.0659,
      "step": 43830
    },
    {
      "epoch": 1.8868899027287596,
      "grad_norm": 0.9692268371582031,
      "learning_rate": 6.392834319572903e-05,
      "loss": 3.1263,
      "step": 43840
    },
    {
      "epoch": 1.8873203064474477,
      "grad_norm": 0.9368258714675903,
      "learning_rate": 6.388500902833551e-05,
      "loss": 2.9951,
      "step": 43850
    },
    {
      "epoch": 1.8873203064474477,
      "eval_bleu": 27.46921837874517,
      "eval_gen_len": 27.535,
      "eval_loss": 2.790971279144287,
      "eval_runtime": 58.425,
      "eval_samples_per_second": 17.116,
      "eval_steps_per_second": 1.078,
      "step": 43850
    },
    {
      "epoch": 1.8877507101661357,
      "grad_norm": 1.0155225992202759,
      "learning_rate": 6.38416826586214e-05,
      "loss": 3.0755,
      "step": 43860
    },
    {
      "epoch": 1.8881811138848241,
      "grad_norm": 0.7677608728408813,
      "learning_rate": 6.379836409594143e-05,
      "loss": 3.0284,
      "step": 43870
    },
    {
      "epoch": 1.888611517603512,
      "grad_norm": 0.8732010126113892,
      "learning_rate": 6.375505334964858e-05,
      "loss": 3.0238,
      "step": 43880
    },
    {
      "epoch": 1.8890419213222003,
      "grad_norm": 0.9363083839416504,
      "learning_rate": 6.371175042909426e-05,
      "loss": 3.0252,
      "step": 43890
    },
    {
      "epoch": 1.8894723250408885,
      "grad_norm": 0.8833836317062378,
      "learning_rate": 6.366845534362802e-05,
      "loss": 3.0077,
      "step": 43900
    },
    {
      "epoch": 1.8894723250408885,
      "eval_bleu": 27.427695047663633,
      "eval_gen_len": 27.553,
      "eval_loss": 2.7891201972961426,
      "eval_runtime": 58.6162,
      "eval_samples_per_second": 17.06,
      "eval_steps_per_second": 1.075,
      "step": 43900
    },
    {
      "epoch": 1.8899027287595764,
      "grad_norm": 1.0168795585632324,
      "learning_rate": 6.362516810259786e-05,
      "loss": 3.0946,
      "step": 43910
    },
    {
      "epoch": 1.8903331324782646,
      "grad_norm": 0.9293899536132812,
      "learning_rate": 6.358188871535002e-05,
      "loss": 3.0838,
      "step": 43920
    },
    {
      "epoch": 1.8907635361969528,
      "grad_norm": 0.9971051812171936,
      "learning_rate": 6.35386171912291e-05,
      "loss": 3.0489,
      "step": 43930
    },
    {
      "epoch": 1.8911939399156408,
      "grad_norm": 0.95255047082901,
      "learning_rate": 6.349535353957793e-05,
      "loss": 3.0367,
      "step": 43940
    },
    {
      "epoch": 1.891624343634329,
      "grad_norm": 0.9217654466629028,
      "learning_rate": 6.345209776973769e-05,
      "loss": 3.0602,
      "step": 43950
    },
    {
      "epoch": 1.891624343634329,
      "eval_bleu": 27.388588084474492,
      "eval_gen_len": 27.513,
      "eval_loss": 2.7868776321411133,
      "eval_runtime": 58.7948,
      "eval_samples_per_second": 17.008,
      "eval_steps_per_second": 1.072,
      "step": 43950
    },
    {
      "epoch": 1.8920547473530172,
      "grad_norm": 1.0410614013671875,
      "learning_rate": 6.340884989104782e-05,
      "loss": 3.0386,
      "step": 43960
    },
    {
      "epoch": 1.8924851510717051,
      "grad_norm": 0.8301406502723694,
      "learning_rate": 6.336560991284614e-05,
      "loss": 2.8792,
      "step": 43970
    },
    {
      "epoch": 1.8929155547903935,
      "grad_norm": 0.8398953676223755,
      "learning_rate": 6.332237784446863e-05,
      "loss": 2.928,
      "step": 43980
    },
    {
      "epoch": 1.8933459585090815,
      "grad_norm": 0.9911681413650513,
      "learning_rate": 6.327915369524966e-05,
      "loss": 3.0324,
      "step": 43990
    },
    {
      "epoch": 1.8937763622277697,
      "grad_norm": 0.8344956636428833,
      "learning_rate": 6.323593747452188e-05,
      "loss": 3.0564,
      "step": 44000
    },
    {
      "epoch": 1.8937763622277697,
      "eval_bleu": 27.332773245848315,
      "eval_gen_len": 27.529,
      "eval_loss": 2.786945104598999,
      "eval_runtime": 58.505,
      "eval_samples_per_second": 17.093,
      "eval_steps_per_second": 1.077,
      "step": 44000
    },
    {
      "epoch": 1.8942067659464579,
      "grad_norm": 0.9341222047805786,
      "learning_rate": 6.31927291916162e-05,
      "loss": 3.0338,
      "step": 44010
    },
    {
      "epoch": 1.8946371696651458,
      "grad_norm": 0.8863925933837891,
      "learning_rate": 6.314952885586186e-05,
      "loss": 2.9419,
      "step": 44020
    },
    {
      "epoch": 1.895067573383834,
      "grad_norm": 0.9403852224349976,
      "learning_rate": 6.31063364765863e-05,
      "loss": 3.0307,
      "step": 44030
    },
    {
      "epoch": 1.8954979771025222,
      "grad_norm": 0.8577350974082947,
      "learning_rate": 6.306315206311534e-05,
      "loss": 2.9392,
      "step": 44040
    },
    {
      "epoch": 1.8959283808212102,
      "grad_norm": 0.8719229698181152,
      "learning_rate": 6.301997562477304e-05,
      "loss": 2.9861,
      "step": 44050
    },
    {
      "epoch": 1.8959283808212102,
      "eval_bleu": 27.227747711562742,
      "eval_gen_len": 27.502,
      "eval_loss": 2.7911593914031982,
      "eval_runtime": 58.993,
      "eval_samples_per_second": 16.951,
      "eval_steps_per_second": 1.068,
      "step": 44050
    },
    {
      "epoch": 1.8963587845398986,
      "grad_norm": 0.9428937435150146,
      "learning_rate": 6.29768071708817e-05,
      "loss": 3.0567,
      "step": 44060
    },
    {
      "epoch": 1.8967891882585866,
      "grad_norm": 0.9100079536437988,
      "learning_rate": 6.293364671076196e-05,
      "loss": 3.0581,
      "step": 44070
    },
    {
      "epoch": 1.8972195919772745,
      "grad_norm": 0.9536827802658081,
      "learning_rate": 6.289049425373267e-05,
      "loss": 2.9693,
      "step": 44080
    },
    {
      "epoch": 1.897649995695963,
      "grad_norm": 0.944320023059845,
      "learning_rate": 6.284734980911102e-05,
      "loss": 2.9343,
      "step": 44090
    },
    {
      "epoch": 1.898080399414651,
      "grad_norm": 1.0291324853897095,
      "learning_rate": 6.280421338621243e-05,
      "loss": 3.0772,
      "step": 44100
    },
    {
      "epoch": 1.898080399414651,
      "eval_bleu": 26.864353768389815,
      "eval_gen_len": 27.687,
      "eval_loss": 2.790922164916992,
      "eval_runtime": 62.1927,
      "eval_samples_per_second": 16.079,
      "eval_steps_per_second": 1.013,
      "step": 44100
    },
    {
      "epoch": 1.898510803133339,
      "grad_norm": 0.8641563653945923,
      "learning_rate": 6.276108499435058e-05,
      "loss": 3.0389,
      "step": 44110
    },
    {
      "epoch": 1.8989412068520273,
      "grad_norm": 0.9437025189399719,
      "learning_rate": 6.271796464283745e-05,
      "loss": 2.9777,
      "step": 44120
    },
    {
      "epoch": 1.8993716105707152,
      "grad_norm": 0.9830185770988464,
      "learning_rate": 6.267485234098326e-05,
      "loss": 3.0061,
      "step": 44130
    },
    {
      "epoch": 1.8998020142894034,
      "grad_norm": 0.9157236218452454,
      "learning_rate": 6.26317480980965e-05,
      "loss": 2.9756,
      "step": 44140
    },
    {
      "epoch": 1.9002324180080916,
      "grad_norm": 1.0813411474227905,
      "learning_rate": 6.258865192348388e-05,
      "loss": 3.054,
      "step": 44150
    },
    {
      "epoch": 1.9002324180080916,
      "eval_bleu": 27.463573320267752,
      "eval_gen_len": 27.581,
      "eval_loss": 2.78932523727417,
      "eval_runtime": 59.0694,
      "eval_samples_per_second": 16.929,
      "eval_steps_per_second": 1.067,
      "step": 44150
    },
    {
      "epoch": 1.9006628217267796,
      "grad_norm": 0.8654157519340515,
      "learning_rate": 6.254556382645047e-05,
      "loss": 2.9478,
      "step": 44160
    },
    {
      "epoch": 1.901093225445468,
      "grad_norm": 0.8514381647109985,
      "learning_rate": 6.250248381629946e-05,
      "loss": 2.9566,
      "step": 44170
    },
    {
      "epoch": 1.901523629164156,
      "grad_norm": 0.9359034895896912,
      "learning_rate": 6.245941190233243e-05,
      "loss": 3.0838,
      "step": 44180
    },
    {
      "epoch": 1.9019540328828441,
      "grad_norm": 0.881006121635437,
      "learning_rate": 6.241634809384908e-05,
      "loss": 3.0215,
      "step": 44190
    },
    {
      "epoch": 1.9023844366015323,
      "grad_norm": 1.0204969644546509,
      "learning_rate": 6.237329240014748e-05,
      "loss": 3.0246,
      "step": 44200
    },
    {
      "epoch": 1.9023844366015323,
      "eval_bleu": 27.34159497896767,
      "eval_gen_len": 27.689,
      "eval_loss": 2.7874181270599365,
      "eval_runtime": 60.905,
      "eval_samples_per_second": 16.419,
      "eval_steps_per_second": 1.034,
      "step": 44200
    },
    {
      "epoch": 1.9028148403202203,
      "grad_norm": 0.978186309337616,
      "learning_rate": 6.233024483052386e-05,
      "loss": 2.9272,
      "step": 44210
    },
    {
      "epoch": 1.9032452440389085,
      "grad_norm": 0.9103866815567017,
      "learning_rate": 6.228720539427278e-05,
      "loss": 2.9593,
      "step": 44220
    },
    {
      "epoch": 1.9036756477575967,
      "grad_norm": 0.9765832424163818,
      "learning_rate": 6.224417410068695e-05,
      "loss": 3.0012,
      "step": 44230
    },
    {
      "epoch": 1.9041060514762846,
      "grad_norm": 0.9241016507148743,
      "learning_rate": 6.220115095905734e-05,
      "loss": 2.9632,
      "step": 44240
    },
    {
      "epoch": 1.9045364551949728,
      "grad_norm": 0.9141467213630676,
      "learning_rate": 6.215813597867325e-05,
      "loss": 3.0251,
      "step": 44250
    },
    {
      "epoch": 1.9045364551949728,
      "eval_bleu": 27.11800203503819,
      "eval_gen_len": 27.56,
      "eval_loss": 2.7888920307159424,
      "eval_runtime": 58.4763,
      "eval_samples_per_second": 17.101,
      "eval_steps_per_second": 1.077,
      "step": 44250
    },
    {
      "epoch": 1.904966858913661,
      "grad_norm": 0.863972008228302,
      "learning_rate": 6.211512916882212e-05,
      "loss": 3.0075,
      "step": 44260
    },
    {
      "epoch": 1.905397262632349,
      "grad_norm": 0.8564783930778503,
      "learning_rate": 6.207213053878966e-05,
      "loss": 3.0522,
      "step": 44270
    },
    {
      "epoch": 1.9058276663510374,
      "grad_norm": 0.9595956802368164,
      "learning_rate": 6.202914009785981e-05,
      "loss": 2.9865,
      "step": 44280
    },
    {
      "epoch": 1.9062580700697254,
      "grad_norm": 1.025160789489746,
      "learning_rate": 6.198615785531477e-05,
      "loss": 3.0069,
      "step": 44290
    },
    {
      "epoch": 1.9066884737884136,
      "grad_norm": 0.9178053736686707,
      "learning_rate": 6.194318382043495e-05,
      "loss": 3.0,
      "step": 44300
    },
    {
      "epoch": 1.9066884737884136,
      "eval_bleu": 27.314468730312914,
      "eval_gen_len": 27.517,
      "eval_loss": 2.7907509803771973,
      "eval_runtime": 59.5892,
      "eval_samples_per_second": 16.782,
      "eval_steps_per_second": 1.057,
      "step": 44300
    },
    {
      "epoch": 1.9071188775071017,
      "grad_norm": 0.9056758284568787,
      "learning_rate": 6.190021800249892e-05,
      "loss": 3.037,
      "step": 44310
    },
    {
      "epoch": 1.9075492812257897,
      "grad_norm": 0.8541103601455688,
      "learning_rate": 6.185726041078357e-05,
      "loss": 3.0449,
      "step": 44320
    },
    {
      "epoch": 1.907979684944478,
      "grad_norm": 0.9535031318664551,
      "learning_rate": 6.181431105456401e-05,
      "loss": 2.9737,
      "step": 44330
    },
    {
      "epoch": 1.908410088663166,
      "grad_norm": 0.9858719110488892,
      "learning_rate": 6.177136994311353e-05,
      "loss": 3.0653,
      "step": 44340
    },
    {
      "epoch": 1.908840492381854,
      "grad_norm": 0.8550224900245667,
      "learning_rate": 6.172843708570365e-05,
      "loss": 3.0194,
      "step": 44350
    },
    {
      "epoch": 1.908840492381854,
      "eval_bleu": 27.439336147715853,
      "eval_gen_len": 27.555,
      "eval_loss": 2.7910280227661133,
      "eval_runtime": 59.1554,
      "eval_samples_per_second": 16.905,
      "eval_steps_per_second": 1.065,
      "step": 44350
    },
    {
      "epoch": 1.9092708961005425,
      "grad_norm": 0.8742446899414062,
      "learning_rate": 6.16855124916041e-05,
      "loss": 3.1254,
      "step": 44360
    },
    {
      "epoch": 1.9097012998192304,
      "grad_norm": 0.9224613308906555,
      "learning_rate": 6.164259617008288e-05,
      "loss": 2.9567,
      "step": 44370
    },
    {
      "epoch": 1.9101317035379186,
      "grad_norm": 0.8448112607002258,
      "learning_rate": 6.159968813040615e-05,
      "loss": 3.0089,
      "step": 44380
    },
    {
      "epoch": 1.9105621072566068,
      "grad_norm": 0.7897387146949768,
      "learning_rate": 6.155678838183825e-05,
      "loss": 2.9513,
      "step": 44390
    },
    {
      "epoch": 1.9109925109752948,
      "grad_norm": 1.0066759586334229,
      "learning_rate": 6.151389693364178e-05,
      "loss": 3.0589,
      "step": 44400
    },
    {
      "epoch": 1.9109925109752948,
      "eval_bleu": 27.21820552716053,
      "eval_gen_len": 27.595,
      "eval_loss": 2.7911746501922607,
      "eval_runtime": 59.053,
      "eval_samples_per_second": 16.934,
      "eval_steps_per_second": 1.067,
      "step": 44400
    },
    {
      "epoch": 1.911422914693983,
      "grad_norm": 0.9087280631065369,
      "learning_rate": 6.14710137950776e-05,
      "loss": 3.0225,
      "step": 44410
    },
    {
      "epoch": 1.9118533184126711,
      "grad_norm": 0.892842173576355,
      "learning_rate": 6.142813897540463e-05,
      "loss": 2.9817,
      "step": 44420
    },
    {
      "epoch": 1.912283722131359,
      "grad_norm": 0.8612218499183655,
      "learning_rate": 6.138527248388015e-05,
      "loss": 3.0753,
      "step": 44430
    },
    {
      "epoch": 1.9127141258500473,
      "grad_norm": 0.8339206576347351,
      "learning_rate": 6.134241432975958e-05,
      "loss": 2.9638,
      "step": 44440
    },
    {
      "epoch": 1.9131445295687355,
      "grad_norm": 1.0186094045639038,
      "learning_rate": 6.129956452229649e-05,
      "loss": 3.0792,
      "step": 44450
    },
    {
      "epoch": 1.9131445295687355,
      "eval_bleu": 27.24330676029502,
      "eval_gen_len": 27.495,
      "eval_loss": 2.79227614402771,
      "eval_runtime": 58.7706,
      "eval_samples_per_second": 17.015,
      "eval_steps_per_second": 1.072,
      "step": 44450
    },
    {
      "epoch": 1.9135749332874235,
      "grad_norm": 0.9965474009513855,
      "learning_rate": 6.125672307074275e-05,
      "loss": 2.9835,
      "step": 44460
    },
    {
      "epoch": 1.9140053370061119,
      "grad_norm": 0.8538923263549805,
      "learning_rate": 6.121388998434827e-05,
      "loss": 2.9688,
      "step": 44470
    },
    {
      "epoch": 1.9144357407247998,
      "grad_norm": 0.8514578938484192,
      "learning_rate": 6.117106527236133e-05,
      "loss": 2.9784,
      "step": 44480
    },
    {
      "epoch": 1.914866144443488,
      "grad_norm": 0.9398086071014404,
      "learning_rate": 6.112824894402829e-05,
      "loss": 3.001,
      "step": 44490
    },
    {
      "epoch": 1.9152965481621762,
      "grad_norm": 0.8931904435157776,
      "learning_rate": 6.108544100859373e-05,
      "loss": 2.9425,
      "step": 44500
    },
    {
      "epoch": 1.9152965481621762,
      "eval_bleu": 27.262756904020968,
      "eval_gen_len": 27.507,
      "eval_loss": 2.7909390926361084,
      "eval_runtime": 58.579,
      "eval_samples_per_second": 17.071,
      "eval_steps_per_second": 1.075,
      "step": 44500
    },
    {
      "epoch": 1.9157269518808642,
      "grad_norm": 1.0345572233200073,
      "learning_rate": 6.104264147530044e-05,
      "loss": 3.0326,
      "step": 44510
    },
    {
      "epoch": 1.9161573555995524,
      "grad_norm": 0.9175238013267517,
      "learning_rate": 6.099985035338933e-05,
      "loss": 2.9799,
      "step": 44520
    },
    {
      "epoch": 1.9165877593182405,
      "grad_norm": 0.9535912871360779,
      "learning_rate": 6.0957067652099606e-05,
      "loss": 2.9584,
      "step": 44530
    },
    {
      "epoch": 1.9170181630369285,
      "grad_norm": 0.8478818535804749,
      "learning_rate": 6.091429338066861e-05,
      "loss": 2.9545,
      "step": 44540
    },
    {
      "epoch": 1.917448566755617,
      "grad_norm": 0.9252377152442932,
      "learning_rate": 6.087152754833174e-05,
      "loss": 3.0322,
      "step": 44550
    },
    {
      "epoch": 1.917448566755617,
      "eval_bleu": 27.245902303805018,
      "eval_gen_len": 27.463,
      "eval_loss": 2.791299819946289,
      "eval_runtime": 58.663,
      "eval_samples_per_second": 17.047,
      "eval_steps_per_second": 1.074,
      "step": 44550
    },
    {
      "epoch": 1.917878970474305,
      "grad_norm": 0.8784450888633728,
      "learning_rate": 6.082877016432273e-05,
      "loss": 3.0376,
      "step": 44560
    },
    {
      "epoch": 1.918309374192993,
      "grad_norm": 0.8290716409683228,
      "learning_rate": 6.0786021237873436e-05,
      "loss": 3.034,
      "step": 44570
    },
    {
      "epoch": 1.9187397779116813,
      "grad_norm": 0.9278481006622314,
      "learning_rate": 6.074328077821388e-05,
      "loss": 2.9804,
      "step": 44580
    },
    {
      "epoch": 1.9191701816303692,
      "grad_norm": 0.86557936668396,
      "learning_rate": 6.070054879457228e-05,
      "loss": 3.0448,
      "step": 44590
    },
    {
      "epoch": 1.9196005853490574,
      "grad_norm": 0.9258086085319519,
      "learning_rate": 6.0657825296174986e-05,
      "loss": 3.0233,
      "step": 44600
    },
    {
      "epoch": 1.9196005853490574,
      "eval_bleu": 27.524050841443845,
      "eval_gen_len": 27.492,
      "eval_loss": 2.788205623626709,
      "eval_runtime": 58.5179,
      "eval_samples_per_second": 17.089,
      "eval_steps_per_second": 1.077,
      "step": 44600
    },
    {
      "epoch": 1.9200309890677456,
      "grad_norm": 0.939361572265625,
      "learning_rate": 6.0615110292246535e-05,
      "loss": 3.0513,
      "step": 44610
    },
    {
      "epoch": 1.9204613927864336,
      "grad_norm": 0.843776285648346,
      "learning_rate": 6.057240379200968e-05,
      "loss": 3.0618,
      "step": 44620
    },
    {
      "epoch": 1.9208917965051218,
      "grad_norm": 0.8713728785514832,
      "learning_rate": 6.052970580468522e-05,
      "loss": 2.9681,
      "step": 44630
    },
    {
      "epoch": 1.92132220022381,
      "grad_norm": 0.9937685132026672,
      "learning_rate": 6.048701633949223e-05,
      "loss": 2.9928,
      "step": 44640
    },
    {
      "epoch": 1.921752603942498,
      "grad_norm": 0.9494566917419434,
      "learning_rate": 6.044433540564789e-05,
      "loss": 2.9392,
      "step": 44650
    },
    {
      "epoch": 1.921752603942498,
      "eval_bleu": 27.663737213742657,
      "eval_gen_len": 27.517,
      "eval_loss": 2.7903003692626953,
      "eval_runtime": 58.2711,
      "eval_samples_per_second": 17.161,
      "eval_steps_per_second": 1.081,
      "step": 44650
    },
    {
      "epoch": 1.9221830076611863,
      "grad_norm": 0.8880285024642944,
      "learning_rate": 6.0401663012367535e-05,
      "loss": 2.8978,
      "step": 44660
    },
    {
      "epoch": 1.9226134113798743,
      "grad_norm": 0.8460870385169983,
      "learning_rate": 6.035899916886469e-05,
      "loss": 3.0681,
      "step": 44670
    },
    {
      "epoch": 1.9230438150985625,
      "grad_norm": 0.8735275268554688,
      "learning_rate": 6.031634388435101e-05,
      "loss": 3.084,
      "step": 44680
    },
    {
      "epoch": 1.9234742188172507,
      "grad_norm": 0.9469191431999207,
      "learning_rate": 6.0273697168036304e-05,
      "loss": 3.026,
      "step": 44690
    },
    {
      "epoch": 1.9239046225359386,
      "grad_norm": 0.8619378209114075,
      "learning_rate": 6.0231059029128556e-05,
      "loss": 2.9643,
      "step": 44700
    },
    {
      "epoch": 1.9239046225359386,
      "eval_bleu": 27.330794497359946,
      "eval_gen_len": 27.479,
      "eval_loss": 2.790764808654785,
      "eval_runtime": 58.4937,
      "eval_samples_per_second": 17.096,
      "eval_steps_per_second": 1.077,
      "step": 44700
    },
    {
      "epoch": 1.9243350262546268,
      "grad_norm": 0.9879999756813049,
      "learning_rate": 6.018842947683383e-05,
      "loss": 3.0349,
      "step": 44710
    },
    {
      "epoch": 1.924765429973315,
      "grad_norm": 1.0446302890777588,
      "learning_rate": 6.0145808520356386e-05,
      "loss": 3.0286,
      "step": 44720
    },
    {
      "epoch": 1.925195833692003,
      "grad_norm": 0.8363003730773926,
      "learning_rate": 6.0103196168898654e-05,
      "loss": 2.9669,
      "step": 44730
    },
    {
      "epoch": 1.9256262374106914,
      "grad_norm": 0.9351961612701416,
      "learning_rate": 6.006059243166115e-05,
      "loss": 3.0675,
      "step": 44740
    },
    {
      "epoch": 1.9260566411293794,
      "grad_norm": 1.0351696014404297,
      "learning_rate": 6.0017997317842566e-05,
      "loss": 2.9839,
      "step": 44750
    },
    {
      "epoch": 1.9260566411293794,
      "eval_bleu": 27.41891282807254,
      "eval_gen_len": 27.551,
      "eval_loss": 2.7905025482177734,
      "eval_runtime": 58.5118,
      "eval_samples_per_second": 17.091,
      "eval_steps_per_second": 1.077,
      "step": 44750
    },
    {
      "epoch": 1.9264870448480675,
      "grad_norm": 1.0039923191070557,
      "learning_rate": 5.997541083663972e-05,
      "loss": 2.9618,
      "step": 44760
    },
    {
      "epoch": 1.9269174485667557,
      "grad_norm": 0.8763123154640198,
      "learning_rate": 5.993283299724757e-05,
      "loss": 3.0151,
      "step": 44770
    },
    {
      "epoch": 1.9273478522854437,
      "grad_norm": 0.8453336358070374,
      "learning_rate": 5.989026380885923e-05,
      "loss": 2.9421,
      "step": 44780
    },
    {
      "epoch": 1.9277782560041319,
      "grad_norm": 0.9180130362510681,
      "learning_rate": 5.9847703280665866e-05,
      "loss": 3.0157,
      "step": 44790
    },
    {
      "epoch": 1.92820865972282,
      "grad_norm": 0.8888099789619446,
      "learning_rate": 5.980515142185685e-05,
      "loss": 2.965,
      "step": 44800
    },
    {
      "epoch": 1.92820865972282,
      "eval_bleu": 27.280714407831333,
      "eval_gen_len": 27.479,
      "eval_loss": 2.7903635501861572,
      "eval_runtime": 58.4586,
      "eval_samples_per_second": 17.106,
      "eval_steps_per_second": 1.078,
      "step": 44800
    },
    {
      "epoch": 1.928639063441508,
      "grad_norm": 0.9000585079193115,
      "learning_rate": 5.9762608241619677e-05,
      "loss": 2.985,
      "step": 44810
    },
    {
      "epoch": 1.9290694671601962,
      "grad_norm": 0.9320933818817139,
      "learning_rate": 5.972007374913995e-05,
      "loss": 3.0452,
      "step": 44820
    },
    {
      "epoch": 1.9294998708788844,
      "grad_norm": 0.8945775032043457,
      "learning_rate": 5.967754795360139e-05,
      "loss": 3.1166,
      "step": 44830
    },
    {
      "epoch": 1.9299302745975724,
      "grad_norm": 0.9501162767410278,
      "learning_rate": 5.963503086418586e-05,
      "loss": 3.0958,
      "step": 44840
    },
    {
      "epoch": 1.9303606783162608,
      "grad_norm": 0.9937978386878967,
      "learning_rate": 5.959252249007332e-05,
      "loss": 3.0689,
      "step": 44850
    },
    {
      "epoch": 1.9303606783162608,
      "eval_bleu": 27.337142535685764,
      "eval_gen_len": 27.493,
      "eval_loss": 2.789487361907959,
      "eval_runtime": 58.5189,
      "eval_samples_per_second": 17.089,
      "eval_steps_per_second": 1.077,
      "step": 44850
    },
    {
      "epoch": 1.9307910820349488,
      "grad_norm": 0.8977110385894775,
      "learning_rate": 5.955002284044186e-05,
      "loss": 3.0224,
      "step": 44860
    },
    {
      "epoch": 1.931221485753637,
      "grad_norm": 0.8661860227584839,
      "learning_rate": 5.950753192446774e-05,
      "loss": 3.0565,
      "step": 44870
    },
    {
      "epoch": 1.9316518894723251,
      "grad_norm": 0.8550297617912292,
      "learning_rate": 5.9465049751325205e-05,
      "loss": 3.0166,
      "step": 44880
    },
    {
      "epoch": 1.932082293191013,
      "grad_norm": 0.8801231384277344,
      "learning_rate": 5.942257633018673e-05,
      "loss": 3.0169,
      "step": 44890
    },
    {
      "epoch": 1.9325126969097013,
      "grad_norm": 0.9188099503517151,
      "learning_rate": 5.938011167022284e-05,
      "loss": 2.9597,
      "step": 44900
    },
    {
      "epoch": 1.9325126969097013,
      "eval_bleu": 27.144345562590278,
      "eval_gen_len": 27.422,
      "eval_loss": 2.788496732711792,
      "eval_runtime": 58.115,
      "eval_samples_per_second": 17.207,
      "eval_steps_per_second": 1.084,
      "step": 44900
    },
    {
      "epoch": 1.9329431006283895,
      "grad_norm": 0.9410024285316467,
      "learning_rate": 5.9337655780602196e-05,
      "loss": 3.0887,
      "step": 44910
    },
    {
      "epoch": 1.9333735043470774,
      "grad_norm": 0.8908407092094421,
      "learning_rate": 5.9295208670491565e-05,
      "loss": 3.0036,
      "step": 44920
    },
    {
      "epoch": 1.9338039080657659,
      "grad_norm": 0.9889310002326965,
      "learning_rate": 5.92527703490558e-05,
      "loss": 3.0498,
      "step": 44930
    },
    {
      "epoch": 1.9342343117844538,
      "grad_norm": 0.9231703281402588,
      "learning_rate": 5.921034082545787e-05,
      "loss": 2.9479,
      "step": 44940
    },
    {
      "epoch": 1.9346647155031418,
      "grad_norm": 0.8212239742279053,
      "learning_rate": 5.916792010885885e-05,
      "loss": 3.0014,
      "step": 44950
    },
    {
      "epoch": 1.9346647155031418,
      "eval_bleu": 27.59819825984589,
      "eval_gen_len": 27.454,
      "eval_loss": 2.790184497833252,
      "eval_runtime": 58.3337,
      "eval_samples_per_second": 17.143,
      "eval_steps_per_second": 1.08,
      "step": 44950
    },
    {
      "epoch": 1.9350951192218302,
      "grad_norm": 0.9239645004272461,
      "learning_rate": 5.91255082084179e-05,
      "loss": 3.0387,
      "step": 44960
    },
    {
      "epoch": 1.9355255229405182,
      "grad_norm": 0.916857123374939,
      "learning_rate": 5.908310513329227e-05,
      "loss": 2.9323,
      "step": 44970
    },
    {
      "epoch": 1.9359559266592063,
      "grad_norm": 1.008493423461914,
      "learning_rate": 5.9040710892637316e-05,
      "loss": 3.0656,
      "step": 44980
    },
    {
      "epoch": 1.9363863303778945,
      "grad_norm": 0.7679307460784912,
      "learning_rate": 5.899832549560651e-05,
      "loss": 3.0145,
      "step": 44990
    },
    {
      "epoch": 1.9368167340965825,
      "grad_norm": 0.9246591329574585,
      "learning_rate": 5.895594895135137e-05,
      "loss": 3.0781,
      "step": 45000
    },
    {
      "epoch": 1.9368167340965825,
      "eval_bleu": 27.366621154779786,
      "eval_gen_len": 27.547,
      "eval_loss": 2.7902090549468994,
      "eval_runtime": 59.5578,
      "eval_samples_per_second": 16.79,
      "eval_steps_per_second": 1.058,
      "step": 45000
    },
    {
      "epoch": 1.9372471378152707,
      "grad_norm": 1.0208700895309448,
      "learning_rate": 5.891358126902151e-05,
      "loss": 3.0018,
      "step": 45010
    },
    {
      "epoch": 1.9376775415339589,
      "grad_norm": 0.9365885853767395,
      "learning_rate": 5.8871222457764685e-05,
      "loss": 2.9875,
      "step": 45020
    },
    {
      "epoch": 1.9381079452526468,
      "grad_norm": 0.9290591478347778,
      "learning_rate": 5.88288725267267e-05,
      "loss": 3.1118,
      "step": 45030
    },
    {
      "epoch": 1.9385383489713353,
      "grad_norm": 0.984174907207489,
      "learning_rate": 5.8786531485051366e-05,
      "loss": 3.0565,
      "step": 45040
    },
    {
      "epoch": 1.9389687526900232,
      "grad_norm": 0.9895753860473633,
      "learning_rate": 5.874419934188067e-05,
      "loss": 2.911,
      "step": 45050
    },
    {
      "epoch": 1.9389687526900232,
      "eval_bleu": 27.09571959274565,
      "eval_gen_len": 27.488,
      "eval_loss": 2.792762279510498,
      "eval_runtime": 58.8344,
      "eval_samples_per_second": 16.997,
      "eval_steps_per_second": 1.071,
      "step": 45050
    },
    {
      "epoch": 1.9393991564087114,
      "grad_norm": 0.9307687878608704,
      "learning_rate": 5.870187610635467e-05,
      "loss": 3.0806,
      "step": 45060
    },
    {
      "epoch": 1.9398295601273996,
      "grad_norm": 0.8430773019790649,
      "learning_rate": 5.8659561787611495e-05,
      "loss": 3.0369,
      "step": 45070
    },
    {
      "epoch": 1.9402599638460876,
      "grad_norm": 0.9534019231796265,
      "learning_rate": 5.8617256394787323e-05,
      "loss": 2.9339,
      "step": 45080
    },
    {
      "epoch": 1.9406903675647758,
      "grad_norm": 0.9189963936805725,
      "learning_rate": 5.8574959937016424e-05,
      "loss": 3.0322,
      "step": 45090
    },
    {
      "epoch": 1.941120771283464,
      "grad_norm": 0.833342969417572,
      "learning_rate": 5.8532672423431126e-05,
      "loss": 3.0313,
      "step": 45100
    },
    {
      "epoch": 1.941120771283464,
      "eval_bleu": 27.52139823109744,
      "eval_gen_len": 27.593,
      "eval_loss": 2.788423776626587,
      "eval_runtime": 59.0744,
      "eval_samples_per_second": 16.928,
      "eval_steps_per_second": 1.066,
      "step": 45100
    },
    {
      "epoch": 1.941551175002152,
      "grad_norm": 0.9229400157928467,
      "learning_rate": 5.849039386316186e-05,
      "loss": 2.9778,
      "step": 45110
    },
    {
      "epoch": 1.94198157872084,
      "grad_norm": 0.8462531566619873,
      "learning_rate": 5.8448124265337054e-05,
      "loss": 3.0216,
      "step": 45120
    },
    {
      "epoch": 1.9424119824395283,
      "grad_norm": 0.9772968888282776,
      "learning_rate": 5.840586363908325e-05,
      "loss": 2.9914,
      "step": 45130
    },
    {
      "epoch": 1.9428423861582163,
      "grad_norm": 0.9831910133361816,
      "learning_rate": 5.836361199352507e-05,
      "loss": 2.8933,
      "step": 45140
    },
    {
      "epoch": 1.9432727898769047,
      "grad_norm": 0.8765564560890198,
      "learning_rate": 5.8321369337785134e-05,
      "loss": 2.94,
      "step": 45150
    },
    {
      "epoch": 1.9432727898769047,
      "eval_bleu": 27.695173912156182,
      "eval_gen_len": 27.562,
      "eval_loss": 2.7879605293273926,
      "eval_runtime": 58.2411,
      "eval_samples_per_second": 17.17,
      "eval_steps_per_second": 1.082,
      "step": 45150
    },
    {
      "epoch": 1.9437031935955926,
      "grad_norm": 0.8337442874908447,
      "learning_rate": 5.8279135680984245e-05,
      "loss": 3.0734,
      "step": 45160
    },
    {
      "epoch": 1.9441335973142808,
      "grad_norm": 0.7881917953491211,
      "learning_rate": 5.823691103224107e-05,
      "loss": 2.9706,
      "step": 45170
    },
    {
      "epoch": 1.944564001032969,
      "grad_norm": 0.7601977586746216,
      "learning_rate": 5.819469540067255e-05,
      "loss": 2.9403,
      "step": 45180
    },
    {
      "epoch": 1.944994404751657,
      "grad_norm": 0.8119197487831116,
      "learning_rate": 5.81524887953935e-05,
      "loss": 2.9611,
      "step": 45190
    },
    {
      "epoch": 1.9454248084703452,
      "grad_norm": 0.7876047492027283,
      "learning_rate": 5.811029122551686e-05,
      "loss": 2.9191,
      "step": 45200
    },
    {
      "epoch": 1.9454248084703452,
      "eval_bleu": 27.296053018231973,
      "eval_gen_len": 27.471,
      "eval_loss": 2.7896387577056885,
      "eval_runtime": 57.9437,
      "eval_samples_per_second": 17.258,
      "eval_steps_per_second": 1.087,
      "step": 45200
    },
    {
      "epoch": 1.9458552121890333,
      "grad_norm": 0.9917502403259277,
      "learning_rate": 5.806810270015364e-05,
      "loss": 2.9681,
      "step": 45210
    },
    {
      "epoch": 1.9462856159077213,
      "grad_norm": 0.9809297323226929,
      "learning_rate": 5.8025923228412815e-05,
      "loss": 3.0563,
      "step": 45220
    },
    {
      "epoch": 1.9467160196264097,
      "grad_norm": 0.9122968316078186,
      "learning_rate": 5.798375281940155e-05,
      "loss": 3.0109,
      "step": 45230
    },
    {
      "epoch": 1.9471464233450977,
      "grad_norm": 0.9296857714653015,
      "learning_rate": 5.794159148222488e-05,
      "loss": 3.0681,
      "step": 45240
    },
    {
      "epoch": 1.9475768270637859,
      "grad_norm": 0.8909152150154114,
      "learning_rate": 5.789943922598604e-05,
      "loss": 2.9347,
      "step": 45250
    },
    {
      "epoch": 1.9475768270637859,
      "eval_bleu": 27.24796860851545,
      "eval_gen_len": 27.569,
      "eval_loss": 2.792524576187134,
      "eval_runtime": 58.3294,
      "eval_samples_per_second": 17.144,
      "eval_steps_per_second": 1.08,
      "step": 45250
    },
    {
      "epoch": 1.948007230782474,
      "grad_norm": 0.9491363167762756,
      "learning_rate": 5.785729605978616e-05,
      "loss": 3.0118,
      "step": 45260
    },
    {
      "epoch": 1.948437634501162,
      "grad_norm": 0.8378942012786865,
      "learning_rate": 5.7815161992724554e-05,
      "loss": 3.0052,
      "step": 45270
    },
    {
      "epoch": 1.9488680382198502,
      "grad_norm": 0.8605761528015137,
      "learning_rate": 5.777303703389846e-05,
      "loss": 2.9967,
      "step": 45280
    },
    {
      "epoch": 1.9492984419385384,
      "grad_norm": 1.060831069946289,
      "learning_rate": 5.773092119240313e-05,
      "loss": 2.9242,
      "step": 45290
    },
    {
      "epoch": 1.9497288456572264,
      "grad_norm": 0.8745790719985962,
      "learning_rate": 5.7688814477332e-05,
      "loss": 2.9953,
      "step": 45300
    },
    {
      "epoch": 1.9497288456572264,
      "eval_bleu": 27.385508293642914,
      "eval_gen_len": 27.462,
      "eval_loss": 2.791710615158081,
      "eval_runtime": 58.6088,
      "eval_samples_per_second": 17.062,
      "eval_steps_per_second": 1.075,
      "step": 45300
    },
    {
      "epoch": 1.9501592493759146,
      "grad_norm": 0.9897860288619995,
      "learning_rate": 5.764671689777634e-05,
      "loss": 2.8998,
      "step": 45310
    },
    {
      "epoch": 1.9505896530946027,
      "grad_norm": 0.9473257064819336,
      "learning_rate": 5.760462846282565e-05,
      "loss": 2.9614,
      "step": 45320
    },
    {
      "epoch": 1.9510200568132907,
      "grad_norm": 0.8781065344810486,
      "learning_rate": 5.756254918156725e-05,
      "loss": 2.9011,
      "step": 45330
    },
    {
      "epoch": 1.9514504605319791,
      "grad_norm": 1.030731439590454,
      "learning_rate": 5.7520479063086663e-05,
      "loss": 3.1523,
      "step": 45340
    },
    {
      "epoch": 1.951880864250667,
      "grad_norm": 0.9132720232009888,
      "learning_rate": 5.7478418116467326e-05,
      "loss": 3.0458,
      "step": 45350
    },
    {
      "epoch": 1.951880864250667,
      "eval_bleu": 27.494880757080573,
      "eval_gen_len": 27.495,
      "eval_loss": 2.7881019115448,
      "eval_runtime": 58.7004,
      "eval_samples_per_second": 17.036,
      "eval_steps_per_second": 1.073,
      "step": 45350
    },
    {
      "epoch": 1.9523112679693553,
      "grad_norm": 0.9638145565986633,
      "learning_rate": 5.7436366350790724e-05,
      "loss": 3.0153,
      "step": 45360
    },
    {
      "epoch": 1.9527416716880435,
      "grad_norm": 0.92393958568573,
      "learning_rate": 5.7394323775136326e-05,
      "loss": 2.9927,
      "step": 45370
    },
    {
      "epoch": 1.9531720754067314,
      "grad_norm": 0.7988156080245972,
      "learning_rate": 5.7352290398581676e-05,
      "loss": 3.0124,
      "step": 45380
    },
    {
      "epoch": 1.9536024791254196,
      "grad_norm": 0.867825448513031,
      "learning_rate": 5.731026623020236e-05,
      "loss": 2.9626,
      "step": 45390
    },
    {
      "epoch": 1.9540328828441078,
      "grad_norm": 0.9470126032829285,
      "learning_rate": 5.7268251279071824e-05,
      "loss": 3.1145,
      "step": 45400
    },
    {
      "epoch": 1.9540328828441078,
      "eval_bleu": 27.64223250797586,
      "eval_gen_len": 27.506,
      "eval_loss": 2.7891173362731934,
      "eval_runtime": 58.8234,
      "eval_samples_per_second": 17.0,
      "eval_steps_per_second": 1.071,
      "step": 45400
    },
    {
      "epoch": 1.9544632865627958,
      "grad_norm": 0.8895394802093506,
      "learning_rate": 5.722624555426173e-05,
      "loss": 2.959,
      "step": 45410
    },
    {
      "epoch": 1.9548936902814842,
      "grad_norm": 0.9450018405914307,
      "learning_rate": 5.7184249064841546e-05,
      "loss": 3.0135,
      "step": 45420
    },
    {
      "epoch": 1.9553240940001722,
      "grad_norm": 0.9439551830291748,
      "learning_rate": 5.714226181987892e-05,
      "loss": 2.9674,
      "step": 45430
    },
    {
      "epoch": 1.9557544977188603,
      "grad_norm": 1.0294125080108643,
      "learning_rate": 5.7100283828439374e-05,
      "loss": 2.9802,
      "step": 45440
    },
    {
      "epoch": 1.9561849014375485,
      "grad_norm": 0.887559711933136,
      "learning_rate": 5.70583150995865e-05,
      "loss": 3.0984,
      "step": 45450
    },
    {
      "epoch": 1.9561849014375485,
      "eval_bleu": 27.022644680729872,
      "eval_gen_len": 27.485,
      "eval_loss": 2.790144920349121,
      "eval_runtime": 58.4928,
      "eval_samples_per_second": 17.096,
      "eval_steps_per_second": 1.077,
      "step": 45450
    },
    {
      "epoch": 1.9566153051562365,
      "grad_norm": 0.898244321346283,
      "learning_rate": 5.7016355642381834e-05,
      "loss": 3.0418,
      "step": 45460
    },
    {
      "epoch": 1.9570457088749247,
      "grad_norm": 0.8649398684501648,
      "learning_rate": 5.6974405465884995e-05,
      "loss": 2.9923,
      "step": 45470
    },
    {
      "epoch": 1.9574761125936129,
      "grad_norm": 0.8379688858985901,
      "learning_rate": 5.693246457915355e-05,
      "loss": 2.9679,
      "step": 45480
    },
    {
      "epoch": 1.9579065163123008,
      "grad_norm": 0.8183508515357971,
      "learning_rate": 5.689053299124305e-05,
      "loss": 2.977,
      "step": 45490
    },
    {
      "epoch": 1.958336920030989,
      "grad_norm": 0.9881443977355957,
      "learning_rate": 5.6848610711207064e-05,
      "loss": 3.007,
      "step": 45500
    },
    {
      "epoch": 1.958336920030989,
      "eval_bleu": 27.214719376122744,
      "eval_gen_len": 27.458,
      "eval_loss": 2.7883243560791016,
      "eval_runtime": 58.1367,
      "eval_samples_per_second": 17.201,
      "eval_steps_per_second": 1.084,
      "step": 45500
    },
    {
      "epoch": 1.9587673237496772,
      "grad_norm": 0.8731983304023743,
      "learning_rate": 5.6806697748097105e-05,
      "loss": 3.0123,
      "step": 45510
    },
    {
      "epoch": 1.9591977274683652,
      "grad_norm": 0.9862940907478333,
      "learning_rate": 5.676479411096279e-05,
      "loss": 3.0127,
      "step": 45520
    },
    {
      "epoch": 1.9596281311870536,
      "grad_norm": 0.9084591269493103,
      "learning_rate": 5.67228998088515e-05,
      "loss": 2.9705,
      "step": 45530
    },
    {
      "epoch": 1.9600585349057416,
      "grad_norm": 0.897837221622467,
      "learning_rate": 5.668101485080888e-05,
      "loss": 3.0208,
      "step": 45540
    },
    {
      "epoch": 1.9604889386244297,
      "grad_norm": 0.8293192386627197,
      "learning_rate": 5.66391392458783e-05,
      "loss": 3.0121,
      "step": 45550
    },
    {
      "epoch": 1.9604889386244297,
      "eval_bleu": 27.516044221502895,
      "eval_gen_len": 27.512,
      "eval_loss": 2.787649154663086,
      "eval_runtime": 58.7605,
      "eval_samples_per_second": 17.018,
      "eval_steps_per_second": 1.072,
      "step": 45550
    },
    {
      "epoch": 1.960919342343118,
      "grad_norm": 0.8841692209243774,
      "learning_rate": 5.6597273003101334e-05,
      "loss": 3.024,
      "step": 45560
    },
    {
      "epoch": 1.961349746061806,
      "grad_norm": 0.8555710911750793,
      "learning_rate": 5.6555416131517336e-05,
      "loss": 3.0233,
      "step": 45570
    },
    {
      "epoch": 1.961780149780494,
      "grad_norm": 0.9151219725608826,
      "learning_rate": 5.651356864016377e-05,
      "loss": 2.9988,
      "step": 45580
    },
    {
      "epoch": 1.9622105534991823,
      "grad_norm": 0.9122093915939331,
      "learning_rate": 5.6471730538076086e-05,
      "loss": 2.9881,
      "step": 45590
    },
    {
      "epoch": 1.9626409572178702,
      "grad_norm": 0.8553081154823303,
      "learning_rate": 5.6429901834287605e-05,
      "loss": 2.9678,
      "step": 45600
    },
    {
      "epoch": 1.9626409572178702,
      "eval_bleu": 27.07433337411436,
      "eval_gen_len": 27.509,
      "eval_loss": 2.788558006286621,
      "eval_runtime": 59.0738,
      "eval_samples_per_second": 16.928,
      "eval_steps_per_second": 1.066,
      "step": 45600
    },
    {
      "epoch": 1.9630713609365587,
      "grad_norm": 0.9047361612319946,
      "learning_rate": 5.6388082537829655e-05,
      "loss": 2.9687,
      "step": 45610
    },
    {
      "epoch": 1.9635017646552466,
      "grad_norm": 0.8781744837760925,
      "learning_rate": 5.6346272657731536e-05,
      "loss": 3.0621,
      "step": 45620
    },
    {
      "epoch": 1.9639321683739348,
      "grad_norm": 0.8144593238830566,
      "learning_rate": 5.63044722030206e-05,
      "loss": 3.0261,
      "step": 45630
    },
    {
      "epoch": 1.964362572092623,
      "grad_norm": 0.8937897682189941,
      "learning_rate": 5.6262681182721975e-05,
      "loss": 3.035,
      "step": 45640
    },
    {
      "epoch": 1.964792975811311,
      "grad_norm": 1.000281572341919,
      "learning_rate": 5.622089960585899e-05,
      "loss": 2.963,
      "step": 45650
    },
    {
      "epoch": 1.964792975811311,
      "eval_bleu": 27.114935268506606,
      "eval_gen_len": 27.367,
      "eval_loss": 2.787501811981201,
      "eval_runtime": 58.4109,
      "eval_samples_per_second": 17.12,
      "eval_steps_per_second": 1.079,
      "step": 45650
    },
    {
      "epoch": 1.9652233795299991,
      "grad_norm": 0.8902022838592529,
      "learning_rate": 5.617912748145271e-05,
      "loss": 2.9946,
      "step": 45660
    },
    {
      "epoch": 1.9656537832486873,
      "grad_norm": 0.9343564510345459,
      "learning_rate": 5.6137364818522296e-05,
      "loss": 3.0288,
      "step": 45670
    },
    {
      "epoch": 1.9660841869673753,
      "grad_norm": 1.0983624458312988,
      "learning_rate": 5.609561162608492e-05,
      "loss": 3.0938,
      "step": 45680
    },
    {
      "epoch": 1.9665145906860635,
      "grad_norm": 0.8049547672271729,
      "learning_rate": 5.605386791315547e-05,
      "loss": 2.9121,
      "step": 45690
    },
    {
      "epoch": 1.9669449944047517,
      "grad_norm": 0.9452903270721436,
      "learning_rate": 5.601213368874703e-05,
      "loss": 3.0394,
      "step": 45700
    },
    {
      "epoch": 1.9669449944047517,
      "eval_bleu": 27.33821835369532,
      "eval_gen_len": 27.403,
      "eval_loss": 2.7896292209625244,
      "eval_runtime": 58.2982,
      "eval_samples_per_second": 17.153,
      "eval_steps_per_second": 1.081,
      "step": 45700
    },
    {
      "epoch": 1.9673753981234396,
      "grad_norm": 1.069959282875061,
      "learning_rate": 5.597040896187049e-05,
      "loss": 2.9959,
      "step": 45710
    },
    {
      "epoch": 1.967805801842128,
      "grad_norm": 0.8836534023284912,
      "learning_rate": 5.59286937415348e-05,
      "loss": 2.9216,
      "step": 45720
    },
    {
      "epoch": 1.968236205560816,
      "grad_norm": 0.929775595664978,
      "learning_rate": 5.5886988036746725e-05,
      "loss": 3.0297,
      "step": 45730
    },
    {
      "epoch": 1.9686666092795042,
      "grad_norm": 0.9841097593307495,
      "learning_rate": 5.584529185651114e-05,
      "loss": 2.9913,
      "step": 45740
    },
    {
      "epoch": 1.9690970129981924,
      "grad_norm": 0.9367644786834717,
      "learning_rate": 5.580360520983068e-05,
      "loss": 2.9889,
      "step": 45750
    },
    {
      "epoch": 1.9690970129981924,
      "eval_bleu": 26.768265348228205,
      "eval_gen_len": 27.415,
      "eval_loss": 2.7901668548583984,
      "eval_runtime": 58.0824,
      "eval_samples_per_second": 17.217,
      "eval_steps_per_second": 1.085,
      "step": 45750
    },
    {
      "epoch": 1.9695274167168804,
      "grad_norm": 0.8753995895385742,
      "learning_rate": 5.576192810570611e-05,
      "loss": 3.2156,
      "step": 45760
    },
    {
      "epoch": 1.9699578204355686,
      "grad_norm": 0.9874267578125,
      "learning_rate": 5.5720260553135974e-05,
      "loss": 3.0925,
      "step": 45770
    },
    {
      "epoch": 1.9703882241542567,
      "grad_norm": 0.7917096614837646,
      "learning_rate": 5.567860256111681e-05,
      "loss": 2.9348,
      "step": 45780
    },
    {
      "epoch": 1.9708186278729447,
      "grad_norm": 0.8904232382774353,
      "learning_rate": 5.563695413864316e-05,
      "loss": 3.0139,
      "step": 45790
    },
    {
      "epoch": 1.9712490315916331,
      "grad_norm": 0.9367856979370117,
      "learning_rate": 5.5595315294707374e-05,
      "loss": 3.0339,
      "step": 45800
    },
    {
      "epoch": 1.9712490315916331,
      "eval_bleu": 27.00542675078691,
      "eval_gen_len": 27.487,
      "eval_loss": 2.7901341915130615,
      "eval_runtime": 58.5913,
      "eval_samples_per_second": 17.067,
      "eval_steps_per_second": 1.075,
      "step": 45800
    },
    {
      "epoch": 1.971679435310321,
      "grad_norm": 0.8187398314476013,
      "learning_rate": 5.555368603829987e-05,
      "loss": 3.0593,
      "step": 45810
    },
    {
      "epoch": 1.972109839029009,
      "grad_norm": 0.828825831413269,
      "learning_rate": 5.5512066378408846e-05,
      "loss": 2.9516,
      "step": 45820
    },
    {
      "epoch": 1.9725402427476975,
      "grad_norm": 0.9396008253097534,
      "learning_rate": 5.547045632402059e-05,
      "loss": 2.9421,
      "step": 45830
    },
    {
      "epoch": 1.9729706464663854,
      "grad_norm": 0.9925167560577393,
      "learning_rate": 5.5428855884119205e-05,
      "loss": 3.0128,
      "step": 45840
    },
    {
      "epoch": 1.9734010501850736,
      "grad_norm": 0.9580684304237366,
      "learning_rate": 5.53872650676867e-05,
      "loss": 2.9417,
      "step": 45850
    },
    {
      "epoch": 1.9734010501850736,
      "eval_bleu": 26.90177252856735,
      "eval_gen_len": 27.458,
      "eval_loss": 2.7912240028381348,
      "eval_runtime": 58.3974,
      "eval_samples_per_second": 17.124,
      "eval_steps_per_second": 1.079,
      "step": 45850
    },
    {
      "epoch": 1.9738314539037618,
      "grad_norm": 0.9595720171928406,
      "learning_rate": 5.534568388370311e-05,
      "loss": 2.9656,
      "step": 45860
    },
    {
      "epoch": 1.9742618576224498,
      "grad_norm": 0.8483081459999084,
      "learning_rate": 5.53041123411463e-05,
      "loss": 2.9952,
      "step": 45870
    },
    {
      "epoch": 1.974692261341138,
      "grad_norm": 0.905131459236145,
      "learning_rate": 5.5262550448992147e-05,
      "loss": 2.9398,
      "step": 45880
    },
    {
      "epoch": 1.9751226650598261,
      "grad_norm": 0.8415326476097107,
      "learning_rate": 5.5220998216214294e-05,
      "loss": 2.9258,
      "step": 45890
    },
    {
      "epoch": 1.975553068778514,
      "grad_norm": 0.8838812708854675,
      "learning_rate": 5.5179455651784486e-05,
      "loss": 2.9928,
      "step": 45900
    },
    {
      "epoch": 1.975553068778514,
      "eval_bleu": 27.08435843653287,
      "eval_gen_len": 27.469,
      "eval_loss": 2.7902443408966064,
      "eval_runtime": 58.4914,
      "eval_samples_per_second": 17.097,
      "eval_steps_per_second": 1.077,
      "step": 45900
    },
    {
      "epoch": 1.9759834724972025,
      "grad_norm": 1.053964376449585,
      "learning_rate": 5.513792276467218e-05,
      "loss": 2.9806,
      "step": 45910
    },
    {
      "epoch": 1.9764138762158905,
      "grad_norm": 0.9145532846450806,
      "learning_rate": 5.5096399563844944e-05,
      "loss": 3.0144,
      "step": 45920
    },
    {
      "epoch": 1.9768442799345787,
      "grad_norm": 0.9139700531959534,
      "learning_rate": 5.505488605826812e-05,
      "loss": 2.9674,
      "step": 45930
    },
    {
      "epoch": 1.9772746836532669,
      "grad_norm": 0.8665347099304199,
      "learning_rate": 5.501338225690495e-05,
      "loss": 2.92,
      "step": 45940
    },
    {
      "epoch": 1.9777050873719548,
      "grad_norm": 0.9578065872192383,
      "learning_rate": 5.4971888168716713e-05,
      "loss": 3.01,
      "step": 45950
    },
    {
      "epoch": 1.9777050873719548,
      "eval_bleu": 27.17246217733875,
      "eval_gen_len": 27.494,
      "eval_loss": 2.7902519702911377,
      "eval_runtime": 58.7869,
      "eval_samples_per_second": 17.011,
      "eval_steps_per_second": 1.072,
      "step": 45950
    },
    {
      "epoch": 1.978135491090643,
      "grad_norm": 1.0380001068115234,
      "learning_rate": 5.4930403802662414e-05,
      "loss": 3.0195,
      "step": 45960
    },
    {
      "epoch": 1.9785658948093312,
      "grad_norm": 0.8650200963020325,
      "learning_rate": 5.488892916769912e-05,
      "loss": 3.0276,
      "step": 45970
    },
    {
      "epoch": 1.9789962985280192,
      "grad_norm": 1.0711828470230103,
      "learning_rate": 5.4847464272781656e-05,
      "loss": 3.111,
      "step": 45980
    },
    {
      "epoch": 1.9794267022467074,
      "grad_norm": 0.8492870330810547,
      "learning_rate": 5.480600912686289e-05,
      "loss": 2.8685,
      "step": 45990
    },
    {
      "epoch": 1.9798571059653955,
      "grad_norm": 1.0084190368652344,
      "learning_rate": 5.476456373889347e-05,
      "loss": 3.0845,
      "step": 46000
    },
    {
      "epoch": 1.9798571059653955,
      "eval_bleu": 27.187790123854075,
      "eval_gen_len": 27.506,
      "eval_loss": 2.7908565998077393,
      "eval_runtime": 59.0591,
      "eval_samples_per_second": 16.932,
      "eval_steps_per_second": 1.067,
      "step": 46000
    },
    {
      "epoch": 1.9802875096840835,
      "grad_norm": 0.8909416794776917,
      "learning_rate": 5.4723128117821945e-05,
      "loss": 3.0167,
      "step": 46010
    },
    {
      "epoch": 1.980717913402772,
      "grad_norm": 0.8880596160888672,
      "learning_rate": 5.4681702272594834e-05,
      "loss": 3.0214,
      "step": 46020
    },
    {
      "epoch": 1.98114831712146,
      "grad_norm": 0.9464948773384094,
      "learning_rate": 5.4640286212156445e-05,
      "loss": 3.1315,
      "step": 46030
    },
    {
      "epoch": 1.981578720840148,
      "grad_norm": 0.9321256279945374,
      "learning_rate": 5.45988799454491e-05,
      "loss": 3.05,
      "step": 46040
    },
    {
      "epoch": 1.9820091245588363,
      "grad_norm": 0.9421400427818298,
      "learning_rate": 5.455748348141284e-05,
      "loss": 2.9916,
      "step": 46050
    },
    {
      "epoch": 1.9820091245588363,
      "eval_bleu": 27.41722127280238,
      "eval_gen_len": 27.485,
      "eval_loss": 2.7876062393188477,
      "eval_runtime": 58.4945,
      "eval_samples_per_second": 17.096,
      "eval_steps_per_second": 1.077,
      "step": 46050
    },
    {
      "epoch": 1.9824395282775242,
      "grad_norm": 0.9308401942253113,
      "learning_rate": 5.451609682898577e-05,
      "loss": 3.1614,
      "step": 46060
    },
    {
      "epoch": 1.9828699319962124,
      "grad_norm": 1.0176423788070679,
      "learning_rate": 5.447471999710372e-05,
      "loss": 3.0421,
      "step": 46070
    },
    {
      "epoch": 1.9833003357149006,
      "grad_norm": 0.9648879170417786,
      "learning_rate": 5.443335299470051e-05,
      "loss": 3.0973,
      "step": 46080
    },
    {
      "epoch": 1.9837307394335886,
      "grad_norm": 0.95655357837677,
      "learning_rate": 5.439199583070777e-05,
      "loss": 3.0648,
      "step": 46090
    },
    {
      "epoch": 1.984161143152277,
      "grad_norm": 0.804722011089325,
      "learning_rate": 5.4350648514055025e-05,
      "loss": 3.0953,
      "step": 46100
    },
    {
      "epoch": 1.984161143152277,
      "eval_bleu": 27.24436013322204,
      "eval_gen_len": 27.509,
      "eval_loss": 2.7918686866760254,
      "eval_runtime": 58.6414,
      "eval_samples_per_second": 17.053,
      "eval_steps_per_second": 1.074,
      "step": 46100
    },
    {
      "epoch": 1.984591546870965,
      "grad_norm": 0.8762721419334412,
      "learning_rate": 5.430931105366972e-05,
      "loss": 2.9842,
      "step": 46110
    },
    {
      "epoch": 1.9850219505896531,
      "grad_norm": 0.8894758820533752,
      "learning_rate": 5.426798345847706e-05,
      "loss": 3.0219,
      "step": 46120
    },
    {
      "epoch": 1.9854523543083413,
      "grad_norm": 0.9431326389312744,
      "learning_rate": 5.422666573740027e-05,
      "loss": 3.0481,
      "step": 46130
    },
    {
      "epoch": 1.9858827580270293,
      "grad_norm": 0.9274017214775085,
      "learning_rate": 5.418535789936028e-05,
      "loss": 3.0137,
      "step": 46140
    },
    {
      "epoch": 1.9863131617457175,
      "grad_norm": 0.8888689279556274,
      "learning_rate": 5.414405995327607e-05,
      "loss": 2.9535,
      "step": 46150
    },
    {
      "epoch": 1.9863131617457175,
      "eval_bleu": 27.606592216369684,
      "eval_gen_len": 27.618,
      "eval_loss": 2.7881648540496826,
      "eval_runtime": 58.6099,
      "eval_samples_per_second": 17.062,
      "eval_steps_per_second": 1.075,
      "step": 46150
    },
    {
      "epoch": 1.9867435654644057,
      "grad_norm": 0.9459089040756226,
      "learning_rate": 5.41027719080643e-05,
      "loss": 2.9491,
      "step": 46160
    },
    {
      "epoch": 1.9871739691830936,
      "grad_norm": 0.8718748092651367,
      "learning_rate": 5.406149377263967e-05,
      "loss": 2.925,
      "step": 46170
    },
    {
      "epoch": 1.9876043729017818,
      "grad_norm": 0.9079724550247192,
      "learning_rate": 5.40202255559145e-05,
      "loss": 2.961,
      "step": 46180
    },
    {
      "epoch": 1.98803477662047,
      "grad_norm": 0.9360150098800659,
      "learning_rate": 5.397896726679926e-05,
      "loss": 3.0384,
      "step": 46190
    },
    {
      "epoch": 1.988465180339158,
      "grad_norm": 0.8638859391212463,
      "learning_rate": 5.393771891420203e-05,
      "loss": 3.0859,
      "step": 46200
    },
    {
      "epoch": 1.988465180339158,
      "eval_bleu": 27.386931374716074,
      "eval_gen_len": 27.604,
      "eval_loss": 2.7906503677368164,
      "eval_runtime": 59.0689,
      "eval_samples_per_second": 16.929,
      "eval_steps_per_second": 1.067,
      "step": 46200
    },
    {
      "epoch": 1.9888955840578464,
      "grad_norm": 0.8501263856887817,
      "learning_rate": 5.389648050702888e-05,
      "loss": 2.9846,
      "step": 46210
    },
    {
      "epoch": 1.9893259877765344,
      "grad_norm": 0.9167682528495789,
      "learning_rate": 5.385525205418376e-05,
      "loss": 2.9398,
      "step": 46220
    },
    {
      "epoch": 1.9897563914952225,
      "grad_norm": 0.9575985074043274,
      "learning_rate": 5.381403356456831e-05,
      "loss": 3.0687,
      "step": 46230
    },
    {
      "epoch": 1.9901867952139107,
      "grad_norm": 0.8932191133499146,
      "learning_rate": 5.377282504708221e-05,
      "loss": 2.9734,
      "step": 46240
    },
    {
      "epoch": 1.9906171989325987,
      "grad_norm": 0.8719269633293152,
      "learning_rate": 5.3731626510622845e-05,
      "loss": 2.9131,
      "step": 46250
    },
    {
      "epoch": 1.9906171989325987,
      "eval_bleu": 27.180982821221924,
      "eval_gen_len": 27.504,
      "eval_loss": 2.791870594024658,
      "eval_runtime": 58.2317,
      "eval_samples_per_second": 17.173,
      "eval_steps_per_second": 1.082,
      "step": 46250
    },
    {
      "epoch": 1.9910476026512869,
      "grad_norm": 0.9741122722625732,
      "learning_rate": 5.369043796408552e-05,
      "loss": 2.927,
      "step": 46260
    },
    {
      "epoch": 1.991478006369975,
      "grad_norm": 1.0150033235549927,
      "learning_rate": 5.36492594163633e-05,
      "loss": 3.0115,
      "step": 46270
    },
    {
      "epoch": 1.991908410088663,
      "grad_norm": 0.8966596126556396,
      "learning_rate": 5.360809087634722e-05,
      "loss": 3.1334,
      "step": 46280
    },
    {
      "epoch": 1.9923388138073514,
      "grad_norm": 0.9104498028755188,
      "learning_rate": 5.3566932352926026e-05,
      "loss": 3.086,
      "step": 46290
    },
    {
      "epoch": 1.9927692175260394,
      "grad_norm": 1.0007718801498413,
      "learning_rate": 5.352578385498638e-05,
      "loss": 3.0077,
      "step": 46300
    },
    {
      "epoch": 1.9927692175260394,
      "eval_bleu": 26.919873069544526,
      "eval_gen_len": 27.505,
      "eval_loss": 2.7901365756988525,
      "eval_runtime": 58.6085,
      "eval_samples_per_second": 17.062,
      "eval_steps_per_second": 1.075,
      "step": 46300
    },
    {
      "epoch": 1.9931996212447276,
      "grad_norm": 0.9035980701446533,
      "learning_rate": 5.34846453914128e-05,
      "loss": 3.0406,
      "step": 46310
    },
    {
      "epoch": 1.9936300249634158,
      "grad_norm": 0.8306760191917419,
      "learning_rate": 5.344351697108755e-05,
      "loss": 3.0606,
      "step": 46320
    },
    {
      "epoch": 1.9940604286821038,
      "grad_norm": 0.935239315032959,
      "learning_rate": 5.340239860289085e-05,
      "loss": 3.061,
      "step": 46330
    },
    {
      "epoch": 1.994490832400792,
      "grad_norm": 0.8759521842002869,
      "learning_rate": 5.3361290295700536e-05,
      "loss": 2.943,
      "step": 46340
    },
    {
      "epoch": 1.9949212361194801,
      "grad_norm": 0.952106237411499,
      "learning_rate": 5.3320192058392516e-05,
      "loss": 2.9664,
      "step": 46350
    },
    {
      "epoch": 1.9949212361194801,
      "eval_bleu": 26.968874818298698,
      "eval_gen_len": 27.516,
      "eval_loss": 2.7894694805145264,
      "eval_runtime": 58.1614,
      "eval_samples_per_second": 17.194,
      "eval_steps_per_second": 1.083,
      "step": 46350
    },
    {
      "epoch": 1.995351639838168,
      "grad_norm": 0.9138028621673584,
      "learning_rate": 5.327910389984033e-05,
      "loss": 2.9636,
      "step": 46360
    },
    {
      "epoch": 1.9957820435568563,
      "grad_norm": 0.9462639093399048,
      "learning_rate": 5.3238025828915525e-05,
      "loss": 3.0235,
      "step": 46370
    },
    {
      "epoch": 1.9962124472755445,
      "grad_norm": 1.0047191381454468,
      "learning_rate": 5.319695785448726e-05,
      "loss": 3.0256,
      "step": 46380
    },
    {
      "epoch": 1.9966428509942324,
      "grad_norm": 0.8410845398902893,
      "learning_rate": 5.315589998542275e-05,
      "loss": 3.0429,
      "step": 46390
    },
    {
      "epoch": 1.9970732547129209,
      "grad_norm": 0.8842248320579529,
      "learning_rate": 5.311485223058679e-05,
      "loss": 3.07,
      "step": 46400
    },
    {
      "epoch": 1.9970732547129209,
      "eval_bleu": 27.048112709497,
      "eval_gen_len": 27.446,
      "eval_loss": 2.789475202560425,
      "eval_runtime": 58.6268,
      "eval_samples_per_second": 17.057,
      "eval_steps_per_second": 1.075,
      "step": 46400
    },
    {
      "epoch": 1.9975036584316088,
      "grad_norm": 0.9589689373970032,
      "learning_rate": 5.3073814598842195e-05,
      "loss": 3.0167,
      "step": 46410
    },
    {
      "epoch": 1.997934062150297,
      "grad_norm": 0.866227388381958,
      "learning_rate": 5.303278709904946e-05,
      "loss": 2.9708,
      "step": 46420
    },
    {
      "epoch": 1.9983644658689852,
      "grad_norm": 1.020833969116211,
      "learning_rate": 5.299176974006691e-05,
      "loss": 3.0001,
      "step": 46430
    },
    {
      "epoch": 1.9987948695876732,
      "grad_norm": 0.9295746088027954,
      "learning_rate": 5.2950762530750774e-05,
      "loss": 2.9876,
      "step": 46440
    },
    {
      "epoch": 1.9992252733063614,
      "grad_norm": 0.8272759914398193,
      "learning_rate": 5.290976547995494e-05,
      "loss": 3.0612,
      "step": 46450
    },
    {
      "epoch": 1.9992252733063614,
      "eval_bleu": 27.082027361468846,
      "eval_gen_len": 27.514,
      "eval_loss": 2.789168119430542,
      "eval_runtime": 58.8491,
      "eval_samples_per_second": 16.993,
      "eval_steps_per_second": 1.071,
      "step": 46450
    },
    {
      "epoch": 1.9996556770250495,
      "grad_norm": 0.896382749080658,
      "learning_rate": 5.286877859653128e-05,
      "loss": 3.0411,
      "step": 46460
    },
    {
      "epoch": 2.0000860807437375,
      "grad_norm": 0.877978503704071,
      "learning_rate": 5.2827801889329285e-05,
      "loss": 3.0858,
      "step": 46470
    },
    {
      "epoch": 2.000516484462426,
      "grad_norm": 0.8961018919944763,
      "learning_rate": 5.278683536719643e-05,
      "loss": 3.0462,
      "step": 46480
    },
    {
      "epoch": 2.000946888181114,
      "grad_norm": 0.934968888759613,
      "learning_rate": 5.274587903897785e-05,
      "loss": 2.969,
      "step": 46490
    },
    {
      "epoch": 2.001377291899802,
      "grad_norm": 0.9107710719108582,
      "learning_rate": 5.270493291351648e-05,
      "loss": 2.9327,
      "step": 46500
    },
    {
      "epoch": 2.001377291899802,
      "eval_bleu": 26.999775182511474,
      "eval_gen_len": 27.567,
      "eval_loss": 2.7892496585845947,
      "eval_runtime": 59.0444,
      "eval_samples_per_second": 16.936,
      "eval_steps_per_second": 1.067,
      "step": 46500
    },
    {
      "epoch": 2.0018076956184903,
      "grad_norm": 0.9510374069213867,
      "learning_rate": 5.266399699965321e-05,
      "loss": 3.0459,
      "step": 46510
    },
    {
      "epoch": 2.0022380993371782,
      "grad_norm": 0.8792545795440674,
      "learning_rate": 5.262307130622652e-05,
      "loss": 3.0105,
      "step": 46520
    },
    {
      "epoch": 2.002668503055866,
      "grad_norm": 0.9475882053375244,
      "learning_rate": 5.258215584207287e-05,
      "loss": 3.0345,
      "step": 46530
    },
    {
      "epoch": 2.0030989067745546,
      "grad_norm": 0.8658787608146667,
      "learning_rate": 5.254125061602633e-05,
      "loss": 2.9077,
      "step": 46540
    },
    {
      "epoch": 2.0035293104932426,
      "grad_norm": 0.8442496657371521,
      "learning_rate": 5.250035563691893e-05,
      "loss": 2.9571,
      "step": 46550
    },
    {
      "epoch": 2.0035293104932426,
      "eval_bleu": 27.022609887098007,
      "eval_gen_len": 27.407,
      "eval_loss": 2.7888224124908447,
      "eval_runtime": 58.7534,
      "eval_samples_per_second": 17.02,
      "eval_steps_per_second": 1.072,
      "step": 46550
    },
    {
      "epoch": 2.003959714211931,
      "grad_norm": 0.8117783665657043,
      "learning_rate": 5.245947091358034e-05,
      "loss": 2.9172,
      "step": 46560
    },
    {
      "epoch": 2.004390117930619,
      "grad_norm": 0.8285595774650574,
      "learning_rate": 5.2418596454838155e-05,
      "loss": 3.0188,
      "step": 46570
    },
    {
      "epoch": 2.004820521649307,
      "grad_norm": 0.9174904227256775,
      "learning_rate": 5.2377732269517657e-05,
      "loss": 2.9752,
      "step": 46580
    },
    {
      "epoch": 2.0052509253679953,
      "grad_norm": 0.7859683632850647,
      "learning_rate": 5.233687836644188e-05,
      "loss": 2.9513,
      "step": 46590
    },
    {
      "epoch": 2.0056813290866833,
      "grad_norm": 1.0639824867248535,
      "learning_rate": 5.229603475443179e-05,
      "loss": 2.9808,
      "step": 46600
    },
    {
      "epoch": 2.0056813290866833,
      "eval_bleu": 27.39362743727943,
      "eval_gen_len": 27.56,
      "eval_loss": 2.7870099544525146,
      "eval_runtime": 58.5048,
      "eval_samples_per_second": 17.093,
      "eval_steps_per_second": 1.077,
      "step": 46600
    },
    {
      "epoch": 2.0061117328053713,
      "grad_norm": 0.9233850240707397,
      "learning_rate": 5.225520144230593e-05,
      "loss": 2.9141,
      "step": 46610
    },
    {
      "epoch": 2.0065421365240597,
      "grad_norm": 0.8362686038017273,
      "learning_rate": 5.221437843888082e-05,
      "loss": 2.8584,
      "step": 46620
    },
    {
      "epoch": 2.0069725402427476,
      "grad_norm": 0.9472743272781372,
      "learning_rate": 5.217356575297059e-05,
      "loss": 2.9784,
      "step": 46630
    },
    {
      "epoch": 2.007402943961436,
      "grad_norm": 0.8265911340713501,
      "learning_rate": 5.213276339338728e-05,
      "loss": 2.9831,
      "step": 46640
    },
    {
      "epoch": 2.007833347680124,
      "grad_norm": 0.9804849028587341,
      "learning_rate": 5.209197136894057e-05,
      "loss": 2.9726,
      "step": 46650
    },
    {
      "epoch": 2.007833347680124,
      "eval_bleu": 27.12985461030291,
      "eval_gen_len": 27.581,
      "eval_loss": 2.7900848388671875,
      "eval_runtime": 59.0113,
      "eval_samples_per_second": 16.946,
      "eval_steps_per_second": 1.068,
      "step": 46650
    },
    {
      "epoch": 2.008263751398812,
      "grad_norm": 0.9502850770950317,
      "learning_rate": 5.205118968843797e-05,
      "loss": 2.9978,
      "step": 46660
    },
    {
      "epoch": 2.0086941551175004,
      "grad_norm": 0.7925819754600525,
      "learning_rate": 5.201041836068481e-05,
      "loss": 2.9919,
      "step": 46670
    },
    {
      "epoch": 2.0091245588361883,
      "grad_norm": 0.8980836868286133,
      "learning_rate": 5.196965739448405e-05,
      "loss": 2.9629,
      "step": 46680
    },
    {
      "epoch": 2.0095549625548763,
      "grad_norm": 0.9133089184761047,
      "learning_rate": 5.192890679863659e-05,
      "loss": 3.0116,
      "step": 46690
    },
    {
      "epoch": 2.0099853662735647,
      "grad_norm": 0.9124712944030762,
      "learning_rate": 5.18881665819409e-05,
      "loss": 2.9217,
      "step": 46700
    },
    {
      "epoch": 2.0099853662735647,
      "eval_bleu": 27.22913558310947,
      "eval_gen_len": 27.486,
      "eval_loss": 2.791208505630493,
      "eval_runtime": 58.6862,
      "eval_samples_per_second": 17.04,
      "eval_steps_per_second": 1.074,
      "step": 46700
    },
    {
      "epoch": 2.0104157699922527,
      "grad_norm": 0.819965124130249,
      "learning_rate": 5.184743675319339e-05,
      "loss": 2.9099,
      "step": 46710
    },
    {
      "epoch": 2.0108461737109407,
      "grad_norm": 1.007590413093567,
      "learning_rate": 5.1806717321188056e-05,
      "loss": 3.0649,
      "step": 46720
    },
    {
      "epoch": 2.011276577429629,
      "grad_norm": 0.9308345913887024,
      "learning_rate": 5.176600829471683e-05,
      "loss": 3.0274,
      "step": 46730
    },
    {
      "epoch": 2.011706981148317,
      "grad_norm": 0.9762873649597168,
      "learning_rate": 5.172530968256923e-05,
      "loss": 3.0229,
      "step": 46740
    },
    {
      "epoch": 2.0121373848670054,
      "grad_norm": 0.9641086459159851,
      "learning_rate": 5.1684621493532584e-05,
      "loss": 3.0702,
      "step": 46750
    },
    {
      "epoch": 2.0121373848670054,
      "eval_bleu": 27.35009909068238,
      "eval_gen_len": 27.623,
      "eval_loss": 2.789583206176758,
      "eval_runtime": 59.1063,
      "eval_samples_per_second": 16.919,
      "eval_steps_per_second": 1.066,
      "step": 46750
    },
    {
      "epoch": 2.0125677885856934,
      "grad_norm": 0.9512236714363098,
      "learning_rate": 5.164394373639205e-05,
      "loss": 2.8585,
      "step": 46760
    },
    {
      "epoch": 2.0129981923043814,
      "grad_norm": 0.861941397190094,
      "learning_rate": 5.160327641993039e-05,
      "loss": 2.9668,
      "step": 46770
    },
    {
      "epoch": 2.01342859602307,
      "grad_norm": 0.866875410079956,
      "learning_rate": 5.156261955292827e-05,
      "loss": 2.9615,
      "step": 46780
    },
    {
      "epoch": 2.0138589997417577,
      "grad_norm": 1.0578906536102295,
      "learning_rate": 5.1521973144163935e-05,
      "loss": 3.0156,
      "step": 46790
    },
    {
      "epoch": 2.0142894034604457,
      "grad_norm": 0.7847184538841248,
      "learning_rate": 5.148133720241354e-05,
      "loss": 2.9565,
      "step": 46800
    },
    {
      "epoch": 2.0142894034604457,
      "eval_bleu": 27.25460194383578,
      "eval_gen_len": 27.568,
      "eval_loss": 2.7888824939727783,
      "eval_runtime": 58.9393,
      "eval_samples_per_second": 16.967,
      "eval_steps_per_second": 1.069,
      "step": 46800
    },
    {
      "epoch": 2.014719807179134,
      "grad_norm": 0.9100605845451355,
      "learning_rate": 5.14407117364508e-05,
      "loss": 3.0706,
      "step": 46810
    },
    {
      "epoch": 2.015150210897822,
      "grad_norm": 0.9574449062347412,
      "learning_rate": 5.140009675504739e-05,
      "loss": 2.9198,
      "step": 46820
    },
    {
      "epoch": 2.0155806146165105,
      "grad_norm": 0.9839341640472412,
      "learning_rate": 5.135949226697243e-05,
      "loss": 2.888,
      "step": 46830
    },
    {
      "epoch": 2.0160110183351985,
      "grad_norm": 0.8738401532173157,
      "learning_rate": 5.131889828099303e-05,
      "loss": 2.9455,
      "step": 46840
    },
    {
      "epoch": 2.0164414220538864,
      "grad_norm": 0.8522701859474182,
      "learning_rate": 5.1278314805873975e-05,
      "loss": 2.8714,
      "step": 46850
    },
    {
      "epoch": 2.0164414220538864,
      "eval_bleu": 26.980842218204963,
      "eval_gen_len": 27.528,
      "eval_loss": 2.7913076877593994,
      "eval_runtime": 58.5309,
      "eval_samples_per_second": 17.085,
      "eval_steps_per_second": 1.076,
      "step": 46850
    },
    {
      "epoch": 2.016871825772575,
      "grad_norm": 0.892841100692749,
      "learning_rate": 5.123774185037766e-05,
      "loss": 2.9448,
      "step": 46860
    },
    {
      "epoch": 2.017302229491263,
      "grad_norm": 0.9619446396827698,
      "learning_rate": 5.1197179423264384e-05,
      "loss": 2.9167,
      "step": 46870
    },
    {
      "epoch": 2.0177326332099508,
      "grad_norm": 0.8886556029319763,
      "learning_rate": 5.115662753329199e-05,
      "loss": 2.9629,
      "step": 46880
    },
    {
      "epoch": 2.018163036928639,
      "grad_norm": 0.9961998462677002,
      "learning_rate": 5.111608618921624e-05,
      "loss": 3.0013,
      "step": 46890
    },
    {
      "epoch": 2.018593440647327,
      "grad_norm": 0.8126704096794128,
      "learning_rate": 5.107555539979045e-05,
      "loss": 3.0466,
      "step": 46900
    },
    {
      "epoch": 2.018593440647327,
      "eval_bleu": 27.400987161913097,
      "eval_gen_len": 27.541,
      "eval_loss": 2.7919323444366455,
      "eval_runtime": 58.9019,
      "eval_samples_per_second": 16.977,
      "eval_steps_per_second": 1.07,
      "step": 46900
    },
    {
      "epoch": 2.019023844366015,
      "grad_norm": 0.8923057913780212,
      "learning_rate": 5.103503517376576e-05,
      "loss": 3.0873,
      "step": 46910
    },
    {
      "epoch": 2.0194542480847035,
      "grad_norm": 0.9805818200111389,
      "learning_rate": 5.099452551989092e-05,
      "loss": 3.0448,
      "step": 46920
    },
    {
      "epoch": 2.0198846518033915,
      "grad_norm": 0.9284600615501404,
      "learning_rate": 5.095402644691254e-05,
      "loss": 3.0234,
      "step": 46930
    },
    {
      "epoch": 2.02031505552208,
      "grad_norm": 0.9712677597999573,
      "learning_rate": 5.091353796357491e-05,
      "loss": 2.9321,
      "step": 46940
    },
    {
      "epoch": 2.020745459240768,
      "grad_norm": 0.9580633640289307,
      "learning_rate": 5.0873060078619914e-05,
      "loss": 2.9525,
      "step": 46950
    },
    {
      "epoch": 2.020745459240768,
      "eval_bleu": 27.427985399759713,
      "eval_gen_len": 27.57,
      "eval_loss": 2.7897658348083496,
      "eval_runtime": 58.5119,
      "eval_samples_per_second": 17.091,
      "eval_steps_per_second": 1.077,
      "step": 46950
    },
    {
      "epoch": 2.021175862959456,
      "grad_norm": 0.9150816202163696,
      "learning_rate": 5.083259280078732e-05,
      "loss": 2.9908,
      "step": 46960
    },
    {
      "epoch": 2.0216062666781442,
      "grad_norm": 0.8573542833328247,
      "learning_rate": 5.079213613881444e-05,
      "loss": 3.0723,
      "step": 46970
    },
    {
      "epoch": 2.022036670396832,
      "grad_norm": 0.935423731803894,
      "learning_rate": 5.07516901014365e-05,
      "loss": 2.9936,
      "step": 46980
    },
    {
      "epoch": 2.02246707411552,
      "grad_norm": 0.9381805658340454,
      "learning_rate": 5.0711254697386137e-05,
      "loss": 3.0477,
      "step": 46990
    },
    {
      "epoch": 2.0228974778342086,
      "grad_norm": 1.046044111251831,
      "learning_rate": 5.067082993539399e-05,
      "loss": 3.0683,
      "step": 47000
    },
    {
      "epoch": 2.0228974778342086,
      "eval_bleu": 27.48803416760499,
      "eval_gen_len": 27.558,
      "eval_loss": 2.789567470550537,
      "eval_runtime": 58.3024,
      "eval_samples_per_second": 17.152,
      "eval_steps_per_second": 1.081,
      "step": 47000
    },
    {
      "epoch": 2.0233278815528966,
      "grad_norm": 0.9368945360183716,
      "learning_rate": 5.0630415824188194e-05,
      "loss": 3.0819,
      "step": 47010
    },
    {
      "epoch": 2.023758285271585,
      "grad_norm": 0.854775071144104,
      "learning_rate": 5.059001237249472e-05,
      "loss": 2.987,
      "step": 47020
    },
    {
      "epoch": 2.024188688990273,
      "grad_norm": 0.9783265590667725,
      "learning_rate": 5.054961958903713e-05,
      "loss": 2.9754,
      "step": 47030
    },
    {
      "epoch": 2.024619092708961,
      "grad_norm": 0.9163330793380737,
      "learning_rate": 5.0509237482536756e-05,
      "loss": 2.9807,
      "step": 47040
    },
    {
      "epoch": 2.0250494964276493,
      "grad_norm": 0.8744290471076965,
      "learning_rate": 5.046886606171264e-05,
      "loss": 2.9747,
      "step": 47050
    },
    {
      "epoch": 2.0250494964276493,
      "eval_bleu": 27.134604415405544,
      "eval_gen_len": 27.482,
      "eval_loss": 2.79145884513855,
      "eval_runtime": 58.6337,
      "eval_samples_per_second": 17.055,
      "eval_steps_per_second": 1.074,
      "step": 47050
    },
    {
      "epoch": 2.0254799001463373,
      "grad_norm": 1.0723074674606323,
      "learning_rate": 5.042850533528145e-05,
      "loss": 2.9381,
      "step": 47060
    },
    {
      "epoch": 2.0259103038650252,
      "grad_norm": 1.0104656219482422,
      "learning_rate": 5.038815531195756e-05,
      "loss": 3.0005,
      "step": 47070
    },
    {
      "epoch": 2.0263407075837137,
      "grad_norm": 0.8519209623336792,
      "learning_rate": 5.034781600045302e-05,
      "loss": 2.9934,
      "step": 47080
    },
    {
      "epoch": 2.0267711113024016,
      "grad_norm": 0.9021782875061035,
      "learning_rate": 5.030748740947765e-05,
      "loss": 2.9225,
      "step": 47090
    },
    {
      "epoch": 2.0272015150210896,
      "grad_norm": 1.0334175825119019,
      "learning_rate": 5.026716954773884e-05,
      "loss": 2.9607,
      "step": 47100
    },
    {
      "epoch": 2.0272015150210896,
      "eval_bleu": 27.375559095504094,
      "eval_gen_len": 27.524,
      "eval_loss": 2.789463996887207,
      "eval_runtime": 58.2838,
      "eval_samples_per_second": 17.157,
      "eval_steps_per_second": 1.081,
      "step": 47100
    },
    {
      "epoch": 2.027631918739778,
      "grad_norm": 1.051112174987793,
      "learning_rate": 5.022686242394179e-05,
      "loss": 2.923,
      "step": 47110
    },
    {
      "epoch": 2.028062322458466,
      "grad_norm": 0.8723117709159851,
      "learning_rate": 5.018656604678925e-05,
      "loss": 3.0036,
      "step": 47120
    },
    {
      "epoch": 2.0284927261771544,
      "grad_norm": 0.8647922873497009,
      "learning_rate": 5.0146280424981776e-05,
      "loss": 2.9363,
      "step": 47130
    },
    {
      "epoch": 2.0289231298958423,
      "grad_norm": 0.9177572727203369,
      "learning_rate": 5.0106005567217495e-05,
      "loss": 3.0413,
      "step": 47140
    },
    {
      "epoch": 2.0293535336145303,
      "grad_norm": 0.9179443717002869,
      "learning_rate": 5.006574148219224e-05,
      "loss": 3.0003,
      "step": 47150
    },
    {
      "epoch": 2.0293535336145303,
      "eval_bleu": 27.333339339533662,
      "eval_gen_len": 27.451,
      "eval_loss": 2.791775703430176,
      "eval_runtime": 58.7586,
      "eval_samples_per_second": 17.019,
      "eval_steps_per_second": 1.072,
      "step": 47150
    },
    {
      "epoch": 2.0297839373332187,
      "grad_norm": 0.9746880531311035,
      "learning_rate": 5.002548817859959e-05,
      "loss": 2.9978,
      "step": 47160
    },
    {
      "epoch": 2.0302143410519067,
      "grad_norm": 0.9282627701759338,
      "learning_rate": 4.998524566513065e-05,
      "loss": 2.9696,
      "step": 47170
    },
    {
      "epoch": 2.0306447447705946,
      "grad_norm": 0.9265081286430359,
      "learning_rate": 4.994501395047439e-05,
      "loss": 3.0362,
      "step": 47180
    },
    {
      "epoch": 2.031075148489283,
      "grad_norm": 0.975669801235199,
      "learning_rate": 4.990479304331724e-05,
      "loss": 3.0269,
      "step": 47190
    },
    {
      "epoch": 2.031505552207971,
      "grad_norm": 0.9213919639587402,
      "learning_rate": 4.98645829523435e-05,
      "loss": 2.9977,
      "step": 47200
    },
    {
      "epoch": 2.031505552207971,
      "eval_bleu": 27.20733124485821,
      "eval_gen_len": 27.588,
      "eval_loss": 2.790369749069214,
      "eval_runtime": 58.9383,
      "eval_samples_per_second": 16.967,
      "eval_steps_per_second": 1.069,
      "step": 47200
    },
    {
      "epoch": 2.0319359559266594,
      "grad_norm": 0.9657052755355835,
      "learning_rate": 4.9824383686234934e-05,
      "loss": 2.9891,
      "step": 47210
    },
    {
      "epoch": 2.0323663596453474,
      "grad_norm": 1.0011875629425049,
      "learning_rate": 4.978419525367114e-05,
      "loss": 2.9553,
      "step": 47220
    },
    {
      "epoch": 2.0327967633640354,
      "grad_norm": 0.9264134764671326,
      "learning_rate": 4.974401766332929e-05,
      "loss": 3.025,
      "step": 47230
    },
    {
      "epoch": 2.0332271670827238,
      "grad_norm": 0.897179901599884,
      "learning_rate": 4.970385092388418e-05,
      "loss": 2.9236,
      "step": 47240
    },
    {
      "epoch": 2.0336575708014117,
      "grad_norm": 0.838030993938446,
      "learning_rate": 4.966369504400837e-05,
      "loss": 2.9872,
      "step": 47250
    },
    {
      "epoch": 2.0336575708014117,
      "eval_bleu": 27.151636351549723,
      "eval_gen_len": 27.513,
      "eval_loss": 2.791965961456299,
      "eval_runtime": 57.9498,
      "eval_samples_per_second": 17.256,
      "eval_steps_per_second": 1.087,
      "step": 47250
    },
    {
      "epoch": 2.0340879745200997,
      "grad_norm": 0.9352389574050903,
      "learning_rate": 4.962355003237198e-05,
      "loss": 2.9957,
      "step": 47260
    },
    {
      "epoch": 2.034518378238788,
      "grad_norm": 0.9213384389877319,
      "learning_rate": 4.958341589764286e-05,
      "loss": 2.9869,
      "step": 47270
    },
    {
      "epoch": 2.034948781957476,
      "grad_norm": 0.9242911338806152,
      "learning_rate": 4.954329264848643e-05,
      "loss": 2.9422,
      "step": 47280
    },
    {
      "epoch": 2.035379185676164,
      "grad_norm": 0.9512543082237244,
      "learning_rate": 4.9503180293565854e-05,
      "loss": 3.0306,
      "step": 47290
    },
    {
      "epoch": 2.0358095893948525,
      "grad_norm": 0.8477476239204407,
      "learning_rate": 4.946307884154187e-05,
      "loss": 2.9375,
      "step": 47300
    },
    {
      "epoch": 2.0358095893948525,
      "eval_bleu": 27.421300211115213,
      "eval_gen_len": 27.546,
      "eval_loss": 2.7884299755096436,
      "eval_runtime": 57.9081,
      "eval_samples_per_second": 17.269,
      "eval_steps_per_second": 1.088,
      "step": 47300
    },
    {
      "epoch": 2.0362399931135404,
      "grad_norm": 0.9245584607124329,
      "learning_rate": 4.9422988301072824e-05,
      "loss": 3.0208,
      "step": 47310
    },
    {
      "epoch": 2.036670396832229,
      "grad_norm": 0.9997103810310364,
      "learning_rate": 4.938290868081487e-05,
      "loss": 2.9678,
      "step": 47320
    },
    {
      "epoch": 2.037100800550917,
      "grad_norm": 0.7992109656333923,
      "learning_rate": 4.934283998942161e-05,
      "loss": 3.0864,
      "step": 47330
    },
    {
      "epoch": 2.0375312042696048,
      "grad_norm": 0.9707385897636414,
      "learning_rate": 4.9302782235544456e-05,
      "loss": 2.9417,
      "step": 47340
    },
    {
      "epoch": 2.037961607988293,
      "grad_norm": 1.014890432357788,
      "learning_rate": 4.92627354278323e-05,
      "loss": 3.0294,
      "step": 47350
    },
    {
      "epoch": 2.037961607988293,
      "eval_bleu": 27.41306502615148,
      "eval_gen_len": 27.519,
      "eval_loss": 2.788325309753418,
      "eval_runtime": 57.6444,
      "eval_samples_per_second": 17.348,
      "eval_steps_per_second": 1.093,
      "step": 47350
    },
    {
      "epoch": 2.038392011706981,
      "grad_norm": 1.0270835161209106,
      "learning_rate": 4.922269957493183e-05,
      "loss": 2.9298,
      "step": 47360
    },
    {
      "epoch": 2.038822415425669,
      "grad_norm": 0.9699775576591492,
      "learning_rate": 4.9182674685487204e-05,
      "loss": 3.0396,
      "step": 47370
    },
    {
      "epoch": 2.0392528191443575,
      "grad_norm": 0.8458110690116882,
      "learning_rate": 4.914266076814039e-05,
      "loss": 2.9299,
      "step": 47380
    },
    {
      "epoch": 2.0396832228630455,
      "grad_norm": 0.8843125104904175,
      "learning_rate": 4.910265783153084e-05,
      "loss": 3.0024,
      "step": 47390
    },
    {
      "epoch": 2.0401136265817335,
      "grad_norm": 1.0343647003173828,
      "learning_rate": 4.9062665884295666e-05,
      "loss": 3.0277,
      "step": 47400
    },
    {
      "epoch": 2.0401136265817335,
      "eval_bleu": 27.06614314630414,
      "eval_gen_len": 27.578,
      "eval_loss": 2.793165922164917,
      "eval_runtime": 57.8549,
      "eval_samples_per_second": 17.285,
      "eval_steps_per_second": 1.089,
      "step": 47400
    },
    {
      "epoch": 2.040544030300422,
      "grad_norm": 0.8875958919525146,
      "learning_rate": 4.9022684935069707e-05,
      "loss": 2.9364,
      "step": 47410
    },
    {
      "epoch": 2.04097443401911,
      "grad_norm": 0.9500114321708679,
      "learning_rate": 4.8982714992485255e-05,
      "loss": 2.9847,
      "step": 47420
    },
    {
      "epoch": 2.0414048377377982,
      "grad_norm": 0.9930957555770874,
      "learning_rate": 4.894275606517241e-05,
      "loss": 3.0181,
      "step": 47430
    },
    {
      "epoch": 2.041835241456486,
      "grad_norm": 0.925565242767334,
      "learning_rate": 4.890280816175874e-05,
      "loss": 2.9884,
      "step": 47440
    },
    {
      "epoch": 2.042265645175174,
      "grad_norm": 0.8322476744651794,
      "learning_rate": 4.886287129086956e-05,
      "loss": 3.0154,
      "step": 47450
    },
    {
      "epoch": 2.042265645175174,
      "eval_bleu": 27.388220145995174,
      "eval_gen_len": 27.599,
      "eval_loss": 2.7900755405426025,
      "eval_runtime": 57.5811,
      "eval_samples_per_second": 17.367,
      "eval_steps_per_second": 1.094,
      "step": 47450
    },
    {
      "epoch": 2.0426960488938626,
      "grad_norm": 0.8725771903991699,
      "learning_rate": 4.882294546112767e-05,
      "loss": 2.9836,
      "step": 47460
    },
    {
      "epoch": 2.0431264526125505,
      "grad_norm": 0.993066132068634,
      "learning_rate": 4.878303068115363e-05,
      "loss": 2.9329,
      "step": 47470
    },
    {
      "epoch": 2.0435568563312385,
      "grad_norm": 0.9028189182281494,
      "learning_rate": 4.874312695956551e-05,
      "loss": 2.858,
      "step": 47480
    },
    {
      "epoch": 2.043987260049927,
      "grad_norm": 1.0066990852355957,
      "learning_rate": 4.870323430497898e-05,
      "loss": 2.9898,
      "step": 47490
    },
    {
      "epoch": 2.044417663768615,
      "grad_norm": 0.906521201133728,
      "learning_rate": 4.866335272600745e-05,
      "loss": 3.0681,
      "step": 47500
    },
    {
      "epoch": 2.044417663768615,
      "eval_bleu": 27.356154757160247,
      "eval_gen_len": 27.571,
      "eval_loss": 2.788802146911621,
      "eval_runtime": 58.2432,
      "eval_samples_per_second": 17.169,
      "eval_steps_per_second": 1.082,
      "step": 47500
    },
    {
      "epoch": 2.0448480674873033,
      "grad_norm": 0.9733990430831909,
      "learning_rate": 4.862348223126178e-05,
      "loss": 2.9291,
      "step": 47510
    },
    {
      "epoch": 2.0452784712059913,
      "grad_norm": 0.945490837097168,
      "learning_rate": 4.858362282935055e-05,
      "loss": 3.0256,
      "step": 47520
    },
    {
      "epoch": 2.0457088749246792,
      "grad_norm": 0.8470648527145386,
      "learning_rate": 4.854377452887987e-05,
      "loss": 2.9952,
      "step": 47530
    },
    {
      "epoch": 2.0461392786433676,
      "grad_norm": 0.9067837595939636,
      "learning_rate": 4.8503937338453545e-05,
      "loss": 3.0442,
      "step": 47540
    },
    {
      "epoch": 2.0465696823620556,
      "grad_norm": 0.8970842957496643,
      "learning_rate": 4.8464111266672886e-05,
      "loss": 2.9726,
      "step": 47550
    },
    {
      "epoch": 2.0465696823620556,
      "eval_bleu": 27.245023993510028,
      "eval_gen_len": 27.551,
      "eval_loss": 2.7878339290618896,
      "eval_runtime": 57.7097,
      "eval_samples_per_second": 17.328,
      "eval_steps_per_second": 1.092,
      "step": 47550
    },
    {
      "epoch": 2.0470000860807436,
      "grad_norm": 0.7616286277770996,
      "learning_rate": 4.842429632213684e-05,
      "loss": 2.8809,
      "step": 47560
    },
    {
      "epoch": 2.047430489799432,
      "grad_norm": 0.9000611305236816,
      "learning_rate": 4.838449251344194e-05,
      "loss": 2.9785,
      "step": 47570
    },
    {
      "epoch": 2.04786089351812,
      "grad_norm": 0.9605188369750977,
      "learning_rate": 4.834469984918232e-05,
      "loss": 3.092,
      "step": 47580
    },
    {
      "epoch": 2.048291297236808,
      "grad_norm": 0.9453862309455872,
      "learning_rate": 4.830491833794979e-05,
      "loss": 3.0252,
      "step": 47590
    },
    {
      "epoch": 2.0487217009554963,
      "grad_norm": 0.9370602369308472,
      "learning_rate": 4.826514798833359e-05,
      "loss": 3.0377,
      "step": 47600
    },
    {
      "epoch": 2.0487217009554963,
      "eval_bleu": 27.24208471598924,
      "eval_gen_len": 27.547,
      "eval_loss": 2.7882535457611084,
      "eval_runtime": 58.0639,
      "eval_samples_per_second": 17.222,
      "eval_steps_per_second": 1.085,
      "step": 47600
    },
    {
      "epoch": 2.0491521046741843,
      "grad_norm": 0.9183399677276611,
      "learning_rate": 4.8225388808920715e-05,
      "loss": 2.9461,
      "step": 47610
    },
    {
      "epoch": 2.0495825083928727,
      "grad_norm": 0.7856180667877197,
      "learning_rate": 4.8185640808295574e-05,
      "loss": 2.9768,
      "step": 47620
    },
    {
      "epoch": 2.0500129121115607,
      "grad_norm": 0.9569419026374817,
      "learning_rate": 4.814590399504041e-05,
      "loss": 2.8145,
      "step": 47630
    },
    {
      "epoch": 2.0504433158302486,
      "grad_norm": 0.9040736556053162,
      "learning_rate": 4.8106178377734726e-05,
      "loss": 2.9495,
      "step": 47640
    },
    {
      "epoch": 2.050873719548937,
      "grad_norm": 1.019848108291626,
      "learning_rate": 4.8066463964955875e-05,
      "loss": 2.9119,
      "step": 47650
    },
    {
      "epoch": 2.050873719548937,
      "eval_bleu": 27.258385036129837,
      "eval_gen_len": 27.546,
      "eval_loss": 2.789496898651123,
      "eval_runtime": 58.029,
      "eval_samples_per_second": 17.233,
      "eval_steps_per_second": 1.086,
      "step": 47650
    },
    {
      "epoch": 2.051304123267625,
      "grad_norm": 0.9765094518661499,
      "learning_rate": 4.8026760765278665e-05,
      "loss": 3.009,
      "step": 47660
    },
    {
      "epoch": 2.051734526986313,
      "grad_norm": 0.9974053502082825,
      "learning_rate": 4.7987068787275524e-05,
      "loss": 2.9893,
      "step": 47670
    },
    {
      "epoch": 2.0521649307050014,
      "grad_norm": 0.818911075592041,
      "learning_rate": 4.7947388039516494e-05,
      "loss": 2.9024,
      "step": 47680
    },
    {
      "epoch": 2.0525953344236894,
      "grad_norm": 0.8685683012008667,
      "learning_rate": 4.7907718530569056e-05,
      "loss": 3.0409,
      "step": 47690
    },
    {
      "epoch": 2.0530257381423778,
      "grad_norm": 1.0716718435287476,
      "learning_rate": 4.786806026899845e-05,
      "loss": 2.926,
      "step": 47700
    },
    {
      "epoch": 2.0530257381423778,
      "eval_bleu": 27.31082528395012,
      "eval_gen_len": 27.573,
      "eval_loss": 2.7894537448883057,
      "eval_runtime": 57.2897,
      "eval_samples_per_second": 17.455,
      "eval_steps_per_second": 1.1,
      "step": 47700
    },
    {
      "epoch": 2.0534561418610657,
      "grad_norm": 1.005221962928772,
      "learning_rate": 4.782841326336736e-05,
      "loss": 3.0112,
      "step": 47710
    },
    {
      "epoch": 2.0538865455797537,
      "grad_norm": 0.8939151763916016,
      "learning_rate": 4.778877752223604e-05,
      "loss": 2.9683,
      "step": 47720
    },
    {
      "epoch": 2.054316949298442,
      "grad_norm": 1.0466008186340332,
      "learning_rate": 4.774915305416232e-05,
      "loss": 3.019,
      "step": 47730
    },
    {
      "epoch": 2.05474735301713,
      "grad_norm": 0.912362813949585,
      "learning_rate": 4.7709539867701704e-05,
      "loss": 2.905,
      "step": 47740
    },
    {
      "epoch": 2.055177756735818,
      "grad_norm": 1.0383591651916504,
      "learning_rate": 4.7669937971407095e-05,
      "loss": 3.0291,
      "step": 47750
    },
    {
      "epoch": 2.055177756735818,
      "eval_bleu": 27.255680730038794,
      "eval_gen_len": 27.596,
      "eval_loss": 2.7926011085510254,
      "eval_runtime": 58.0619,
      "eval_samples_per_second": 17.223,
      "eval_steps_per_second": 1.085,
      "step": 47750
    },
    {
      "epoch": 2.0556081604545065,
      "grad_norm": 0.9105147123336792,
      "learning_rate": 4.763034737382912e-05,
      "loss": 3.0965,
      "step": 47760
    },
    {
      "epoch": 2.0560385641731944,
      "grad_norm": 0.9421610236167908,
      "learning_rate": 4.75907680835158e-05,
      "loss": 2.9956,
      "step": 47770
    },
    {
      "epoch": 2.0564689678918824,
      "grad_norm": 0.8952837586402893,
      "learning_rate": 4.755120010901285e-05,
      "loss": 3.031,
      "step": 47780
    },
    {
      "epoch": 2.056899371610571,
      "grad_norm": 0.9261516332626343,
      "learning_rate": 4.751164345886354e-05,
      "loss": 2.9712,
      "step": 47790
    },
    {
      "epoch": 2.0573297753292588,
      "grad_norm": 0.907645046710968,
      "learning_rate": 4.747209814160854e-05,
      "loss": 2.9677,
      "step": 47800
    },
    {
      "epoch": 2.0573297753292588,
      "eval_bleu": 27.45439581176625,
      "eval_gen_len": 27.56,
      "eval_loss": 2.789618730545044,
      "eval_runtime": 58.4551,
      "eval_samples_per_second": 17.107,
      "eval_steps_per_second": 1.078,
      "step": 47800
    },
    {
      "epoch": 2.057760179047947,
      "grad_norm": 1.0540142059326172,
      "learning_rate": 4.7432564165786254e-05,
      "loss": 2.9882,
      "step": 47810
    },
    {
      "epoch": 2.058190582766635,
      "grad_norm": 0.9073408246040344,
      "learning_rate": 4.73930415399325e-05,
      "loss": 2.9565,
      "step": 47820
    },
    {
      "epoch": 2.058620986485323,
      "grad_norm": 0.9328787326812744,
      "learning_rate": 4.7353530272580795e-05,
      "loss": 3.0408,
      "step": 47830
    },
    {
      "epoch": 2.0590513902040115,
      "grad_norm": 0.8920733332633972,
      "learning_rate": 4.731403037226202e-05,
      "loss": 2.9509,
      "step": 47840
    },
    {
      "epoch": 2.0594817939226995,
      "grad_norm": 0.8635393977165222,
      "learning_rate": 4.7274541847504794e-05,
      "loss": 3.0585,
      "step": 47850
    },
    {
      "epoch": 2.0594817939226995,
      "eval_bleu": 27.644341190095467,
      "eval_gen_len": 27.621,
      "eval_loss": 2.7890639305114746,
      "eval_runtime": 59.2925,
      "eval_samples_per_second": 16.866,
      "eval_steps_per_second": 1.063,
      "step": 47850
    },
    {
      "epoch": 2.0599121976413874,
      "grad_norm": 0.8632166981697083,
      "learning_rate": 4.7235064706835096e-05,
      "loss": 3.0027,
      "step": 47860
    },
    {
      "epoch": 2.060342601360076,
      "grad_norm": 0.9274776577949524,
      "learning_rate": 4.719559895877663e-05,
      "loss": 2.9894,
      "step": 47870
    },
    {
      "epoch": 2.060773005078764,
      "grad_norm": 0.8090236783027649,
      "learning_rate": 4.715614461185048e-05,
      "loss": 2.9262,
      "step": 47880
    },
    {
      "epoch": 2.061203408797452,
      "grad_norm": 1.003708004951477,
      "learning_rate": 4.711670167457532e-05,
      "loss": 2.88,
      "step": 47890
    },
    {
      "epoch": 2.06163381251614,
      "grad_norm": 1.0068368911743164,
      "learning_rate": 4.7077270155467445e-05,
      "loss": 2.9217,
      "step": 47900
    },
    {
      "epoch": 2.06163381251614,
      "eval_bleu": 27.467125606166828,
      "eval_gen_len": 27.596,
      "eval_loss": 2.791518449783325,
      "eval_runtime": 58.1537,
      "eval_samples_per_second": 17.196,
      "eval_steps_per_second": 1.083,
      "step": 47900
    },
    {
      "epoch": 2.062064216234828,
      "grad_norm": 0.9591138362884521,
      "learning_rate": 4.703785006304053e-05,
      "loss": 3.053,
      "step": 47910
    },
    {
      "epoch": 2.0624946199535166,
      "grad_norm": 0.8612590432167053,
      "learning_rate": 4.699844140580596e-05,
      "loss": 2.9952,
      "step": 47920
    },
    {
      "epoch": 2.0629250236722045,
      "grad_norm": 0.9225105047225952,
      "learning_rate": 4.695904419227246e-05,
      "loss": 3.0591,
      "step": 47930
    },
    {
      "epoch": 2.0633554273908925,
      "grad_norm": 0.872912585735321,
      "learning_rate": 4.691965843094648e-05,
      "loss": 2.9745,
      "step": 47940
    },
    {
      "epoch": 2.063785831109581,
      "grad_norm": 0.9257040023803711,
      "learning_rate": 4.6880284130331844e-05,
      "loss": 2.9775,
      "step": 47950
    },
    {
      "epoch": 2.063785831109581,
      "eval_bleu": 27.767119996992303,
      "eval_gen_len": 27.613,
      "eval_loss": 2.789519786834717,
      "eval_runtime": 58.269,
      "eval_samples_per_second": 17.162,
      "eval_steps_per_second": 1.081,
      "step": 47950
    },
    {
      "epoch": 2.064216234828269,
      "grad_norm": 0.9727665185928345,
      "learning_rate": 4.684092129892993e-05,
      "loss": 2.9857,
      "step": 47960
    },
    {
      "epoch": 2.064646638546957,
      "grad_norm": 0.8675928711891174,
      "learning_rate": 4.6801569945239734e-05,
      "loss": 2.9765,
      "step": 47970
    },
    {
      "epoch": 2.0650770422656453,
      "grad_norm": 0.9005471467971802,
      "learning_rate": 4.676223007775764e-05,
      "loss": 2.9545,
      "step": 47980
    },
    {
      "epoch": 2.0655074459843332,
      "grad_norm": 0.9070753455162048,
      "learning_rate": 4.67229017049777e-05,
      "loss": 2.9303,
      "step": 47990
    },
    {
      "epoch": 2.0659378497030216,
      "grad_norm": 0.9042891263961792,
      "learning_rate": 4.6683584835391304e-05,
      "loss": 2.9572,
      "step": 48000
    },
    {
      "epoch": 2.0659378497030216,
      "eval_bleu": 27.64804425397172,
      "eval_gen_len": 27.621,
      "eval_loss": 2.7893729209899902,
      "eval_runtime": 58.0208,
      "eval_samples_per_second": 17.235,
      "eval_steps_per_second": 1.086,
      "step": 48000
    },
    {
      "epoch": 2.0663682534217096,
      "grad_norm": 0.9419703483581543,
      "learning_rate": 4.664427947748755e-05,
      "loss": 2.9999,
      "step": 48010
    },
    {
      "epoch": 2.0667986571403976,
      "grad_norm": 0.8780612945556641,
      "learning_rate": 4.660498563975288e-05,
      "loss": 2.8958,
      "step": 48020
    },
    {
      "epoch": 2.067229060859086,
      "grad_norm": 0.978932797908783,
      "learning_rate": 4.6565703330671405e-05,
      "loss": 3.0391,
      "step": 48030
    },
    {
      "epoch": 2.067659464577774,
      "grad_norm": 0.9977205395698547,
      "learning_rate": 4.652643255872462e-05,
      "loss": 2.9854,
      "step": 48040
    },
    {
      "epoch": 2.068089868296462,
      "grad_norm": 0.9226742386817932,
      "learning_rate": 4.648717333239154e-05,
      "loss": 2.8965,
      "step": 48050
    },
    {
      "epoch": 2.068089868296462,
      "eval_bleu": 27.326035476827954,
      "eval_gen_len": 27.528,
      "eval_loss": 2.7916207313537598,
      "eval_runtime": 58.3094,
      "eval_samples_per_second": 17.15,
      "eval_steps_per_second": 1.08,
      "step": 48050
    },
    {
      "epoch": 2.0685202720151503,
      "grad_norm": 0.8486756682395935,
      "learning_rate": 4.644792566014882e-05,
      "loss": 2.8897,
      "step": 48060
    },
    {
      "epoch": 2.0689506757338383,
      "grad_norm": 0.8224453330039978,
      "learning_rate": 4.640868955047043e-05,
      "loss": 3.0073,
      "step": 48070
    },
    {
      "epoch": 2.0693810794525263,
      "grad_norm": 0.90743088722229,
      "learning_rate": 4.636946501182802e-05,
      "loss": 2.8975,
      "step": 48080
    },
    {
      "epoch": 2.0698114831712147,
      "grad_norm": 0.9014110565185547,
      "learning_rate": 4.6330252052690573e-05,
      "loss": 2.9451,
      "step": 48090
    },
    {
      "epoch": 2.0702418868899026,
      "grad_norm": 0.8622792363166809,
      "learning_rate": 4.629105068152475e-05,
      "loss": 2.9537,
      "step": 48100
    },
    {
      "epoch": 2.0702418868899026,
      "eval_bleu": 27.465832867996628,
      "eval_gen_len": 27.595,
      "eval_loss": 2.78952693939209,
      "eval_runtime": 58.6768,
      "eval_samples_per_second": 17.043,
      "eval_steps_per_second": 1.074,
      "step": 48100
    },
    {
      "epoch": 2.070672290608591,
      "grad_norm": 0.9688475728034973,
      "learning_rate": 4.625186090679453e-05,
      "loss": 2.907,
      "step": 48110
    },
    {
      "epoch": 2.071102694327279,
      "grad_norm": 0.9584150314331055,
      "learning_rate": 4.621268273696157e-05,
      "loss": 2.9967,
      "step": 48120
    },
    {
      "epoch": 2.071533098045967,
      "grad_norm": 0.8638754487037659,
      "learning_rate": 4.6173516180484864e-05,
      "loss": 2.9373,
      "step": 48130
    },
    {
      "epoch": 2.0719635017646554,
      "grad_norm": 0.9427036046981812,
      "learning_rate": 4.6134361245820945e-05,
      "loss": 2.9671,
      "step": 48140
    },
    {
      "epoch": 2.0723939054833433,
      "grad_norm": 0.9391994476318359,
      "learning_rate": 4.609521794142393e-05,
      "loss": 2.9162,
      "step": 48150
    },
    {
      "epoch": 2.0723939054833433,
      "eval_bleu": 27.309794737081372,
      "eval_gen_len": 27.614,
      "eval_loss": 2.7891652584075928,
      "eval_runtime": 58.9649,
      "eval_samples_per_second": 16.959,
      "eval_steps_per_second": 1.068,
      "step": 48150
    },
    {
      "epoch": 2.0728243092020313,
      "grad_norm": 0.8606880903244019,
      "learning_rate": 4.605608627574527e-05,
      "loss": 2.9579,
      "step": 48160
    },
    {
      "epoch": 2.0732547129207197,
      "grad_norm": 0.9468750357627869,
      "learning_rate": 4.601696625723405e-05,
      "loss": 2.9436,
      "step": 48170
    },
    {
      "epoch": 2.0736851166394077,
      "grad_norm": 0.8486166000366211,
      "learning_rate": 4.597785789433671e-05,
      "loss": 2.9169,
      "step": 48180
    },
    {
      "epoch": 2.074115520358096,
      "grad_norm": 0.9711928963661194,
      "learning_rate": 4.5938761195497306e-05,
      "loss": 2.9626,
      "step": 48190
    },
    {
      "epoch": 2.074545924076784,
      "grad_norm": 0.9424186944961548,
      "learning_rate": 4.5899676169157255e-05,
      "loss": 2.9701,
      "step": 48200
    },
    {
      "epoch": 2.074545924076784,
      "eval_bleu": 27.266606584061027,
      "eval_gen_len": 27.54,
      "eval_loss": 2.7896995544433594,
      "eval_runtime": 58.1178,
      "eval_samples_per_second": 17.206,
      "eval_steps_per_second": 1.084,
      "step": 48200
    },
    {
      "epoch": 2.074976327795472,
      "grad_norm": 0.8484879732131958,
      "learning_rate": 4.5860602823755484e-05,
      "loss": 2.9541,
      "step": 48210
    },
    {
      "epoch": 2.0754067315141604,
      "grad_norm": 0.9755206108093262,
      "learning_rate": 4.582154116772849e-05,
      "loss": 2.8879,
      "step": 48220
    },
    {
      "epoch": 2.0758371352328484,
      "grad_norm": 0.8583067655563354,
      "learning_rate": 4.57824912095101e-05,
      "loss": 2.9295,
      "step": 48230
    },
    {
      "epoch": 2.0762675389515364,
      "grad_norm": 0.9007099866867065,
      "learning_rate": 4.574345295753175e-05,
      "loss": 2.9802,
      "step": 48240
    },
    {
      "epoch": 2.076697942670225,
      "grad_norm": 0.8502309322357178,
      "learning_rate": 4.5704426420222234e-05,
      "loss": 2.9814,
      "step": 48250
    },
    {
      "epoch": 2.076697942670225,
      "eval_bleu": 27.084069220751772,
      "eval_gen_len": 27.558,
      "eval_loss": 2.7916259765625,
      "eval_runtime": 58.7236,
      "eval_samples_per_second": 17.029,
      "eval_steps_per_second": 1.073,
      "step": 48250
    },
    {
      "epoch": 2.0771283463889127,
      "grad_norm": 0.9978270530700684,
      "learning_rate": 4.566541160600795e-05,
      "loss": 3.0894,
      "step": 48260
    },
    {
      "epoch": 2.0775587501076007,
      "grad_norm": 0.8093603849411011,
      "learning_rate": 4.562640852331257e-05,
      "loss": 3.0184,
      "step": 48270
    },
    {
      "epoch": 2.077989153826289,
      "grad_norm": 0.9603430032730103,
      "learning_rate": 4.5587417180557504e-05,
      "loss": 2.9573,
      "step": 48280
    },
    {
      "epoch": 2.078419557544977,
      "grad_norm": 0.8782671689987183,
      "learning_rate": 4.554843758616131e-05,
      "loss": 2.9691,
      "step": 48290
    },
    {
      "epoch": 2.0788499612636655,
      "grad_norm": 0.8508761525154114,
      "learning_rate": 4.550946974854023e-05,
      "loss": 2.8794,
      "step": 48300
    },
    {
      "epoch": 2.0788499612636655,
      "eval_bleu": 27.28716077473205,
      "eval_gen_len": 27.574,
      "eval_loss": 2.790428638458252,
      "eval_runtime": 57.9991,
      "eval_samples_per_second": 17.242,
      "eval_steps_per_second": 1.086,
      "step": 48300
    },
    {
      "epoch": 2.0792803649823535,
      "grad_norm": 0.8690000772476196,
      "learning_rate": 4.547051367610796e-05,
      "loss": 2.9249,
      "step": 48310
    },
    {
      "epoch": 2.0797107687010414,
      "grad_norm": 0.98548424243927,
      "learning_rate": 4.543156937727554e-05,
      "loss": 2.9617,
      "step": 48320
    },
    {
      "epoch": 2.08014117241973,
      "grad_norm": 0.9487442374229431,
      "learning_rate": 4.539263686045159e-05,
      "loss": 3.0084,
      "step": 48330
    },
    {
      "epoch": 2.080571576138418,
      "grad_norm": 0.9048148989677429,
      "learning_rate": 4.535371613404206e-05,
      "loss": 2.8696,
      "step": 48340
    },
    {
      "epoch": 2.0810019798571058,
      "grad_norm": 0.8834100365638733,
      "learning_rate": 4.531480720645049e-05,
      "loss": 2.9038,
      "step": 48350
    },
    {
      "epoch": 2.0810019798571058,
      "eval_bleu": 27.493989463678417,
      "eval_gen_len": 27.522,
      "eval_loss": 2.7894606590270996,
      "eval_runtime": 57.9698,
      "eval_samples_per_second": 17.25,
      "eval_steps_per_second": 1.087,
      "step": 48350
    },
    {
      "epoch": 2.081432383575794,
      "grad_norm": 0.9383212924003601,
      "learning_rate": 4.527591008607778e-05,
      "loss": 2.9323,
      "step": 48360
    },
    {
      "epoch": 2.081862787294482,
      "grad_norm": 0.9815220832824707,
      "learning_rate": 4.52370247813223e-05,
      "loss": 3.0167,
      "step": 48370
    },
    {
      "epoch": 2.0822931910131706,
      "grad_norm": 0.8366872072219849,
      "learning_rate": 4.519815130057985e-05,
      "loss": 3.0095,
      "step": 48380
    },
    {
      "epoch": 2.0827235947318585,
      "grad_norm": 1.0439753532409668,
      "learning_rate": 4.515928965224375e-05,
      "loss": 2.9039,
      "step": 48390
    },
    {
      "epoch": 2.0831539984505465,
      "grad_norm": 0.9122330546379089,
      "learning_rate": 4.5120439844704666e-05,
      "loss": 2.9601,
      "step": 48400
    },
    {
      "epoch": 2.0831539984505465,
      "eval_bleu": 27.405885388259648,
      "eval_gen_len": 27.534,
      "eval_loss": 2.787598133087158,
      "eval_runtime": 57.3948,
      "eval_samples_per_second": 17.423,
      "eval_steps_per_second": 1.098,
      "step": 48400
    },
    {
      "epoch": 2.083584402169235,
      "grad_norm": 0.8012080192565918,
      "learning_rate": 4.508160188635079e-05,
      "loss": 2.8846,
      "step": 48410
    },
    {
      "epoch": 2.084014805887923,
      "grad_norm": 0.9181188941001892,
      "learning_rate": 4.504277578556775e-05,
      "loss": 3.012,
      "step": 48420
    },
    {
      "epoch": 2.084445209606611,
      "grad_norm": 0.9853352308273315,
      "learning_rate": 4.500396155073853e-05,
      "loss": 2.9205,
      "step": 48430
    },
    {
      "epoch": 2.0848756133252992,
      "grad_norm": 0.8707452416419983,
      "learning_rate": 4.496515919024371e-05,
      "loss": 3.0982,
      "step": 48440
    },
    {
      "epoch": 2.085306017043987,
      "grad_norm": 0.9712920784950256,
      "learning_rate": 4.4926368712461065e-05,
      "loss": 3.0117,
      "step": 48450
    },
    {
      "epoch": 2.085306017043987,
      "eval_bleu": 27.117113135085482,
      "eval_gen_len": 27.568,
      "eval_loss": 2.790379524230957,
      "eval_runtime": 57.8772,
      "eval_samples_per_second": 17.278,
      "eval_steps_per_second": 1.089,
      "step": 48450
    },
    {
      "epoch": 2.085736420762675,
      "grad_norm": 0.9322909116744995,
      "learning_rate": 4.488759012576604e-05,
      "loss": 2.9068,
      "step": 48460
    },
    {
      "epoch": 2.0861668244813636,
      "grad_norm": 0.943287193775177,
      "learning_rate": 4.484882343853137e-05,
      "loss": 2.8821,
      "step": 48470
    },
    {
      "epoch": 2.0865972282000516,
      "grad_norm": 0.8496598601341248,
      "learning_rate": 4.481006865912733e-05,
      "loss": 2.9433,
      "step": 48480
    },
    {
      "epoch": 2.08702763191874,
      "grad_norm": 0.8170950412750244,
      "learning_rate": 4.4771325795921507e-05,
      "loss": 2.9777,
      "step": 48490
    },
    {
      "epoch": 2.087458035637428,
      "grad_norm": 1.0060360431671143,
      "learning_rate": 4.4732594857278966e-05,
      "loss": 3.0312,
      "step": 48500
    },
    {
      "epoch": 2.087458035637428,
      "eval_bleu": 27.481865516668506,
      "eval_gen_len": 27.543,
      "eval_loss": 2.7896034717559814,
      "eval_runtime": 57.9355,
      "eval_samples_per_second": 17.261,
      "eval_steps_per_second": 1.087,
      "step": 48500
    },
    {
      "epoch": 2.087888439356116,
      "grad_norm": 0.9478632807731628,
      "learning_rate": 4.469387585156227e-05,
      "loss": 2.9103,
      "step": 48510
    },
    {
      "epoch": 2.0883188430748043,
      "grad_norm": 0.9421700835227966,
      "learning_rate": 4.465516878713131e-05,
      "loss": 2.9526,
      "step": 48520
    },
    {
      "epoch": 2.0887492467934923,
      "grad_norm": 0.9501855373382568,
      "learning_rate": 4.4616473672343395e-05,
      "loss": 3.0505,
      "step": 48530
    },
    {
      "epoch": 2.0891796505121802,
      "grad_norm": 0.9460691213607788,
      "learning_rate": 4.457779051555326e-05,
      "loss": 3.036,
      "step": 48540
    },
    {
      "epoch": 2.0896100542308687,
      "grad_norm": 0.9970806837081909,
      "learning_rate": 4.4539119325113174e-05,
      "loss": 2.8712,
      "step": 48550
    },
    {
      "epoch": 2.0896100542308687,
      "eval_bleu": 27.272069936783204,
      "eval_gen_len": 27.629,
      "eval_loss": 2.7915828227996826,
      "eval_runtime": 58.4351,
      "eval_samples_per_second": 17.113,
      "eval_steps_per_second": 1.078,
      "step": 48550
    },
    {
      "epoch": 2.0900404579495566,
      "grad_norm": 1.0573267936706543,
      "learning_rate": 4.4500460109372644e-05,
      "loss": 2.9297,
      "step": 48560
    },
    {
      "epoch": 2.090470861668245,
      "grad_norm": 0.8592000603675842,
      "learning_rate": 4.4461812876678756e-05,
      "loss": 2.9172,
      "step": 48570
    },
    {
      "epoch": 2.090901265386933,
      "grad_norm": 0.879779040813446,
      "learning_rate": 4.4423177635375855e-05,
      "loss": 3.0764,
      "step": 48580
    },
    {
      "epoch": 2.091331669105621,
      "grad_norm": 0.8909615874290466,
      "learning_rate": 4.4384554393805854e-05,
      "loss": 2.9511,
      "step": 48590
    },
    {
      "epoch": 2.0917620728243094,
      "grad_norm": 0.9049314260482788,
      "learning_rate": 4.4345943160307954e-05,
      "loss": 3.0162,
      "step": 48600
    },
    {
      "epoch": 2.0917620728243094,
      "eval_bleu": 27.327132896356524,
      "eval_gen_len": 27.51,
      "eval_loss": 2.789620876312256,
      "eval_runtime": 57.9892,
      "eval_samples_per_second": 17.245,
      "eval_steps_per_second": 1.086,
      "step": 48600
    },
    {
      "epoch": 2.0921924765429973,
      "grad_norm": 0.872161865234375,
      "learning_rate": 4.430734394321878e-05,
      "loss": 2.9262,
      "step": 48610
    },
    {
      "epoch": 2.0926228802616853,
      "grad_norm": 0.8804024457931519,
      "learning_rate": 4.426875675087244e-05,
      "loss": 2.9327,
      "step": 48620
    },
    {
      "epoch": 2.0930532839803737,
      "grad_norm": 0.9268758893013,
      "learning_rate": 4.4230181591600326e-05,
      "loss": 3.0874,
      "step": 48630
    },
    {
      "epoch": 2.0934836876990617,
      "grad_norm": 0.907476007938385,
      "learning_rate": 4.419161847373138e-05,
      "loss": 2.9785,
      "step": 48640
    },
    {
      "epoch": 2.0939140914177496,
      "grad_norm": 0.8784180879592896,
      "learning_rate": 4.4153067405591785e-05,
      "loss": 2.9329,
      "step": 48650
    },
    {
      "epoch": 2.0939140914177496,
      "eval_bleu": 27.290404156290446,
      "eval_gen_len": 27.603,
      "eval_loss": 2.7933828830718994,
      "eval_runtime": 58.5394,
      "eval_samples_per_second": 17.083,
      "eval_steps_per_second": 1.076,
      "step": 48650
    },
    {
      "epoch": 2.094344495136438,
      "grad_norm": 0.956680417060852,
      "learning_rate": 4.411452839550526e-05,
      "loss": 2.9793,
      "step": 48660
    },
    {
      "epoch": 2.094774898855126,
      "grad_norm": 0.9294587969779968,
      "learning_rate": 4.407600145179282e-05,
      "loss": 3.0077,
      "step": 48670
    },
    {
      "epoch": 2.0952053025738144,
      "grad_norm": 0.9594752192497253,
      "learning_rate": 4.403748658277295e-05,
      "loss": 3.0472,
      "step": 48680
    },
    {
      "epoch": 2.0956357062925024,
      "grad_norm": 0.9866001009941101,
      "learning_rate": 4.3998983796761484e-05,
      "loss": 3.0469,
      "step": 48690
    },
    {
      "epoch": 2.0960661100111904,
      "grad_norm": 0.9757418036460876,
      "learning_rate": 4.396049310207161e-05,
      "loss": 2.9677,
      "step": 48700
    },
    {
      "epoch": 2.0960661100111904,
      "eval_bleu": 27.384867406124155,
      "eval_gen_len": 27.531,
      "eval_loss": 2.790013313293457,
      "eval_runtime": 57.7959,
      "eval_samples_per_second": 17.302,
      "eval_steps_per_second": 1.09,
      "step": 48700
    },
    {
      "epoch": 2.0964965137298788,
      "grad_norm": 0.953456461429596,
      "learning_rate": 4.392201450701402e-05,
      "loss": 2.9917,
      "step": 48710
    },
    {
      "epoch": 2.0969269174485667,
      "grad_norm": 0.9482024312019348,
      "learning_rate": 4.388354801989667e-05,
      "loss": 3.0263,
      "step": 48720
    },
    {
      "epoch": 2.0973573211672547,
      "grad_norm": 0.908334493637085,
      "learning_rate": 4.3845093649025e-05,
      "loss": 2.9488,
      "step": 48730
    },
    {
      "epoch": 2.097787724885943,
      "grad_norm": 0.9552208185195923,
      "learning_rate": 4.380665140270175e-05,
      "loss": 2.8715,
      "step": 48740
    },
    {
      "epoch": 2.098218128604631,
      "grad_norm": 0.8775005340576172,
      "learning_rate": 4.376822128922713e-05,
      "loss": 2.8965,
      "step": 48750
    },
    {
      "epoch": 2.098218128604631,
      "eval_bleu": 27.39539767359035,
      "eval_gen_len": 27.597,
      "eval_loss": 2.7884747982025146,
      "eval_runtime": 57.7677,
      "eval_samples_per_second": 17.311,
      "eval_steps_per_second": 1.091,
      "step": 48750
    },
    {
      "epoch": 2.0986485323233195,
      "grad_norm": 0.9791111350059509,
      "learning_rate": 4.372980331689863e-05,
      "loss": 3.0222,
      "step": 48760
    },
    {
      "epoch": 2.0990789360420075,
      "grad_norm": 0.9814885258674622,
      "learning_rate": 4.369139749401123e-05,
      "loss": 3.0109,
      "step": 48770
    },
    {
      "epoch": 2.0995093397606954,
      "grad_norm": 0.9500210285186768,
      "learning_rate": 4.365300382885721e-05,
      "loss": 3.0175,
      "step": 48780
    },
    {
      "epoch": 2.099939743479384,
      "grad_norm": 0.956583559513092,
      "learning_rate": 4.361462232972618e-05,
      "loss": 3.0143,
      "step": 48790
    },
    {
      "epoch": 2.100370147198072,
      "grad_norm": 0.9970039129257202,
      "learning_rate": 4.3576253004905286e-05,
      "loss": 3.0222,
      "step": 48800
    },
    {
      "epoch": 2.100370147198072,
      "eval_bleu": 27.012449932316912,
      "eval_gen_len": 27.501,
      "eval_loss": 2.792861223220825,
      "eval_runtime": 57.7058,
      "eval_samples_per_second": 17.329,
      "eval_steps_per_second": 1.092,
      "step": 48800
    },
    {
      "epoch": 2.1008005509167598,
      "grad_norm": 0.9209589958190918,
      "learning_rate": 4.353789586267887e-05,
      "loss": 3.0397,
      "step": 48810
    },
    {
      "epoch": 2.101230954635448,
      "grad_norm": 0.9283101558685303,
      "learning_rate": 4.349955091132878e-05,
      "loss": 2.9404,
      "step": 48820
    },
    {
      "epoch": 2.101661358354136,
      "grad_norm": 0.8427969217300415,
      "learning_rate": 4.34612181591341e-05,
      "loss": 2.9554,
      "step": 48830
    },
    {
      "epoch": 2.102091762072824,
      "grad_norm": 0.8806201815605164,
      "learning_rate": 4.342289761437144e-05,
      "loss": 2.96,
      "step": 48840
    },
    {
      "epoch": 2.1025221657915125,
      "grad_norm": 0.9688988924026489,
      "learning_rate": 4.3384589285314633e-05,
      "loss": 2.9144,
      "step": 48850
    },
    {
      "epoch": 2.1025221657915125,
      "eval_bleu": 27.19054363117008,
      "eval_gen_len": 27.616,
      "eval_loss": 2.790546178817749,
      "eval_runtime": 58.0572,
      "eval_samples_per_second": 17.224,
      "eval_steps_per_second": 1.085,
      "step": 48850
    },
    {
      "epoch": 2.1029525695102005,
      "grad_norm": 0.9682892560958862,
      "learning_rate": 4.33462931802349e-05,
      "loss": 2.9858,
      "step": 48860
    },
    {
      "epoch": 2.103382973228889,
      "grad_norm": 0.9340012073516846,
      "learning_rate": 4.330800930740092e-05,
      "loss": 2.9348,
      "step": 48870
    },
    {
      "epoch": 2.103813376947577,
      "grad_norm": 0.9049645662307739,
      "learning_rate": 4.326973767507859e-05,
      "loss": 3.1094,
      "step": 48880
    },
    {
      "epoch": 2.104243780666265,
      "grad_norm": 0.9913410544395447,
      "learning_rate": 4.323147829153131e-05,
      "loss": 3.0395,
      "step": 48890
    },
    {
      "epoch": 2.1046741843849532,
      "grad_norm": 0.912784218788147,
      "learning_rate": 4.3193231165019674e-05,
      "loss": 2.9774,
      "step": 48900
    },
    {
      "epoch": 2.1046741843849532,
      "eval_bleu": 27.20449487415993,
      "eval_gen_len": 27.567,
      "eval_loss": 2.7894508838653564,
      "eval_runtime": 58.7698,
      "eval_samples_per_second": 17.016,
      "eval_steps_per_second": 1.072,
      "step": 48900
    },
    {
      "epoch": 2.105104588103641,
      "grad_norm": 0.8699454069137573,
      "learning_rate": 4.315499630380182e-05,
      "loss": 2.9422,
      "step": 48910
    },
    {
      "epoch": 2.105534991822329,
      "grad_norm": 0.8341930508613586,
      "learning_rate": 4.311677371613303e-05,
      "loss": 2.9486,
      "step": 48920
    },
    {
      "epoch": 2.1059653955410176,
      "grad_norm": 1.0364255905151367,
      "learning_rate": 4.3078563410266124e-05,
      "loss": 2.9182,
      "step": 48930
    },
    {
      "epoch": 2.1063957992597055,
      "grad_norm": 1.0032891035079956,
      "learning_rate": 4.3040365394451154e-05,
      "loss": 3.0281,
      "step": 48940
    },
    {
      "epoch": 2.106826202978394,
      "grad_norm": 0.8321212530136108,
      "learning_rate": 4.3002179676935506e-05,
      "loss": 3.0985,
      "step": 48950
    },
    {
      "epoch": 2.106826202978394,
      "eval_bleu": 27.403031479743508,
      "eval_gen_len": 27.567,
      "eval_loss": 2.7895543575286865,
      "eval_runtime": 58.1127,
      "eval_samples_per_second": 17.208,
      "eval_steps_per_second": 1.084,
      "step": 48950
    },
    {
      "epoch": 2.107256606697082,
      "grad_norm": 0.8679625988006592,
      "learning_rate": 4.296400626596404e-05,
      "loss": 2.9851,
      "step": 48960
    },
    {
      "epoch": 2.10768701041577,
      "grad_norm": 0.9090720415115356,
      "learning_rate": 4.292584516977879e-05,
      "loss": 2.9888,
      "step": 48970
    },
    {
      "epoch": 2.1081174141344583,
      "grad_norm": 0.8811689019203186,
      "learning_rate": 4.288769639661929e-05,
      "loss": 2.9924,
      "step": 48980
    },
    {
      "epoch": 2.1085478178531463,
      "grad_norm": 0.8592150211334229,
      "learning_rate": 4.2849559954722275e-05,
      "loss": 3.0435,
      "step": 48990
    },
    {
      "epoch": 2.1089782215718342,
      "grad_norm": 0.8912795186042786,
      "learning_rate": 4.281143585232193e-05,
      "loss": 2.9354,
      "step": 49000
    },
    {
      "epoch": 2.1089782215718342,
      "eval_bleu": 27.40601198345135,
      "eval_gen_len": 27.514,
      "eval_loss": 2.790940284729004,
      "eval_runtime": 58.6761,
      "eval_samples_per_second": 17.043,
      "eval_steps_per_second": 1.074,
      "step": 49000
    },
    {
      "epoch": 2.1094086252905226,
      "grad_norm": 0.8241493701934814,
      "learning_rate": 4.2773324097649724e-05,
      "loss": 2.9442,
      "step": 49010
    },
    {
      "epoch": 2.1098390290092106,
      "grad_norm": 0.8578172326087952,
      "learning_rate": 4.2735224698934437e-05,
      "loss": 2.9106,
      "step": 49020
    },
    {
      "epoch": 2.1102694327278986,
      "grad_norm": 1.0547817945480347,
      "learning_rate": 4.2697137664402184e-05,
      "loss": 2.9265,
      "step": 49030
    },
    {
      "epoch": 2.110699836446587,
      "grad_norm": 0.8734729886054993,
      "learning_rate": 4.265906300227646e-05,
      "loss": 2.9639,
      "step": 49040
    },
    {
      "epoch": 2.111130240165275,
      "grad_norm": 0.9760169386863708,
      "learning_rate": 4.26210007207781e-05,
      "loss": 3.0551,
      "step": 49050
    },
    {
      "epoch": 2.111130240165275,
      "eval_bleu": 27.437259637376332,
      "eval_gen_len": 27.522,
      "eval_loss": 2.790750026702881,
      "eval_runtime": 58.8074,
      "eval_samples_per_second": 17.005,
      "eval_steps_per_second": 1.071,
      "step": 49050
    },
    {
      "epoch": 2.1115606438839634,
      "grad_norm": 0.879643976688385,
      "learning_rate": 4.2582950828125165e-05,
      "loss": 2.896,
      "step": 49060
    },
    {
      "epoch": 2.1119910476026513,
      "grad_norm": 1.0748549699783325,
      "learning_rate": 4.2544913332533164e-05,
      "loss": 3.0351,
      "step": 49070
    },
    {
      "epoch": 2.1124214513213393,
      "grad_norm": 0.9098755121231079,
      "learning_rate": 4.2506888242214816e-05,
      "loss": 3.0488,
      "step": 49080
    },
    {
      "epoch": 2.1128518550400277,
      "grad_norm": 0.8848896026611328,
      "learning_rate": 4.24688755653803e-05,
      "loss": 2.9588,
      "step": 49090
    },
    {
      "epoch": 2.1132822587587157,
      "grad_norm": 1.153739333152771,
      "learning_rate": 4.2430875310236895e-05,
      "loss": 2.9748,
      "step": 49100
    },
    {
      "epoch": 2.1132822587587157,
      "eval_bleu": 27.34418389229174,
      "eval_gen_len": 27.562,
      "eval_loss": 2.7910311222076416,
      "eval_runtime": 59.0876,
      "eval_samples_per_second": 16.924,
      "eval_steps_per_second": 1.066,
      "step": 49100
    },
    {
      "epoch": 2.1137126624774036,
      "grad_norm": 0.9942357540130615,
      "learning_rate": 4.239288748498944e-05,
      "loss": 3.1306,
      "step": 49110
    },
    {
      "epoch": 2.114143066196092,
      "grad_norm": 0.9405151009559631,
      "learning_rate": 4.235491209783992e-05,
      "loss": 3.04,
      "step": 49120
    },
    {
      "epoch": 2.11457346991478,
      "grad_norm": 0.9693212509155273,
      "learning_rate": 4.2316949156987706e-05,
      "loss": 2.9438,
      "step": 49130
    },
    {
      "epoch": 2.115003873633468,
      "grad_norm": 0.7852445840835571,
      "learning_rate": 4.227899867062954e-05,
      "loss": 3.0294,
      "step": 49140
    },
    {
      "epoch": 2.1154342773521564,
      "grad_norm": 1.0282320976257324,
      "learning_rate": 4.224106064695933e-05,
      "loss": 3.0186,
      "step": 49150
    },
    {
      "epoch": 2.1154342773521564,
      "eval_bleu": 27.322003224801847,
      "eval_gen_len": 27.521,
      "eval_loss": 2.7911763191223145,
      "eval_runtime": 58.8818,
      "eval_samples_per_second": 16.983,
      "eval_steps_per_second": 1.07,
      "step": 49150
    },
    {
      "epoch": 2.1158646810708444,
      "grad_norm": 0.9014595746994019,
      "learning_rate": 4.2203135094168425e-05,
      "loss": 2.9924,
      "step": 49160
    },
    {
      "epoch": 2.1162950847895328,
      "grad_norm": 0.9409050941467285,
      "learning_rate": 4.216522202044542e-05,
      "loss": 2.9567,
      "step": 49170
    },
    {
      "epoch": 2.1167254885082207,
      "grad_norm": 0.9841516613960266,
      "learning_rate": 4.212732143397619e-05,
      "loss": 3.0384,
      "step": 49180
    },
    {
      "epoch": 2.1171558922269087,
      "grad_norm": 0.9121528267860413,
      "learning_rate": 4.208943334294393e-05,
      "loss": 3.0359,
      "step": 49190
    },
    {
      "epoch": 2.117586295945597,
      "grad_norm": 0.8896766901016235,
      "learning_rate": 4.205155775552922e-05,
      "loss": 2.9585,
      "step": 49200
    },
    {
      "epoch": 2.117586295945597,
      "eval_bleu": 27.31427020814953,
      "eval_gen_len": 27.504,
      "eval_loss": 2.7903084754943848,
      "eval_runtime": 57.6067,
      "eval_samples_per_second": 17.359,
      "eval_steps_per_second": 1.094,
      "step": 49200
    },
    {
      "epoch": 2.118016699664285,
      "grad_norm": 1.028243899345398,
      "learning_rate": 4.201369467990982e-05,
      "loss": 2.9721,
      "step": 49210
    },
    {
      "epoch": 2.118447103382973,
      "grad_norm": 0.8513177633285522,
      "learning_rate": 4.197584412426089e-05,
      "loss": 3.0745,
      "step": 49220
    },
    {
      "epoch": 2.1188775071016615,
      "grad_norm": 1.0273598432540894,
      "learning_rate": 4.193800609675478e-05,
      "loss": 2.9115,
      "step": 49230
    },
    {
      "epoch": 2.1193079108203494,
      "grad_norm": 1.0456933975219727,
      "learning_rate": 4.190018060556122e-05,
      "loss": 2.9517,
      "step": 49240
    },
    {
      "epoch": 2.119738314539038,
      "grad_norm": 0.9568222165107727,
      "learning_rate": 4.18623676588473e-05,
      "loss": 2.9341,
      "step": 49250
    },
    {
      "epoch": 2.119738314539038,
      "eval_bleu": 27.6233844947727,
      "eval_gen_len": 27.56,
      "eval_loss": 2.78975510597229,
      "eval_runtime": 58.6356,
      "eval_samples_per_second": 17.054,
      "eval_steps_per_second": 1.074,
      "step": 49250
    },
    {
      "epoch": 2.120168718257726,
      "grad_norm": 0.9633440375328064,
      "learning_rate": 4.182456726477715e-05,
      "loss": 2.9749,
      "step": 49260
    },
    {
      "epoch": 2.1205991219764138,
      "grad_norm": 0.9310207962989807,
      "learning_rate": 4.178677943151246e-05,
      "loss": 2.9301,
      "step": 49270
    },
    {
      "epoch": 2.121029525695102,
      "grad_norm": 0.9334465265274048,
      "learning_rate": 4.174900416721202e-05,
      "loss": 3.0786,
      "step": 49280
    },
    {
      "epoch": 2.12145992941379,
      "grad_norm": 0.9568402171134949,
      "learning_rate": 4.171124148003207e-05,
      "loss": 2.9783,
      "step": 49290
    },
    {
      "epoch": 2.121890333132478,
      "grad_norm": 0.9050094485282898,
      "learning_rate": 4.167349137812596e-05,
      "loss": 2.955,
      "step": 49300
    },
    {
      "epoch": 2.121890333132478,
      "eval_bleu": 27.443096547214868,
      "eval_gen_len": 27.569,
      "eval_loss": 2.7893028259277344,
      "eval_runtime": 58.4252,
      "eval_samples_per_second": 17.116,
      "eval_steps_per_second": 1.078,
      "step": 49300
    },
    {
      "epoch": 2.1223207368511665,
      "grad_norm": 0.8827146887779236,
      "learning_rate": 4.16357538696445e-05,
      "loss": 3.0447,
      "step": 49310
    },
    {
      "epoch": 2.1227511405698545,
      "grad_norm": 0.8895864486694336,
      "learning_rate": 4.15980289627356e-05,
      "loss": 2.957,
      "step": 49320
    },
    {
      "epoch": 2.1231815442885424,
      "grad_norm": 0.9618678092956543,
      "learning_rate": 4.1560316665544584e-05,
      "loss": 3.0283,
      "step": 49330
    },
    {
      "epoch": 2.123611948007231,
      "grad_norm": 0.932694137096405,
      "learning_rate": 4.152261698621409e-05,
      "loss": 2.9729,
      "step": 49340
    },
    {
      "epoch": 2.124042351725919,
      "grad_norm": 0.8567045331001282,
      "learning_rate": 4.14849299328838e-05,
      "loss": 3.0416,
      "step": 49350
    },
    {
      "epoch": 2.124042351725919,
      "eval_bleu": 27.23515985850882,
      "eval_gen_len": 27.562,
      "eval_loss": 2.7887046337127686,
      "eval_runtime": 58.5907,
      "eval_samples_per_second": 17.068,
      "eval_steps_per_second": 1.075,
      "step": 49350
    },
    {
      "epoch": 2.1244727554446072,
      "grad_norm": 0.9087108969688416,
      "learning_rate": 4.144725551369092e-05,
      "loss": 2.9673,
      "step": 49360
    },
    {
      "epoch": 2.124903159163295,
      "grad_norm": 0.9889615178108215,
      "learning_rate": 4.140959373676977e-05,
      "loss": 3.024,
      "step": 49370
    },
    {
      "epoch": 2.125333562881983,
      "grad_norm": 0.8698107004165649,
      "learning_rate": 4.1371944610252066e-05,
      "loss": 2.8785,
      "step": 49380
    },
    {
      "epoch": 2.1257639666006716,
      "grad_norm": 0.8506002426147461,
      "learning_rate": 4.133430814226666e-05,
      "loss": 2.9981,
      "step": 49390
    },
    {
      "epoch": 2.1261943703193595,
      "grad_norm": 0.9059067964553833,
      "learning_rate": 4.129668434093982e-05,
      "loss": 2.9864,
      "step": 49400
    },
    {
      "epoch": 2.1261943703193595,
      "eval_bleu": 27.39002558195415,
      "eval_gen_len": 27.589,
      "eval_loss": 2.788827657699585,
      "eval_runtime": 58.8451,
      "eval_samples_per_second": 16.994,
      "eval_steps_per_second": 1.071,
      "step": 49400
    },
    {
      "epoch": 2.1266247740380475,
      "grad_norm": 0.9131250977516174,
      "learning_rate": 4.1259073214394893e-05,
      "loss": 2.996,
      "step": 49410
    },
    {
      "epoch": 2.127055177756736,
      "grad_norm": 1.0051082372665405,
      "learning_rate": 4.12214747707527e-05,
      "loss": 3.067,
      "step": 49420
    },
    {
      "epoch": 2.127485581475424,
      "grad_norm": 0.8932603597640991,
      "learning_rate": 4.118388901813115e-05,
      "loss": 2.9888,
      "step": 49430
    },
    {
      "epoch": 2.127915985194112,
      "grad_norm": 0.9492128491401672,
      "learning_rate": 4.114631596464547e-05,
      "loss": 3.0565,
      "step": 49440
    },
    {
      "epoch": 2.1283463889128003,
      "grad_norm": 0.9120250344276428,
      "learning_rate": 4.110875561840819e-05,
      "loss": 2.9274,
      "step": 49450
    },
    {
      "epoch": 2.1283463889128003,
      "eval_bleu": 27.414647581874757,
      "eval_gen_len": 27.591,
      "eval_loss": 2.7885684967041016,
      "eval_runtime": 58.2378,
      "eval_samples_per_second": 17.171,
      "eval_steps_per_second": 1.082,
      "step": 49450
    },
    {
      "epoch": 2.1287767926314882,
      "grad_norm": 0.9359626173973083,
      "learning_rate": 4.107120798752903e-05,
      "loss": 3.1002,
      "step": 49460
    },
    {
      "epoch": 2.1292071963501766,
      "grad_norm": 0.8490657806396484,
      "learning_rate": 4.103367308011503e-05,
      "loss": 2.9094,
      "step": 49470
    },
    {
      "epoch": 2.1296376000688646,
      "grad_norm": 0.9053153395652771,
      "learning_rate": 4.09961509042704e-05,
      "loss": 2.9167,
      "step": 49480
    },
    {
      "epoch": 2.1300680037875526,
      "grad_norm": 0.8964513540267944,
      "learning_rate": 4.0958641468096715e-05,
      "loss": 2.9994,
      "step": 49490
    },
    {
      "epoch": 2.130498407506241,
      "grad_norm": 0.8543559312820435,
      "learning_rate": 4.092114477969268e-05,
      "loss": 2.9997,
      "step": 49500
    },
    {
      "epoch": 2.130498407506241,
      "eval_bleu": 27.598584714995063,
      "eval_gen_len": 27.627,
      "eval_loss": 2.7900006771087646,
      "eval_runtime": 58.2525,
      "eval_samples_per_second": 17.167,
      "eval_steps_per_second": 1.081,
      "step": 49500
    },
    {
      "epoch": 2.130928811224929,
      "grad_norm": 0.7668740153312683,
      "learning_rate": 4.088366084715428e-05,
      "loss": 2.9146,
      "step": 49510
    },
    {
      "epoch": 2.131359214943617,
      "grad_norm": 0.8386980891227722,
      "learning_rate": 4.0846189678574844e-05,
      "loss": 2.8954,
      "step": 49520
    },
    {
      "epoch": 2.1317896186623053,
      "grad_norm": 0.9603250026702881,
      "learning_rate": 4.080873128204478e-05,
      "loss": 3.1032,
      "step": 49530
    },
    {
      "epoch": 2.1322200223809933,
      "grad_norm": 0.7688686847686768,
      "learning_rate": 4.077128566565191e-05,
      "loss": 2.9248,
      "step": 49540
    },
    {
      "epoch": 2.1326504260996817,
      "grad_norm": 0.8911969065666199,
      "learning_rate": 4.073385283748112e-05,
      "loss": 2.9747,
      "step": 49550
    },
    {
      "epoch": 2.1326504260996817,
      "eval_bleu": 27.51884409938333,
      "eval_gen_len": 27.658,
      "eval_loss": 2.788851261138916,
      "eval_runtime": 58.4917,
      "eval_samples_per_second": 17.096,
      "eval_steps_per_second": 1.077,
      "step": 49550
    },
    {
      "epoch": 2.1330808298183697,
      "grad_norm": 0.9840384125709534,
      "learning_rate": 4.069643280561472e-05,
      "loss": 2.9703,
      "step": 49560
    },
    {
      "epoch": 2.1335112335370576,
      "grad_norm": 0.9918850660324097,
      "learning_rate": 4.065902557813209e-05,
      "loss": 2.9927,
      "step": 49570
    },
    {
      "epoch": 2.133941637255746,
      "grad_norm": 0.8602268099784851,
      "learning_rate": 4.062163116310997e-05,
      "loss": 3.045,
      "step": 49580
    },
    {
      "epoch": 2.134372040974434,
      "grad_norm": 0.945315957069397,
      "learning_rate": 4.058424956862228e-05,
      "loss": 2.9924,
      "step": 49590
    },
    {
      "epoch": 2.134802444693122,
      "grad_norm": 0.9112583994865417,
      "learning_rate": 4.054688080274012e-05,
      "loss": 2.9001,
      "step": 49600
    },
    {
      "epoch": 2.134802444693122,
      "eval_bleu": 27.498272608184926,
      "eval_gen_len": 27.628,
      "eval_loss": 2.7892653942108154,
      "eval_runtime": 58.1189,
      "eval_samples_per_second": 17.206,
      "eval_steps_per_second": 1.084,
      "step": 49600
    },
    {
      "epoch": 2.1352328484118104,
      "grad_norm": 0.94105064868927,
      "learning_rate": 4.050952487353195e-05,
      "loss": 2.9449,
      "step": 49610
    },
    {
      "epoch": 2.1356632521304983,
      "grad_norm": 0.8534678220748901,
      "learning_rate": 4.04721817890633e-05,
      "loss": 2.9605,
      "step": 49620
    },
    {
      "epoch": 2.1360936558491863,
      "grad_norm": 0.803629994392395,
      "learning_rate": 4.043485155739711e-05,
      "loss": 2.9508,
      "step": 49630
    },
    {
      "epoch": 2.1365240595678747,
      "grad_norm": 0.8449947237968445,
      "learning_rate": 4.039753418659334e-05,
      "loss": 2.9498,
      "step": 49640
    },
    {
      "epoch": 2.1369544632865627,
      "grad_norm": 0.9032838940620422,
      "learning_rate": 4.036022968470938e-05,
      "loss": 2.9873,
      "step": 49650
    },
    {
      "epoch": 2.1369544632865627,
      "eval_bleu": 27.214174740376635,
      "eval_gen_len": 27.567,
      "eval_loss": 2.790095806121826,
      "eval_runtime": 57.986,
      "eval_samples_per_second": 17.246,
      "eval_steps_per_second": 1.086,
      "step": 49650
    },
    {
      "epoch": 2.137384867005251,
      "grad_norm": 0.9336134195327759,
      "learning_rate": 4.032293805979969e-05,
      "loss": 2.9776,
      "step": 49660
    },
    {
      "epoch": 2.137815270723939,
      "grad_norm": 0.9666239023208618,
      "learning_rate": 4.0285659319915956e-05,
      "loss": 2.9928,
      "step": 49670
    },
    {
      "epoch": 2.138245674442627,
      "grad_norm": 1.0067493915557861,
      "learning_rate": 4.02483934731072e-05,
      "loss": 2.8607,
      "step": 49680
    },
    {
      "epoch": 2.1386760781613154,
      "grad_norm": 0.8160621523857117,
      "learning_rate": 4.021114052741953e-05,
      "loss": 3.0259,
      "step": 49690
    },
    {
      "epoch": 2.1391064818800034,
      "grad_norm": 0.9360018968582153,
      "learning_rate": 4.017390049089639e-05,
      "loss": 2.9096,
      "step": 49700
    },
    {
      "epoch": 2.1391064818800034,
      "eval_bleu": 27.262110191310505,
      "eval_gen_len": 27.596,
      "eval_loss": 2.789167642593384,
      "eval_runtime": 58.1751,
      "eval_samples_per_second": 17.189,
      "eval_steps_per_second": 1.083,
      "step": 49700
    },
    {
      "epoch": 2.1395368855986914,
      "grad_norm": 0.8286612033843994,
      "learning_rate": 4.013667337157828e-05,
      "loss": 2.8457,
      "step": 49710
    },
    {
      "epoch": 2.13996728931738,
      "grad_norm": 0.9868254065513611,
      "learning_rate": 4.00994591775031e-05,
      "loss": 2.9452,
      "step": 49720
    },
    {
      "epoch": 2.1403976930360677,
      "grad_norm": 0.9604505300521851,
      "learning_rate": 4.006225791670577e-05,
      "loss": 2.9445,
      "step": 49730
    },
    {
      "epoch": 2.140828096754756,
      "grad_norm": 0.9440819621086121,
      "learning_rate": 4.0025069597218624e-05,
      "loss": 2.9486,
      "step": 49740
    },
    {
      "epoch": 2.141258500473444,
      "grad_norm": 0.8990813493728638,
      "learning_rate": 3.9987894227070947e-05,
      "loss": 3.0088,
      "step": 49750
    },
    {
      "epoch": 2.141258500473444,
      "eval_bleu": 27.34465447148492,
      "eval_gen_len": 27.562,
      "eval_loss": 2.7883853912353516,
      "eval_runtime": 58.2989,
      "eval_samples_per_second": 17.153,
      "eval_steps_per_second": 1.081,
      "step": 49750
    },
    {
      "epoch": 2.141688904192132,
      "grad_norm": 0.9390939474105835,
      "learning_rate": 3.9950731814289433e-05,
      "loss": 3.0567,
      "step": 49760
    },
    {
      "epoch": 2.1421193079108205,
      "grad_norm": 0.8805758953094482,
      "learning_rate": 3.991358236689794e-05,
      "loss": 2.9645,
      "step": 49770
    },
    {
      "epoch": 2.1425497116295085,
      "grad_norm": 0.9167447090148926,
      "learning_rate": 3.987644589291745e-05,
      "loss": 2.9404,
      "step": 49780
    },
    {
      "epoch": 2.1429801153481964,
      "grad_norm": 0.978958010673523,
      "learning_rate": 3.9839322400366253e-05,
      "loss": 2.9784,
      "step": 49790
    },
    {
      "epoch": 2.143410519066885,
      "grad_norm": 0.8326528668403625,
      "learning_rate": 3.98022118972597e-05,
      "loss": 2.9992,
      "step": 49800
    },
    {
      "epoch": 2.143410519066885,
      "eval_bleu": 26.955880760636646,
      "eval_gen_len": 27.508,
      "eval_loss": 2.7905757427215576,
      "eval_runtime": 57.9595,
      "eval_samples_per_second": 17.253,
      "eval_steps_per_second": 1.087,
      "step": 49800
    },
    {
      "epoch": 2.143840922785573,
      "grad_norm": 0.8931031227111816,
      "learning_rate": 3.976511439161049e-05,
      "loss": 3.0774,
      "step": 49810
    },
    {
      "epoch": 2.1442713265042608,
      "grad_norm": 0.9351012110710144,
      "learning_rate": 3.9728029891428406e-05,
      "loss": 3.1092,
      "step": 49820
    },
    {
      "epoch": 2.144701730222949,
      "grad_norm": 0.7961986064910889,
      "learning_rate": 3.969095840472047e-05,
      "loss": 2.9999,
      "step": 49830
    },
    {
      "epoch": 2.145132133941637,
      "grad_norm": 0.9412212371826172,
      "learning_rate": 3.9653899939490816e-05,
      "loss": 2.9875,
      "step": 49840
    },
    {
      "epoch": 2.1455625376603256,
      "grad_norm": 1.045483946800232,
      "learning_rate": 3.961685450374092e-05,
      "loss": 2.9659,
      "step": 49850
    },
    {
      "epoch": 2.1455625376603256,
      "eval_bleu": 27.151139654977758,
      "eval_gen_len": 27.476,
      "eval_loss": 2.7913787364959717,
      "eval_runtime": 58.4058,
      "eval_samples_per_second": 17.122,
      "eval_steps_per_second": 1.079,
      "step": 49850
    },
    {
      "epoch": 2.1459929413790135,
      "grad_norm": 1.0296601057052612,
      "learning_rate": 3.957982210546928e-05,
      "loss": 2.9313,
      "step": 49860
    },
    {
      "epoch": 2.1464233450977015,
      "grad_norm": 0.8526344299316406,
      "learning_rate": 3.954280275267169e-05,
      "loss": 2.996,
      "step": 49870
    },
    {
      "epoch": 2.14685374881639,
      "grad_norm": 0.9560539126396179,
      "learning_rate": 3.950579645334114e-05,
      "loss": 2.9791,
      "step": 49880
    },
    {
      "epoch": 2.147284152535078,
      "grad_norm": 0.836508572101593,
      "learning_rate": 3.9468803215467664e-05,
      "loss": 2.9335,
      "step": 49890
    },
    {
      "epoch": 2.147714556253766,
      "grad_norm": 0.8602660298347473,
      "learning_rate": 3.9431823047038694e-05,
      "loss": 2.9489,
      "step": 49900
    },
    {
      "epoch": 2.147714556253766,
      "eval_bleu": 27.229923612928673,
      "eval_gen_len": 27.556,
      "eval_loss": 2.7884535789489746,
      "eval_runtime": 57.8085,
      "eval_samples_per_second": 17.298,
      "eval_steps_per_second": 1.09,
      "step": 49900
    },
    {
      "epoch": 2.1481449599724542,
      "grad_norm": 0.9135955572128296,
      "learning_rate": 3.939485595603855e-05,
      "loss": 2.9753,
      "step": 49910
    },
    {
      "epoch": 2.148575363691142,
      "grad_norm": 0.9052733778953552,
      "learning_rate": 3.9357901950449e-05,
      "loss": 2.9076,
      "step": 49920
    },
    {
      "epoch": 2.1490057674098306,
      "grad_norm": 0.9167386293411255,
      "learning_rate": 3.932096103824883e-05,
      "loss": 3.0035,
      "step": 49930
    },
    {
      "epoch": 2.1494361711285186,
      "grad_norm": 0.9662363529205322,
      "learning_rate": 3.9284033227414085e-05,
      "loss": 2.9654,
      "step": 49940
    },
    {
      "epoch": 2.1498665748472066,
      "grad_norm": 0.8755533695220947,
      "learning_rate": 3.924711852591789e-05,
      "loss": 3.0806,
      "step": 49950
    },
    {
      "epoch": 2.1498665748472066,
      "eval_bleu": 27.202584412687745,
      "eval_gen_len": 27.569,
      "eval_loss": 2.7897610664367676,
      "eval_runtime": 58.1693,
      "eval_samples_per_second": 17.191,
      "eval_steps_per_second": 1.083,
      "step": 49950
    },
    {
      "epoch": 2.150296978565895,
      "grad_norm": 0.9860309958457947,
      "learning_rate": 3.921021694173066e-05,
      "loss": 3.0718,
      "step": 49960
    },
    {
      "epoch": 2.150727382284583,
      "grad_norm": 0.843092143535614,
      "learning_rate": 3.917332848281983e-05,
      "loss": 3.0597,
      "step": 49970
    },
    {
      "epoch": 2.151157786003271,
      "grad_norm": 0.8534315824508667,
      "learning_rate": 3.913645315715012e-05,
      "loss": 3.0036,
      "step": 49980
    },
    {
      "epoch": 2.1515881897219593,
      "grad_norm": 0.8333254456520081,
      "learning_rate": 3.909959097268346e-05,
      "loss": 2.9677,
      "step": 49990
    },
    {
      "epoch": 2.1520185934406473,
      "grad_norm": 0.8993740081787109,
      "learning_rate": 3.90627419373787e-05,
      "loss": 3.0103,
      "step": 50000
    },
    {
      "epoch": 2.1520185934406473,
      "eval_bleu": 27.15368738444163,
      "eval_gen_len": 27.572,
      "eval_loss": 2.787478446960449,
      "eval_runtime": 58.761,
      "eval_samples_per_second": 17.018,
      "eval_steps_per_second": 1.072,
      "step": 50000
    },
    {
      "epoch": 2.1524489971593352,
      "grad_norm": 0.9455478191375732,
      "learning_rate": 3.902590605919212e-05,
      "loss": 2.9612,
      "step": 50010
    },
    {
      "epoch": 2.1528794008780237,
      "grad_norm": 0.9277251362800598,
      "learning_rate": 3.8989083346076984e-05,
      "loss": 2.975,
      "step": 50020
    },
    {
      "epoch": 2.1533098045967116,
      "grad_norm": 0.9268130660057068,
      "learning_rate": 3.895227380598384e-05,
      "loss": 3.028,
      "step": 50030
    },
    {
      "epoch": 2.1537402083154,
      "grad_norm": 0.8695681691169739,
      "learning_rate": 3.891547744686026e-05,
      "loss": 3.0064,
      "step": 50040
    },
    {
      "epoch": 2.154170612034088,
      "grad_norm": 0.8623362183570862,
      "learning_rate": 3.8878694276651106e-05,
      "loss": 2.9742,
      "step": 50050
    },
    {
      "epoch": 2.154170612034088,
      "eval_bleu": 27.10708153431382,
      "eval_gen_len": 27.565,
      "eval_loss": 2.787548303604126,
      "eval_runtime": 57.7171,
      "eval_samples_per_second": 17.326,
      "eval_steps_per_second": 1.092,
      "step": 50050
    },
    {
      "epoch": 2.154601015752776,
      "grad_norm": 0.9725406765937805,
      "learning_rate": 3.8841924303298264e-05,
      "loss": 2.9717,
      "step": 50060
    },
    {
      "epoch": 2.1550314194714644,
      "grad_norm": 0.8937119245529175,
      "learning_rate": 3.8805167534740894e-05,
      "loss": 2.9773,
      "step": 50070
    },
    {
      "epoch": 2.1554618231901523,
      "grad_norm": 0.9692946672439575,
      "learning_rate": 3.8768423978915214e-05,
      "loss": 2.983,
      "step": 50080
    },
    {
      "epoch": 2.1558922269088403,
      "grad_norm": 0.9303473830223083,
      "learning_rate": 3.873169364375458e-05,
      "loss": 3.0451,
      "step": 50090
    },
    {
      "epoch": 2.1563226306275287,
      "grad_norm": 0.9288623332977295,
      "learning_rate": 3.869497653718962e-05,
      "loss": 2.9894,
      "step": 50100
    },
    {
      "epoch": 2.1563226306275287,
      "eval_bleu": 27.52074008272648,
      "eval_gen_len": 27.575,
      "eval_loss": 2.7884325981140137,
      "eval_runtime": 57.984,
      "eval_samples_per_second": 17.246,
      "eval_steps_per_second": 1.087,
      "step": 50100
    },
    {
      "epoch": 2.1567530343462167,
      "grad_norm": 0.9155171513557434,
      "learning_rate": 3.865827266714791e-05,
      "loss": 2.8984,
      "step": 50110
    },
    {
      "epoch": 2.157183438064905,
      "grad_norm": 0.8870717287063599,
      "learning_rate": 3.862158204155438e-05,
      "loss": 3.023,
      "step": 50120
    },
    {
      "epoch": 2.157613841783593,
      "grad_norm": 0.8900614380836487,
      "learning_rate": 3.858490466833091e-05,
      "loss": 2.9762,
      "step": 50130
    },
    {
      "epoch": 2.158044245502281,
      "grad_norm": 0.9141342043876648,
      "learning_rate": 3.854824055539668e-05,
      "loss": 3.0099,
      "step": 50140
    },
    {
      "epoch": 2.1584746492209694,
      "grad_norm": 0.9113959074020386,
      "learning_rate": 3.8511589710667896e-05,
      "loss": 3.0597,
      "step": 50150
    },
    {
      "epoch": 2.1584746492209694,
      "eval_bleu": 27.081979234306115,
      "eval_gen_len": 27.518,
      "eval_loss": 2.787463426589966,
      "eval_runtime": 57.8093,
      "eval_samples_per_second": 17.298,
      "eval_steps_per_second": 1.09,
      "step": 50150
    },
    {
      "epoch": 2.1589050529396574,
      "grad_norm": 0.8874837160110474,
      "learning_rate": 3.84749521420579e-05,
      "loss": 2.8938,
      "step": 50160
    },
    {
      "epoch": 2.1593354566583454,
      "grad_norm": 0.9466579556465149,
      "learning_rate": 3.8438327857477265e-05,
      "loss": 2.9394,
      "step": 50170
    },
    {
      "epoch": 2.1597658603770338,
      "grad_norm": 0.9051818251609802,
      "learning_rate": 3.840171686483357e-05,
      "loss": 3.0103,
      "step": 50180
    },
    {
      "epoch": 2.1601962640957217,
      "grad_norm": 0.9322910904884338,
      "learning_rate": 3.836511917203166e-05,
      "loss": 3.0131,
      "step": 50190
    },
    {
      "epoch": 2.1606266678144097,
      "grad_norm": 0.9967305064201355,
      "learning_rate": 3.832853478697337e-05,
      "loss": 2.9992,
      "step": 50200
    },
    {
      "epoch": 2.1606266678144097,
      "eval_bleu": 27.179924201634094,
      "eval_gen_len": 27.516,
      "eval_loss": 2.787651538848877,
      "eval_runtime": 57.8252,
      "eval_samples_per_second": 17.293,
      "eval_steps_per_second": 1.089,
      "step": 50200
    },
    {
      "epoch": 2.161057071533098,
      "grad_norm": 0.8649171590805054,
      "learning_rate": 3.8291963717557785e-05,
      "loss": 2.9996,
      "step": 50210
    },
    {
      "epoch": 2.161487475251786,
      "grad_norm": 0.9001117944717407,
      "learning_rate": 3.825540597168099e-05,
      "loss": 2.9695,
      "step": 50220
    },
    {
      "epoch": 2.1619178789704745,
      "grad_norm": 0.9591902494430542,
      "learning_rate": 3.821886155723634e-05,
      "loss": 2.9959,
      "step": 50230
    },
    {
      "epoch": 2.1623482826891625,
      "grad_norm": 0.9340047240257263,
      "learning_rate": 3.818233048211418e-05,
      "loss": 2.9757,
      "step": 50240
    },
    {
      "epoch": 2.1627786864078504,
      "grad_norm": 0.8339803218841553,
      "learning_rate": 3.8145812754202015e-05,
      "loss": 3.0626,
      "step": 50250
    },
    {
      "epoch": 2.1627786864078504,
      "eval_bleu": 27.052111174133717,
      "eval_gen_len": 27.473,
      "eval_loss": 2.788580894470215,
      "eval_runtime": 57.7527,
      "eval_samples_per_second": 17.315,
      "eval_steps_per_second": 1.091,
      "step": 50250
    },
    {
      "epoch": 2.163209090126539,
      "grad_norm": 0.9644699096679688,
      "learning_rate": 3.810930838138453e-05,
      "loss": 3.0286,
      "step": 50260
    },
    {
      "epoch": 2.163639493845227,
      "grad_norm": 0.9204583764076233,
      "learning_rate": 3.8072817371543425e-05,
      "loss": 2.8997,
      "step": 50270
    },
    {
      "epoch": 2.1640698975639148,
      "grad_norm": 1.024330496788025,
      "learning_rate": 3.8036339732557624e-05,
      "loss": 3.0219,
      "step": 50280
    },
    {
      "epoch": 2.164500301282603,
      "grad_norm": 0.995597243309021,
      "learning_rate": 3.799987547230304e-05,
      "loss": 3.0031,
      "step": 50290
    },
    {
      "epoch": 2.164930705001291,
      "grad_norm": 0.9391070008277893,
      "learning_rate": 3.796342459865283e-05,
      "loss": 2.9703,
      "step": 50300
    },
    {
      "epoch": 2.164930705001291,
      "eval_bleu": 27.025534398565167,
      "eval_gen_len": 27.458,
      "eval_loss": 2.7907862663269043,
      "eval_runtime": 58.4389,
      "eval_samples_per_second": 17.112,
      "eval_steps_per_second": 1.078,
      "step": 50300
    },
    {
      "epoch": 2.1653611087199796,
      "grad_norm": 0.9646222591400146,
      "learning_rate": 3.7926987119477164e-05,
      "loss": 3.0088,
      "step": 50310
    },
    {
      "epoch": 2.1657915124386675,
      "grad_norm": 0.877236008644104,
      "learning_rate": 3.789056304264332e-05,
      "loss": 2.9362,
      "step": 50320
    },
    {
      "epoch": 2.1662219161573555,
      "grad_norm": 0.8410673141479492,
      "learning_rate": 3.785415237601577e-05,
      "loss": 2.9033,
      "step": 50330
    },
    {
      "epoch": 2.166652319876044,
      "grad_norm": 0.9782286882400513,
      "learning_rate": 3.781775512745598e-05,
      "loss": 3.1165,
      "step": 50340
    },
    {
      "epoch": 2.167082723594732,
      "grad_norm": 0.9266318082809448,
      "learning_rate": 3.778137130482263e-05,
      "loss": 2.937,
      "step": 50350
    },
    {
      "epoch": 2.167082723594732,
      "eval_bleu": 27.301206720567947,
      "eval_gen_len": 27.487,
      "eval_loss": 2.7898733615875244,
      "eval_runtime": 58.1084,
      "eval_samples_per_second": 17.209,
      "eval_steps_per_second": 1.084,
      "step": 50350
    },
    {
      "epoch": 2.16751312731342,
      "grad_norm": 0.9643900990486145,
      "learning_rate": 3.7745000915971385e-05,
      "loss": 3.0407,
      "step": 50360
    },
    {
      "epoch": 2.1679435310321082,
      "grad_norm": 0.9203397631645203,
      "learning_rate": 3.770864396875512e-05,
      "loss": 3.0333,
      "step": 50370
    },
    {
      "epoch": 2.168373934750796,
      "grad_norm": 0.8371759653091431,
      "learning_rate": 3.76723004710237e-05,
      "loss": 2.9866,
      "step": 50380
    },
    {
      "epoch": 2.168804338469484,
      "grad_norm": 0.8834683299064636,
      "learning_rate": 3.763597043062421e-05,
      "loss": 2.9195,
      "step": 50390
    },
    {
      "epoch": 2.1692347421881726,
      "grad_norm": 0.8958362936973572,
      "learning_rate": 3.759965385540072e-05,
      "loss": 2.9216,
      "step": 50400
    },
    {
      "epoch": 2.1692347421881726,
      "eval_bleu": 27.394063596565218,
      "eval_gen_len": 27.491,
      "eval_loss": 2.7888100147247314,
      "eval_runtime": 57.4422,
      "eval_samples_per_second": 17.409,
      "eval_steps_per_second": 1.097,
      "step": 50400
    },
    {
      "epoch": 2.1696651459068605,
      "grad_norm": 0.9150428175926208,
      "learning_rate": 3.756335075319441e-05,
      "loss": 2.8393,
      "step": 50410
    },
    {
      "epoch": 2.170095549625549,
      "grad_norm": 1.0231810808181763,
      "learning_rate": 3.7527061131843635e-05,
      "loss": 2.9352,
      "step": 50420
    },
    {
      "epoch": 2.170525953344237,
      "grad_norm": 0.9400126338005066,
      "learning_rate": 3.7490784999183714e-05,
      "loss": 3.0233,
      "step": 50430
    },
    {
      "epoch": 2.170956357062925,
      "grad_norm": 0.8908237814903259,
      "learning_rate": 3.745452236304718e-05,
      "loss": 2.9556,
      "step": 50440
    },
    {
      "epoch": 2.1713867607816133,
      "grad_norm": 1.0275099277496338,
      "learning_rate": 3.741827323126354e-05,
      "loss": 3.0113,
      "step": 50450
    },
    {
      "epoch": 2.1713867607816133,
      "eval_bleu": 27.32575500678647,
      "eval_gen_len": 27.513,
      "eval_loss": 2.787856340408325,
      "eval_runtime": 57.805,
      "eval_samples_per_second": 17.3,
      "eval_steps_per_second": 1.09,
      "step": 50450
    },
    {
      "epoch": 2.1718171645003013,
      "grad_norm": 0.912777304649353,
      "learning_rate": 3.738203761165949e-05,
      "loss": 3.0157,
      "step": 50460
    },
    {
      "epoch": 2.1722475682189892,
      "grad_norm": 0.9101250171661377,
      "learning_rate": 3.734581551205874e-05,
      "loss": 2.9911,
      "step": 50470
    },
    {
      "epoch": 2.1726779719376776,
      "grad_norm": 0.9018948078155518,
      "learning_rate": 3.730960694028206e-05,
      "loss": 3.0463,
      "step": 50480
    },
    {
      "epoch": 2.1731083756563656,
      "grad_norm": 0.8926698565483093,
      "learning_rate": 3.727341190414731e-05,
      "loss": 3.0176,
      "step": 50490
    },
    {
      "epoch": 2.173538779375054,
      "grad_norm": 0.8599418997764587,
      "learning_rate": 3.723723041146953e-05,
      "loss": 3.0358,
      "step": 50500
    },
    {
      "epoch": 2.173538779375054,
      "eval_bleu": 27.690959463589973,
      "eval_gen_len": 27.533,
      "eval_loss": 2.7871956825256348,
      "eval_runtime": 57.9598,
      "eval_samples_per_second": 17.253,
      "eval_steps_per_second": 1.087,
      "step": 50500
    },
    {
      "epoch": 2.173969183093742,
      "grad_norm": 0.829301118850708,
      "learning_rate": 3.720106247006073e-05,
      "loss": 2.919,
      "step": 50510
    },
    {
      "epoch": 2.17439958681243,
      "grad_norm": 0.9441171288490295,
      "learning_rate": 3.716490808773e-05,
      "loss": 2.9968,
      "step": 50520
    },
    {
      "epoch": 2.1748299905311184,
      "grad_norm": 0.8646804094314575,
      "learning_rate": 3.712876727228357e-05,
      "loss": 2.951,
      "step": 50530
    },
    {
      "epoch": 2.1752603942498063,
      "grad_norm": 0.9124255180358887,
      "learning_rate": 3.709264003152463e-05,
      "loss": 3.032,
      "step": 50540
    },
    {
      "epoch": 2.1756907979684943,
      "grad_norm": 0.8997049927711487,
      "learning_rate": 3.705652637325361e-05,
      "loss": 3.0611,
      "step": 50550
    },
    {
      "epoch": 2.1756907979684943,
      "eval_bleu": 27.445195508960776,
      "eval_gen_len": 27.485,
      "eval_loss": 2.7885520458221436,
      "eval_runtime": 57.7771,
      "eval_samples_per_second": 17.308,
      "eval_steps_per_second": 1.09,
      "step": 50550
    },
    {
      "epoch": 2.1761212016871827,
      "grad_norm": 1.042757272720337,
      "learning_rate": 3.702042630526776e-05,
      "loss": 2.9798,
      "step": 50560
    },
    {
      "epoch": 2.1765516054058707,
      "grad_norm": 0.9576451778411865,
      "learning_rate": 3.698433983536166e-05,
      "loss": 3.0468,
      "step": 50570
    },
    {
      "epoch": 2.1769820091245586,
      "grad_norm": 0.989025890827179,
      "learning_rate": 3.6948266971326725e-05,
      "loss": 2.9494,
      "step": 50580
    },
    {
      "epoch": 2.177412412843247,
      "grad_norm": 0.9062245488166809,
      "learning_rate": 3.6912207720951654e-05,
      "loss": 2.9265,
      "step": 50590
    },
    {
      "epoch": 2.177842816561935,
      "grad_norm": 0.959151566028595,
      "learning_rate": 3.6876162092021985e-05,
      "loss": 3.009,
      "step": 50600
    },
    {
      "epoch": 2.177842816561935,
      "eval_bleu": 27.294156812075187,
      "eval_gen_len": 27.427,
      "eval_loss": 2.789466142654419,
      "eval_runtime": 57.3707,
      "eval_samples_per_second": 17.431,
      "eval_steps_per_second": 1.098,
      "step": 50600
    },
    {
      "epoch": 2.1782732202806234,
      "grad_norm": 0.875654935836792,
      "learning_rate": 3.684013009232046e-05,
      "loss": 3.0042,
      "step": 50610
    },
    {
      "epoch": 2.1787036239993114,
      "grad_norm": 0.9283455610275269,
      "learning_rate": 3.680411172962689e-05,
      "loss": 3.0348,
      "step": 50620
    },
    {
      "epoch": 2.1791340277179994,
      "grad_norm": 0.8702751994132996,
      "learning_rate": 3.676810701171802e-05,
      "loss": 2.9836,
      "step": 50630
    },
    {
      "epoch": 2.1795644314366878,
      "grad_norm": 0.9129887223243713,
      "learning_rate": 3.6732115946367816e-05,
      "loss": 2.9171,
      "step": 50640
    },
    {
      "epoch": 2.1799948351553757,
      "grad_norm": 0.9555491209030151,
      "learning_rate": 3.669613854134706e-05,
      "loss": 3.0331,
      "step": 50650
    },
    {
      "epoch": 2.1799948351553757,
      "eval_bleu": 27.338305614884973,
      "eval_gen_len": 27.511,
      "eval_loss": 2.7886672019958496,
      "eval_runtime": 58.7252,
      "eval_samples_per_second": 17.028,
      "eval_steps_per_second": 1.073,
      "step": 50650
    },
    {
      "epoch": 2.1804252388740637,
      "grad_norm": 0.9201334118843079,
      "learning_rate": 3.666017480442384e-05,
      "loss": 2.9279,
      "step": 50660
    },
    {
      "epoch": 2.180855642592752,
      "grad_norm": 0.9865568280220032,
      "learning_rate": 3.66242247433631e-05,
      "loss": 2.99,
      "step": 50670
    },
    {
      "epoch": 2.18128604631144,
      "grad_norm": 0.9305770993232727,
      "learning_rate": 3.658828836592697e-05,
      "loss": 2.9867,
      "step": 50680
    },
    {
      "epoch": 2.1817164500301285,
      "grad_norm": 0.977928876876831,
      "learning_rate": 3.655236567987451e-05,
      "loss": 2.9343,
      "step": 50690
    },
    {
      "epoch": 2.1821468537488165,
      "grad_norm": 0.9222613573074341,
      "learning_rate": 3.651645669296192e-05,
      "loss": 3.0885,
      "step": 50700
    },
    {
      "epoch": 2.1821468537488165,
      "eval_bleu": 27.213843680393108,
      "eval_gen_len": 27.469,
      "eval_loss": 2.7891194820404053,
      "eval_runtime": 58.4646,
      "eval_samples_per_second": 17.104,
      "eval_steps_per_second": 1.078,
      "step": 50700
    },
    {
      "epoch": 2.1825772574675044,
      "grad_norm": 0.9467309713363647,
      "learning_rate": 3.648056141294242e-05,
      "loss": 2.986,
      "step": 50710
    },
    {
      "epoch": 2.183007661186193,
      "grad_norm": 0.9624033570289612,
      "learning_rate": 3.644467984756621e-05,
      "loss": 2.9661,
      "step": 50720
    },
    {
      "epoch": 2.183438064904881,
      "grad_norm": 0.9050387740135193,
      "learning_rate": 3.640881200458058e-05,
      "loss": 2.9886,
      "step": 50730
    },
    {
      "epoch": 2.1838684686235688,
      "grad_norm": 0.8826296329498291,
      "learning_rate": 3.637295789172982e-05,
      "loss": 2.9979,
      "step": 50740
    },
    {
      "epoch": 2.184298872342257,
      "grad_norm": 0.8250125646591187,
      "learning_rate": 3.6337117516755334e-05,
      "loss": 2.9556,
      "step": 50750
    },
    {
      "epoch": 2.184298872342257,
      "eval_bleu": 27.47258427805688,
      "eval_gen_len": 27.509,
      "eval_loss": 2.790151357650757,
      "eval_runtime": 58.3788,
      "eval_samples_per_second": 17.13,
      "eval_steps_per_second": 1.079,
      "step": 50750
    },
    {
      "epoch": 2.184729276060945,
      "grad_norm": 0.903569757938385,
      "learning_rate": 3.630129088739547e-05,
      "loss": 3.0182,
      "step": 50760
    },
    {
      "epoch": 2.185159679779633,
      "grad_norm": 1.0210957527160645,
      "learning_rate": 3.626547801138568e-05,
      "loss": 3.0345,
      "step": 50770
    },
    {
      "epoch": 2.1855900834983215,
      "grad_norm": 0.8374593257904053,
      "learning_rate": 3.622967889645835e-05,
      "loss": 3.0323,
      "step": 50780
    },
    {
      "epoch": 2.1860204872170095,
      "grad_norm": 1.0492995977401733,
      "learning_rate": 3.619389355034305e-05,
      "loss": 2.9959,
      "step": 50790
    },
    {
      "epoch": 2.186450890935698,
      "grad_norm": 0.8989269137382507,
      "learning_rate": 3.6158121980766235e-05,
      "loss": 3.0104,
      "step": 50800
    },
    {
      "epoch": 2.186450890935698,
      "eval_bleu": 27.227017901237645,
      "eval_gen_len": 27.553,
      "eval_loss": 2.7872557640075684,
      "eval_runtime": 57.8878,
      "eval_samples_per_second": 17.275,
      "eval_steps_per_second": 1.088,
      "step": 50800
    },
    {
      "epoch": 2.186881294654386,
      "grad_norm": 0.9686709046363831,
      "learning_rate": 3.6122364195451395e-05,
      "loss": 3.01,
      "step": 50810
    },
    {
      "epoch": 2.187311698373074,
      "grad_norm": 0.9870112538337708,
      "learning_rate": 3.608662020211917e-05,
      "loss": 3.0596,
      "step": 50820
    },
    {
      "epoch": 2.1877421020917622,
      "grad_norm": 0.8522298336029053,
      "learning_rate": 3.605089000848705e-05,
      "loss": 2.9552,
      "step": 50830
    },
    {
      "epoch": 2.18817250581045,
      "grad_norm": 1.0464107990264893,
      "learning_rate": 3.6015173622269705e-05,
      "loss": 2.9955,
      "step": 50840
    },
    {
      "epoch": 2.188602909529138,
      "grad_norm": 1.0707615613937378,
      "learning_rate": 3.597947105117869e-05,
      "loss": 3.0292,
      "step": 50850
    },
    {
      "epoch": 2.188602909529138,
      "eval_bleu": 27.02549864772319,
      "eval_gen_len": 27.53,
      "eval_loss": 2.790580987930298,
      "eval_runtime": 57.9445,
      "eval_samples_per_second": 17.258,
      "eval_steps_per_second": 1.087,
      "step": 50850
    },
    {
      "epoch": 2.1890333132478266,
      "grad_norm": 0.9779567718505859,
      "learning_rate": 3.59437823029227e-05,
      "loss": 3.0414,
      "step": 50860
    },
    {
      "epoch": 2.1894637169665145,
      "grad_norm": 0.9310951828956604,
      "learning_rate": 3.590810738520732e-05,
      "loss": 3.0365,
      "step": 50870
    },
    {
      "epoch": 2.189894120685203,
      "grad_norm": 0.9096446633338928,
      "learning_rate": 3.587244630573529e-05,
      "loss": 2.9598,
      "step": 50880
    },
    {
      "epoch": 2.190324524403891,
      "grad_norm": 0.9558581709861755,
      "learning_rate": 3.583679907220622e-05,
      "loss": 3.0308,
      "step": 50890
    },
    {
      "epoch": 2.190754928122579,
      "grad_norm": 1.0594589710235596,
      "learning_rate": 3.580116569231677e-05,
      "loss": 3.0429,
      "step": 50900
    },
    {
      "epoch": 2.190754928122579,
      "eval_bleu": 27.13610497084879,
      "eval_gen_len": 27.585,
      "eval_loss": 2.790432929992676,
      "eval_runtime": 58.83,
      "eval_samples_per_second": 16.998,
      "eval_steps_per_second": 1.071,
      "step": 50900
    },
    {
      "epoch": 2.1911853318412673,
      "grad_norm": 1.129504919052124,
      "learning_rate": 3.576554617376072e-05,
      "loss": 3.0685,
      "step": 50910
    },
    {
      "epoch": 2.1916157355599553,
      "grad_norm": 0.940818727016449,
      "learning_rate": 3.57299405242287e-05,
      "loss": 2.9438,
      "step": 50920
    },
    {
      "epoch": 2.1920461392786432,
      "grad_norm": 0.9686588048934937,
      "learning_rate": 3.569434875140847e-05,
      "loss": 3.0453,
      "step": 50930
    },
    {
      "epoch": 2.1924765429973316,
      "grad_norm": 0.9916623830795288,
      "learning_rate": 3.565877086298467e-05,
      "loss": 2.9717,
      "step": 50940
    },
    {
      "epoch": 2.1929069467160196,
      "grad_norm": 0.9697491526603699,
      "learning_rate": 3.56232068666391e-05,
      "loss": 2.8791,
      "step": 50950
    },
    {
      "epoch": 2.1929069467160196,
      "eval_bleu": 26.889710452637374,
      "eval_gen_len": 27.518,
      "eval_loss": 2.789605140686035,
      "eval_runtime": 58.5306,
      "eval_samples_per_second": 17.085,
      "eval_steps_per_second": 1.076,
      "step": 50950
    },
    {
      "epoch": 2.1933373504347076,
      "grad_norm": 0.8942055106163025,
      "learning_rate": 3.558765677005042e-05,
      "loss": 2.9004,
      "step": 50960
    },
    {
      "epoch": 2.193767754153396,
      "grad_norm": 0.9631280899047852,
      "learning_rate": 3.5552120580894324e-05,
      "loss": 3.0318,
      "step": 50970
    },
    {
      "epoch": 2.194198157872084,
      "grad_norm": 0.8590860962867737,
      "learning_rate": 3.551659830684357e-05,
      "loss": 2.9664,
      "step": 50980
    },
    {
      "epoch": 2.194628561590772,
      "grad_norm": 0.9609149098396301,
      "learning_rate": 3.54810899555678e-05,
      "loss": 2.9709,
      "step": 50990
    },
    {
      "epoch": 2.1950589653094603,
      "grad_norm": 0.8704186081886292,
      "learning_rate": 3.54455955347338e-05,
      "loss": 2.8738,
      "step": 51000
    },
    {
      "epoch": 2.1950589653094603,
      "eval_bleu": 27.13250531498048,
      "eval_gen_len": 27.539,
      "eval_loss": 2.788682699203491,
      "eval_runtime": 58.5781,
      "eval_samples_per_second": 17.071,
      "eval_steps_per_second": 1.075,
      "step": 51000
    },
    {
      "epoch": 2.1954893690281483,
      "grad_norm": 0.9636791944503784,
      "learning_rate": 3.541011505200517e-05,
      "loss": 2.9972,
      "step": 51010
    },
    {
      "epoch": 2.1959197727468367,
      "grad_norm": 0.9762729406356812,
      "learning_rate": 3.537464851504266e-05,
      "loss": 3.0139,
      "step": 51020
    },
    {
      "epoch": 2.1963501764655247,
      "grad_norm": 0.9429835081100464,
      "learning_rate": 3.5339195931503886e-05,
      "loss": 2.9259,
      "step": 51030
    },
    {
      "epoch": 2.1967805801842126,
      "grad_norm": 0.981917679309845,
      "learning_rate": 3.530375730904357e-05,
      "loss": 2.9446,
      "step": 51040
    },
    {
      "epoch": 2.197210983902901,
      "grad_norm": 0.925335705280304,
      "learning_rate": 3.5268332655313304e-05,
      "loss": 3.0191,
      "step": 51050
    },
    {
      "epoch": 2.197210983902901,
      "eval_bleu": 26.868084877785247,
      "eval_gen_len": 27.533,
      "eval_loss": 2.7887206077575684,
      "eval_runtime": 58.4813,
      "eval_samples_per_second": 17.099,
      "eval_steps_per_second": 1.077,
      "step": 51050
    },
    {
      "epoch": 2.197641387621589,
      "grad_norm": 1.1008620262145996,
      "learning_rate": 3.523292197796171e-05,
      "loss": 3.0145,
      "step": 51060
    },
    {
      "epoch": 2.1980717913402774,
      "grad_norm": 0.8974224925041199,
      "learning_rate": 3.5197525284634436e-05,
      "loss": 2.9707,
      "step": 51070
    },
    {
      "epoch": 2.1985021950589654,
      "grad_norm": 0.9609619975090027,
      "learning_rate": 3.516214258297401e-05,
      "loss": 2.9296,
      "step": 51080
    },
    {
      "epoch": 2.1989325987776533,
      "grad_norm": 0.9718437790870667,
      "learning_rate": 3.512677388062009e-05,
      "loss": 2.9271,
      "step": 51090
    },
    {
      "epoch": 2.1993630024963418,
      "grad_norm": 0.9444953203201294,
      "learning_rate": 3.509141918520914e-05,
      "loss": 2.9566,
      "step": 51100
    },
    {
      "epoch": 2.1993630024963418,
      "eval_bleu": 27.129953191051076,
      "eval_gen_len": 27.553,
      "eval_loss": 2.7869484424591064,
      "eval_runtime": 58.3617,
      "eval_samples_per_second": 17.135,
      "eval_steps_per_second": 1.079,
      "step": 51100
    },
    {
      "epoch": 2.1997934062150297,
      "grad_norm": 0.9636026620864868,
      "learning_rate": 3.5056078504374745e-05,
      "loss": 2.9431,
      "step": 51110
    },
    {
      "epoch": 2.2002238099337177,
      "grad_norm": 0.8358058929443359,
      "learning_rate": 3.502075184574737e-05,
      "loss": 3.0049,
      "step": 51120
    },
    {
      "epoch": 2.200654213652406,
      "grad_norm": 0.8162080645561218,
      "learning_rate": 3.498543921695445e-05,
      "loss": 3.0504,
      "step": 51130
    },
    {
      "epoch": 2.201084617371094,
      "grad_norm": 0.940078854560852,
      "learning_rate": 3.49501406256205e-05,
      "loss": 2.9878,
      "step": 51140
    },
    {
      "epoch": 2.201515021089782,
      "grad_norm": 0.9160478711128235,
      "learning_rate": 3.491485607936685e-05,
      "loss": 3.0138,
      "step": 51150
    },
    {
      "epoch": 2.201515021089782,
      "eval_bleu": 27.05605851058908,
      "eval_gen_len": 27.532,
      "eval_loss": 2.789236545562744,
      "eval_runtime": 58.191,
      "eval_samples_per_second": 17.185,
      "eval_steps_per_second": 1.083,
      "step": 51150
    },
    {
      "epoch": 2.2019454248084704,
      "grad_norm": 0.8515855073928833,
      "learning_rate": 3.487958558581196e-05,
      "loss": 2.9423,
      "step": 51160
    },
    {
      "epoch": 2.2023758285271584,
      "grad_norm": 0.9919300675392151,
      "learning_rate": 3.4844329152571085e-05,
      "loss": 3.0841,
      "step": 51170
    },
    {
      "epoch": 2.2028062322458464,
      "grad_norm": 0.8458607196807861,
      "learning_rate": 3.4809086787256606e-05,
      "loss": 2.936,
      "step": 51180
    },
    {
      "epoch": 2.203236635964535,
      "grad_norm": 0.8853669762611389,
      "learning_rate": 3.477385849747773e-05,
      "loss": 2.9482,
      "step": 51190
    },
    {
      "epoch": 2.2036670396832228,
      "grad_norm": 0.9988855719566345,
      "learning_rate": 3.473864429084077e-05,
      "loss": 2.9722,
      "step": 51200
    },
    {
      "epoch": 2.2036670396832228,
      "eval_bleu": 26.790805615872987,
      "eval_gen_len": 27.486,
      "eval_loss": 2.790931224822998,
      "eval_runtime": 57.77,
      "eval_samples_per_second": 17.31,
      "eval_steps_per_second": 1.091,
      "step": 51200
    },
    {
      "epoch": 2.204097443401911,
      "grad_norm": 0.9317398071289062,
      "learning_rate": 3.47034441749488e-05,
      "loss": 2.8547,
      "step": 51210
    },
    {
      "epoch": 2.204527847120599,
      "grad_norm": 0.8780705332756042,
      "learning_rate": 3.466825815740206e-05,
      "loss": 2.89,
      "step": 51220
    },
    {
      "epoch": 2.204958250839287,
      "grad_norm": 0.9234088659286499,
      "learning_rate": 3.4633086245797584e-05,
      "loss": 3.0311,
      "step": 51230
    },
    {
      "epoch": 2.2053886545579755,
      "grad_norm": 0.9689022302627563,
      "learning_rate": 3.4597928447729466e-05,
      "loss": 3.0263,
      "step": 51240
    },
    {
      "epoch": 2.2058190582766635,
      "grad_norm": 0.9245508909225464,
      "learning_rate": 3.456278477078874e-05,
      "loss": 2.8664,
      "step": 51250
    },
    {
      "epoch": 2.2058190582766635,
      "eval_bleu": 27.259193462147095,
      "eval_gen_len": 27.581,
      "eval_loss": 2.789907217025757,
      "eval_runtime": 58.7884,
      "eval_samples_per_second": 17.01,
      "eval_steps_per_second": 1.072,
      "step": 51250
    },
    {
      "epoch": 2.2062494619953514,
      "grad_norm": 0.8041797876358032,
      "learning_rate": 3.45276552225633e-05,
      "loss": 3.019,
      "step": 51260
    },
    {
      "epoch": 2.20667986571404,
      "grad_norm": 0.9749842286109924,
      "learning_rate": 3.4492539810638146e-05,
      "loss": 2.9763,
      "step": 51270
    },
    {
      "epoch": 2.207110269432728,
      "grad_norm": 0.7982768416404724,
      "learning_rate": 3.4457438542595046e-05,
      "loss": 2.9296,
      "step": 51280
    },
    {
      "epoch": 2.207540673151416,
      "grad_norm": 1.0036966800689697,
      "learning_rate": 3.44223514260129e-05,
      "loss": 2.9964,
      "step": 51290
    },
    {
      "epoch": 2.207971076870104,
      "grad_norm": 0.9950197339057922,
      "learning_rate": 3.438727846846734e-05,
      "loss": 2.9204,
      "step": 51300
    },
    {
      "epoch": 2.207971076870104,
      "eval_bleu": 27.247104343933852,
      "eval_gen_len": 27.548,
      "eval_loss": 2.787994623184204,
      "eval_runtime": 58.215,
      "eval_samples_per_second": 17.178,
      "eval_steps_per_second": 1.082,
      "step": 51300
    },
    {
      "epoch": 2.208401480588792,
      "grad_norm": 0.8686671257019043,
      "learning_rate": 3.435221967753115e-05,
      "loss": 2.9466,
      "step": 51310
    },
    {
      "epoch": 2.2088318843074806,
      "grad_norm": 1.011614441871643,
      "learning_rate": 3.4317175060773884e-05,
      "loss": 3.0977,
      "step": 51320
    },
    {
      "epoch": 2.2092622880261685,
      "grad_norm": 0.8447913527488708,
      "learning_rate": 3.428214462576218e-05,
      "loss": 3.0532,
      "step": 51330
    },
    {
      "epoch": 2.2096926917448565,
      "grad_norm": 0.9321047067642212,
      "learning_rate": 3.4247128380059546e-05,
      "loss": 3.0526,
      "step": 51340
    },
    {
      "epoch": 2.210123095463545,
      "grad_norm": 0.8733768463134766,
      "learning_rate": 3.421212633122638e-05,
      "loss": 2.9699,
      "step": 51350
    },
    {
      "epoch": 2.210123095463545,
      "eval_bleu": 27.043944049729266,
      "eval_gen_len": 27.559,
      "eval_loss": 2.7882649898529053,
      "eval_runtime": 58.0026,
      "eval_samples_per_second": 17.241,
      "eval_steps_per_second": 1.086,
      "step": 51350
    },
    {
      "epoch": 2.210553499182233,
      "grad_norm": 0.9686533212661743,
      "learning_rate": 3.4177138486820124e-05,
      "loss": 3.0537,
      "step": 51360
    },
    {
      "epoch": 2.210983902900921,
      "grad_norm": 0.7777481079101562,
      "learning_rate": 3.4142164854395074e-05,
      "loss": 2.8974,
      "step": 51370
    },
    {
      "epoch": 2.2114143066196092,
      "grad_norm": 0.9522612690925598,
      "learning_rate": 3.410720544150246e-05,
      "loss": 2.9961,
      "step": 51380
    },
    {
      "epoch": 2.211844710338297,
      "grad_norm": 0.9895794987678528,
      "learning_rate": 3.407226025569041e-05,
      "loss": 2.9572,
      "step": 51390
    },
    {
      "epoch": 2.2122751140569856,
      "grad_norm": 0.9130285382270813,
      "learning_rate": 3.403732930450413e-05,
      "loss": 3.0376,
      "step": 51400
    },
    {
      "epoch": 2.2122751140569856,
      "eval_bleu": 26.896967970401555,
      "eval_gen_len": 27.546,
      "eval_loss": 2.7887980937957764,
      "eval_runtime": 58.014,
      "eval_samples_per_second": 17.237,
      "eval_steps_per_second": 1.086,
      "step": 51400
    },
    {
      "epoch": 2.2127055177756736,
      "grad_norm": 0.9906685948371887,
      "learning_rate": 3.4002412595485566e-05,
      "loss": 2.9068,
      "step": 51410
    },
    {
      "epoch": 2.2131359214943616,
      "grad_norm": 1.0020109415054321,
      "learning_rate": 3.396751013617373e-05,
      "loss": 2.9732,
      "step": 51420
    },
    {
      "epoch": 2.21356632521305,
      "grad_norm": 1.021337866783142,
      "learning_rate": 3.393262193410445e-05,
      "loss": 2.9011,
      "step": 51430
    },
    {
      "epoch": 2.213996728931738,
      "grad_norm": 0.912395715713501,
      "learning_rate": 3.389774799681056e-05,
      "loss": 2.9871,
      "step": 51440
    },
    {
      "epoch": 2.214427132650426,
      "grad_norm": 0.9494967460632324,
      "learning_rate": 3.386288833182183e-05,
      "loss": 3.0277,
      "step": 51450
    },
    {
      "epoch": 2.214427132650426,
      "eval_bleu": 27.251334546644838,
      "eval_gen_len": 27.52,
      "eval_loss": 2.786726236343384,
      "eval_runtime": 58.1557,
      "eval_samples_per_second": 17.195,
      "eval_steps_per_second": 1.083,
      "step": 51450
    },
    {
      "epoch": 2.2148575363691143,
      "grad_norm": 0.9805850386619568,
      "learning_rate": 3.3828042946664774e-05,
      "loss": 2.9788,
      "step": 51460
    },
    {
      "epoch": 2.2152879400878023,
      "grad_norm": 0.8602944016456604,
      "learning_rate": 3.379321184886306e-05,
      "loss": 2.9258,
      "step": 51470
    },
    {
      "epoch": 2.2157183438064907,
      "grad_norm": 0.7832169532775879,
      "learning_rate": 3.3758395045937075e-05,
      "loss": 2.9426,
      "step": 51480
    },
    {
      "epoch": 2.2161487475251787,
      "grad_norm": 0.7629126310348511,
      "learning_rate": 3.372359254540427e-05,
      "loss": 2.8291,
      "step": 51490
    },
    {
      "epoch": 2.2165791512438666,
      "grad_norm": 0.815395176410675,
      "learning_rate": 3.368880435477889e-05,
      "loss": 2.9307,
      "step": 51500
    },
    {
      "epoch": 2.2165791512438666,
      "eval_bleu": 27.226550870579715,
      "eval_gen_len": 27.522,
      "eval_loss": 2.7878756523132324,
      "eval_runtime": 57.5394,
      "eval_samples_per_second": 17.379,
      "eval_steps_per_second": 1.095,
      "step": 51500
    },
    {
      "epoch": 2.217009554962555,
      "grad_norm": 0.9274395704269409,
      "learning_rate": 3.365403048157221e-05,
      "loss": 3.0194,
      "step": 51510
    },
    {
      "epoch": 2.217439958681243,
      "grad_norm": 0.8753430247306824,
      "learning_rate": 3.361927093329226e-05,
      "loss": 3.0208,
      "step": 51520
    },
    {
      "epoch": 2.217870362399931,
      "grad_norm": 0.8780311346054077,
      "learning_rate": 3.358452571744413e-05,
      "loss": 2.8954,
      "step": 51530
    },
    {
      "epoch": 2.2183007661186194,
      "grad_norm": 0.9673742055892944,
      "learning_rate": 3.3549794841529726e-05,
      "loss": 2.9419,
      "step": 51540
    },
    {
      "epoch": 2.2187311698373073,
      "grad_norm": 0.9679761528968811,
      "learning_rate": 3.3515078313047846e-05,
      "loss": 3.0524,
      "step": 51550
    },
    {
      "epoch": 2.2187311698373073,
      "eval_bleu": 27.187914077697098,
      "eval_gen_len": 27.533,
      "eval_loss": 2.788456678390503,
      "eval_runtime": 58.335,
      "eval_samples_per_second": 17.142,
      "eval_steps_per_second": 1.08,
      "step": 51550
    },
    {
      "epoch": 2.2191615735559953,
      "grad_norm": 1.0509836673736572,
      "learning_rate": 3.348037613949427e-05,
      "loss": 3.0265,
      "step": 51560
    },
    {
      "epoch": 2.2195919772746837,
      "grad_norm": 0.9779388308525085,
      "learning_rate": 3.34456883283616e-05,
      "loss": 2.9744,
      "step": 51570
    },
    {
      "epoch": 2.2200223809933717,
      "grad_norm": 0.8900954127311707,
      "learning_rate": 3.3411014887139416e-05,
      "loss": 3.006,
      "step": 51580
    },
    {
      "epoch": 2.22045278471206,
      "grad_norm": 0.928207278251648,
      "learning_rate": 3.337635582331408e-05,
      "loss": 2.9431,
      "step": 51590
    },
    {
      "epoch": 2.220883188430748,
      "grad_norm": 0.883174479007721,
      "learning_rate": 3.334171114436899e-05,
      "loss": 3.051,
      "step": 51600
    },
    {
      "epoch": 2.220883188430748,
      "eval_bleu": 27.454700406332822,
      "eval_gen_len": 27.552,
      "eval_loss": 2.7881906032562256,
      "eval_runtime": 58.3452,
      "eval_samples_per_second": 17.139,
      "eval_steps_per_second": 1.08,
      "step": 51600
    },
    {
      "epoch": 2.221313592149436,
      "grad_norm": 0.9257109761238098,
      "learning_rate": 3.330708085778433e-05,
      "loss": 3.0155,
      "step": 51610
    },
    {
      "epoch": 2.2217439958681244,
      "grad_norm": 0.882049024105072,
      "learning_rate": 3.32724649710372e-05,
      "loss": 2.9845,
      "step": 51620
    },
    {
      "epoch": 2.2221743995868124,
      "grad_norm": 0.7302088141441345,
      "learning_rate": 3.323786349160164e-05,
      "loss": 2.9863,
      "step": 51630
    },
    {
      "epoch": 2.2226048033055004,
      "grad_norm": 0.9095031023025513,
      "learning_rate": 3.3203276426948484e-05,
      "loss": 2.9219,
      "step": 51640
    },
    {
      "epoch": 2.2230352070241888,
      "grad_norm": 0.9521424770355225,
      "learning_rate": 3.316870378454559e-05,
      "loss": 2.9568,
      "step": 51650
    },
    {
      "epoch": 2.2230352070241888,
      "eval_bleu": 27.21602982137931,
      "eval_gen_len": 27.543,
      "eval_loss": 2.7877750396728516,
      "eval_runtime": 58.5841,
      "eval_samples_per_second": 17.069,
      "eval_steps_per_second": 1.075,
      "step": 51650
    },
    {
      "epoch": 2.2234656107428767,
      "grad_norm": 0.8485382795333862,
      "learning_rate": 3.313414557185756e-05,
      "loss": 2.9637,
      "step": 51660
    },
    {
      "epoch": 2.223896014461565,
      "grad_norm": 0.8811826705932617,
      "learning_rate": 3.3099601796346e-05,
      "loss": 3.0396,
      "step": 51670
    },
    {
      "epoch": 2.224326418180253,
      "grad_norm": 0.8672823309898376,
      "learning_rate": 3.306507246546928e-05,
      "loss": 2.9925,
      "step": 51680
    },
    {
      "epoch": 2.224756821898941,
      "grad_norm": 0.9127233624458313,
      "learning_rate": 3.30305575866828e-05,
      "loss": 3.0742,
      "step": 51690
    },
    {
      "epoch": 2.2251872256176295,
      "grad_norm": 1.0303701162338257,
      "learning_rate": 3.29960571674387e-05,
      "loss": 2.9223,
      "step": 51700
    },
    {
      "epoch": 2.2251872256176295,
      "eval_bleu": 27.204611581375058,
      "eval_gen_len": 27.541,
      "eval_loss": 2.787797689437866,
      "eval_runtime": 57.9893,
      "eval_samples_per_second": 17.245,
      "eval_steps_per_second": 1.086,
      "step": 51700
    },
    {
      "epoch": 2.2256176293363175,
      "grad_norm": 0.8564621806144714,
      "learning_rate": 3.2961571215186024e-05,
      "loss": 3.0343,
      "step": 51710
    },
    {
      "epoch": 2.2260480330550054,
      "grad_norm": 0.9775375127792358,
      "learning_rate": 3.292709973737079e-05,
      "loss": 2.9491,
      "step": 51720
    },
    {
      "epoch": 2.226478436773694,
      "grad_norm": 0.9163739085197449,
      "learning_rate": 3.289264274143576e-05,
      "loss": 2.9582,
      "step": 51730
    },
    {
      "epoch": 2.226908840492382,
      "grad_norm": 0.9488199949264526,
      "learning_rate": 3.2858200234820704e-05,
      "loss": 3.0089,
      "step": 51740
    },
    {
      "epoch": 2.2273392442110698,
      "grad_norm": 0.8226272463798523,
      "learning_rate": 3.282377222496211e-05,
      "loss": 2.9572,
      "step": 51750
    },
    {
      "epoch": 2.2273392442110698,
      "eval_bleu": 27.31902346135277,
      "eval_gen_len": 27.494,
      "eval_loss": 2.788346529006958,
      "eval_runtime": 58.673,
      "eval_samples_per_second": 17.044,
      "eval_steps_per_second": 1.074,
      "step": 51750
    },
    {
      "epoch": 2.227769647929758,
      "grad_norm": 0.8701657652854919,
      "learning_rate": 3.278935871929348e-05,
      "loss": 2.8902,
      "step": 51760
    },
    {
      "epoch": 2.228200051648446,
      "grad_norm": 0.9503600001335144,
      "learning_rate": 3.2754959725245115e-05,
      "loss": 3.0442,
      "step": 51770
    },
    {
      "epoch": 2.2286304553671346,
      "grad_norm": 0.9756509065628052,
      "learning_rate": 3.2720575250244125e-05,
      "loss": 3.0677,
      "step": 51780
    },
    {
      "epoch": 2.2290608590858225,
      "grad_norm": 0.853103518486023,
      "learning_rate": 3.268620530171463e-05,
      "loss": 2.9566,
      "step": 51790
    },
    {
      "epoch": 2.2294912628045105,
      "grad_norm": 0.9471337795257568,
      "learning_rate": 3.265184988707748e-05,
      "loss": 2.9208,
      "step": 51800
    },
    {
      "epoch": 2.2294912628045105,
      "eval_bleu": 27.568407429039016,
      "eval_gen_len": 27.521,
      "eval_loss": 2.7871642112731934,
      "eval_runtime": 58.393,
      "eval_samples_per_second": 17.125,
      "eval_steps_per_second": 1.079,
      "step": 51800
    },
    {
      "epoch": 2.229921666523199,
      "grad_norm": 0.9227254986763,
      "learning_rate": 3.261750901375048e-05,
      "loss": 3.0424,
      "step": 51810
    },
    {
      "epoch": 2.230352070241887,
      "grad_norm": 0.9274421334266663,
      "learning_rate": 3.258318268914821e-05,
      "loss": 2.9833,
      "step": 51820
    },
    {
      "epoch": 2.230782473960575,
      "grad_norm": 0.893911600112915,
      "learning_rate": 3.25488709206822e-05,
      "loss": 2.9573,
      "step": 51830
    },
    {
      "epoch": 2.2312128776792632,
      "grad_norm": 0.9708549380302429,
      "learning_rate": 3.2514573715760745e-05,
      "loss": 3.0378,
      "step": 51840
    },
    {
      "epoch": 2.231643281397951,
      "grad_norm": 0.9328894019126892,
      "learning_rate": 3.248029108178912e-05,
      "loss": 3.0284,
      "step": 51850
    },
    {
      "epoch": 2.231643281397951,
      "eval_bleu": 27.4545290270956,
      "eval_gen_len": 27.51,
      "eval_loss": 2.7894082069396973,
      "eval_runtime": 57.65,
      "eval_samples_per_second": 17.346,
      "eval_steps_per_second": 1.093,
      "step": 51850
    },
    {
      "epoch": 2.2320736851166396,
      "grad_norm": 0.9001268744468689,
      "learning_rate": 3.2446023026169256e-05,
      "loss": 2.9997,
      "step": 51860
    },
    {
      "epoch": 2.2325040888353276,
      "grad_norm": 1.0879400968551636,
      "learning_rate": 3.241176955630013e-05,
      "loss": 2.9972,
      "step": 51870
    },
    {
      "epoch": 2.2329344925540155,
      "grad_norm": 0.914167582988739,
      "learning_rate": 3.237753067957753e-05,
      "loss": 3.0154,
      "step": 51880
    },
    {
      "epoch": 2.233364896272704,
      "grad_norm": 0.9210753440856934,
      "learning_rate": 3.234330640339396e-05,
      "loss": 2.9977,
      "step": 51890
    },
    {
      "epoch": 2.233795299991392,
      "grad_norm": 0.893761157989502,
      "learning_rate": 3.230909673513897e-05,
      "loss": 2.9299,
      "step": 51900
    },
    {
      "epoch": 2.233795299991392,
      "eval_bleu": 27.61005951606822,
      "eval_gen_len": 27.541,
      "eval_loss": 2.788684844970703,
      "eval_runtime": 58.3495,
      "eval_samples_per_second": 17.138,
      "eval_steps_per_second": 1.08,
      "step": 51900
    },
    {
      "epoch": 2.23422570371008,
      "grad_norm": 0.8928731083869934,
      "learning_rate": 3.227490168219878e-05,
      "loss": 2.9465,
      "step": 51910
    },
    {
      "epoch": 2.2346561074287683,
      "grad_norm": 0.950863778591156,
      "learning_rate": 3.224072125195659e-05,
      "loss": 3.01,
      "step": 51920
    },
    {
      "epoch": 2.2350865111474563,
      "grad_norm": 0.9200976490974426,
      "learning_rate": 3.220655545179233e-05,
      "loss": 3.0391,
      "step": 51930
    },
    {
      "epoch": 2.2355169148661442,
      "grad_norm": 1.0743223428726196,
      "learning_rate": 3.2172404289082914e-05,
      "loss": 2.9545,
      "step": 51940
    },
    {
      "epoch": 2.2359473185848326,
      "grad_norm": 0.8266412615776062,
      "learning_rate": 3.213826777120188e-05,
      "loss": 2.9684,
      "step": 51950
    },
    {
      "epoch": 2.2359473185848326,
      "eval_bleu": 27.598255575860566,
      "eval_gen_len": 27.491,
      "eval_loss": 2.788750648498535,
      "eval_runtime": 58.5307,
      "eval_samples_per_second": 17.085,
      "eval_steps_per_second": 1.076,
      "step": 51950
    },
    {
      "epoch": 2.2363777223035206,
      "grad_norm": 0.9511186480522156,
      "learning_rate": 3.21041459055198e-05,
      "loss": 2.9774,
      "step": 51960
    },
    {
      "epoch": 2.236808126022209,
      "grad_norm": 0.9101347327232361,
      "learning_rate": 3.207003869940403e-05,
      "loss": 2.994,
      "step": 51970
    },
    {
      "epoch": 2.237238529740897,
      "grad_norm": 0.9882542490959167,
      "learning_rate": 3.203594616021869e-05,
      "loss": 3.0382,
      "step": 51980
    },
    {
      "epoch": 2.237668933459585,
      "grad_norm": 0.8815281391143799,
      "learning_rate": 3.200186829532484e-05,
      "loss": 2.988,
      "step": 51990
    },
    {
      "epoch": 2.2380993371782734,
      "grad_norm": 0.9180336594581604,
      "learning_rate": 3.1967805112080277e-05,
      "loss": 2.9891,
      "step": 52000
    },
    {
      "epoch": 2.2380993371782734,
      "eval_bleu": 27.765549698660692,
      "eval_gen_len": 27.539,
      "eval_loss": 2.7886290550231934,
      "eval_runtime": 58.1192,
      "eval_samples_per_second": 17.206,
      "eval_steps_per_second": 1.084,
      "step": 52000
    },
    {
      "epoch": 2.2385297408969613,
      "grad_norm": 0.8316059112548828,
      "learning_rate": 3.193375661783972e-05,
      "loss": 2.9878,
      "step": 52010
    },
    {
      "epoch": 2.2389601446156493,
      "grad_norm": 0.9371936321258545,
      "learning_rate": 3.189972281995463e-05,
      "loss": 2.9066,
      "step": 52020
    },
    {
      "epoch": 2.2393905483343377,
      "grad_norm": 0.9303039908409119,
      "learning_rate": 3.186570372577332e-05,
      "loss": 2.9833,
      "step": 52030
    },
    {
      "epoch": 2.2398209520530257,
      "grad_norm": 0.9938921332359314,
      "learning_rate": 3.1831699342640934e-05,
      "loss": 2.9198,
      "step": 52040
    },
    {
      "epoch": 2.240251355771714,
      "grad_norm": 0.8771734237670898,
      "learning_rate": 3.17977096778995e-05,
      "loss": 2.9692,
      "step": 52050
    },
    {
      "epoch": 2.240251355771714,
      "eval_bleu": 27.387670961197788,
      "eval_gen_len": 27.5,
      "eval_loss": 2.788917303085327,
      "eval_runtime": 58.6776,
      "eval_samples_per_second": 17.042,
      "eval_steps_per_second": 1.074,
      "step": 52050
    },
    {
      "epoch": 2.240681759490402,
      "grad_norm": 0.9356749653816223,
      "learning_rate": 3.1763734738887726e-05,
      "loss": 3.0102,
      "step": 52060
    },
    {
      "epoch": 2.24111216320909,
      "grad_norm": 0.9307722449302673,
      "learning_rate": 3.1729774532941304e-05,
      "loss": 2.8811,
      "step": 52070
    },
    {
      "epoch": 2.2415425669277784,
      "grad_norm": 0.9354407787322998,
      "learning_rate": 3.169582906739266e-05,
      "loss": 3.0486,
      "step": 52080
    },
    {
      "epoch": 2.2419729706464664,
      "grad_norm": 1.0302022695541382,
      "learning_rate": 3.1661898349570996e-05,
      "loss": 2.9988,
      "step": 52090
    },
    {
      "epoch": 2.2424033743651544,
      "grad_norm": 0.8996014595031738,
      "learning_rate": 3.162798238680248e-05,
      "loss": 2.9741,
      "step": 52100
    },
    {
      "epoch": 2.2424033743651544,
      "eval_bleu": 27.42223317848263,
      "eval_gen_len": 27.544,
      "eval_loss": 2.7874510288238525,
      "eval_runtime": 58.8139,
      "eval_samples_per_second": 17.003,
      "eval_steps_per_second": 1.071,
      "step": 52100
    },
    {
      "epoch": 2.2428337780838428,
      "grad_norm": 0.9391310811042786,
      "learning_rate": 3.159408118640985e-05,
      "loss": 2.9853,
      "step": 52110
    },
    {
      "epoch": 2.2432641818025307,
      "grad_norm": 0.8356626629829407,
      "learning_rate": 3.1560194755712916e-05,
      "loss": 2.9747,
      "step": 52120
    },
    {
      "epoch": 2.2436945855212187,
      "grad_norm": 0.9568073153495789,
      "learning_rate": 3.152632310202811e-05,
      "loss": 2.9252,
      "step": 52130
    },
    {
      "epoch": 2.244124989239907,
      "grad_norm": 0.9092323780059814,
      "learning_rate": 3.1492466232668815e-05,
      "loss": 2.8846,
      "step": 52140
    },
    {
      "epoch": 2.244555392958595,
      "grad_norm": 0.8912228941917419,
      "learning_rate": 3.1458624154945084e-05,
      "loss": 2.9441,
      "step": 52150
    },
    {
      "epoch": 2.244555392958595,
      "eval_bleu": 27.196650380613608,
      "eval_gen_len": 27.541,
      "eval_loss": 2.789809465408325,
      "eval_runtime": 57.9673,
      "eval_samples_per_second": 17.251,
      "eval_steps_per_second": 1.087,
      "step": 52150
    },
    {
      "epoch": 2.2449857966772835,
      "grad_norm": 0.9625124335289001,
      "learning_rate": 3.1424796876163874e-05,
      "loss": 2.9106,
      "step": 52160
    },
    {
      "epoch": 2.2454162003959715,
      "grad_norm": 0.9433139562606812,
      "learning_rate": 3.139098440362897e-05,
      "loss": 3.0897,
      "step": 52170
    },
    {
      "epoch": 2.2458466041146594,
      "grad_norm": 0.8094007968902588,
      "learning_rate": 3.135718674464084e-05,
      "loss": 3.0756,
      "step": 52180
    },
    {
      "epoch": 2.246277007833348,
      "grad_norm": 0.829662561416626,
      "learning_rate": 3.132340390649686e-05,
      "loss": 2.9681,
      "step": 52190
    },
    {
      "epoch": 2.246707411552036,
      "grad_norm": 0.8536170125007629,
      "learning_rate": 3.1289635896491135e-05,
      "loss": 2.9002,
      "step": 52200
    },
    {
      "epoch": 2.246707411552036,
      "eval_bleu": 27.1745327576077,
      "eval_gen_len": 27.571,
      "eval_loss": 2.7899460792541504,
      "eval_runtime": 58.0812,
      "eval_samples_per_second": 17.217,
      "eval_steps_per_second": 1.085,
      "step": 52200
    },
    {
      "epoch": 2.2471378152707238,
      "grad_norm": 0.9344011545181274,
      "learning_rate": 3.125588272191463e-05,
      "loss": 3.0321,
      "step": 52210
    },
    {
      "epoch": 2.247568218989412,
      "grad_norm": 0.8778495788574219,
      "learning_rate": 3.1222144390055055e-05,
      "loss": 2.9142,
      "step": 52220
    },
    {
      "epoch": 2.2479986227081,
      "grad_norm": 0.9323914647102356,
      "learning_rate": 3.118842090819698e-05,
      "loss": 2.9847,
      "step": 52230
    },
    {
      "epoch": 2.2484290264267885,
      "grad_norm": 0.9232760071754456,
      "learning_rate": 3.1154712283621665e-05,
      "loss": 2.9115,
      "step": 52240
    },
    {
      "epoch": 2.2488594301454765,
      "grad_norm": 1.0117865800857544,
      "learning_rate": 3.112101852360729e-05,
      "loss": 2.9914,
      "step": 52250
    },
    {
      "epoch": 2.2488594301454765,
      "eval_bleu": 27.158462890832755,
      "eval_gen_len": 27.557,
      "eval_loss": 2.789287805557251,
      "eval_runtime": 58.5279,
      "eval_samples_per_second": 17.086,
      "eval_steps_per_second": 1.076,
      "step": 52250
    },
    {
      "epoch": 2.2492898338641645,
      "grad_norm": 0.9271721243858337,
      "learning_rate": 3.1087339635428745e-05,
      "loss": 2.96,
      "step": 52260
    },
    {
      "epoch": 2.249720237582853,
      "grad_norm": 0.8954326510429382,
      "learning_rate": 3.105367562635767e-05,
      "loss": 2.9567,
      "step": 52270
    },
    {
      "epoch": 2.250150641301541,
      "grad_norm": 1.091764211654663,
      "learning_rate": 3.1020026503662625e-05,
      "loss": 2.9967,
      "step": 52280
    },
    {
      "epoch": 2.250581045020229,
      "grad_norm": 0.9209467768669128,
      "learning_rate": 3.0986392274608797e-05,
      "loss": 2.9655,
      "step": 52290
    },
    {
      "epoch": 2.2510114487389172,
      "grad_norm": 1.0250686407089233,
      "learning_rate": 3.095277294645832e-05,
      "loss": 3.0883,
      "step": 52300
    },
    {
      "epoch": 2.2510114487389172,
      "eval_bleu": 27.432298453288514,
      "eval_gen_len": 27.591,
      "eval_loss": 2.78940486907959,
      "eval_runtime": 58.6907,
      "eval_samples_per_second": 17.038,
      "eval_steps_per_second": 1.073,
      "step": 52300
    },
    {
      "epoch": 2.251441852457605,
      "grad_norm": 0.9259602427482605,
      "learning_rate": 3.091916852646995e-05,
      "loss": 3.0166,
      "step": 52310
    },
    {
      "epoch": 2.251872256176293,
      "grad_norm": 0.9081346988677979,
      "learning_rate": 3.088557902189939e-05,
      "loss": 2.9972,
      "step": 52320
    },
    {
      "epoch": 2.2523026598949816,
      "grad_norm": 0.8095223903656006,
      "learning_rate": 3.085200443999894e-05,
      "loss": 3.0453,
      "step": 52330
    },
    {
      "epoch": 2.2527330636136695,
      "grad_norm": 0.9586799740791321,
      "learning_rate": 3.0818444788017854e-05,
      "loss": 2.9705,
      "step": 52340
    },
    {
      "epoch": 2.2531634673323575,
      "grad_norm": 0.8656180500984192,
      "learning_rate": 3.078490007320205e-05,
      "loss": 3.0018,
      "step": 52350
    },
    {
      "epoch": 2.2531634673323575,
      "eval_bleu": 27.222885071720317,
      "eval_gen_len": 27.551,
      "eval_loss": 2.7892003059387207,
      "eval_runtime": 58.3801,
      "eval_samples_per_second": 17.129,
      "eval_steps_per_second": 1.079,
      "step": 52350
    },
    {
      "epoch": 2.253593871051046,
      "grad_norm": 0.9395633339881897,
      "learning_rate": 3.0751370302794224e-05,
      "loss": 3.0573,
      "step": 52360
    },
    {
      "epoch": 2.254024274769734,
      "grad_norm": 0.977966845035553,
      "learning_rate": 3.071785548403393e-05,
      "loss": 2.8972,
      "step": 52370
    },
    {
      "epoch": 2.2544546784884223,
      "grad_norm": 1.042253851890564,
      "learning_rate": 3.0684355624157366e-05,
      "loss": 3.0647,
      "step": 52380
    },
    {
      "epoch": 2.2548850822071103,
      "grad_norm": 0.9810803532600403,
      "learning_rate": 3.065087073039766e-05,
      "loss": 2.9289,
      "step": 52390
    },
    {
      "epoch": 2.2553154859257982,
      "grad_norm": 0.9083554744720459,
      "learning_rate": 3.061740080998454e-05,
      "loss": 2.9229,
      "step": 52400
    },
    {
      "epoch": 2.2553154859257982,
      "eval_bleu": 27.58253580659574,
      "eval_gen_len": 27.518,
      "eval_loss": 2.78930401802063,
      "eval_runtime": 58.3314,
      "eval_samples_per_second": 17.143,
      "eval_steps_per_second": 1.08,
      "step": 52400
    },
    {
      "epoch": 2.2557458896444866,
      "grad_norm": 0.8316552042961121,
      "learning_rate": 3.0583945870144634e-05,
      "loss": 2.9738,
      "step": 52410
    },
    {
      "epoch": 2.2561762933631746,
      "grad_norm": 0.9005473256111145,
      "learning_rate": 3.055050591810128e-05,
      "loss": 3.0109,
      "step": 52420
    },
    {
      "epoch": 2.256606697081863,
      "grad_norm": 0.8824008107185364,
      "learning_rate": 3.0517080961074527e-05,
      "loss": 2.987,
      "step": 52430
    },
    {
      "epoch": 2.257037100800551,
      "grad_norm": 0.9240342974662781,
      "learning_rate": 3.0483671006281323e-05,
      "loss": 3.0127,
      "step": 52440
    },
    {
      "epoch": 2.257467504519239,
      "grad_norm": 0.8654810786247253,
      "learning_rate": 3.0450276060935225e-05,
      "loss": 3.009,
      "step": 52450
    },
    {
      "epoch": 2.257467504519239,
      "eval_bleu": 27.364726799629263,
      "eval_gen_len": 27.516,
      "eval_loss": 2.7876527309417725,
      "eval_runtime": 58.3805,
      "eval_samples_per_second": 17.129,
      "eval_steps_per_second": 1.079,
      "step": 52450
    },
    {
      "epoch": 2.2578979082379274,
      "grad_norm": 0.8273653388023376,
      "learning_rate": 3.0416896132246674e-05,
      "loss": 2.9145,
      "step": 52460
    },
    {
      "epoch": 2.2583283119566153,
      "grad_norm": 0.900441586971283,
      "learning_rate": 3.038353122742277e-05,
      "loss": 2.9572,
      "step": 52470
    },
    {
      "epoch": 2.2587587156753033,
      "grad_norm": 0.9102916717529297,
      "learning_rate": 3.035018135366746e-05,
      "loss": 2.9472,
      "step": 52480
    },
    {
      "epoch": 2.2591891193939917,
      "grad_norm": 0.9788126349449158,
      "learning_rate": 3.0316846518181354e-05,
      "loss": 2.9586,
      "step": 52490
    },
    {
      "epoch": 2.2596195231126797,
      "grad_norm": 1.019395351409912,
      "learning_rate": 3.0283526728161916e-05,
      "loss": 2.9788,
      "step": 52500
    },
    {
      "epoch": 2.2596195231126797,
      "eval_bleu": 27.29525393186462,
      "eval_gen_len": 27.567,
      "eval_loss": 2.7875874042510986,
      "eval_runtime": 58.8636,
      "eval_samples_per_second": 16.988,
      "eval_steps_per_second": 1.07,
      "step": 52500
    },
    {
      "epoch": 2.2600499268313676,
      "grad_norm": 0.8865727782249451,
      "learning_rate": 3.0250221990803273e-05,
      "loss": 3.0223,
      "step": 52510
    },
    {
      "epoch": 2.260480330550056,
      "grad_norm": 1.004956603050232,
      "learning_rate": 3.0216932313296297e-05,
      "loss": 3.0079,
      "step": 52520
    },
    {
      "epoch": 2.260910734268744,
      "grad_norm": 0.8265392184257507,
      "learning_rate": 3.0183657702828728e-05,
      "loss": 2.9758,
      "step": 52530
    },
    {
      "epoch": 2.261341137987432,
      "grad_norm": 0.9068421125411987,
      "learning_rate": 3.0150398166584892e-05,
      "loss": 2.9891,
      "step": 52540
    },
    {
      "epoch": 2.2617715417061204,
      "grad_norm": 0.8376474380493164,
      "learning_rate": 3.0117153711746016e-05,
      "loss": 2.9477,
      "step": 52550
    },
    {
      "epoch": 2.2617715417061204,
      "eval_bleu": 27.36470063714053,
      "eval_gen_len": 27.475,
      "eval_loss": 2.787731170654297,
      "eval_runtime": 58.3731,
      "eval_samples_per_second": 17.131,
      "eval_steps_per_second": 1.079,
      "step": 52550
    },
    {
      "epoch": 2.2622019454248083,
      "grad_norm": 0.8357367515563965,
      "learning_rate": 3.0083924345489934e-05,
      "loss": 2.9943,
      "step": 52560
    },
    {
      "epoch": 2.2626323491434968,
      "grad_norm": 0.8174588680267334,
      "learning_rate": 3.0050710074991317e-05,
      "loss": 2.9695,
      "step": 52570
    },
    {
      "epoch": 2.2630627528621847,
      "grad_norm": 0.9766355752944946,
      "learning_rate": 3.001751090742152e-05,
      "loss": 2.9692,
      "step": 52580
    },
    {
      "epoch": 2.2634931565808727,
      "grad_norm": 0.9780826568603516,
      "learning_rate": 2.9984326849948687e-05,
      "loss": 3.0593,
      "step": 52590
    },
    {
      "epoch": 2.263923560299561,
      "grad_norm": 0.9476742148399353,
      "learning_rate": 2.995115790973767e-05,
      "loss": 3.0354,
      "step": 52600
    },
    {
      "epoch": 2.263923560299561,
      "eval_bleu": 27.45372920359743,
      "eval_gen_len": 27.503,
      "eval_loss": 2.789435863494873,
      "eval_runtime": 58.3802,
      "eval_samples_per_second": 17.129,
      "eval_steps_per_second": 1.079,
      "step": 52600
    },
    {
      "epoch": 2.264353964018249,
      "grad_norm": 0.856620728969574,
      "learning_rate": 2.9918004093950003e-05,
      "loss": 2.9364,
      "step": 52610
    },
    {
      "epoch": 2.2647843677369375,
      "grad_norm": 0.9106122851371765,
      "learning_rate": 2.988486540974409e-05,
      "loss": 2.9296,
      "step": 52620
    },
    {
      "epoch": 2.2652147714556254,
      "grad_norm": 0.9324386119842529,
      "learning_rate": 2.985174186427492e-05,
      "loss": 2.9399,
      "step": 52630
    },
    {
      "epoch": 2.2656451751743134,
      "grad_norm": 0.9161012172698975,
      "learning_rate": 2.9818633464694346e-05,
      "loss": 3.0321,
      "step": 52640
    },
    {
      "epoch": 2.266075578893002,
      "grad_norm": 0.9810160398483276,
      "learning_rate": 2.978554021815081e-05,
      "loss": 2.9606,
      "step": 52650
    },
    {
      "epoch": 2.266075578893002,
      "eval_bleu": 27.1252014032448,
      "eval_gen_len": 27.502,
      "eval_loss": 2.7880423069000244,
      "eval_runtime": 58.773,
      "eval_samples_per_second": 17.015,
      "eval_steps_per_second": 1.072,
      "step": 52650
    },
    {
      "epoch": 2.26650598261169,
      "grad_norm": 0.9304314851760864,
      "learning_rate": 2.975246213178965e-05,
      "loss": 3.0471,
      "step": 52660
    },
    {
      "epoch": 2.2669363863303778,
      "grad_norm": 0.9420238137245178,
      "learning_rate": 2.9719399212752785e-05,
      "loss": 2.9447,
      "step": 52670
    },
    {
      "epoch": 2.267366790049066,
      "grad_norm": 0.9267054796218872,
      "learning_rate": 2.968635146817892e-05,
      "loss": 2.9611,
      "step": 52680
    },
    {
      "epoch": 2.267797193767754,
      "grad_norm": 0.9406640529632568,
      "learning_rate": 2.9653318905203452e-05,
      "loss": 2.9449,
      "step": 52690
    },
    {
      "epoch": 2.268227597486442,
      "grad_norm": 0.939243495464325,
      "learning_rate": 2.962030153095855e-05,
      "loss": 2.9514,
      "step": 52700
    },
    {
      "epoch": 2.268227597486442,
      "eval_bleu": 27.324725533910662,
      "eval_gen_len": 27.466,
      "eval_loss": 2.7899491786956787,
      "eval_runtime": 57.8015,
      "eval_samples_per_second": 17.301,
      "eval_steps_per_second": 1.09,
      "step": 52700
    },
    {
      "epoch": 2.2686580012051305,
      "grad_norm": 0.8951435685157776,
      "learning_rate": 2.958729935257312e-05,
      "loss": 3.1022,
      "step": 52710
    },
    {
      "epoch": 2.2690884049238185,
      "grad_norm": 0.9612491726875305,
      "learning_rate": 2.9554312377172667e-05,
      "loss": 3.0271,
      "step": 52720
    },
    {
      "epoch": 2.2695188086425064,
      "grad_norm": 0.9616573452949524,
      "learning_rate": 2.9521340611879566e-05,
      "loss": 2.9696,
      "step": 52730
    },
    {
      "epoch": 2.269949212361195,
      "grad_norm": 0.9768179655075073,
      "learning_rate": 2.948838406381277e-05,
      "loss": 3.0152,
      "step": 52740
    },
    {
      "epoch": 2.270379616079883,
      "grad_norm": 1.0507588386535645,
      "learning_rate": 2.9455442740088103e-05,
      "loss": 2.9961,
      "step": 52750
    },
    {
      "epoch": 2.270379616079883,
      "eval_bleu": 27.154178940564407,
      "eval_gen_len": 27.523,
      "eval_loss": 2.788531541824341,
      "eval_runtime": 57.9785,
      "eval_samples_per_second": 17.248,
      "eval_steps_per_second": 1.087,
      "step": 52750
    },
    {
      "epoch": 2.2708100197985712,
      "grad_norm": 0.868106484413147,
      "learning_rate": 2.9422516647817888e-05,
      "loss": 2.9647,
      "step": 52760
    },
    {
      "epoch": 2.271240423517259,
      "grad_norm": 0.8838859796524048,
      "learning_rate": 2.9389605794111387e-05,
      "loss": 2.9831,
      "step": 52770
    },
    {
      "epoch": 2.271670827235947,
      "grad_norm": 0.9584671854972839,
      "learning_rate": 2.9356710186074375e-05,
      "loss": 2.9626,
      "step": 52780
    },
    {
      "epoch": 2.2721012309546356,
      "grad_norm": 1.0783799886703491,
      "learning_rate": 2.932382983080948e-05,
      "loss": 2.9822,
      "step": 52790
    },
    {
      "epoch": 2.2725316346733235,
      "grad_norm": 0.9714834094047546,
      "learning_rate": 2.9290964735416003e-05,
      "loss": 2.9717,
      "step": 52800
    },
    {
      "epoch": 2.2725316346733235,
      "eval_bleu": 27.110956967196632,
      "eval_gen_len": 27.566,
      "eval_loss": 2.788332939147949,
      "eval_runtime": 58.6144,
      "eval_samples_per_second": 17.061,
      "eval_steps_per_second": 1.075,
      "step": 52800
    },
    {
      "epoch": 2.272962038392012,
      "grad_norm": 0.8940364718437195,
      "learning_rate": 2.9258114906989875e-05,
      "loss": 2.9351,
      "step": 52810
    },
    {
      "epoch": 2.2733924421107,
      "grad_norm": 0.9164802432060242,
      "learning_rate": 2.922528035262384e-05,
      "loss": 3.0912,
      "step": 52820
    },
    {
      "epoch": 2.273822845829388,
      "grad_norm": 0.8684741854667664,
      "learning_rate": 2.9192461079407274e-05,
      "loss": 2.9996,
      "step": 52830
    },
    {
      "epoch": 2.2742532495480763,
      "grad_norm": 0.8417761921882629,
      "learning_rate": 2.915965709442625e-05,
      "loss": 2.9967,
      "step": 52840
    },
    {
      "epoch": 2.2746836532667642,
      "grad_norm": 0.8453576564788818,
      "learning_rate": 2.9126868404763554e-05,
      "loss": 2.9564,
      "step": 52850
    },
    {
      "epoch": 2.2746836532667642,
      "eval_bleu": 27.16450689426911,
      "eval_gen_len": 27.558,
      "eval_loss": 2.789181709289551,
      "eval_runtime": 58.6346,
      "eval_samples_per_second": 17.055,
      "eval_steps_per_second": 1.074,
      "step": 52850
    },
    {
      "epoch": 2.275114056985452,
      "grad_norm": 0.9506999254226685,
      "learning_rate": 2.9094095017498714e-05,
      "loss": 3.0123,
      "step": 52860
    },
    {
      "epoch": 2.2755444607041406,
      "grad_norm": 0.9697898626327515,
      "learning_rate": 2.906133693970785e-05,
      "loss": 2.9732,
      "step": 52870
    },
    {
      "epoch": 2.2759748644228286,
      "grad_norm": 0.8412909507751465,
      "learning_rate": 2.9028594178463932e-05,
      "loss": 2.8991,
      "step": 52880
    },
    {
      "epoch": 2.2764052681415166,
      "grad_norm": 0.9189106225967407,
      "learning_rate": 2.899586674083644e-05,
      "loss": 3.1131,
      "step": 52890
    },
    {
      "epoch": 2.276835671860205,
      "grad_norm": 1.0534825325012207,
      "learning_rate": 2.8963154633891687e-05,
      "loss": 3.0872,
      "step": 52900
    },
    {
      "epoch": 2.276835671860205,
      "eval_bleu": 27.65183236510075,
      "eval_gen_len": 27.582,
      "eval_loss": 2.7866525650024414,
      "eval_runtime": 58.2367,
      "eval_samples_per_second": 17.171,
      "eval_steps_per_second": 1.082,
      "step": 52900
    },
    {
      "epoch": 2.277266075578893,
      "grad_norm": 0.932421863079071,
      "learning_rate": 2.8930457864692682e-05,
      "loss": 2.9468,
      "step": 52910
    },
    {
      "epoch": 2.277696479297581,
      "grad_norm": 0.7475996017456055,
      "learning_rate": 2.889777644029895e-05,
      "loss": 2.9928,
      "step": 52920
    },
    {
      "epoch": 2.2781268830162693,
      "grad_norm": 0.8929126262664795,
      "learning_rate": 2.8865110367766913e-05,
      "loss": 3.03,
      "step": 52930
    },
    {
      "epoch": 2.2785572867349573,
      "grad_norm": 0.8657878637313843,
      "learning_rate": 2.883245965414951e-05,
      "loss": 2.9598,
      "step": 52940
    },
    {
      "epoch": 2.2789876904536457,
      "grad_norm": 0.8694988489151001,
      "learning_rate": 2.8799824306496525e-05,
      "loss": 2.895,
      "step": 52950
    },
    {
      "epoch": 2.2789876904536457,
      "eval_bleu": 27.33920958505632,
      "eval_gen_len": 27.515,
      "eval_loss": 2.786984920501709,
      "eval_runtime": 58.0098,
      "eval_samples_per_second": 17.238,
      "eval_steps_per_second": 1.086,
      "step": 52950
    },
    {
      "epoch": 2.2794180941723337,
      "grad_norm": 0.7779650688171387,
      "learning_rate": 2.876720433185426e-05,
      "loss": 2.9326,
      "step": 52960
    },
    {
      "epoch": 2.2798484978910216,
      "grad_norm": 0.9500412344932556,
      "learning_rate": 2.8734599737265834e-05,
      "loss": 2.98,
      "step": 52970
    },
    {
      "epoch": 2.28027890160971,
      "grad_norm": 0.9832775592803955,
      "learning_rate": 2.870201052977094e-05,
      "loss": 3.026,
      "step": 52980
    },
    {
      "epoch": 2.280709305328398,
      "grad_norm": 0.8922871947288513,
      "learning_rate": 2.866943671640605e-05,
      "loss": 2.9786,
      "step": 52990
    },
    {
      "epoch": 2.2811397090470864,
      "grad_norm": 1.0116723775863647,
      "learning_rate": 2.863687830420424e-05,
      "loss": 2.9291,
      "step": 53000
    },
    {
      "epoch": 2.2811397090470864,
      "eval_bleu": 27.416356473393023,
      "eval_gen_len": 27.472,
      "eval_loss": 2.7876131534576416,
      "eval_runtime": 58.5976,
      "eval_samples_per_second": 17.066,
      "eval_steps_per_second": 1.075,
      "step": 53000
    },
    {
      "epoch": 2.2815701127657744,
      "grad_norm": 0.8465976119041443,
      "learning_rate": 2.8604335300195228e-05,
      "loss": 2.983,
      "step": 53010
    },
    {
      "epoch": 2.2820005164844623,
      "grad_norm": 0.9554511904716492,
      "learning_rate": 2.857180771140553e-05,
      "loss": 3.0079,
      "step": 53020
    },
    {
      "epoch": 2.2824309202031507,
      "grad_norm": 0.8750789761543274,
      "learning_rate": 2.85392955448582e-05,
      "loss": 2.933,
      "step": 53030
    },
    {
      "epoch": 2.2828613239218387,
      "grad_norm": 0.8711968064308167,
      "learning_rate": 2.8506798807573088e-05,
      "loss": 2.9879,
      "step": 53040
    },
    {
      "epoch": 2.2832917276405267,
      "grad_norm": 0.8034070730209351,
      "learning_rate": 2.8474317506566573e-05,
      "loss": 2.9225,
      "step": 53050
    },
    {
      "epoch": 2.2832917276405267,
      "eval_bleu": 27.030023937554354,
      "eval_gen_len": 27.545,
      "eval_loss": 2.7885398864746094,
      "eval_runtime": 58.0469,
      "eval_samples_per_second": 17.227,
      "eval_steps_per_second": 1.085,
      "step": 53050
    },
    {
      "epoch": 2.283722131359215,
      "grad_norm": 0.798725426197052,
      "learning_rate": 2.8441851648851848e-05,
      "loss": 3.0152,
      "step": 53060
    },
    {
      "epoch": 2.284152535077903,
      "grad_norm": 1.022544026374817,
      "learning_rate": 2.840940124143866e-05,
      "loss": 3.0131,
      "step": 53070
    },
    {
      "epoch": 2.284582938796591,
      "grad_norm": 0.8693529367446899,
      "learning_rate": 2.8376966291333428e-05,
      "loss": 3.0798,
      "step": 53080
    },
    {
      "epoch": 2.2850133425152794,
      "grad_norm": 0.9776453971862793,
      "learning_rate": 2.834454680553933e-05,
      "loss": 2.9165,
      "step": 53090
    },
    {
      "epoch": 2.2854437462339674,
      "grad_norm": 1.0140092372894287,
      "learning_rate": 2.8312142791056085e-05,
      "loss": 2.9533,
      "step": 53100
    },
    {
      "epoch": 2.2854437462339674,
      "eval_bleu": 27.1179601809867,
      "eval_gen_len": 27.473,
      "eval_loss": 2.7892773151397705,
      "eval_runtime": 58.1955,
      "eval_samples_per_second": 17.183,
      "eval_steps_per_second": 1.083,
      "step": 53100
    },
    {
      "epoch": 2.2858741499526554,
      "grad_norm": 0.8933073878288269,
      "learning_rate": 2.8279754254880177e-05,
      "loss": 3.0054,
      "step": 53110
    },
    {
      "epoch": 2.2863045536713438,
      "grad_norm": 0.8226133584976196,
      "learning_rate": 2.824738120400463e-05,
      "loss": 2.8976,
      "step": 53120
    },
    {
      "epoch": 2.2867349573900317,
      "grad_norm": 0.9442071914672852,
      "learning_rate": 2.8215023645419268e-05,
      "loss": 3.0559,
      "step": 53130
    },
    {
      "epoch": 2.28716536110872,
      "grad_norm": 0.9027661681175232,
      "learning_rate": 2.8182681586110426e-05,
      "loss": 3.023,
      "step": 53140
    },
    {
      "epoch": 2.287595764827408,
      "grad_norm": 0.9257763028144836,
      "learning_rate": 2.8150355033061225e-05,
      "loss": 2.9921,
      "step": 53150
    },
    {
      "epoch": 2.287595764827408,
      "eval_bleu": 27.347085209617415,
      "eval_gen_len": 27.505,
      "eval_loss": 2.7872097492218018,
      "eval_runtime": 57.6988,
      "eval_samples_per_second": 17.331,
      "eval_steps_per_second": 1.092,
      "step": 53150
    },
    {
      "epoch": 2.288026168546096,
      "grad_norm": 0.9110820889472961,
      "learning_rate": 2.811804399325133e-05,
      "loss": 2.9889,
      "step": 53160
    },
    {
      "epoch": 2.2884565722647845,
      "grad_norm": 0.856508195400238,
      "learning_rate": 2.808574847365708e-05,
      "loss": 2.9826,
      "step": 53170
    },
    {
      "epoch": 2.2888869759834725,
      "grad_norm": 0.8764838576316833,
      "learning_rate": 2.8053468481251545e-05,
      "loss": 2.9136,
      "step": 53180
    },
    {
      "epoch": 2.289317379702161,
      "grad_norm": 0.899941623210907,
      "learning_rate": 2.802120402300432e-05,
      "loss": 2.9778,
      "step": 53190
    },
    {
      "epoch": 2.289747783420849,
      "grad_norm": 0.9282569885253906,
      "learning_rate": 2.7988955105881754e-05,
      "loss": 2.9588,
      "step": 53200
    },
    {
      "epoch": 2.289747783420849,
      "eval_bleu": 27.38520530065094,
      "eval_gen_len": 27.554,
      "eval_loss": 2.787731170654297,
      "eval_runtime": 58.1866,
      "eval_samples_per_second": 17.186,
      "eval_steps_per_second": 1.083,
      "step": 53200
    },
    {
      "epoch": 2.290178187139537,
      "grad_norm": 0.8429442048072815,
      "learning_rate": 2.7956721736846748e-05,
      "loss": 2.9952,
      "step": 53210
    },
    {
      "epoch": 2.290608590858225,
      "grad_norm": 1.0298328399658203,
      "learning_rate": 2.7924503922858935e-05,
      "loss": 3.0215,
      "step": 53220
    },
    {
      "epoch": 2.291038994576913,
      "grad_norm": 0.861932098865509,
      "learning_rate": 2.78923016708745e-05,
      "loss": 2.9639,
      "step": 53230
    },
    {
      "epoch": 2.291469398295601,
      "grad_norm": 0.9435716867446899,
      "learning_rate": 2.7860114987846363e-05,
      "loss": 2.928,
      "step": 53240
    },
    {
      "epoch": 2.2918998020142896,
      "grad_norm": 1.043177604675293,
      "learning_rate": 2.7827943880724017e-05,
      "loss": 3.0322,
      "step": 53250
    },
    {
      "epoch": 2.2918998020142896,
      "eval_bleu": 26.93565080191921,
      "eval_gen_len": 27.477,
      "eval_loss": 2.789212703704834,
      "eval_runtime": 57.8167,
      "eval_samples_per_second": 17.296,
      "eval_steps_per_second": 1.09,
      "step": 53250
    },
    {
      "epoch": 2.2923302057329775,
      "grad_norm": 0.8978514671325684,
      "learning_rate": 2.7795788356453554e-05,
      "loss": 2.9633,
      "step": 53260
    },
    {
      "epoch": 2.2927606094516655,
      "grad_norm": 0.8000063300132751,
      "learning_rate": 2.776364842197784e-05,
      "loss": 2.9504,
      "step": 53270
    },
    {
      "epoch": 2.293191013170354,
      "grad_norm": 0.939347505569458,
      "learning_rate": 2.7731524084236203e-05,
      "loss": 2.9863,
      "step": 53280
    },
    {
      "epoch": 2.293621416889042,
      "grad_norm": 0.9007366895675659,
      "learning_rate": 2.769941535016477e-05,
      "loss": 2.9492,
      "step": 53290
    },
    {
      "epoch": 2.29405182060773,
      "grad_norm": 0.9672139883041382,
      "learning_rate": 2.7667322226696156e-05,
      "loss": 2.9235,
      "step": 53300
    },
    {
      "epoch": 2.29405182060773,
      "eval_bleu": 26.994686849835666,
      "eval_gen_len": 27.445,
      "eval_loss": 2.7890613079071045,
      "eval_runtime": 57.6949,
      "eval_samples_per_second": 17.333,
      "eval_steps_per_second": 1.092,
      "step": 53300
    },
    {
      "epoch": 2.2944822243264182,
      "grad_norm": 0.9864469170570374,
      "learning_rate": 2.7635244720759725e-05,
      "loss": 3.0166,
      "step": 53310
    },
    {
      "epoch": 2.294912628045106,
      "grad_norm": 1.0532305240631104,
      "learning_rate": 2.7603182839281384e-05,
      "loss": 3.0122,
      "step": 53320
    },
    {
      "epoch": 2.2953430317637946,
      "grad_norm": 0.9314954280853271,
      "learning_rate": 2.7571136589183666e-05,
      "loss": 2.9296,
      "step": 53330
    },
    {
      "epoch": 2.2957734354824826,
      "grad_norm": 0.9616863131523132,
      "learning_rate": 2.7539105977385825e-05,
      "loss": 2.9855,
      "step": 53340
    },
    {
      "epoch": 2.2962038392011705,
      "grad_norm": 0.9597480893135071,
      "learning_rate": 2.75070910108036e-05,
      "loss": 2.9538,
      "step": 53350
    },
    {
      "epoch": 2.2962038392011705,
      "eval_bleu": 27.2389908161902,
      "eval_gen_len": 27.498,
      "eval_loss": 2.788367986679077,
      "eval_runtime": 58.0586,
      "eval_samples_per_second": 17.224,
      "eval_steps_per_second": 1.085,
      "step": 53350
    },
    {
      "epoch": 2.296634242919859,
      "grad_norm": 0.9214043617248535,
      "learning_rate": 2.7475091696349485e-05,
      "loss": 3.0109,
      "step": 53360
    },
    {
      "epoch": 2.297064646638547,
      "grad_norm": 0.8191735744476318,
      "learning_rate": 2.7443108040932474e-05,
      "loss": 2.8979,
      "step": 53370
    },
    {
      "epoch": 2.2974950503572353,
      "grad_norm": 0.9332672953605652,
      "learning_rate": 2.7411140051458317e-05,
      "loss": 2.9806,
      "step": 53380
    },
    {
      "epoch": 2.2979254540759233,
      "grad_norm": 0.9256026148796082,
      "learning_rate": 2.7379187734829215e-05,
      "loss": 2.9743,
      "step": 53390
    },
    {
      "epoch": 2.2983558577946113,
      "grad_norm": 0.8628720045089722,
      "learning_rate": 2.7347251097944182e-05,
      "loss": 3.0494,
      "step": 53400
    },
    {
      "epoch": 2.2983558577946113,
      "eval_bleu": 27.20597637649402,
      "eval_gen_len": 27.557,
      "eval_loss": 2.7877490520477295,
      "eval_runtime": 58.2678,
      "eval_samples_per_second": 17.162,
      "eval_steps_per_second": 1.081,
      "step": 53400
    },
    {
      "epoch": 2.2987862615132997,
      "grad_norm": 0.8845728635787964,
      "learning_rate": 2.7315330147698614e-05,
      "loss": 3.0094,
      "step": 53410
    },
    {
      "epoch": 2.2992166652319876,
      "grad_norm": 0.8848641514778137,
      "learning_rate": 2.728342489098473e-05,
      "loss": 2.915,
      "step": 53420
    },
    {
      "epoch": 2.2996470689506756,
      "grad_norm": 0.9142904281616211,
      "learning_rate": 2.7251535334691226e-05,
      "loss": 2.9069,
      "step": 53430
    },
    {
      "epoch": 2.300077472669364,
      "grad_norm": 0.8990989327430725,
      "learning_rate": 2.7219661485703484e-05,
      "loss": 2.9305,
      "step": 53440
    },
    {
      "epoch": 2.300507876388052,
      "grad_norm": 1.0126755237579346,
      "learning_rate": 2.7187803350903486e-05,
      "loss": 2.9449,
      "step": 53450
    },
    {
      "epoch": 2.300507876388052,
      "eval_bleu": 27.202397176267674,
      "eval_gen_len": 27.471,
      "eval_loss": 2.7897822856903076,
      "eval_runtime": 57.646,
      "eval_samples_per_second": 17.347,
      "eval_steps_per_second": 1.093,
      "step": 53450
    },
    {
      "epoch": 2.30093828010674,
      "grad_norm": 0.8715804815292358,
      "learning_rate": 2.7155960937169754e-05,
      "loss": 2.9737,
      "step": 53460
    },
    {
      "epoch": 2.3013686838254284,
      "grad_norm": 0.8959105610847473,
      "learning_rate": 2.7124134251377518e-05,
      "loss": 3.0161,
      "step": 53470
    },
    {
      "epoch": 2.3017990875441163,
      "grad_norm": 0.9509896039962769,
      "learning_rate": 2.7092323300398535e-05,
      "loss": 3.029,
      "step": 53480
    },
    {
      "epoch": 2.3022294912628043,
      "grad_norm": 0.9902973771095276,
      "learning_rate": 2.7060528091101188e-05,
      "loss": 2.9562,
      "step": 53490
    },
    {
      "epoch": 2.3026598949814927,
      "grad_norm": 0.9509194493293762,
      "learning_rate": 2.7028748630350432e-05,
      "loss": 2.9304,
      "step": 53500
    },
    {
      "epoch": 2.3026598949814927,
      "eval_bleu": 27.211961511594918,
      "eval_gen_len": 27.539,
      "eval_loss": 2.787790298461914,
      "eval_runtime": 58.4867,
      "eval_samples_per_second": 17.098,
      "eval_steps_per_second": 1.077,
      "step": 53500
    },
    {
      "epoch": 2.3030902987001807,
      "grad_norm": 0.9119080305099487,
      "learning_rate": 2.6996984925007895e-05,
      "loss": 3.057,
      "step": 53510
    },
    {
      "epoch": 2.303520702418869,
      "grad_norm": 0.8656355738639832,
      "learning_rate": 2.696523698193172e-05,
      "loss": 3.0396,
      "step": 53520
    },
    {
      "epoch": 2.303951106137557,
      "grad_norm": 0.8328858613967896,
      "learning_rate": 2.6933504807976705e-05,
      "loss": 2.8854,
      "step": 53530
    },
    {
      "epoch": 2.304381509856245,
      "grad_norm": 0.9618801474571228,
      "learning_rate": 2.6901788409994268e-05,
      "loss": 2.9644,
      "step": 53540
    },
    {
      "epoch": 2.3048119135749334,
      "grad_norm": 0.9370063543319702,
      "learning_rate": 2.687008779483229e-05,
      "loss": 2.8925,
      "step": 53550
    },
    {
      "epoch": 2.3048119135749334,
      "eval_bleu": 27.324767520928482,
      "eval_gen_len": 27.464,
      "eval_loss": 2.789370059967041,
      "eval_runtime": 57.8819,
      "eval_samples_per_second": 17.277,
      "eval_steps_per_second": 1.088,
      "step": 53550
    },
    {
      "epoch": 2.3052423172936214,
      "grad_norm": 0.8790960907936096,
      "learning_rate": 2.683840296933544e-05,
      "loss": 3.0633,
      "step": 53560
    },
    {
      "epoch": 2.3056727210123094,
      "grad_norm": 0.8972577452659607,
      "learning_rate": 2.6806733940344752e-05,
      "loss": 2.9453,
      "step": 53570
    },
    {
      "epoch": 2.3061031247309978,
      "grad_norm": 0.8854223489761353,
      "learning_rate": 2.677508071469805e-05,
      "loss": 2.9256,
      "step": 53580
    },
    {
      "epoch": 2.3065335284496857,
      "grad_norm": 0.9182952046394348,
      "learning_rate": 2.6743443299229608e-05,
      "loss": 3.0248,
      "step": 53590
    },
    {
      "epoch": 2.306963932168374,
      "grad_norm": 1.03622305393219,
      "learning_rate": 2.67118217007704e-05,
      "loss": 3.0642,
      "step": 53600
    },
    {
      "epoch": 2.306963932168374,
      "eval_bleu": 27.144315395543202,
      "eval_gen_len": 27.46,
      "eval_loss": 2.788647174835205,
      "eval_runtime": 58.8462,
      "eval_samples_per_second": 16.993,
      "eval_steps_per_second": 1.071,
      "step": 53600
    },
    {
      "epoch": 2.307394335887062,
      "grad_norm": 0.8547855615615845,
      "learning_rate": 2.6680215926147854e-05,
      "loss": 3.0583,
      "step": 53610
    },
    {
      "epoch": 2.30782473960575,
      "grad_norm": 0.8749276399612427,
      "learning_rate": 2.6648625982186117e-05,
      "loss": 2.9031,
      "step": 53620
    },
    {
      "epoch": 2.3082551433244385,
      "grad_norm": 0.8038514852523804,
      "learning_rate": 2.66170518757058e-05,
      "loss": 2.9154,
      "step": 53630
    },
    {
      "epoch": 2.3086855470431265,
      "grad_norm": 1.058459997177124,
      "learning_rate": 2.6585493613524215e-05,
      "loss": 3.0272,
      "step": 53640
    },
    {
      "epoch": 2.3091159507618144,
      "grad_norm": 0.8069279193878174,
      "learning_rate": 2.655395120245514e-05,
      "loss": 3.0624,
      "step": 53650
    },
    {
      "epoch": 2.3091159507618144,
      "eval_bleu": 27.119606888160725,
      "eval_gen_len": 27.463,
      "eval_loss": 2.789116382598877,
      "eval_runtime": 58.1864,
      "eval_samples_per_second": 17.186,
      "eval_steps_per_second": 1.083,
      "step": 53650
    },
    {
      "epoch": 2.309546354480503,
      "grad_norm": 0.9597871899604797,
      "learning_rate": 2.6522424649308963e-05,
      "loss": 2.9951,
      "step": 53660
    },
    {
      "epoch": 2.309976758199191,
      "grad_norm": 0.8645319938659668,
      "learning_rate": 2.6490913960892705e-05,
      "loss": 2.9996,
      "step": 53670
    },
    {
      "epoch": 2.3104071619178788,
      "grad_norm": 0.9001694917678833,
      "learning_rate": 2.6459419144009877e-05,
      "loss": 2.9166,
      "step": 53680
    },
    {
      "epoch": 2.310837565636567,
      "grad_norm": 0.8435006141662598,
      "learning_rate": 2.6427940205460643e-05,
      "loss": 2.9248,
      "step": 53690
    },
    {
      "epoch": 2.311267969355255,
      "grad_norm": 0.8339128494262695,
      "learning_rate": 2.6396477152041666e-05,
      "loss": 2.9253,
      "step": 53700
    },
    {
      "epoch": 2.311267969355255,
      "eval_bleu": 27.403441646225144,
      "eval_gen_len": 27.452,
      "eval_loss": 2.788527250289917,
      "eval_runtime": 57.5708,
      "eval_samples_per_second": 17.37,
      "eval_steps_per_second": 1.094,
      "step": 53700
    },
    {
      "epoch": 2.3116983730739435,
      "grad_norm": 0.8691746592521667,
      "learning_rate": 2.6365029990546263e-05,
      "loss": 3.0235,
      "step": 53710
    },
    {
      "epoch": 2.3121287767926315,
      "grad_norm": 0.8923275470733643,
      "learning_rate": 2.633359872776423e-05,
      "loss": 2.8845,
      "step": 53720
    },
    {
      "epoch": 2.3125591805113195,
      "grad_norm": 0.9739824533462524,
      "learning_rate": 2.630218337048195e-05,
      "loss": 2.9767,
      "step": 53730
    },
    {
      "epoch": 2.312989584230008,
      "grad_norm": 0.8674196004867554,
      "learning_rate": 2.6270783925482455e-05,
      "loss": 2.9464,
      "step": 53740
    },
    {
      "epoch": 2.313419987948696,
      "grad_norm": 0.8584962487220764,
      "learning_rate": 2.6239400399545212e-05,
      "loss": 2.9066,
      "step": 53750
    },
    {
      "epoch": 2.313419987948696,
      "eval_bleu": 27.35712238970022,
      "eval_gen_len": 27.523,
      "eval_loss": 2.7890732288360596,
      "eval_runtime": 58.2877,
      "eval_samples_per_second": 17.156,
      "eval_steps_per_second": 1.081,
      "step": 53750
    },
    {
      "epoch": 2.313850391667384,
      "grad_norm": 0.9699152708053589,
      "learning_rate": 2.620803279944639e-05,
      "loss": 3.066,
      "step": 53760
    },
    {
      "epoch": 2.3142807953860722,
      "grad_norm": 0.9510143995285034,
      "learning_rate": 2.617668113195857e-05,
      "loss": 3.0008,
      "step": 53770
    },
    {
      "epoch": 2.31471119910476,
      "grad_norm": 0.833889901638031,
      "learning_rate": 2.614534540385105e-05,
      "loss": 3.0368,
      "step": 53780
    },
    {
      "epoch": 2.3151416028234486,
      "grad_norm": 0.8259021639823914,
      "learning_rate": 2.6114025621889526e-05,
      "loss": 2.9575,
      "step": 53790
    },
    {
      "epoch": 2.3155720065421366,
      "grad_norm": 0.8702719807624817,
      "learning_rate": 2.6082721792836406e-05,
      "loss": 2.9652,
      "step": 53800
    },
    {
      "epoch": 2.3155720065421366,
      "eval_bleu": 27.403414059928572,
      "eval_gen_len": 27.557,
      "eval_loss": 2.78830885887146,
      "eval_runtime": 57.908,
      "eval_samples_per_second": 17.269,
      "eval_steps_per_second": 1.088,
      "step": 53800
    },
    {
      "epoch": 2.3160024102608245,
      "grad_norm": 0.9958086013793945,
      "learning_rate": 2.605143392345054e-05,
      "loss": 3.0607,
      "step": 53810
    },
    {
      "epoch": 2.316432813979513,
      "grad_norm": 0.9331153631210327,
      "learning_rate": 2.602016202048736e-05,
      "loss": 2.9154,
      "step": 53820
    },
    {
      "epoch": 2.316863217698201,
      "grad_norm": 0.8818994760513306,
      "learning_rate": 2.5988906090698893e-05,
      "loss": 2.8887,
      "step": 53830
    },
    {
      "epoch": 2.317293621416889,
      "grad_norm": 0.8527992367744446,
      "learning_rate": 2.5957666140833648e-05,
      "loss": 2.9809,
      "step": 53840
    },
    {
      "epoch": 2.3177240251355773,
      "grad_norm": 0.9501069188117981,
      "learning_rate": 2.5926442177636766e-05,
      "loss": 3.0441,
      "step": 53850
    },
    {
      "epoch": 2.3177240251355773,
      "eval_bleu": 27.307988851276523,
      "eval_gen_len": 27.483,
      "eval_loss": 2.787778377532959,
      "eval_runtime": 58.4582,
      "eval_samples_per_second": 17.106,
      "eval_steps_per_second": 1.078,
      "step": 53850
    },
    {
      "epoch": 2.3181544288542653,
      "grad_norm": 0.8870229125022888,
      "learning_rate": 2.589523420784985e-05,
      "loss": 2.948,
      "step": 53860
    },
    {
      "epoch": 2.3185848325729532,
      "grad_norm": 1.0219966173171997,
      "learning_rate": 2.586404223821115e-05,
      "loss": 2.9515,
      "step": 53870
    },
    {
      "epoch": 2.3190152362916416,
      "grad_norm": 0.9786357283592224,
      "learning_rate": 2.5832866275455326e-05,
      "loss": 2.9811,
      "step": 53880
    },
    {
      "epoch": 2.3194456400103296,
      "grad_norm": 0.9005092978477478,
      "learning_rate": 2.5801706326313734e-05,
      "loss": 2.9391,
      "step": 53890
    },
    {
      "epoch": 2.319876043729018,
      "grad_norm": 0.9182144999504089,
      "learning_rate": 2.5770562397514164e-05,
      "loss": 2.9532,
      "step": 53900
    },
    {
      "epoch": 2.319876043729018,
      "eval_bleu": 27.19981438622351,
      "eval_gen_len": 27.469,
      "eval_loss": 2.7882094383239746,
      "eval_runtime": 58.1268,
      "eval_samples_per_second": 17.204,
      "eval_steps_per_second": 1.084,
      "step": 53900
    },
    {
      "epoch": 2.320306447447706,
      "grad_norm": 0.9380307197570801,
      "learning_rate": 2.5739434495780946e-05,
      "loss": 3.155,
      "step": 53910
    },
    {
      "epoch": 2.320736851166394,
      "grad_norm": 0.9780231714248657,
      "learning_rate": 2.5708322627835057e-05,
      "loss": 3.0525,
      "step": 53920
    },
    {
      "epoch": 2.3211672548850824,
      "grad_norm": 0.8628199100494385,
      "learning_rate": 2.567722680039386e-05,
      "loss": 2.9561,
      "step": 53930
    },
    {
      "epoch": 2.3215976586037703,
      "grad_norm": 0.8574657440185547,
      "learning_rate": 2.564614702017142e-05,
      "loss": 2.9633,
      "step": 53940
    },
    {
      "epoch": 2.3220280623224583,
      "grad_norm": 0.9321266412734985,
      "learning_rate": 2.561508329387816e-05,
      "loss": 2.9141,
      "step": 53950
    },
    {
      "epoch": 2.3220280623224583,
      "eval_bleu": 27.33589888527533,
      "eval_gen_len": 27.474,
      "eval_loss": 2.789703607559204,
      "eval_runtime": 58.1484,
      "eval_samples_per_second": 17.197,
      "eval_steps_per_second": 1.083,
      "step": 53950
    },
    {
      "epoch": 2.3224584660411467,
      "grad_norm": 0.9313643574714661,
      "learning_rate": 2.5584035628221213e-05,
      "loss": 2.9645,
      "step": 53960
    },
    {
      "epoch": 2.3228888697598347,
      "grad_norm": 0.8933417201042175,
      "learning_rate": 2.5553004029904127e-05,
      "loss": 2.9401,
      "step": 53970
    },
    {
      "epoch": 2.323319273478523,
      "grad_norm": 0.8941711187362671,
      "learning_rate": 2.552198850562697e-05,
      "loss": 2.9855,
      "step": 53980
    },
    {
      "epoch": 2.323749677197211,
      "grad_norm": 0.8468731045722961,
      "learning_rate": 2.5490989062086445e-05,
      "loss": 2.8659,
      "step": 53990
    },
    {
      "epoch": 2.324180080915899,
      "grad_norm": 1.0657994747161865,
      "learning_rate": 2.5460005705975677e-05,
      "loss": 3.0508,
      "step": 54000
    },
    {
      "epoch": 2.324180080915899,
      "eval_bleu": 27.30066134553607,
      "eval_gen_len": 27.525,
      "eval_loss": 2.788614511489868,
      "eval_runtime": 58.7778,
      "eval_samples_per_second": 17.013,
      "eval_steps_per_second": 1.072,
      "step": 54000
    },
    {
      "epoch": 2.3246104846345874,
      "grad_norm": 0.9594866037368774,
      "learning_rate": 2.54290384439844e-05,
      "loss": 2.9816,
      "step": 54010
    },
    {
      "epoch": 2.3250408883532754,
      "grad_norm": 0.9773968458175659,
      "learning_rate": 2.539808728279879e-05,
      "loss": 2.9047,
      "step": 54020
    },
    {
      "epoch": 2.3254712920719633,
      "grad_norm": 1.0604578256607056,
      "learning_rate": 2.536715222910164e-05,
      "loss": 2.9505,
      "step": 54030
    },
    {
      "epoch": 2.3259016957906518,
      "grad_norm": 0.8419232368469238,
      "learning_rate": 2.5336233289572165e-05,
      "loss": 2.913,
      "step": 54040
    },
    {
      "epoch": 2.3263320995093397,
      "grad_norm": 0.8969664573669434,
      "learning_rate": 2.5305330470886234e-05,
      "loss": 2.8982,
      "step": 54050
    },
    {
      "epoch": 2.3263320995093397,
      "eval_bleu": 27.233264091666648,
      "eval_gen_len": 27.534,
      "eval_loss": 2.787625312805176,
      "eval_runtime": 58.3723,
      "eval_samples_per_second": 17.131,
      "eval_steps_per_second": 1.079,
      "step": 54050
    },
    {
      "epoch": 2.3267625032280277,
      "grad_norm": 0.8396199345588684,
      "learning_rate": 2.5274443779716038e-05,
      "loss": 2.9665,
      "step": 54060
    },
    {
      "epoch": 2.327192906946716,
      "grad_norm": 0.8876233696937561,
      "learning_rate": 2.5243573222730454e-05,
      "loss": 2.9282,
      "step": 54070
    },
    {
      "epoch": 2.327623310665404,
      "grad_norm": 1.0034161806106567,
      "learning_rate": 2.521271880659486e-05,
      "loss": 2.9725,
      "step": 54080
    },
    {
      "epoch": 2.328053714384092,
      "grad_norm": 0.9981207847595215,
      "learning_rate": 2.5181880537971057e-05,
      "loss": 2.9524,
      "step": 54090
    },
    {
      "epoch": 2.3284841181027804,
      "grad_norm": 0.8303143978118896,
      "learning_rate": 2.515105842351746e-05,
      "loss": 2.9493,
      "step": 54100
    },
    {
      "epoch": 2.3284841181027804,
      "eval_bleu": 27.384929776388464,
      "eval_gen_len": 27.525,
      "eval_loss": 2.787295341491699,
      "eval_runtime": 58.2119,
      "eval_samples_per_second": 17.179,
      "eval_steps_per_second": 1.082,
      "step": 54100
    },
    {
      "epoch": 2.3289145218214684,
      "grad_norm": 0.9639162421226501,
      "learning_rate": 2.5120252469888894e-05,
      "loss": 3.0356,
      "step": 54110
    },
    {
      "epoch": 2.329344925540157,
      "grad_norm": 0.9079220294952393,
      "learning_rate": 2.508946268373682e-05,
      "loss": 2.8939,
      "step": 54120
    },
    {
      "epoch": 2.329775329258845,
      "grad_norm": 0.9186530113220215,
      "learning_rate": 2.5058689071709085e-05,
      "loss": 2.9293,
      "step": 54130
    },
    {
      "epoch": 2.3302057329775328,
      "grad_norm": 0.9420446157455444,
      "learning_rate": 2.5027931640450132e-05,
      "loss": 3.0607,
      "step": 54140
    },
    {
      "epoch": 2.330636136696221,
      "grad_norm": 0.9177377820014954,
      "learning_rate": 2.4997190396600824e-05,
      "loss": 2.9516,
      "step": 54150
    },
    {
      "epoch": 2.330636136696221,
      "eval_bleu": 27.335331074480163,
      "eval_gen_len": 27.571,
      "eval_loss": 2.788015127182007,
      "eval_runtime": 58.2275,
      "eval_samples_per_second": 17.174,
      "eval_steps_per_second": 1.082,
      "step": 54150
    },
    {
      "epoch": 2.331066540414909,
      "grad_norm": 0.7873328924179077,
      "learning_rate": 2.4966465346798606e-05,
      "loss": 2.9312,
      "step": 54160
    },
    {
      "epoch": 2.3314969441335975,
      "grad_norm": 0.8335928320884705,
      "learning_rate": 2.4935756497677453e-05,
      "loss": 2.9107,
      "step": 54170
    },
    {
      "epoch": 2.3319273478522855,
      "grad_norm": 0.9901410341262817,
      "learning_rate": 2.4905063855867706e-05,
      "loss": 2.9559,
      "step": 54180
    },
    {
      "epoch": 2.3323577515709735,
      "grad_norm": 0.9928611516952515,
      "learning_rate": 2.487438742799637e-05,
      "loss": 3.018,
      "step": 54190
    },
    {
      "epoch": 2.332788155289662,
      "grad_norm": 0.9026943445205688,
      "learning_rate": 2.484372722068681e-05,
      "loss": 3.0729,
      "step": 54200
    },
    {
      "epoch": 2.332788155289662,
      "eval_bleu": 27.188166360876366,
      "eval_gen_len": 27.493,
      "eval_loss": 2.787468671798706,
      "eval_runtime": 58.2068,
      "eval_samples_per_second": 17.18,
      "eval_steps_per_second": 1.082,
      "step": 54200
    },
    {
      "epoch": 2.33321855900835,
      "grad_norm": 1.0445094108581543,
      "learning_rate": 2.4813083240559022e-05,
      "loss": 2.9077,
      "step": 54210
    },
    {
      "epoch": 2.333648962727038,
      "grad_norm": 0.8040622472763062,
      "learning_rate": 2.4782455494229327e-05,
      "loss": 2.8981,
      "step": 54220
    },
    {
      "epoch": 2.3340793664457262,
      "grad_norm": 0.9230813980102539,
      "learning_rate": 2.4751843988310718e-05,
      "loss": 2.9907,
      "step": 54230
    },
    {
      "epoch": 2.334509770164414,
      "grad_norm": 0.9597361087799072,
      "learning_rate": 2.4721248729412537e-05,
      "loss": 2.937,
      "step": 54240
    },
    {
      "epoch": 2.334940173883102,
      "grad_norm": 0.9470760226249695,
      "learning_rate": 2.4690669724140758e-05,
      "loss": 2.986,
      "step": 54250
    },
    {
      "epoch": 2.334940173883102,
      "eval_bleu": 27.404634693339123,
      "eval_gen_len": 27.517,
      "eval_loss": 2.7865991592407227,
      "eval_runtime": 58.4176,
      "eval_samples_per_second": 17.118,
      "eval_steps_per_second": 1.078,
      "step": 54250
    },
    {
      "epoch": 2.3353705776017906,
      "grad_norm": 0.8904744982719421,
      "learning_rate": 2.4660106979097707e-05,
      "loss": 2.893,
      "step": 54260
    },
    {
      "epoch": 2.3358009813204785,
      "grad_norm": 0.92337566614151,
      "learning_rate": 2.4629560500882287e-05,
      "loss": 3.0368,
      "step": 54270
    },
    {
      "epoch": 2.3362313850391665,
      "grad_norm": 0.9689658284187317,
      "learning_rate": 2.45990302960899e-05,
      "loss": 3.0682,
      "step": 54280
    },
    {
      "epoch": 2.336661788757855,
      "grad_norm": 0.9781065583229065,
      "learning_rate": 2.4568516371312377e-05,
      "loss": 2.9081,
      "step": 54290
    },
    {
      "epoch": 2.337092192476543,
      "grad_norm": 1.0397611856460571,
      "learning_rate": 2.4538018733138045e-05,
      "loss": 3.0133,
      "step": 54300
    },
    {
      "epoch": 2.337092192476543,
      "eval_bleu": 27.132184266931386,
      "eval_gen_len": 27.495,
      "eval_loss": 2.788363456726074,
      "eval_runtime": 58.5826,
      "eval_samples_per_second": 17.07,
      "eval_steps_per_second": 1.075,
      "step": 54300
    },
    {
      "epoch": 2.3375225961952313,
      "grad_norm": 0.8275268077850342,
      "learning_rate": 2.4507537388151703e-05,
      "loss": 2.8973,
      "step": 54310
    },
    {
      "epoch": 2.3379529999139192,
      "grad_norm": 0.8930360674858093,
      "learning_rate": 2.4477072342934716e-05,
      "loss": 2.8894,
      "step": 54320
    },
    {
      "epoch": 2.338383403632607,
      "grad_norm": 0.9576632976531982,
      "learning_rate": 2.4446623604064813e-05,
      "loss": 2.9173,
      "step": 54330
    },
    {
      "epoch": 2.3388138073512956,
      "grad_norm": 0.9175246953964233,
      "learning_rate": 2.4416191178116298e-05,
      "loss": 2.9032,
      "step": 54340
    },
    {
      "epoch": 2.3392442110699836,
      "grad_norm": 1.0432130098342896,
      "learning_rate": 2.438577507165989e-05,
      "loss": 3.0178,
      "step": 54350
    },
    {
      "epoch": 2.3392442110699836,
      "eval_bleu": 27.153422407200114,
      "eval_gen_len": 27.489,
      "eval_loss": 2.7878258228302,
      "eval_runtime": 58.2898,
      "eval_samples_per_second": 17.156,
      "eval_steps_per_second": 1.081,
      "step": 54350
    },
    {
      "epoch": 2.339674614788672,
      "grad_norm": 0.8826568722724915,
      "learning_rate": 2.4355375291262805e-05,
      "loss": 2.9421,
      "step": 54360
    },
    {
      "epoch": 2.34010501850736,
      "grad_norm": 0.9590480923652649,
      "learning_rate": 2.432499184348881e-05,
      "loss": 3.024,
      "step": 54370
    },
    {
      "epoch": 2.340535422226048,
      "grad_norm": 0.8590612411499023,
      "learning_rate": 2.4294624734897954e-05,
      "loss": 2.958,
      "step": 54380
    },
    {
      "epoch": 2.3409658259447363,
      "grad_norm": 0.9814832210540771,
      "learning_rate": 2.4264273972046957e-05,
      "loss": 2.9337,
      "step": 54390
    },
    {
      "epoch": 2.3413962296634243,
      "grad_norm": 1.0937557220458984,
      "learning_rate": 2.4233939561488883e-05,
      "loss": 2.9428,
      "step": 54400
    },
    {
      "epoch": 2.3413962296634243,
      "eval_bleu": 27.11175310533959,
      "eval_gen_len": 27.547,
      "eval_loss": 2.7888457775115967,
      "eval_runtime": 58.7353,
      "eval_samples_per_second": 17.026,
      "eval_steps_per_second": 1.073,
      "step": 54400
    },
    {
      "epoch": 2.3418266333821123,
      "grad_norm": 0.9115272760391235,
      "learning_rate": 2.4203621509773356e-05,
      "loss": 2.9919,
      "step": 54410
    },
    {
      "epoch": 2.3422570371008007,
      "grad_norm": 0.9197360873222351,
      "learning_rate": 2.4173319823446383e-05,
      "loss": 2.993,
      "step": 54420
    },
    {
      "epoch": 2.3426874408194887,
      "grad_norm": 0.9600892663002014,
      "learning_rate": 2.414303450905052e-05,
      "loss": 2.9717,
      "step": 54430
    },
    {
      "epoch": 2.3431178445381766,
      "grad_norm": 0.8385944962501526,
      "learning_rate": 2.4112765573124696e-05,
      "loss": 2.9025,
      "step": 54440
    },
    {
      "epoch": 2.343548248256865,
      "grad_norm": 0.8841109275817871,
      "learning_rate": 2.408251302220441e-05,
      "loss": 2.9321,
      "step": 54450
    },
    {
      "epoch": 2.343548248256865,
      "eval_bleu": 27.0997079230201,
      "eval_gen_len": 27.502,
      "eval_loss": 2.7893636226654053,
      "eval_runtime": 58.3182,
      "eval_samples_per_second": 17.147,
      "eval_steps_per_second": 1.08,
      "step": 54450
    },
    {
      "epoch": 2.343978651975553,
      "grad_norm": 0.7810126543045044,
      "learning_rate": 2.405227686282153e-05,
      "loss": 2.9358,
      "step": 54460
    },
    {
      "epoch": 2.344409055694241,
      "grad_norm": 0.9837932586669922,
      "learning_rate": 2.4022057101504414e-05,
      "loss": 3.1234,
      "step": 54470
    },
    {
      "epoch": 2.3448394594129294,
      "grad_norm": 0.9020376801490784,
      "learning_rate": 2.3991853744777925e-05,
      "loss": 2.95,
      "step": 54480
    },
    {
      "epoch": 2.3452698631316173,
      "grad_norm": 0.9334637522697449,
      "learning_rate": 2.3961666799163295e-05,
      "loss": 3.0277,
      "step": 54490
    },
    {
      "epoch": 2.3457002668503057,
      "grad_norm": 0.8014504313468933,
      "learning_rate": 2.3931496271178332e-05,
      "loss": 3.0077,
      "step": 54500
    },
    {
      "epoch": 2.3457002668503057,
      "eval_bleu": 27.161378913670635,
      "eval_gen_len": 27.462,
      "eval_loss": 2.790117025375366,
      "eval_runtime": 58.6265,
      "eval_samples_per_second": 17.057,
      "eval_steps_per_second": 1.075,
      "step": 54500
    },
    {
      "epoch": 2.3461306705689937,
      "grad_norm": 0.9609277844429016,
      "learning_rate": 2.390134216733716e-05,
      "loss": 2.9872,
      "step": 54510
    },
    {
      "epoch": 2.3465610742876817,
      "grad_norm": 0.9313544631004333,
      "learning_rate": 2.387120449415049e-05,
      "loss": 3.0505,
      "step": 54520
    },
    {
      "epoch": 2.34699147800637,
      "grad_norm": 0.9320422410964966,
      "learning_rate": 2.3841083258125364e-05,
      "loss": 2.9962,
      "step": 54530
    },
    {
      "epoch": 2.347421881725058,
      "grad_norm": 0.915703535079956,
      "learning_rate": 2.38109784657654e-05,
      "loss": 3.007,
      "step": 54540
    },
    {
      "epoch": 2.3478522854437465,
      "grad_norm": 1.0751177072525024,
      "learning_rate": 2.3780890123570554e-05,
      "loss": 3.0134,
      "step": 54550
    },
    {
      "epoch": 2.3478522854437465,
      "eval_bleu": 27.280494771652474,
      "eval_gen_len": 27.519,
      "eval_loss": 2.789121150970459,
      "eval_runtime": 58.9059,
      "eval_samples_per_second": 16.976,
      "eval_steps_per_second": 1.07,
      "step": 54550
    },
    {
      "epoch": 2.3482826891624344,
      "grad_norm": 1.0469719171524048,
      "learning_rate": 2.3750818238037263e-05,
      "loss": 3.0246,
      "step": 54560
    },
    {
      "epoch": 2.3487130928811224,
      "grad_norm": 0.8987055420875549,
      "learning_rate": 2.3720762815658492e-05,
      "loss": 2.9901,
      "step": 54570
    },
    {
      "epoch": 2.349143496599811,
      "grad_norm": 0.8819283843040466,
      "learning_rate": 2.3690723862923502e-05,
      "loss": 2.915,
      "step": 54580
    },
    {
      "epoch": 2.3495739003184988,
      "grad_norm": 1.0512346029281616,
      "learning_rate": 2.366070138631814e-05,
      "loss": 3.0161,
      "step": 54590
    },
    {
      "epoch": 2.3500043040371867,
      "grad_norm": 0.919407069683075,
      "learning_rate": 2.3630695392324597e-05,
      "loss": 2.9821,
      "step": 54600
    },
    {
      "epoch": 2.3500043040371867,
      "eval_bleu": 27.289857816334766,
      "eval_gen_len": 27.469,
      "eval_loss": 2.7886435985565186,
      "eval_runtime": 58.3851,
      "eval_samples_per_second": 17.128,
      "eval_steps_per_second": 1.079,
      "step": 54600
    },
    {
      "epoch": 2.350434707755875,
      "grad_norm": 1.027955412864685,
      "learning_rate": 2.3600705887421582e-05,
      "loss": 3.0146,
      "step": 54610
    },
    {
      "epoch": 2.350865111474563,
      "grad_norm": 0.9714906811714172,
      "learning_rate": 2.357073287808419e-05,
      "loss": 2.9506,
      "step": 54620
    },
    {
      "epoch": 2.351295515193251,
      "grad_norm": 0.8866518139839172,
      "learning_rate": 2.3540776370783924e-05,
      "loss": 3.009,
      "step": 54630
    },
    {
      "epoch": 2.3517259189119395,
      "grad_norm": 0.8572887778282166,
      "learning_rate": 2.351083637198884e-05,
      "loss": 2.9746,
      "step": 54640
    },
    {
      "epoch": 2.3521563226306275,
      "grad_norm": 0.9408376216888428,
      "learning_rate": 2.348091288816331e-05,
      "loss": 2.9941,
      "step": 54650
    },
    {
      "epoch": 2.3521563226306275,
      "eval_bleu": 27.24395768460005,
      "eval_gen_len": 27.417,
      "eval_loss": 2.7879843711853027,
      "eval_runtime": 57.8547,
      "eval_samples_per_second": 17.285,
      "eval_steps_per_second": 1.089,
      "step": 54650
    },
    {
      "epoch": 2.3525867263493154,
      "grad_norm": 0.8991411328315735,
      "learning_rate": 2.345100592576822e-05,
      "loss": 2.916,
      "step": 54660
    },
    {
      "epoch": 2.353017130068004,
      "grad_norm": 0.8782981634140015,
      "learning_rate": 2.3421115491260827e-05,
      "loss": 3.0348,
      "step": 54670
    },
    {
      "epoch": 2.353447533786692,
      "grad_norm": 0.8560718297958374,
      "learning_rate": 2.339124159109489e-05,
      "loss": 2.9678,
      "step": 54680
    },
    {
      "epoch": 2.35387793750538,
      "grad_norm": 0.9523227214813232,
      "learning_rate": 2.336138423172052e-05,
      "loss": 3.0061,
      "step": 54690
    },
    {
      "epoch": 2.354308341224068,
      "grad_norm": 0.882994532585144,
      "learning_rate": 2.3331543419584333e-05,
      "loss": 2.9502,
      "step": 54700
    },
    {
      "epoch": 2.354308341224068,
      "eval_bleu": 27.244074071418154,
      "eval_gen_len": 27.472,
      "eval_loss": 2.7869184017181396,
      "eval_runtime": 57.9701,
      "eval_samples_per_second": 17.25,
      "eval_steps_per_second": 1.087,
      "step": 54700
    },
    {
      "epoch": 2.354738744942756,
      "grad_norm": 0.9616785049438477,
      "learning_rate": 2.3301719161129322e-05,
      "loss": 2.9303,
      "step": 54710
    },
    {
      "epoch": 2.3551691486614446,
      "grad_norm": 1.0389386415481567,
      "learning_rate": 2.3271911462794872e-05,
      "loss": 3.0477,
      "step": 54720
    },
    {
      "epoch": 2.3555995523801325,
      "grad_norm": 0.9175524711608887,
      "learning_rate": 2.32421203310169e-05,
      "loss": 2.959,
      "step": 54730
    },
    {
      "epoch": 2.356029956098821,
      "grad_norm": 0.8339983224868774,
      "learning_rate": 2.321234577222765e-05,
      "loss": 2.9578,
      "step": 54740
    },
    {
      "epoch": 2.356460359817509,
      "grad_norm": 0.9533805847167969,
      "learning_rate": 2.3182587792855858e-05,
      "loss": 3.0879,
      "step": 54750
    },
    {
      "epoch": 2.356460359817509,
      "eval_bleu": 27.137602709892708,
      "eval_gen_len": 27.531,
      "eval_loss": 2.7872533798217773,
      "eval_runtime": 57.6808,
      "eval_samples_per_second": 17.337,
      "eval_steps_per_second": 1.092,
      "step": 54750
    },
    {
      "epoch": 2.356890763536197,
      "grad_norm": 0.9071762561798096,
      "learning_rate": 2.315284639932659e-05,
      "loss": 2.9738,
      "step": 54760
    },
    {
      "epoch": 2.3573211672548853,
      "grad_norm": 0.8881277441978455,
      "learning_rate": 2.312312159806145e-05,
      "loss": 2.8909,
      "step": 54770
    },
    {
      "epoch": 2.3577515709735732,
      "grad_norm": 0.9406686425209045,
      "learning_rate": 2.309341339547836e-05,
      "loss": 2.9773,
      "step": 54780
    },
    {
      "epoch": 2.358181974692261,
      "grad_norm": 0.9605703353881836,
      "learning_rate": 2.3063721797991666e-05,
      "loss": 3.036,
      "step": 54790
    },
    {
      "epoch": 2.3586123784109496,
      "grad_norm": 0.9396501183509827,
      "learning_rate": 2.3034046812012224e-05,
      "loss": 2.9431,
      "step": 54800
    },
    {
      "epoch": 2.3586123784109496,
      "eval_bleu": 27.192392310095318,
      "eval_gen_len": 27.511,
      "eval_loss": 2.7878074645996094,
      "eval_runtime": 58.0745,
      "eval_samples_per_second": 17.219,
      "eval_steps_per_second": 1.085,
      "step": 54800
    },
    {
      "epoch": 2.3590427821296376,
      "grad_norm": 0.9819192290306091,
      "learning_rate": 2.3004388443947166e-05,
      "loss": 2.9059,
      "step": 54810
    },
    {
      "epoch": 2.3594731858483255,
      "grad_norm": 0.9498850107192993,
      "learning_rate": 2.2974746700200167e-05,
      "loss": 3.0093,
      "step": 54820
    },
    {
      "epoch": 2.359903589567014,
      "grad_norm": 0.9129767417907715,
      "learning_rate": 2.294512158717118e-05,
      "loss": 3.0107,
      "step": 54830
    },
    {
      "epoch": 2.360333993285702,
      "grad_norm": 0.8395349979400635,
      "learning_rate": 2.2915513111256727e-05,
      "loss": 2.9912,
      "step": 54840
    },
    {
      "epoch": 2.36076439700439,
      "grad_norm": 0.9485301375389099,
      "learning_rate": 2.2885921278849563e-05,
      "loss": 2.9942,
      "step": 54850
    },
    {
      "epoch": 2.36076439700439,
      "eval_bleu": 27.306874830213072,
      "eval_gen_len": 27.478,
      "eval_loss": 2.786919593811035,
      "eval_runtime": 58.0589,
      "eval_samples_per_second": 17.224,
      "eval_steps_per_second": 1.085,
      "step": 54850
    },
    {
      "epoch": 2.3611948007230783,
      "grad_norm": 1.3580809831619263,
      "learning_rate": 2.2856346096339043e-05,
      "loss": 2.9832,
      "step": 54860
    },
    {
      "epoch": 2.3616252044417663,
      "grad_norm": 0.8883218169212341,
      "learning_rate": 2.2826787570110684e-05,
      "loss": 2.9258,
      "step": 54870
    },
    {
      "epoch": 2.3620556081604547,
      "grad_norm": 0.9427041411399841,
      "learning_rate": 2.2797245706546643e-05,
      "loss": 2.9392,
      "step": 54880
    },
    {
      "epoch": 2.3624860118791426,
      "grad_norm": 0.8915372490882874,
      "learning_rate": 2.2767720512025325e-05,
      "loss": 2.9419,
      "step": 54890
    },
    {
      "epoch": 2.3629164155978306,
      "grad_norm": 0.8732487559318542,
      "learning_rate": 2.2738211992921598e-05,
      "loss": 2.9539,
      "step": 54900
    },
    {
      "epoch": 2.3629164155978306,
      "eval_bleu": 27.14484571281323,
      "eval_gen_len": 27.538,
      "eval_loss": 2.788508892059326,
      "eval_runtime": 58.1733,
      "eval_samples_per_second": 17.19,
      "eval_steps_per_second": 1.083,
      "step": 54900
    },
    {
      "epoch": 2.363346819316519,
      "grad_norm": 0.8732680082321167,
      "learning_rate": 2.270872015560678e-05,
      "loss": 2.9532,
      "step": 54910
    },
    {
      "epoch": 2.363777223035207,
      "grad_norm": 0.8782287240028381,
      "learning_rate": 2.2679245006448436e-05,
      "loss": 2.9847,
      "step": 54920
    },
    {
      "epoch": 2.3642076267538954,
      "grad_norm": 0.8385989665985107,
      "learning_rate": 2.2649786551810702e-05,
      "loss": 3.0234,
      "step": 54930
    },
    {
      "epoch": 2.3646380304725834,
      "grad_norm": 0.951073408126831,
      "learning_rate": 2.2620344798053993e-05,
      "loss": 3.0116,
      "step": 54940
    },
    {
      "epoch": 2.3650684341912713,
      "grad_norm": 0.8454462885856628,
      "learning_rate": 2.2590919751535156e-05,
      "loss": 2.9418,
      "step": 54950
    },
    {
      "epoch": 2.3650684341912713,
      "eval_bleu": 27.165267960023577,
      "eval_gen_len": 27.52,
      "eval_loss": 2.788221836090088,
      "eval_runtime": 57.4918,
      "eval_samples_per_second": 17.394,
      "eval_steps_per_second": 1.096,
      "step": 54950
    },
    {
      "epoch": 2.3654988379099597,
      "grad_norm": 0.8992660641670227,
      "learning_rate": 2.2561511418607393e-05,
      "loss": 2.9332,
      "step": 54960
    },
    {
      "epoch": 2.3659292416286477,
      "grad_norm": 0.8381171226501465,
      "learning_rate": 2.25321198056204e-05,
      "loss": 2.936,
      "step": 54970
    },
    {
      "epoch": 2.3663596453473357,
      "grad_norm": 1.021262526512146,
      "learning_rate": 2.2502744918920116e-05,
      "loss": 3.0634,
      "step": 54980
    },
    {
      "epoch": 2.366790049066024,
      "grad_norm": 0.8917877078056335,
      "learning_rate": 2.2473386764849002e-05,
      "loss": 3.0637,
      "step": 54990
    },
    {
      "epoch": 2.367220452784712,
      "grad_norm": 0.9309072494506836,
      "learning_rate": 2.2444045349745857e-05,
      "loss": 3.0135,
      "step": 55000
    },
    {
      "epoch": 2.367220452784712,
      "eval_bleu": 27.23605423096774,
      "eval_gen_len": 27.521,
      "eval_loss": 2.787262439727783,
      "eval_runtime": 58.106,
      "eval_samples_per_second": 17.21,
      "eval_steps_per_second": 1.084,
      "step": 55000
    },
    {
      "epoch": 2.3676508565034,
      "grad_norm": 0.8425541520118713,
      "learning_rate": 2.241472067994582e-05,
      "loss": 2.8909,
      "step": 55010
    },
    {
      "epoch": 2.3680812602220884,
      "grad_norm": 1.0006283521652222,
      "learning_rate": 2.238541276178053e-05,
      "loss": 3.1022,
      "step": 55020
    },
    {
      "epoch": 2.3685116639407764,
      "grad_norm": 0.891425609588623,
      "learning_rate": 2.2356121601577827e-05,
      "loss": 2.9191,
      "step": 55030
    },
    {
      "epoch": 2.3689420676594644,
      "grad_norm": 0.9952686429023743,
      "learning_rate": 2.2326847205662117e-05,
      "loss": 3.0119,
      "step": 55040
    },
    {
      "epoch": 2.3693724713781528,
      "grad_norm": 0.9805334806442261,
      "learning_rate": 2.229758958035406e-05,
      "loss": 2.9517,
      "step": 55050
    },
    {
      "epoch": 2.3693724713781528,
      "eval_bleu": 27.15185696936309,
      "eval_gen_len": 27.503,
      "eval_loss": 2.7875545024871826,
      "eval_runtime": 58.0738,
      "eval_samples_per_second": 17.219,
      "eval_steps_per_second": 1.085,
      "step": 55050
    },
    {
      "epoch": 2.3698028750968407,
      "grad_norm": 0.8517253398895264,
      "learning_rate": 2.2268348731970812e-05,
      "loss": 2.9769,
      "step": 55060
    },
    {
      "epoch": 2.370233278815529,
      "grad_norm": 0.8560357093811035,
      "learning_rate": 2.223912466682575e-05,
      "loss": 2.9634,
      "step": 55070
    },
    {
      "epoch": 2.370663682534217,
      "grad_norm": 0.9200997352600098,
      "learning_rate": 2.2209917391228806e-05,
      "loss": 2.9114,
      "step": 55080
    },
    {
      "epoch": 2.371094086252905,
      "grad_norm": 0.8386624455451965,
      "learning_rate": 2.2180726911486117e-05,
      "loss": 2.9261,
      "step": 55090
    },
    {
      "epoch": 2.3715244899715935,
      "grad_norm": 0.9808794856071472,
      "learning_rate": 2.2151553233900323e-05,
      "loss": 3.0297,
      "step": 55100
    },
    {
      "epoch": 2.3715244899715935,
      "eval_bleu": 27.209254272785746,
      "eval_gen_len": 27.473,
      "eval_loss": 2.7877466678619385,
      "eval_runtime": 57.7212,
      "eval_samples_per_second": 17.325,
      "eval_steps_per_second": 1.091,
      "step": 55100
    },
    {
      "epoch": 2.3719548936902815,
      "grad_norm": 1.057160496711731,
      "learning_rate": 2.2122396364770415e-05,
      "loss": 2.984,
      "step": 55110
    },
    {
      "epoch": 2.37238529740897,
      "grad_norm": 0.8659718036651611,
      "learning_rate": 2.2093256310391643e-05,
      "loss": 2.9481,
      "step": 55120
    },
    {
      "epoch": 2.372815701127658,
      "grad_norm": 0.9229331612586975,
      "learning_rate": 2.206413307705577e-05,
      "loss": 2.9355,
      "step": 55130
    },
    {
      "epoch": 2.373246104846346,
      "grad_norm": 0.9810435175895691,
      "learning_rate": 2.203502667105084e-05,
      "loss": 2.9938,
      "step": 55140
    },
    {
      "epoch": 2.373676508565034,
      "grad_norm": 0.9336010813713074,
      "learning_rate": 2.2005937098661324e-05,
      "loss": 3.0664,
      "step": 55150
    },
    {
      "epoch": 2.373676508565034,
      "eval_bleu": 27.318775170410973,
      "eval_gen_len": 27.504,
      "eval_loss": 2.7875523567199707,
      "eval_runtime": 58.0464,
      "eval_samples_per_second": 17.228,
      "eval_steps_per_second": 1.085,
      "step": 55150
    },
    {
      "epoch": 2.374106912283722,
      "grad_norm": 0.8275631666183472,
      "learning_rate": 2.197686436616796e-05,
      "loss": 2.9638,
      "step": 55160
    },
    {
      "epoch": 2.37453731600241,
      "grad_norm": 0.9310397505760193,
      "learning_rate": 2.194780847984801e-05,
      "loss": 2.99,
      "step": 55170
    },
    {
      "epoch": 2.3749677197210985,
      "grad_norm": 0.9718078970909119,
      "learning_rate": 2.1918769445974908e-05,
      "loss": 3.0154,
      "step": 55180
    },
    {
      "epoch": 2.3753981234397865,
      "grad_norm": 0.8763561844825745,
      "learning_rate": 2.188974727081863e-05,
      "loss": 2.9466,
      "step": 55190
    },
    {
      "epoch": 2.3758285271584745,
      "grad_norm": 1.0205698013305664,
      "learning_rate": 2.1860741960645383e-05,
      "loss": 2.9493,
      "step": 55200
    },
    {
      "epoch": 2.3758285271584745,
      "eval_bleu": 27.142357220124815,
      "eval_gen_len": 27.521,
      "eval_loss": 2.7878174781799316,
      "eval_runtime": 58.2887,
      "eval_samples_per_second": 17.156,
      "eval_steps_per_second": 1.081,
      "step": 55200
    },
    {
      "epoch": 2.376258930877163,
      "grad_norm": 1.0091074705123901,
      "learning_rate": 2.1831753521717745e-05,
      "loss": 2.9122,
      "step": 55210
    },
    {
      "epoch": 2.376689334595851,
      "grad_norm": 0.9510037899017334,
      "learning_rate": 2.180278196029476e-05,
      "loss": 2.9547,
      "step": 55220
    },
    {
      "epoch": 2.377119738314539,
      "grad_norm": 0.8516696691513062,
      "learning_rate": 2.1773827282631688e-05,
      "loss": 2.8865,
      "step": 55230
    },
    {
      "epoch": 2.3775501420332272,
      "grad_norm": 0.8108578324317932,
      "learning_rate": 2.1744889494980246e-05,
      "loss": 2.983,
      "step": 55240
    },
    {
      "epoch": 2.377980545751915,
      "grad_norm": 0.8572219014167786,
      "learning_rate": 2.1715968603588434e-05,
      "loss": 2.9637,
      "step": 55250
    },
    {
      "epoch": 2.377980545751915,
      "eval_bleu": 27.11416940123876,
      "eval_gen_len": 27.507,
      "eval_loss": 2.788447856903076,
      "eval_runtime": 57.8791,
      "eval_samples_per_second": 17.277,
      "eval_steps_per_second": 1.088,
      "step": 55250
    },
    {
      "epoch": 2.3784109494706036,
      "grad_norm": 0.9573186635971069,
      "learning_rate": 2.168706461470068e-05,
      "loss": 2.928,
      "step": 55260
    },
    {
      "epoch": 2.3788413531892916,
      "grad_norm": 1.1092021465301514,
      "learning_rate": 2.1658177534557688e-05,
      "loss": 2.9683,
      "step": 55270
    },
    {
      "epoch": 2.3792717569079795,
      "grad_norm": 0.9645345211029053,
      "learning_rate": 2.1629307369396512e-05,
      "loss": 2.9562,
      "step": 55280
    },
    {
      "epoch": 2.379702160626668,
      "grad_norm": 0.999040961265564,
      "learning_rate": 2.1600454125450643e-05,
      "loss": 2.8865,
      "step": 55290
    },
    {
      "epoch": 2.380132564345356,
      "grad_norm": 0.9013964533805847,
      "learning_rate": 2.1571617808949795e-05,
      "loss": 2.9704,
      "step": 55300
    },
    {
      "epoch": 2.380132564345356,
      "eval_bleu": 27.230512229872843,
      "eval_gen_len": 27.45,
      "eval_loss": 2.7874367237091064,
      "eval_runtime": 57.7592,
      "eval_samples_per_second": 17.313,
      "eval_steps_per_second": 1.091,
      "step": 55300
    },
    {
      "epoch": 2.380562968064044,
      "grad_norm": 0.8196346759796143,
      "learning_rate": 2.154279842612015e-05,
      "loss": 3.0,
      "step": 55310
    },
    {
      "epoch": 2.3809933717827323,
      "grad_norm": 0.883415699005127,
      "learning_rate": 2.151399598318412e-05,
      "loss": 3.0133,
      "step": 55320
    },
    {
      "epoch": 2.3814237755014203,
      "grad_norm": 0.939175009727478,
      "learning_rate": 2.1485210486360575e-05,
      "loss": 3.0208,
      "step": 55330
    },
    {
      "epoch": 2.3818541792201087,
      "grad_norm": 0.9054791927337646,
      "learning_rate": 2.1456441941864603e-05,
      "loss": 2.9309,
      "step": 55340
    },
    {
      "epoch": 2.3822845829387966,
      "grad_norm": 0.9263373017311096,
      "learning_rate": 2.1427690355907748e-05,
      "loss": 3.0165,
      "step": 55350
    },
    {
      "epoch": 2.3822845829387966,
      "eval_bleu": 27.23467408465465,
      "eval_gen_len": 27.487,
      "eval_loss": 2.7866272926330566,
      "eval_runtime": 57.8085,
      "eval_samples_per_second": 17.299,
      "eval_steps_per_second": 1.09,
      "step": 55350
    },
    {
      "epoch": 2.3827149866574846,
      "grad_norm": 0.9675621390342712,
      "learning_rate": 2.139895573469781e-05,
      "loss": 2.9593,
      "step": 55360
    },
    {
      "epoch": 2.383145390376173,
      "grad_norm": 0.862409234046936,
      "learning_rate": 2.137023808443892e-05,
      "loss": 2.993,
      "step": 55370
    },
    {
      "epoch": 2.383575794094861,
      "grad_norm": 0.8570936918258667,
      "learning_rate": 2.1341537411331657e-05,
      "loss": 2.9621,
      "step": 55380
    },
    {
      "epoch": 2.384006197813549,
      "grad_norm": 0.8872924447059631,
      "learning_rate": 2.1312853721572777e-05,
      "loss": 2.9926,
      "step": 55390
    },
    {
      "epoch": 2.3844366015322374,
      "grad_norm": 0.955072283744812,
      "learning_rate": 2.1284187021355516e-05,
      "loss": 2.9977,
      "step": 55400
    },
    {
      "epoch": 2.3844366015322374,
      "eval_bleu": 27.141419264402078,
      "eval_gen_len": 27.438,
      "eval_loss": 2.786465883255005,
      "eval_runtime": 57.6997,
      "eval_samples_per_second": 17.331,
      "eval_steps_per_second": 1.092,
      "step": 55400
    },
    {
      "epoch": 2.3848670052509253,
      "grad_norm": 0.848445475101471,
      "learning_rate": 2.125553731686931e-05,
      "loss": 2.8676,
      "step": 55410
    },
    {
      "epoch": 2.3852974089696133,
      "grad_norm": 0.8640162348747253,
      "learning_rate": 2.1226904614300046e-05,
      "loss": 2.9678,
      "step": 55420
    },
    {
      "epoch": 2.3857278126883017,
      "grad_norm": 0.89780193567276,
      "learning_rate": 2.1198288919829866e-05,
      "loss": 2.9583,
      "step": 55430
    },
    {
      "epoch": 2.3861582164069897,
      "grad_norm": 0.972031831741333,
      "learning_rate": 2.116969023963723e-05,
      "loss": 2.9065,
      "step": 55440
    },
    {
      "epoch": 2.386588620125678,
      "grad_norm": 0.8216227889060974,
      "learning_rate": 2.1141108579896986e-05,
      "loss": 2.9893,
      "step": 55450
    },
    {
      "epoch": 2.386588620125678,
      "eval_bleu": 27.10225924147033,
      "eval_gen_len": 27.457,
      "eval_loss": 2.7867014408111572,
      "eval_runtime": 57.4772,
      "eval_samples_per_second": 17.398,
      "eval_steps_per_second": 1.096,
      "step": 55450
    },
    {
      "epoch": 2.387019023844366,
      "grad_norm": 0.9961886405944824,
      "learning_rate": 2.1112543946780237e-05,
      "loss": 2.9585,
      "step": 55460
    },
    {
      "epoch": 2.387449427563054,
      "grad_norm": 1.0211962461471558,
      "learning_rate": 2.1083996346454503e-05,
      "loss": 2.9515,
      "step": 55470
    },
    {
      "epoch": 2.3878798312817424,
      "grad_norm": 1.0960406064987183,
      "learning_rate": 2.1055465785083495e-05,
      "loss": 2.9634,
      "step": 55480
    },
    {
      "epoch": 2.3883102350004304,
      "grad_norm": 0.9851067662239075,
      "learning_rate": 2.1026952268827392e-05,
      "loss": 2.9617,
      "step": 55490
    },
    {
      "epoch": 2.3887406387191183,
      "grad_norm": 0.9265770316123962,
      "learning_rate": 2.0998455803842553e-05,
      "loss": 2.9311,
      "step": 55500
    },
    {
      "epoch": 2.3887406387191183,
      "eval_bleu": 27.39782320997716,
      "eval_gen_len": 27.436,
      "eval_loss": 2.7871205806732178,
      "eval_runtime": 57.6395,
      "eval_samples_per_second": 17.349,
      "eval_steps_per_second": 1.093,
      "step": 55500
    },
    {
      "epoch": 2.3891710424378068,
      "grad_norm": 0.9929105043411255,
      "learning_rate": 2.0969976396281822e-05,
      "loss": 2.9173,
      "step": 55510
    },
    {
      "epoch": 2.3896014461564947,
      "grad_norm": 0.8928699493408203,
      "learning_rate": 2.094151405229412e-05,
      "loss": 3.0296,
      "step": 55520
    },
    {
      "epoch": 2.390031849875183,
      "grad_norm": 0.9114801287651062,
      "learning_rate": 2.0913068778024913e-05,
      "loss": 3.0735,
      "step": 55530
    },
    {
      "epoch": 2.390462253593871,
      "grad_norm": 1.0602569580078125,
      "learning_rate": 2.0884640579615887e-05,
      "loss": 2.8881,
      "step": 55540
    },
    {
      "epoch": 2.390892657312559,
      "grad_norm": 1.0177971124649048,
      "learning_rate": 2.0856229463205024e-05,
      "loss": 3.0358,
      "step": 55550
    },
    {
      "epoch": 2.390892657312559,
      "eval_bleu": 27.084341965354024,
      "eval_gen_len": 27.434,
      "eval_loss": 2.787594795227051,
      "eval_runtime": 57.5534,
      "eval_samples_per_second": 17.375,
      "eval_steps_per_second": 1.095,
      "step": 55550
    },
    {
      "epoch": 2.3913230610312475,
      "grad_norm": 0.9521206021308899,
      "learning_rate": 2.0827835434926668e-05,
      "loss": 2.9611,
      "step": 55560
    },
    {
      "epoch": 2.3917534647499354,
      "grad_norm": 1.0186434984207153,
      "learning_rate": 2.0799458500911407e-05,
      "loss": 2.9262,
      "step": 55570
    },
    {
      "epoch": 2.3921838684686234,
      "grad_norm": 0.9910049438476562,
      "learning_rate": 2.0771098667286226e-05,
      "loss": 2.9412,
      "step": 55580
    },
    {
      "epoch": 2.392614272187312,
      "grad_norm": 0.9527150392532349,
      "learning_rate": 2.074275594017434e-05,
      "loss": 3.1061,
      "step": 55590
    },
    {
      "epoch": 2.393044675906,
      "grad_norm": 0.8560330271720886,
      "learning_rate": 2.07144303256953e-05,
      "loss": 2.9924,
      "step": 55600
    },
    {
      "epoch": 2.393044675906,
      "eval_bleu": 27.25378314730259,
      "eval_gen_len": 27.489,
      "eval_loss": 2.7863261699676514,
      "eval_runtime": 57.9932,
      "eval_samples_per_second": 17.243,
      "eval_steps_per_second": 1.086,
      "step": 55600
    },
    {
      "epoch": 2.3934750796246878,
      "grad_norm": 0.950370728969574,
      "learning_rate": 2.0686121829964945e-05,
      "loss": 3.064,
      "step": 55610
    },
    {
      "epoch": 2.393905483343376,
      "grad_norm": 0.8085895776748657,
      "learning_rate": 2.065783045909545e-05,
      "loss": 2.9209,
      "step": 55620
    },
    {
      "epoch": 2.394335887062064,
      "grad_norm": 0.8408846855163574,
      "learning_rate": 2.06295562191953e-05,
      "loss": 2.9345,
      "step": 55630
    },
    {
      "epoch": 2.3947662907807525,
      "grad_norm": 0.9444335699081421,
      "learning_rate": 2.060129911636921e-05,
      "loss": 2.9912,
      "step": 55640
    },
    {
      "epoch": 2.3951966944994405,
      "grad_norm": 0.947399377822876,
      "learning_rate": 2.05730591567183e-05,
      "loss": 3.0576,
      "step": 55650
    },
    {
      "epoch": 2.3951966944994405,
      "eval_bleu": 27.396444126579166,
      "eval_gen_len": 27.521,
      "eval_loss": 2.7857887744903564,
      "eval_runtime": 58.3925,
      "eval_samples_per_second": 17.125,
      "eval_steps_per_second": 1.079,
      "step": 55650
    },
    {
      "epoch": 2.3956270982181285,
      "grad_norm": 0.9727497696876526,
      "learning_rate": 2.0544836346339868e-05,
      "loss": 2.9708,
      "step": 55660
    },
    {
      "epoch": 2.396057501936817,
      "grad_norm": 0.957652747631073,
      "learning_rate": 2.0516630691327666e-05,
      "loss": 2.9355,
      "step": 55670
    },
    {
      "epoch": 2.396487905655505,
      "grad_norm": 1.0208966732025146,
      "learning_rate": 2.0488442197771527e-05,
      "loss": 2.9894,
      "step": 55680
    },
    {
      "epoch": 2.396918309374193,
      "grad_norm": 0.8953250050544739,
      "learning_rate": 2.046027087175779e-05,
      "loss": 2.9685,
      "step": 55690
    },
    {
      "epoch": 2.3973487130928812,
      "grad_norm": 0.9017301797866821,
      "learning_rate": 2.0432116719368955e-05,
      "loss": 2.9854,
      "step": 55700
    },
    {
      "epoch": 2.3973487130928812,
      "eval_bleu": 27.262158325769374,
      "eval_gen_len": 27.458,
      "eval_loss": 2.78646183013916,
      "eval_runtime": 58.4018,
      "eval_samples_per_second": 17.123,
      "eval_steps_per_second": 1.079,
      "step": 55700
    },
    {
      "epoch": 2.397779116811569,
      "grad_norm": 0.9085039496421814,
      "learning_rate": 2.040397974668389e-05,
      "loss": 2.9485,
      "step": 55710
    },
    {
      "epoch": 2.3982095205302576,
      "grad_norm": 0.8884512782096863,
      "learning_rate": 2.0375859959777664e-05,
      "loss": 2.9793,
      "step": 55720
    },
    {
      "epoch": 2.3986399242489456,
      "grad_norm": 0.8025785684585571,
      "learning_rate": 2.0347757364721732e-05,
      "loss": 2.9439,
      "step": 55730
    },
    {
      "epoch": 2.3990703279676335,
      "grad_norm": 0.901323676109314,
      "learning_rate": 2.031967196758383e-05,
      "loss": 2.9031,
      "step": 55740
    },
    {
      "epoch": 2.399500731686322,
      "grad_norm": 1.0078684091567993,
      "learning_rate": 2.029160377442787e-05,
      "loss": 3.0221,
      "step": 55750
    },
    {
      "epoch": 2.399500731686322,
      "eval_bleu": 27.44575634771237,
      "eval_gen_len": 27.505,
      "eval_loss": 2.7845284938812256,
      "eval_runtime": 58.5187,
      "eval_samples_per_second": 17.089,
      "eval_steps_per_second": 1.077,
      "step": 55750
    },
    {
      "epoch": 2.39993113540501,
      "grad_norm": 0.8727110028266907,
      "learning_rate": 2.0263552791314235e-05,
      "loss": 2.9358,
      "step": 55760
    },
    {
      "epoch": 2.400361539123698,
      "grad_norm": 0.9032418727874756,
      "learning_rate": 2.0235519024299354e-05,
      "loss": 3.002,
      "step": 55770
    },
    {
      "epoch": 2.4007919428423863,
      "grad_norm": 0.9621639251708984,
      "learning_rate": 2.0207502479436157e-05,
      "loss": 3.0016,
      "step": 55780
    },
    {
      "epoch": 2.4012223465610743,
      "grad_norm": 0.9093819260597229,
      "learning_rate": 2.0179503162773715e-05,
      "loss": 2.9015,
      "step": 55790
    },
    {
      "epoch": 2.401652750279762,
      "grad_norm": 0.850974440574646,
      "learning_rate": 2.0151521080357493e-05,
      "loss": 2.992,
      "step": 55800
    },
    {
      "epoch": 2.401652750279762,
      "eval_bleu": 27.434494891297074,
      "eval_gen_len": 27.499,
      "eval_loss": 2.785731792449951,
      "eval_runtime": 57.6424,
      "eval_samples_per_second": 17.348,
      "eval_steps_per_second": 1.093,
      "step": 55800
    },
    {
      "epoch": 2.4020831539984506,
      "grad_norm": 0.9791143536567688,
      "learning_rate": 2.0123556238229102e-05,
      "loss": 2.9668,
      "step": 55810
    },
    {
      "epoch": 2.4025135577171386,
      "grad_norm": 0.8683682084083557,
      "learning_rate": 2.0095608642426545e-05,
      "loss": 3.0148,
      "step": 55820
    },
    {
      "epoch": 2.4029439614358266,
      "grad_norm": 0.9873707294464111,
      "learning_rate": 2.006767829898407e-05,
      "loss": 2.9241,
      "step": 55830
    },
    {
      "epoch": 2.403374365154515,
      "grad_norm": 0.9464672207832336,
      "learning_rate": 2.0039765213932183e-05,
      "loss": 2.9566,
      "step": 55840
    },
    {
      "epoch": 2.403804768873203,
      "grad_norm": 0.8772829174995422,
      "learning_rate": 2.0011869393297644e-05,
      "loss": 2.9491,
      "step": 55850
    },
    {
      "epoch": 2.403804768873203,
      "eval_bleu": 27.289701532912364,
      "eval_gen_len": 27.461,
      "eval_loss": 2.7871499061584473,
      "eval_runtime": 58.0829,
      "eval_samples_per_second": 17.217,
      "eval_steps_per_second": 1.085,
      "step": 55850
    },
    {
      "epoch": 2.4042351725918913,
      "grad_norm": 0.827978253364563,
      "learning_rate": 1.9983990843103507e-05,
      "loss": 2.803,
      "step": 55860
    },
    {
      "epoch": 2.4046655763105793,
      "grad_norm": 0.8437461256980896,
      "learning_rate": 1.995612956936913e-05,
      "loss": 2.965,
      "step": 55870
    },
    {
      "epoch": 2.4050959800292673,
      "grad_norm": 0.8904432654380798,
      "learning_rate": 1.9928285578110086e-05,
      "loss": 2.8641,
      "step": 55880
    },
    {
      "epoch": 2.4055263837479557,
      "grad_norm": 0.8742953538894653,
      "learning_rate": 1.990045887533827e-05,
      "loss": 2.9642,
      "step": 55890
    },
    {
      "epoch": 2.4059567874666437,
      "grad_norm": 0.8803709745407104,
      "learning_rate": 1.9872649467061778e-05,
      "loss": 2.9732,
      "step": 55900
    },
    {
      "epoch": 2.4059567874666437,
      "eval_bleu": 27.191890490976633,
      "eval_gen_len": 27.429,
      "eval_loss": 2.7871055603027344,
      "eval_runtime": 58.1048,
      "eval_samples_per_second": 17.21,
      "eval_steps_per_second": 1.084,
      "step": 55900
    },
    {
      "epoch": 2.406387191185332,
      "grad_norm": 0.9269663095474243,
      "learning_rate": 1.9844857359285063e-05,
      "loss": 2.9486,
      "step": 55910
    },
    {
      "epoch": 2.40681759490402,
      "grad_norm": 0.9008238315582275,
      "learning_rate": 1.981708255800875e-05,
      "loss": 2.9439,
      "step": 55920
    },
    {
      "epoch": 2.407247998622708,
      "grad_norm": 0.9615299105644226,
      "learning_rate": 1.9789325069229746e-05,
      "loss": 3.0118,
      "step": 55930
    },
    {
      "epoch": 2.4076784023413964,
      "grad_norm": 0.9370705485343933,
      "learning_rate": 1.976158489894131e-05,
      "loss": 2.9935,
      "step": 55940
    },
    {
      "epoch": 2.4081088060600844,
      "grad_norm": 0.9772223234176636,
      "learning_rate": 1.9733862053132812e-05,
      "loss": 2.9463,
      "step": 55950
    },
    {
      "epoch": 2.4081088060600844,
      "eval_bleu": 27.093860240041423,
      "eval_gen_len": 27.422,
      "eval_loss": 2.7875843048095703,
      "eval_runtime": 58.4409,
      "eval_samples_per_second": 17.111,
      "eval_steps_per_second": 1.078,
      "step": 55950
    },
    {
      "epoch": 2.4085392097787723,
      "grad_norm": 0.924704909324646,
      "learning_rate": 1.970615653779003e-05,
      "loss": 2.9686,
      "step": 55960
    },
    {
      "epoch": 2.4089696134974607,
      "grad_norm": 0.9806188941001892,
      "learning_rate": 1.9678468358894887e-05,
      "loss": 3.0666,
      "step": 55970
    },
    {
      "epoch": 2.4094000172161487,
      "grad_norm": 0.8555580973625183,
      "learning_rate": 1.9650797522425646e-05,
      "loss": 3.0132,
      "step": 55980
    },
    {
      "epoch": 2.4098304209348367,
      "grad_norm": 0.9624637961387634,
      "learning_rate": 1.9623144034356743e-05,
      "loss": 2.982,
      "step": 55990
    },
    {
      "epoch": 2.410260824653525,
      "grad_norm": 0.9863819479942322,
      "learning_rate": 1.959550790065897e-05,
      "loss": 2.9309,
      "step": 56000
    },
    {
      "epoch": 2.410260824653525,
      "eval_bleu": 27.260787970596716,
      "eval_gen_len": 27.491,
      "eval_loss": 2.7868077754974365,
      "eval_runtime": 57.9439,
      "eval_samples_per_second": 17.258,
      "eval_steps_per_second": 1.087,
      "step": 56000
    },
    {
      "epoch": 2.410691228372213,
      "grad_norm": 0.8869860172271729,
      "learning_rate": 1.9567889127299277e-05,
      "loss": 3.0074,
      "step": 56010
    },
    {
      "epoch": 2.411121632090901,
      "grad_norm": 1.0439139604568481,
      "learning_rate": 1.954028772024088e-05,
      "loss": 2.9224,
      "step": 56020
    },
    {
      "epoch": 2.4115520358095894,
      "grad_norm": 0.9822914600372314,
      "learning_rate": 1.9512703685443335e-05,
      "loss": 2.9848,
      "step": 56030
    },
    {
      "epoch": 2.4119824395282774,
      "grad_norm": 0.9349579811096191,
      "learning_rate": 1.94851370288623e-05,
      "loss": 2.9253,
      "step": 56040
    },
    {
      "epoch": 2.412412843246966,
      "grad_norm": 0.901470959186554,
      "learning_rate": 1.9457587756449847e-05,
      "loss": 2.9781,
      "step": 56050
    },
    {
      "epoch": 2.412412843246966,
      "eval_bleu": 27.268400673471756,
      "eval_gen_len": 27.524,
      "eval_loss": 2.786088705062866,
      "eval_runtime": 58.0546,
      "eval_samples_per_second": 17.225,
      "eval_steps_per_second": 1.085,
      "step": 56050
    },
    {
      "epoch": 2.4128432469656538,
      "grad_norm": 0.910606324672699,
      "learning_rate": 1.9430055874154128e-05,
      "loss": 2.9542,
      "step": 56060
    },
    {
      "epoch": 2.4132736506843417,
      "grad_norm": 0.9064199328422546,
      "learning_rate": 1.9402541387919692e-05,
      "loss": 3.0154,
      "step": 56070
    },
    {
      "epoch": 2.41370405440303,
      "grad_norm": 0.8209477663040161,
      "learning_rate": 1.937504430368724e-05,
      "loss": 2.977,
      "step": 56080
    },
    {
      "epoch": 2.414134458121718,
      "grad_norm": 0.888140082359314,
      "learning_rate": 1.9347564627393698e-05,
      "loss": 2.9779,
      "step": 56090
    },
    {
      "epoch": 2.4145648618404065,
      "grad_norm": 0.9568844437599182,
      "learning_rate": 1.9320102364972325e-05,
      "loss": 2.9166,
      "step": 56100
    },
    {
      "epoch": 2.4145648618404065,
      "eval_bleu": 27.113709397142387,
      "eval_gen_len": 27.487,
      "eval_loss": 2.7865967750549316,
      "eval_runtime": 58.9725,
      "eval_samples_per_second": 16.957,
      "eval_steps_per_second": 1.068,
      "step": 56100
    },
    {
      "epoch": 2.4149952655590945,
      "grad_norm": 0.7653026580810547,
      "learning_rate": 1.9292657522352518e-05,
      "loss": 3.0005,
      "step": 56110
    },
    {
      "epoch": 2.4154256692777825,
      "grad_norm": 0.8636044263839722,
      "learning_rate": 1.926523010546002e-05,
      "loss": 2.9588,
      "step": 56120
    },
    {
      "epoch": 2.415856072996471,
      "grad_norm": 1.0462523698806763,
      "learning_rate": 1.9237820120216698e-05,
      "loss": 3.0492,
      "step": 56130
    },
    {
      "epoch": 2.416286476715159,
      "grad_norm": 0.944758415222168,
      "learning_rate": 1.921042757254077e-05,
      "loss": 2.9694,
      "step": 56140
    },
    {
      "epoch": 2.416716880433847,
      "grad_norm": 0.928534209728241,
      "learning_rate": 1.9183052468346565e-05,
      "loss": 2.974,
      "step": 56150
    },
    {
      "epoch": 2.416716880433847,
      "eval_bleu": 27.360216185693194,
      "eval_gen_len": 27.484,
      "eval_loss": 2.786370038986206,
      "eval_runtime": 57.9584,
      "eval_samples_per_second": 17.254,
      "eval_steps_per_second": 1.087,
      "step": 56150
    },
    {
      "epoch": 2.417147284152535,
      "grad_norm": 0.9601806402206421,
      "learning_rate": 1.915569481354478e-05,
      "loss": 2.9767,
      "step": 56160
    },
    {
      "epoch": 2.417577687871223,
      "grad_norm": 0.8138348460197449,
      "learning_rate": 1.9128354614042233e-05,
      "loss": 2.9957,
      "step": 56170
    },
    {
      "epoch": 2.418008091589911,
      "grad_norm": 0.9762865900993347,
      "learning_rate": 1.910103187574199e-05,
      "loss": 2.9864,
      "step": 56180
    },
    {
      "epoch": 2.4184384953085996,
      "grad_norm": 0.985999345779419,
      "learning_rate": 1.907372660454345e-05,
      "loss": 2.9385,
      "step": 56190
    },
    {
      "epoch": 2.4188688990272875,
      "grad_norm": 0.9849889874458313,
      "learning_rate": 1.9046438806342083e-05,
      "loss": 3.0505,
      "step": 56200
    },
    {
      "epoch": 2.4188688990272875,
      "eval_bleu": 27.196004617240785,
      "eval_gen_len": 27.465,
      "eval_loss": 2.7874948978424072,
      "eval_runtime": 58.3596,
      "eval_samples_per_second": 17.135,
      "eval_steps_per_second": 1.08,
      "step": 56200
    },
    {
      "epoch": 2.4192993027459755,
      "grad_norm": 0.9126155972480774,
      "learning_rate": 1.9019168487029726e-05,
      "loss": 3.0551,
      "step": 56210
    },
    {
      "epoch": 2.419729706464664,
      "grad_norm": 0.9260562062263489,
      "learning_rate": 1.8991915652494353e-05,
      "loss": 2.9543,
      "step": 56220
    },
    {
      "epoch": 2.420160110183352,
      "grad_norm": 0.9287069439888,
      "learning_rate": 1.896468030862021e-05,
      "loss": 2.9184,
      "step": 56230
    },
    {
      "epoch": 2.4205905139020403,
      "grad_norm": 0.8941834568977356,
      "learning_rate": 1.893746246128775e-05,
      "loss": 3.022,
      "step": 56240
    },
    {
      "epoch": 2.4210209176207282,
      "grad_norm": 0.9859669804573059,
      "learning_rate": 1.89102621163736e-05,
      "loss": 3.0269,
      "step": 56250
    },
    {
      "epoch": 2.4210209176207282,
      "eval_bleu": 27.11791000230518,
      "eval_gen_len": 27.488,
      "eval_loss": 2.7860047817230225,
      "eval_runtime": 57.9683,
      "eval_samples_per_second": 17.251,
      "eval_steps_per_second": 1.087,
      "step": 56250
    },
    {
      "epoch": 2.421451321339416,
      "grad_norm": 0.9639077186584473,
      "learning_rate": 1.8883079279750725e-05,
      "loss": 2.9326,
      "step": 56260
    },
    {
      "epoch": 2.4218817250581046,
      "grad_norm": 0.9371873736381531,
      "learning_rate": 1.8855913957288172e-05,
      "loss": 2.9743,
      "step": 56270
    },
    {
      "epoch": 2.4223121287767926,
      "grad_norm": 0.9431024193763733,
      "learning_rate": 1.882876615485135e-05,
      "loss": 2.9236,
      "step": 56280
    },
    {
      "epoch": 2.422742532495481,
      "grad_norm": 0.8868805766105652,
      "learning_rate": 1.8801635878301736e-05,
      "loss": 2.9239,
      "step": 56290
    },
    {
      "epoch": 2.423172936214169,
      "grad_norm": 0.8785443305969238,
      "learning_rate": 1.8774523133497167e-05,
      "loss": 3.0654,
      "step": 56300
    },
    {
      "epoch": 2.423172936214169,
      "eval_bleu": 27.20394513508427,
      "eval_gen_len": 27.493,
      "eval_loss": 2.785658597946167,
      "eval_runtime": 57.3578,
      "eval_samples_per_second": 17.434,
      "eval_steps_per_second": 1.098,
      "step": 56300
    },
    {
      "epoch": 2.423603339932857,
      "grad_norm": 0.9141059517860413,
      "learning_rate": 1.874742792629156e-05,
      "loss": 2.9245,
      "step": 56310
    },
    {
      "epoch": 2.4240337436515453,
      "grad_norm": 0.9008874297142029,
      "learning_rate": 1.872035026253519e-05,
      "loss": 2.9247,
      "step": 56320
    },
    {
      "epoch": 2.4244641473702333,
      "grad_norm": 1.047593355178833,
      "learning_rate": 1.869329014807436e-05,
      "loss": 2.9891,
      "step": 56330
    },
    {
      "epoch": 2.4248945510889213,
      "grad_norm": 0.9677031636238098,
      "learning_rate": 1.8666247588751774e-05,
      "loss": 3.0161,
      "step": 56340
    },
    {
      "epoch": 2.4253249548076097,
      "grad_norm": 1.004323959350586,
      "learning_rate": 1.8639222590406192e-05,
      "loss": 3.0142,
      "step": 56350
    },
    {
      "epoch": 2.4253249548076097,
      "eval_bleu": 27.072267483144504,
      "eval_gen_len": 27.51,
      "eval_loss": 2.7854247093200684,
      "eval_runtime": 57.74,
      "eval_samples_per_second": 17.319,
      "eval_steps_per_second": 1.091,
      "step": 56350
    },
    {
      "epoch": 2.4257553585262976,
      "grad_norm": 1.0040627717971802,
      "learning_rate": 1.861221515887268e-05,
      "loss": 2.958,
      "step": 56360
    },
    {
      "epoch": 2.4261857622449856,
      "grad_norm": 0.977557897567749,
      "learning_rate": 1.8585225299982523e-05,
      "loss": 2.9894,
      "step": 56370
    },
    {
      "epoch": 2.426616165963674,
      "grad_norm": 0.9781822562217712,
      "learning_rate": 1.855825301956311e-05,
      "loss": 2.9826,
      "step": 56380
    },
    {
      "epoch": 2.427046569682362,
      "grad_norm": 0.963304877281189,
      "learning_rate": 1.853129832343814e-05,
      "loss": 2.9003,
      "step": 56390
    },
    {
      "epoch": 2.42747697340105,
      "grad_norm": 0.8783015012741089,
      "learning_rate": 1.8504361217427423e-05,
      "loss": 2.8751,
      "step": 56400
    },
    {
      "epoch": 2.42747697340105,
      "eval_bleu": 26.818194898385343,
      "eval_gen_len": 27.474,
      "eval_loss": 2.7873027324676514,
      "eval_runtime": 57.6572,
      "eval_samples_per_second": 17.344,
      "eval_steps_per_second": 1.093,
      "step": 56400
    },
    {
      "epoch": 2.4279073771197384,
      "grad_norm": 0.9060788750648499,
      "learning_rate": 1.8477441707347086e-05,
      "loss": 2.9844,
      "step": 56410
    },
    {
      "epoch": 2.4283377808384263,
      "grad_norm": 0.8605608344078064,
      "learning_rate": 1.8450539799009302e-05,
      "loss": 2.8573,
      "step": 56420
    },
    {
      "epoch": 2.4287681845571147,
      "grad_norm": 1.0093921422958374,
      "learning_rate": 1.8423655498222592e-05,
      "loss": 2.9776,
      "step": 56430
    },
    {
      "epoch": 2.4291985882758027,
      "grad_norm": 0.9976425766944885,
      "learning_rate": 1.8396788810791576e-05,
      "loss": 2.9231,
      "step": 56440
    },
    {
      "epoch": 2.4296289919944907,
      "grad_norm": 0.9334859251976013,
      "learning_rate": 1.836993974251716e-05,
      "loss": 2.9674,
      "step": 56450
    },
    {
      "epoch": 2.4296289919944907,
      "eval_bleu": 27.064479075878566,
      "eval_gen_len": 27.464,
      "eval_loss": 2.787060022354126,
      "eval_runtime": 57.3668,
      "eval_samples_per_second": 17.432,
      "eval_steps_per_second": 1.098,
      "step": 56450
    },
    {
      "epoch": 2.430059395713179,
      "grad_norm": 0.9749420285224915,
      "learning_rate": 1.8343108299196332e-05,
      "loss": 2.9549,
      "step": 56460
    },
    {
      "epoch": 2.430489799431867,
      "grad_norm": 0.982856035232544,
      "learning_rate": 1.8316294486622366e-05,
      "loss": 3.0461,
      "step": 56470
    },
    {
      "epoch": 2.4309202031505555,
      "grad_norm": 0.9343950748443604,
      "learning_rate": 1.8289498310584718e-05,
      "loss": 2.9716,
      "step": 56480
    },
    {
      "epoch": 2.4313506068692434,
      "grad_norm": 0.9458443522453308,
      "learning_rate": 1.826271977686902e-05,
      "loss": 2.9932,
      "step": 56490
    },
    {
      "epoch": 2.4317810105879314,
      "grad_norm": 1.0020939111709595,
      "learning_rate": 1.8235958891257064e-05,
      "loss": 2.9567,
      "step": 56500
    },
    {
      "epoch": 2.4317810105879314,
      "eval_bleu": 27.237432864727975,
      "eval_gen_len": 27.472,
      "eval_loss": 2.7863481044769287,
      "eval_runtime": 57.3317,
      "eval_samples_per_second": 17.442,
      "eval_steps_per_second": 1.099,
      "step": 56500
    },
    {
      "epoch": 2.43221141430662,
      "grad_norm": 1.049864649772644,
      "learning_rate": 1.8209215659526845e-05,
      "loss": 2.9717,
      "step": 56510
    },
    {
      "epoch": 2.4326418180253078,
      "grad_norm": 0.8165504932403564,
      "learning_rate": 1.818249008745263e-05,
      "loss": 2.97,
      "step": 56520
    },
    {
      "epoch": 2.4330722217439957,
      "grad_norm": 0.9301323890686035,
      "learning_rate": 1.8155782180804726e-05,
      "loss": 2.976,
      "step": 56530
    },
    {
      "epoch": 2.433502625462684,
      "grad_norm": 1.0107598304748535,
      "learning_rate": 1.8129091945349773e-05,
      "loss": 3.0166,
      "step": 56540
    },
    {
      "epoch": 2.433933029181372,
      "grad_norm": 0.8760069012641907,
      "learning_rate": 1.8102419386850477e-05,
      "loss": 2.9988,
      "step": 56550
    },
    {
      "epoch": 2.433933029181372,
      "eval_bleu": 27.30106337304951,
      "eval_gen_len": 27.524,
      "eval_loss": 2.7857041358947754,
      "eval_runtime": 57.3058,
      "eval_samples_per_second": 17.45,
      "eval_steps_per_second": 1.099,
      "step": 56550
    },
    {
      "epoch": 2.43436343290006,
      "grad_norm": 0.8669852018356323,
      "learning_rate": 1.8075764511065794e-05,
      "loss": 2.8995,
      "step": 56560
    },
    {
      "epoch": 2.4347938366187485,
      "grad_norm": 0.8865799307823181,
      "learning_rate": 1.8049127323750904e-05,
      "loss": 2.9175,
      "step": 56570
    },
    {
      "epoch": 2.4352242403374365,
      "grad_norm": 0.863356351852417,
      "learning_rate": 1.8022507830657e-05,
      "loss": 2.9253,
      "step": 56580
    },
    {
      "epoch": 2.4356546440561244,
      "grad_norm": 0.9089106321334839,
      "learning_rate": 1.7995906037531652e-05,
      "loss": 3.0202,
      "step": 56590
    },
    {
      "epoch": 2.436085047774813,
      "grad_norm": 0.9668095707893372,
      "learning_rate": 1.7969321950118468e-05,
      "loss": 3.0792,
      "step": 56600
    },
    {
      "epoch": 2.436085047774813,
      "eval_bleu": 27.060389842832073,
      "eval_gen_len": 27.513,
      "eval_loss": 2.785536050796509,
      "eval_runtime": 57.6935,
      "eval_samples_per_second": 17.333,
      "eval_steps_per_second": 1.092,
      "step": 56600
    },
    {
      "epoch": 2.436515451493501,
      "grad_norm": 1.0795842409133911,
      "learning_rate": 1.7942755574157323e-05,
      "loss": 3.1518,
      "step": 56610
    },
    {
      "epoch": 2.436945855212189,
      "grad_norm": 0.9035769701004028,
      "learning_rate": 1.7916206915384192e-05,
      "loss": 2.943,
      "step": 56620
    },
    {
      "epoch": 2.437376258930877,
      "grad_norm": 0.8805388808250427,
      "learning_rate": 1.7889675979531317e-05,
      "loss": 2.9337,
      "step": 56630
    },
    {
      "epoch": 2.437806662649565,
      "grad_norm": 0.9171884059906006,
      "learning_rate": 1.7863162772327e-05,
      "loss": 2.9417,
      "step": 56640
    },
    {
      "epoch": 2.4382370663682535,
      "grad_norm": 0.9289556741714478,
      "learning_rate": 1.7836667299495835e-05,
      "loss": 3.1088,
      "step": 56650
    },
    {
      "epoch": 2.4382370663682535,
      "eval_bleu": 27.22011190097016,
      "eval_gen_len": 27.53,
      "eval_loss": 2.78664231300354,
      "eval_runtime": 57.328,
      "eval_samples_per_second": 17.443,
      "eval_steps_per_second": 1.099,
      "step": 56650
    },
    {
      "epoch": 2.4386674700869415,
      "grad_norm": 0.922656774520874,
      "learning_rate": 1.7810189566758494e-05,
      "loss": 2.9118,
      "step": 56660
    },
    {
      "epoch": 2.43909787380563,
      "grad_norm": 0.8546894192695618,
      "learning_rate": 1.778372957983183e-05,
      "loss": 3.0131,
      "step": 56670
    },
    {
      "epoch": 2.439528277524318,
      "grad_norm": 0.9849451184272766,
      "learning_rate": 1.775728734442893e-05,
      "loss": 2.945,
      "step": 56680
    },
    {
      "epoch": 2.439958681243006,
      "grad_norm": 0.8964415788650513,
      "learning_rate": 1.7730862866258968e-05,
      "loss": 2.9727,
      "step": 56690
    },
    {
      "epoch": 2.4403890849616943,
      "grad_norm": 0.9374074935913086,
      "learning_rate": 1.770445615102735e-05,
      "loss": 3.0344,
      "step": 56700
    },
    {
      "epoch": 2.4403890849616943,
      "eval_bleu": 27.159424998940356,
      "eval_gen_len": 27.502,
      "eval_loss": 2.7877137660980225,
      "eval_runtime": 57.4792,
      "eval_samples_per_second": 17.398,
      "eval_steps_per_second": 1.096,
      "step": 56700
    },
    {
      "epoch": 2.4408194886803822,
      "grad_norm": 0.8962000608444214,
      "learning_rate": 1.767806720443559e-05,
      "loss": 3.0459,
      "step": 56710
    },
    {
      "epoch": 2.44124989239907,
      "grad_norm": 0.808266818523407,
      "learning_rate": 1.765169603218142e-05,
      "loss": 2.9432,
      "step": 56720
    },
    {
      "epoch": 2.4416802961177586,
      "grad_norm": 1.023607611656189,
      "learning_rate": 1.7625342639958698e-05,
      "loss": 2.9352,
      "step": 56730
    },
    {
      "epoch": 2.4421106998364466,
      "grad_norm": 0.9185159802436829,
      "learning_rate": 1.7599007033457416e-05,
      "loss": 2.9571,
      "step": 56740
    },
    {
      "epoch": 2.4425411035551345,
      "grad_norm": 0.8631901144981384,
      "learning_rate": 1.7572689218363815e-05,
      "loss": 3.0118,
      "step": 56750
    },
    {
      "epoch": 2.4425411035551345,
      "eval_bleu": 27.17788089000473,
      "eval_gen_len": 27.489,
      "eval_loss": 2.7866225242614746,
      "eval_runtime": 57.8867,
      "eval_samples_per_second": 17.275,
      "eval_steps_per_second": 1.088,
      "step": 56750
    },
    {
      "epoch": 2.442971507273823,
      "grad_norm": 0.886770486831665,
      "learning_rate": 1.7546389200360204e-05,
      "loss": 3.0373,
      "step": 56760
    },
    {
      "epoch": 2.443401910992511,
      "grad_norm": 0.9275375008583069,
      "learning_rate": 1.7520106985125117e-05,
      "loss": 3.0262,
      "step": 56770
    },
    {
      "epoch": 2.443832314711199,
      "grad_norm": 0.860641598701477,
      "learning_rate": 1.7493842578333175e-05,
      "loss": 2.9279,
      "step": 56780
    },
    {
      "epoch": 2.4442627184298873,
      "grad_norm": 0.8199352025985718,
      "learning_rate": 1.7467595985655237e-05,
      "loss": 2.9214,
      "step": 56790
    },
    {
      "epoch": 2.4446931221485753,
      "grad_norm": 1.073219895362854,
      "learning_rate": 1.7441367212758232e-05,
      "loss": 3.0064,
      "step": 56800
    },
    {
      "epoch": 2.4446931221485753,
      "eval_bleu": 27.290406107927435,
      "eval_gen_len": 27.465,
      "eval_loss": 2.786855936050415,
      "eval_runtime": 57.8404,
      "eval_samples_per_second": 17.289,
      "eval_steps_per_second": 1.089,
      "step": 56800
    },
    {
      "epoch": 2.4451235258672637,
      "grad_norm": 0.9387234449386597,
      "learning_rate": 1.741515626530531e-05,
      "loss": 3.0677,
      "step": 56810
    },
    {
      "epoch": 2.4455539295859516,
      "grad_norm": 0.8829460740089417,
      "learning_rate": 1.738896314895575e-05,
      "loss": 2.9826,
      "step": 56820
    },
    {
      "epoch": 2.4459843333046396,
      "grad_norm": 0.9275423884391785,
      "learning_rate": 1.7362787869364917e-05,
      "loss": 2.9562,
      "step": 56830
    },
    {
      "epoch": 2.446414737023328,
      "grad_norm": 0.9362580180168152,
      "learning_rate": 1.7336630432184455e-05,
      "loss": 3.0445,
      "step": 56840
    },
    {
      "epoch": 2.446845140742016,
      "grad_norm": 0.8276758790016174,
      "learning_rate": 1.7310490843062022e-05,
      "loss": 2.8844,
      "step": 56850
    },
    {
      "epoch": 2.446845140742016,
      "eval_bleu": 27.271922708708917,
      "eval_gen_len": 27.497,
      "eval_loss": 2.7875967025756836,
      "eval_runtime": 57.8368,
      "eval_samples_per_second": 17.29,
      "eval_steps_per_second": 1.089,
      "step": 56850
    },
    {
      "epoch": 2.4472755444607044,
      "grad_norm": 1.0425273180007935,
      "learning_rate": 1.7284369107641528e-05,
      "loss": 2.9884,
      "step": 56860
    },
    {
      "epoch": 2.4477059481793924,
      "grad_norm": 0.9417226314544678,
      "learning_rate": 1.7258265231562953e-05,
      "loss": 2.9493,
      "step": 56870
    },
    {
      "epoch": 2.4481363518980803,
      "grad_norm": 0.8984373807907104,
      "learning_rate": 1.7232179220462473e-05,
      "loss": 2.9477,
      "step": 56880
    },
    {
      "epoch": 2.4485667556167687,
      "grad_norm": 0.8887356519699097,
      "learning_rate": 1.7206111079972387e-05,
      "loss": 2.9515,
      "step": 56890
    },
    {
      "epoch": 2.4489971593354567,
      "grad_norm": 0.8484148979187012,
      "learning_rate": 1.71800608157211e-05,
      "loss": 3.0547,
      "step": 56900
    },
    {
      "epoch": 2.4489971593354567,
      "eval_bleu": 27.324098957397823,
      "eval_gen_len": 27.534,
      "eval_loss": 2.786019802093506,
      "eval_runtime": 57.8959,
      "eval_samples_per_second": 17.272,
      "eval_steps_per_second": 1.088,
      "step": 56900
    },
    {
      "epoch": 2.4494275630541447,
      "grad_norm": 0.8838495016098022,
      "learning_rate": 1.7154028433333235e-05,
      "loss": 2.961,
      "step": 56910
    },
    {
      "epoch": 2.449857966772833,
      "grad_norm": 0.9305099844932556,
      "learning_rate": 1.7128013938429454e-05,
      "loss": 3.0437,
      "step": 56920
    },
    {
      "epoch": 2.450288370491521,
      "grad_norm": 0.9668962359428406,
      "learning_rate": 1.7102017336626675e-05,
      "loss": 2.9915,
      "step": 56930
    },
    {
      "epoch": 2.450718774210209,
      "grad_norm": 0.8451305627822876,
      "learning_rate": 1.707603863353784e-05,
      "loss": 3.0317,
      "step": 56940
    },
    {
      "epoch": 2.4511491779288974,
      "grad_norm": 0.9223394393920898,
      "learning_rate": 1.7050077834772127e-05,
      "loss": 2.9539,
      "step": 56950
    },
    {
      "epoch": 2.4511491779288974,
      "eval_bleu": 27.28852504151412,
      "eval_gen_len": 27.496,
      "eval_loss": 2.78603458404541,
      "eval_runtime": 57.729,
      "eval_samples_per_second": 17.322,
      "eval_steps_per_second": 1.091,
      "step": 56950
    },
    {
      "epoch": 2.4515795816475854,
      "grad_norm": 0.9532549977302551,
      "learning_rate": 1.702413494593473e-05,
      "loss": 2.9798,
      "step": 56960
    },
    {
      "epoch": 2.4520099853662733,
      "grad_norm": 0.940916121006012,
      "learning_rate": 1.6998209972627144e-05,
      "loss": 3.0746,
      "step": 56970
    },
    {
      "epoch": 2.4524403890849618,
      "grad_norm": 0.8027209639549255,
      "learning_rate": 1.6972302920446782e-05,
      "loss": 3.0042,
      "step": 56980
    },
    {
      "epoch": 2.4528707928036497,
      "grad_norm": 0.8882446885108948,
      "learning_rate": 1.694641379498736e-05,
      "loss": 2.9629,
      "step": 56990
    },
    {
      "epoch": 2.453301196522338,
      "grad_norm": 0.8968334197998047,
      "learning_rate": 1.6920542601838674e-05,
      "loss": 3.0269,
      "step": 57000
    },
    {
      "epoch": 2.453301196522338,
      "eval_bleu": 27.345537103835863,
      "eval_gen_len": 27.52,
      "eval_loss": 2.7859046459198,
      "eval_runtime": 58.1882,
      "eval_samples_per_second": 17.186,
      "eval_steps_per_second": 1.083,
      "step": 57000
    },
    {
      "epoch": 2.453731600241026,
      "grad_norm": 0.8862089514732361,
      "learning_rate": 1.68946893465866e-05,
      "loss": 2.9963,
      "step": 57010
    },
    {
      "epoch": 2.454162003959714,
      "grad_norm": 0.8852733969688416,
      "learning_rate": 1.6868854034813242e-05,
      "loss": 3.0486,
      "step": 57020
    },
    {
      "epoch": 2.4545924076784025,
      "grad_norm": 0.9812709093093872,
      "learning_rate": 1.684303667209669e-05,
      "loss": 3.0207,
      "step": 57030
    },
    {
      "epoch": 2.4550228113970904,
      "grad_norm": 0.9119954109191895,
      "learning_rate": 1.681723726401131e-05,
      "loss": 2.936,
      "step": 57040
    },
    {
      "epoch": 2.4554532151157784,
      "grad_norm": 0.9623156189918518,
      "learning_rate": 1.6791455816127456e-05,
      "loss": 2.9049,
      "step": 57050
    },
    {
      "epoch": 2.4554532151157784,
      "eval_bleu": 27.306185670031294,
      "eval_gen_len": 27.535,
      "eval_loss": 2.7854270935058594,
      "eval_runtime": 58.4678,
      "eval_samples_per_second": 17.103,
      "eval_steps_per_second": 1.078,
      "step": 57050
    },
    {
      "epoch": 2.455883618834467,
      "grad_norm": 0.9052114486694336,
      "learning_rate": 1.676569233401174e-05,
      "loss": 3.0425,
      "step": 57060
    },
    {
      "epoch": 2.456314022553155,
      "grad_norm": 1.0828579664230347,
      "learning_rate": 1.673994682322674e-05,
      "loss": 3.0793,
      "step": 57070
    },
    {
      "epoch": 2.456744426271843,
      "grad_norm": 1.0063118934631348,
      "learning_rate": 1.6714219289331278e-05,
      "loss": 2.9322,
      "step": 57080
    },
    {
      "epoch": 2.457174829990531,
      "grad_norm": 1.099437952041626,
      "learning_rate": 1.6688509737880222e-05,
      "loss": 3.0425,
      "step": 57090
    },
    {
      "epoch": 2.457605233709219,
      "grad_norm": 1.039004921913147,
      "learning_rate": 1.666281817442461e-05,
      "loss": 3.0122,
      "step": 57100
    },
    {
      "epoch": 2.457605233709219,
      "eval_bleu": 27.209181904562534,
      "eval_gen_len": 27.513,
      "eval_loss": 2.785161256790161,
      "eval_runtime": 58.8743,
      "eval_samples_per_second": 16.985,
      "eval_steps_per_second": 1.07,
      "step": 57100
    },
    {
      "epoch": 2.4580356374279075,
      "grad_norm": 0.9308508634567261,
      "learning_rate": 1.663714460451159e-05,
      "loss": 2.9399,
      "step": 57110
    },
    {
      "epoch": 2.4584660411465955,
      "grad_norm": 0.8856387138366699,
      "learning_rate": 1.6611489033684368e-05,
      "loss": 2.9639,
      "step": 57120
    },
    {
      "epoch": 2.4588964448652835,
      "grad_norm": 1.0699973106384277,
      "learning_rate": 1.6585851467482348e-05,
      "loss": 3.0016,
      "step": 57130
    },
    {
      "epoch": 2.459326848583972,
      "grad_norm": 0.8805938959121704,
      "learning_rate": 1.6560231911440973e-05,
      "loss": 2.8817,
      "step": 57140
    },
    {
      "epoch": 2.45975725230266,
      "grad_norm": 1.0140349864959717,
      "learning_rate": 1.653463037109183e-05,
      "loss": 3.082,
      "step": 57150
    },
    {
      "epoch": 2.45975725230266,
      "eval_bleu": 27.329347070797688,
      "eval_gen_len": 27.555,
      "eval_loss": 2.7848238945007324,
      "eval_runtime": 58.9549,
      "eval_samples_per_second": 16.962,
      "eval_steps_per_second": 1.069,
      "step": 57150
    },
    {
      "epoch": 2.460187656021348,
      "grad_norm": 0.8137078285217285,
      "learning_rate": 1.6509046851962594e-05,
      "loss": 2.9341,
      "step": 57160
    },
    {
      "epoch": 2.4606180597400362,
      "grad_norm": 0.9423549175262451,
      "learning_rate": 1.64834813595771e-05,
      "loss": 2.9792,
      "step": 57170
    },
    {
      "epoch": 2.461048463458724,
      "grad_norm": 1.0236657857894897,
      "learning_rate": 1.6457933899455234e-05,
      "loss": 2.987,
      "step": 57180
    },
    {
      "epoch": 2.4614788671774126,
      "grad_norm": 0.8219642639160156,
      "learning_rate": 1.643240447711302e-05,
      "loss": 3.0165,
      "step": 57190
    },
    {
      "epoch": 2.4619092708961006,
      "grad_norm": 0.9522566199302673,
      "learning_rate": 1.6406893098062605e-05,
      "loss": 3.0396,
      "step": 57200
    },
    {
      "epoch": 2.4619092708961006,
      "eval_bleu": 27.258635231562927,
      "eval_gen_len": 27.53,
      "eval_loss": 2.7862417697906494,
      "eval_runtime": 58.4475,
      "eval_samples_per_second": 17.109,
      "eval_steps_per_second": 1.078,
      "step": 57200
    },
    {
      "epoch": 2.4623396746147885,
      "grad_norm": 0.8524655699729919,
      "learning_rate": 1.6381399767812178e-05,
      "loss": 2.9112,
      "step": 57210
    },
    {
      "epoch": 2.462770078333477,
      "grad_norm": 0.8444514870643616,
      "learning_rate": 1.6355924491866126e-05,
      "loss": 2.9902,
      "step": 57220
    },
    {
      "epoch": 2.463200482052165,
      "grad_norm": 0.9392637610435486,
      "learning_rate": 1.633046727572479e-05,
      "loss": 3.0407,
      "step": 57230
    },
    {
      "epoch": 2.463630885770853,
      "grad_norm": 0.8810732364654541,
      "learning_rate": 1.630502812488479e-05,
      "loss": 2.922,
      "step": 57240
    },
    {
      "epoch": 2.4640612894895413,
      "grad_norm": 1.0656583309173584,
      "learning_rate": 1.6279607044838683e-05,
      "loss": 2.9967,
      "step": 57250
    },
    {
      "epoch": 2.4640612894895413,
      "eval_bleu": 27.33255015954493,
      "eval_gen_len": 27.538,
      "eval_loss": 2.785884380340576,
      "eval_runtime": 57.983,
      "eval_samples_per_second": 17.246,
      "eval_steps_per_second": 1.087,
      "step": 57250
    },
    {
      "epoch": 2.4644916932082293,
      "grad_norm": 0.9385108351707458,
      "learning_rate": 1.6254204041075262e-05,
      "loss": 2.9647,
      "step": 57260
    },
    {
      "epoch": 2.4649220969269177,
      "grad_norm": 0.874745786190033,
      "learning_rate": 1.622881911907931e-05,
      "loss": 3.0759,
      "step": 57270
    },
    {
      "epoch": 2.4653525006456056,
      "grad_norm": 0.928257405757904,
      "learning_rate": 1.620345228433179e-05,
      "loss": 2.9218,
      "step": 57280
    },
    {
      "epoch": 2.4657829043642936,
      "grad_norm": 0.869577169418335,
      "learning_rate": 1.6178103542309675e-05,
      "loss": 2.9658,
      "step": 57290
    },
    {
      "epoch": 2.466213308082982,
      "grad_norm": 0.9209519624710083,
      "learning_rate": 1.615277289848611e-05,
      "loss": 2.9825,
      "step": 57300
    },
    {
      "epoch": 2.466213308082982,
      "eval_bleu": 27.34002234565271,
      "eval_gen_len": 27.502,
      "eval_loss": 2.785919666290283,
      "eval_runtime": 58.5052,
      "eval_samples_per_second": 17.092,
      "eval_steps_per_second": 1.077,
      "step": 57300
    },
    {
      "epoch": 2.46664371180167,
      "grad_norm": 0.9074119329452515,
      "learning_rate": 1.6127460358330304e-05,
      "loss": 2.9811,
      "step": 57310
    },
    {
      "epoch": 2.467074115520358,
      "grad_norm": 0.9861786365509033,
      "learning_rate": 1.610216592730751e-05,
      "loss": 3.0144,
      "step": 57320
    },
    {
      "epoch": 2.4675045192390463,
      "grad_norm": 0.9904934763908386,
      "learning_rate": 1.6076889610879154e-05,
      "loss": 2.9424,
      "step": 57330
    },
    {
      "epoch": 2.4679349229577343,
      "grad_norm": 0.8579459190368652,
      "learning_rate": 1.6051631414502676e-05,
      "loss": 2.9749,
      "step": 57340
    },
    {
      "epoch": 2.4683653266764223,
      "grad_norm": 0.9124356508255005,
      "learning_rate": 1.6026391343631673e-05,
      "loss": 2.9185,
      "step": 57350
    },
    {
      "epoch": 2.4683653266764223,
      "eval_bleu": 27.427631012846774,
      "eval_gen_len": 27.55,
      "eval_loss": 2.7869088649749756,
      "eval_runtime": 58.6285,
      "eval_samples_per_second": 17.057,
      "eval_steps_per_second": 1.075,
      "step": 57350
    },
    {
      "epoch": 2.4687957303951107,
      "grad_norm": 0.896058976650238,
      "learning_rate": 1.6001169403715764e-05,
      "loss": 2.9497,
      "step": 57360
    },
    {
      "epoch": 2.4692261341137987,
      "grad_norm": 0.806233286857605,
      "learning_rate": 1.5975965600200704e-05,
      "loss": 2.9346,
      "step": 57370
    },
    {
      "epoch": 2.469656537832487,
      "grad_norm": 0.9443625807762146,
      "learning_rate": 1.5950779938528303e-05,
      "loss": 2.9511,
      "step": 57380
    },
    {
      "epoch": 2.470086941551175,
      "grad_norm": 1.009278655052185,
      "learning_rate": 1.592561242413644e-05,
      "loss": 2.9059,
      "step": 57390
    },
    {
      "epoch": 2.470517345269863,
      "grad_norm": 0.927524209022522,
      "learning_rate": 1.5900463062459136e-05,
      "loss": 2.9472,
      "step": 57400
    },
    {
      "epoch": 2.470517345269863,
      "eval_bleu": 27.30687197439244,
      "eval_gen_len": 27.531,
      "eval_loss": 2.7864410877227783,
      "eval_runtime": 58.8297,
      "eval_samples_per_second": 16.998,
      "eval_steps_per_second": 1.071,
      "step": 57400
    },
    {
      "epoch": 2.4709477489885514,
      "grad_norm": 0.8562753200531006,
      "learning_rate": 1.58753318589264e-05,
      "loss": 3.0722,
      "step": 57410
    },
    {
      "epoch": 2.4713781527072394,
      "grad_norm": 0.9511244297027588,
      "learning_rate": 1.5850218818964436e-05,
      "loss": 2.9139,
      "step": 57420
    },
    {
      "epoch": 2.4718085564259273,
      "grad_norm": 0.9177368879318237,
      "learning_rate": 1.5825123947995414e-05,
      "loss": 2.9411,
      "step": 57430
    },
    {
      "epoch": 2.4722389601446157,
      "grad_norm": 1.0300769805908203,
      "learning_rate": 1.5800047251437678e-05,
      "loss": 2.9729,
      "step": 57440
    },
    {
      "epoch": 2.4726693638633037,
      "grad_norm": 0.9955756068229675,
      "learning_rate": 1.577498873470554e-05,
      "loss": 3.0145,
      "step": 57450
    },
    {
      "epoch": 2.4726693638633037,
      "eval_bleu": 27.079454400145327,
      "eval_gen_len": 27.497,
      "eval_loss": 2.7868258953094482,
      "eval_runtime": 58.592,
      "eval_samples_per_second": 17.067,
      "eval_steps_per_second": 1.075,
      "step": 57450
    },
    {
      "epoch": 2.473099767581992,
      "grad_norm": 0.9692320227622986,
      "learning_rate": 1.5749948403209514e-05,
      "loss": 3.0082,
      "step": 57460
    },
    {
      "epoch": 2.47353017130068,
      "grad_norm": 0.9282031655311584,
      "learning_rate": 1.572492626235609e-05,
      "loss": 2.9561,
      "step": 57470
    },
    {
      "epoch": 2.473960575019368,
      "grad_norm": 0.9020121693611145,
      "learning_rate": 1.5699922317547833e-05,
      "loss": 3.0947,
      "step": 57480
    },
    {
      "epoch": 2.4743909787380565,
      "grad_norm": 0.9363803267478943,
      "learning_rate": 1.5674936574183462e-05,
      "loss": 2.9806,
      "step": 57490
    },
    {
      "epoch": 2.4748213824567444,
      "grad_norm": 0.8206612467765808,
      "learning_rate": 1.5649969037657675e-05,
      "loss": 2.9998,
      "step": 57500
    },
    {
      "epoch": 2.4748213824567444,
      "eval_bleu": 27.377496577377528,
      "eval_gen_len": 27.54,
      "eval_loss": 2.7856392860412598,
      "eval_runtime": 58.4063,
      "eval_samples_per_second": 17.121,
      "eval_steps_per_second": 1.079,
      "step": 57500
    },
    {
      "epoch": 2.4752517861754324,
      "grad_norm": 0.8056740760803223,
      "learning_rate": 1.56250197133613e-05,
      "loss": 3.0036,
      "step": 57510
    },
    {
      "epoch": 2.475682189894121,
      "grad_norm": 0.9828225374221802,
      "learning_rate": 1.5600088606681186e-05,
      "loss": 3.0064,
      "step": 57520
    },
    {
      "epoch": 2.4761125936128088,
      "grad_norm": 1.0350395441055298,
      "learning_rate": 1.55751757230003e-05,
      "loss": 3.0172,
      "step": 57530
    },
    {
      "epoch": 2.4765429973314967,
      "grad_norm": 0.8331640958786011,
      "learning_rate": 1.5550281067697635e-05,
      "loss": 2.9968,
      "step": 57540
    },
    {
      "epoch": 2.476973401050185,
      "grad_norm": 0.8734950423240662,
      "learning_rate": 1.552540464614822e-05,
      "loss": 2.9055,
      "step": 57550
    },
    {
      "epoch": 2.476973401050185,
      "eval_bleu": 27.122544036805884,
      "eval_gen_len": 27.538,
      "eval_loss": 2.786745548248291,
      "eval_runtime": 59.0426,
      "eval_samples_per_second": 16.937,
      "eval_steps_per_second": 1.067,
      "step": 57550
    },
    {
      "epoch": 2.477403804768873,
      "grad_norm": 0.9409489631652832,
      "learning_rate": 1.5500546463723255e-05,
      "loss": 2.9574,
      "step": 57560
    },
    {
      "epoch": 2.477834208487561,
      "grad_norm": 0.9658427238464355,
      "learning_rate": 1.547570652578987e-05,
      "loss": 3.0708,
      "step": 57570
    },
    {
      "epoch": 2.4782646122062495,
      "grad_norm": 1.0435841083526611,
      "learning_rate": 1.5450884837711378e-05,
      "loss": 2.9726,
      "step": 57580
    },
    {
      "epoch": 2.4786950159249375,
      "grad_norm": 0.8764594793319702,
      "learning_rate": 1.5426081404847026e-05,
      "loss": 3.0522,
      "step": 57590
    },
    {
      "epoch": 2.479125419643626,
      "grad_norm": 1.0563167333602905,
      "learning_rate": 1.5401296232552252e-05,
      "loss": 3.1464,
      "step": 57600
    },
    {
      "epoch": 2.479125419643626,
      "eval_bleu": 27.205502321197855,
      "eval_gen_len": 27.571,
      "eval_loss": 2.7873127460479736,
      "eval_runtime": 58.3929,
      "eval_samples_per_second": 17.125,
      "eval_steps_per_second": 1.079,
      "step": 57600
    },
    {
      "epoch": 2.479555823362314,
      "grad_norm": 0.937063992023468,
      "learning_rate": 1.5376529326178436e-05,
      "loss": 2.9869,
      "step": 57610
    },
    {
      "epoch": 2.479986227081002,
      "grad_norm": 0.8789066076278687,
      "learning_rate": 1.5351780691073104e-05,
      "loss": 2.9812,
      "step": 57620
    },
    {
      "epoch": 2.48041663079969,
      "grad_norm": 0.9746899604797363,
      "learning_rate": 1.5327050332579783e-05,
      "loss": 2.9405,
      "step": 57630
    },
    {
      "epoch": 2.480847034518378,
      "grad_norm": 0.9429957270622253,
      "learning_rate": 1.5302338256038027e-05,
      "loss": 2.9816,
      "step": 57640
    },
    {
      "epoch": 2.4812774382370666,
      "grad_norm": 0.9050678014755249,
      "learning_rate": 1.5277644466783548e-05,
      "loss": 3.0014,
      "step": 57650
    },
    {
      "epoch": 2.4812774382370666,
      "eval_bleu": 27.2239064233194,
      "eval_gen_len": 27.508,
      "eval_loss": 2.7874372005462646,
      "eval_runtime": 58.1399,
      "eval_samples_per_second": 17.2,
      "eval_steps_per_second": 1.084,
      "step": 57650
    },
    {
      "epoch": 2.4817078419557546,
      "grad_norm": 0.9216053485870361,
      "learning_rate": 1.5252968970147985e-05,
      "loss": 2.9557,
      "step": 57660
    },
    {
      "epoch": 2.4821382456744425,
      "grad_norm": 1.0443055629730225,
      "learning_rate": 1.5228311771459148e-05,
      "loss": 2.9825,
      "step": 57670
    },
    {
      "epoch": 2.482568649393131,
      "grad_norm": 1.0133482217788696,
      "learning_rate": 1.5203672876040775e-05,
      "loss": 3.0173,
      "step": 57680
    },
    {
      "epoch": 2.482999053111819,
      "grad_norm": 0.9315758347511292,
      "learning_rate": 1.5179052289212758e-05,
      "loss": 2.9971,
      "step": 57690
    },
    {
      "epoch": 2.483429456830507,
      "grad_norm": 1.0084142684936523,
      "learning_rate": 1.5154450016290956e-05,
      "loss": 3.0247,
      "step": 57700
    },
    {
      "epoch": 2.483429456830507,
      "eval_bleu": 27.197165997305124,
      "eval_gen_len": 27.525,
      "eval_loss": 2.7871689796447754,
      "eval_runtime": 57.9813,
      "eval_samples_per_second": 17.247,
      "eval_steps_per_second": 1.087,
      "step": 57700
    },
    {
      "epoch": 2.4838598605491953,
      "grad_norm": 0.9194068312644958,
      "learning_rate": 1.5129866062587372e-05,
      "loss": 3.0431,
      "step": 57710
    },
    {
      "epoch": 2.4842902642678832,
      "grad_norm": 0.9549798965454102,
      "learning_rate": 1.5105300433409897e-05,
      "loss": 3.0788,
      "step": 57720
    },
    {
      "epoch": 2.484720667986571,
      "grad_norm": 0.8551002144813538,
      "learning_rate": 1.5080753134062608e-05,
      "loss": 2.9682,
      "step": 57730
    },
    {
      "epoch": 2.4851510717052596,
      "grad_norm": 0.9481660723686218,
      "learning_rate": 1.505622416984559e-05,
      "loss": 2.868,
      "step": 57740
    },
    {
      "epoch": 2.4855814754239476,
      "grad_norm": 0.9081920981407166,
      "learning_rate": 1.5031713546054915e-05,
      "loss": 2.8384,
      "step": 57750
    },
    {
      "epoch": 2.4855814754239476,
      "eval_bleu": 27.363282335978447,
      "eval_gen_len": 27.565,
      "eval_loss": 2.7865943908691406,
      "eval_runtime": 58.2424,
      "eval_samples_per_second": 17.17,
      "eval_steps_per_second": 1.082,
      "step": 57750
    },
    {
      "epoch": 2.4860118791426356,
      "grad_norm": 0.9686879515647888,
      "learning_rate": 1.5007221267982774e-05,
      "loss": 3.0683,
      "step": 57760
    },
    {
      "epoch": 2.486442282861324,
      "grad_norm": 0.9045599699020386,
      "learning_rate": 1.4982747340917314e-05,
      "loss": 2.9228,
      "step": 57770
    },
    {
      "epoch": 2.486872686580012,
      "grad_norm": 0.7621952891349792,
      "learning_rate": 1.4958291770142819e-05,
      "loss": 3.0545,
      "step": 57780
    },
    {
      "epoch": 2.4873030902987003,
      "grad_norm": 0.9698739647865295,
      "learning_rate": 1.493385456093951e-05,
      "loss": 2.9716,
      "step": 57790
    },
    {
      "epoch": 2.4877334940173883,
      "grad_norm": 0.8705650568008423,
      "learning_rate": 1.4909435718583698e-05,
      "loss": 2.9688,
      "step": 57800
    },
    {
      "epoch": 2.4877334940173883,
      "eval_bleu": 27.130179512619634,
      "eval_gen_len": 27.531,
      "eval_loss": 2.786774158477783,
      "eval_runtime": 57.9683,
      "eval_samples_per_second": 17.251,
      "eval_steps_per_second": 1.087,
      "step": 57800
    },
    {
      "epoch": 2.4881638977360763,
      "grad_norm": 1.052184820175171,
      "learning_rate": 1.48850352483477e-05,
      "loss": 3.0639,
      "step": 57810
    },
    {
      "epoch": 2.4885943014547647,
      "grad_norm": 0.9793781638145447,
      "learning_rate": 1.4860653155499904e-05,
      "loss": 3.0901,
      "step": 57820
    },
    {
      "epoch": 2.4890247051734526,
      "grad_norm": 1.032127022743225,
      "learning_rate": 1.4836289445304718e-05,
      "loss": 3.066,
      "step": 57830
    },
    {
      "epoch": 2.489455108892141,
      "grad_norm": 0.8393070101737976,
      "learning_rate": 1.4811944123022537e-05,
      "loss": 2.9355,
      "step": 57840
    },
    {
      "epoch": 2.489885512610829,
      "grad_norm": 0.9709213376045227,
      "learning_rate": 1.4787617193909876e-05,
      "loss": 2.9492,
      "step": 57850
    },
    {
      "epoch": 2.489885512610829,
      "eval_bleu": 27.286839453942765,
      "eval_gen_len": 27.501,
      "eval_loss": 2.7863802909851074,
      "eval_runtime": 58.3487,
      "eval_samples_per_second": 17.138,
      "eval_steps_per_second": 1.08,
      "step": 57850
    },
    {
      "epoch": 2.490315916329517,
      "grad_norm": 1.0552393198013306,
      "learning_rate": 1.4763308663219166e-05,
      "loss": 2.9293,
      "step": 57860
    },
    {
      "epoch": 2.4907463200482054,
      "grad_norm": 0.8858076930046082,
      "learning_rate": 1.4739018536199001e-05,
      "loss": 3.0691,
      "step": 57870
    },
    {
      "epoch": 2.4911767237668934,
      "grad_norm": 0.9648533463478088,
      "learning_rate": 1.4714746818093817e-05,
      "loss": 3.0183,
      "step": 57880
    },
    {
      "epoch": 2.4916071274855813,
      "grad_norm": 0.7752028703689575,
      "learning_rate": 1.4690493514144266e-05,
      "loss": 2.9564,
      "step": 57890
    },
    {
      "epoch": 2.4920375312042697,
      "grad_norm": 0.9059749245643616,
      "learning_rate": 1.4666258629586893e-05,
      "loss": 3.0102,
      "step": 57900
    },
    {
      "epoch": 2.4920375312042697,
      "eval_bleu": 27.35385711989621,
      "eval_gen_len": 27.536,
      "eval_loss": 2.785784959793091,
      "eval_runtime": 58.74,
      "eval_samples_per_second": 17.024,
      "eval_steps_per_second": 1.073,
      "step": 57900
    },
    {
      "epoch": 2.4924679349229577,
      "grad_norm": 0.8735670447349548,
      "learning_rate": 1.4642042169654358e-05,
      "loss": 2.9104,
      "step": 57910
    },
    {
      "epoch": 2.4928983386416457,
      "grad_norm": 0.8320019245147705,
      "learning_rate": 1.4617844139575254e-05,
      "loss": 2.9936,
      "step": 57920
    },
    {
      "epoch": 2.493328742360334,
      "grad_norm": 0.9089863896369934,
      "learning_rate": 1.4593664544574248e-05,
      "loss": 2.9817,
      "step": 57930
    },
    {
      "epoch": 2.493759146079022,
      "grad_norm": 0.89032381772995,
      "learning_rate": 1.4569503389872064e-05,
      "loss": 2.945,
      "step": 57940
    },
    {
      "epoch": 2.49418954979771,
      "grad_norm": 0.9967172145843506,
      "learning_rate": 1.454536068068535e-05,
      "loss": 2.9915,
      "step": 57950
    },
    {
      "epoch": 2.49418954979771,
      "eval_bleu": 27.305255849070136,
      "eval_gen_len": 27.548,
      "eval_loss": 2.784886360168457,
      "eval_runtime": 58.6981,
      "eval_samples_per_second": 17.036,
      "eval_steps_per_second": 1.073,
      "step": 57950
    },
    {
      "epoch": 2.4946199535163984,
      "grad_norm": 0.8569210171699524,
      "learning_rate": 1.4521236422226847e-05,
      "loss": 2.9698,
      "step": 57960
    },
    {
      "epoch": 2.4950503572350864,
      "grad_norm": 0.9102995991706848,
      "learning_rate": 1.4497130619705234e-05,
      "loss": 2.9592,
      "step": 57970
    },
    {
      "epoch": 2.495480760953775,
      "grad_norm": 0.8924787044525146,
      "learning_rate": 1.4473043278325327e-05,
      "loss": 2.9821,
      "step": 57980
    },
    {
      "epoch": 2.4959111646724628,
      "grad_norm": 0.7803608775138855,
      "learning_rate": 1.4448974403287818e-05,
      "loss": 2.9715,
      "step": 57990
    },
    {
      "epoch": 2.4963415683911507,
      "grad_norm": 1.043086051940918,
      "learning_rate": 1.4424923999789542e-05,
      "loss": 2.8995,
      "step": 58000
    },
    {
      "epoch": 2.4963415683911507,
      "eval_bleu": 27.204990074793667,
      "eval_gen_len": 27.535,
      "eval_loss": 2.7853074073791504,
      "eval_runtime": 59.311,
      "eval_samples_per_second": 16.86,
      "eval_steps_per_second": 1.062,
      "step": 58000
    },
    {
      "epoch": 2.496771972109839,
      "grad_norm": 0.9539466500282288,
      "learning_rate": 1.4400892073023232e-05,
      "loss": 2.9525,
      "step": 58010
    },
    {
      "epoch": 2.497202375828527,
      "grad_norm": 0.8755365610122681,
      "learning_rate": 1.4376878628177692e-05,
      "loss": 2.9533,
      "step": 58020
    },
    {
      "epoch": 2.4976327795472155,
      "grad_norm": 0.8661718368530273,
      "learning_rate": 1.4352883670437789e-05,
      "loss": 3.0015,
      "step": 58030
    },
    {
      "epoch": 2.4980631832659035,
      "grad_norm": 0.8719859719276428,
      "learning_rate": 1.4328907204984243e-05,
      "loss": 2.942,
      "step": 58040
    },
    {
      "epoch": 2.4984935869845915,
      "grad_norm": 0.8587441444396973,
      "learning_rate": 1.4304949236993925e-05,
      "loss": 2.9209,
      "step": 58050
    },
    {
      "epoch": 2.4984935869845915,
      "eval_bleu": 27.197206089454454,
      "eval_gen_len": 27.498,
      "eval_loss": 2.7869131565093994,
      "eval_runtime": 58.7472,
      "eval_samples_per_second": 17.022,
      "eval_steps_per_second": 1.072,
      "step": 58050
    },
    {
      "epoch": 2.49892399070328,
      "grad_norm": 0.9813153743743896,
      "learning_rate": 1.4281009771639641e-05,
      "loss": 2.9939,
      "step": 58060
    },
    {
      "epoch": 2.499354394421968,
      "grad_norm": 0.9518311023712158,
      "learning_rate": 1.4257088814090237e-05,
      "loss": 2.9235,
      "step": 58070
    },
    {
      "epoch": 2.499784798140656,
      "grad_norm": 0.8887103796005249,
      "learning_rate": 1.4233186369510532e-05,
      "loss": 2.8818,
      "step": 58080
    },
    {
      "epoch": 2.500215201859344,
      "grad_norm": 0.891039252281189,
      "learning_rate": 1.4209302443061378e-05,
      "loss": 3.0022,
      "step": 58090
    },
    {
      "epoch": 2.500645605578032,
      "grad_norm": 0.8791689276695251,
      "learning_rate": 1.4185437039899596e-05,
      "loss": 3.0323,
      "step": 58100
    },
    {
      "epoch": 2.500645605578032,
      "eval_bleu": 27.263352197055585,
      "eval_gen_len": 27.526,
      "eval_loss": 2.7857465744018555,
      "eval_runtime": 58.7606,
      "eval_samples_per_second": 17.018,
      "eval_steps_per_second": 1.072,
      "step": 58100
    },
    {
      "epoch": 2.50107600929672,
      "grad_norm": 0.9480025768280029,
      "learning_rate": 1.4161590165178063e-05,
      "loss": 3.0007,
      "step": 58110
    },
    {
      "epoch": 2.5015064130154085,
      "grad_norm": 0.7764498591423035,
      "learning_rate": 1.4137761824045592e-05,
      "loss": 2.9517,
      "step": 58120
    },
    {
      "epoch": 2.5019368167340965,
      "grad_norm": 0.8722413182258606,
      "learning_rate": 1.4113952021646992e-05,
      "loss": 2.9709,
      "step": 58130
    },
    {
      "epoch": 2.5023672204527845,
      "grad_norm": 0.9171583652496338,
      "learning_rate": 1.4090160763123161e-05,
      "loss": 3.0456,
      "step": 58140
    },
    {
      "epoch": 2.502797624171473,
      "grad_norm": 0.9295884370803833,
      "learning_rate": 1.4066388053610869e-05,
      "loss": 2.9123,
      "step": 58150
    },
    {
      "epoch": 2.502797624171473,
      "eval_bleu": 27.205491245988213,
      "eval_gen_len": 27.483,
      "eval_loss": 2.785642147064209,
      "eval_runtime": 58.5003,
      "eval_samples_per_second": 17.094,
      "eval_steps_per_second": 1.077,
      "step": 58150
    },
    {
      "epoch": 2.503228027890161,
      "grad_norm": 0.995130717754364,
      "learning_rate": 1.4042633898242996e-05,
      "loss": 2.9852,
      "step": 58160
    },
    {
      "epoch": 2.5036584316088493,
      "grad_norm": 1.0733293294906616,
      "learning_rate": 1.401889830214831e-05,
      "loss": 3.1239,
      "step": 58170
    },
    {
      "epoch": 2.5040888353275372,
      "grad_norm": 0.9267581701278687,
      "learning_rate": 1.3995181270451673e-05,
      "loss": 2.9736,
      "step": 58180
    },
    {
      "epoch": 2.504519239046225,
      "grad_norm": 0.9287979602813721,
      "learning_rate": 1.3971482808273872e-05,
      "loss": 2.9898,
      "step": 58190
    },
    {
      "epoch": 2.5049496427649136,
      "grad_norm": 0.9635443091392517,
      "learning_rate": 1.3947802920731667e-05,
      "loss": 2.9242,
      "step": 58200
    },
    {
      "epoch": 2.5049496427649136,
      "eval_bleu": 27.283441225560086,
      "eval_gen_len": 27.518,
      "eval_loss": 2.7864186763763428,
      "eval_runtime": 59.1758,
      "eval_samples_per_second": 16.899,
      "eval_steps_per_second": 1.065,
      "step": 58200
    },
    {
      "epoch": 2.5053800464836016,
      "grad_norm": 0.8942891359329224,
      "learning_rate": 1.3924141612937903e-05,
      "loss": 3.03,
      "step": 58210
    },
    {
      "epoch": 2.50581045020229,
      "grad_norm": 0.8929660320281982,
      "learning_rate": 1.390049889000129e-05,
      "loss": 2.9277,
      "step": 58220
    },
    {
      "epoch": 2.506240853920978,
      "grad_norm": 0.8777288794517517,
      "learning_rate": 1.3876874757026648e-05,
      "loss": 2.9071,
      "step": 58230
    },
    {
      "epoch": 2.506671257639666,
      "grad_norm": 0.9657217264175415,
      "learning_rate": 1.3853269219114672e-05,
      "loss": 3.0219,
      "step": 58240
    },
    {
      "epoch": 2.5071016613583543,
      "grad_norm": 0.9018031358718872,
      "learning_rate": 1.3829682281362144e-05,
      "loss": 2.9656,
      "step": 58250
    },
    {
      "epoch": 2.5071016613583543,
      "eval_bleu": 27.320565941728834,
      "eval_gen_len": 27.561,
      "eval_loss": 2.786090135574341,
      "eval_runtime": 58.432,
      "eval_samples_per_second": 17.114,
      "eval_steps_per_second": 1.078,
      "step": 58250
    },
    {
      "epoch": 2.5075320650770423,
      "grad_norm": 0.8897095322608948,
      "learning_rate": 1.3806113948861732e-05,
      "loss": 2.9139,
      "step": 58260
    },
    {
      "epoch": 2.5079624687957303,
      "grad_norm": 0.9099165201187134,
      "learning_rate": 1.3782564226702177e-05,
      "loss": 3.0262,
      "step": 58270
    },
    {
      "epoch": 2.5083928725144187,
      "grad_norm": 0.9257768988609314,
      "learning_rate": 1.3759033119968134e-05,
      "loss": 3.0215,
      "step": 58280
    },
    {
      "epoch": 2.5088232762331066,
      "grad_norm": 0.884759783744812,
      "learning_rate": 1.3735520633740252e-05,
      "loss": 3.041,
      "step": 58290
    },
    {
      "epoch": 2.5092536799517946,
      "grad_norm": 0.8963695764541626,
      "learning_rate": 1.371202677309521e-05,
      "loss": 2.9454,
      "step": 58300
    },
    {
      "epoch": 2.5092536799517946,
      "eval_bleu": 27.378347834336488,
      "eval_gen_len": 27.554,
      "eval_loss": 2.786057233810425,
      "eval_runtime": 58.8054,
      "eval_samples_per_second": 17.005,
      "eval_steps_per_second": 1.071,
      "step": 58300
    },
    {
      "epoch": 2.509684083670483,
      "grad_norm": 0.830397367477417,
      "learning_rate": 1.3688551543105577e-05,
      "loss": 3.0145,
      "step": 58310
    },
    {
      "epoch": 2.510114487389171,
      "grad_norm": 0.849073588848114,
      "learning_rate": 1.3665094948840007e-05,
      "loss": 3.0159,
      "step": 58320
    },
    {
      "epoch": 2.510544891107859,
      "grad_norm": 0.9635786414146423,
      "learning_rate": 1.3641656995363017e-05,
      "loss": 2.99,
      "step": 58330
    },
    {
      "epoch": 2.5109752948265474,
      "grad_norm": 0.9761527180671692,
      "learning_rate": 1.3618237687735202e-05,
      "loss": 3.0261,
      "step": 58340
    },
    {
      "epoch": 2.5114056985452353,
      "grad_norm": 0.9858880639076233,
      "learning_rate": 1.3594837031013041e-05,
      "loss": 2.9373,
      "step": 58350
    },
    {
      "epoch": 2.5114056985452353,
      "eval_bleu": 27.255367331514375,
      "eval_gen_len": 27.523,
      "eval_loss": 2.7874350547790527,
      "eval_runtime": 58.8854,
      "eval_samples_per_second": 16.982,
      "eval_steps_per_second": 1.07,
      "step": 58350
    },
    {
      "epoch": 2.5118361022639233,
      "grad_norm": 0.9210695624351501,
      "learning_rate": 1.357145503024908e-05,
      "loss": 3.0378,
      "step": 58360
    },
    {
      "epoch": 2.5122665059826117,
      "grad_norm": 0.9339504837989807,
      "learning_rate": 1.354809169049176e-05,
      "loss": 3.0744,
      "step": 58370
    },
    {
      "epoch": 2.5126969097012997,
      "grad_norm": 0.9617188572883606,
      "learning_rate": 1.3524747016785489e-05,
      "loss": 2.961,
      "step": 58380
    },
    {
      "epoch": 2.513127313419988,
      "grad_norm": 1.0017824172973633,
      "learning_rate": 1.3501421014170724e-05,
      "loss": 3.0197,
      "step": 58390
    },
    {
      "epoch": 2.513557717138676,
      "grad_norm": 0.836194634437561,
      "learning_rate": 1.3478113687683803e-05,
      "loss": 2.9162,
      "step": 58400
    },
    {
      "epoch": 2.513557717138676,
      "eval_bleu": 27.359116512795303,
      "eval_gen_len": 27.472,
      "eval_loss": 2.78780198097229,
      "eval_runtime": 58.6778,
      "eval_samples_per_second": 17.042,
      "eval_steps_per_second": 1.074,
      "step": 58400
    },
    {
      "epoch": 2.5139881208573644,
      "grad_norm": 0.8927512764930725,
      "learning_rate": 1.3454825042357111e-05,
      "loss": 2.9045,
      "step": 58410
    },
    {
      "epoch": 2.5144185245760524,
      "grad_norm": 0.8601812720298767,
      "learning_rate": 1.3431555083218906e-05,
      "loss": 2.9823,
      "step": 58420
    },
    {
      "epoch": 2.5148489282947404,
      "grad_norm": 1.066543698310852,
      "learning_rate": 1.3408303815293521e-05,
      "loss": 3.0535,
      "step": 58430
    },
    {
      "epoch": 2.515279332013429,
      "grad_norm": 0.9156854152679443,
      "learning_rate": 1.3385071243601165e-05,
      "loss": 2.8879,
      "step": 58440
    },
    {
      "epoch": 2.5157097357321168,
      "grad_norm": 0.8950883746147156,
      "learning_rate": 1.3361857373158026e-05,
      "loss": 2.9387,
      "step": 58450
    },
    {
      "epoch": 2.5157097357321168,
      "eval_bleu": 27.23216747452913,
      "eval_gen_len": 27.508,
      "eval_loss": 2.7875449657440186,
      "eval_runtime": 58.0653,
      "eval_samples_per_second": 17.222,
      "eval_steps_per_second": 1.085,
      "step": 58450
    },
    {
      "epoch": 2.5161401394508047,
      "grad_norm": 0.8217227458953857,
      "learning_rate": 1.3338662208976305e-05,
      "loss": 3.0066,
      "step": 58460
    },
    {
      "epoch": 2.516570543169493,
      "grad_norm": 0.9500518441200256,
      "learning_rate": 1.3315485756064094e-05,
      "loss": 2.9966,
      "step": 58470
    },
    {
      "epoch": 2.517000946888181,
      "grad_norm": 0.8358517289161682,
      "learning_rate": 1.3292328019425526e-05,
      "loss": 2.939,
      "step": 58480
    },
    {
      "epoch": 2.517431350606869,
      "grad_norm": 0.8527423143386841,
      "learning_rate": 1.326918900406059e-05,
      "loss": 2.9244,
      "step": 58490
    },
    {
      "epoch": 2.5178617543255575,
      "grad_norm": 0.9077750444412231,
      "learning_rate": 1.3246068714965343e-05,
      "loss": 2.9326,
      "step": 58500
    },
    {
      "epoch": 2.5178617543255575,
      "eval_bleu": 26.892228594880645,
      "eval_gen_len": 27.495,
      "eval_loss": 2.786945104598999,
      "eval_runtime": 58.4196,
      "eval_samples_per_second": 17.118,
      "eval_steps_per_second": 1.078,
      "step": 58500
    },
    {
      "epoch": 2.5182921580442454,
      "grad_norm": 0.9368159174919128,
      "learning_rate": 1.3222967157131693e-05,
      "loss": 2.9636,
      "step": 58510
    },
    {
      "epoch": 2.5187225617629334,
      "grad_norm": 0.8888652324676514,
      "learning_rate": 1.319988433554763e-05,
      "loss": 2.9182,
      "step": 58520
    },
    {
      "epoch": 2.519152965481622,
      "grad_norm": 0.906431257724762,
      "learning_rate": 1.3176820255196943e-05,
      "loss": 3.0118,
      "step": 58530
    },
    {
      "epoch": 2.51958336920031,
      "grad_norm": 1.0398213863372803,
      "learning_rate": 1.3153774921059503e-05,
      "loss": 2.9901,
      "step": 58540
    },
    {
      "epoch": 2.5200137729189978,
      "grad_norm": 0.9945611357688904,
      "learning_rate": 1.3130748338111054e-05,
      "loss": 2.8998,
      "step": 58550
    },
    {
      "epoch": 2.5200137729189978,
      "eval_bleu": 27.25378481990249,
      "eval_gen_len": 27.555,
      "eval_loss": 2.786389112472534,
      "eval_runtime": 58.6545,
      "eval_samples_per_second": 17.049,
      "eval_steps_per_second": 1.074,
      "step": 58550
    },
    {
      "epoch": 2.520444176637686,
      "grad_norm": 0.8502539396286011,
      "learning_rate": 1.3107740511323352e-05,
      "loss": 3.017,
      "step": 58560
    },
    {
      "epoch": 2.520874580356374,
      "grad_norm": 0.9925743937492371,
      "learning_rate": 1.308475144566409e-05,
      "loss": 3.0148,
      "step": 58570
    },
    {
      "epoch": 2.5213049840750625,
      "grad_norm": 0.9863366484642029,
      "learning_rate": 1.3061781146096851e-05,
      "loss": 2.9934,
      "step": 58580
    },
    {
      "epoch": 2.5217353877937505,
      "grad_norm": 1.0211745500564575,
      "learning_rate": 1.303882961758125e-05,
      "loss": 2.8778,
      "step": 58590
    },
    {
      "epoch": 2.522165791512439,
      "grad_norm": 0.8136915564537048,
      "learning_rate": 1.3015896865072807e-05,
      "loss": 2.9629,
      "step": 58600
    },
    {
      "epoch": 2.522165791512439,
      "eval_bleu": 27.31061351057272,
      "eval_gen_len": 27.52,
      "eval_loss": 2.786284923553467,
      "eval_runtime": 58.2817,
      "eval_samples_per_second": 17.158,
      "eval_steps_per_second": 1.081,
      "step": 58600
    },
    {
      "epoch": 2.522596195231127,
      "grad_norm": 0.8457180857658386,
      "learning_rate": 1.2992982893522965e-05,
      "loss": 3.0209,
      "step": 58610
    },
    {
      "epoch": 2.523026598949815,
      "grad_norm": 0.8533478379249573,
      "learning_rate": 1.297008770787913e-05,
      "loss": 3.0316,
      "step": 58620
    },
    {
      "epoch": 2.5234570026685033,
      "grad_norm": 0.8933006525039673,
      "learning_rate": 1.2947211313084706e-05,
      "loss": 3.0318,
      "step": 58630
    },
    {
      "epoch": 2.5238874063871912,
      "grad_norm": 0.9266795516014099,
      "learning_rate": 1.292435371407894e-05,
      "loss": 3.0277,
      "step": 58640
    },
    {
      "epoch": 2.524317810105879,
      "grad_norm": 1.0062187910079956,
      "learning_rate": 1.2901514915797108e-05,
      "loss": 2.9684,
      "step": 58650
    },
    {
      "epoch": 2.524317810105879,
      "eval_bleu": 27.17097864549018,
      "eval_gen_len": 27.549,
      "eval_loss": 2.785952568054199,
      "eval_runtime": 58.8315,
      "eval_samples_per_second": 16.998,
      "eval_steps_per_second": 1.071,
      "step": 58650
    },
    {
      "epoch": 2.5247482138245676,
      "grad_norm": 0.9149567484855652,
      "learning_rate": 1.2878694923170409e-05,
      "loss": 2.9282,
      "step": 58660
    },
    {
      "epoch": 2.5251786175432556,
      "grad_norm": 0.8799993395805359,
      "learning_rate": 1.2855893741125923e-05,
      "loss": 3.0505,
      "step": 58670
    },
    {
      "epoch": 2.5256090212619435,
      "grad_norm": 0.8252776265144348,
      "learning_rate": 1.2833111374586771e-05,
      "loss": 2.9325,
      "step": 58680
    },
    {
      "epoch": 2.526039424980632,
      "grad_norm": 0.8952389359474182,
      "learning_rate": 1.2810347828471869e-05,
      "loss": 2.997,
      "step": 58690
    },
    {
      "epoch": 2.52646982869932,
      "grad_norm": 0.9435077905654907,
      "learning_rate": 1.2787603107696212e-05,
      "loss": 2.9889,
      "step": 58700
    },
    {
      "epoch": 2.52646982869932,
      "eval_bleu": 27.181243184086988,
      "eval_gen_len": 27.465,
      "eval_loss": 2.7855348587036133,
      "eval_runtime": 58.6263,
      "eval_samples_per_second": 17.057,
      "eval_steps_per_second": 1.075,
      "step": 58700
    },
    {
      "epoch": 2.526900232418008,
      "grad_norm": 0.9316962361335754,
      "learning_rate": 1.2764877217170634e-05,
      "loss": 3.02,
      "step": 58710
    },
    {
      "epoch": 2.5273306361366963,
      "grad_norm": 0.9670791625976562,
      "learning_rate": 1.2742170161801981e-05,
      "loss": 3.0042,
      "step": 58720
    },
    {
      "epoch": 2.5277610398553843,
      "grad_norm": 0.9416185021400452,
      "learning_rate": 1.271948194649295e-05,
      "loss": 3.04,
      "step": 58730
    },
    {
      "epoch": 2.528191443574072,
      "grad_norm": 0.899415910243988,
      "learning_rate": 1.2696812576142247e-05,
      "loss": 2.9785,
      "step": 58740
    },
    {
      "epoch": 2.5286218472927606,
      "grad_norm": 1.035548210144043,
      "learning_rate": 1.2674162055644445e-05,
      "loss": 2.9621,
      "step": 58750
    },
    {
      "epoch": 2.5286218472927606,
      "eval_bleu": 27.210675205039394,
      "eval_gen_len": 27.511,
      "eval_loss": 2.7856523990631104,
      "eval_runtime": 58.3703,
      "eval_samples_per_second": 17.132,
      "eval_steps_per_second": 1.079,
      "step": 58750
    },
    {
      "epoch": 2.5290522510114486,
      "grad_norm": 0.9600508213043213,
      "learning_rate": 1.2651530389890099e-05,
      "loss": 2.9352,
      "step": 58760
    },
    {
      "epoch": 2.529482654730137,
      "grad_norm": 0.958176851272583,
      "learning_rate": 1.2628917583765665e-05,
      "loss": 3.007,
      "step": 58770
    },
    {
      "epoch": 2.529913058448825,
      "grad_norm": 0.9827446341514587,
      "learning_rate": 1.2606323642153495e-05,
      "loss": 3.003,
      "step": 58780
    },
    {
      "epoch": 2.5303434621675134,
      "grad_norm": 0.8888169527053833,
      "learning_rate": 1.2583748569931964e-05,
      "loss": 2.9173,
      "step": 58790
    },
    {
      "epoch": 2.5307738658862013,
      "grad_norm": 0.9423475861549377,
      "learning_rate": 1.256119237197525e-05,
      "loss": 2.9856,
      "step": 58800
    },
    {
      "epoch": 2.5307738658862013,
      "eval_bleu": 27.150852509722096,
      "eval_gen_len": 27.445,
      "eval_loss": 2.785998582839966,
      "eval_runtime": 58.97,
      "eval_samples_per_second": 16.958,
      "eval_steps_per_second": 1.068,
      "step": 58800
    },
    {
      "epoch": 2.5312042696048893,
      "grad_norm": 0.9641964435577393,
      "learning_rate": 1.253865505315358e-05,
      "loss": 3.0469,
      "step": 58810
    },
    {
      "epoch": 2.5316346733235777,
      "grad_norm": 0.8778603672981262,
      "learning_rate": 1.2516136618332997e-05,
      "loss": 3.0001,
      "step": 58820
    },
    {
      "epoch": 2.5320650770422657,
      "grad_norm": 0.9043121933937073,
      "learning_rate": 1.2493637072375541e-05,
      "loss": 2.9543,
      "step": 58830
    },
    {
      "epoch": 2.5324954807609537,
      "grad_norm": 0.9532671570777893,
      "learning_rate": 1.2471156420139141e-05,
      "loss": 2.9461,
      "step": 58840
    },
    {
      "epoch": 2.532925884479642,
      "grad_norm": 0.8704511523246765,
      "learning_rate": 1.2448694666477634e-05,
      "loss": 2.9889,
      "step": 58850
    },
    {
      "epoch": 2.532925884479642,
      "eval_bleu": 27.26562219794613,
      "eval_gen_len": 27.482,
      "eval_loss": 2.7865567207336426,
      "eval_runtime": 59.1744,
      "eval_samples_per_second": 16.899,
      "eval_steps_per_second": 1.065,
      "step": 58850
    },
    {
      "epoch": 2.53335628819833,
      "grad_norm": 0.878816545009613,
      "learning_rate": 1.2426251816240819e-05,
      "loss": 2.967,
      "step": 58860
    },
    {
      "epoch": 2.533786691917018,
      "grad_norm": 0.9803932309150696,
      "learning_rate": 1.2403827874274366e-05,
      "loss": 2.9847,
      "step": 58870
    },
    {
      "epoch": 2.5342170956357064,
      "grad_norm": 0.915773332118988,
      "learning_rate": 1.238142284541991e-05,
      "loss": 2.9129,
      "step": 58880
    },
    {
      "epoch": 2.5346474993543944,
      "grad_norm": 0.8454483151435852,
      "learning_rate": 1.235903673451495e-05,
      "loss": 2.9842,
      "step": 58890
    },
    {
      "epoch": 2.5350779030730823,
      "grad_norm": 0.8432437777519226,
      "learning_rate": 1.2336669546392953e-05,
      "loss": 3.0053,
      "step": 58900
    },
    {
      "epoch": 2.5350779030730823,
      "eval_bleu": 27.102742834351982,
      "eval_gen_len": 27.44,
      "eval_loss": 2.78645920753479,
      "eval_runtime": 57.9845,
      "eval_samples_per_second": 17.246,
      "eval_steps_per_second": 1.086,
      "step": 58900
    },
    {
      "epoch": 2.5355083067917707,
      "grad_norm": 0.9645780324935913,
      "learning_rate": 1.2314321285883256e-05,
      "loss": 2.9762,
      "step": 58910
    },
    {
      "epoch": 2.5359387105104587,
      "grad_norm": 0.8634167313575745,
      "learning_rate": 1.2291991957811156e-05,
      "loss": 2.9625,
      "step": 58920
    },
    {
      "epoch": 2.5363691142291467,
      "grad_norm": 0.8157650828361511,
      "learning_rate": 1.2269681566997816e-05,
      "loss": 2.9405,
      "step": 58930
    },
    {
      "epoch": 2.536799517947835,
      "grad_norm": 0.9502773284912109,
      "learning_rate": 1.2247390118260304e-05,
      "loss": 3.0116,
      "step": 58940
    },
    {
      "epoch": 2.537229921666523,
      "grad_norm": 0.8936442732810974,
      "learning_rate": 1.2225117616411664e-05,
      "loss": 2.9682,
      "step": 58950
    },
    {
      "epoch": 2.537229921666523,
      "eval_bleu": 27.217335385093552,
      "eval_gen_len": 27.485,
      "eval_loss": 2.7869670391082764,
      "eval_runtime": 58.9767,
      "eval_samples_per_second": 16.956,
      "eval_steps_per_second": 1.068,
      "step": 58950
    },
    {
      "epoch": 2.5376603253852115,
      "grad_norm": 0.9483445882797241,
      "learning_rate": 1.2202864066260788e-05,
      "loss": 2.9603,
      "step": 58960
    },
    {
      "epoch": 2.5380907291038994,
      "grad_norm": 1.0337677001953125,
      "learning_rate": 1.2180629472612515e-05,
      "loss": 3.046,
      "step": 58970
    },
    {
      "epoch": 2.538521132822588,
      "grad_norm": 1.0089256763458252,
      "learning_rate": 1.2158413840267535e-05,
      "loss": 2.9689,
      "step": 58980
    },
    {
      "epoch": 2.538951536541276,
      "grad_norm": 0.8574661612510681,
      "learning_rate": 1.2136217174022535e-05,
      "loss": 3.0202,
      "step": 58990
    },
    {
      "epoch": 2.5393819402599638,
      "grad_norm": 0.9824321866035461,
      "learning_rate": 1.2114039478669992e-05,
      "loss": 3.0396,
      "step": 59000
    },
    {
      "epoch": 2.5393819402599638,
      "eval_bleu": 27.29643193573275,
      "eval_gen_len": 27.498,
      "eval_loss": 2.7864291667938232,
      "eval_runtime": 58.525,
      "eval_samples_per_second": 17.087,
      "eval_steps_per_second": 1.076,
      "step": 59000
    },
    {
      "epoch": 2.539812343978652,
      "grad_norm": 0.9481936693191528,
      "learning_rate": 1.209188075899842e-05,
      "loss": 3.0078,
      "step": 59010
    },
    {
      "epoch": 2.54024274769734,
      "grad_norm": 0.97640460729599,
      "learning_rate": 1.2069741019792114e-05,
      "loss": 3.0081,
      "step": 59020
    },
    {
      "epoch": 2.540673151416028,
      "grad_norm": 0.9617637395858765,
      "learning_rate": 1.2047620265831305e-05,
      "loss": 3.0121,
      "step": 59030
    },
    {
      "epoch": 2.5411035551347165,
      "grad_norm": 0.9980664849281311,
      "learning_rate": 1.2025518501892208e-05,
      "loss": 2.9539,
      "step": 59040
    },
    {
      "epoch": 2.5415339588534045,
      "grad_norm": 0.95103520154953,
      "learning_rate": 1.2003435732746793e-05,
      "loss": 3.0205,
      "step": 59050
    },
    {
      "epoch": 2.5415339588534045,
      "eval_bleu": 27.36827135095798,
      "eval_gen_len": 27.487,
      "eval_loss": 2.7866601943969727,
      "eval_runtime": 59.2116,
      "eval_samples_per_second": 16.889,
      "eval_steps_per_second": 1.064,
      "step": 59050
    },
    {
      "epoch": 2.5419643625720925,
      "grad_norm": 0.9017301201820374,
      "learning_rate": 1.198137196316308e-05,
      "loss": 3.0232,
      "step": 59060
    },
    {
      "epoch": 2.542394766290781,
      "grad_norm": 0.8679594993591309,
      "learning_rate": 1.1959327197904857e-05,
      "loss": 3.0221,
      "step": 59070
    },
    {
      "epoch": 2.542825170009469,
      "grad_norm": 0.8292712569236755,
      "learning_rate": 1.1937301441731896e-05,
      "loss": 2.9933,
      "step": 59080
    },
    {
      "epoch": 2.543255573728157,
      "grad_norm": 0.9590380191802979,
      "learning_rate": 1.1915294699399837e-05,
      "loss": 2.8697,
      "step": 59090
    },
    {
      "epoch": 2.543685977446845,
      "grad_norm": 0.9970027208328247,
      "learning_rate": 1.1893306975660179e-05,
      "loss": 3.0523,
      "step": 59100
    },
    {
      "epoch": 2.543685977446845,
      "eval_bleu": 27.25145602058653,
      "eval_gen_len": 27.49,
      "eval_loss": 2.7871172428131104,
      "eval_runtime": 58.8632,
      "eval_samples_per_second": 16.989,
      "eval_steps_per_second": 1.07,
      "step": 59100
    },
    {
      "epoch": 2.544116381165533,
      "grad_norm": 0.8595774173736572,
      "learning_rate": 1.187133827526039e-05,
      "loss": 2.9466,
      "step": 59110
    },
    {
      "epoch": 2.544546784884221,
      "grad_norm": 0.8883416056632996,
      "learning_rate": 1.1849388602943745e-05,
      "loss": 2.9932,
      "step": 59120
    },
    {
      "epoch": 2.5449771886029096,
      "grad_norm": 0.8847935199737549,
      "learning_rate": 1.1827457963449495e-05,
      "loss": 3.0082,
      "step": 59130
    },
    {
      "epoch": 2.5454075923215975,
      "grad_norm": 0.8817765116691589,
      "learning_rate": 1.1805546361512698e-05,
      "loss": 2.998,
      "step": 59140
    },
    {
      "epoch": 2.545837996040286,
      "grad_norm": 1.1415702104568481,
      "learning_rate": 1.178365380186438e-05,
      "loss": 2.9852,
      "step": 59150
    },
    {
      "epoch": 2.545837996040286,
      "eval_bleu": 27.23741938983176,
      "eval_gen_len": 27.445,
      "eval_loss": 2.7866389751434326,
      "eval_runtime": 58.5574,
      "eval_samples_per_second": 17.077,
      "eval_steps_per_second": 1.076,
      "step": 59150
    },
    {
      "epoch": 2.546268399758974,
      "grad_norm": 0.9186027646064758,
      "learning_rate": 1.1761780289231394e-05,
      "loss": 2.9889,
      "step": 59160
    },
    {
      "epoch": 2.5466988034776623,
      "grad_norm": 0.8888105750083923,
      "learning_rate": 1.1739925828336551e-05,
      "loss": 2.9817,
      "step": 59170
    },
    {
      "epoch": 2.5471292071963503,
      "grad_norm": 0.828870415687561,
      "learning_rate": 1.1718090423898431e-05,
      "loss": 2.8777,
      "step": 59180
    },
    {
      "epoch": 2.5475596109150382,
      "grad_norm": 0.898161768913269,
      "learning_rate": 1.1696274080631608e-05,
      "loss": 2.9696,
      "step": 59190
    },
    {
      "epoch": 2.5479900146337267,
      "grad_norm": 0.8554777503013611,
      "learning_rate": 1.1674476803246525e-05,
      "loss": 3.0633,
      "step": 59200
    },
    {
      "epoch": 2.5479900146337267,
      "eval_bleu": 27.45093398095471,
      "eval_gen_len": 27.456,
      "eval_loss": 2.787585973739624,
      "eval_runtime": 58.4843,
      "eval_samples_per_second": 17.099,
      "eval_steps_per_second": 1.077,
      "step": 59200
    },
    {
      "epoch": 2.5484204183524146,
      "grad_norm": 0.8882696628570557,
      "learning_rate": 1.1652698596449452e-05,
      "loss": 3.0193,
      "step": 59210
    },
    {
      "epoch": 2.5488508220711026,
      "grad_norm": 0.9789752960205078,
      "learning_rate": 1.1630939464942603e-05,
      "loss": 3.0009,
      "step": 59220
    },
    {
      "epoch": 2.549281225789791,
      "grad_norm": 0.950003445148468,
      "learning_rate": 1.1609199413424032e-05,
      "loss": 2.9431,
      "step": 59230
    },
    {
      "epoch": 2.549711629508479,
      "grad_norm": 0.8058416247367859,
      "learning_rate": 1.1587478446587696e-05,
      "loss": 2.9598,
      "step": 59240
    },
    {
      "epoch": 2.550142033227167,
      "grad_norm": 0.8656273484230042,
      "learning_rate": 1.1565776569123433e-05,
      "loss": 2.9396,
      "step": 59250
    },
    {
      "epoch": 2.550142033227167,
      "eval_bleu": 27.31515622009861,
      "eval_gen_len": 27.423,
      "eval_loss": 2.786770820617676,
      "eval_runtime": 58.2966,
      "eval_samples_per_second": 17.154,
      "eval_steps_per_second": 1.081,
      "step": 59250
    },
    {
      "epoch": 2.5505724369458553,
      "grad_norm": 1.010136604309082,
      "learning_rate": 1.1544093785716936e-05,
      "loss": 2.9638,
      "step": 59260
    },
    {
      "epoch": 2.5510028406645433,
      "grad_norm": 0.830293595790863,
      "learning_rate": 1.1522430101049774e-05,
      "loss": 3.0051,
      "step": 59270
    },
    {
      "epoch": 2.5514332443832313,
      "grad_norm": 0.9310460686683655,
      "learning_rate": 1.1500785519799428e-05,
      "loss": 2.9876,
      "step": 59280
    },
    {
      "epoch": 2.5518636481019197,
      "grad_norm": 0.932770311832428,
      "learning_rate": 1.147916004663926e-05,
      "loss": 2.9837,
      "step": 59290
    },
    {
      "epoch": 2.5522940518206076,
      "grad_norm": 0.9205096364021301,
      "learning_rate": 1.1457553686238431e-05,
      "loss": 2.88,
      "step": 59300
    },
    {
      "epoch": 2.5522940518206076,
      "eval_bleu": 27.200700730662405,
      "eval_gen_len": 27.432,
      "eval_loss": 2.786384105682373,
      "eval_runtime": 58.5492,
      "eval_samples_per_second": 17.08,
      "eval_steps_per_second": 1.076,
      "step": 59300
    },
    {
      "epoch": 2.5527244555392956,
      "grad_norm": 0.893565833568573,
      "learning_rate": 1.1435966443262059e-05,
      "loss": 2.9531,
      "step": 59310
    },
    {
      "epoch": 2.553154859257984,
      "grad_norm": 0.878715455532074,
      "learning_rate": 1.1414398322371078e-05,
      "loss": 2.9726,
      "step": 59320
    },
    {
      "epoch": 2.553585262976672,
      "grad_norm": 0.9358429312705994,
      "learning_rate": 1.1392849328222376e-05,
      "loss": 3.0012,
      "step": 59330
    },
    {
      "epoch": 2.5540156666953604,
      "grad_norm": 0.9099836349487305,
      "learning_rate": 1.1371319465468555e-05,
      "loss": 3.0,
      "step": 59340
    },
    {
      "epoch": 2.5544460704140484,
      "grad_norm": 0.9684905409812927,
      "learning_rate": 1.134980873875825e-05,
      "loss": 2.9406,
      "step": 59350
    },
    {
      "epoch": 2.5544460704140484,
      "eval_bleu": 27.404903019863692,
      "eval_gen_len": 27.454,
      "eval_loss": 2.7866647243499756,
      "eval_runtime": 58.5718,
      "eval_samples_per_second": 17.073,
      "eval_steps_per_second": 1.076,
      "step": 59350
    },
    {
      "epoch": 2.5548764741327368,
      "grad_norm": 0.9875108599662781,
      "learning_rate": 1.1328317152735857e-05,
      "loss": 2.9649,
      "step": 59360
    },
    {
      "epoch": 2.5553068778514247,
      "grad_norm": 0.8314375281333923,
      "learning_rate": 1.130684471204172e-05,
      "loss": 2.9256,
      "step": 59370
    },
    {
      "epoch": 2.5557372815701127,
      "grad_norm": 0.919479489326477,
      "learning_rate": 1.1285391421311964e-05,
      "loss": 3.033,
      "step": 59380
    },
    {
      "epoch": 2.556167685288801,
      "grad_norm": 0.9677829146385193,
      "learning_rate": 1.126395728517865e-05,
      "loss": 2.9256,
      "step": 59390
    },
    {
      "epoch": 2.556598089007489,
      "grad_norm": 0.8763830661773682,
      "learning_rate": 1.1242542308269689e-05,
      "loss": 3.0053,
      "step": 59400
    },
    {
      "epoch": 2.556598089007489,
      "eval_bleu": 27.210319434223667,
      "eval_gen_len": 27.449,
      "eval_loss": 2.785212516784668,
      "eval_runtime": 58.8036,
      "eval_samples_per_second": 17.006,
      "eval_steps_per_second": 1.071,
      "step": 59400
    },
    {
      "epoch": 2.557028492726177,
      "grad_norm": 0.8644652962684631,
      "learning_rate": 1.1221146495208835e-05,
      "loss": 3.0581,
      "step": 59410
    },
    {
      "epoch": 2.5574588964448655,
      "grad_norm": 0.7624630331993103,
      "learning_rate": 1.1199769850615704e-05,
      "loss": 2.9479,
      "step": 59420
    },
    {
      "epoch": 2.5578893001635534,
      "grad_norm": 0.930902898311615,
      "learning_rate": 1.1178412379105751e-05,
      "loss": 3.0251,
      "step": 59430
    },
    {
      "epoch": 2.5583197038822414,
      "grad_norm": 1.0097942352294922,
      "learning_rate": 1.1157074085290386e-05,
      "loss": 3.0586,
      "step": 59440
    },
    {
      "epoch": 2.55875010760093,
      "grad_norm": 0.9057452082633972,
      "learning_rate": 1.1135754973776757e-05,
      "loss": 2.9912,
      "step": 59450
    },
    {
      "epoch": 2.55875010760093,
      "eval_bleu": 27.435539942663528,
      "eval_gen_len": 27.501,
      "eval_loss": 2.7852745056152344,
      "eval_runtime": 58.8139,
      "eval_samples_per_second": 17.003,
      "eval_steps_per_second": 1.071,
      "step": 59450
    },
    {
      "epoch": 2.5591805113196178,
      "grad_norm": 0.9067330956459045,
      "learning_rate": 1.111445504916797e-05,
      "loss": 2.9619,
      "step": 59460
    },
    {
      "epoch": 2.5596109150383057,
      "grad_norm": 0.8862408995628357,
      "learning_rate": 1.1093174316062915e-05,
      "loss": 2.9454,
      "step": 59470
    },
    {
      "epoch": 2.560041318756994,
      "grad_norm": 0.8958637118339539,
      "learning_rate": 1.1071912779056393e-05,
      "loss": 3.0128,
      "step": 59480
    },
    {
      "epoch": 2.560471722475682,
      "grad_norm": 0.9616138339042664,
      "learning_rate": 1.1050670442739031e-05,
      "loss": 2.9071,
      "step": 59490
    },
    {
      "epoch": 2.56090212619437,
      "grad_norm": 0.9156672358512878,
      "learning_rate": 1.1029447311697294e-05,
      "loss": 2.9078,
      "step": 59500
    },
    {
      "epoch": 2.56090212619437,
      "eval_bleu": 27.343953358054264,
      "eval_gen_len": 27.558,
      "eval_loss": 2.785088062286377,
      "eval_runtime": 58.5619,
      "eval_samples_per_second": 17.076,
      "eval_steps_per_second": 1.076,
      "step": 59500
    },
    {
      "epoch": 2.5613325299130585,
      "grad_norm": 1.0235660076141357,
      "learning_rate": 1.1008243390513551e-05,
      "loss": 2.9918,
      "step": 59510
    },
    {
      "epoch": 2.5617629336317465,
      "grad_norm": 0.8446967005729675,
      "learning_rate": 1.0987058683765961e-05,
      "loss": 2.9694,
      "step": 59520
    },
    {
      "epoch": 2.562193337350435,
      "grad_norm": 0.9634571075439453,
      "learning_rate": 1.096589319602862e-05,
      "loss": 3.0558,
      "step": 59530
    },
    {
      "epoch": 2.562623741069123,
      "grad_norm": 0.9394205212593079,
      "learning_rate": 1.0944746931871364e-05,
      "loss": 2.998,
      "step": 59540
    },
    {
      "epoch": 2.5630541447878112,
      "grad_norm": 1.034706711769104,
      "learning_rate": 1.0923619895859982e-05,
      "loss": 3.0115,
      "step": 59550
    },
    {
      "epoch": 2.5630541447878112,
      "eval_bleu": 27.22373410326753,
      "eval_gen_len": 27.511,
      "eval_loss": 2.7860219478607178,
      "eval_runtime": 59.1508,
      "eval_samples_per_second": 16.906,
      "eval_steps_per_second": 1.065,
      "step": 59550
    },
    {
      "epoch": 2.563484548506499,
      "grad_norm": 0.9592316150665283,
      "learning_rate": 1.0902512092556028e-05,
      "loss": 3.0099,
      "step": 59560
    },
    {
      "epoch": 2.563914952225187,
      "grad_norm": 0.9243007898330688,
      "learning_rate": 1.0881423526516976e-05,
      "loss": 3.021,
      "step": 59570
    },
    {
      "epoch": 2.5643453559438756,
      "grad_norm": 0.849861741065979,
      "learning_rate": 1.0860354202296107e-05,
      "loss": 2.9864,
      "step": 59580
    },
    {
      "epoch": 2.5647757596625635,
      "grad_norm": 0.9731316566467285,
      "learning_rate": 1.0839304124442517e-05,
      "loss": 3.0124,
      "step": 59590
    },
    {
      "epoch": 2.5652061633812515,
      "grad_norm": 0.9164740443229675,
      "learning_rate": 1.0818273297501224e-05,
      "loss": 3.0161,
      "step": 59600
    },
    {
      "epoch": 2.5652061633812515,
      "eval_bleu": 27.165391864455426,
      "eval_gen_len": 27.479,
      "eval_loss": 2.785940408706665,
      "eval_runtime": 58.9935,
      "eval_samples_per_second": 16.951,
      "eval_steps_per_second": 1.068,
      "step": 59600
    },
    {
      "epoch": 2.56563656709994,
      "grad_norm": 0.9466323852539062,
      "learning_rate": 1.0797261726013009e-05,
      "loss": 3.0778,
      "step": 59610
    },
    {
      "epoch": 2.566066970818628,
      "grad_norm": 0.9238808155059814,
      "learning_rate": 1.0776269414514584e-05,
      "loss": 3.0217,
      "step": 59620
    },
    {
      "epoch": 2.566497374537316,
      "grad_norm": 0.9105949401855469,
      "learning_rate": 1.0755296367538393e-05,
      "loss": 2.9888,
      "step": 59630
    },
    {
      "epoch": 2.5669277782560043,
      "grad_norm": 0.9232838749885559,
      "learning_rate": 1.0734342589612834e-05,
      "loss": 3.0109,
      "step": 59640
    },
    {
      "epoch": 2.5673581819746922,
      "grad_norm": 0.9060539603233337,
      "learning_rate": 1.0713408085262055e-05,
      "loss": 2.9418,
      "step": 59650
    },
    {
      "epoch": 2.5673581819746922,
      "eval_bleu": 27.316238795166946,
      "eval_gen_len": 27.557,
      "eval_loss": 2.786586046218872,
      "eval_runtime": 58.7862,
      "eval_samples_per_second": 17.011,
      "eval_steps_per_second": 1.072,
      "step": 59650
    },
    {
      "epoch": 2.56778858569338,
      "grad_norm": 0.8947400450706482,
      "learning_rate": 1.0692492859006098e-05,
      "loss": 2.9311,
      "step": 59660
    },
    {
      "epoch": 2.5682189894120686,
      "grad_norm": 0.9084614515304565,
      "learning_rate": 1.0671596915360815e-05,
      "loss": 2.9512,
      "step": 59670
    },
    {
      "epoch": 2.5686493931307566,
      "grad_norm": 1.0073245763778687,
      "learning_rate": 1.0650720258837887e-05,
      "loss": 3.0022,
      "step": 59680
    },
    {
      "epoch": 2.5690797968494445,
      "grad_norm": 0.9930155277252197,
      "learning_rate": 1.0629862893944875e-05,
      "loss": 3.0209,
      "step": 59690
    },
    {
      "epoch": 2.569510200568133,
      "grad_norm": 0.8984255194664001,
      "learning_rate": 1.060902482518511e-05,
      "loss": 2.9561,
      "step": 59700
    },
    {
      "epoch": 2.569510200568133,
      "eval_bleu": 27.350512543168755,
      "eval_gen_len": 27.533,
      "eval_loss": 2.7868995666503906,
      "eval_runtime": 59.1222,
      "eval_samples_per_second": 16.914,
      "eval_steps_per_second": 1.066,
      "step": 59700
    },
    {
      "epoch": 2.569940604286821,
      "grad_norm": 0.8174951672554016,
      "learning_rate": 1.0588206057057836e-05,
      "loss": 3.0157,
      "step": 59710
    },
    {
      "epoch": 2.5703710080055093,
      "grad_norm": 1.0099610090255737,
      "learning_rate": 1.056740659405805e-05,
      "loss": 3.0,
      "step": 59720
    },
    {
      "epoch": 2.5708014117241973,
      "grad_norm": 0.9859301447868347,
      "learning_rate": 1.0546626440676644e-05,
      "loss": 2.9898,
      "step": 59730
    },
    {
      "epoch": 2.5712318154428853,
      "grad_norm": 0.9057148694992065,
      "learning_rate": 1.0525865601400297e-05,
      "loss": 3.0006,
      "step": 59740
    },
    {
      "epoch": 2.5716622191615737,
      "grad_norm": 1.016860008239746,
      "learning_rate": 1.0505124080711526e-05,
      "loss": 2.9444,
      "step": 59750
    },
    {
      "epoch": 2.5716622191615737,
      "eval_bleu": 27.470734761149398,
      "eval_gen_len": 27.527,
      "eval_loss": 2.7861058712005615,
      "eval_runtime": 58.8724,
      "eval_samples_per_second": 16.986,
      "eval_steps_per_second": 1.07,
      "step": 59750
    },
    {
      "epoch": 2.5720926228802616,
      "grad_norm": 0.9477930665016174,
      "learning_rate": 1.0484401883088702e-05,
      "loss": 2.8721,
      "step": 59760
    },
    {
      "epoch": 2.57252302659895,
      "grad_norm": 0.866646409034729,
      "learning_rate": 1.046369901300599e-05,
      "loss": 2.965,
      "step": 59770
    },
    {
      "epoch": 2.572953430317638,
      "grad_norm": 1.0717910528182983,
      "learning_rate": 1.0443015474933438e-05,
      "loss": 3.0066,
      "step": 59780
    },
    {
      "epoch": 2.573383834036326,
      "grad_norm": 0.9908829927444458,
      "learning_rate": 1.0422351273336827e-05,
      "loss": 3.0564,
      "step": 59790
    },
    {
      "epoch": 2.5738142377550144,
      "grad_norm": 0.9614909887313843,
      "learning_rate": 1.040170641267787e-05,
      "loss": 2.9999,
      "step": 59800
    },
    {
      "epoch": 2.5738142377550144,
      "eval_bleu": 27.450622268939885,
      "eval_gen_len": 27.494,
      "eval_loss": 2.786128044128418,
      "eval_runtime": 58.7707,
      "eval_samples_per_second": 17.015,
      "eval_steps_per_second": 1.072,
      "step": 59800
    },
    {
      "epoch": 2.5742446414737024,
      "grad_norm": 0.9551324844360352,
      "learning_rate": 1.0381080897413998e-05,
      "loss": 3.0156,
      "step": 59810
    },
    {
      "epoch": 2.5746750451923903,
      "grad_norm": 0.8500957489013672,
      "learning_rate": 1.036047473199857e-05,
      "loss": 2.9999,
      "step": 59820
    },
    {
      "epoch": 2.5751054489110787,
      "grad_norm": 0.8887503147125244,
      "learning_rate": 1.0339887920880698e-05,
      "loss": 2.9137,
      "step": 59830
    },
    {
      "epoch": 2.5755358526297667,
      "grad_norm": 0.8869110941886902,
      "learning_rate": 1.03193204685053e-05,
      "loss": 2.9255,
      "step": 59840
    },
    {
      "epoch": 2.5759662563484547,
      "grad_norm": 1.0461699962615967,
      "learning_rate": 1.0298772379313192e-05,
      "loss": 3.1066,
      "step": 59850
    },
    {
      "epoch": 2.5759662563484547,
      "eval_bleu": 27.322092811304444,
      "eval_gen_len": 27.505,
      "eval_loss": 2.7865970134735107,
      "eval_runtime": 58.8459,
      "eval_samples_per_second": 16.994,
      "eval_steps_per_second": 1.071,
      "step": 59850
    },
    {
      "epoch": 2.576396660067143,
      "grad_norm": 0.9207367300987244,
      "learning_rate": 1.0278243657740926e-05,
      "loss": 3.1179,
      "step": 59860
    },
    {
      "epoch": 2.576827063785831,
      "grad_norm": 0.9432678818702698,
      "learning_rate": 1.0257734308220956e-05,
      "loss": 2.9164,
      "step": 59870
    },
    {
      "epoch": 2.577257467504519,
      "grad_norm": 0.8607399463653564,
      "learning_rate": 1.0237244335181462e-05,
      "loss": 3.0045,
      "step": 59880
    },
    {
      "epoch": 2.5776878712232074,
      "grad_norm": 0.8438519835472107,
      "learning_rate": 1.0216773743046525e-05,
      "loss": 2.9246,
      "step": 59890
    },
    {
      "epoch": 2.5781182749418954,
      "grad_norm": 0.8598402738571167,
      "learning_rate": 1.019632253623598e-05,
      "loss": 2.9442,
      "step": 59900
    },
    {
      "epoch": 2.5781182749418954,
      "eval_bleu": 27.49132148908903,
      "eval_gen_len": 27.518,
      "eval_loss": 2.786641836166382,
      "eval_runtime": 58.6688,
      "eval_samples_per_second": 17.045,
      "eval_steps_per_second": 1.074,
      "step": 59900
    },
    {
      "epoch": 2.578548678660584,
      "grad_norm": 0.8797951340675354,
      "learning_rate": 1.0175890719165504e-05,
      "loss": 2.9464,
      "step": 59910
    },
    {
      "epoch": 2.5789790823792718,
      "grad_norm": 0.8769685626029968,
      "learning_rate": 1.0155478296246557e-05,
      "loss": 2.9971,
      "step": 59920
    },
    {
      "epoch": 2.5794094860979597,
      "grad_norm": 0.8607537150382996,
      "learning_rate": 1.013508527188647e-05,
      "loss": 3.0145,
      "step": 59930
    },
    {
      "epoch": 2.579839889816648,
      "grad_norm": 1.038115382194519,
      "learning_rate": 1.011471165048835e-05,
      "loss": 2.9284,
      "step": 59940
    },
    {
      "epoch": 2.580270293535336,
      "grad_norm": 0.9206795692443848,
      "learning_rate": 1.0094357436451107e-05,
      "loss": 2.9233,
      "step": 59950
    },
    {
      "epoch": 2.580270293535336,
      "eval_bleu": 27.363242151736067,
      "eval_gen_len": 27.506,
      "eval_loss": 2.786616802215576,
      "eval_runtime": 59.2796,
      "eval_samples_per_second": 16.869,
      "eval_steps_per_second": 1.063,
      "step": 59950
    },
    {
      "epoch": 2.5807006972540245,
      "grad_norm": 0.9280835390090942,
      "learning_rate": 1.0074022634169489e-05,
      "loss": 2.9512,
      "step": 59960
    },
    {
      "epoch": 2.5811311009727125,
      "grad_norm": 0.8750175833702087,
      "learning_rate": 1.0053707248033994e-05,
      "loss": 2.8845,
      "step": 59970
    },
    {
      "epoch": 2.5815615046914004,
      "grad_norm": 0.8965067267417908,
      "learning_rate": 1.0033411282431039e-05,
      "loss": 2.9606,
      "step": 59980
    },
    {
      "epoch": 2.581991908410089,
      "grad_norm": 0.9671820998191833,
      "learning_rate": 1.0013134741742702e-05,
      "loss": 3.0105,
      "step": 59990
    },
    {
      "epoch": 2.582422312128777,
      "grad_norm": 1.0123026371002197,
      "learning_rate": 9.992877630346985e-06,
      "loss": 3.0261,
      "step": 60000
    },
    {
      "epoch": 2.582422312128777,
      "eval_bleu": 27.32644688391081,
      "eval_gen_len": 27.511,
      "eval_loss": 2.785921573638916,
      "eval_runtime": 59.2394,
      "eval_samples_per_second": 16.881,
      "eval_steps_per_second": 1.063,
      "step": 60000
    },
    {
      "epoch": 2.582852715847465,
      "grad_norm": 0.9914826154708862,
      "learning_rate": 9.972639952617624e-06,
      "loss": 2.9336,
      "step": 60010
    },
    {
      "epoch": 2.583283119566153,
      "grad_norm": 0.9723789691925049,
      "learning_rate": 9.952421712924208e-06,
      "loss": 2.9816,
      "step": 60020
    },
    {
      "epoch": 2.583713523284841,
      "grad_norm": 1.1867510080337524,
      "learning_rate": 9.932222915632128e-06,
      "loss": 2.9854,
      "step": 60030
    },
    {
      "epoch": 2.584143927003529,
      "grad_norm": 1.0273849964141846,
      "learning_rate": 9.912043565102514e-06,
      "loss": 2.8735,
      "step": 60040
    },
    {
      "epoch": 2.5845743307222175,
      "grad_norm": 0.8801807761192322,
      "learning_rate": 9.891883665692381e-06,
      "loss": 3.0029,
      "step": 60050
    },
    {
      "epoch": 2.5845743307222175,
      "eval_bleu": 27.31444769677786,
      "eval_gen_len": 27.56,
      "eval_loss": 2.7861671447753906,
      "eval_runtime": 58.7025,
      "eval_samples_per_second": 17.035,
      "eval_steps_per_second": 1.073,
      "step": 60050
    },
    {
      "epoch": 2.5850047344409055,
      "grad_norm": 1.0559113025665283,
      "learning_rate": 9.871743221754481e-06,
      "loss": 2.9917,
      "step": 60060
    },
    {
      "epoch": 2.5854351381595935,
      "grad_norm": 0.846147358417511,
      "learning_rate": 9.851622237637393e-06,
      "loss": 2.9918,
      "step": 60070
    },
    {
      "epoch": 2.585865541878282,
      "grad_norm": 0.8762874007225037,
      "learning_rate": 9.831520717685472e-06,
      "loss": 2.9196,
      "step": 60080
    },
    {
      "epoch": 2.58629594559697,
      "grad_norm": 0.9615445137023926,
      "learning_rate": 9.811438666238926e-06,
      "loss": 2.9403,
      "step": 60090
    },
    {
      "epoch": 2.586726349315658,
      "grad_norm": 0.966659426689148,
      "learning_rate": 9.791376087633675e-06,
      "loss": 2.924,
      "step": 60100
    },
    {
      "epoch": 2.586726349315658,
      "eval_bleu": 27.322818575737525,
      "eval_gen_len": 27.485,
      "eval_loss": 2.7863643169403076,
      "eval_runtime": 58.9429,
      "eval_samples_per_second": 16.966,
      "eval_steps_per_second": 1.069,
      "step": 60100
    },
    {
      "epoch": 2.5871567530343462,
      "grad_norm": 0.981538712978363,
      "learning_rate": 9.771332986201531e-06,
      "loss": 2.9952,
      "step": 60110
    },
    {
      "epoch": 2.587587156753034,
      "grad_norm": 0.8847580552101135,
      "learning_rate": 9.751309366270012e-06,
      "loss": 2.93,
      "step": 60120
    },
    {
      "epoch": 2.5880175604717226,
      "grad_norm": 1.0098451375961304,
      "learning_rate": 9.731305232162491e-06,
      "loss": 2.8844,
      "step": 60130
    },
    {
      "epoch": 2.5884479641904106,
      "grad_norm": 0.8446263074874878,
      "learning_rate": 9.711320588198125e-06,
      "loss": 3.0093,
      "step": 60140
    },
    {
      "epoch": 2.588878367909099,
      "grad_norm": 0.9696025848388672,
      "learning_rate": 9.691355438691808e-06,
      "loss": 2.9967,
      "step": 60150
    },
    {
      "epoch": 2.588878367909099,
      "eval_bleu": 27.211963964979034,
      "eval_gen_len": 27.445,
      "eval_loss": 2.785705089569092,
      "eval_runtime": 58.855,
      "eval_samples_per_second": 16.991,
      "eval_steps_per_second": 1.07,
      "step": 60150
    },
    {
      "epoch": 2.589308771627787,
      "grad_norm": 0.9543673992156982,
      "learning_rate": 9.671409787954288e-06,
      "loss": 2.9602,
      "step": 60160
    },
    {
      "epoch": 2.589739175346475,
      "grad_norm": 0.9235156178474426,
      "learning_rate": 9.65148364029208e-06,
      "loss": 2.8479,
      "step": 60170
    },
    {
      "epoch": 2.5901695790651633,
      "grad_norm": 0.9365261793136597,
      "learning_rate": 9.631577000007496e-06,
      "loss": 3.0033,
      "step": 60180
    },
    {
      "epoch": 2.5905999827838513,
      "grad_norm": 0.9726607203483582,
      "learning_rate": 9.61168987139861e-06,
      "loss": 2.9899,
      "step": 60190
    },
    {
      "epoch": 2.5910303865025393,
      "grad_norm": 0.9776283502578735,
      "learning_rate": 9.591822258759331e-06,
      "loss": 3.0505,
      "step": 60200
    },
    {
      "epoch": 2.5910303865025393,
      "eval_bleu": 27.247797367075584,
      "eval_gen_len": 27.472,
      "eval_loss": 2.7857606410980225,
      "eval_runtime": 58.8883,
      "eval_samples_per_second": 16.981,
      "eval_steps_per_second": 1.07,
      "step": 60200
    },
    {
      "epoch": 2.5914607902212277,
      "grad_norm": 0.9987179636955261,
      "learning_rate": 9.571974166379283e-06,
      "loss": 2.9232,
      "step": 60210
    },
    {
      "epoch": 2.5918911939399156,
      "grad_norm": 1.0219210386276245,
      "learning_rate": 9.552145598543971e-06,
      "loss": 3.1038,
      "step": 60220
    },
    {
      "epoch": 2.5923215976586036,
      "grad_norm": 0.9453838467597961,
      "learning_rate": 9.532336559534605e-06,
      "loss": 3.0585,
      "step": 60230
    },
    {
      "epoch": 2.592752001377292,
      "grad_norm": 0.9164855480194092,
      "learning_rate": 9.512547053628185e-06,
      "loss": 2.9917,
      "step": 60240
    },
    {
      "epoch": 2.59318240509598,
      "grad_norm": 0.8705673217773438,
      "learning_rate": 9.49277708509756e-06,
      "loss": 2.9247,
      "step": 60250
    },
    {
      "epoch": 2.59318240509598,
      "eval_bleu": 27.24404085123694,
      "eval_gen_len": 27.472,
      "eval_loss": 2.7861876487731934,
      "eval_runtime": 59.5309,
      "eval_samples_per_second": 16.798,
      "eval_steps_per_second": 1.058,
      "step": 60250
    },
    {
      "epoch": 2.593612808814668,
      "grad_norm": 1.0015619993209839,
      "learning_rate": 9.47302665821126e-06,
      "loss": 3.0381,
      "step": 60260
    },
    {
      "epoch": 2.5940432125333563,
      "grad_norm": 0.9596068263053894,
      "learning_rate": 9.453295777233695e-06,
      "loss": 2.9493,
      "step": 60270
    },
    {
      "epoch": 2.5944736162520443,
      "grad_norm": 0.8954747915267944,
      "learning_rate": 9.43358444642497e-06,
      "loss": 2.9955,
      "step": 60280
    },
    {
      "epoch": 2.5949040199707323,
      "grad_norm": 0.8971748948097229,
      "learning_rate": 9.413892670041059e-06,
      "loss": 2.9442,
      "step": 60290
    },
    {
      "epoch": 2.5953344236894207,
      "grad_norm": 0.9646411538124084,
      "learning_rate": 9.394220452333612e-06,
      "loss": 2.9648,
      "step": 60300
    },
    {
      "epoch": 2.5953344236894207,
      "eval_bleu": 27.206789028074223,
      "eval_gen_len": 27.542,
      "eval_loss": 2.785320997238159,
      "eval_runtime": 58.4759,
      "eval_samples_per_second": 17.101,
      "eval_steps_per_second": 1.077,
      "step": 60300
    },
    {
      "epoch": 2.5957648274081087,
      "grad_norm": 0.7909097075462341,
      "learning_rate": 9.37456779755015e-06,
      "loss": 2.8713,
      "step": 60310
    },
    {
      "epoch": 2.596195231126797,
      "grad_norm": 0.9933593273162842,
      "learning_rate": 9.354934709933904e-06,
      "loss": 3.0695,
      "step": 60320
    },
    {
      "epoch": 2.596625634845485,
      "grad_norm": 0.8647910952568054,
      "learning_rate": 9.3353211937239e-06,
      "loss": 2.965,
      "step": 60330
    },
    {
      "epoch": 2.5970560385641734,
      "grad_norm": 0.9117569923400879,
      "learning_rate": 9.31572725315496e-06,
      "loss": 2.8888,
      "step": 60340
    },
    {
      "epoch": 2.5974864422828614,
      "grad_norm": 0.9090341329574585,
      "learning_rate": 9.296152892457633e-06,
      "loss": 3.0717,
      "step": 60350
    },
    {
      "epoch": 2.5974864422828614,
      "eval_bleu": 27.38525370214799,
      "eval_gen_len": 27.513,
      "eval_loss": 2.7864830493927,
      "eval_runtime": 58.5763,
      "eval_samples_per_second": 17.072,
      "eval_steps_per_second": 1.076,
      "step": 60350
    },
    {
      "epoch": 2.5979168460015494,
      "grad_norm": 0.9090221524238586,
      "learning_rate": 9.276598115858303e-06,
      "loss": 3.055,
      "step": 60360
    },
    {
      "epoch": 2.598347249720238,
      "grad_norm": 0.964944064617157,
      "learning_rate": 9.257062927579063e-06,
      "loss": 3.0694,
      "step": 60370
    },
    {
      "epoch": 2.5987776534389257,
      "grad_norm": 0.9499419927597046,
      "learning_rate": 9.237547331837837e-06,
      "loss": 2.9156,
      "step": 60380
    },
    {
      "epoch": 2.5992080571576137,
      "grad_norm": 0.9657159447669983,
      "learning_rate": 9.218051332848266e-06,
      "loss": 2.9663,
      "step": 60390
    },
    {
      "epoch": 2.599638460876302,
      "grad_norm": 0.9226863980293274,
      "learning_rate": 9.19857493481976e-06,
      "loss": 2.9002,
      "step": 60400
    },
    {
      "epoch": 2.599638460876302,
      "eval_bleu": 27.264033362604497,
      "eval_gen_len": 27.487,
      "eval_loss": 2.785613536834717,
      "eval_runtime": 58.5264,
      "eval_samples_per_second": 17.086,
      "eval_steps_per_second": 1.076,
      "step": 60400
    },
    {
      "epoch": 2.60006886459499,
      "grad_norm": 1.0053616762161255,
      "learning_rate": 9.179118141957566e-06,
      "loss": 3.0301,
      "step": 60410
    },
    {
      "epoch": 2.600499268313678,
      "grad_norm": 0.949487566947937,
      "learning_rate": 9.159680958462601e-06,
      "loss": 3.0405,
      "step": 60420
    },
    {
      "epoch": 2.6009296720323665,
      "grad_norm": 0.9871969819068909,
      "learning_rate": 9.140263388531633e-06,
      "loss": 3.0007,
      "step": 60430
    },
    {
      "epoch": 2.6013600757510544,
      "grad_norm": 0.8188295960426331,
      "learning_rate": 9.12086543635714e-06,
      "loss": 2.8664,
      "step": 60440
    },
    {
      "epoch": 2.6017904794697424,
      "grad_norm": 0.9544017314910889,
      "learning_rate": 9.101487106127393e-06,
      "loss": 2.8468,
      "step": 60450
    },
    {
      "epoch": 2.6017904794697424,
      "eval_bleu": 27.530917700403492,
      "eval_gen_len": 27.521,
      "eval_loss": 2.785433530807495,
      "eval_runtime": 58.7363,
      "eval_samples_per_second": 17.025,
      "eval_steps_per_second": 1.073,
      "step": 60450
    },
    {
      "epoch": 2.602220883188431,
      "grad_norm": 0.8861671686172485,
      "learning_rate": 9.082128402026401e-06,
      "loss": 2.9925,
      "step": 60460
    },
    {
      "epoch": 2.6026512869071188,
      "grad_norm": 0.856640636920929,
      "learning_rate": 9.062789328233979e-06,
      "loss": 3.0182,
      "step": 60470
    },
    {
      "epoch": 2.6030816906258067,
      "grad_norm": 0.9431694149971008,
      "learning_rate": 9.04346988892565e-06,
      "loss": 3.0143,
      "step": 60480
    },
    {
      "epoch": 2.603512094344495,
      "grad_norm": 0.8529301285743713,
      "learning_rate": 9.02417008827272e-06,
      "loss": 2.9749,
      "step": 60490
    },
    {
      "epoch": 2.603942498063183,
      "grad_norm": 0.950743556022644,
      "learning_rate": 9.004889930442285e-06,
      "loss": 2.9643,
      "step": 60500
    },
    {
      "epoch": 2.603942498063183,
      "eval_bleu": 27.24118203486116,
      "eval_gen_len": 27.502,
      "eval_loss": 2.785442590713501,
      "eval_runtime": 58.707,
      "eval_samples_per_second": 17.034,
      "eval_steps_per_second": 1.073,
      "step": 60500
    },
    {
      "epoch": 2.6043729017818715,
      "grad_norm": 0.8788071870803833,
      "learning_rate": 8.98562941959714e-06,
      "loss": 2.94,
      "step": 60510
    },
    {
      "epoch": 2.6048033055005595,
      "grad_norm": 0.9515433311462402,
      "learning_rate": 8.96638855989591e-06,
      "loss": 2.9917,
      "step": 60520
    },
    {
      "epoch": 2.605233709219248,
      "grad_norm": 0.9471508860588074,
      "learning_rate": 8.947167355492892e-06,
      "loss": 2.9512,
      "step": 60530
    },
    {
      "epoch": 2.605664112937936,
      "grad_norm": 0.8487266898155212,
      "learning_rate": 8.92796581053823e-06,
      "loss": 2.9074,
      "step": 60540
    },
    {
      "epoch": 2.606094516656624,
      "grad_norm": 0.9144738912582397,
      "learning_rate": 8.908783929177766e-06,
      "loss": 2.9363,
      "step": 60550
    },
    {
      "epoch": 2.606094516656624,
      "eval_bleu": 27.22477993115931,
      "eval_gen_len": 27.443,
      "eval_loss": 2.785501718521118,
      "eval_runtime": 58.5544,
      "eval_samples_per_second": 17.078,
      "eval_steps_per_second": 1.076,
      "step": 60550
    },
    {
      "epoch": 2.6065249203753122,
      "grad_norm": 0.7829925417900085,
      "learning_rate": 8.889621715553066e-06,
      "loss": 2.9852,
      "step": 60560
    },
    {
      "epoch": 2.606955324094,
      "grad_norm": 0.866110622882843,
      "learning_rate": 8.870479173801549e-06,
      "loss": 2.9243,
      "step": 60570
    },
    {
      "epoch": 2.607385727812688,
      "grad_norm": 0.9611830115318298,
      "learning_rate": 8.85135630805629e-06,
      "loss": 3.0663,
      "step": 60580
    },
    {
      "epoch": 2.6078161315313766,
      "grad_norm": 0.9693455696105957,
      "learning_rate": 8.832253122446198e-06,
      "loss": 2.9158,
      "step": 60590
    },
    {
      "epoch": 2.6082465352500646,
      "grad_norm": 0.9801904559135437,
      "learning_rate": 8.81316962109584e-06,
      "loss": 3.0087,
      "step": 60600
    },
    {
      "epoch": 2.6082465352500646,
      "eval_bleu": 27.28928809129231,
      "eval_gen_len": 27.473,
      "eval_loss": 2.785198450088501,
      "eval_runtime": 58.543,
      "eval_samples_per_second": 17.081,
      "eval_steps_per_second": 1.076,
      "step": 60600
    },
    {
      "epoch": 2.6086769389687525,
      "grad_norm": 0.9099735021591187,
      "learning_rate": 8.79410580812563e-06,
      "loss": 2.902,
      "step": 60610
    },
    {
      "epoch": 2.609107342687441,
      "grad_norm": 0.9709731340408325,
      "learning_rate": 8.775061687651642e-06,
      "loss": 2.91,
      "step": 60620
    },
    {
      "epoch": 2.609537746406129,
      "grad_norm": 0.8740511536598206,
      "learning_rate": 8.756037263785787e-06,
      "loss": 2.9745,
      "step": 60630
    },
    {
      "epoch": 2.609968150124817,
      "grad_norm": 0.9389996528625488,
      "learning_rate": 8.737032540635626e-06,
      "loss": 3.0675,
      "step": 60640
    },
    {
      "epoch": 2.6103985538435053,
      "grad_norm": 0.8835762739181519,
      "learning_rate": 8.71804752230454e-06,
      "loss": 2.9315,
      "step": 60650
    },
    {
      "epoch": 2.6103985538435053,
      "eval_bleu": 27.40349127616605,
      "eval_gen_len": 27.489,
      "eval_loss": 2.784778594970703,
      "eval_runtime": 58.5898,
      "eval_samples_per_second": 17.068,
      "eval_steps_per_second": 1.075,
      "step": 60650
    },
    {
      "epoch": 2.6108289575621932,
      "grad_norm": 0.8512768149375916,
      "learning_rate": 8.699082212891652e-06,
      "loss": 3.0332,
      "step": 60660
    },
    {
      "epoch": 2.611259361280881,
      "grad_norm": 0.980486273765564,
      "learning_rate": 8.680136616491774e-06,
      "loss": 2.9985,
      "step": 60670
    },
    {
      "epoch": 2.6116897649995696,
      "grad_norm": 1.0302186012268066,
      "learning_rate": 8.661210737195524e-06,
      "loss": 2.832,
      "step": 60680
    },
    {
      "epoch": 2.6121201687182576,
      "grad_norm": 0.9856322407722473,
      "learning_rate": 8.642304579089222e-06,
      "loss": 2.9581,
      "step": 60690
    },
    {
      "epoch": 2.612550572436946,
      "grad_norm": 0.9516296982765198,
      "learning_rate": 8.623418146254969e-06,
      "loss": 2.9698,
      "step": 60700
    },
    {
      "epoch": 2.612550572436946,
      "eval_bleu": 27.25094133981329,
      "eval_gen_len": 27.486,
      "eval_loss": 2.7846665382385254,
      "eval_runtime": 58.3917,
      "eval_samples_per_second": 17.126,
      "eval_steps_per_second": 1.079,
      "step": 60700
    },
    {
      "epoch": 2.612980976155634,
      "grad_norm": 0.8455529808998108,
      "learning_rate": 8.604551442770559e-06,
      "loss": 2.8526,
      "step": 60710
    },
    {
      "epoch": 2.6134113798743224,
      "grad_norm": 0.929060161113739,
      "learning_rate": 8.585704472709566e-06,
      "loss": 2.9512,
      "step": 60720
    },
    {
      "epoch": 2.6138417835930103,
      "grad_norm": 0.9111208915710449,
      "learning_rate": 8.566877240141247e-06,
      "loss": 2.9578,
      "step": 60730
    },
    {
      "epoch": 2.6142721873116983,
      "grad_norm": 0.9124503135681152,
      "learning_rate": 8.548069749130694e-06,
      "loss": 2.9338,
      "step": 60740
    },
    {
      "epoch": 2.6147025910303867,
      "grad_norm": 1.0711945295333862,
      "learning_rate": 8.529282003738626e-06,
      "loss": 2.9714,
      "step": 60750
    },
    {
      "epoch": 2.6147025910303867,
      "eval_bleu": 27.2304375535026,
      "eval_gen_len": 27.499,
      "eval_loss": 2.7855632305145264,
      "eval_runtime": 58.468,
      "eval_samples_per_second": 17.103,
      "eval_steps_per_second": 1.078,
      "step": 60750
    },
    {
      "epoch": 2.6151329947490747,
      "grad_norm": 0.9568807482719421,
      "learning_rate": 8.510514008021586e-06,
      "loss": 3.0333,
      "step": 60760
    },
    {
      "epoch": 2.6155633984677626,
      "grad_norm": 0.9207909107208252,
      "learning_rate": 8.491765766031833e-06,
      "loss": 2.9902,
      "step": 60770
    },
    {
      "epoch": 2.615993802186451,
      "grad_norm": 0.8669273853302002,
      "learning_rate": 8.473037281817309e-06,
      "loss": 2.9345,
      "step": 60780
    },
    {
      "epoch": 2.616424205905139,
      "grad_norm": 0.8463643789291382,
      "learning_rate": 8.454328559421786e-06,
      "loss": 2.9915,
      "step": 60790
    },
    {
      "epoch": 2.616854609623827,
      "grad_norm": 0.9855180978775024,
      "learning_rate": 8.435639602884637e-06,
      "loss": 2.9927,
      "step": 60800
    },
    {
      "epoch": 2.616854609623827,
      "eval_bleu": 27.193963491244663,
      "eval_gen_len": 27.459,
      "eval_loss": 2.7861623764038086,
      "eval_runtime": 58.3506,
      "eval_samples_per_second": 17.138,
      "eval_steps_per_second": 1.08,
      "step": 60800
    },
    {
      "epoch": 2.6172850133425154,
      "grad_norm": 0.9429417252540588,
      "learning_rate": 8.4169704162411e-06,
      "loss": 2.9587,
      "step": 60810
    },
    {
      "epoch": 2.6177154170612034,
      "grad_norm": 0.9162782430648804,
      "learning_rate": 8.398321003522047e-06,
      "loss": 2.9519,
      "step": 60820
    },
    {
      "epoch": 2.6181458207798913,
      "grad_norm": 1.0778157711029053,
      "learning_rate": 8.37969136875415e-06,
      "loss": 3.0119,
      "step": 60830
    },
    {
      "epoch": 2.6185762244985797,
      "grad_norm": 0.9818832278251648,
      "learning_rate": 8.361081515959757e-06,
      "loss": 3.0316,
      "step": 60840
    },
    {
      "epoch": 2.6190066282172677,
      "grad_norm": 1.0069634914398193,
      "learning_rate": 8.342491449156987e-06,
      "loss": 2.942,
      "step": 60850
    },
    {
      "epoch": 2.6190066282172677,
      "eval_bleu": 27.39704716508333,
      "eval_gen_len": 27.49,
      "eval_loss": 2.786090135574341,
      "eval_runtime": 59.1118,
      "eval_samples_per_second": 16.917,
      "eval_steps_per_second": 1.066,
      "step": 60850
    },
    {
      "epoch": 2.6194370319359557,
      "grad_norm": 0.9019491076469421,
      "learning_rate": 8.323921172359672e-06,
      "loss": 3.0433,
      "step": 60860
    },
    {
      "epoch": 2.619867435654644,
      "grad_norm": 0.853887677192688,
      "learning_rate": 8.305370689577352e-06,
      "loss": 2.9537,
      "step": 60870
    },
    {
      "epoch": 2.620297839373332,
      "grad_norm": 0.9377981424331665,
      "learning_rate": 8.286840004815333e-06,
      "loss": 2.9916,
      "step": 60880
    },
    {
      "epoch": 2.6207282430920205,
      "grad_norm": 0.8320183753967285,
      "learning_rate": 8.268329122074569e-06,
      "loss": 2.9035,
      "step": 60890
    },
    {
      "epoch": 2.6211586468107084,
      "grad_norm": 0.9790758490562439,
      "learning_rate": 8.249838045351854e-06,
      "loss": 3.0062,
      "step": 60900
    },
    {
      "epoch": 2.6211586468107084,
      "eval_bleu": 27.340503753921258,
      "eval_gen_len": 27.481,
      "eval_loss": 2.7857041358947754,
      "eval_runtime": 59.3295,
      "eval_samples_per_second": 16.855,
      "eval_steps_per_second": 1.062,
      "step": 60900
    },
    {
      "epoch": 2.621589050529397,
      "grad_norm": 0.9280329942703247,
      "learning_rate": 8.231366778639593e-06,
      "loss": 2.8207,
      "step": 60910
    },
    {
      "epoch": 2.622019454248085,
      "grad_norm": 0.9064091444015503,
      "learning_rate": 8.212915325926008e-06,
      "loss": 2.9996,
      "step": 60920
    },
    {
      "epoch": 2.6224498579667728,
      "grad_norm": 0.9251274466514587,
      "learning_rate": 8.194483691194964e-06,
      "loss": 3.0192,
      "step": 60930
    },
    {
      "epoch": 2.622880261685461,
      "grad_norm": 0.930964469909668,
      "learning_rate": 8.176071878426106e-06,
      "loss": 2.9973,
      "step": 60940
    },
    {
      "epoch": 2.623310665404149,
      "grad_norm": 0.9768269062042236,
      "learning_rate": 8.15767989159476e-06,
      "loss": 2.9755,
      "step": 60950
    },
    {
      "epoch": 2.623310665404149,
      "eval_bleu": 27.35981857716243,
      "eval_gen_len": 27.508,
      "eval_loss": 2.785217046737671,
      "eval_runtime": 58.8296,
      "eval_samples_per_second": 16.998,
      "eval_steps_per_second": 1.071,
      "step": 60950
    },
    {
      "epoch": 2.623741069122837,
      "grad_norm": 0.9871233105659485,
      "learning_rate": 8.139307734671997e-06,
      "loss": 2.9783,
      "step": 60960
    },
    {
      "epoch": 2.6241714728415255,
      "grad_norm": 0.9002211689949036,
      "learning_rate": 8.120955411624598e-06,
      "loss": 2.9277,
      "step": 60970
    },
    {
      "epoch": 2.6246018765602135,
      "grad_norm": 0.9172571897506714,
      "learning_rate": 8.102622926415038e-06,
      "loss": 2.9645,
      "step": 60980
    },
    {
      "epoch": 2.6250322802789015,
      "grad_norm": 0.8904248476028442,
      "learning_rate": 8.084310283001562e-06,
      "loss": 2.964,
      "step": 60990
    },
    {
      "epoch": 2.62546268399759,
      "grad_norm": 0.8761984705924988,
      "learning_rate": 8.066017485338063e-06,
      "loss": 3.0853,
      "step": 61000
    },
    {
      "epoch": 2.62546268399759,
      "eval_bleu": 27.3409372750876,
      "eval_gen_len": 27.556,
      "eval_loss": 2.78490948677063,
      "eval_runtime": 58.7751,
      "eval_samples_per_second": 17.014,
      "eval_steps_per_second": 1.072,
      "step": 61000
    },
    {
      "epoch": 2.625893087716278,
      "grad_norm": 1.0516990423202515,
      "learning_rate": 8.047744537374213e-06,
      "loss": 2.9661,
      "step": 61010
    },
    {
      "epoch": 2.626323491434966,
      "grad_norm": 0.904701828956604,
      "learning_rate": 8.029491443055359e-06,
      "loss": 3.0483,
      "step": 61020
    },
    {
      "epoch": 2.626753895153654,
      "grad_norm": 0.8191422820091248,
      "learning_rate": 8.011258206322592e-06,
      "loss": 2.932,
      "step": 61030
    },
    {
      "epoch": 2.627184298872342,
      "grad_norm": 0.9489712119102478,
      "learning_rate": 7.993044831112673e-06,
      "loss": 3.0109,
      "step": 61040
    },
    {
      "epoch": 2.62761470259103,
      "grad_norm": 0.8429877758026123,
      "learning_rate": 7.974851321358101e-06,
      "loss": 2.9489,
      "step": 61050
    },
    {
      "epoch": 2.62761470259103,
      "eval_bleu": 27.388732535108126,
      "eval_gen_len": 27.572,
      "eval_loss": 2.785067558288574,
      "eval_runtime": 58.687,
      "eval_samples_per_second": 17.04,
      "eval_steps_per_second": 1.073,
      "step": 61050
    },
    {
      "epoch": 2.6280451063097185,
      "grad_norm": 0.841260552406311,
      "learning_rate": 7.95667768098709e-06,
      "loss": 2.931,
      "step": 61060
    },
    {
      "epoch": 2.6284755100284065,
      "grad_norm": 0.8884979486465454,
      "learning_rate": 7.938523913923557e-06,
      "loss": 2.9852,
      "step": 61070
    },
    {
      "epoch": 2.628905913747095,
      "grad_norm": 0.9241563081741333,
      "learning_rate": 7.920390024087132e-06,
      "loss": 3.0087,
      "step": 61080
    },
    {
      "epoch": 2.629336317465783,
      "grad_norm": 0.9476426243782043,
      "learning_rate": 7.902276015393118e-06,
      "loss": 2.9433,
      "step": 61090
    },
    {
      "epoch": 2.6297667211844713,
      "grad_norm": 1.004099726676941,
      "learning_rate": 7.884181891752617e-06,
      "loss": 2.9432,
      "step": 61100
    },
    {
      "epoch": 2.6297667211844713,
      "eval_bleu": 27.120405121921035,
      "eval_gen_len": 27.479,
      "eval_loss": 2.7851133346557617,
      "eval_runtime": 58.4824,
      "eval_samples_per_second": 17.099,
      "eval_steps_per_second": 1.077,
      "step": 61100
    },
    {
      "epoch": 2.6301971249031593,
      "grad_norm": 0.8630812168121338,
      "learning_rate": 7.866107657072309e-06,
      "loss": 2.959,
      "step": 61110
    },
    {
      "epoch": 2.6306275286218472,
      "grad_norm": 0.8865326642990112,
      "learning_rate": 7.848053315254711e-06,
      "loss": 2.9086,
      "step": 61120
    },
    {
      "epoch": 2.6310579323405356,
      "grad_norm": 0.9992364645004272,
      "learning_rate": 7.830018870197942e-06,
      "loss": 3.0226,
      "step": 61130
    },
    {
      "epoch": 2.6314883360592236,
      "grad_norm": 0.8688614368438721,
      "learning_rate": 7.812004325795863e-06,
      "loss": 2.9213,
      "step": 61140
    },
    {
      "epoch": 2.6319187397779116,
      "grad_norm": 0.8497973084449768,
      "learning_rate": 7.794009685938063e-06,
      "loss": 2.9886,
      "step": 61150
    },
    {
      "epoch": 2.6319187397779116,
      "eval_bleu": 27.187076596027023,
      "eval_gen_len": 27.483,
      "eval_loss": 2.785364866256714,
      "eval_runtime": 58.8788,
      "eval_samples_per_second": 16.984,
      "eval_steps_per_second": 1.07,
      "step": 61150
    },
    {
      "epoch": 2.6323491434966,
      "grad_norm": 0.98153156042099,
      "learning_rate": 7.776034954509781e-06,
      "loss": 3.0347,
      "step": 61160
    },
    {
      "epoch": 2.632779547215288,
      "grad_norm": 0.9594031572341919,
      "learning_rate": 7.758080135392031e-06,
      "loss": 3.0233,
      "step": 61170
    },
    {
      "epoch": 2.633209950933976,
      "grad_norm": 0.9587937593460083,
      "learning_rate": 7.740145232461437e-06,
      "loss": 2.9826,
      "step": 61180
    },
    {
      "epoch": 2.6336403546526643,
      "grad_norm": 0.8903703093528748,
      "learning_rate": 7.7222302495904e-06,
      "loss": 2.9691,
      "step": 61190
    },
    {
      "epoch": 2.6340707583713523,
      "grad_norm": 0.846620500087738,
      "learning_rate": 7.704335190646993e-06,
      "loss": 2.9685,
      "step": 61200
    },
    {
      "epoch": 2.6340707583713523,
      "eval_bleu": 27.321008351153875,
      "eval_gen_len": 27.549,
      "eval_loss": 2.7850773334503174,
      "eval_runtime": 58.7364,
      "eval_samples_per_second": 17.025,
      "eval_steps_per_second": 1.073,
      "step": 61200
    },
    {
      "epoch": 2.6345011620900403,
      "grad_norm": 0.8290736675262451,
      "learning_rate": 7.686460059494938e-06,
      "loss": 3.0002,
      "step": 61210
    },
    {
      "epoch": 2.6349315658087287,
      "grad_norm": 1.0000182390213013,
      "learning_rate": 7.668604859993755e-06,
      "loss": 2.9814,
      "step": 61220
    },
    {
      "epoch": 2.6353619695274166,
      "grad_norm": 1.0321282148361206,
      "learning_rate": 7.650769595998563e-06,
      "loss": 3.0235,
      "step": 61230
    },
    {
      "epoch": 2.6357923732461046,
      "grad_norm": 1.0476322174072266,
      "learning_rate": 7.63295427136026e-06,
      "loss": 2.9878,
      "step": 61240
    },
    {
      "epoch": 2.636222776964793,
      "grad_norm": 0.8693568110466003,
      "learning_rate": 7.615158889925366e-06,
      "loss": 2.9408,
      "step": 61250
    },
    {
      "epoch": 2.636222776964793,
      "eval_bleu": 27.175144730192482,
      "eval_gen_len": 27.497,
      "eval_loss": 2.7847707271575928,
      "eval_runtime": 58.7993,
      "eval_samples_per_second": 17.007,
      "eval_steps_per_second": 1.071,
      "step": 61250
    },
    {
      "epoch": 2.636653180683481,
      "grad_norm": 0.90264493227005,
      "learning_rate": 7.597383455536145e-06,
      "loss": 2.9474,
      "step": 61260
    },
    {
      "epoch": 2.6370835844021694,
      "grad_norm": 0.8487510681152344,
      "learning_rate": 7.579627972030512e-06,
      "loss": 2.9538,
      "step": 61270
    },
    {
      "epoch": 2.6375139881208574,
      "grad_norm": 0.887483537197113,
      "learning_rate": 7.5618924432421356e-06,
      "loss": 3.0205,
      "step": 61280
    },
    {
      "epoch": 2.6379443918395458,
      "grad_norm": 0.91618812084198,
      "learning_rate": 7.544176873000308e-06,
      "loss": 2.9962,
      "step": 61290
    },
    {
      "epoch": 2.6383747955582337,
      "grad_norm": 0.9522454738616943,
      "learning_rate": 7.5264812651300475e-06,
      "loss": 2.9257,
      "step": 61300
    },
    {
      "epoch": 2.6383747955582337,
      "eval_bleu": 27.24820295930247,
      "eval_gen_len": 27.572,
      "eval_loss": 2.7851483821868896,
      "eval_runtime": 58.7916,
      "eval_samples_per_second": 17.009,
      "eval_steps_per_second": 1.072,
      "step": 61300
    },
    {
      "epoch": 2.6388051992769217,
      "grad_norm": 0.8998917937278748,
      "learning_rate": 7.508805623452076e-06,
      "loss": 3.0642,
      "step": 61310
    },
    {
      "epoch": 2.63923560299561,
      "grad_norm": 0.8713736534118652,
      "learning_rate": 7.491149951782761e-06,
      "loss": 2.9574,
      "step": 61320
    },
    {
      "epoch": 2.639666006714298,
      "grad_norm": 0.960821270942688,
      "learning_rate": 7.473514253934211e-06,
      "loss": 2.9778,
      "step": 61330
    },
    {
      "epoch": 2.640096410432986,
      "grad_norm": 0.874575674533844,
      "learning_rate": 7.455898533714167e-06,
      "loss": 3.0046,
      "step": 61340
    },
    {
      "epoch": 2.6405268141516745,
      "grad_norm": 0.9388437867164612,
      "learning_rate": 7.4383027949261104e-06,
      "loss": 3.0342,
      "step": 61350
    },
    {
      "epoch": 2.6405268141516745,
      "eval_bleu": 27.113492772661377,
      "eval_gen_len": 27.555,
      "eval_loss": 2.785501718521118,
      "eval_runtime": 58.8637,
      "eval_samples_per_second": 16.988,
      "eval_steps_per_second": 1.07,
      "step": 61350
    },
    {
      "epoch": 2.6409572178703624,
      "grad_norm": 0.923085629940033,
      "learning_rate": 7.420727041369157e-06,
      "loss": 3.0312,
      "step": 61360
    },
    {
      "epoch": 2.6413876215890504,
      "grad_norm": 0.9957253336906433,
      "learning_rate": 7.403171276838161e-06,
      "loss": 3.0407,
      "step": 61370
    },
    {
      "epoch": 2.641818025307739,
      "grad_norm": 0.9370946288108826,
      "learning_rate": 7.385635505123589e-06,
      "loss": 2.9541,
      "step": 61380
    },
    {
      "epoch": 2.6422484290264268,
      "grad_norm": 0.9719976782798767,
      "learning_rate": 7.368119730011658e-06,
      "loss": 3.0335,
      "step": 61390
    },
    {
      "epoch": 2.6426788327451147,
      "grad_norm": 0.8457173109054565,
      "learning_rate": 7.3506239552842636e-06,
      "loss": 3.0458,
      "step": 61400
    },
    {
      "epoch": 2.6426788327451147,
      "eval_bleu": 27.23282280387484,
      "eval_gen_len": 27.501,
      "eval_loss": 2.785966157913208,
      "eval_runtime": 58.6165,
      "eval_samples_per_second": 17.06,
      "eval_steps_per_second": 1.075,
      "step": 61400
    },
    {
      "epoch": 2.643109236463803,
      "grad_norm": 0.9389542937278748,
      "learning_rate": 7.33314818471893e-06,
      "loss": 3.0012,
      "step": 61410
    },
    {
      "epoch": 2.643539640182491,
      "grad_norm": 0.8797752261161804,
      "learning_rate": 7.3156924220889155e-06,
      "loss": 3.0157,
      "step": 61420
    },
    {
      "epoch": 2.643970043901179,
      "grad_norm": 0.8873607516288757,
      "learning_rate": 7.2982566711631285e-06,
      "loss": 3.0533,
      "step": 61430
    },
    {
      "epoch": 2.6444004476198675,
      "grad_norm": 0.9901944398880005,
      "learning_rate": 7.280840935706202e-06,
      "loss": 2.903,
      "step": 61440
    },
    {
      "epoch": 2.6448308513385554,
      "grad_norm": 0.9378849267959595,
      "learning_rate": 7.263445219478338e-06,
      "loss": 3.0224,
      "step": 61450
    },
    {
      "epoch": 2.6448308513385554,
      "eval_bleu": 27.205889883834715,
      "eval_gen_len": 27.499,
      "eval_loss": 2.785616397857666,
      "eval_runtime": 58.3723,
      "eval_samples_per_second": 17.131,
      "eval_steps_per_second": 1.079,
      "step": 61450
    },
    {
      "epoch": 2.645261255057244,
      "grad_norm": 0.8784775137901306,
      "learning_rate": 7.2460695262355545e-06,
      "loss": 3.0274,
      "step": 61460
    },
    {
      "epoch": 2.645691658775932,
      "grad_norm": 0.930675745010376,
      "learning_rate": 7.228713859729441e-06,
      "loss": 2.9432,
      "step": 61470
    },
    {
      "epoch": 2.6461220624946202,
      "grad_norm": 0.8346478939056396,
      "learning_rate": 7.211378223707321e-06,
      "loss": 2.9722,
      "step": 61480
    },
    {
      "epoch": 2.646552466213308,
      "grad_norm": 0.9297962784767151,
      "learning_rate": 7.19406262191219e-06,
      "loss": 3.027,
      "step": 61490
    },
    {
      "epoch": 2.646982869931996,
      "grad_norm": 0.8721796870231628,
      "learning_rate": 7.176767058082667e-06,
      "loss": 2.9917,
      "step": 61500
    },
    {
      "epoch": 2.646982869931996,
      "eval_bleu": 27.067386631934617,
      "eval_gen_len": 27.502,
      "eval_loss": 2.785299301147461,
      "eval_runtime": 58.5204,
      "eval_samples_per_second": 17.088,
      "eval_steps_per_second": 1.077,
      "step": 61500
    },
    {
      "epoch": 2.6474132736506846,
      "grad_norm": 0.8658084869384766,
      "learning_rate": 7.159491535953133e-06,
      "loss": 2.955,
      "step": 61510
    },
    {
      "epoch": 2.6478436773693725,
      "grad_norm": 0.9622615575790405,
      "learning_rate": 7.142236059253549e-06,
      "loss": 2.9475,
      "step": 61520
    },
    {
      "epoch": 2.6482740810880605,
      "grad_norm": 0.8131933808326721,
      "learning_rate": 7.1250006317096e-06,
      "loss": 2.9625,
      "step": 61530
    },
    {
      "epoch": 2.648704484806749,
      "grad_norm": 1.0054343938827515,
      "learning_rate": 7.10778525704262e-06,
      "loss": 2.962,
      "step": 61540
    },
    {
      "epoch": 2.649134888525437,
      "grad_norm": 0.8966029286384583,
      "learning_rate": 7.0905899389696495e-06,
      "loss": 2.9416,
      "step": 61550
    },
    {
      "epoch": 2.649134888525437,
      "eval_bleu": 27.132598029882466,
      "eval_gen_len": 27.497,
      "eval_loss": 2.785320997238159,
      "eval_runtime": 58.8125,
      "eval_samples_per_second": 17.003,
      "eval_steps_per_second": 1.071,
      "step": 61550
    },
    {
      "epoch": 2.649565292244125,
      "grad_norm": 0.9803546071052551,
      "learning_rate": 7.07341468120335e-06,
      "loss": 3.035,
      "step": 61560
    },
    {
      "epoch": 2.6499956959628133,
      "grad_norm": 0.9278494715690613,
      "learning_rate": 7.056259487452088e-06,
      "loss": 3.0587,
      "step": 61570
    },
    {
      "epoch": 2.6504260996815012,
      "grad_norm": 1.0023554563522339,
      "learning_rate": 7.039124361419869e-06,
      "loss": 2.8686,
      "step": 61580
    },
    {
      "epoch": 2.650856503400189,
      "grad_norm": 0.8860343098640442,
      "learning_rate": 7.022009306806399e-06,
      "loss": 3.0026,
      "step": 61590
    },
    {
      "epoch": 2.6512869071188776,
      "grad_norm": 0.9491596221923828,
      "learning_rate": 7.004914327307033e-06,
      "loss": 3.0635,
      "step": 61600
    },
    {
      "epoch": 2.6512869071188776,
      "eval_bleu": 27.247970593828796,
      "eval_gen_len": 27.498,
      "eval_loss": 2.785367965698242,
      "eval_runtime": 58.5184,
      "eval_samples_per_second": 17.089,
      "eval_steps_per_second": 1.077,
      "step": 61600
    },
    {
      "epoch": 2.6517173108375656,
      "grad_norm": 0.9182847142219543,
      "learning_rate": 6.987839426612797e-06,
      "loss": 3.0605,
      "step": 61610
    },
    {
      "epoch": 2.6521477145562535,
      "grad_norm": 0.934424638748169,
      "learning_rate": 6.970784608410352e-06,
      "loss": 3.0342,
      "step": 61620
    },
    {
      "epoch": 2.652578118274942,
      "grad_norm": 1.0270172357559204,
      "learning_rate": 6.953749876382054e-06,
      "loss": 3.0266,
      "step": 61630
    },
    {
      "epoch": 2.65300852199363,
      "grad_norm": 0.9409862160682678,
      "learning_rate": 6.936735234205938e-06,
      "loss": 2.9497,
      "step": 61640
    },
    {
      "epoch": 2.6534389257123183,
      "grad_norm": 0.9201568961143494,
      "learning_rate": 6.919740685555643e-06,
      "loss": 3.0172,
      "step": 61650
    },
    {
      "epoch": 2.6534389257123183,
      "eval_bleu": 27.23585117069171,
      "eval_gen_len": 27.501,
      "eval_loss": 2.785358428955078,
      "eval_runtime": 58.6369,
      "eval_samples_per_second": 17.054,
      "eval_steps_per_second": 1.074,
      "step": 61650
    },
    {
      "epoch": 2.6538693294310063,
      "grad_norm": 0.9276512265205383,
      "learning_rate": 6.902766234100533e-06,
      "loss": 2.9705,
      "step": 61660
    },
    {
      "epoch": 2.6542997331496943,
      "grad_norm": 1.0522218942642212,
      "learning_rate": 6.885811883505588e-06,
      "loss": 2.9885,
      "step": 61670
    },
    {
      "epoch": 2.6547301368683827,
      "grad_norm": 0.8677423000335693,
      "learning_rate": 6.868877637431481e-06,
      "loss": 2.9449,
      "step": 61680
    },
    {
      "epoch": 2.6551605405870706,
      "grad_norm": 0.8992279171943665,
      "learning_rate": 6.851963499534542e-06,
      "loss": 3.0736,
      "step": 61690
    },
    {
      "epoch": 2.655590944305759,
      "grad_norm": 0.9234101176261902,
      "learning_rate": 6.835069473466693e-06,
      "loss": 2.9686,
      "step": 61700
    },
    {
      "epoch": 2.655590944305759,
      "eval_bleu": 27.35678016786268,
      "eval_gen_len": 27.562,
      "eval_loss": 2.785184860229492,
      "eval_runtime": 58.4647,
      "eval_samples_per_second": 17.104,
      "eval_steps_per_second": 1.078,
      "step": 61700
    },
    {
      "epoch": 2.656021348024447,
      "grad_norm": 0.8321816325187683,
      "learning_rate": 6.818195562875607e-06,
      "loss": 2.9351,
      "step": 61710
    },
    {
      "epoch": 2.656451751743135,
      "grad_norm": 0.8511675000190735,
      "learning_rate": 6.801341771404546e-06,
      "loss": 3.0269,
      "step": 61720
    },
    {
      "epoch": 2.6568821554618234,
      "grad_norm": 0.8422821164131165,
      "learning_rate": 6.784508102692499e-06,
      "loss": 2.9341,
      "step": 61730
    },
    {
      "epoch": 2.6573125591805113,
      "grad_norm": 0.8705783486366272,
      "learning_rate": 6.767694560374016e-06,
      "loss": 3.0103,
      "step": 61740
    },
    {
      "epoch": 2.6577429628991993,
      "grad_norm": 0.9250925183296204,
      "learning_rate": 6.750901148079392e-06,
      "loss": 2.9431,
      "step": 61750
    },
    {
      "epoch": 2.6577429628991993,
      "eval_bleu": 27.40816680611899,
      "eval_gen_len": 27.528,
      "eval_loss": 2.7851595878601074,
      "eval_runtime": 59.0032,
      "eval_samples_per_second": 16.948,
      "eval_steps_per_second": 1.068,
      "step": 61750
    },
    {
      "epoch": 2.6581733666178877,
      "grad_norm": 1.0168427228927612,
      "learning_rate": 6.734127869434492e-06,
      "loss": 3.0025,
      "step": 61760
    },
    {
      "epoch": 2.6586037703365757,
      "grad_norm": 0.8918853402137756,
      "learning_rate": 6.717374728060932e-06,
      "loss": 2.979,
      "step": 61770
    },
    {
      "epoch": 2.6590341740552637,
      "grad_norm": 1.0393861532211304,
      "learning_rate": 6.700641727575885e-06,
      "loss": 2.9923,
      "step": 61780
    },
    {
      "epoch": 2.659464577773952,
      "grad_norm": 1.02517569065094,
      "learning_rate": 6.683928871592216e-06,
      "loss": 2.9275,
      "step": 61790
    },
    {
      "epoch": 2.65989498149264,
      "grad_norm": 0.9663649201393127,
      "learning_rate": 6.6672361637184714e-06,
      "loss": 2.9864,
      "step": 61800
    },
    {
      "epoch": 2.65989498149264,
      "eval_bleu": 27.323816156169798,
      "eval_gen_len": 27.516,
      "eval_loss": 2.7850329875946045,
      "eval_runtime": 58.6719,
      "eval_samples_per_second": 17.044,
      "eval_steps_per_second": 1.074,
      "step": 61800
    },
    {
      "epoch": 2.660325385211328,
      "grad_norm": 0.8211477994918823,
      "learning_rate": 6.650563607558768e-06,
      "loss": 2.9944,
      "step": 61810
    },
    {
      "epoch": 2.6607557889300164,
      "grad_norm": 0.9873045682907104,
      "learning_rate": 6.6339112067129725e-06,
      "loss": 3.0546,
      "step": 61820
    },
    {
      "epoch": 2.6611861926487044,
      "grad_norm": 0.883518636226654,
      "learning_rate": 6.617278964776508e-06,
      "loss": 3.0124,
      "step": 61830
    },
    {
      "epoch": 2.6616165963673923,
      "grad_norm": 0.9396529793739319,
      "learning_rate": 6.600666885340512e-06,
      "loss": 3.0199,
      "step": 61840
    },
    {
      "epoch": 2.6620470000860808,
      "grad_norm": 0.9832063317298889,
      "learning_rate": 6.5840749719917165e-06,
      "loss": 3.0492,
      "step": 61850
    },
    {
      "epoch": 2.6620470000860808,
      "eval_bleu": 27.278078178390263,
      "eval_gen_len": 27.493,
      "eval_loss": 2.7852649688720703,
      "eval_runtime": 58.9732,
      "eval_samples_per_second": 16.957,
      "eval_steps_per_second": 1.068,
      "step": 61850
    },
    {
      "epoch": 2.6624774038047687,
      "grad_norm": 1.0289592742919922,
      "learning_rate": 6.567503228312522e-06,
      "loss": 2.9326,
      "step": 61860
    },
    {
      "epoch": 2.662907807523457,
      "grad_norm": 1.043946385383606,
      "learning_rate": 6.550951657881011e-06,
      "loss": 2.9536,
      "step": 61870
    },
    {
      "epoch": 2.663338211242145,
      "grad_norm": 0.8677077889442444,
      "learning_rate": 6.534420264270835e-06,
      "loss": 2.9597,
      "step": 61880
    },
    {
      "epoch": 2.6637686149608335,
      "grad_norm": 0.9804404377937317,
      "learning_rate": 6.517909051051352e-06,
      "loss": 2.9377,
      "step": 61890
    },
    {
      "epoch": 2.6641990186795215,
      "grad_norm": 0.9263750314712524,
      "learning_rate": 6.50141802178752e-06,
      "loss": 2.9932,
      "step": 61900
    },
    {
      "epoch": 2.6641990186795215,
      "eval_bleu": 27.329571584623196,
      "eval_gen_len": 27.511,
      "eval_loss": 2.7847843170166016,
      "eval_runtime": 58.7873,
      "eval_samples_per_second": 17.01,
      "eval_steps_per_second": 1.072,
      "step": 61900
    },
    {
      "epoch": 2.6646294223982094,
      "grad_norm": 0.937362551689148,
      "learning_rate": 6.484947180040002e-06,
      "loss": 2.956,
      "step": 61910
    },
    {
      "epoch": 2.665059826116898,
      "grad_norm": 0.8965641856193542,
      "learning_rate": 6.468496529364998e-06,
      "loss": 3.1192,
      "step": 61920
    },
    {
      "epoch": 2.665490229835586,
      "grad_norm": 0.9573920965194702,
      "learning_rate": 6.452066073314467e-06,
      "loss": 3.0502,
      "step": 61930
    },
    {
      "epoch": 2.6659206335542738,
      "grad_norm": 0.9005876779556274,
      "learning_rate": 6.435655815435926e-06,
      "loss": 3.0379,
      "step": 61940
    },
    {
      "epoch": 2.666351037272962,
      "grad_norm": 0.8571312427520752,
      "learning_rate": 6.41926575927253e-06,
      "loss": 2.9898,
      "step": 61950
    },
    {
      "epoch": 2.666351037272962,
      "eval_bleu": 27.36818967750914,
      "eval_gen_len": 27.55,
      "eval_loss": 2.7849783897399902,
      "eval_runtime": 59.2073,
      "eval_samples_per_second": 16.89,
      "eval_steps_per_second": 1.064,
      "step": 61950
    },
    {
      "epoch": 2.66678144099165,
      "grad_norm": 0.8488065004348755,
      "learning_rate": 6.402895908363149e-06,
      "loss": 2.9942,
      "step": 61960
    },
    {
      "epoch": 2.667211844710338,
      "grad_norm": 0.9894636273384094,
      "learning_rate": 6.386546266242188e-06,
      "loss": 2.9865,
      "step": 61970
    },
    {
      "epoch": 2.6676422484290265,
      "grad_norm": 1.0369330644607544,
      "learning_rate": 6.37021683643978e-06,
      "loss": 2.9981,
      "step": 61980
    },
    {
      "epoch": 2.6680726521477145,
      "grad_norm": 0.8769416213035583,
      "learning_rate": 6.353907622481625e-06,
      "loss": 3.04,
      "step": 61990
    },
    {
      "epoch": 2.6685030558664025,
      "grad_norm": 0.9577592611312866,
      "learning_rate": 6.3376186278891195e-06,
      "loss": 3.0315,
      "step": 62000
    },
    {
      "epoch": 2.6685030558664025,
      "eval_bleu": 27.18377032112914,
      "eval_gen_len": 27.512,
      "eval_loss": 2.7855587005615234,
      "eval_runtime": 59.3496,
      "eval_samples_per_second": 16.849,
      "eval_steps_per_second": 1.062,
      "step": 62000
    },
    {
      "epoch": 2.668933459585091,
      "grad_norm": 1.0126376152038574,
      "learning_rate": 6.321349856179238e-06,
      "loss": 3.0809,
      "step": 62010
    },
    {
      "epoch": 2.669363863303779,
      "grad_norm": 0.8781440258026123,
      "learning_rate": 6.305101310864603e-06,
      "loss": 3.025,
      "step": 62020
    },
    {
      "epoch": 2.669794267022467,
      "grad_norm": 0.9324425458908081,
      "learning_rate": 6.2888729954534985e-06,
      "loss": 3.0541,
      "step": 62030
    },
    {
      "epoch": 2.670224670741155,
      "grad_norm": 0.8651586174964905,
      "learning_rate": 6.27266491344981e-06,
      "loss": 2.9255,
      "step": 62040
    },
    {
      "epoch": 2.670655074459843,
      "grad_norm": 0.9164531230926514,
      "learning_rate": 6.2564770683530835e-06,
      "loss": 3.0229,
      "step": 62050
    },
    {
      "epoch": 2.670655074459843,
      "eval_bleu": 27.237557673407156,
      "eval_gen_len": 27.511,
      "eval_loss": 2.7850699424743652,
      "eval_runtime": 59.1356,
      "eval_samples_per_second": 16.91,
      "eval_steps_per_second": 1.065,
      "step": 62050
    },
    {
      "epoch": 2.6710854781785316,
      "grad_norm": 0.9180956482887268,
      "learning_rate": 6.240309463658456e-06,
      "loss": 2.9836,
      "step": 62060
    },
    {
      "epoch": 2.6715158818972196,
      "grad_norm": 0.9223865270614624,
      "learning_rate": 6.2241621028567345e-06,
      "loss": 3.0282,
      "step": 62070
    },
    {
      "epoch": 2.671946285615908,
      "grad_norm": 0.9076625108718872,
      "learning_rate": 6.208034989434308e-06,
      "loss": 3.0,
      "step": 62080
    },
    {
      "epoch": 2.672376689334596,
      "grad_norm": 0.944990873336792,
      "learning_rate": 6.191928126873281e-06,
      "loss": 2.9752,
      "step": 62090
    },
    {
      "epoch": 2.672807093053284,
      "grad_norm": 0.961110532283783,
      "learning_rate": 6.175841518651248e-06,
      "loss": 3.0244,
      "step": 62100
    },
    {
      "epoch": 2.672807093053284,
      "eval_bleu": 27.197319881675813,
      "eval_gen_len": 27.551,
      "eval_loss": 2.784848213195801,
      "eval_runtime": 58.7447,
      "eval_samples_per_second": 17.023,
      "eval_steps_per_second": 1.072,
      "step": 62100
    },
    {
      "epoch": 2.6732374967719723,
      "grad_norm": 0.8362260460853577,
      "learning_rate": 6.159775168241555e-06,
      "loss": 2.9143,
      "step": 62110
    },
    {
      "epoch": 2.6736679004906603,
      "grad_norm": 0.9275223612785339,
      "learning_rate": 6.143729079113136e-06,
      "loss": 2.9292,
      "step": 62120
    },
    {
      "epoch": 2.6740983042093482,
      "grad_norm": 0.9487325549125671,
      "learning_rate": 6.127703254730521e-06,
      "loss": 3.0342,
      "step": 62130
    },
    {
      "epoch": 2.6745287079280367,
      "grad_norm": 0.9240336418151855,
      "learning_rate": 6.111697698553909e-06,
      "loss": 3.0135,
      "step": 62140
    },
    {
      "epoch": 2.6749591116467246,
      "grad_norm": 0.9790151715278625,
      "learning_rate": 6.095712414039068e-06,
      "loss": 2.9732,
      "step": 62150
    },
    {
      "epoch": 2.6749591116467246,
      "eval_bleu": 27.245922708287676,
      "eval_gen_len": 27.504,
      "eval_loss": 2.784970760345459,
      "eval_runtime": 59.0229,
      "eval_samples_per_second": 16.943,
      "eval_steps_per_second": 1.067,
      "step": 62150
    },
    {
      "epoch": 2.6753895153654126,
      "grad_norm": 0.8973779082298279,
      "learning_rate": 6.079747404637448e-06,
      "loss": 2.9425,
      "step": 62160
    },
    {
      "epoch": 2.675819919084101,
      "grad_norm": 0.9693430066108704,
      "learning_rate": 6.0638026737960815e-06,
      "loss": 3.0054,
      "step": 62170
    },
    {
      "epoch": 2.676250322802789,
      "grad_norm": 0.8707205653190613,
      "learning_rate": 6.047878224957671e-06,
      "loss": 3.0173,
      "step": 62180
    },
    {
      "epoch": 2.676680726521477,
      "grad_norm": 1.010843276977539,
      "learning_rate": 6.031974061560442e-06,
      "loss": 2.9414,
      "step": 62190
    },
    {
      "epoch": 2.6771111302401653,
      "grad_norm": 0.9461944699287415,
      "learning_rate": 6.016090187038348e-06,
      "loss": 3.0148,
      "step": 62200
    },
    {
      "epoch": 2.6771111302401653,
      "eval_bleu": 27.330507474939054,
      "eval_gen_len": 27.574,
      "eval_loss": 2.785416841506958,
      "eval_runtime": 59.1034,
      "eval_samples_per_second": 16.919,
      "eval_steps_per_second": 1.066,
      "step": 62200
    },
    {
      "epoch": 2.6775415339588533,
      "grad_norm": 1.0156686305999756,
      "learning_rate": 6.000226604820891e-06,
      "loss": 2.8699,
      "step": 62210
    },
    {
      "epoch": 2.6779719376775413,
      "grad_norm": 0.8722211718559265,
      "learning_rate": 5.984383318333231e-06,
      "loss": 2.973,
      "step": 62220
    },
    {
      "epoch": 2.6784023413962297,
      "grad_norm": 0.9269514679908752,
      "learning_rate": 5.968560330996143e-06,
      "loss": 2.9824,
      "step": 62230
    },
    {
      "epoch": 2.6788327451149176,
      "grad_norm": 0.960054337978363,
      "learning_rate": 5.9527576462259925e-06,
      "loss": 2.9594,
      "step": 62240
    },
    {
      "epoch": 2.679263148833606,
      "grad_norm": 1.07938551902771,
      "learning_rate": 5.936975267434786e-06,
      "loss": 2.9282,
      "step": 62250
    },
    {
      "epoch": 2.679263148833606,
      "eval_bleu": 27.114111199368285,
      "eval_gen_len": 27.463,
      "eval_loss": 2.7851617336273193,
      "eval_runtime": 58.5083,
      "eval_samples_per_second": 17.092,
      "eval_steps_per_second": 1.077,
      "step": 62250
    },
    {
      "epoch": 2.679693552552294,
      "grad_norm": 0.8995181918144226,
      "learning_rate": 5.92121319803014e-06,
      "loss": 3.0495,
      "step": 62260
    },
    {
      "epoch": 2.6801239562709824,
      "grad_norm": 0.9387481212615967,
      "learning_rate": 5.905471441415267e-06,
      "loss": 3.0318,
      "step": 62270
    },
    {
      "epoch": 2.6805543599896704,
      "grad_norm": 0.9035784006118774,
      "learning_rate": 5.889750000989014e-06,
      "loss": 2.9785,
      "step": 62280
    },
    {
      "epoch": 2.6809847637083584,
      "grad_norm": 0.9103248715400696,
      "learning_rate": 5.874048880145844e-06,
      "loss": 2.9283,
      "step": 62290
    },
    {
      "epoch": 2.6814151674270468,
      "grad_norm": 0.9171610474586487,
      "learning_rate": 5.8583680822758225e-06,
      "loss": 2.978,
      "step": 62300
    },
    {
      "epoch": 2.6814151674270468,
      "eval_bleu": 27.195750420957026,
      "eval_gen_len": 27.482,
      "eval_loss": 2.7850959300994873,
      "eval_runtime": 58.6073,
      "eval_samples_per_second": 17.063,
      "eval_steps_per_second": 1.075,
      "step": 62300
    },
    {
      "epoch": 2.6818455711457347,
      "grad_norm": 0.8682742714881897,
      "learning_rate": 5.8427076107646415e-06,
      "loss": 2.942,
      "step": 62310
    },
    {
      "epoch": 2.6822759748644227,
      "grad_norm": 0.8373603224754333,
      "learning_rate": 5.8270674689935635e-06,
      "loss": 2.9499,
      "step": 62320
    },
    {
      "epoch": 2.682706378583111,
      "grad_norm": 0.9143648147583008,
      "learning_rate": 5.811447660339508e-06,
      "loss": 2.89,
      "step": 62330
    },
    {
      "epoch": 2.683136782301799,
      "grad_norm": 0.93813556432724,
      "learning_rate": 5.795848188175035e-06,
      "loss": 3.0287,
      "step": 62340
    },
    {
      "epoch": 2.683567186020487,
      "grad_norm": 0.9128800630569458,
      "learning_rate": 5.780269055868181e-06,
      "loss": 3.0573,
      "step": 62350
    },
    {
      "epoch": 2.683567186020487,
      "eval_bleu": 27.195936432930527,
      "eval_gen_len": 27.505,
      "eval_loss": 2.7851154804229736,
      "eval_runtime": 58.4737,
      "eval_samples_per_second": 17.102,
      "eval_steps_per_second": 1.077,
      "step": 62350
    },
    {
      "epoch": 2.6839975897391755,
      "grad_norm": 0.7436906695365906,
      "learning_rate": 5.764710266782735e-06,
      "loss": 2.9017,
      "step": 62360
    },
    {
      "epoch": 2.6844279934578634,
      "grad_norm": 0.8772198557853699,
      "learning_rate": 5.749171824277999e-06,
      "loss": 2.9788,
      "step": 62370
    },
    {
      "epoch": 2.6848583971765514,
      "grad_norm": 0.8922585844993591,
      "learning_rate": 5.7336537317089435e-06,
      "loss": 2.9843,
      "step": 62380
    },
    {
      "epoch": 2.68528880089524,
      "grad_norm": 0.9609459638595581,
      "learning_rate": 5.718155992426099e-06,
      "loss": 2.9033,
      "step": 62390
    },
    {
      "epoch": 2.6857192046139278,
      "grad_norm": 0.9843453764915466,
      "learning_rate": 5.702678609775658e-06,
      "loss": 2.9263,
      "step": 62400
    },
    {
      "epoch": 2.6857192046139278,
      "eval_bleu": 27.04623037888261,
      "eval_gen_len": 27.47,
      "eval_loss": 2.7847323417663574,
      "eval_runtime": 58.7295,
      "eval_samples_per_second": 17.027,
      "eval_steps_per_second": 1.073,
      "step": 62400
    },
    {
      "epoch": 2.6861496083326157,
      "grad_norm": 0.9876990914344788,
      "learning_rate": 5.687221587099334e-06,
      "loss": 2.9791,
      "step": 62410
    },
    {
      "epoch": 2.686580012051304,
      "grad_norm": 0.8678461313247681,
      "learning_rate": 5.671784927734525e-06,
      "loss": 2.9902,
      "step": 62420
    },
    {
      "epoch": 2.687010415769992,
      "grad_norm": 0.8851195573806763,
      "learning_rate": 5.6563686350141975e-06,
      "loss": 3.0703,
      "step": 62430
    },
    {
      "epoch": 2.6874408194886805,
      "grad_norm": 0.8888192772865295,
      "learning_rate": 5.640972712266901e-06,
      "loss": 2.9977,
      "step": 62440
    },
    {
      "epoch": 2.6878712232073685,
      "grad_norm": 0.9135542511940002,
      "learning_rate": 5.625597162816832e-06,
      "loss": 3.0749,
      "step": 62450
    },
    {
      "epoch": 2.6878712232073685,
      "eval_bleu": 27.160392863505912,
      "eval_gen_len": 27.506,
      "eval_loss": 2.7852866649627686,
      "eval_runtime": 58.5693,
      "eval_samples_per_second": 17.074,
      "eval_steps_per_second": 1.076,
      "step": 62450
    },
    {
      "epoch": 2.688301626926057,
      "grad_norm": 0.8325506448745728,
      "learning_rate": 5.610241989983733e-06,
      "loss": 3.0414,
      "step": 62460
    },
    {
      "epoch": 2.688732030644745,
      "grad_norm": 0.9404975771903992,
      "learning_rate": 5.594907197083021e-06,
      "loss": 2.9409,
      "step": 62470
    },
    {
      "epoch": 2.689162434363433,
      "grad_norm": 0.8878536224365234,
      "learning_rate": 5.579592787425636e-06,
      "loss": 2.9901,
      "step": 62480
    },
    {
      "epoch": 2.6895928380821212,
      "grad_norm": 0.9390649199485779,
      "learning_rate": 5.5642987643181655e-06,
      "loss": 3.0283,
      "step": 62490
    },
    {
      "epoch": 2.690023241800809,
      "grad_norm": 0.9182093143463135,
      "learning_rate": 5.549025131062791e-06,
      "loss": 3.0131,
      "step": 62500
    },
    {
      "epoch": 2.690023241800809,
      "eval_bleu": 27.113619122979397,
      "eval_gen_len": 27.477,
      "eval_loss": 2.78551983833313,
      "eval_runtime": 58.5043,
      "eval_samples_per_second": 17.093,
      "eval_steps_per_second": 1.077,
      "step": 62500
    },
    {
      "epoch": 2.690453645519497,
      "grad_norm": 0.8800532817840576,
      "learning_rate": 5.533771890957251e-06,
      "loss": 2.9596,
      "step": 62510
    },
    {
      "epoch": 2.6908840492381856,
      "grad_norm": 0.9067397117614746,
      "learning_rate": 5.518539047294935e-06,
      "loss": 2.9172,
      "step": 62520
    },
    {
      "epoch": 2.6913144529568735,
      "grad_norm": 1.054178237915039,
      "learning_rate": 5.5033266033648005e-06,
      "loss": 3.0113,
      "step": 62530
    },
    {
      "epoch": 2.6917448566755615,
      "grad_norm": 0.9928159713745117,
      "learning_rate": 5.488134562451408e-06,
      "loss": 2.9641,
      "step": 62540
    },
    {
      "epoch": 2.69217526039425,
      "grad_norm": 0.8930362462997437,
      "learning_rate": 5.4729629278348906e-06,
      "loss": 2.9514,
      "step": 62550
    },
    {
      "epoch": 2.69217526039425,
      "eval_bleu": 27.054052448368424,
      "eval_gen_len": 27.483,
      "eval_loss": 2.785629987716675,
      "eval_runtime": 58.7551,
      "eval_samples_per_second": 17.02,
      "eval_steps_per_second": 1.072,
      "step": 62550
    },
    {
      "epoch": 2.692605664112938,
      "grad_norm": 0.8956332206726074,
      "learning_rate": 5.457811702791027e-06,
      "loss": 3.0003,
      "step": 62560
    },
    {
      "epoch": 2.693036067831626,
      "grad_norm": 0.8750614523887634,
      "learning_rate": 5.4426808905911235e-06,
      "loss": 2.8572,
      "step": 62570
    },
    {
      "epoch": 2.6934664715503143,
      "grad_norm": 0.8762413859367371,
      "learning_rate": 5.427570494502143e-06,
      "loss": 2.9407,
      "step": 62580
    },
    {
      "epoch": 2.6938968752690022,
      "grad_norm": 0.917556881904602,
      "learning_rate": 5.4124805177866e-06,
      "loss": 2.9537,
      "step": 62590
    },
    {
      "epoch": 2.69432727898769,
      "grad_norm": 0.9349554777145386,
      "learning_rate": 5.397410963702576e-06,
      "loss": 3.0878,
      "step": 62600
    },
    {
      "epoch": 2.69432727898769,
      "eval_bleu": 27.14927003191422,
      "eval_gen_len": 27.494,
      "eval_loss": 2.7857699394226074,
      "eval_runtime": 58.4748,
      "eval_samples_per_second": 17.101,
      "eval_steps_per_second": 1.077,
      "step": 62600
    },
    {
      "epoch": 2.6947576827063786,
      "grad_norm": 0.8787239193916321,
      "learning_rate": 5.382361835503824e-06,
      "loss": 2.9292,
      "step": 62610
    },
    {
      "epoch": 2.6951880864250666,
      "grad_norm": 0.8936955332756042,
      "learning_rate": 5.367333136439612e-06,
      "loss": 2.9987,
      "step": 62620
    },
    {
      "epoch": 2.695618490143755,
      "grad_norm": 0.950420081615448,
      "learning_rate": 5.3523248697548435e-06,
      "loss": 2.9049,
      "step": 62630
    },
    {
      "epoch": 2.696048893862443,
      "grad_norm": 0.9533776640892029,
      "learning_rate": 5.3373370386899604e-06,
      "loss": 2.9914,
      "step": 62640
    },
    {
      "epoch": 2.6964792975811314,
      "grad_norm": 0.9003772735595703,
      "learning_rate": 5.3223696464810625e-06,
      "loss": 2.9829,
      "step": 62650
    },
    {
      "epoch": 2.6964792975811314,
      "eval_bleu": 27.150592200844688,
      "eval_gen_len": 27.512,
      "eval_loss": 2.7856221199035645,
      "eval_runtime": 58.1373,
      "eval_samples_per_second": 17.201,
      "eval_steps_per_second": 1.084,
      "step": 62650
    },
    {
      "epoch": 2.6969097012998193,
      "grad_norm": 0.9802955389022827,
      "learning_rate": 5.307422696359776e-06,
      "loss": 2.9375,
      "step": 62660
    },
    {
      "epoch": 2.6973401050185073,
      "grad_norm": 0.9973122477531433,
      "learning_rate": 5.292496191553331e-06,
      "loss": 2.9973,
      "step": 62670
    },
    {
      "epoch": 2.6977705087371957,
      "grad_norm": 0.9272966980934143,
      "learning_rate": 5.27759013528456e-06,
      "loss": 2.9635,
      "step": 62680
    },
    {
      "epoch": 2.6982009124558837,
      "grad_norm": 0.8042064905166626,
      "learning_rate": 5.262704530771845e-06,
      "loss": 2.8972,
      "step": 62690
    },
    {
      "epoch": 2.6986313161745716,
      "grad_norm": 0.963327169418335,
      "learning_rate": 5.2478393812292135e-06,
      "loss": 2.9649,
      "step": 62700
    },
    {
      "epoch": 2.6986313161745716,
      "eval_bleu": 27.147601418958484,
      "eval_gen_len": 27.483,
      "eval_loss": 2.785853385925293,
      "eval_runtime": 58.7109,
      "eval_samples_per_second": 17.033,
      "eval_steps_per_second": 1.073,
      "step": 62700
    },
    {
      "epoch": 2.69906171989326,
      "grad_norm": 0.9397956132888794,
      "learning_rate": 5.232994689866189e-06,
      "loss": 2.9151,
      "step": 62710
    },
    {
      "epoch": 2.699492123611948,
      "grad_norm": 1.0109491348266602,
      "learning_rate": 5.2181704598879725e-06,
      "loss": 3.006,
      "step": 62720
    },
    {
      "epoch": 2.699922527330636,
      "grad_norm": 0.8946195840835571,
      "learning_rate": 5.203366694495271e-06,
      "loss": 3.0738,
      "step": 62730
    },
    {
      "epoch": 2.7003529310493244,
      "grad_norm": 0.8762314915657043,
      "learning_rate": 5.188583396884417e-06,
      "loss": 3.0009,
      "step": 62740
    },
    {
      "epoch": 2.7007833347680124,
      "grad_norm": 0.8826411962509155,
      "learning_rate": 5.173820570247312e-06,
      "loss": 2.9507,
      "step": 62750
    },
    {
      "epoch": 2.7007833347680124,
      "eval_bleu": 27.135247418412018,
      "eval_gen_len": 27.532,
      "eval_loss": 2.7855072021484375,
      "eval_runtime": 59.0243,
      "eval_samples_per_second": 16.942,
      "eval_steps_per_second": 1.067,
      "step": 62750
    },
    {
      "epoch": 2.7012137384867003,
      "grad_norm": 0.8855516314506531,
      "learning_rate": 5.159078217771418e-06,
      "loss": 3.0028,
      "step": 62760
    },
    {
      "epoch": 2.7016441422053887,
      "grad_norm": 1.034925937652588,
      "learning_rate": 5.144356342639811e-06,
      "loss": 3.0192,
      "step": 62770
    },
    {
      "epoch": 2.7020745459240767,
      "grad_norm": 0.9176833629608154,
      "learning_rate": 5.129654948031115e-06,
      "loss": 2.9333,
      "step": 62780
    },
    {
      "epoch": 2.7025049496427647,
      "grad_norm": 1.0267037153244019,
      "learning_rate": 5.114974037119569e-06,
      "loss": 2.9133,
      "step": 62790
    },
    {
      "epoch": 2.702935353361453,
      "grad_norm": 1.0001099109649658,
      "learning_rate": 5.100313613074925e-06,
      "loss": 2.9417,
      "step": 62800
    },
    {
      "epoch": 2.702935353361453,
      "eval_bleu": 27.22068484827565,
      "eval_gen_len": 27.494,
      "eval_loss": 2.7855026721954346,
      "eval_runtime": 58.5436,
      "eval_samples_per_second": 17.081,
      "eval_steps_per_second": 1.076,
      "step": 62800
    },
    {
      "epoch": 2.703365757080141,
      "grad_norm": 0.9110832810401917,
      "learning_rate": 5.085673679062597e-06,
      "loss": 2.9437,
      "step": 62810
    },
    {
      "epoch": 2.7037961607988295,
      "grad_norm": 0.9432224631309509,
      "learning_rate": 5.0710542382435e-06,
      "loss": 3.0304,
      "step": 62820
    },
    {
      "epoch": 2.7042265645175174,
      "grad_norm": 0.8238345980644226,
      "learning_rate": 5.056455293774187e-06,
      "loss": 2.9836,
      "step": 62830
    },
    {
      "epoch": 2.704656968236206,
      "grad_norm": 1.071539282798767,
      "learning_rate": 5.041876848806704e-06,
      "loss": 3.0249,
      "step": 62840
    },
    {
      "epoch": 2.705087371954894,
      "grad_norm": 1.0112552642822266,
      "learning_rate": 5.027318906488754e-06,
      "loss": 2.9972,
      "step": 62850
    },
    {
      "epoch": 2.705087371954894,
      "eval_bleu": 27.201718209269423,
      "eval_gen_len": 27.521,
      "eval_loss": 2.785313606262207,
      "eval_runtime": 58.7064,
      "eval_samples_per_second": 17.034,
      "eval_steps_per_second": 1.073,
      "step": 62850
    },
    {
      "epoch": 2.7055177756735818,
      "grad_norm": 0.9918113350868225,
      "learning_rate": 5.012781469963579e-06,
      "loss": 3.0023,
      "step": 62860
    },
    {
      "epoch": 2.70594817939227,
      "grad_norm": 0.9545665979385376,
      "learning_rate": 4.998264542369979e-06,
      "loss": 2.9817,
      "step": 62870
    },
    {
      "epoch": 2.706378583110958,
      "grad_norm": 0.8965981006622314,
      "learning_rate": 4.983768126842358e-06,
      "loss": 3.0964,
      "step": 62880
    },
    {
      "epoch": 2.706808986829646,
      "grad_norm": 0.8748872876167297,
      "learning_rate": 4.969292226510647e-06,
      "loss": 2.9578,
      "step": 62890
    },
    {
      "epoch": 2.7072393905483345,
      "grad_norm": 0.8558990955352783,
      "learning_rate": 4.95483684450041e-06,
      "loss": 2.9178,
      "step": 62900
    },
    {
      "epoch": 2.7072393905483345,
      "eval_bleu": 26.94037216005439,
      "eval_gen_len": 27.499,
      "eval_loss": 2.785257577896118,
      "eval_runtime": 58.8687,
      "eval_samples_per_second": 16.987,
      "eval_steps_per_second": 1.07,
      "step": 62900
    },
    {
      "epoch": 2.7076697942670225,
      "grad_norm": 0.896865725517273,
      "learning_rate": 4.94040198393273e-06,
      "loss": 3.0214,
      "step": 62910
    },
    {
      "epoch": 2.7081001979857104,
      "grad_norm": 0.8588483333587646,
      "learning_rate": 4.9259876479242685e-06,
      "loss": 2.9278,
      "step": 62920
    },
    {
      "epoch": 2.708530601704399,
      "grad_norm": 0.8324906229972839,
      "learning_rate": 4.911593839587259e-06,
      "loss": 2.9998,
      "step": 62930
    },
    {
      "epoch": 2.708961005423087,
      "grad_norm": 0.9638213515281677,
      "learning_rate": 4.897220562029514e-06,
      "loss": 2.91,
      "step": 62940
    },
    {
      "epoch": 2.709391409141775,
      "grad_norm": 0.8476143479347229,
      "learning_rate": 4.882867818354397e-06,
      "loss": 2.9663,
      "step": 62950
    },
    {
      "epoch": 2.709391409141775,
      "eval_bleu": 27.042781280025018,
      "eval_gen_len": 27.521,
      "eval_loss": 2.7854130268096924,
      "eval_runtime": 58.3492,
      "eval_samples_per_second": 17.138,
      "eval_steps_per_second": 1.08,
      "step": 62950
    },
    {
      "epoch": 2.709821812860463,
      "grad_norm": 1.0010032653808594,
      "learning_rate": 4.8685356116608405e-06,
      "loss": 3.0631,
      "step": 62960
    },
    {
      "epoch": 2.710252216579151,
      "grad_norm": 0.7915260195732117,
      "learning_rate": 4.854223945043379e-06,
      "loss": 2.8843,
      "step": 62970
    },
    {
      "epoch": 2.710682620297839,
      "grad_norm": 1.0591968297958374,
      "learning_rate": 4.839932821592042e-06,
      "loss": 2.9839,
      "step": 62980
    },
    {
      "epoch": 2.7111130240165275,
      "grad_norm": 0.9073299169540405,
      "learning_rate": 4.825662244392503e-06,
      "loss": 2.9793,
      "step": 62990
    },
    {
      "epoch": 2.7115434277352155,
      "grad_norm": 1.0219589471817017,
      "learning_rate": 4.811412216525912e-06,
      "loss": 2.9841,
      "step": 63000
    },
    {
      "epoch": 2.7115434277352155,
      "eval_bleu": 27.109656131709052,
      "eval_gen_len": 27.518,
      "eval_loss": 2.7855234146118164,
      "eval_runtime": 59.1969,
      "eval_samples_per_second": 16.893,
      "eval_steps_per_second": 1.064,
      "step": 63000
    },
    {
      "epoch": 2.711973831453904,
      "grad_norm": 0.920194149017334,
      "learning_rate": 4.7971827410690615e-06,
      "loss": 2.9896,
      "step": 63010
    },
    {
      "epoch": 2.712404235172592,
      "grad_norm": 0.8584157228469849,
      "learning_rate": 4.78297382109425e-06,
      "loss": 2.9074,
      "step": 63020
    },
    {
      "epoch": 2.7128346388912803,
      "grad_norm": 1.0949372053146362,
      "learning_rate": 4.76878545966939e-06,
      "loss": 2.998,
      "step": 63030
    },
    {
      "epoch": 2.7132650426099683,
      "grad_norm": 0.9263409972190857,
      "learning_rate": 4.754617659857896e-06,
      "loss": 2.9367,
      "step": 63040
    },
    {
      "epoch": 2.7136954463286562,
      "grad_norm": 0.9422834515571594,
      "learning_rate": 4.7404704247187905e-06,
      "loss": 2.9782,
      "step": 63050
    },
    {
      "epoch": 2.7136954463286562,
      "eval_bleu": 27.130974794970935,
      "eval_gen_len": 27.556,
      "eval_loss": 2.7849998474121094,
      "eval_runtime": 58.7386,
      "eval_samples_per_second": 17.025,
      "eval_steps_per_second": 1.073,
      "step": 63050
    },
    {
      "epoch": 2.7141258500473446,
      "grad_norm": 0.9439685344696045,
      "learning_rate": 4.726343757306651e-06,
      "loss": 2.967,
      "step": 63060
    },
    {
      "epoch": 2.7145562537660326,
      "grad_norm": 0.8490992784500122,
      "learning_rate": 4.712237660671592e-06,
      "loss": 2.9991,
      "step": 63070
    },
    {
      "epoch": 2.7149866574847206,
      "grad_norm": 0.9305508136749268,
      "learning_rate": 4.698152137859291e-06,
      "loss": 2.9673,
      "step": 63080
    },
    {
      "epoch": 2.715417061203409,
      "grad_norm": 0.8752739429473877,
      "learning_rate": 4.684087191910968e-06,
      "loss": 2.9525,
      "step": 63090
    },
    {
      "epoch": 2.715847464922097,
      "grad_norm": 0.8289071917533875,
      "learning_rate": 4.670042825863475e-06,
      "loss": 2.8812,
      "step": 63100
    },
    {
      "epoch": 2.715847464922097,
      "eval_bleu": 27.128113990615567,
      "eval_gen_len": 27.521,
      "eval_loss": 2.785031795501709,
      "eval_runtime": 58.3786,
      "eval_samples_per_second": 17.13,
      "eval_steps_per_second": 1.079,
      "step": 63100
    },
    {
      "epoch": 2.716277868640785,
      "grad_norm": 0.8334745764732361,
      "learning_rate": 4.656019042749115e-06,
      "loss": 2.9449,
      "step": 63110
    },
    {
      "epoch": 2.7167082723594733,
      "grad_norm": 0.922825813293457,
      "learning_rate": 4.642015845595826e-06,
      "loss": 2.9467,
      "step": 63120
    },
    {
      "epoch": 2.7171386760781613,
      "grad_norm": 0.9949395060539246,
      "learning_rate": 4.628033237427065e-06,
      "loss": 2.898,
      "step": 63130
    },
    {
      "epoch": 2.7175690797968493,
      "grad_norm": 1.0992237329483032,
      "learning_rate": 4.614071221261862e-06,
      "loss": 2.9796,
      "step": 63140
    },
    {
      "epoch": 2.7179994835155377,
      "grad_norm": 0.957940936088562,
      "learning_rate": 4.600129800114794e-06,
      "loss": 2.9598,
      "step": 63150
    },
    {
      "epoch": 2.7179994835155377,
      "eval_bleu": 27.201910510637365,
      "eval_gen_len": 27.501,
      "eval_loss": 2.7852001190185547,
      "eval_runtime": 58.6684,
      "eval_samples_per_second": 17.045,
      "eval_steps_per_second": 1.074,
      "step": 63150
    },
    {
      "epoch": 2.7184298872342256,
      "grad_norm": 0.9147322177886963,
      "learning_rate": 4.586208976995954e-06,
      "loss": 3.0436,
      "step": 63160
    },
    {
      "epoch": 2.7188602909529136,
      "grad_norm": 0.9442779421806335,
      "learning_rate": 4.57230875491107e-06,
      "loss": 2.9555,
      "step": 63170
    },
    {
      "epoch": 2.719290694671602,
      "grad_norm": 0.7900559902191162,
      "learning_rate": 4.558429136861331e-06,
      "loss": 2.9537,
      "step": 63180
    },
    {
      "epoch": 2.71972109839029,
      "grad_norm": 0.9060413837432861,
      "learning_rate": 4.544570125843561e-06,
      "loss": 2.9264,
      "step": 63190
    },
    {
      "epoch": 2.7201515021089784,
      "grad_norm": 0.860859215259552,
      "learning_rate": 4.530731724850057e-06,
      "loss": 2.9442,
      "step": 63200
    },
    {
      "epoch": 2.7201515021089784,
      "eval_bleu": 27.144565800257215,
      "eval_gen_len": 27.485,
      "eval_loss": 2.785243034362793,
      "eval_runtime": 59.5793,
      "eval_samples_per_second": 16.784,
      "eval_steps_per_second": 1.057,
      "step": 63200
    },
    {
      "epoch": 2.7205819058276663,
      "grad_norm": 0.8884339928627014,
      "learning_rate": 4.516913936868739e-06,
      "loss": 3.0017,
      "step": 63210
    },
    {
      "epoch": 2.7210123095463548,
      "grad_norm": 0.9151220917701721,
      "learning_rate": 4.5031167648830085e-06,
      "loss": 3.1333,
      "step": 63220
    },
    {
      "epoch": 2.7214427132650427,
      "grad_norm": 0.9809483289718628,
      "learning_rate": 4.489340211871873e-06,
      "loss": 3.0407,
      "step": 63230
    },
    {
      "epoch": 2.7218731169837307,
      "grad_norm": 0.940812349319458,
      "learning_rate": 4.475584280809852e-06,
      "loss": 3.0413,
      "step": 63240
    },
    {
      "epoch": 2.722303520702419,
      "grad_norm": 0.8438661098480225,
      "learning_rate": 4.461848974667016e-06,
      "loss": 2.8413,
      "step": 63250
    },
    {
      "epoch": 2.722303520702419,
      "eval_bleu": 27.332876650201634,
      "eval_gen_len": 27.508,
      "eval_loss": 2.7852439880371094,
      "eval_runtime": 58.9752,
      "eval_samples_per_second": 16.956,
      "eval_steps_per_second": 1.068,
      "step": 63250
    },
    {
      "epoch": 2.722733924421107,
      "grad_norm": 0.9691435098648071,
      "learning_rate": 4.4481342964090014e-06,
      "loss": 3.0045,
      "step": 63260
    },
    {
      "epoch": 2.723164328139795,
      "grad_norm": 0.9746605753898621,
      "learning_rate": 4.434440248996963e-06,
      "loss": 2.8827,
      "step": 63270
    },
    {
      "epoch": 2.7235947318584834,
      "grad_norm": 0.8558990359306335,
      "learning_rate": 4.4207668353876465e-06,
      "loss": 2.943,
      "step": 63280
    },
    {
      "epoch": 2.7240251355771714,
      "grad_norm": 1.0141218900680542,
      "learning_rate": 4.407114058533291e-06,
      "loss": 2.9552,
      "step": 63290
    },
    {
      "epoch": 2.7244555392958594,
      "grad_norm": 0.9165287017822266,
      "learning_rate": 4.393481921381715e-06,
      "loss": 2.9797,
      "step": 63300
    },
    {
      "epoch": 2.7244555392958594,
      "eval_bleu": 27.24480170866959,
      "eval_gen_len": 27.481,
      "eval_loss": 2.785630464553833,
      "eval_runtime": 58.6984,
      "eval_samples_per_second": 17.036,
      "eval_steps_per_second": 1.073,
      "step": 63300
    },
    {
      "epoch": 2.724885943014548,
      "grad_norm": 0.8681379556655884,
      "learning_rate": 4.379870426876253e-06,
      "loss": 2.9821,
      "step": 63310
    },
    {
      "epoch": 2.7253163467332358,
      "grad_norm": 0.9125285744667053,
      "learning_rate": 4.3662795779558e-06,
      "loss": 2.9265,
      "step": 63320
    },
    {
      "epoch": 2.7257467504519237,
      "grad_norm": 0.8821460604667664,
      "learning_rate": 4.3527093775548086e-06,
      "loss": 2.9555,
      "step": 63330
    },
    {
      "epoch": 2.726177154170612,
      "grad_norm": 0.8913881778717041,
      "learning_rate": 4.339159828603223e-06,
      "loss": 2.9447,
      "step": 63340
    },
    {
      "epoch": 2.7266075578893,
      "grad_norm": 0.9716309905052185,
      "learning_rate": 4.325630934026592e-06,
      "loss": 3.0246,
      "step": 63350
    },
    {
      "epoch": 2.7266075578893,
      "eval_bleu": 27.156993676016484,
      "eval_gen_len": 27.517,
      "eval_loss": 2.785440683364868,
      "eval_runtime": 59.055,
      "eval_samples_per_second": 16.933,
      "eval_steps_per_second": 1.067,
      "step": 63350
    },
    {
      "epoch": 2.727037961607988,
      "grad_norm": 0.9668906927108765,
      "learning_rate": 4.312122696745957e-06,
      "loss": 3.0303,
      "step": 63360
    },
    {
      "epoch": 2.7274683653266765,
      "grad_norm": 1.023827075958252,
      "learning_rate": 4.298635119677929e-06,
      "loss": 2.9454,
      "step": 63370
    },
    {
      "epoch": 2.7278987690453644,
      "grad_norm": 1.038901686668396,
      "learning_rate": 4.285168205734624e-06,
      "loss": 3.0593,
      "step": 63380
    },
    {
      "epoch": 2.728329172764053,
      "grad_norm": 0.7897998094558716,
      "learning_rate": 4.271721957823749e-06,
      "loss": 2.9525,
      "step": 63390
    },
    {
      "epoch": 2.728759576482741,
      "grad_norm": 0.9926156401634216,
      "learning_rate": 4.258296378848492e-06,
      "loss": 2.9298,
      "step": 63400
    },
    {
      "epoch": 2.728759576482741,
      "eval_bleu": 27.014475063463532,
      "eval_gen_len": 27.506,
      "eval_loss": 2.7858192920684814,
      "eval_runtime": 58.4669,
      "eval_samples_per_second": 17.104,
      "eval_steps_per_second": 1.078,
      "step": 63400
    },
    {
      "epoch": 2.7291899802014288,
      "grad_norm": 0.8490446209907532,
      "learning_rate": 4.244891471707602e-06,
      "loss": 2.966,
      "step": 63410
    },
    {
      "epoch": 2.729620383920117,
      "grad_norm": 0.8304172158241272,
      "learning_rate": 4.231507239295374e-06,
      "loss": 2.9478,
      "step": 63420
    },
    {
      "epoch": 2.730050787638805,
      "grad_norm": 0.9061599969863892,
      "learning_rate": 4.21814368450163e-06,
      "loss": 2.9493,
      "step": 63430
    },
    {
      "epoch": 2.7304811913574936,
      "grad_norm": 0.8794320821762085,
      "learning_rate": 4.204800810211751e-06,
      "loss": 2.9971,
      "step": 63440
    },
    {
      "epoch": 2.7309115950761815,
      "grad_norm": 0.95061856508255,
      "learning_rate": 4.191478619306588e-06,
      "loss": 3.0422,
      "step": 63450
    },
    {
      "epoch": 2.7309115950761815,
      "eval_bleu": 27.071361434854637,
      "eval_gen_len": 27.507,
      "eval_loss": 2.7862210273742676,
      "eval_runtime": 58.8632,
      "eval_samples_per_second": 16.989,
      "eval_steps_per_second": 1.07,
      "step": 63450
    },
    {
      "epoch": 2.7313419987948695,
      "grad_norm": 0.9553608298301697,
      "learning_rate": 4.178177114662607e-06,
      "loss": 2.9881,
      "step": 63460
    },
    {
      "epoch": 2.731772402513558,
      "grad_norm": 0.8375007510185242,
      "learning_rate": 4.164896299151743e-06,
      "loss": 2.9233,
      "step": 63470
    },
    {
      "epoch": 2.732202806232246,
      "grad_norm": 0.9467208981513977,
      "learning_rate": 4.1516361756415265e-06,
      "loss": 3.0476,
      "step": 63480
    },
    {
      "epoch": 2.732633209950934,
      "grad_norm": 0.9430877566337585,
      "learning_rate": 4.1383967469949434e-06,
      "loss": 3.0043,
      "step": 63490
    },
    {
      "epoch": 2.7330636136696222,
      "grad_norm": 1.0588220357894897,
      "learning_rate": 4.1251780160705636e-06,
      "loss": 2.9782,
      "step": 63500
    },
    {
      "epoch": 2.7330636136696222,
      "eval_bleu": 27.15523339757526,
      "eval_gen_len": 27.502,
      "eval_loss": 2.786022186279297,
      "eval_runtime": 58.6374,
      "eval_samples_per_second": 17.054,
      "eval_steps_per_second": 1.074,
      "step": 63500
    },
    {
      "epoch": 2.73349401738831,
      "grad_norm": 0.8927841186523438,
      "learning_rate": 4.1119799857225025e-06,
      "loss": 2.9117,
      "step": 63510
    },
    {
      "epoch": 2.733924421106998,
      "grad_norm": 0.8265674710273743,
      "learning_rate": 4.098802658800338e-06,
      "loss": 3.0035,
      "step": 63520
    },
    {
      "epoch": 2.7343548248256866,
      "grad_norm": 1.0556217432022095,
      "learning_rate": 4.08564603814926e-06,
      "loss": 3.1017,
      "step": 63530
    },
    {
      "epoch": 2.7347852285443746,
      "grad_norm": 0.954421877861023,
      "learning_rate": 4.072510126609919e-06,
      "loss": 3.0631,
      "step": 63540
    },
    {
      "epoch": 2.7352156322630625,
      "grad_norm": 1.0368940830230713,
      "learning_rate": 4.059394927018556e-06,
      "loss": 3.0607,
      "step": 63550
    },
    {
      "epoch": 2.7352156322630625,
      "eval_bleu": 27.120850105024243,
      "eval_gen_len": 27.458,
      "eval_loss": 2.7858152389526367,
      "eval_runtime": 58.8358,
      "eval_samples_per_second": 16.996,
      "eval_steps_per_second": 1.071,
      "step": 63550
    },
    {
      "epoch": 2.735646035981751,
      "grad_norm": 0.8716344237327576,
      "learning_rate": 4.046300442206874e-06,
      "loss": 2.9919,
      "step": 63560
    },
    {
      "epoch": 2.736076439700439,
      "grad_norm": 0.9246827960014343,
      "learning_rate": 4.033226675002155e-06,
      "loss": 2.9579,
      "step": 63570
    },
    {
      "epoch": 2.736506843419127,
      "grad_norm": 0.885505735874176,
      "learning_rate": 4.020173628227164e-06,
      "loss": 2.9526,
      "step": 63580
    },
    {
      "epoch": 2.7369372471378153,
      "grad_norm": 0.8706366419792175,
      "learning_rate": 4.0071413047002346e-06,
      "loss": 2.9821,
      "step": 63590
    },
    {
      "epoch": 2.7373676508565032,
      "grad_norm": 0.8855228424072266,
      "learning_rate": 3.994129707235228e-06,
      "loss": 2.9644,
      "step": 63600
    },
    {
      "epoch": 2.7373676508565032,
      "eval_bleu": 27.056517257242188,
      "eval_gen_len": 27.454,
      "eval_loss": 2.785658359527588,
      "eval_runtime": 59.0024,
      "eval_samples_per_second": 16.948,
      "eval_steps_per_second": 1.068,
      "step": 63600
    },
    {
      "epoch": 2.7377980545751917,
      "grad_norm": 1.037896990776062,
      "learning_rate": 3.981138838641485e-06,
      "loss": 2.9676,
      "step": 63610
    },
    {
      "epoch": 2.7382284582938796,
      "grad_norm": 0.8590984344482422,
      "learning_rate": 3.968168701723907e-06,
      "loss": 3.0082,
      "step": 63620
    },
    {
      "epoch": 2.738658862012568,
      "grad_norm": 1.0211002826690674,
      "learning_rate": 3.955219299282909e-06,
      "loss": 3.1098,
      "step": 63630
    },
    {
      "epoch": 2.739089265731256,
      "grad_norm": 0.8961228132247925,
      "learning_rate": 3.942290634114443e-06,
      "loss": 3.0854,
      "step": 63640
    },
    {
      "epoch": 2.739519669449944,
      "grad_norm": 0.9320461750030518,
      "learning_rate": 3.929382709009932e-06,
      "loss": 2.9246,
      "step": 63650
    },
    {
      "epoch": 2.739519669449944,
      "eval_bleu": 27.143239913835096,
      "eval_gen_len": 27.468,
      "eval_loss": 2.7856905460357666,
      "eval_runtime": 58.7339,
      "eval_samples_per_second": 17.026,
      "eval_steps_per_second": 1.073,
      "step": 63650
    },
    {
      "epoch": 2.7399500731686324,
      "grad_norm": 0.9935911297798157,
      "learning_rate": 3.916495526756403e-06,
      "loss": 2.9034,
      "step": 63660
    },
    {
      "epoch": 2.7403804768873203,
      "grad_norm": 0.9507816433906555,
      "learning_rate": 3.9036290901363186e-06,
      "loss": 3.0129,
      "step": 63670
    },
    {
      "epoch": 2.7408108806060083,
      "grad_norm": 0.9982491731643677,
      "learning_rate": 3.8907834019277225e-06,
      "loss": 2.9784,
      "step": 63680
    },
    {
      "epoch": 2.7412412843246967,
      "grad_norm": 0.9006518125534058,
      "learning_rate": 3.877958464904186e-06,
      "loss": 3.003,
      "step": 63690
    },
    {
      "epoch": 2.7416716880433847,
      "grad_norm": 0.966763436794281,
      "learning_rate": 3.865154281834727e-06,
      "loss": 2.9754,
      "step": 63700
    },
    {
      "epoch": 2.7416716880433847,
      "eval_bleu": 27.279096707280694,
      "eval_gen_len": 27.524,
      "eval_loss": 2.785762310028076,
      "eval_runtime": 58.931,
      "eval_samples_per_second": 16.969,
      "eval_steps_per_second": 1.069,
      "step": 63700
    },
    {
      "epoch": 2.7421020917620726,
      "grad_norm": 0.8858239650726318,
      "learning_rate": 3.852370855483966e-06,
      "loss": 2.9455,
      "step": 63710
    },
    {
      "epoch": 2.742532495480761,
      "grad_norm": 0.9003069400787354,
      "learning_rate": 3.839608188611987e-06,
      "loss": 3.0176,
      "step": 63720
    },
    {
      "epoch": 2.742962899199449,
      "grad_norm": 0.9597200155258179,
      "learning_rate": 3.826866283974429e-06,
      "loss": 2.9004,
      "step": 63730
    },
    {
      "epoch": 2.743393302918137,
      "grad_norm": 0.9161575436592102,
      "learning_rate": 3.8141451443223895e-06,
      "loss": 3.0446,
      "step": 63740
    },
    {
      "epoch": 2.7438237066368254,
      "grad_norm": 0.9596095681190491,
      "learning_rate": 3.8014447724025515e-06,
      "loss": 2.9677,
      "step": 63750
    },
    {
      "epoch": 2.7438237066368254,
      "eval_bleu": 27.045197459403646,
      "eval_gen_len": 27.489,
      "eval_loss": 2.7855844497680664,
      "eval_runtime": 58.7867,
      "eval_samples_per_second": 17.011,
      "eval_steps_per_second": 1.072,
      "step": 63750
    },
    {
      "epoch": 2.7442541103555134,
      "grad_norm": 1.0157859325408936,
      "learning_rate": 3.788765170957087e-06,
      "loss": 2.9101,
      "step": 63760
    },
    {
      "epoch": 2.7446845140742013,
      "grad_norm": 1.0120912790298462,
      "learning_rate": 3.7761063427236733e-06,
      "loss": 3.0405,
      "step": 63770
    },
    {
      "epoch": 2.7451149177928897,
      "grad_norm": 0.8487763404846191,
      "learning_rate": 3.763468290435501e-06,
      "loss": 3.0276,
      "step": 63780
    },
    {
      "epoch": 2.7455453215115777,
      "grad_norm": 0.874380886554718,
      "learning_rate": 3.7508510168212884e-06,
      "loss": 2.9609,
      "step": 63790
    },
    {
      "epoch": 2.745975725230266,
      "grad_norm": 0.9548276662826538,
      "learning_rate": 3.7382545246053004e-06,
      "loss": 2.9362,
      "step": 63800
    },
    {
      "epoch": 2.745975725230266,
      "eval_bleu": 27.12096102593871,
      "eval_gen_len": 27.489,
      "eval_loss": 2.7850735187530518,
      "eval_runtime": 58.6142,
      "eval_samples_per_second": 17.061,
      "eval_steps_per_second": 1.075,
      "step": 63800
    },
    {
      "epoch": 2.746406128948954,
      "grad_norm": 0.7864153385162354,
      "learning_rate": 3.7256788165072164e-06,
      "loss": 2.9424,
      "step": 63810
    },
    {
      "epoch": 2.7468365326676425,
      "grad_norm": 0.8884319067001343,
      "learning_rate": 3.713123895242321e-06,
      "loss": 2.9595,
      "step": 63820
    },
    {
      "epoch": 2.7472669363863305,
      "grad_norm": 0.9427522420883179,
      "learning_rate": 3.700589763521378e-06,
      "loss": 2.9847,
      "step": 63830
    },
    {
      "epoch": 2.7476973401050184,
      "grad_norm": 0.8373041152954102,
      "learning_rate": 3.688076424050668e-06,
      "loss": 2.9258,
      "step": 63840
    },
    {
      "epoch": 2.748127743823707,
      "grad_norm": 1.132939338684082,
      "learning_rate": 3.675583879531963e-06,
      "loss": 2.9216,
      "step": 63850
    },
    {
      "epoch": 2.748127743823707,
      "eval_bleu": 27.218387895055002,
      "eval_gen_len": 27.489,
      "eval_loss": 2.7853338718414307,
      "eval_runtime": 58.3405,
      "eval_samples_per_second": 17.141,
      "eval_steps_per_second": 1.08,
      "step": 63850
    },
    {
      "epoch": 2.748558147542395,
      "grad_norm": 0.9582326412200928,
      "learning_rate": 3.6631121326625827e-06,
      "loss": 2.9125,
      "step": 63860
    },
    {
      "epoch": 2.7489885512610828,
      "grad_norm": 1.0202703475952148,
      "learning_rate": 3.650661186135307e-06,
      "loss": 2.9725,
      "step": 63870
    },
    {
      "epoch": 2.749418954979771,
      "grad_norm": 1.109975814819336,
      "learning_rate": 3.6382310426384734e-06,
      "loss": 2.986,
      "step": 63880
    },
    {
      "epoch": 2.749849358698459,
      "grad_norm": 0.9872991442680359,
      "learning_rate": 3.6258217048558917e-06,
      "loss": 2.9831,
      "step": 63890
    },
    {
      "epoch": 2.750279762417147,
      "grad_norm": 0.9268730878829956,
      "learning_rate": 3.613433175466896e-06,
      "loss": 3.0332,
      "step": 63900
    },
    {
      "epoch": 2.750279762417147,
      "eval_bleu": 27.234914626405576,
      "eval_gen_len": 27.495,
      "eval_loss": 2.7851874828338623,
      "eval_runtime": 59.3395,
      "eval_samples_per_second": 16.852,
      "eval_steps_per_second": 1.062,
      "step": 63900
    },
    {
      "epoch": 2.7507101661358355,
      "grad_norm": 1.042279839515686,
      "learning_rate": 3.601065457146335e-06,
      "loss": 3.0784,
      "step": 63910
    },
    {
      "epoch": 2.7511405698545235,
      "grad_norm": 0.894923746585846,
      "learning_rate": 3.5887185525645407e-06,
      "loss": 2.9317,
      "step": 63920
    },
    {
      "epoch": 2.7515709735732115,
      "grad_norm": 0.8307388424873352,
      "learning_rate": 3.576392464387379e-06,
      "loss": 2.9779,
      "step": 63930
    },
    {
      "epoch": 2.7520013772919,
      "grad_norm": 0.9308247566223145,
      "learning_rate": 3.5640871952761888e-06,
      "loss": 2.968,
      "step": 63940
    },
    {
      "epoch": 2.752431781010588,
      "grad_norm": 0.8809190988540649,
      "learning_rate": 3.5518027478878446e-06,
      "loss": 2.9858,
      "step": 63950
    },
    {
      "epoch": 2.752431781010588,
      "eval_bleu": 27.393834627922775,
      "eval_gen_len": 27.486,
      "eval_loss": 2.785557508468628,
      "eval_runtime": 58.9289,
      "eval_samples_per_second": 16.97,
      "eval_steps_per_second": 1.069,
      "step": 63950
    },
    {
      "epoch": 2.752862184729276,
      "grad_norm": 1.0231456756591797,
      "learning_rate": 3.5395391248747133e-06,
      "loss": 2.945,
      "step": 63960
    },
    {
      "epoch": 2.753292588447964,
      "grad_norm": 0.9059240221977234,
      "learning_rate": 3.527296328884655e-06,
      "loss": 2.9225,
      "step": 63970
    },
    {
      "epoch": 2.753722992166652,
      "grad_norm": 0.8408203721046448,
      "learning_rate": 3.515074362561055e-06,
      "loss": 3.0237,
      "step": 63980
    },
    {
      "epoch": 2.7541533958853406,
      "grad_norm": 1.0358467102050781,
      "learning_rate": 3.5028732285427802e-06,
      "loss": 2.9237,
      "step": 63990
    },
    {
      "epoch": 2.7545837996040285,
      "grad_norm": 1.0522732734680176,
      "learning_rate": 3.490692929464212e-06,
      "loss": 3.0067,
      "step": 64000
    },
    {
      "epoch": 2.7545837996040285,
      "eval_bleu": 27.316134669221288,
      "eval_gen_len": 27.525,
      "eval_loss": 2.784943103790283,
      "eval_runtime": 58.8277,
      "eval_samples_per_second": 16.999,
      "eval_steps_per_second": 1.071,
      "step": 64000
    },
    {
      "epoch": 2.755014203322717,
      "grad_norm": 0.91664057970047,
      "learning_rate": 3.478533467955225e-06,
      "loss": 3.0261,
      "step": 64010
    },
    {
      "epoch": 2.755444607041405,
      "grad_norm": 0.9504610896110535,
      "learning_rate": 3.466394846641219e-06,
      "loss": 2.9642,
      "step": 64020
    },
    {
      "epoch": 2.755875010760093,
      "grad_norm": 0.8110285401344299,
      "learning_rate": 3.4542770681430414e-06,
      "loss": 2.9747,
      "step": 64030
    },
    {
      "epoch": 2.7563054144787813,
      "grad_norm": 0.9965415000915527,
      "learning_rate": 3.4421801350770998e-06,
      "loss": 2.9123,
      "step": 64040
    },
    {
      "epoch": 2.7567358181974693,
      "grad_norm": 0.8372222185134888,
      "learning_rate": 3.4301040500552715e-06,
      "loss": 3.0291,
      "step": 64050
    },
    {
      "epoch": 2.7567358181974693,
      "eval_bleu": 27.288501728320618,
      "eval_gen_len": 27.514,
      "eval_loss": 2.7847023010253906,
      "eval_runtime": 59.4267,
      "eval_samples_per_second": 16.827,
      "eval_steps_per_second": 1.06,
      "step": 64050
    },
    {
      "epoch": 2.7571662219161572,
      "grad_norm": 0.8901987075805664,
      "learning_rate": 3.4180488156849154e-06,
      "loss": 3.0186,
      "step": 64060
    },
    {
      "epoch": 2.7575966256348456,
      "grad_norm": 0.8608006238937378,
      "learning_rate": 3.406014434568927e-06,
      "loss": 2.9032,
      "step": 64070
    },
    {
      "epoch": 2.7580270293535336,
      "grad_norm": 0.888527512550354,
      "learning_rate": 3.3940009093056614e-06,
      "loss": 2.8982,
      "step": 64080
    },
    {
      "epoch": 2.7584574330722216,
      "grad_norm": 1.0284756422042847,
      "learning_rate": 3.382008242489021e-06,
      "loss": 2.9815,
      "step": 64090
    },
    {
      "epoch": 2.75888783679091,
      "grad_norm": 0.877805233001709,
      "learning_rate": 3.3700364367083346e-06,
      "loss": 2.9836,
      "step": 64100
    },
    {
      "epoch": 2.75888783679091,
      "eval_bleu": 27.18483779909844,
      "eval_gen_len": 27.544,
      "eval_loss": 2.7846121788024902,
      "eval_runtime": 58.9326,
      "eval_samples_per_second": 16.969,
      "eval_steps_per_second": 1.069,
      "step": 64100
    },
    {
      "epoch": 2.759318240509598,
      "grad_norm": 0.8724794387817383,
      "learning_rate": 3.358085494548491e-06,
      "loss": 3.059,
      "step": 64110
    },
    {
      "epoch": 2.759748644228286,
      "grad_norm": 1.00088632106781,
      "learning_rate": 3.3461554185898357e-06,
      "loss": 2.9902,
      "step": 64120
    },
    {
      "epoch": 2.7601790479469743,
      "grad_norm": 1.0345805883407593,
      "learning_rate": 3.334246211408232e-06,
      "loss": 2.9701,
      "step": 64130
    },
    {
      "epoch": 2.7606094516656623,
      "grad_norm": 0.9085701704025269,
      "learning_rate": 3.322357875575033e-06,
      "loss": 3.0176,
      "step": 64140
    },
    {
      "epoch": 2.7610398553843503,
      "grad_norm": 0.9692150354385376,
      "learning_rate": 3.3104904136570525e-06,
      "loss": 2.9933,
      "step": 64150
    },
    {
      "epoch": 2.7610398553843503,
      "eval_bleu": 27.260979755113233,
      "eval_gen_len": 27.54,
      "eval_loss": 2.7843589782714844,
      "eval_runtime": 59.661,
      "eval_samples_per_second": 16.761,
      "eval_steps_per_second": 1.056,
      "step": 64150
    },
    {
      "epoch": 2.7614702591030387,
      "grad_norm": 1.023898720741272,
      "learning_rate": 3.2986438282166408e-06,
      "loss": 2.9043,
      "step": 64160
    },
    {
      "epoch": 2.7619006628217266,
      "grad_norm": 0.8772997856140137,
      "learning_rate": 3.28681812181163e-06,
      "loss": 2.9337,
      "step": 64170
    },
    {
      "epoch": 2.762331066540415,
      "grad_norm": 0.9973753094673157,
      "learning_rate": 3.2750132969953327e-06,
      "loss": 2.957,
      "step": 64180
    },
    {
      "epoch": 2.762761470259103,
      "grad_norm": 0.9072466492652893,
      "learning_rate": 3.263229356316555e-06,
      "loss": 2.9936,
      "step": 64190
    },
    {
      "epoch": 2.7631918739777914,
      "grad_norm": 0.8935851454734802,
      "learning_rate": 3.2514663023196055e-06,
      "loss": 2.9709,
      "step": 64200
    },
    {
      "epoch": 2.7631918739777914,
      "eval_bleu": 27.18483271448238,
      "eval_gen_len": 27.508,
      "eval_loss": 2.7847492694854736,
      "eval_runtime": 59.205,
      "eval_samples_per_second": 16.89,
      "eval_steps_per_second": 1.064,
      "step": 64200
    },
    {
      "epoch": 2.7636222776964794,
      "grad_norm": 1.0491448640823364,
      "learning_rate": 3.2397241375442643e-06,
      "loss": 2.9811,
      "step": 64210
    },
    {
      "epoch": 2.7640526814151674,
      "grad_norm": 0.8938643336296082,
      "learning_rate": 3.2280028645258144e-06,
      "loss": 3.0064,
      "step": 64220
    },
    {
      "epoch": 2.7644830851338558,
      "grad_norm": 0.9142695069313049,
      "learning_rate": 3.216302485795042e-06,
      "loss": 2.9722,
      "step": 64230
    },
    {
      "epoch": 2.7649134888525437,
      "grad_norm": 0.9065759778022766,
      "learning_rate": 3.204623003878182e-06,
      "loss": 2.9662,
      "step": 64240
    },
    {
      "epoch": 2.7653438925712317,
      "grad_norm": 0.911937415599823,
      "learning_rate": 3.1929644212969958e-06,
      "loss": 2.9894,
      "step": 64250
    },
    {
      "epoch": 2.7653438925712317,
      "eval_bleu": 27.116023579613888,
      "eval_gen_len": 27.47,
      "eval_loss": 2.784910202026367,
      "eval_runtime": 58.6424,
      "eval_samples_per_second": 17.053,
      "eval_steps_per_second": 1.074,
      "step": 64250
    },
    {
      "epoch": 2.76577429628992,
      "grad_norm": 0.909772515296936,
      "learning_rate": 3.181326740568702e-06,
      "loss": 3.0249,
      "step": 64260
    },
    {
      "epoch": 2.766204700008608,
      "grad_norm": 0.9321447610855103,
      "learning_rate": 3.1697099642060467e-06,
      "loss": 2.9817,
      "step": 64270
    },
    {
      "epoch": 2.766635103727296,
      "grad_norm": 0.8310593366622925,
      "learning_rate": 3.158114094717224e-06,
      "loss": 2.9666,
      "step": 64280
    },
    {
      "epoch": 2.7670655074459845,
      "grad_norm": 0.9049574732780457,
      "learning_rate": 3.1465391346059413e-06,
      "loss": 3.1069,
      "step": 64290
    },
    {
      "epoch": 2.7674959111646724,
      "grad_norm": 0.973760187625885,
      "learning_rate": 3.1349850863713337e-06,
      "loss": 2.951,
      "step": 64300
    },
    {
      "epoch": 2.7674959111646724,
      "eval_bleu": 27.309784931210935,
      "eval_gen_len": 27.536,
      "eval_loss": 2.784930944442749,
      "eval_runtime": 58.9117,
      "eval_samples_per_second": 16.975,
      "eval_steps_per_second": 1.069,
      "step": 64300
    },
    {
      "epoch": 2.7679263148833604,
      "grad_norm": 0.8217153549194336,
      "learning_rate": 3.123451952508105e-06,
      "loss": 2.8828,
      "step": 64310
    },
    {
      "epoch": 2.768356718602049,
      "grad_norm": 0.9591902494430542,
      "learning_rate": 3.1119397355064084e-06,
      "loss": 2.9275,
      "step": 64320
    },
    {
      "epoch": 2.7687871223207368,
      "grad_norm": 0.9225111603736877,
      "learning_rate": 3.100448437851844e-06,
      "loss": 2.9893,
      "step": 64330
    },
    {
      "epoch": 2.7692175260394247,
      "grad_norm": 0.886366069316864,
      "learning_rate": 3.0889780620255493e-06,
      "loss": 2.99,
      "step": 64340
    },
    {
      "epoch": 2.769647929758113,
      "grad_norm": 0.9217793941497803,
      "learning_rate": 3.0775286105041214e-06,
      "loss": 2.9723,
      "step": 64350
    },
    {
      "epoch": 2.769647929758113,
      "eval_bleu": 27.25690637991894,
      "eval_gen_len": 27.545,
      "eval_loss": 2.785191297531128,
      "eval_runtime": 58.9457,
      "eval_samples_per_second": 16.965,
      "eval_steps_per_second": 1.069,
      "step": 64350
    },
    {
      "epoch": 2.770078333476801,
      "grad_norm": 0.9183927774429321,
      "learning_rate": 3.0661000857596377e-06,
      "loss": 2.9768,
      "step": 64360
    },
    {
      "epoch": 2.7705087371954895,
      "grad_norm": 0.906956672668457,
      "learning_rate": 3.0546924902596586e-06,
      "loss": 2.9505,
      "step": 64370
    },
    {
      "epoch": 2.7709391409141775,
      "grad_norm": 0.9275423288345337,
      "learning_rate": 3.043305826467224e-06,
      "loss": 3.0137,
      "step": 64380
    },
    {
      "epoch": 2.771369544632866,
      "grad_norm": 0.95177161693573,
      "learning_rate": 3.031940096840857e-06,
      "loss": 3.0591,
      "step": 64390
    },
    {
      "epoch": 2.771799948351554,
      "grad_norm": 1.0214775800704956,
      "learning_rate": 3.0205953038345726e-06,
      "loss": 2.9278,
      "step": 64400
    },
    {
      "epoch": 2.771799948351554,
      "eval_bleu": 27.24990494210693,
      "eval_gen_len": 27.47,
      "eval_loss": 2.785355806350708,
      "eval_runtime": 58.9424,
      "eval_samples_per_second": 16.966,
      "eval_steps_per_second": 1.069,
      "step": 64400
    },
    {
      "epoch": 2.772230352070242,
      "grad_norm": 0.8519791960716248,
      "learning_rate": 3.0092714498978437e-06,
      "loss": 2.935,
      "step": 64410
    },
    {
      "epoch": 2.7726607557889302,
      "grad_norm": 0.9455446600914001,
      "learning_rate": 2.997968537475626e-06,
      "loss": 2.9112,
      "step": 64420
    },
    {
      "epoch": 2.773091159507618,
      "grad_norm": 0.8796536922454834,
      "learning_rate": 2.986686569008379e-06,
      "loss": 2.9807,
      "step": 64430
    },
    {
      "epoch": 2.773521563226306,
      "grad_norm": 0.959231972694397,
      "learning_rate": 2.975425546931998e-06,
      "loss": 2.9975,
      "step": 64440
    },
    {
      "epoch": 2.7739519669449946,
      "grad_norm": 0.9045027494430542,
      "learning_rate": 2.964185473677916e-06,
      "loss": 2.9183,
      "step": 64450
    },
    {
      "epoch": 2.7739519669449946,
      "eval_bleu": 27.166559429729652,
      "eval_gen_len": 27.505,
      "eval_loss": 2.7855570316314697,
      "eval_runtime": 58.9164,
      "eval_samples_per_second": 16.973,
      "eval_steps_per_second": 1.069,
      "step": 64450
    },
    {
      "epoch": 2.7743823706636825,
      "grad_norm": 0.9496105909347534,
      "learning_rate": 2.9529663516729587e-06,
      "loss": 3.0266,
      "step": 64460
    },
    {
      "epoch": 2.7748127743823705,
      "grad_norm": 0.9111151099205017,
      "learning_rate": 2.9417681833395105e-06,
      "loss": 3.0495,
      "step": 64470
    },
    {
      "epoch": 2.775243178101059,
      "grad_norm": 0.8723688125610352,
      "learning_rate": 2.9305909710953703e-06,
      "loss": 2.9671,
      "step": 64480
    },
    {
      "epoch": 2.775673581819747,
      "grad_norm": 0.8562098145484924,
      "learning_rate": 2.919434717353875e-06,
      "loss": 2.8992,
      "step": 64490
    },
    {
      "epoch": 2.776103985538435,
      "grad_norm": 0.8983442783355713,
      "learning_rate": 2.908299424523753e-06,
      "loss": 2.9548,
      "step": 64500
    },
    {
      "epoch": 2.776103985538435,
      "eval_bleu": 27.36288072502543,
      "eval_gen_len": 27.508,
      "eval_loss": 2.7853705883026123,
      "eval_runtime": 58.7813,
      "eval_samples_per_second": 17.012,
      "eval_steps_per_second": 1.072,
      "step": 64500
    },
    {
      "epoch": 2.7765343892571233,
      "grad_norm": 0.8959493041038513,
      "learning_rate": 2.8971850950092803e-06,
      "loss": 2.9428,
      "step": 64510
    },
    {
      "epoch": 2.7769647929758112,
      "grad_norm": 0.8901762366294861,
      "learning_rate": 2.886091731210183e-06,
      "loss": 2.9236,
      "step": 64520
    },
    {
      "epoch": 2.777395196694499,
      "grad_norm": 0.939302384853363,
      "learning_rate": 2.8750193355216558e-06,
      "loss": 3.0109,
      "step": 64530
    },
    {
      "epoch": 2.7778256004131876,
      "grad_norm": 1.0793120861053467,
      "learning_rate": 2.863967910334364e-06,
      "loss": 2.9098,
      "step": 64540
    },
    {
      "epoch": 2.7782560041318756,
      "grad_norm": 0.8627299070358276,
      "learning_rate": 2.8529374580344437e-06,
      "loss": 3.0227,
      "step": 64550
    },
    {
      "epoch": 2.7782560041318756,
      "eval_bleu": 27.189948768093725,
      "eval_gen_len": 27.493,
      "eval_loss": 2.7852089405059814,
      "eval_runtime": 58.8314,
      "eval_samples_per_second": 16.998,
      "eval_steps_per_second": 1.071,
      "step": 64550
    },
    {
      "epoch": 2.778686407850564,
      "grad_norm": 0.9941444396972656,
      "learning_rate": 2.8419279810035114e-06,
      "loss": 2.9358,
      "step": 64560
    },
    {
      "epoch": 2.779116811569252,
      "grad_norm": 0.9279217720031738,
      "learning_rate": 2.830939481618644e-06,
      "loss": 3.0181,
      "step": 64570
    },
    {
      "epoch": 2.7795472152879404,
      "grad_norm": 0.9145607948303223,
      "learning_rate": 2.819971962252421e-06,
      "loss": 2.9356,
      "step": 64580
    },
    {
      "epoch": 2.7799776190066283,
      "grad_norm": 0.9028050899505615,
      "learning_rate": 2.8090254252728377e-06,
      "loss": 2.9719,
      "step": 64590
    },
    {
      "epoch": 2.7804080227253163,
      "grad_norm": 0.9601311087608337,
      "learning_rate": 2.7980998730434136e-06,
      "loss": 2.9395,
      "step": 64600
    },
    {
      "epoch": 2.7804080227253163,
      "eval_bleu": 27.317458705238653,
      "eval_gen_len": 27.542,
      "eval_loss": 2.7849981784820557,
      "eval_runtime": 58.6263,
      "eval_samples_per_second": 17.057,
      "eval_steps_per_second": 1.075,
      "step": 64600
    },
    {
      "epoch": 2.7808384264440047,
      "grad_norm": 1.107350468635559,
      "learning_rate": 2.7871953079230963e-06,
      "loss": 2.9909,
      "step": 64610
    },
    {
      "epoch": 2.7812688301626927,
      "grad_norm": 1.0243016481399536,
      "learning_rate": 2.7763117322663235e-06,
      "loss": 3.0238,
      "step": 64620
    },
    {
      "epoch": 2.7816992338813806,
      "grad_norm": 1.0173850059509277,
      "learning_rate": 2.7654491484229937e-06,
      "loss": 3.0605,
      "step": 64630
    },
    {
      "epoch": 2.782129637600069,
      "grad_norm": 0.945645272731781,
      "learning_rate": 2.7546075587384644e-06,
      "loss": 2.9517,
      "step": 64640
    },
    {
      "epoch": 2.782560041318757,
      "grad_norm": 0.9611919522285461,
      "learning_rate": 2.7437869655536075e-06,
      "loss": 2.9973,
      "step": 64650
    },
    {
      "epoch": 2.782560041318757,
      "eval_bleu": 27.281533462591963,
      "eval_gen_len": 27.487,
      "eval_loss": 2.785200834274292,
      "eval_runtime": 58.7218,
      "eval_samples_per_second": 17.029,
      "eval_steps_per_second": 1.073,
      "step": 64650
    },
    {
      "epoch": 2.782990445037445,
      "grad_norm": 0.9383379817008972,
      "learning_rate": 2.732987371204676e-06,
      "loss": 3.0445,
      "step": 64660
    },
    {
      "epoch": 2.7834208487561334,
      "grad_norm": 0.9182446002960205,
      "learning_rate": 2.7222087780234715e-06,
      "loss": 2.9417,
      "step": 64670
    },
    {
      "epoch": 2.7838512524748213,
      "grad_norm": 0.7718127369880676,
      "learning_rate": 2.7114511883372108e-06,
      "loss": 2.9511,
      "step": 64680
    },
    {
      "epoch": 2.7842816561935093,
      "grad_norm": 0.918684720993042,
      "learning_rate": 2.700714604468613e-06,
      "loss": 3.0228,
      "step": 64690
    },
    {
      "epoch": 2.7847120599121977,
      "grad_norm": 0.8698008060455322,
      "learning_rate": 2.6899990287358234e-06,
      "loss": 2.9578,
      "step": 64700
    },
    {
      "epoch": 2.7847120599121977,
      "eval_bleu": 27.153590429888137,
      "eval_gen_len": 27.516,
      "eval_loss": 2.7849793434143066,
      "eval_runtime": 59.2146,
      "eval_samples_per_second": 16.888,
      "eval_steps_per_second": 1.064,
      "step": 64700
    },
    {
      "epoch": 2.7851424636308857,
      "grad_norm": 0.9062038660049438,
      "learning_rate": 2.679304463452459e-06,
      "loss": 2.9152,
      "step": 64710
    },
    {
      "epoch": 2.7855728673495737,
      "grad_norm": 0.8458046317100525,
      "learning_rate": 2.6686309109276386e-06,
      "loss": 2.8731,
      "step": 64720
    },
    {
      "epoch": 2.786003271068262,
      "grad_norm": 0.9517327547073364,
      "learning_rate": 2.657978373465897e-06,
      "loss": 3.0107,
      "step": 64730
    },
    {
      "epoch": 2.78643367478695,
      "grad_norm": 1.0187877416610718,
      "learning_rate": 2.647346853367261e-06,
      "loss": 3.031,
      "step": 64740
    },
    {
      "epoch": 2.7868640785056384,
      "grad_norm": 0.9826332926750183,
      "learning_rate": 2.636736352927183e-06,
      "loss": 2.9751,
      "step": 64750
    },
    {
      "epoch": 2.7868640785056384,
      "eval_bleu": 27.262683146031033,
      "eval_gen_len": 27.509,
      "eval_loss": 2.78501033782959,
      "eval_runtime": 59.2637,
      "eval_samples_per_second": 16.874,
      "eval_steps_per_second": 1.063,
      "step": 64750
    },
    {
      "epoch": 2.7872944822243264,
      "grad_norm": 0.8965556621551514,
      "learning_rate": 2.6261468744366524e-06,
      "loss": 3.0309,
      "step": 64760
    },
    {
      "epoch": 2.787724885943015,
      "grad_norm": 0.953082263469696,
      "learning_rate": 2.615578420182019e-06,
      "loss": 3.0867,
      "step": 64770
    },
    {
      "epoch": 2.788155289661703,
      "grad_norm": 0.8722383379936218,
      "learning_rate": 2.6050309924451787e-06,
      "loss": 2.9414,
      "step": 64780
    },
    {
      "epoch": 2.7885856933803908,
      "grad_norm": 0.9785969853401184,
      "learning_rate": 2.594504593503444e-06,
      "loss": 2.9413,
      "step": 64790
    },
    {
      "epoch": 2.789016097099079,
      "grad_norm": 0.8720537424087524,
      "learning_rate": 2.5839992256295854e-06,
      "loss": 3.0146,
      "step": 64800
    },
    {
      "epoch": 2.789016097099079,
      "eval_bleu": 27.223914144945006,
      "eval_gen_len": 27.496,
      "eval_loss": 2.784919261932373,
      "eval_runtime": 58.878,
      "eval_samples_per_second": 16.984,
      "eval_steps_per_second": 1.07,
      "step": 64800
    },
    {
      "epoch": 2.789446500817767,
      "grad_norm": 0.8963233828544617,
      "learning_rate": 2.573514891091866e-06,
      "loss": 3.0512,
      "step": 64810
    },
    {
      "epoch": 2.789876904536455,
      "grad_norm": 0.8739993572235107,
      "learning_rate": 2.563051592153953e-06,
      "loss": 2.839,
      "step": 64820
    },
    {
      "epoch": 2.7903073082551435,
      "grad_norm": 0.9119254946708679,
      "learning_rate": 2.55260933107504e-06,
      "loss": 2.9557,
      "step": 64830
    },
    {
      "epoch": 2.7907377119738315,
      "grad_norm": 0.9249423742294312,
      "learning_rate": 2.542188110109711e-06,
      "loss": 2.927,
      "step": 64840
    },
    {
      "epoch": 2.7911681156925194,
      "grad_norm": 0.9909370541572571,
      "learning_rate": 2.5317879315080673e-06,
      "loss": 2.949,
      "step": 64850
    },
    {
      "epoch": 2.7911681156925194,
      "eval_bleu": 27.319186388306374,
      "eval_gen_len": 27.463,
      "eval_loss": 2.785088539123535,
      "eval_runtime": 59.0599,
      "eval_samples_per_second": 16.932,
      "eval_steps_per_second": 1.067,
      "step": 64850
    },
    {
      "epoch": 2.791598519411208,
      "grad_norm": 0.958994448184967,
      "learning_rate": 2.521408797515612e-06,
      "loss": 3.0262,
      "step": 64860
    },
    {
      "epoch": 2.792028923129896,
      "grad_norm": 0.9908754825592041,
      "learning_rate": 2.5110507103733417e-06,
      "loss": 2.9622,
      "step": 64870
    },
    {
      "epoch": 2.792459326848584,
      "grad_norm": 0.9457114338874817,
      "learning_rate": 2.5007136723177005e-06,
      "loss": 3.0884,
      "step": 64880
    },
    {
      "epoch": 2.792889730567272,
      "grad_norm": 0.8700857758522034,
      "learning_rate": 2.49039768558057e-06,
      "loss": 2.8747,
      "step": 64890
    },
    {
      "epoch": 2.79332013428596,
      "grad_norm": 0.9917347431182861,
      "learning_rate": 2.480102752389324e-06,
      "loss": 3.0256,
      "step": 64900
    },
    {
      "epoch": 2.79332013428596,
      "eval_bleu": 27.14907424318261,
      "eval_gen_len": 27.52,
      "eval_loss": 2.784976005554199,
      "eval_runtime": 58.8836,
      "eval_samples_per_second": 16.983,
      "eval_steps_per_second": 1.07,
      "step": 64900
    },
    {
      "epoch": 2.793750538004648,
      "grad_norm": 0.9120451807975769,
      "learning_rate": 2.46982887496674e-06,
      "loss": 2.9325,
      "step": 64910
    },
    {
      "epoch": 2.7941809417233365,
      "grad_norm": 0.9255087971687317,
      "learning_rate": 2.4595760555311098e-06,
      "loss": 3.1173,
      "step": 64920
    },
    {
      "epoch": 2.7946113454420245,
      "grad_norm": 0.9099622368812561,
      "learning_rate": 2.4493442962961076e-06,
      "loss": 2.9915,
      "step": 64930
    },
    {
      "epoch": 2.795041749160713,
      "grad_norm": 0.8315746188163757,
      "learning_rate": 2.439133599470944e-06,
      "loss": 2.9136,
      "step": 64940
    },
    {
      "epoch": 2.795472152879401,
      "grad_norm": 0.891374945640564,
      "learning_rate": 2.4289439672601997e-06,
      "loss": 2.9692,
      "step": 64950
    },
    {
      "epoch": 2.795472152879401,
      "eval_bleu": 27.232667601953597,
      "eval_gen_len": 27.492,
      "eval_loss": 2.7850632667541504,
      "eval_runtime": 58.8149,
      "eval_samples_per_second": 17.002,
      "eval_steps_per_second": 1.071,
      "step": 64950
    },
    {
      "epoch": 2.7959025565980893,
      "grad_norm": 0.9017040133476257,
      "learning_rate": 2.4187754018639487e-06,
      "loss": 2.9853,
      "step": 64960
    },
    {
      "epoch": 2.7963329603167772,
      "grad_norm": 1.0142128467559814,
      "learning_rate": 2.408627905477734e-06,
      "loss": 3.0204,
      "step": 64970
    },
    {
      "epoch": 2.796763364035465,
      "grad_norm": 0.9240041375160217,
      "learning_rate": 2.398501480292492e-06,
      "loss": 2.9246,
      "step": 64980
    },
    {
      "epoch": 2.7971937677541536,
      "grad_norm": 0.9002818465232849,
      "learning_rate": 2.3883961284946852e-06,
      "loss": 2.9516,
      "step": 64990
    },
    {
      "epoch": 2.7976241714728416,
      "grad_norm": 0.9305358529090881,
      "learning_rate": 2.378311852266146e-06,
      "loss": 2.9733,
      "step": 65000
    },
    {
      "epoch": 2.7976241714728416,
      "eval_bleu": 27.26948524979569,
      "eval_gen_len": 27.499,
      "eval_loss": 2.784791946411133,
      "eval_runtime": 58.8951,
      "eval_samples_per_second": 16.979,
      "eval_steps_per_second": 1.07,
      "step": 65000
    },
    {
      "epoch": 2.7980545751915296,
      "grad_norm": 0.919731080532074,
      "learning_rate": 2.368248653784233e-06,
      "loss": 2.916,
      "step": 65010
    },
    {
      "epoch": 2.798484978910218,
      "grad_norm": 0.7925025820732117,
      "learning_rate": 2.3582065352216963e-06,
      "loss": 2.907,
      "step": 65020
    },
    {
      "epoch": 2.798915382628906,
      "grad_norm": 1.0122144222259521,
      "learning_rate": 2.3481854987467577e-06,
      "loss": 3.0626,
      "step": 65030
    },
    {
      "epoch": 2.799345786347594,
      "grad_norm": 0.9974863529205322,
      "learning_rate": 2.3381855465230862e-06,
      "loss": 2.9949,
      "step": 65040
    },
    {
      "epoch": 2.7997761900662823,
      "grad_norm": 0.9030160903930664,
      "learning_rate": 2.328206680709788e-06,
      "loss": 3.0022,
      "step": 65050
    },
    {
      "epoch": 2.7997761900662823,
      "eval_bleu": 27.26849870785939,
      "eval_gen_len": 27.534,
      "eval_loss": 2.785027503967285,
      "eval_runtime": 59.214,
      "eval_samples_per_second": 16.888,
      "eval_steps_per_second": 1.064,
      "step": 65050
    },
    {
      "epoch": 2.8002065937849703,
      "grad_norm": 0.9525821208953857,
      "learning_rate": 2.3182489034614396e-06,
      "loss": 2.9248,
      "step": 65060
    },
    {
      "epoch": 2.8006369975036582,
      "grad_norm": 0.8947624564170837,
      "learning_rate": 2.3083122169280324e-06,
      "loss": 2.9891,
      "step": 65070
    },
    {
      "epoch": 2.8010674012223467,
      "grad_norm": 0.8268605470657349,
      "learning_rate": 2.29839662325505e-06,
      "loss": 2.9889,
      "step": 65080
    },
    {
      "epoch": 2.8014978049410346,
      "grad_norm": 0.9384133219718933,
      "learning_rate": 2.2885021245833692e-06,
      "loss": 2.9482,
      "step": 65090
    },
    {
      "epoch": 2.8019282086597226,
      "grad_norm": 0.9279464483261108,
      "learning_rate": 2.2786287230493585e-06,
      "loss": 2.9419,
      "step": 65100
    },
    {
      "epoch": 2.8019282086597226,
      "eval_bleu": 27.251249202130932,
      "eval_gen_len": 27.543,
      "eval_loss": 2.7851760387420654,
      "eval_runtime": 58.9792,
      "eval_samples_per_second": 16.955,
      "eval_steps_per_second": 1.068,
      "step": 65100
    },
    {
      "epoch": 2.802358612378411,
      "grad_norm": 0.8593007326126099,
      "learning_rate": 2.2687764207847796e-06,
      "loss": 2.9611,
      "step": 65110
    },
    {
      "epoch": 2.802789016097099,
      "grad_norm": 0.9694970846176147,
      "learning_rate": 2.258945219916886e-06,
      "loss": 2.9874,
      "step": 65120
    },
    {
      "epoch": 2.8032194198157874,
      "grad_norm": 0.9457680583000183,
      "learning_rate": 2.2491351225683467e-06,
      "loss": 3.004,
      "step": 65130
    },
    {
      "epoch": 2.8036498235344753,
      "grad_norm": 0.859319269657135,
      "learning_rate": 2.2393461308572894e-06,
      "loss": 2.9464,
      "step": 65140
    },
    {
      "epoch": 2.8040802272531633,
      "grad_norm": 1.0094492435455322,
      "learning_rate": 2.2295782468973013e-06,
      "loss": 2.9735,
      "step": 65150
    },
    {
      "epoch": 2.8040802272531633,
      "eval_bleu": 27.282609211191367,
      "eval_gen_len": 27.561,
      "eval_loss": 2.78521990776062,
      "eval_runtime": 58.5079,
      "eval_samples_per_second": 17.092,
      "eval_steps_per_second": 1.077,
      "step": 65150
    },
    {
      "epoch": 2.8045106309718517,
      "grad_norm": 0.9467039704322815,
      "learning_rate": 2.2198314727973512e-06,
      "loss": 2.9261,
      "step": 65160
    },
    {
      "epoch": 2.8049410346905397,
      "grad_norm": 1.0133816003799438,
      "learning_rate": 2.2101058106619333e-06,
      "loss": 2.9203,
      "step": 65170
    },
    {
      "epoch": 2.805371438409228,
      "grad_norm": 0.9634721875190735,
      "learning_rate": 2.200401262590912e-06,
      "loss": 2.9745,
      "step": 65180
    },
    {
      "epoch": 2.805801842127916,
      "grad_norm": 0.9662863612174988,
      "learning_rate": 2.190717830679623e-06,
      "loss": 2.94,
      "step": 65190
    },
    {
      "epoch": 2.806232245846604,
      "grad_norm": 0.908473014831543,
      "learning_rate": 2.1810555170188372e-06,
      "loss": 2.9736,
      "step": 65200
    },
    {
      "epoch": 2.806232245846604,
      "eval_bleu": 27.409262469390416,
      "eval_gen_len": 27.516,
      "eval_loss": 2.785207509994507,
      "eval_runtime": 58.716,
      "eval_samples_per_second": 17.031,
      "eval_steps_per_second": 1.073,
      "step": 65200
    },
    {
      "epoch": 2.8066626495652924,
      "grad_norm": 1.008439064025879,
      "learning_rate": 2.171414323694787e-06,
      "loss": 3.0669,
      "step": 65210
    },
    {
      "epoch": 2.8070930532839804,
      "grad_norm": 0.9194083213806152,
      "learning_rate": 2.1617942527891066e-06,
      "loss": 2.9741,
      "step": 65220
    },
    {
      "epoch": 2.8075234570026684,
      "grad_norm": 0.9438545107841492,
      "learning_rate": 2.1521953063789126e-06,
      "loss": 3.0286,
      "step": 65230
    },
    {
      "epoch": 2.8079538607213568,
      "grad_norm": 0.9026077389717102,
      "learning_rate": 2.1426174865367133e-06,
      "loss": 3.0245,
      "step": 65240
    },
    {
      "epoch": 2.8083842644400447,
      "grad_norm": 0.9265053868293762,
      "learning_rate": 2.1330607953304883e-06,
      "loss": 2.9521,
      "step": 65250
    },
    {
      "epoch": 2.8083842644400447,
      "eval_bleu": 27.195408652538944,
      "eval_gen_len": 27.517,
      "eval_loss": 2.785193920135498,
      "eval_runtime": 59.0142,
      "eval_samples_per_second": 16.945,
      "eval_steps_per_second": 1.068,
      "step": 65250
    },
    {
      "epoch": 2.8088146681587327,
      "grad_norm": 0.9557140469551086,
      "learning_rate": 2.1235252348236755e-06,
      "loss": 3.0759,
      "step": 65260
    },
    {
      "epoch": 2.809245071877421,
      "grad_norm": 0.9914799332618713,
      "learning_rate": 2.114010807075073e-06,
      "loss": 2.9672,
      "step": 65270
    },
    {
      "epoch": 2.809675475596109,
      "grad_norm": 0.961264967918396,
      "learning_rate": 2.1045175141390038e-06,
      "loss": 2.9417,
      "step": 65280
    },
    {
      "epoch": 2.810105879314797,
      "grad_norm": 0.9046213626861572,
      "learning_rate": 2.095045358065162e-06,
      "loss": 2.9113,
      "step": 65290
    },
    {
      "epoch": 2.8105362830334855,
      "grad_norm": 0.8706933856010437,
      "learning_rate": 2.085594340898733e-06,
      "loss": 3.0748,
      "step": 65300
    },
    {
      "epoch": 2.8105362830334855,
      "eval_bleu": 27.329274752793417,
      "eval_gen_len": 27.541,
      "eval_loss": 2.7854013442993164,
      "eval_runtime": 58.8035,
      "eval_samples_per_second": 17.006,
      "eval_steps_per_second": 1.071,
      "step": 65300
    },
    {
      "epoch": 2.8109666867521734,
      "grad_norm": 0.8865256309509277,
      "learning_rate": 2.0761644646802746e-06,
      "loss": 2.984,
      "step": 65310
    },
    {
      "epoch": 2.8113970904708614,
      "grad_norm": 0.9409937858581543,
      "learning_rate": 2.0667557314458573e-06,
      "loss": 2.9889,
      "step": 65320
    },
    {
      "epoch": 2.81182749418955,
      "grad_norm": 0.8656278848648071,
      "learning_rate": 2.057368143226901e-06,
      "loss": 2.9384,
      "step": 65330
    },
    {
      "epoch": 2.8122578979082378,
      "grad_norm": 1.0000460147857666,
      "learning_rate": 2.0480017020503393e-06,
      "loss": 3.0319,
      "step": 65340
    },
    {
      "epoch": 2.812688301626926,
      "grad_norm": 0.9233567118644714,
      "learning_rate": 2.0386564099384886e-06,
      "loss": 2.9621,
      "step": 65350
    },
    {
      "epoch": 2.812688301626926,
      "eval_bleu": 27.121968602345046,
      "eval_gen_len": 27.483,
      "eval_loss": 2.7851388454437256,
      "eval_runtime": 58.9407,
      "eval_samples_per_second": 16.966,
      "eval_steps_per_second": 1.069,
      "step": 65350
    },
    {
      "epoch": 2.813118705345614,
      "grad_norm": 1.005026936531067,
      "learning_rate": 2.029332268909112e-06,
      "loss": 3.0434,
      "step": 65360
    },
    {
      "epoch": 2.8135491090643026,
      "grad_norm": 0.9649892449378967,
      "learning_rate": 2.0200292809754106e-06,
      "loss": 2.9509,
      "step": 65370
    },
    {
      "epoch": 2.8139795127829905,
      "grad_norm": 0.9255103468894958,
      "learning_rate": 2.010747448146022e-06,
      "loss": 2.99,
      "step": 65380
    },
    {
      "epoch": 2.8144099165016785,
      "grad_norm": 0.9283264875411987,
      "learning_rate": 2.00148677242501e-06,
      "loss": 2.9081,
      "step": 65390
    },
    {
      "epoch": 2.814840320220367,
      "grad_norm": 0.9788393974304199,
      "learning_rate": 1.992247255811852e-06,
      "loss": 2.9709,
      "step": 65400
    },
    {
      "epoch": 2.814840320220367,
      "eval_bleu": 27.113846167679778,
      "eval_gen_len": 27.516,
      "eval_loss": 2.785104990005493,
      "eval_runtime": 58.9179,
      "eval_samples_per_second": 16.973,
      "eval_steps_per_second": 1.069,
      "step": 65400
    },
    {
      "epoch": 2.815270723939055,
      "grad_norm": 1.0980265140533447,
      "learning_rate": 1.983028900301509e-06,
      "loss": 2.9539,
      "step": 65410
    },
    {
      "epoch": 2.815701127657743,
      "grad_norm": 0.9305984973907471,
      "learning_rate": 1.9738317078842994e-06,
      "loss": 2.9831,
      "step": 65420
    },
    {
      "epoch": 2.8161315313764312,
      "grad_norm": 1.0375722646713257,
      "learning_rate": 1.964655680546057e-06,
      "loss": 2.9946,
      "step": 65430
    },
    {
      "epoch": 2.816561935095119,
      "grad_norm": 0.9261143207550049,
      "learning_rate": 1.9555008202679637e-06,
      "loss": 2.9674,
      "step": 65440
    },
    {
      "epoch": 2.816992338813807,
      "grad_norm": 0.9848387837409973,
      "learning_rate": 1.9463671290266826e-06,
      "loss": 3.006,
      "step": 65450
    },
    {
      "epoch": 2.816992338813807,
      "eval_bleu": 27.270087148090965,
      "eval_gen_len": 27.517,
      "eval_loss": 2.785122871398926,
      "eval_runtime": 58.4246,
      "eval_samples_per_second": 17.116,
      "eval_steps_per_second": 1.078,
      "step": 65450
    },
    {
      "epoch": 2.8174227425324956,
      "grad_norm": 0.83189457654953,
      "learning_rate": 1.937254608794303e-06,
      "loss": 3.003,
      "step": 65460
    },
    {
      "epoch": 2.8178531462511835,
      "grad_norm": 0.9903953671455383,
      "learning_rate": 1.9281632615383073e-06,
      "loss": 2.9766,
      "step": 65470
    },
    {
      "epoch": 2.8182835499698715,
      "grad_norm": 0.9354683756828308,
      "learning_rate": 1.9190930892216573e-06,
      "loss": 2.9759,
      "step": 65480
    },
    {
      "epoch": 2.81871395368856,
      "grad_norm": 0.8670694828033447,
      "learning_rate": 1.9100440938026985e-06,
      "loss": 2.9311,
      "step": 65490
    },
    {
      "epoch": 2.819144357407248,
      "grad_norm": 0.8940713405609131,
      "learning_rate": 1.9010162772352458e-06,
      "loss": 2.9766,
      "step": 65500
    },
    {
      "epoch": 2.819144357407248,
      "eval_bleu": 27.28982736014087,
      "eval_gen_len": 27.522,
      "eval_loss": 2.7850403785705566,
      "eval_runtime": 58.8809,
      "eval_samples_per_second": 16.983,
      "eval_steps_per_second": 1.07,
      "step": 65500
    },
    {
      "epoch": 2.819574761125936,
      "grad_norm": 1.0006428956985474,
      "learning_rate": 1.8920096414684952e-06,
      "loss": 2.9886,
      "step": 65510
    },
    {
      "epoch": 2.8200051648446243,
      "grad_norm": 0.9366402626037598,
      "learning_rate": 1.88302418844708e-06,
      "loss": 3.0708,
      "step": 65520
    },
    {
      "epoch": 2.8204355685633122,
      "grad_norm": 0.8666087985038757,
      "learning_rate": 1.8740599201111153e-06,
      "loss": 2.9708,
      "step": 65530
    },
    {
      "epoch": 2.8208659722820006,
      "grad_norm": 0.8952349424362183,
      "learning_rate": 1.8651168383960527e-06,
      "loss": 3.0258,
      "step": 65540
    },
    {
      "epoch": 2.8212963760006886,
      "grad_norm": 0.9078690409660339,
      "learning_rate": 1.8561949452328586e-06,
      "loss": 2.9726,
      "step": 65550
    },
    {
      "epoch": 2.8212963760006886,
      "eval_bleu": 26.99231471853298,
      "eval_gen_len": 27.517,
      "eval_loss": 2.785236358642578,
      "eval_runtime": 59.4981,
      "eval_samples_per_second": 16.807,
      "eval_steps_per_second": 1.059,
      "step": 65550
    },
    {
      "epoch": 2.821726779719377,
      "grad_norm": 1.0355134010314941,
      "learning_rate": 1.847294242547848e-06,
      "loss": 2.9599,
      "step": 65560
    },
    {
      "epoch": 2.822157183438065,
      "grad_norm": 0.9892873167991638,
      "learning_rate": 1.8384147322628165e-06,
      "loss": 2.91,
      "step": 65570
    },
    {
      "epoch": 2.822587587156753,
      "grad_norm": 0.8126081824302673,
      "learning_rate": 1.8295564162949419e-06,
      "loss": 2.9629,
      "step": 65580
    },
    {
      "epoch": 2.8230179908754414,
      "grad_norm": 1.1428579092025757,
      "learning_rate": 1.820719296556861e-06,
      "loss": 2.947,
      "step": 65590
    },
    {
      "epoch": 2.8234483945941293,
      "grad_norm": 0.9021382927894592,
      "learning_rate": 1.811903374956614e-06,
      "loss": 3.1509,
      "step": 65600
    },
    {
      "epoch": 2.8234483945941293,
      "eval_bleu": 27.176029291583085,
      "eval_gen_len": 27.549,
      "eval_loss": 2.7852323055267334,
      "eval_runtime": 58.5781,
      "eval_samples_per_second": 17.071,
      "eval_steps_per_second": 1.075,
      "step": 65600
    },
    {
      "epoch": 2.8238787983128173,
      "grad_norm": 1.0119378566741943,
      "learning_rate": 1.803108653397667e-06,
      "loss": 3.04,
      "step": 65610
    },
    {
      "epoch": 2.8243092020315057,
      "grad_norm": 0.8085725903511047,
      "learning_rate": 1.7943351337789126e-06,
      "loss": 2.9267,
      "step": 65620
    },
    {
      "epoch": 2.8247396057501937,
      "grad_norm": 0.8504266142845154,
      "learning_rate": 1.7855828179946576e-06,
      "loss": 2.9029,
      "step": 65630
    },
    {
      "epoch": 2.8251700094688816,
      "grad_norm": 0.873928427696228,
      "learning_rate": 1.776851707934657e-06,
      "loss": 2.9467,
      "step": 65640
    },
    {
      "epoch": 2.82560041318757,
      "grad_norm": 0.839238703250885,
      "learning_rate": 1.768141805484036e-06,
      "loss": 2.9624,
      "step": 65650
    },
    {
      "epoch": 2.82560041318757,
      "eval_bleu": 27.306444110243618,
      "eval_gen_len": 27.495,
      "eval_loss": 2.785275459289551,
      "eval_runtime": 58.4423,
      "eval_samples_per_second": 17.111,
      "eval_steps_per_second": 1.078,
      "step": 65650
    },
    {
      "epoch": 2.826030816906258,
      "grad_norm": 0.9661206007003784,
      "learning_rate": 1.7594531125234016e-06,
      "loss": 2.9577,
      "step": 65660
    },
    {
      "epoch": 2.826461220624946,
      "grad_norm": 0.9458143711090088,
      "learning_rate": 1.7507856309287418e-06,
      "loss": 2.9687,
      "step": 65670
    },
    {
      "epoch": 2.8268916243436344,
      "grad_norm": 0.8668767809867859,
      "learning_rate": 1.74213936257146e-06,
      "loss": 3.0171,
      "step": 65680
    },
    {
      "epoch": 2.8273220280623224,
      "grad_norm": 0.9521095156669617,
      "learning_rate": 1.733514309318407e-06,
      "loss": 2.9803,
      "step": 65690
    },
    {
      "epoch": 2.8277524317810103,
      "grad_norm": 0.8874403834342957,
      "learning_rate": 1.7249104730318378e-06,
      "loss": 3.0257,
      "step": 65700
    },
    {
      "epoch": 2.8277524317810103,
      "eval_bleu": 27.190362151837295,
      "eval_gen_len": 27.516,
      "eval_loss": 2.785212516784668,
      "eval_runtime": 58.6855,
      "eval_samples_per_second": 17.04,
      "eval_steps_per_second": 1.074,
      "step": 65700
    },
    {
      "epoch": 2.8281828354996987,
      "grad_norm": 0.8693913221359253,
      "learning_rate": 1.7163278555694328e-06,
      "loss": 2.9801,
      "step": 65710
    },
    {
      "epoch": 2.8286132392183867,
      "grad_norm": 0.9223985075950623,
      "learning_rate": 1.7077664587842768e-06,
      "loss": 2.9904,
      "step": 65720
    },
    {
      "epoch": 2.829043642937075,
      "grad_norm": 0.9028310775756836,
      "learning_rate": 1.6992262845249019e-06,
      "loss": 2.9325,
      "step": 65730
    },
    {
      "epoch": 2.829474046655763,
      "grad_norm": 1.0937596559524536,
      "learning_rate": 1.6907073346352109e-06,
      "loss": 2.9614,
      "step": 65740
    },
    {
      "epoch": 2.8299044503744515,
      "grad_norm": 0.8592999577522278,
      "learning_rate": 1.682209610954577e-06,
      "loss": 2.9641,
      "step": 65750
    },
    {
      "epoch": 2.8299044503744515,
      "eval_bleu": 27.24595865942859,
      "eval_gen_len": 27.517,
      "eval_loss": 2.785341739654541,
      "eval_runtime": 58.9895,
      "eval_samples_per_second": 16.952,
      "eval_steps_per_second": 1.068,
      "step": 65750
    },
    {
      "epoch": 2.8303348540931395,
      "grad_norm": 0.9224571585655212,
      "learning_rate": 1.6737331153177438e-06,
      "loss": 2.9472,
      "step": 65760
    },
    {
      "epoch": 2.8307652578118274,
      "grad_norm": 0.9145446419715881,
      "learning_rate": 1.6652778495549137e-06,
      "loss": 3.0203,
      "step": 65770
    },
    {
      "epoch": 2.831195661530516,
      "grad_norm": 0.9266452789306641,
      "learning_rate": 1.6568438154916598e-06,
      "loss": 3.0741,
      "step": 65780
    },
    {
      "epoch": 2.831626065249204,
      "grad_norm": 0.9407500624656677,
      "learning_rate": 1.6484310149490257e-06,
      "loss": 2.9871,
      "step": 65790
    },
    {
      "epoch": 2.8320564689678918,
      "grad_norm": 0.8647066950798035,
      "learning_rate": 1.6400394497434245e-06,
      "loss": 3.016,
      "step": 65800
    },
    {
      "epoch": 2.8320564689678918,
      "eval_bleu": 27.072649473600418,
      "eval_gen_len": 27.48,
      "eval_loss": 2.7851624488830566,
      "eval_runtime": 58.7788,
      "eval_samples_per_second": 17.013,
      "eval_steps_per_second": 1.072,
      "step": 65800
    },
    {
      "epoch": 2.83248687268658,
      "grad_norm": 0.9034802317619324,
      "learning_rate": 1.6316691216866965e-06,
      "loss": 2.881,
      "step": 65810
    },
    {
      "epoch": 2.832917276405268,
      "grad_norm": 0.8585728406906128,
      "learning_rate": 1.6233200325861064e-06,
      "loss": 2.9467,
      "step": 65820
    },
    {
      "epoch": 2.833347680123956,
      "grad_norm": 0.9511812925338745,
      "learning_rate": 1.614992184244335e-06,
      "loss": 2.9841,
      "step": 65830
    },
    {
      "epoch": 2.8337780838426445,
      "grad_norm": 0.9158385396003723,
      "learning_rate": 1.6066855784594548e-06,
      "loss": 2.9123,
      "step": 65840
    },
    {
      "epoch": 2.8342084875613325,
      "grad_norm": 0.9519721865653992,
      "learning_rate": 1.5984002170249647e-06,
      "loss": 2.9266,
      "step": 65850
    },
    {
      "epoch": 2.8342084875613325,
      "eval_bleu": 27.268627436823675,
      "eval_gen_len": 27.537,
      "eval_loss": 2.785407304763794,
      "eval_runtime": 58.7108,
      "eval_samples_per_second": 17.033,
      "eval_steps_per_second": 1.073,
      "step": 65850
    },
    {
      "epoch": 2.8346388912800204,
      "grad_norm": 0.8604125380516052,
      "learning_rate": 1.590136101729789e-06,
      "loss": 3.033,
      "step": 65860
    },
    {
      "epoch": 2.835069294998709,
      "grad_norm": 0.9552919268608093,
      "learning_rate": 1.581893234358256e-06,
      "loss": 2.9657,
      "step": 65870
    },
    {
      "epoch": 2.835499698717397,
      "grad_norm": 0.9647051095962524,
      "learning_rate": 1.5736716166900867e-06,
      "loss": 3.071,
      "step": 65880
    },
    {
      "epoch": 2.835930102436085,
      "grad_norm": 0.9396884441375732,
      "learning_rate": 1.56547125050045e-06,
      "loss": 2.9433,
      "step": 65890
    },
    {
      "epoch": 2.836360506154773,
      "grad_norm": 0.9271908402442932,
      "learning_rate": 1.557292137559907e-06,
      "loss": 2.9368,
      "step": 65900
    },
    {
      "epoch": 2.836360506154773,
      "eval_bleu": 27.069411715207405,
      "eval_gen_len": 27.471,
      "eval_loss": 2.7853572368621826,
      "eval_runtime": 58.7772,
      "eval_samples_per_second": 17.013,
      "eval_steps_per_second": 1.072,
      "step": 65900
    },
    {
      "epoch": 2.836790909873461,
      "grad_norm": 0.9846889972686768,
      "learning_rate": 1.5491342796344233e-06,
      "loss": 2.903,
      "step": 65910
    },
    {
      "epoch": 2.8372213135921496,
      "grad_norm": 0.8460291624069214,
      "learning_rate": 1.5409976784853787e-06,
      "loss": 2.9801,
      "step": 65920
    },
    {
      "epoch": 2.8376517173108375,
      "grad_norm": 0.8774324655532837,
      "learning_rate": 1.5328823358695788e-06,
      "loss": 3.1136,
      "step": 65930
    },
    {
      "epoch": 2.838082121029526,
      "grad_norm": 0.9373790621757507,
      "learning_rate": 1.524788253539211e-06,
      "loss": 2.9659,
      "step": 65940
    },
    {
      "epoch": 2.838512524748214,
      "grad_norm": 0.8428205847740173,
      "learning_rate": 1.516715433241911e-06,
      "loss": 2.96,
      "step": 65950
    },
    {
      "epoch": 2.838512524748214,
      "eval_bleu": 26.992484126283223,
      "eval_gen_len": 27.551,
      "eval_loss": 2.785203456878662,
      "eval_runtime": 58.7406,
      "eval_samples_per_second": 17.024,
      "eval_steps_per_second": 1.073,
      "step": 65950
    },
    {
      "epoch": 2.838942928466902,
      "grad_norm": 0.9055435657501221,
      "learning_rate": 1.5086638767206839e-06,
      "loss": 3.1229,
      "step": 65960
    },
    {
      "epoch": 2.8393733321855903,
      "grad_norm": 0.896989107131958,
      "learning_rate": 1.500633585713973e-06,
      "loss": 2.9968,
      "step": 65970
    },
    {
      "epoch": 2.8398037359042783,
      "grad_norm": 0.7871863842010498,
      "learning_rate": 1.4926245619556022e-06,
      "loss": 3.0136,
      "step": 65980
    },
    {
      "epoch": 2.8402341396229662,
      "grad_norm": 0.9199379682540894,
      "learning_rate": 1.484636807174855e-06,
      "loss": 2.9767,
      "step": 65990
    },
    {
      "epoch": 2.8406645433416546,
      "grad_norm": 0.9288843274116516,
      "learning_rate": 1.476670323096352e-06,
      "loss": 3.0156,
      "step": 66000
    },
    {
      "epoch": 2.8406645433416546,
      "eval_bleu": 26.981745255882004,
      "eval_gen_len": 27.477,
      "eval_loss": 2.7854037284851074,
      "eval_runtime": 59.0768,
      "eval_samples_per_second": 16.927,
      "eval_steps_per_second": 1.066,
      "step": 66000
    },
    {
      "epoch": 2.8410949470603426,
      "grad_norm": 0.9853368997573853,
      "learning_rate": 1.4687251114401613e-06,
      "loss": 2.9425,
      "step": 66010
    },
    {
      "epoch": 2.8415253507790306,
      "grad_norm": 0.9707452654838562,
      "learning_rate": 1.4608011739217774e-06,
      "loss": 2.9567,
      "step": 66020
    },
    {
      "epoch": 2.841955754497719,
      "grad_norm": 0.9486709833145142,
      "learning_rate": 1.4528985122520543e-06,
      "loss": 2.9112,
      "step": 66030
    },
    {
      "epoch": 2.842386158216407,
      "grad_norm": 1.0185288190841675,
      "learning_rate": 1.4450171281372937e-06,
      "loss": 2.9662,
      "step": 66040
    },
    {
      "epoch": 2.842816561935095,
      "grad_norm": 1.01006281375885,
      "learning_rate": 1.4371570232791675e-06,
      "loss": 3.0087,
      "step": 66050
    },
    {
      "epoch": 2.842816561935095,
      "eval_bleu": 27.059496792356473,
      "eval_gen_len": 27.503,
      "eval_loss": 2.7855191230773926,
      "eval_runtime": 58.5621,
      "eval_samples_per_second": 17.076,
      "eval_steps_per_second": 1.076,
      "step": 66050
    },
    {
      "epoch": 2.8432469656537833,
      "grad_norm": 0.9454023241996765,
      "learning_rate": 1.429318199374785e-06,
      "loss": 3.0047,
      "step": 66060
    },
    {
      "epoch": 2.8436773693724713,
      "grad_norm": 0.8194680213928223,
      "learning_rate": 1.4215006581166368e-06,
      "loss": 3.0039,
      "step": 66070
    },
    {
      "epoch": 2.8441077730911593,
      "grad_norm": 0.8874284625053406,
      "learning_rate": 1.4137044011926393e-06,
      "loss": 2.9145,
      "step": 66080
    },
    {
      "epoch": 2.8445381768098477,
      "grad_norm": 0.9220300316810608,
      "learning_rate": 1.4059294302860904e-06,
      "loss": 2.9787,
      "step": 66090
    },
    {
      "epoch": 2.8449685805285356,
      "grad_norm": 0.7956854104995728,
      "learning_rate": 1.398175747075714e-06,
      "loss": 2.9643,
      "step": 66100
    },
    {
      "epoch": 2.8449685805285356,
      "eval_bleu": 27.19471882917607,
      "eval_gen_len": 27.505,
      "eval_loss": 2.7853598594665527,
      "eval_runtime": 58.4639,
      "eval_samples_per_second": 17.105,
      "eval_steps_per_second": 1.078,
      "step": 66100
    },
    {
      "epoch": 2.845398984247224,
      "grad_norm": 0.8807689547538757,
      "learning_rate": 1.3904433532356154e-06,
      "loss": 2.9322,
      "step": 66110
    },
    {
      "epoch": 2.845829387965912,
      "grad_norm": 0.9257208704948425,
      "learning_rate": 1.3827322504353258e-06,
      "loss": 2.8976,
      "step": 66120
    },
    {
      "epoch": 2.8462597916846004,
      "grad_norm": 0.9143239855766296,
      "learning_rate": 1.3750424403397578e-06,
      "loss": 2.9184,
      "step": 66130
    },
    {
      "epoch": 2.8466901954032884,
      "grad_norm": 0.9178208708763123,
      "learning_rate": 1.36737392460925e-06,
      "loss": 2.9352,
      "step": 66140
    },
    {
      "epoch": 2.8471205991219763,
      "grad_norm": 0.9424073696136475,
      "learning_rate": 1.3597267048995333e-06,
      "loss": 2.9203,
      "step": 66150
    },
    {
      "epoch": 2.8471205991219763,
      "eval_bleu": 27.110197740059927,
      "eval_gen_len": 27.506,
      "eval_loss": 2.785297155380249,
      "eval_runtime": 58.7737,
      "eval_samples_per_second": 17.014,
      "eval_steps_per_second": 1.072,
      "step": 66150
    },
    {
      "epoch": 2.8475510028406648,
      "grad_norm": 0.9095399975776672,
      "learning_rate": 1.3521007828617315e-06,
      "loss": 2.8613,
      "step": 66160
    },
    {
      "epoch": 2.8479814065593527,
      "grad_norm": 0.8632141351699829,
      "learning_rate": 1.344496160142361e-06,
      "loss": 2.9352,
      "step": 66170
    },
    {
      "epoch": 2.8484118102780407,
      "grad_norm": 0.9162665605545044,
      "learning_rate": 1.3369128383833862e-06,
      "loss": 3.007,
      "step": 66180
    },
    {
      "epoch": 2.848842213996729,
      "grad_norm": 0.9018566608428955,
      "learning_rate": 1.3293508192221193e-06,
      "loss": 3.0028,
      "step": 66190
    },
    {
      "epoch": 2.849272617715417,
      "grad_norm": 0.9043107032775879,
      "learning_rate": 1.32181010429131e-06,
      "loss": 3.0232,
      "step": 66200
    },
    {
      "epoch": 2.849272617715417,
      "eval_bleu": 27.233293365562727,
      "eval_gen_len": 27.486,
      "eval_loss": 2.785343647003174,
      "eval_runtime": 58.9599,
      "eval_samples_per_second": 16.961,
      "eval_steps_per_second": 1.069,
      "step": 66200
    },
    {
      "epoch": 2.849703021434105,
      "grad_norm": 0.955356776714325,
      "learning_rate": 1.3142906952190782e-06,
      "loss": 3.0013,
      "step": 66210
    },
    {
      "epoch": 2.8501334251527934,
      "grad_norm": 0.9469118118286133,
      "learning_rate": 1.3067925936289692e-06,
      "loss": 2.9654,
      "step": 66220
    },
    {
      "epoch": 2.8505638288714814,
      "grad_norm": 0.8814494609832764,
      "learning_rate": 1.2993158011398998e-06,
      "loss": 2.9808,
      "step": 66230
    },
    {
      "epoch": 2.8509942325901694,
      "grad_norm": 0.9604994654655457,
      "learning_rate": 1.2918603193662338e-06,
      "loss": 2.9926,
      "step": 66240
    },
    {
      "epoch": 2.851424636308858,
      "grad_norm": 0.848697304725647,
      "learning_rate": 1.2844261499176836e-06,
      "loss": 3.018,
      "step": 66250
    },
    {
      "epoch": 2.851424636308858,
      "eval_bleu": 27.14562936168495,
      "eval_gen_len": 27.482,
      "eval_loss": 2.785430431365967,
      "eval_runtime": 58.7282,
      "eval_samples_per_second": 17.028,
      "eval_steps_per_second": 1.073,
      "step": 66250
    },
    {
      "epoch": 2.8518550400275458,
      "grad_norm": 0.9269912242889404,
      "learning_rate": 1.2770132943993762e-06,
      "loss": 3.0988,
      "step": 66260
    },
    {
      "epoch": 2.8522854437462337,
      "grad_norm": 0.9400578141212463,
      "learning_rate": 1.269621754411854e-06,
      "loss": 3.0029,
      "step": 66270
    },
    {
      "epoch": 2.852715847464922,
      "grad_norm": 0.8786773085594177,
      "learning_rate": 1.2622515315510286e-06,
      "loss": 2.9147,
      "step": 66280
    },
    {
      "epoch": 2.85314625118361,
      "grad_norm": 0.8988944292068481,
      "learning_rate": 1.2549026274082277e-06,
      "loss": 2.9991,
      "step": 66290
    },
    {
      "epoch": 2.8535766549022985,
      "grad_norm": 0.9922783374786377,
      "learning_rate": 1.2475750435701816e-06,
      "loss": 2.9939,
      "step": 66300
    },
    {
      "epoch": 2.8535766549022985,
      "eval_bleu": 27.053107736453615,
      "eval_gen_len": 27.498,
      "eval_loss": 2.7852225303649902,
      "eval_runtime": 58.8557,
      "eval_samples_per_second": 16.991,
      "eval_steps_per_second": 1.07,
      "step": 66300
    },
    {
      "epoch": 2.8540070586209865,
      "grad_norm": 0.9433633089065552,
      "learning_rate": 1.240268781619003e-06,
      "loss": 2.9807,
      "step": 66310
    },
    {
      "epoch": 2.854437462339675,
      "grad_norm": 0.9676786661148071,
      "learning_rate": 1.232983843132196e-06,
      "loss": 2.9991,
      "step": 66320
    },
    {
      "epoch": 2.854867866058363,
      "grad_norm": 0.9005582928657532,
      "learning_rate": 1.2257202296826808e-06,
      "loss": 2.9855,
      "step": 66330
    },
    {
      "epoch": 2.855298269777051,
      "grad_norm": 0.9615123867988586,
      "learning_rate": 1.2184779428387582e-06,
      "loss": 3.0092,
      "step": 66340
    },
    {
      "epoch": 2.8557286734957392,
      "grad_norm": 0.919309139251709,
      "learning_rate": 1.211256984164122e-06,
      "loss": 3.0054,
      "step": 66350
    },
    {
      "epoch": 2.8557286734957392,
      "eval_bleu": 27.29236558145621,
      "eval_gen_len": 27.484,
      "eval_loss": 2.7852609157562256,
      "eval_runtime": 58.3318,
      "eval_samples_per_second": 17.143,
      "eval_steps_per_second": 1.08,
      "step": 66350
    },
    {
      "epoch": 2.856159077214427,
      "grad_norm": 1.1814939975738525,
      "learning_rate": 1.2040573552178912e-06,
      "loss": 2.9463,
      "step": 66360
    },
    {
      "epoch": 2.856589480933115,
      "grad_norm": 0.9874386787414551,
      "learning_rate": 1.196879057554523e-06,
      "loss": 2.9193,
      "step": 66370
    },
    {
      "epoch": 2.8570198846518036,
      "grad_norm": 0.8696383833885193,
      "learning_rate": 1.1897220927239327e-06,
      "loss": 2.9572,
      "step": 66380
    },
    {
      "epoch": 2.8574502883704915,
      "grad_norm": 0.7696786522865295,
      "learning_rate": 1.1825864622713734e-06,
      "loss": 2.9361,
      "step": 66390
    },
    {
      "epoch": 2.8578806920891795,
      "grad_norm": 1.0403859615325928,
      "learning_rate": 1.1754721677375346e-06,
      "loss": 3.0799,
      "step": 66400
    },
    {
      "epoch": 2.8578806920891795,
      "eval_bleu": 27.12383084421091,
      "eval_gen_len": 27.51,
      "eval_loss": 2.7852280139923096,
      "eval_runtime": 58.6192,
      "eval_samples_per_second": 17.059,
      "eval_steps_per_second": 1.075,
      "step": 66400
    },
    {
      "epoch": 2.858311095807868,
      "grad_norm": 0.9000784754753113,
      "learning_rate": 1.1683792106584767e-06,
      "loss": 2.9884,
      "step": 66410
    },
    {
      "epoch": 2.858741499526556,
      "grad_norm": 0.9591620564460754,
      "learning_rate": 1.1613075925656524e-06,
      "loss": 2.9998,
      "step": 66420
    },
    {
      "epoch": 2.859171903245244,
      "grad_norm": 0.8024662733078003,
      "learning_rate": 1.1542573149859183e-06,
      "loss": 3.0046,
      "step": 66430
    },
    {
      "epoch": 2.8596023069639323,
      "grad_norm": 0.8990649580955505,
      "learning_rate": 1.1472283794415228e-06,
      "loss": 2.9382,
      "step": 66440
    },
    {
      "epoch": 2.86003271068262,
      "grad_norm": 0.9444237351417542,
      "learning_rate": 1.140220787450097e-06,
      "loss": 3.0008,
      "step": 66450
    },
    {
      "epoch": 2.86003271068262,
      "eval_bleu": 27.16492022889335,
      "eval_gen_len": 27.53,
      "eval_loss": 2.7851784229278564,
      "eval_runtime": 58.5555,
      "eval_samples_per_second": 17.078,
      "eval_steps_per_second": 1.076,
      "step": 66450
    },
    {
      "epoch": 2.860463114401308,
      "grad_norm": 0.8279659748077393,
      "learning_rate": 1.1332345405246526e-06,
      "loss": 2.9134,
      "step": 66460
    },
    {
      "epoch": 2.8608935181199966,
      "grad_norm": 0.8187891840934753,
      "learning_rate": 1.1262696401736273e-06,
      "loss": 2.8878,
      "step": 66470
    },
    {
      "epoch": 2.8613239218386846,
      "grad_norm": 1.0343362092971802,
      "learning_rate": 1.1193260879008404e-06,
      "loss": 3.0916,
      "step": 66480
    },
    {
      "epoch": 2.861754325557373,
      "grad_norm": 0.9972769618034363,
      "learning_rate": 1.1124038852054596e-06,
      "loss": 3.0847,
      "step": 66490
    },
    {
      "epoch": 2.862184729276061,
      "grad_norm": 0.8610036373138428,
      "learning_rate": 1.1055030335820892e-06,
      "loss": 3.0571,
      "step": 66500
    },
    {
      "epoch": 2.862184729276061,
      "eval_bleu": 27.112210682495693,
      "eval_gen_len": 27.48,
      "eval_loss": 2.7852845191955566,
      "eval_runtime": 58.4814,
      "eval_samples_per_second": 17.099,
      "eval_steps_per_second": 1.077,
      "step": 66500
    },
    {
      "epoch": 2.8626151329947493,
      "grad_norm": 0.9116309285163879,
      "learning_rate": 1.0986235345207152e-06,
      "loss": 2.9267,
      "step": 66510
    },
    {
      "epoch": 2.8630455367134373,
      "grad_norm": 0.9776217341423035,
      "learning_rate": 1.0917653895067159e-06,
      "loss": 3.0183,
      "step": 66520
    },
    {
      "epoch": 2.8634759404321253,
      "grad_norm": 0.9108002781867981,
      "learning_rate": 1.0849286000208291e-06,
      "loss": 2.9884,
      "step": 66530
    },
    {
      "epoch": 2.8639063441508137,
      "grad_norm": 0.9718204140663147,
      "learning_rate": 1.0781131675392187e-06,
      "loss": 2.9347,
      "step": 66540
    },
    {
      "epoch": 2.8643367478695017,
      "grad_norm": 0.977088987827301,
      "learning_rate": 1.0713190935334073e-06,
      "loss": 2.952,
      "step": 66550
    },
    {
      "epoch": 2.8643367478695017,
      "eval_bleu": 27.184933194835235,
      "eval_gen_len": 27.499,
      "eval_loss": 2.785273551940918,
      "eval_runtime": 58.8522,
      "eval_samples_per_second": 16.992,
      "eval_steps_per_second": 1.07,
      "step": 66550
    },
    {
      "epoch": 2.8647671515881896,
      "grad_norm": 0.8518046736717224,
      "learning_rate": 1.0645463794703436e-06,
      "loss": 2.9955,
      "step": 66560
    },
    {
      "epoch": 2.865197555306878,
      "grad_norm": 0.9267190098762512,
      "learning_rate": 1.057795026812325e-06,
      "loss": 2.9922,
      "step": 66570
    },
    {
      "epoch": 2.865627959025566,
      "grad_norm": 0.9946612119674683,
      "learning_rate": 1.0510650370170515e-06,
      "loss": 3.0259,
      "step": 66580
    },
    {
      "epoch": 2.866058362744254,
      "grad_norm": 0.8707326054573059,
      "learning_rate": 1.0443564115376282e-06,
      "loss": 3.04,
      "step": 66590
    },
    {
      "epoch": 2.8664887664629424,
      "grad_norm": 0.8609799742698669,
      "learning_rate": 1.0376691518225067e-06,
      "loss": 3.0708,
      "step": 66600
    },
    {
      "epoch": 2.8664887664629424,
      "eval_bleu": 27.24284230289717,
      "eval_gen_len": 27.513,
      "eval_loss": 2.785236120223999,
      "eval_runtime": 58.9358,
      "eval_samples_per_second": 16.968,
      "eval_steps_per_second": 1.069,
      "step": 66600
    },
    {
      "epoch": 2.8669191701816303,
      "grad_norm": 0.8434747457504272,
      "learning_rate": 1.0310032593155772e-06,
      "loss": 2.9866,
      "step": 66610
    },
    {
      "epoch": 2.8673495739003183,
      "grad_norm": 1.0076231956481934,
      "learning_rate": 1.0243587354560658e-06,
      "loss": 2.9841,
      "step": 66620
    },
    {
      "epoch": 2.8677799776190067,
      "grad_norm": 0.9423750042915344,
      "learning_rate": 1.017735581678625e-06,
      "loss": 3.0925,
      "step": 66630
    },
    {
      "epoch": 2.8682103813376947,
      "grad_norm": 0.9559093117713928,
      "learning_rate": 1.0111337994132664e-06,
      "loss": 2.9262,
      "step": 66640
    },
    {
      "epoch": 2.8686407850563826,
      "grad_norm": 0.8572203516960144,
      "learning_rate": 1.0045533900854165e-06,
      "loss": 2.9757,
      "step": 66650
    },
    {
      "epoch": 2.8686407850563826,
      "eval_bleu": 27.09257069191439,
      "eval_gen_len": 27.484,
      "eval_loss": 2.78536319732666,
      "eval_runtime": 58.9561,
      "eval_samples_per_second": 16.962,
      "eval_steps_per_second": 1.069,
      "step": 66650
    },
    {
      "epoch": 2.869071188775071,
      "grad_norm": 0.8721701502799988,
      "learning_rate": 9.97994355115839e-07,
      "loss": 3.008,
      "step": 66660
    },
    {
      "epoch": 2.869501592493759,
      "grad_norm": 0.8984414339065552,
      "learning_rate": 9.914566959207338e-07,
      "loss": 3.0407,
      "step": 66670
    },
    {
      "epoch": 2.8699319962124474,
      "grad_norm": 0.9695558547973633,
      "learning_rate": 9.849404139116502e-07,
      "loss": 2.9637,
      "step": 66680
    },
    {
      "epoch": 2.8703623999311354,
      "grad_norm": 0.9508504271507263,
      "learning_rate": 9.784455104955403e-07,
      "loss": 2.9415,
      "step": 66690
    },
    {
      "epoch": 2.870792803649824,
      "grad_norm": 0.816508948802948,
      "learning_rate": 9.719719870747378e-07,
      "loss": 2.9766,
      "step": 66700
    },
    {
      "epoch": 2.870792803649824,
      "eval_bleu": 27.28635905724237,
      "eval_gen_len": 27.484,
      "eval_loss": 2.785372257232666,
      "eval_runtime": 58.6322,
      "eval_samples_per_second": 17.055,
      "eval_steps_per_second": 1.074,
      "step": 66700
    },
    {
      "epoch": 2.8712232073685118,
      "grad_norm": 0.9241014719009399,
      "learning_rate": 9.655198450469582e-07,
      "loss": 2.8987,
      "step": 66710
    },
    {
      "epoch": 2.8716536110871997,
      "grad_norm": 0.9525666832923889,
      "learning_rate": 9.590890858052981e-07,
      "loss": 3.0834,
      "step": 66720
    },
    {
      "epoch": 2.872084014805888,
      "grad_norm": 0.889877438545227,
      "learning_rate": 9.526797107382468e-07,
      "loss": 2.8886,
      "step": 66730
    },
    {
      "epoch": 2.872514418524576,
      "grad_norm": 0.9314708113670349,
      "learning_rate": 9.46291721229653e-07,
      "loss": 2.931,
      "step": 66740
    },
    {
      "epoch": 2.872944822243264,
      "grad_norm": 0.9510374665260315,
      "learning_rate": 9.399251186587687e-07,
      "loss": 3.0252,
      "step": 66750
    },
    {
      "epoch": 2.872944822243264,
      "eval_bleu": 26.85485215066292,
      "eval_gen_len": 27.492,
      "eval_loss": 2.7853124141693115,
      "eval_runtime": 58.4017,
      "eval_samples_per_second": 17.123,
      "eval_steps_per_second": 1.079,
      "step": 66750
    },
    {
      "epoch": 2.8733752259619525,
      "grad_norm": 0.8492421507835388,
      "learning_rate": 9.335799044002392e-07,
      "loss": 2.851,
      "step": 66760
    },
    {
      "epoch": 2.8738056296806405,
      "grad_norm": 0.9873213768005371,
      "learning_rate": 9.27256079824046e-07,
      "loss": 2.8974,
      "step": 66770
    },
    {
      "epoch": 2.8742360333993284,
      "grad_norm": 0.9049108028411865,
      "learning_rate": 9.209536462956081e-07,
      "loss": 2.9352,
      "step": 66780
    },
    {
      "epoch": 2.874666437118017,
      "grad_norm": 0.9866324067115784,
      "learning_rate": 9.146726051756816e-07,
      "loss": 2.9753,
      "step": 66790
    },
    {
      "epoch": 2.875096840836705,
      "grad_norm": 0.8291353583335876,
      "learning_rate": 9.08412957820437e-07,
      "loss": 2.9714,
      "step": 66800
    },
    {
      "epoch": 2.875096840836705,
      "eval_bleu": 27.00923594826096,
      "eval_gen_len": 27.529,
      "eval_loss": 2.785447597503662,
      "eval_runtime": 58.5338,
      "eval_samples_per_second": 17.084,
      "eval_steps_per_second": 1.076,
      "step": 66800
    },
    {
      "epoch": 2.8755272445553928,
      "grad_norm": 0.8895713090896606,
      "learning_rate": 9.021747055814045e-07,
      "loss": 2.9641,
      "step": 66810
    },
    {
      "epoch": 2.875957648274081,
      "grad_norm": 0.9172623753547668,
      "learning_rate": 8.959578498055066e-07,
      "loss": 2.9423,
      "step": 66820
    },
    {
      "epoch": 2.876388051992769,
      "grad_norm": 0.8560221791267395,
      "learning_rate": 8.897623918350251e-07,
      "loss": 2.9921,
      "step": 66830
    },
    {
      "epoch": 2.876818455711457,
      "grad_norm": 0.9620011448860168,
      "learning_rate": 8.835883330076456e-07,
      "loss": 3.03,
      "step": 66840
    },
    {
      "epoch": 2.8772488594301455,
      "grad_norm": 0.8887282609939575,
      "learning_rate": 8.77435674656435e-07,
      "loss": 2.9059,
      "step": 66850
    },
    {
      "epoch": 2.8772488594301455,
      "eval_bleu": 27.1385680908792,
      "eval_gen_len": 27.494,
      "eval_loss": 2.7853682041168213,
      "eval_runtime": 58.9584,
      "eval_samples_per_second": 16.961,
      "eval_steps_per_second": 1.069,
      "step": 66850
    },
    {
      "epoch": 2.8776792631488335,
      "grad_norm": 1.0666738748550415,
      "learning_rate": 8.713044181098196e-07,
      "loss": 3.0382,
      "step": 66860
    },
    {
      "epoch": 2.878109666867522,
      "grad_norm": 0.9369116425514221,
      "learning_rate": 8.651945646916181e-07,
      "loss": 2.8901,
      "step": 66870
    },
    {
      "epoch": 2.87854007058621,
      "grad_norm": 0.920042097568512,
      "learning_rate": 8.59106115721009e-07,
      "loss": 2.984,
      "step": 66880
    },
    {
      "epoch": 2.878970474304898,
      "grad_norm": 0.9497661590576172,
      "learning_rate": 8.530390725125847e-07,
      "loss": 2.9847,
      "step": 66890
    },
    {
      "epoch": 2.8794008780235862,
      "grad_norm": 1.0039538145065308,
      "learning_rate": 8.469934363762977e-07,
      "loss": 3.0098,
      "step": 66900
    },
    {
      "epoch": 2.8794008780235862,
      "eval_bleu": 27.072753245251526,
      "eval_gen_len": 27.557,
      "eval_loss": 2.785508632659912,
      "eval_runtime": 59.2371,
      "eval_samples_per_second": 16.881,
      "eval_steps_per_second": 1.064,
      "step": 66900
    },
    {
      "epoch": 2.879831281742274,
      "grad_norm": 0.8893715739250183,
      "learning_rate": 8.409692086174481e-07,
      "loss": 2.9668,
      "step": 66910
    },
    {
      "epoch": 2.8802616854609626,
      "grad_norm": 0.9592397809028625,
      "learning_rate": 8.349663905367844e-07,
      "loss": 2.9388,
      "step": 66920
    },
    {
      "epoch": 2.8806920891796506,
      "grad_norm": 0.970960795879364,
      "learning_rate": 8.289849834303476e-07,
      "loss": 2.8354,
      "step": 66930
    },
    {
      "epoch": 2.8811224928983385,
      "grad_norm": 0.8049291372299194,
      "learning_rate": 8.23024988589638e-07,
      "loss": 2.8471,
      "step": 66940
    },
    {
      "epoch": 2.881552896617027,
      "grad_norm": 0.9557060599327087,
      "learning_rate": 8.170864073014595e-07,
      "loss": 2.8908,
      "step": 66950
    },
    {
      "epoch": 2.881552896617027,
      "eval_bleu": 27.18685675380874,
      "eval_gen_len": 27.491,
      "eval_loss": 2.7854206562042236,
      "eval_runtime": 58.7094,
      "eval_samples_per_second": 17.033,
      "eval_steps_per_second": 1.073,
      "step": 66950
    },
    {
      "epoch": 2.881983300335715,
      "grad_norm": 0.9348480701446533,
      "learning_rate": 8.111692408480421e-07,
      "loss": 2.9887,
      "step": 66960
    },
    {
      "epoch": 2.882413704054403,
      "grad_norm": 0.9778504967689514,
      "learning_rate": 8.052734905069859e-07,
      "loss": 3.0839,
      "step": 66970
    },
    {
      "epoch": 2.8828441077730913,
      "grad_norm": 1.0901968479156494,
      "learning_rate": 7.993991575512283e-07,
      "loss": 2.9652,
      "step": 66980
    },
    {
      "epoch": 2.8832745114917793,
      "grad_norm": 0.8534764647483826,
      "learning_rate": 7.935462432491437e-07,
      "loss": 3.0129,
      "step": 66990
    },
    {
      "epoch": 2.8837049152104672,
      "grad_norm": 0.9388095736503601,
      "learning_rate": 7.877147488644321e-07,
      "loss": 3.0271,
      "step": 67000
    },
    {
      "epoch": 2.8837049152104672,
      "eval_bleu": 27.06909621522019,
      "eval_gen_len": 27.495,
      "eval_loss": 2.785525321960449,
      "eval_runtime": 59.0458,
      "eval_samples_per_second": 16.936,
      "eval_steps_per_second": 1.067,
      "step": 67000
    },
    {
      "epoch": 2.8841353189291556,
      "grad_norm": 0.952915608882904,
      "learning_rate": 7.819046756561866e-07,
      "loss": 3.009,
      "step": 67010
    },
    {
      "epoch": 2.8845657226478436,
      "grad_norm": 0.984760582447052,
      "learning_rate": 7.761160248788701e-07,
      "loss": 3.0592,
      "step": 67020
    },
    {
      "epoch": 2.8849961263665316,
      "grad_norm": 1.0067658424377441,
      "learning_rate": 7.703487977823498e-07,
      "loss": 2.988,
      "step": 67030
    },
    {
      "epoch": 2.88542653008522,
      "grad_norm": 0.9419505000114441,
      "learning_rate": 7.646029956118184e-07,
      "loss": 2.8906,
      "step": 67040
    },
    {
      "epoch": 2.885856933803908,
      "grad_norm": 0.8689043521881104,
      "learning_rate": 7.588786196078723e-07,
      "loss": 2.9654,
      "step": 67050
    },
    {
      "epoch": 2.885856933803908,
      "eval_bleu": 27.30078112058568,
      "eval_gen_len": 27.487,
      "eval_loss": 2.7856812477111816,
      "eval_runtime": 59.5323,
      "eval_samples_per_second": 16.798,
      "eval_steps_per_second": 1.058,
      "step": 67050
    },
    {
      "epoch": 2.886287337522596,
      "grad_norm": 0.9499581456184387,
      "learning_rate": 7.531756710064785e-07,
      "loss": 2.9594,
      "step": 67060
    },
    {
      "epoch": 2.8867177412412843,
      "grad_norm": 0.943623423576355,
      "learning_rate": 7.474941510389633e-07,
      "loss": 2.9952,
      "step": 67070
    },
    {
      "epoch": 2.8871481449599723,
      "grad_norm": 0.8847448229789734,
      "learning_rate": 7.418340609320674e-07,
      "loss": 2.9706,
      "step": 67080
    },
    {
      "epoch": 2.8875785486786607,
      "grad_norm": 0.9465861320495605,
      "learning_rate": 7.361954019078354e-07,
      "loss": 2.9668,
      "step": 67090
    },
    {
      "epoch": 2.8880089523973487,
      "grad_norm": 0.9115139842033386,
      "learning_rate": 7.305781751837604e-07,
      "loss": 2.9855,
      "step": 67100
    },
    {
      "epoch": 2.8880089523973487,
      "eval_bleu": 27.20309435923011,
      "eval_gen_len": 27.526,
      "eval_loss": 2.7854082584381104,
      "eval_runtime": 58.8936,
      "eval_samples_per_second": 16.98,
      "eval_steps_per_second": 1.07,
      "step": 67100
    },
    {
      "epoch": 2.888439356116037,
      "grad_norm": 0.9539687037467957,
      "learning_rate": 7.249823819726498e-07,
      "loss": 2.9507,
      "step": 67110
    },
    {
      "epoch": 2.888869759834725,
      "grad_norm": 0.9889692664146423,
      "learning_rate": 7.19408023482726e-07,
      "loss": 2.9343,
      "step": 67120
    },
    {
      "epoch": 2.889300163553413,
      "grad_norm": 0.8490192294120789,
      "learning_rate": 7.138551009175376e-07,
      "loss": 2.9326,
      "step": 67130
    },
    {
      "epoch": 2.8897305672721014,
      "grad_norm": 0.996894121170044,
      "learning_rate": 7.083236154760475e-07,
      "loss": 2.9621,
      "step": 67140
    },
    {
      "epoch": 2.8901609709907894,
      "grad_norm": 1.0566378831863403,
      "learning_rate": 7.028135683525671e-07,
      "loss": 3.044,
      "step": 67150
    },
    {
      "epoch": 2.8901609709907894,
      "eval_bleu": 26.98609921428194,
      "eval_gen_len": 27.484,
      "eval_loss": 2.785508394241333,
      "eval_runtime": 59.2692,
      "eval_samples_per_second": 16.872,
      "eval_steps_per_second": 1.063,
      "step": 67150
    },
    {
      "epoch": 2.8905913747094774,
      "grad_norm": 0.9547915458679199,
      "learning_rate": 6.973249607367783e-07,
      "loss": 2.9807,
      "step": 67160
    },
    {
      "epoch": 2.8910217784281658,
      "grad_norm": 0.9133332371711731,
      "learning_rate": 6.918577938137549e-07,
      "loss": 3.0495,
      "step": 67170
    },
    {
      "epoch": 2.8914521821468537,
      "grad_norm": 0.9919305443763733,
      "learning_rate": 6.864120687639086e-07,
      "loss": 2.9759,
      "step": 67180
    },
    {
      "epoch": 2.8918825858655417,
      "grad_norm": 0.9966141581535339,
      "learning_rate": 6.809877867630654e-07,
      "loss": 3.0209,
      "step": 67190
    },
    {
      "epoch": 2.89231298958423,
      "grad_norm": 0.9058473110198975,
      "learning_rate": 6.755849489823662e-07,
      "loss": 2.9945,
      "step": 67200
    },
    {
      "epoch": 2.89231298958423,
      "eval_bleu": 27.067993148562685,
      "eval_gen_len": 27.502,
      "eval_loss": 2.7855286598205566,
      "eval_runtime": 58.6958,
      "eval_samples_per_second": 17.037,
      "eval_steps_per_second": 1.073,
      "step": 67200
    },
    {
      "epoch": 2.892743393302918,
      "grad_norm": 1.0099289417266846,
      "learning_rate": 6.702035565883779e-07,
      "loss": 3.0422,
      "step": 67210
    },
    {
      "epoch": 2.893173797021606,
      "grad_norm": 0.9320486187934875,
      "learning_rate": 6.648436107429934e-07,
      "loss": 2.9124,
      "step": 67220
    },
    {
      "epoch": 2.8936042007402945,
      "grad_norm": 1.0006091594696045,
      "learning_rate": 6.595051126034979e-07,
      "loss": 2.9967,
      "step": 67230
    },
    {
      "epoch": 2.8940346044589824,
      "grad_norm": 0.8583551645278931,
      "learning_rate": 6.541880633225361e-07,
      "loss": 2.9553,
      "step": 67240
    },
    {
      "epoch": 2.8944650081776704,
      "grad_norm": 0.8668069243431091,
      "learning_rate": 6.488924640481342e-07,
      "loss": 3.0422,
      "step": 67250
    },
    {
      "epoch": 2.8944650081776704,
      "eval_bleu": 27.182209154607833,
      "eval_gen_len": 27.5,
      "eval_loss": 2.7855374813079834,
      "eval_runtime": 58.6882,
      "eval_samples_per_second": 17.039,
      "eval_steps_per_second": 1.073,
      "step": 67250
    },
    {
      "epoch": 2.894895411896359,
      "grad_norm": 0.9662221074104309,
      "learning_rate": 6.436183159236775e-07,
      "loss": 3.0007,
      "step": 67260
    },
    {
      "epoch": 2.8953258156150468,
      "grad_norm": 1.013802170753479,
      "learning_rate": 6.383656200878996e-07,
      "loss": 3.0026,
      "step": 67270
    },
    {
      "epoch": 2.895756219333735,
      "grad_norm": 0.8746048212051392,
      "learning_rate": 6.331343776749599e-07,
      "loss": 2.9795,
      "step": 67280
    },
    {
      "epoch": 2.896186623052423,
      "grad_norm": 0.9219176173210144,
      "learning_rate": 6.279245898143216e-07,
      "loss": 3.0425,
      "step": 67290
    },
    {
      "epoch": 2.8966170267711115,
      "grad_norm": 1.0664935111999512,
      "learning_rate": 6.227362576308515e-07,
      "loss": 3.0227,
      "step": 67300
    },
    {
      "epoch": 2.8966170267711115,
      "eval_bleu": 27.194555654668143,
      "eval_gen_len": 27.533,
      "eval_loss": 2.7854220867156982,
      "eval_runtime": 58.4117,
      "eval_samples_per_second": 17.12,
      "eval_steps_per_second": 1.079,
      "step": 67300
    },
    {
      "epoch": 2.8970474304897995,
      "grad_norm": 0.9065027832984924,
      "learning_rate": 6.175693822447759e-07,
      "loss": 3.0042,
      "step": 67310
    },
    {
      "epoch": 2.8974778342084875,
      "grad_norm": 0.8888693451881409,
      "learning_rate": 6.124239647716911e-07,
      "loss": 2.9398,
      "step": 67320
    },
    {
      "epoch": 2.897908237927176,
      "grad_norm": 0.856097400188446,
      "learning_rate": 6.07300006322542e-07,
      "loss": 2.9377,
      "step": 67330
    },
    {
      "epoch": 2.898338641645864,
      "grad_norm": 1.0610344409942627,
      "learning_rate": 6.021975080036768e-07,
      "loss": 3.0397,
      "step": 67340
    },
    {
      "epoch": 2.898769045364552,
      "grad_norm": 0.9534383416175842,
      "learning_rate": 5.971164709167698e-07,
      "loss": 2.9952,
      "step": 67350
    },
    {
      "epoch": 2.898769045364552,
      "eval_bleu": 27.02634271579266,
      "eval_gen_len": 27.483,
      "eval_loss": 2.785555124282837,
      "eval_runtime": 58.7029,
      "eval_samples_per_second": 17.035,
      "eval_steps_per_second": 1.073,
      "step": 67350
    },
    {
      "epoch": 2.8991994490832402,
      "grad_norm": 0.8689855337142944,
      "learning_rate": 5.920568961588991e-07,
      "loss": 3.0333,
      "step": 67360
    },
    {
      "epoch": 2.899629852801928,
      "grad_norm": 0.8617028594017029,
      "learning_rate": 5.870187848224795e-07,
      "loss": 3.0697,
      "step": 67370
    },
    {
      "epoch": 2.900060256520616,
      "grad_norm": 0.9318253397941589,
      "learning_rate": 5.820021379953078e-07,
      "loss": 2.994,
      "step": 67380
    },
    {
      "epoch": 2.9004906602393046,
      "grad_norm": 1.0066018104553223,
      "learning_rate": 5.770069567605396e-07,
      "loss": 3.0413,
      "step": 67390
    },
    {
      "epoch": 2.9009210639579925,
      "grad_norm": 0.8583979606628418,
      "learning_rate": 5.72033242196679e-07,
      "loss": 2.8723,
      "step": 67400
    },
    {
      "epoch": 2.9009210639579925,
      "eval_bleu": 27.200596644032014,
      "eval_gen_len": 27.549,
      "eval_loss": 2.7855331897735596,
      "eval_runtime": 58.3435,
      "eval_samples_per_second": 17.14,
      "eval_steps_per_second": 1.08,
      "step": 67400
    },
    {
      "epoch": 2.9013514676766805,
      "grad_norm": 0.8128887414932251,
      "learning_rate": 5.670809953776446e-07,
      "loss": 2.8824,
      "step": 67410
    },
    {
      "epoch": 2.901781871395369,
      "grad_norm": 0.8238460421562195,
      "learning_rate": 5.621502173726701e-07,
      "loss": 2.8822,
      "step": 67420
    },
    {
      "epoch": 2.902212275114057,
      "grad_norm": 1.0554548501968384,
      "learning_rate": 5.572409092463704e-07,
      "loss": 2.9634,
      "step": 67430
    },
    {
      "epoch": 2.902642678832745,
      "grad_norm": 1.0657248497009277,
      "learning_rate": 5.523530720587311e-07,
      "loss": 2.9777,
      "step": 67440
    },
    {
      "epoch": 2.9030730825514333,
      "grad_norm": 0.9094821810722351,
      "learning_rate": 5.47486706865108e-07,
      "loss": 2.9795,
      "step": 67450
    },
    {
      "epoch": 2.9030730825514333,
      "eval_bleu": 27.153467573326676,
      "eval_gen_len": 27.512,
      "eval_loss": 2.7855656147003174,
      "eval_runtime": 58.652,
      "eval_samples_per_second": 17.05,
      "eval_steps_per_second": 1.074,
      "step": 67450
    },
    {
      "epoch": 2.9035034862701212,
      "grad_norm": 0.8851505517959595,
      "learning_rate": 5.426418147161938e-07,
      "loss": 2.9165,
      "step": 67460
    },
    {
      "epoch": 2.9039338899888096,
      "grad_norm": 1.0622798204421997,
      "learning_rate": 5.378183966580741e-07,
      "loss": 2.9375,
      "step": 67470
    },
    {
      "epoch": 2.9043642937074976,
      "grad_norm": 0.9102408289909363,
      "learning_rate": 5.330164537321714e-07,
      "loss": 2.9884,
      "step": 67480
    },
    {
      "epoch": 2.904794697426186,
      "grad_norm": 1.0129653215408325,
      "learning_rate": 5.282359869752895e-07,
      "loss": 3.0066,
      "step": 67490
    },
    {
      "epoch": 2.905225101144874,
      "grad_norm": 0.9418315291404724,
      "learning_rate": 5.234769974196141e-07,
      "loss": 2.9251,
      "step": 67500
    },
    {
      "epoch": 2.905225101144874,
      "eval_bleu": 27.35980570465191,
      "eval_gen_len": 27.511,
      "eval_loss": 2.785515308380127,
      "eval_runtime": 58.8838,
      "eval_samples_per_second": 16.983,
      "eval_steps_per_second": 1.07,
      "step": 67500
    },
    {
      "epoch": 2.905655504863562,
      "grad_norm": 0.865021288394928,
      "learning_rate": 5.187394860926343e-07,
      "loss": 3.0463,
      "step": 67510
    },
    {
      "epoch": 2.9060859085822504,
      "grad_norm": 0.9796717762947083,
      "learning_rate": 5.14023454017265e-07,
      "loss": 2.9476,
      "step": 67520
    },
    {
      "epoch": 2.9065163123009383,
      "grad_norm": 0.9578292369842529,
      "learning_rate": 5.093289022117365e-07,
      "loss": 3.0014,
      "step": 67530
    },
    {
      "epoch": 2.9069467160196263,
      "grad_norm": 0.8936545848846436,
      "learning_rate": 5.046558316896822e-07,
      "loss": 2.9551,
      "step": 67540
    },
    {
      "epoch": 2.9073771197383147,
      "grad_norm": 0.9650472402572632,
      "learning_rate": 5.000042434600616e-07,
      "loss": 2.9697,
      "step": 67550
    },
    {
      "epoch": 2.9073771197383147,
      "eval_bleu": 27.162730131533706,
      "eval_gen_len": 27.47,
      "eval_loss": 2.78554630279541,
      "eval_runtime": 58.3707,
      "eval_samples_per_second": 17.132,
      "eval_steps_per_second": 1.079,
      "step": 67550
    },
    {
      "epoch": 2.9078075234570027,
      "grad_norm": 0.9534424543380737,
      "learning_rate": 4.953741385272159e-07,
      "loss": 2.9864,
      "step": 67560
    },
    {
      "epoch": 2.9082379271756906,
      "grad_norm": 1.0288143157958984,
      "learning_rate": 4.907655178908455e-07,
      "loss": 2.9789,
      "step": 67570
    },
    {
      "epoch": 2.908668330894379,
      "grad_norm": 1.0126590728759766,
      "learning_rate": 4.861783825460098e-07,
      "loss": 2.9788,
      "step": 67580
    },
    {
      "epoch": 2.909098734613067,
      "grad_norm": 0.918405294418335,
      "learning_rate": 4.816127334831167e-07,
      "loss": 3.0069,
      "step": 67590
    },
    {
      "epoch": 2.909529138331755,
      "grad_norm": 0.9427640438079834,
      "learning_rate": 4.770685716879664e-07,
      "loss": 2.9732,
      "step": 67600
    },
    {
      "epoch": 2.909529138331755,
      "eval_bleu": 27.290083043080628,
      "eval_gen_len": 27.482,
      "eval_loss": 2.7855002880096436,
      "eval_runtime": 58.4498,
      "eval_samples_per_second": 17.109,
      "eval_steps_per_second": 1.078,
      "step": 67600
    },
    {
      "epoch": 2.9099595420504434,
      "grad_norm": 0.9689158797264099,
      "learning_rate": 4.7254589814168524e-07,
      "loss": 3.0354,
      "step": 67610
    },
    {
      "epoch": 2.9103899457691313,
      "grad_norm": 0.971808135509491,
      "learning_rate": 4.6804471382078106e-07,
      "loss": 2.9366,
      "step": 67620
    },
    {
      "epoch": 2.9108203494878193,
      "grad_norm": 0.9121434092521667,
      "learning_rate": 4.6356501969710976e-07,
      "loss": 2.9628,
      "step": 67630
    },
    {
      "epoch": 2.9112507532065077,
      "grad_norm": 0.8773654103279114,
      "learning_rate": 4.5910681673790866e-07,
      "loss": 2.9882,
      "step": 67640
    },
    {
      "epoch": 2.9116811569251957,
      "grad_norm": 0.9385296106338501,
      "learning_rate": 4.546701059057412e-07,
      "loss": 3.0398,
      "step": 67650
    },
    {
      "epoch": 2.9116811569251957,
      "eval_bleu": 27.04692449735575,
      "eval_gen_len": 27.471,
      "eval_loss": 2.785423755645752,
      "eval_runtime": 58.4168,
      "eval_samples_per_second": 17.118,
      "eval_steps_per_second": 1.078,
      "step": 67650
    },
    {
      "epoch": 2.912111560643884,
      "grad_norm": 0.9295485615730286,
      "learning_rate": 4.502548881585633e-07,
      "loss": 2.9434,
      "step": 67660
    },
    {
      "epoch": 2.912541964362572,
      "grad_norm": 0.8948753476142883,
      "learning_rate": 4.4586116444965685e-07,
      "loss": 3.0275,
      "step": 67670
    },
    {
      "epoch": 2.9129723680812605,
      "grad_norm": 0.9194875955581665,
      "learning_rate": 4.4148893572770746e-07,
      "loss": 2.9224,
      "step": 67680
    },
    {
      "epoch": 2.9134027717999484,
      "grad_norm": 0.8372606635093689,
      "learning_rate": 4.3713820293671547e-07,
      "loss": 3.022,
      "step": 67690
    },
    {
      "epoch": 2.9138331755186364,
      "grad_norm": 0.9262425303459167,
      "learning_rate": 4.3280896701607397e-07,
      "loss": 2.8934,
      "step": 67700
    },
    {
      "epoch": 2.9138331755186364,
      "eval_bleu": 27.152911993052204,
      "eval_gen_len": 27.505,
      "eval_loss": 2.7855286598205566,
      "eval_runtime": 58.4666,
      "eval_samples_per_second": 17.104,
      "eval_steps_per_second": 1.078,
      "step": 67700
    },
    {
      "epoch": 2.914263579237325,
      "grad_norm": 0.921554684638977,
      "learning_rate": 4.2850122890051303e-07,
      "loss": 2.9815,
      "step": 67710
    },
    {
      "epoch": 2.914693982956013,
      "grad_norm": 0.9293639063835144,
      "learning_rate": 4.2421498952011084e-07,
      "loss": 3.0159,
      "step": 67720
    },
    {
      "epoch": 2.9151243866747008,
      "grad_norm": 0.9838796257972717,
      "learning_rate": 4.1995024980033825e-07,
      "loss": 2.9076,
      "step": 67730
    },
    {
      "epoch": 2.915554790393389,
      "grad_norm": 0.8469620943069458,
      "learning_rate": 4.157070106620031e-07,
      "loss": 2.9063,
      "step": 67740
    },
    {
      "epoch": 2.915985194112077,
      "grad_norm": 0.9280303120613098,
      "learning_rate": 4.114852730212726e-07,
      "loss": 2.9373,
      "step": 67750
    },
    {
      "epoch": 2.915985194112077,
      "eval_bleu": 27.15081839632731,
      "eval_gen_len": 27.497,
      "eval_loss": 2.7855496406555176,
      "eval_runtime": 58.3908,
      "eval_samples_per_second": 17.126,
      "eval_steps_per_second": 1.079,
      "step": 67750
    },
    {
      "epoch": 2.916415597830765,
      "grad_norm": 0.8624368906021118,
      "learning_rate": 4.072850377896731e-07,
      "loss": 2.969,
      "step": 67760
    },
    {
      "epoch": 2.9168460015494535,
      "grad_norm": 0.8694074153900146,
      "learning_rate": 4.0310630587409025e-07,
      "loss": 2.8573,
      "step": 67770
    },
    {
      "epoch": 2.9172764052681415,
      "grad_norm": 1.0054477453231812,
      "learning_rate": 3.98949078176758e-07,
      "loss": 2.9111,
      "step": 67780
    },
    {
      "epoch": 2.9177068089868294,
      "grad_norm": 0.8503705263137817,
      "learning_rate": 3.9481335559528043e-07,
      "loss": 2.9131,
      "step": 67790
    },
    {
      "epoch": 2.918137212705518,
      "grad_norm": 0.9625207185745239,
      "learning_rate": 3.9069913902261003e-07,
      "loss": 3.0233,
      "step": 67800
    },
    {
      "epoch": 2.918137212705518,
      "eval_bleu": 27.137032895639127,
      "eval_gen_len": 27.487,
      "eval_loss": 2.7855379581451416,
      "eval_runtime": 58.4549,
      "eval_samples_per_second": 17.107,
      "eval_steps_per_second": 1.078,
      "step": 67800
    },
    {
      "epoch": 2.918567616424206,
      "grad_norm": 0.9912976622581482,
      "learning_rate": 3.8660642934704725e-07,
      "loss": 2.9705,
      "step": 67810
    },
    {
      "epoch": 2.918998020142894,
      "grad_norm": 0.8682153224945068,
      "learning_rate": 3.825352274522853e-07,
      "loss": 2.9136,
      "step": 67820
    },
    {
      "epoch": 2.919428423861582,
      "grad_norm": 0.8637799620628357,
      "learning_rate": 3.78485534217321e-07,
      "loss": 2.9517,
      "step": 67830
    },
    {
      "epoch": 2.91985882758027,
      "grad_norm": 1.1237165927886963,
      "learning_rate": 3.7445735051654383e-07,
      "loss": 3.0492,
      "step": 67840
    },
    {
      "epoch": 2.9202892312989586,
      "grad_norm": 0.9488650560379028,
      "learning_rate": 3.704506772196914e-07,
      "loss": 3.0391,
      "step": 67850
    },
    {
      "epoch": 2.9202892312989586,
      "eval_bleu": 27.153998781999622,
      "eval_gen_len": 27.503,
      "eval_loss": 2.78559947013855,
      "eval_runtime": 58.7279,
      "eval_samples_per_second": 17.028,
      "eval_steps_per_second": 1.073,
      "step": 67850
    },
    {
      "epoch": 2.9207196350176465,
      "grad_norm": 0.8348782658576965,
      "learning_rate": 3.6646551519186054e-07,
      "loss": 2.9215,
      "step": 67860
    },
    {
      "epoch": 2.921150038736335,
      "grad_norm": 0.870139479637146,
      "learning_rate": 3.625018652934853e-07,
      "loss": 2.9572,
      "step": 67870
    },
    {
      "epoch": 2.921580442455023,
      "grad_norm": 0.8025118112564087,
      "learning_rate": 3.585597283803699e-07,
      "loss": 2.9611,
      "step": 67880
    },
    {
      "epoch": 2.922010846173711,
      "grad_norm": 0.8680698871612549,
      "learning_rate": 3.546391053036779e-07,
      "loss": 2.9864,
      "step": 67890
    },
    {
      "epoch": 2.9224412498923993,
      "grad_norm": 0.8954806327819824,
      "learning_rate": 3.507399969099212e-07,
      "loss": 2.9662,
      "step": 67900
    },
    {
      "epoch": 2.9224412498923993,
      "eval_bleu": 27.094671737634826,
      "eval_gen_len": 27.492,
      "eval_loss": 2.7854554653167725,
      "eval_runtime": 58.9742,
      "eval_samples_per_second": 16.957,
      "eval_steps_per_second": 1.068,
      "step": 67900
    },
    {
      "epoch": 2.9228716536110873,
      "grad_norm": 0.8136842846870422,
      "learning_rate": 3.468624040409596e-07,
      "loss": 2.974,
      "step": 67910
    },
    {
      "epoch": 2.923302057329775,
      "grad_norm": 0.9169275760650635,
      "learning_rate": 3.430063275340123e-07,
      "loss": 2.974,
      "step": 67920
    },
    {
      "epoch": 2.9237324610484636,
      "grad_norm": 0.9301733374595642,
      "learning_rate": 3.3917176822165777e-07,
      "loss": 3.011,
      "step": 67930
    },
    {
      "epoch": 2.9241628647671516,
      "grad_norm": 0.9442252516746521,
      "learning_rate": 3.353587269318337e-07,
      "loss": 2.9884,
      "step": 67940
    },
    {
      "epoch": 2.9245932684858396,
      "grad_norm": 0.8879691362380981,
      "learning_rate": 3.3156720448781487e-07,
      "loss": 3.0181,
      "step": 67950
    },
    {
      "epoch": 2.9245932684858396,
      "eval_bleu": 27.25561459606118,
      "eval_gen_len": 27.517,
      "eval_loss": 2.7853450775146484,
      "eval_runtime": 58.7805,
      "eval_samples_per_second": 17.012,
      "eval_steps_per_second": 1.072,
      "step": 67950
    },
    {
      "epoch": 2.925023672204528,
      "grad_norm": 0.8241499066352844,
      "learning_rate": 3.277972017082243e-07,
      "loss": 2.9902,
      "step": 67960
    },
    {
      "epoch": 2.925454075923216,
      "grad_norm": 1.0194593667984009,
      "learning_rate": 3.240487194070885e-07,
      "loss": 2.9347,
      "step": 67970
    },
    {
      "epoch": 2.925884479641904,
      "grad_norm": 0.9318959712982178,
      "learning_rate": 3.203217583937157e-07,
      "loss": 3.0385,
      "step": 67980
    },
    {
      "epoch": 2.9263148833605923,
      "grad_norm": 0.9386205673217773,
      "learning_rate": 3.166163194728289e-07,
      "loss": 2.8961,
      "step": 67990
    },
    {
      "epoch": 2.9267452870792803,
      "grad_norm": 0.9717684388160706,
      "learning_rate": 3.1293240344446584e-07,
      "loss": 2.9557,
      "step": 68000
    },
    {
      "epoch": 2.9267452870792803,
      "eval_bleu": 27.016803425234905,
      "eval_gen_len": 27.525,
      "eval_loss": 2.7854464054107666,
      "eval_runtime": 58.7731,
      "eval_samples_per_second": 17.015,
      "eval_steps_per_second": 1.072,
      "step": 68000
    },
    {
      "epoch": 2.9271756907979682,
      "grad_norm": 0.993213415145874,
      "learning_rate": 3.0927001110403476e-07,
      "loss": 2.9869,
      "step": 68010
    },
    {
      "epoch": 2.9276060945166567,
      "grad_norm": 1.016770839691162,
      "learning_rate": 3.0562914324230307e-07,
      "loss": 3.0004,
      "step": 68020
    },
    {
      "epoch": 2.9280364982353446,
      "grad_norm": 1.0773022174835205,
      "learning_rate": 3.0200980064535314e-07,
      "loss": 2.9965,
      "step": 68030
    },
    {
      "epoch": 2.928466901954033,
      "grad_norm": 0.9202106595039368,
      "learning_rate": 2.9841198409467084e-07,
      "loss": 3.0109,
      "step": 68040
    },
    {
      "epoch": 2.928897305672721,
      "grad_norm": 0.9523758292198181,
      "learning_rate": 2.9483569436704607e-07,
      "loss": 3.0047,
      "step": 68050
    },
    {
      "epoch": 2.928897305672721,
      "eval_bleu": 27.08275847223581,
      "eval_gen_len": 27.514,
      "eval_loss": 2.785478115081787,
      "eval_runtime": 59.3121,
      "eval_samples_per_second": 16.86,
      "eval_steps_per_second": 1.062,
      "step": 68050
    },
    {
      "epoch": 2.9293277093914094,
      "grad_norm": 0.9033911228179932,
      "learning_rate": 2.912809322346721e-07,
      "loss": 2.9468,
      "step": 68060
    },
    {
      "epoch": 2.9297581131100974,
      "grad_norm": 0.8628827333450317,
      "learning_rate": 2.877476984650462e-07,
      "loss": 2.9704,
      "step": 68070
    },
    {
      "epoch": 2.9301885168287853,
      "grad_norm": 0.9337264895439148,
      "learning_rate": 2.8423599382104707e-07,
      "loss": 3.0132,
      "step": 68080
    },
    {
      "epoch": 2.9306189205474737,
      "grad_norm": 1.0206965208053589,
      "learning_rate": 2.807458190608903e-07,
      "loss": 2.9059,
      "step": 68090
    },
    {
      "epoch": 2.9310493242661617,
      "grad_norm": 0.9689217805862427,
      "learning_rate": 2.7727717493815085e-07,
      "loss": 2.9934,
      "step": 68100
    },
    {
      "epoch": 2.9310493242661617,
      "eval_bleu": 27.218953038070868,
      "eval_gen_len": 27.467,
      "eval_loss": 2.7854907512664795,
      "eval_runtime": 59.0484,
      "eval_samples_per_second": 16.935,
      "eval_steps_per_second": 1.067,
      "step": 68100
    },
    {
      "epoch": 2.9314797279848497,
      "grad_norm": 1.0292192697525024,
      "learning_rate": 2.738300622017631e-07,
      "loss": 2.9914,
      "step": 68110
    },
    {
      "epoch": 2.931910131703538,
      "grad_norm": 0.9376908540725708,
      "learning_rate": 2.704044815959872e-07,
      "loss": 3.0966,
      "step": 68120
    },
    {
      "epoch": 2.932340535422226,
      "grad_norm": 0.9873132109642029,
      "learning_rate": 2.670004338604537e-07,
      "loss": 2.9977,
      "step": 68130
    },
    {
      "epoch": 2.932770939140914,
      "grad_norm": 0.8950254321098328,
      "learning_rate": 2.636179197301414e-07,
      "loss": 2.8855,
      "step": 68140
    },
    {
      "epoch": 2.9332013428596024,
      "grad_norm": 0.9720718860626221,
      "learning_rate": 2.6025693993537715e-07,
      "loss": 3.0666,
      "step": 68150
    },
    {
      "epoch": 2.9332013428596024,
      "eval_bleu": 27.129063671889433,
      "eval_gen_len": 27.477,
      "eval_loss": 2.7855427265167236,
      "eval_runtime": 58.7844,
      "eval_samples_per_second": 17.011,
      "eval_steps_per_second": 1.072,
      "step": 68150
    },
    {
      "epoch": 2.9336317465782904,
      "grad_norm": 0.925682008266449,
      "learning_rate": 2.5691749520182494e-07,
      "loss": 2.9963,
      "step": 68160
    },
    {
      "epoch": 2.9340621502969784,
      "grad_norm": 0.9065722823143005,
      "learning_rate": 2.5359958625053024e-07,
      "loss": 2.9307,
      "step": 68170
    },
    {
      "epoch": 2.9344925540156668,
      "grad_norm": 0.9689427614212036,
      "learning_rate": 2.5030321379787557e-07,
      "loss": 3.008,
      "step": 68180
    },
    {
      "epoch": 2.9349229577343547,
      "grad_norm": 0.9331371188163757,
      "learning_rate": 2.470283785555694e-07,
      "loss": 3.0911,
      "step": 68190
    },
    {
      "epoch": 2.9353533614530427,
      "grad_norm": 0.8456358909606934,
      "learning_rate": 2.4377508123070157e-07,
      "loss": 2.9703,
      "step": 68200
    },
    {
      "epoch": 2.9353533614530427,
      "eval_bleu": 27.221295982549005,
      "eval_gen_len": 27.481,
      "eval_loss": 2.785449266433716,
      "eval_runtime": 58.7884,
      "eval_samples_per_second": 17.01,
      "eval_steps_per_second": 1.072,
      "step": 68200
    },
    {
      "epoch": 2.935783765171731,
      "grad_norm": 0.8832677006721497,
      "learning_rate": 2.4054332252569923e-07,
      "loss": 2.8955,
      "step": 68210
    },
    {
      "epoch": 2.936214168890419,
      "grad_norm": 0.9560568332672119,
      "learning_rate": 2.3733310313833745e-07,
      "loss": 3.0013,
      "step": 68220
    },
    {
      "epoch": 2.9366445726091075,
      "grad_norm": 0.932076096534729,
      "learning_rate": 2.3414442376173962e-07,
      "loss": 2.8238,
      "step": 68230
    },
    {
      "epoch": 2.9370749763277955,
      "grad_norm": 0.8650851249694824,
      "learning_rate": 2.3097728508438832e-07,
      "loss": 3.1068,
      "step": 68240
    },
    {
      "epoch": 2.937505380046484,
      "grad_norm": 0.8913288116455078,
      "learning_rate": 2.2783168779011432e-07,
      "loss": 2.98,
      "step": 68250
    },
    {
      "epoch": 2.937505380046484,
      "eval_bleu": 27.240375425336747,
      "eval_gen_len": 27.49,
      "eval_loss": 2.785428762435913,
      "eval_runtime": 58.7235,
      "eval_samples_per_second": 17.029,
      "eval_steps_per_second": 1.073,
      "step": 68250
    },
    {
      "epoch": 2.937935783765172,
      "grad_norm": 0.9265261888504028,
      "learning_rate": 2.2470763255807437e-07,
      "loss": 2.976,
      "step": 68260
    },
    {
      "epoch": 2.93836618748386,
      "grad_norm": 0.9264456629753113,
      "learning_rate": 2.2160512006279555e-07,
      "loss": 3.0073,
      "step": 68270
    },
    {
      "epoch": 2.938796591202548,
      "grad_norm": 0.8795340657234192,
      "learning_rate": 2.1852415097416422e-07,
      "loss": 3.0273,
      "step": 68280
    },
    {
      "epoch": 2.939226994921236,
      "grad_norm": 0.849425733089447,
      "learning_rate": 2.1546472595738166e-07,
      "loss": 2.9826,
      "step": 68290
    },
    {
      "epoch": 2.939657398639924,
      "grad_norm": 0.9650050401687622,
      "learning_rate": 2.124268456730305e-07,
      "loss": 2.91,
      "step": 68300
    },
    {
      "epoch": 2.939657398639924,
      "eval_bleu": 27.33168699852082,
      "eval_gen_len": 27.49,
      "eval_loss": 2.7853219509124756,
      "eval_runtime": 58.3616,
      "eval_samples_per_second": 17.135,
      "eval_steps_per_second": 1.079,
      "step": 68300
    },
    {
      "epoch": 2.9400878023586126,
      "grad_norm": 1.017641305923462,
      "learning_rate": 2.0941051077700835e-07,
      "loss": 2.8848,
      "step": 68310
    },
    {
      "epoch": 2.9405182060773005,
      "grad_norm": 0.8374572992324829,
      "learning_rate": 2.064157219206053e-07,
      "loss": 2.9557,
      "step": 68320
    },
    {
      "epoch": 2.9409486097959885,
      "grad_norm": 0.9380495548248291,
      "learning_rate": 2.034424797504153e-07,
      "loss": 2.9273,
      "step": 68330
    },
    {
      "epoch": 2.941379013514677,
      "grad_norm": 0.9560773372650146,
      "learning_rate": 2.0049078490840255e-07,
      "loss": 2.9585,
      "step": 68340
    },
    {
      "epoch": 2.941809417233365,
      "grad_norm": 0.8317918181419373,
      "learning_rate": 1.9756063803187953e-07,
      "loss": 2.9195,
      "step": 68350
    },
    {
      "epoch": 2.941809417233365,
      "eval_bleu": 27.164108983271657,
      "eval_gen_len": 27.477,
      "eval_loss": 2.785287618637085,
      "eval_runtime": 58.8374,
      "eval_samples_per_second": 16.996,
      "eval_steps_per_second": 1.071,
      "step": 68350
    },
    {
      "epoch": 2.942239820952053,
      "grad_norm": 0.8511269092559814,
      "learning_rate": 1.9465203975349565e-07,
      "loss": 3.0595,
      "step": 68360
    },
    {
      "epoch": 2.9426702246707412,
      "grad_norm": 0.9014690518379211,
      "learning_rate": 1.9176499070124864e-07,
      "loss": 2.9002,
      "step": 68370
    },
    {
      "epoch": 2.943100628389429,
      "grad_norm": 0.9936653971672058,
      "learning_rate": 1.888994914985065e-07,
      "loss": 2.9943,
      "step": 68380
    },
    {
      "epoch": 2.943531032108117,
      "grad_norm": 0.9579930901527405,
      "learning_rate": 1.860555427639521e-07,
      "loss": 2.8683,
      "step": 68390
    },
    {
      "epoch": 2.9439614358268056,
      "grad_norm": 0.86884605884552,
      "learning_rate": 1.8323314511163868e-07,
      "loss": 2.9156,
      "step": 68400
    },
    {
      "epoch": 2.9439614358268056,
      "eval_bleu": 27.11363276895106,
      "eval_gen_len": 27.495,
      "eval_loss": 2.78537917137146,
      "eval_runtime": 58.7499,
      "eval_samples_per_second": 17.021,
      "eval_steps_per_second": 1.072,
      "step": 68400
    },
    {
      "epoch": 2.9443918395454935,
      "grad_norm": 0.9468244314193726,
      "learning_rate": 1.804322991509566e-07,
      "loss": 3.056,
      "step": 68410
    },
    {
      "epoch": 2.944822243264182,
      "grad_norm": 0.8326843976974487,
      "learning_rate": 1.7765300548663321e-07,
      "loss": 2.8902,
      "step": 68420
    },
    {
      "epoch": 2.94525264698287,
      "grad_norm": 0.9546858668327332,
      "learning_rate": 1.7489526471875516e-07,
      "loss": 3.0158,
      "step": 68430
    },
    {
      "epoch": 2.9456830507015583,
      "grad_norm": 0.8554175496101379,
      "learning_rate": 1.7215907744275727e-07,
      "loss": 2.9664,
      "step": 68440
    },
    {
      "epoch": 2.9461134544202463,
      "grad_norm": 0.8417505621910095,
      "learning_rate": 1.6944444424942252e-07,
      "loss": 2.9875,
      "step": 68450
    },
    {
      "epoch": 2.9461134544202463,
      "eval_bleu": 27.137002039536952,
      "eval_gen_len": 27.49,
      "eval_loss": 2.7853970527648926,
      "eval_runtime": 58.7014,
      "eval_samples_per_second": 17.035,
      "eval_steps_per_second": 1.073,
      "step": 68450
    },
    {
      "epoch": 2.9465438581389343,
      "grad_norm": 0.8784002065658569,
      "learning_rate": 1.6675136572487093e-07,
      "loss": 2.9926,
      "step": 68460
    },
    {
      "epoch": 2.9469742618576227,
      "grad_norm": 0.8728165030479431,
      "learning_rate": 1.6407984245055962e-07,
      "loss": 2.9814,
      "step": 68470
    },
    {
      "epoch": 2.9474046655763106,
      "grad_norm": 1.041757583618164,
      "learning_rate": 1.6142987500332718e-07,
      "loss": 3.0092,
      "step": 68480
    },
    {
      "epoch": 2.9478350692949986,
      "grad_norm": 0.8743213415145874,
      "learning_rate": 1.588014639553048e-07,
      "loss": 2.9509,
      "step": 68490
    },
    {
      "epoch": 2.948265473013687,
      "grad_norm": 1.042540431022644,
      "learning_rate": 1.5619460987402745e-07,
      "loss": 3.0599,
      "step": 68500
    },
    {
      "epoch": 2.948265473013687,
      "eval_bleu": 27.21809221368005,
      "eval_gen_len": 27.553,
      "eval_loss": 2.785388231277466,
      "eval_runtime": 58.6374,
      "eval_samples_per_second": 17.054,
      "eval_steps_per_second": 1.074,
      "step": 68500
    },
    {
      "epoch": 2.948695876732375,
      "grad_norm": 0.8876202702522278,
      "learning_rate": 1.5360931332233374e-07,
      "loss": 3.0204,
      "step": 68510
    },
    {
      "epoch": 2.949126280451063,
      "grad_norm": 0.8374796509742737,
      "learning_rate": 1.5104557485842163e-07,
      "loss": 2.977,
      "step": 68520
    },
    {
      "epoch": 2.9495566841697514,
      "grad_norm": 0.9927913546562195,
      "learning_rate": 1.4850339503583722e-07,
      "loss": 3.0059,
      "step": 68530
    },
    {
      "epoch": 2.9499870878884393,
      "grad_norm": 1.0059877634048462,
      "learning_rate": 1.4598277440347474e-07,
      "loss": 2.9628,
      "step": 68540
    },
    {
      "epoch": 2.9504174916071273,
      "grad_norm": 0.7839387655258179,
      "learning_rate": 1.4348371350555445e-07,
      "loss": 2.9196,
      "step": 68550
    },
    {
      "epoch": 2.9504174916071273,
      "eval_bleu": 27.200220613339738,
      "eval_gen_len": 27.485,
      "eval_loss": 2.785418748855591,
      "eval_runtime": 59.0359,
      "eval_samples_per_second": 16.939,
      "eval_steps_per_second": 1.067,
      "step": 68550
    },
    {
      "epoch": 2.9508478953258157,
      "grad_norm": 0.9099898934364319,
      "learning_rate": 1.4100621288166692e-07,
      "loss": 3.0004,
      "step": 68560
    },
    {
      "epoch": 2.9512782990445037,
      "grad_norm": 1.1120686531066895,
      "learning_rate": 1.3855027306672874e-07,
      "loss": 3.0223,
      "step": 68570
    },
    {
      "epoch": 2.9517087027631916,
      "grad_norm": 0.9088289737701416,
      "learning_rate": 1.3611589459101572e-07,
      "loss": 2.9867,
      "step": 68580
    },
    {
      "epoch": 2.95213910648188,
      "grad_norm": 0.8322848081588745,
      "learning_rate": 1.337030779801296e-07,
      "loss": 3.0059,
      "step": 68590
    },
    {
      "epoch": 2.952569510200568,
      "grad_norm": 0.884892463684082,
      "learning_rate": 1.3131182375503148e-07,
      "loss": 3.0366,
      "step": 68600
    },
    {
      "epoch": 2.952569510200568,
      "eval_bleu": 27.138006925429288,
      "eval_gen_len": 27.478,
      "eval_loss": 2.785290479660034,
      "eval_runtime": 58.503,
      "eval_samples_per_second": 17.093,
      "eval_steps_per_second": 1.077,
      "step": 68600
    },
    {
      "epoch": 2.9529999139192564,
      "grad_norm": 0.8636437058448792,
      "learning_rate": 1.2894213243203058e-07,
      "loss": 2.915,
      "step": 68610
    },
    {
      "epoch": 2.9534303176379444,
      "grad_norm": 0.9828250408172607,
      "learning_rate": 1.2659400452276204e-07,
      "loss": 3.0475,
      "step": 68620
    },
    {
      "epoch": 2.9538607213566324,
      "grad_norm": 0.938790500164032,
      "learning_rate": 1.2426744053422034e-07,
      "loss": 2.895,
      "step": 68630
    },
    {
      "epoch": 2.9542911250753208,
      "grad_norm": 0.9076982736587524,
      "learning_rate": 1.21962440968737e-07,
      "loss": 3.0306,
      "step": 68640
    },
    {
      "epoch": 2.9547215287940087,
      "grad_norm": 0.9547641277313232,
      "learning_rate": 1.1967900632400275e-07,
      "loss": 2.7719,
      "step": 68650
    },
    {
      "epoch": 2.9547215287940087,
      "eval_bleu": 27.069739128217094,
      "eval_gen_len": 27.493,
      "eval_loss": 2.785365581512451,
      "eval_runtime": 58.7921,
      "eval_samples_per_second": 17.009,
      "eval_steps_per_second": 1.072,
      "step": 68650
    },
    {
      "epoch": 2.955151932512697,
      "grad_norm": 1.0573203563690186,
      "learning_rate": 1.1741713709303437e-07,
      "loss": 2.916,
      "step": 68660
    },
    {
      "epoch": 2.955582336231385,
      "grad_norm": 0.8981136679649353,
      "learning_rate": 1.1517683376418564e-07,
      "loss": 2.9634,
      "step": 68670
    },
    {
      "epoch": 2.956012739950073,
      "grad_norm": 1.0603554248809814,
      "learning_rate": 1.1295809682118075e-07,
      "loss": 2.99,
      "step": 68680
    },
    {
      "epoch": 2.9564431436687615,
      "grad_norm": 0.8500849008560181,
      "learning_rate": 1.1076092674306981e-07,
      "loss": 2.8659,
      "step": 68690
    },
    {
      "epoch": 2.9568735473874495,
      "grad_norm": 1.0017913579940796,
      "learning_rate": 1.0858532400424004e-07,
      "loss": 2.9398,
      "step": 68700
    },
    {
      "epoch": 2.9568735473874495,
      "eval_bleu": 27.177801888203422,
      "eval_gen_len": 27.482,
      "eval_loss": 2.785416841506958,
      "eval_runtime": 58.4498,
      "eval_samples_per_second": 17.109,
      "eval_steps_per_second": 1.078,
      "step": 68700
    },
    {
      "epoch": 2.9573039511061374,
      "grad_norm": 0.8519347310066223,
      "learning_rate": 1.0643128907443789e-07,
      "loss": 2.9633,
      "step": 68710
    },
    {
      "epoch": 2.957734354824826,
      "grad_norm": 1.014786720275879,
      "learning_rate": 1.0429882241875799e-07,
      "loss": 3.0096,
      "step": 68720
    },
    {
      "epoch": 2.958164758543514,
      "grad_norm": 0.8871422410011292,
      "learning_rate": 1.0218792449759873e-07,
      "loss": 3.0234,
      "step": 68730
    },
    {
      "epoch": 2.9585951622622018,
      "grad_norm": 0.9103121757507324,
      "learning_rate": 1.0009859576676216e-07,
      "loss": 2.9798,
      "step": 68740
    },
    {
      "epoch": 2.95902556598089,
      "grad_norm": 0.9068394899368286,
      "learning_rate": 9.803083667733192e-08,
      "loss": 2.9923,
      "step": 68750
    },
    {
      "epoch": 2.95902556598089,
      "eval_bleu": 27.148620184333385,
      "eval_gen_len": 27.49,
      "eval_loss": 2.785369634628296,
      "eval_runtime": 58.8125,
      "eval_samples_per_second": 17.003,
      "eval_steps_per_second": 1.071,
      "step": 68750
    },
    {
      "epoch": 2.959455969699578,
      "grad_norm": 0.8133450150489807,
      "learning_rate": 9.598464767578419e-08,
      "loss": 3.0022,
      "step": 68760
    },
    {
      "epoch": 2.959886373418266,
      "grad_norm": 0.9555309414863586,
      "learning_rate": 9.39600292038989e-08,
      "loss": 3.0721,
      "step": 68770
    },
    {
      "epoch": 2.9603167771369545,
      "grad_norm": 0.9203231930732727,
      "learning_rate": 9.195698169883748e-08,
      "loss": 2.9989,
      "step": 68780
    },
    {
      "epoch": 2.9607471808556425,
      "grad_norm": 0.8883039951324463,
      "learning_rate": 8.997550559306512e-08,
      "loss": 2.9619,
      "step": 68790
    },
    {
      "epoch": 2.9611775845743304,
      "grad_norm": 0.8925885558128357,
      "learning_rate": 8.801560131441733e-08,
      "loss": 2.886,
      "step": 68800
    },
    {
      "epoch": 2.9611775845743304,
      "eval_bleu": 27.104686187792886,
      "eval_gen_len": 27.508,
      "eval_loss": 2.7853684425354004,
      "eval_runtime": 58.9757,
      "eval_samples_per_second": 16.956,
      "eval_steps_per_second": 1.068,
      "step": 68800
    },
    {
      "epoch": 2.961607988293019,
      "grad_norm": 0.8590158224105835,
      "learning_rate": 8.607726928605565e-08,
      "loss": 3.0218,
      "step": 68810
    },
    {
      "epoch": 2.962038392011707,
      "grad_norm": 0.9528636336326599,
      "learning_rate": 8.416050992648972e-08,
      "loss": 3.0119,
      "step": 68820
    },
    {
      "epoch": 2.9624687957303952,
      "grad_norm": 0.8549340963363647,
      "learning_rate": 8.22653236495774e-08,
      "loss": 2.9918,
      "step": 68830
    },
    {
      "epoch": 2.962899199449083,
      "grad_norm": 0.8964371681213379,
      "learning_rate": 8.039171086451358e-08,
      "loss": 2.9904,
      "step": 68840
    },
    {
      "epoch": 2.9633296031677716,
      "grad_norm": 0.945991575717926,
      "learning_rate": 7.853967197583023e-08,
      "loss": 2.9471,
      "step": 68850
    },
    {
      "epoch": 2.9633296031677716,
      "eval_bleu": 27.30385757226876,
      "eval_gen_len": 27.505,
      "eval_loss": 2.7852795124053955,
      "eval_runtime": 59.1218,
      "eval_samples_per_second": 16.914,
      "eval_steps_per_second": 1.066,
      "step": 68850
    },
    {
      "epoch": 2.9637600068864596,
      "grad_norm": 0.9686122536659241,
      "learning_rate": 7.670920738340748e-08,
      "loss": 2.9841,
      "step": 68860
    },
    {
      "epoch": 2.9641904106051475,
      "grad_norm": 0.9042823314666748,
      "learning_rate": 7.490031748247362e-08,
      "loss": 2.9922,
      "step": 68870
    },
    {
      "epoch": 2.964620814323836,
      "grad_norm": 0.7964228391647339,
      "learning_rate": 7.31130026635718e-08,
      "loss": 2.9434,
      "step": 68880
    },
    {
      "epoch": 2.965051218042524,
      "grad_norm": 0.9289915561676025,
      "learning_rate": 7.134726331262665e-08,
      "loss": 2.9418,
      "step": 68890
    },
    {
      "epoch": 2.965481621761212,
      "grad_norm": 0.9671072959899902,
      "learning_rate": 6.960309981086654e-08,
      "loss": 2.9639,
      "step": 68900
    },
    {
      "epoch": 2.965481621761212,
      "eval_bleu": 27.210582527602334,
      "eval_gen_len": 27.468,
      "eval_loss": 2.785419225692749,
      "eval_runtime": 58.3086,
      "eval_samples_per_second": 17.15,
      "eval_steps_per_second": 1.08,
      "step": 68900
    },
    {
      "epoch": 2.9659120254799003,
      "grad_norm": 0.8872206211090088,
      "learning_rate": 6.788051253489026e-08,
      "loss": 2.9248,
      "step": 68910
    },
    {
      "epoch": 2.9663424291985883,
      "grad_norm": 0.9327418208122253,
      "learning_rate": 6.617950185661137e-08,
      "loss": 2.983,
      "step": 68920
    },
    {
      "epoch": 2.9667728329172762,
      "grad_norm": 0.8551971316337585,
      "learning_rate": 6.450006814332499e-08,
      "loss": 2.9676,
      "step": 68930
    },
    {
      "epoch": 2.9672032366359646,
      "grad_norm": 0.9683324694633484,
      "learning_rate": 6.284221175760773e-08,
      "loss": 3.013,
      "step": 68940
    },
    {
      "epoch": 2.9676336403546526,
      "grad_norm": 0.9062509536743164,
      "learning_rate": 6.120593305743993e-08,
      "loss": 3.008,
      "step": 68950
    },
    {
      "epoch": 2.9676336403546526,
      "eval_bleu": 27.144490663427845,
      "eval_gen_len": 27.48,
      "eval_loss": 2.7854185104370117,
      "eval_runtime": 58.7127,
      "eval_samples_per_second": 17.032,
      "eval_steps_per_second": 1.073,
      "step": 68950
    },
    {
      "epoch": 2.9680640440733406,
      "grad_norm": 0.9048259854316711,
      "learning_rate": 5.959123239610564e-08,
      "loss": 2.9746,
      "step": 68960
    },
    {
      "epoch": 2.968494447792029,
      "grad_norm": 0.8307747840881348,
      "learning_rate": 5.79981101222371e-08,
      "loss": 2.919,
      "step": 68970
    },
    {
      "epoch": 2.968924851510717,
      "grad_norm": 0.9913475513458252,
      "learning_rate": 5.642656657981471e-08,
      "loss": 2.9477,
      "step": 68980
    },
    {
      "epoch": 2.969355255229405,
      "grad_norm": 1.0254380702972412,
      "learning_rate": 5.487660210814483e-08,
      "loss": 2.9951,
      "step": 68990
    },
    {
      "epoch": 2.9697856589480933,
      "grad_norm": 0.9130259156227112,
      "learning_rate": 5.3348217041881976e-08,
      "loss": 2.9877,
      "step": 69000
    },
    {
      "epoch": 2.9697856589480933,
      "eval_bleu": 27.175810336264306,
      "eval_gen_len": 27.484,
      "eval_loss": 2.7853362560272217,
      "eval_runtime": 58.7041,
      "eval_samples_per_second": 17.035,
      "eval_steps_per_second": 1.073,
      "step": 69000
    },
    {
      "epoch": 2.9702160626667813,
      "grad_norm": 0.8355326652526855,
      "learning_rate": 5.184141171103996e-08,
      "loss": 2.9845,
      "step": 69010
    },
    {
      "epoch": 2.9706464663854697,
      "grad_norm": 1.01083505153656,
      "learning_rate": 5.0356186440947417e-08,
      "loss": 2.9957,
      "step": 69020
    },
    {
      "epoch": 2.9710768701041577,
      "grad_norm": 0.926109254360199,
      "learning_rate": 4.889254155228118e-08,
      "loss": 3.0717,
      "step": 69030
    },
    {
      "epoch": 2.971507273822846,
      "grad_norm": 0.9107818007469177,
      "learning_rate": 4.7450477361066225e-08,
      "loss": 2.8689,
      "step": 69040
    },
    {
      "epoch": 2.971937677541534,
      "grad_norm": 0.8757227659225464,
      "learning_rate": 4.60299941786646e-08,
      "loss": 2.9837,
      "step": 69050
    },
    {
      "epoch": 2.971937677541534,
      "eval_bleu": 26.984424379166093,
      "eval_gen_len": 27.504,
      "eval_loss": 2.7853810787200928,
      "eval_runtime": 59.1186,
      "eval_samples_per_second": 16.915,
      "eval_steps_per_second": 1.066,
      "step": 69050
    },
    {
      "epoch": 2.972368081260222,
      "grad_norm": 1.0395931005477905,
      "learning_rate": 4.463109231175322e-08,
      "loss": 3.0108,
      "step": 69060
    },
    {
      "epoch": 2.9727984849789104,
      "grad_norm": 0.9288104176521301,
      "learning_rate": 4.325377206240156e-08,
      "loss": 2.8699,
      "step": 69070
    },
    {
      "epoch": 2.9732288886975984,
      "grad_norm": 0.9912835359573364,
      "learning_rate": 4.1898033727982847e-08,
      "loss": 3.0228,
      "step": 69080
    },
    {
      "epoch": 2.9736592924162863,
      "grad_norm": 0.8364688158035278,
      "learning_rate": 4.056387760120739e-08,
      "loss": 2.909,
      "step": 69090
    },
    {
      "epoch": 2.9740896961349748,
      "grad_norm": 0.8505263924598694,
      "learning_rate": 3.925130397014476e-08,
      "loss": 2.9169,
      "step": 69100
    },
    {
      "epoch": 2.9740896961349748,
      "eval_bleu": 27.146488113253508,
      "eval_gen_len": 27.484,
      "eval_loss": 2.7851734161376953,
      "eval_runtime": 58.7832,
      "eval_samples_per_second": 17.012,
      "eval_steps_per_second": 1.072,
      "step": 69100
    },
    {
      "epoch": 2.9745200998536627,
      "grad_norm": 0.8842430114746094,
      "learning_rate": 3.796031311820158e-08,
      "loss": 3.0339,
      "step": 69110
    },
    {
      "epoch": 2.9749505035723507,
      "grad_norm": 0.951403021812439,
      "learning_rate": 3.6690905324099357e-08,
      "loss": 3.114,
      "step": 69120
    },
    {
      "epoch": 2.975380907291039,
      "grad_norm": 0.8508255481719971,
      "learning_rate": 3.544308086194104e-08,
      "loss": 2.9894,
      "step": 69130
    },
    {
      "epoch": 2.975811311009727,
      "grad_norm": 0.9818423986434937,
      "learning_rate": 3.4216840001133347e-08,
      "loss": 2.9994,
      "step": 69140
    },
    {
      "epoch": 2.976241714728415,
      "grad_norm": 0.9554807543754578,
      "learning_rate": 3.301218300644227e-08,
      "loss": 2.9729,
      "step": 69150
    },
    {
      "epoch": 2.976241714728415,
      "eval_bleu": 27.15952753078047,
      "eval_gen_len": 27.495,
      "eval_loss": 2.7853505611419678,
      "eval_runtime": 58.9256,
      "eval_samples_per_second": 16.971,
      "eval_steps_per_second": 1.069,
      "step": 69150
    },
    {
      "epoch": 2.9766721184471034,
      "grad_norm": 0.9342442154884338,
      "learning_rate": 3.182911013797085e-08,
      "loss": 2.9927,
      "step": 69160
    },
    {
      "epoch": 2.9771025221657914,
      "grad_norm": 0.979266345500946,
      "learning_rate": 3.066762165115922e-08,
      "loss": 2.9067,
      "step": 69170
    },
    {
      "epoch": 2.9775329258844794,
      "grad_norm": 0.8970203995704651,
      "learning_rate": 2.9527717796773434e-08,
      "loss": 2.8946,
      "step": 69180
    },
    {
      "epoch": 2.977963329603168,
      "grad_norm": 0.9003342390060425,
      "learning_rate": 2.840939882094995e-08,
      "loss": 2.9952,
      "step": 69190
    },
    {
      "epoch": 2.9783937333218558,
      "grad_norm": 0.8169690370559692,
      "learning_rate": 2.7312664965140068e-08,
      "loss": 2.8915,
      "step": 69200
    },
    {
      "epoch": 2.9783937333218558,
      "eval_bleu": 27.007209240810457,
      "eval_gen_len": 27.493,
      "eval_loss": 2.7853360176086426,
      "eval_runtime": 58.6249,
      "eval_samples_per_second": 17.058,
      "eval_steps_per_second": 1.075,
      "step": 69200
    },
    {
      "epoch": 2.978824137040544,
      "grad_norm": 1.0037943124771118,
      "learning_rate": 2.6237516466154356e-08,
      "loss": 3.0649,
      "step": 69210
    },
    {
      "epoch": 2.979254540759232,
      "grad_norm": 0.8548905253410339,
      "learning_rate": 2.5183953556107144e-08,
      "loss": 2.9789,
      "step": 69220
    },
    {
      "epoch": 2.9796849444779205,
      "grad_norm": 0.9670418500900269,
      "learning_rate": 2.415197646249423e-08,
      "loss": 2.9737,
      "step": 69230
    },
    {
      "epoch": 2.9801153481966085,
      "grad_norm": 0.9492300152778625,
      "learning_rate": 2.3141585408126275e-08,
      "loss": 2.9559,
      "step": 69240
    },
    {
      "epoch": 2.9805457519152965,
      "grad_norm": 0.9869318008422852,
      "learning_rate": 2.2152780611162104e-08,
      "loss": 2.9761,
      "step": 69250
    },
    {
      "epoch": 2.9805457519152965,
      "eval_bleu": 27.1768642759192,
      "eval_gen_len": 27.472,
      "eval_loss": 2.7853312492370605,
      "eval_runtime": 58.7047,
      "eval_samples_per_second": 17.034,
      "eval_steps_per_second": 1.073,
      "step": 69250
    },
    {
      "epoch": 2.980976155633985,
      "grad_norm": 0.89886075258255,
      "learning_rate": 2.1185562285097603e-08,
      "loss": 2.9022,
      "step": 69260
    },
    {
      "epoch": 2.981406559352673,
      "grad_norm": 0.919304370880127,
      "learning_rate": 2.0239930638765726e-08,
      "loss": 2.9627,
      "step": 69270
    },
    {
      "epoch": 2.981836963071361,
      "grad_norm": 0.9721605181694031,
      "learning_rate": 1.9315885876347585e-08,
      "loss": 3.0552,
      "step": 69280
    },
    {
      "epoch": 2.9822673667900492,
      "grad_norm": 0.9479386210441589,
      "learning_rate": 1.8413428197339157e-08,
      "loss": 2.9312,
      "step": 69290
    },
    {
      "epoch": 2.982697770508737,
      "grad_norm": 0.9393823742866516,
      "learning_rate": 1.7532557796595682e-08,
      "loss": 2.9329,
      "step": 69300
    },
    {
      "epoch": 2.982697770508737,
      "eval_bleu": 27.154901072736994,
      "eval_gen_len": 27.522,
      "eval_loss": 2.7853891849517822,
      "eval_runtime": 58.9976,
      "eval_samples_per_second": 16.95,
      "eval_steps_per_second": 1.068,
      "step": 69300
    },
    {
      "epoch": 2.983128174227425,
      "grad_norm": 1.0240614414215088,
      "learning_rate": 1.6673274864320577e-08,
      "loss": 3.024,
      "step": 69310
    },
    {
      "epoch": 2.9835585779461136,
      "grad_norm": 0.9970555901527405,
      "learning_rate": 1.5835579586043202e-08,
      "loss": 2.9889,
      "step": 69320
    },
    {
      "epoch": 2.9839889816648015,
      "grad_norm": 0.7999768257141113,
      "learning_rate": 1.5019472142618896e-08,
      "loss": 2.9478,
      "step": 69330
    },
    {
      "epoch": 2.9844193853834895,
      "grad_norm": 0.9815053343772888,
      "learning_rate": 1.4224952710262252e-08,
      "loss": 3.0843,
      "step": 69340
    },
    {
      "epoch": 2.984849789102178,
      "grad_norm": 0.9481858611106873,
      "learning_rate": 1.3452021460524933e-08,
      "loss": 2.9666,
      "step": 69350
    },
    {
      "epoch": 2.984849789102178,
      "eval_bleu": 27.178792428976674,
      "eval_gen_len": 27.484,
      "eval_loss": 2.7854347229003906,
      "eval_runtime": 58.8635,
      "eval_samples_per_second": 16.988,
      "eval_steps_per_second": 1.07,
      "step": 69350
    },
    {
      "epoch": 2.985280192820866,
      "grad_norm": 0.9066506624221802,
      "learning_rate": 1.2700678560284563e-08,
      "loss": 3.0174,
      "step": 69360
    },
    {
      "epoch": 2.985710596539554,
      "grad_norm": 0.8174251914024353,
      "learning_rate": 1.1970924171778031e-08,
      "loss": 3.001,
      "step": 69370
    },
    {
      "epoch": 2.9861410002582423,
      "grad_norm": 1.0022351741790771,
      "learning_rate": 1.1262758452545985e-08,
      "loss": 2.9722,
      "step": 69380
    },
    {
      "epoch": 2.98657140397693,
      "grad_norm": 0.9044751524925232,
      "learning_rate": 1.0576181555510546e-08,
      "loss": 2.9083,
      "step": 69390
    },
    {
      "epoch": 2.9870018076956186,
      "grad_norm": 0.9829921126365662,
      "learning_rate": 9.911193628908688e-09,
      "loss": 2.9675,
      "step": 69400
    },
    {
      "epoch": 2.9870018076956186,
      "eval_bleu": 27.256556881516705,
      "eval_gen_len": 27.5,
      "eval_loss": 2.7853288650512695,
      "eval_runtime": 58.7578,
      "eval_samples_per_second": 17.019,
      "eval_steps_per_second": 1.072,
      "step": 69400
    },
    {
      "epoch": 2.9874322114143066,
      "grad_norm": 0.8864853382110596,
      "learning_rate": 9.267794816314457e-09,
      "loss": 3.0832,
      "step": 69410
    },
    {
      "epoch": 2.987862615132995,
      "grad_norm": 0.900723397731781,
      "learning_rate": 8.645985256650057e-09,
      "loss": 2.9449,
      "step": 69420
    },
    {
      "epoch": 2.988293018851683,
      "grad_norm": 0.8893024325370789,
      "learning_rate": 8.045765084174762e-09,
      "loss": 2.9649,
      "step": 69430
    },
    {
      "epoch": 2.988723422570371,
      "grad_norm": 0.8855565190315247,
      "learning_rate": 7.467134428473798e-09,
      "loss": 2.9118,
      "step": 69440
    },
    {
      "epoch": 2.9891538262890593,
      "grad_norm": 0.891235888004303,
      "learning_rate": 6.910093414480567e-09,
      "loss": 2.9651,
      "step": 69450
    },
    {
      "epoch": 2.9891538262890593,
      "eval_bleu": 27.120917496592792,
      "eval_gen_len": 27.504,
      "eval_loss": 2.7853171825408936,
      "eval_runtime": 59.1805,
      "eval_samples_per_second": 16.897,
      "eval_steps_per_second": 1.065,
      "step": 69450
    },
    {
      "epoch": 2.9895842300077473,
      "grad_norm": 0.9309150576591492,
      "learning_rate": 6.374642162476629e-09,
      "loss": 2.9392,
      "step": 69460
    },
    {
      "epoch": 2.9900146337264353,
      "grad_norm": 0.8656713366508484,
      "learning_rate": 5.860780788069509e-09,
      "loss": 3.0707,
      "step": 69470
    },
    {
      "epoch": 2.9904450374451237,
      "grad_norm": 0.935034990310669,
      "learning_rate": 5.368509402203792e-09,
      "loss": 3.0599,
      "step": 69480
    },
    {
      "epoch": 2.9908754411638117,
      "grad_norm": 0.9753415584564209,
      "learning_rate": 4.8978281111722314e-09,
      "loss": 2.9708,
      "step": 69490
    },
    {
      "epoch": 2.9913058448824996,
      "grad_norm": 0.8981946110725403,
      "learning_rate": 4.448737016604643e-09,
      "loss": 2.9367,
      "step": 69500
    },
    {
      "epoch": 2.9913058448824996,
      "eval_bleu": 27.124372291350674,
      "eval_gen_len": 27.495,
      "eval_loss": 2.7851836681365967,
      "eval_runtime": 58.8154,
      "eval_samples_per_second": 17.002,
      "eval_steps_per_second": 1.071,
      "step": 69500
    },
    {
      "epoch": 2.991736248601188,
      "grad_norm": 0.8853452801704407,
      "learning_rate": 4.021236215456803e-09,
      "loss": 2.8534,
      "step": 69510
    },
    {
      "epoch": 2.992166652319876,
      "grad_norm": 0.8593286275863647,
      "learning_rate": 3.615325800032654e-09,
      "loss": 2.93,
      "step": 69520
    },
    {
      "epoch": 2.992597056038564,
      "grad_norm": 0.8232768774032593,
      "learning_rate": 3.2310058579732017e-09,
      "loss": 2.9686,
      "step": 69530
    },
    {
      "epoch": 2.9930274597572524,
      "grad_norm": 0.8842641711235046,
      "learning_rate": 2.868276472267617e-09,
      "loss": 3.0828,
      "step": 69540
    },
    {
      "epoch": 2.9934578634759403,
      "grad_norm": 0.9669875502586365,
      "learning_rate": 2.52713772121993e-09,
      "loss": 3.0139,
      "step": 69550
    },
    {
      "epoch": 2.9934578634759403,
      "eval_bleu": 27.295839929940527,
      "eval_gen_len": 27.508,
      "eval_loss": 2.785259962081909,
      "eval_runtime": 59.1435,
      "eval_samples_per_second": 16.908,
      "eval_steps_per_second": 1.065,
      "step": 69550
    },
    {
      "epoch": 2.9938882671946283,
      "grad_norm": 1.0175034999847412,
      "learning_rate": 2.2075896784934382e-09,
      "loss": 2.9264,
      "step": 69560
    },
    {
      "epoch": 2.9943186709133167,
      "grad_norm": 0.9382572770118713,
      "learning_rate": 1.9096324130774e-09,
      "loss": 2.9921,
      "step": 69570
    },
    {
      "epoch": 2.9947490746320047,
      "grad_norm": 0.8180544972419739,
      "learning_rate": 1.6332659893092405e-09,
      "loss": 3.0573,
      "step": 69580
    },
    {
      "epoch": 2.995179478350693,
      "grad_norm": 0.9146080017089844,
      "learning_rate": 1.3784904668634468e-09,
      "loss": 2.9693,
      "step": 69590
    },
    {
      "epoch": 2.995609882069381,
      "grad_norm": 0.9569810628890991,
      "learning_rate": 1.1453059007515699e-09,
      "loss": 3.0006,
      "step": 69600
    },
    {
      "epoch": 2.995609882069381,
      "eval_bleu": 27.059563788337424,
      "eval_gen_len": 27.485,
      "eval_loss": 2.7855281829833984,
      "eval_runtime": 59.0118,
      "eval_samples_per_second": 16.946,
      "eval_steps_per_second": 1.068,
      "step": 69600
    },
    {
      "epoch": 2.9960402857880695,
      "grad_norm": 0.8768898248672485,
      "learning_rate": 9.337123413111216e-10,
      "loss": 3.0573,
      "step": 69610
    },
    {
      "epoch": 2.9964706895067574,
      "grad_norm": 1.0516611337661743,
      "learning_rate": 7.437098342277793e-10,
      "loss": 3.0194,
      "step": 69620
    },
    {
      "epoch": 2.9969010932254454,
      "grad_norm": 1.0667325258255005,
      "learning_rate": 5.75298420524284e-10,
      "loss": 2.9534,
      "step": 69630
    },
    {
      "epoch": 2.997331496944134,
      "grad_norm": 0.7747732400894165,
      "learning_rate": 4.284781365715418e-10,
      "loss": 3.0081,
      "step": 69640
    },
    {
      "epoch": 2.9977619006628218,
      "grad_norm": 0.9566056132316589,
      "learning_rate": 3.0324901406642015e-10,
      "loss": 3.0296,
      "step": 69650
    },
    {
      "epoch": 2.9977619006628218,
      "eval_bleu": 27.188223840441143,
      "eval_gen_len": 27.515,
      "eval_loss": 2.785330057144165,
      "eval_runtime": 59.1953,
      "eval_samples_per_second": 16.893,
      "eval_steps_per_second": 1.064,
      "step": 69650
    },
    {
      "epoch": 2.9981923043815097,
      "grad_norm": 0.8972005844116211,
      "learning_rate": 1.996110800539519e-10,
      "loss": 2.9536,
      "step": 69660
    },
    {
      "epoch": 2.998622708100198,
      "grad_norm": 0.8935365080833435,
      "learning_rate": 1.1756435689402879e-10,
      "loss": 3.0474,
      "step": 69670
    },
    {
      "epoch": 2.999053111818886,
      "grad_norm": 0.9367725849151611,
      "learning_rate": 5.710886231691248e-11,
      "loss": 2.999,
      "step": 69680
    },
    {
      "epoch": 2.999483515537574,
      "grad_norm": 0.9033075571060181,
      "learning_rate": 1.8244609367723543e-11,
      "loss": 2.9649,
      "step": 69690
    },
    {
      "epoch": 2.9999139192562625,
      "grad_norm": 1.014859914779663,
      "learning_rate": 9.716064397480296e-13,
      "loss": 2.952,
      "step": 69700
    },
    {
      "epoch": 2.9999139192562625,
      "eval_bleu": 27.149441523832834,
      "eval_gen_len": 27.51,
      "eval_loss": 2.78530216217041,
      "eval_runtime": 58.8023,
      "eval_samples_per_second": 17.006,
      "eval_steps_per_second": 1.071,
      "step": 69700
    },
    {
      "epoch": 3.0,
      "step": 69702,
      "total_flos": 7.231007562094019e+17,
      "train_loss": 3.0444417680025766,
      "train_runtime": 128430.1084,
      "train_samples_per_second": 34.734,
      "train_steps_per_second": 0.543
    }
  ],
  "logging_steps": 10,
  "max_steps": 69702,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.231007562094019e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
