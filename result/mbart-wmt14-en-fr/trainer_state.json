{
  "best_global_step": 11550,
  "best_metric": 35.810321176925605,
  "best_model_checkpoint": "../root/autodl-fs/outputs/mbart-wmt14-en-fr/checkpoint-4000",
  "epoch": 3.0,
  "eval_steps": 50,
  "global_step": 18750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016,
      "grad_norm": 1.802713394165039,
      "learning_rate": 3.197158081705151e-06,
      "loss": 2.6474,
      "step": 10
    },
    {
      "epoch": 0.0032,
      "grad_norm": 1.667413592338562,
      "learning_rate": 6.74955595026643e-06,
      "loss": 2.6574,
      "step": 20
    },
    {
      "epoch": 0.0048,
      "grad_norm": 1.6929062604904175,
      "learning_rate": 1.030195381882771e-05,
      "loss": 2.6605,
      "step": 30
    },
    {
      "epoch": 0.0064,
      "grad_norm": 1.6385143995285034,
      "learning_rate": 1.3854351687388988e-05,
      "loss": 2.6125,
      "step": 40
    },
    {
      "epoch": 0.008,
      "grad_norm": 1.2007200717926025,
      "learning_rate": 1.7406749555950266e-05,
      "loss": 2.6064,
      "step": 50
    },
    {
      "epoch": 0.008,
      "eval_bleu": 17.658426483917832,
      "eval_gen_len": 29.376,
      "eval_loss": 2.717991828918457,
      "eval_runtime": 65.6267,
      "eval_samples_per_second": 15.238,
      "eval_steps_per_second": 0.96,
      "step": 50
    },
    {
      "epoch": 0.0096,
      "grad_norm": 0.784948468208313,
      "learning_rate": 2.0959147424511547e-05,
      "loss": 2.6168,
      "step": 60
    },
    {
      "epoch": 0.0112,
      "grad_norm": 0.669950008392334,
      "learning_rate": 2.4511545293072824e-05,
      "loss": 2.5936,
      "step": 70
    },
    {
      "epoch": 0.0128,
      "grad_norm": 0.6305859088897705,
      "learning_rate": 2.8063943161634105e-05,
      "loss": 2.5585,
      "step": 80
    },
    {
      "epoch": 0.0144,
      "grad_norm": 0.6167147755622864,
      "learning_rate": 3.1616341030195386e-05,
      "loss": 2.5627,
      "step": 90
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.64000403881073,
      "learning_rate": 3.516873889875667e-05,
      "loss": 2.5488,
      "step": 100
    },
    {
      "epoch": 0.016,
      "eval_bleu": 35.24472036358543,
      "eval_gen_len": 31.633,
      "eval_loss": 2.6303513050079346,
      "eval_runtime": 62.8124,
      "eval_samples_per_second": 15.92,
      "eval_steps_per_second": 1.003,
      "step": 100
    },
    {
      "epoch": 0.0176,
      "grad_norm": 0.5878324508666992,
      "learning_rate": 3.872113676731794e-05,
      "loss": 2.5304,
      "step": 110
    },
    {
      "epoch": 0.0192,
      "grad_norm": 0.5900993347167969,
      "learning_rate": 4.227353463587922e-05,
      "loss": 2.5773,
      "step": 120
    },
    {
      "epoch": 0.0208,
      "grad_norm": 0.6193339824676514,
      "learning_rate": 4.58259325044405e-05,
      "loss": 2.5476,
      "step": 130
    },
    {
      "epoch": 0.0224,
      "grad_norm": 0.6565779447555542,
      "learning_rate": 4.9378330373001777e-05,
      "loss": 2.5385,
      "step": 140
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.5916334986686707,
      "learning_rate": 5.293072824156306e-05,
      "loss": 2.5454,
      "step": 150
    },
    {
      "epoch": 0.024,
      "eval_bleu": 34.99990561859038,
      "eval_gen_len": 31.623,
      "eval_loss": 2.6270394325256348,
      "eval_runtime": 62.9981,
      "eval_samples_per_second": 15.874,
      "eval_steps_per_second": 1.0,
      "step": 150
    },
    {
      "epoch": 0.0256,
      "grad_norm": 0.592271625995636,
      "learning_rate": 5.648312611012434e-05,
      "loss": 2.5032,
      "step": 160
    },
    {
      "epoch": 0.0272,
      "grad_norm": 0.5818440914154053,
      "learning_rate": 6.003552397868561e-05,
      "loss": 2.5278,
      "step": 170
    },
    {
      "epoch": 0.0288,
      "grad_norm": 0.5796532034873962,
      "learning_rate": 6.358792184724689e-05,
      "loss": 2.5387,
      "step": 180
    },
    {
      "epoch": 0.0304,
      "grad_norm": 0.616319477558136,
      "learning_rate": 6.714031971580817e-05,
      "loss": 2.5288,
      "step": 190
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.6376436948776245,
      "learning_rate": 7.069271758436945e-05,
      "loss": 2.5226,
      "step": 200
    },
    {
      "epoch": 0.032,
      "eval_bleu": 35.228422605768976,
      "eval_gen_len": 31.688,
      "eval_loss": 2.622711658477783,
      "eval_runtime": 63.1494,
      "eval_samples_per_second": 15.835,
      "eval_steps_per_second": 0.998,
      "step": 200
    },
    {
      "epoch": 0.0336,
      "grad_norm": 0.6725986003875732,
      "learning_rate": 7.424511545293074e-05,
      "loss": 2.5304,
      "step": 210
    },
    {
      "epoch": 0.0352,
      "grad_norm": 0.607879102230072,
      "learning_rate": 7.779751332149202e-05,
      "loss": 2.5388,
      "step": 220
    },
    {
      "epoch": 0.0368,
      "grad_norm": 0.5841575860977173,
      "learning_rate": 8.134991119005328e-05,
      "loss": 2.516,
      "step": 230
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.6156225800514221,
      "learning_rate": 8.490230905861456e-05,
      "loss": 2.5375,
      "step": 240
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5878845453262329,
      "learning_rate": 8.845470692717585e-05,
      "loss": 2.5038,
      "step": 250
    },
    {
      "epoch": 0.04,
      "eval_bleu": 35.223608992083605,
      "eval_gen_len": 31.652,
      "eval_loss": 2.6229891777038574,
      "eval_runtime": 62.4742,
      "eval_samples_per_second": 16.007,
      "eval_steps_per_second": 1.008,
      "step": 250
    },
    {
      "epoch": 0.0416,
      "grad_norm": 0.5862129330635071,
      "learning_rate": 9.200710479573713e-05,
      "loss": 2.4976,
      "step": 260
    },
    {
      "epoch": 0.0432,
      "grad_norm": 0.6076602339744568,
      "learning_rate": 9.555950266429841e-05,
      "loss": 2.5396,
      "step": 270
    },
    {
      "epoch": 0.0448,
      "grad_norm": 0.631551206111908,
      "learning_rate": 9.911190053285967e-05,
      "loss": 2.5442,
      "step": 280
    },
    {
      "epoch": 0.0464,
      "grad_norm": 0.6507546901702881,
      "learning_rate": 0.00010266429840142096,
      "loss": 2.5325,
      "step": 290
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.5714645385742188,
      "learning_rate": 0.00010621669626998225,
      "loss": 2.5148,
      "step": 300
    },
    {
      "epoch": 0.048,
      "eval_bleu": 35.38792140325679,
      "eval_gen_len": 31.713,
      "eval_loss": 2.6215877532958984,
      "eval_runtime": 63.1287,
      "eval_samples_per_second": 15.841,
      "eval_steps_per_second": 0.998,
      "step": 300
    },
    {
      "epoch": 0.0496,
      "grad_norm": 0.5629217624664307,
      "learning_rate": 0.00010976909413854353,
      "loss": 2.4999,
      "step": 310
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.593198299407959,
      "learning_rate": 0.0001133214920071048,
      "loss": 2.5348,
      "step": 320
    },
    {
      "epoch": 0.0528,
      "grad_norm": 0.6079200506210327,
      "learning_rate": 0.00011687388987566608,
      "loss": 2.5303,
      "step": 330
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.5753571391105652,
      "learning_rate": 0.00012042628774422735,
      "loss": 2.5176,
      "step": 340
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.6399985551834106,
      "learning_rate": 0.00012397868561278864,
      "loss": 2.5056,
      "step": 350
    },
    {
      "epoch": 0.056,
      "eval_bleu": 35.05549427989245,
      "eval_gen_len": 31.778,
      "eval_loss": 2.6270463466644287,
      "eval_runtime": 64.0894,
      "eval_samples_per_second": 15.603,
      "eval_steps_per_second": 0.983,
      "step": 350
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.5788777470588684,
      "learning_rate": 0.00012753108348134993,
      "loss": 2.5212,
      "step": 360
    },
    {
      "epoch": 0.0592,
      "grad_norm": 0.6189374327659607,
      "learning_rate": 0.0001310834813499112,
      "loss": 2.499,
      "step": 370
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.6070706844329834,
      "learning_rate": 0.00013463587921847247,
      "loss": 2.4979,
      "step": 380
    },
    {
      "epoch": 0.0624,
      "grad_norm": 0.6043503284454346,
      "learning_rate": 0.00013818827708703374,
      "loss": 2.5153,
      "step": 390
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.599821150302887,
      "learning_rate": 0.00014174067495559503,
      "loss": 2.5118,
      "step": 400
    },
    {
      "epoch": 0.064,
      "eval_bleu": 35.01883309035918,
      "eval_gen_len": 31.703,
      "eval_loss": 2.6232166290283203,
      "eval_runtime": 62.789,
      "eval_samples_per_second": 15.926,
      "eval_steps_per_second": 1.003,
      "step": 400
    },
    {
      "epoch": 0.0656,
      "grad_norm": 0.5918038487434387,
      "learning_rate": 0.00014529307282415633,
      "loss": 2.5061,
      "step": 410
    },
    {
      "epoch": 0.0672,
      "grad_norm": 0.5855076909065247,
      "learning_rate": 0.0001488454706927176,
      "loss": 2.5427,
      "step": 420
    },
    {
      "epoch": 0.0688,
      "grad_norm": 0.597314178943634,
      "learning_rate": 0.00015239786856127886,
      "loss": 2.4916,
      "step": 430
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.5917900800704956,
      "learning_rate": 0.00015595026642984015,
      "loss": 2.5104,
      "step": 440
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.6807295083999634,
      "learning_rate": 0.00015950266429840145,
      "loss": 2.5009,
      "step": 450
    },
    {
      "epoch": 0.072,
      "eval_bleu": 35.10845842476276,
      "eval_gen_len": 31.791,
      "eval_loss": 2.623060941696167,
      "eval_runtime": 62.8511,
      "eval_samples_per_second": 15.911,
      "eval_steps_per_second": 1.002,
      "step": 450
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.5976626873016357,
      "learning_rate": 0.00016305506216696272,
      "loss": 2.5482,
      "step": 460
    },
    {
      "epoch": 0.0752,
      "grad_norm": 0.6195077896118164,
      "learning_rate": 0.00016660746003552398,
      "loss": 2.4888,
      "step": 470
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.5984970331192017,
      "learning_rate": 0.00017015985790408525,
      "loss": 2.5133,
      "step": 480
    },
    {
      "epoch": 0.0784,
      "grad_norm": 0.614220917224884,
      "learning_rate": 0.00017371225577264654,
      "loss": 2.4924,
      "step": 490
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.646163284778595,
      "learning_rate": 0.00017726465364120784,
      "loss": 2.5087,
      "step": 500
    },
    {
      "epoch": 0.08,
      "eval_bleu": 34.98821563067005,
      "eval_gen_len": 31.701,
      "eval_loss": 2.6257851123809814,
      "eval_runtime": 63.5215,
      "eval_samples_per_second": 15.743,
      "eval_steps_per_second": 0.992,
      "step": 500
    },
    {
      "epoch": 0.0816,
      "grad_norm": 0.6196068525314331,
      "learning_rate": 0.0001808170515097691,
      "loss": 2.4815,
      "step": 510
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.611778974533081,
      "learning_rate": 0.00018436944937833037,
      "loss": 2.5436,
      "step": 520
    },
    {
      "epoch": 0.0848,
      "grad_norm": 0.5695515871047974,
      "learning_rate": 0.00018792184724689167,
      "loss": 2.5018,
      "step": 530
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.6559233069419861,
      "learning_rate": 0.00019147424511545294,
      "loss": 2.4985,
      "step": 540
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.6149383187294006,
      "learning_rate": 0.00019502664298401423,
      "loss": 2.4796,
      "step": 550
    },
    {
      "epoch": 0.088,
      "eval_bleu": 35.35399352341292,
      "eval_gen_len": 31.738,
      "eval_loss": 2.6335089206695557,
      "eval_runtime": 63.6966,
      "eval_samples_per_second": 15.699,
      "eval_steps_per_second": 0.989,
      "step": 550
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.6143848896026611,
      "learning_rate": 0.0001985790408525755,
      "loss": 2.4995,
      "step": 560
    },
    {
      "epoch": 0.0912,
      "grad_norm": 0.6171473264694214,
      "learning_rate": 0.00019999994629062756,
      "loss": 2.4974,
      "step": 570
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.5675005912780762,
      "learning_rate": 0.00019999961806689375,
      "loss": 2.4968,
      "step": 580
    },
    {
      "epoch": 0.0944,
      "grad_norm": 0.5714704394340515,
      "learning_rate": 0.00019999899145894457,
      "loss": 2.5104,
      "step": 590
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.5831843018531799,
      "learning_rate": 0.0001999980664686497,
      "loss": 2.4984,
      "step": 600
    },
    {
      "epoch": 0.096,
      "eval_bleu": 34.785600428871234,
      "eval_gen_len": 31.842,
      "eval_loss": 2.634241819381714,
      "eval_runtime": 63.5187,
      "eval_samples_per_second": 15.743,
      "eval_steps_per_second": 0.992,
      "step": 600
    },
    {
      "epoch": 0.0976,
      "grad_norm": 0.5672258138656616,
      "learning_rate": 0.00019999684309876924,
      "loss": 2.4685,
      "step": 610
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.6198582053184509,
      "learning_rate": 0.00019999532135295346,
      "loss": 2.5041,
      "step": 620
    },
    {
      "epoch": 0.1008,
      "grad_norm": 0.6096998453140259,
      "learning_rate": 0.0001999935012357431,
      "loss": 2.4976,
      "step": 630
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.5738027691841125,
      "learning_rate": 0.0001999913827525691,
      "loss": 2.5211,
      "step": 640
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.5587992072105408,
      "learning_rate": 0.00019998896590975266,
      "loss": 2.4894,
      "step": 650
    },
    {
      "epoch": 0.104,
      "eval_bleu": 34.870176546581725,
      "eval_gen_len": 31.76,
      "eval_loss": 2.636903762817383,
      "eval_runtime": 64.4141,
      "eval_samples_per_second": 15.525,
      "eval_steps_per_second": 0.978,
      "step": 650
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.5435234904289246,
      "learning_rate": 0.00019998625071450534,
      "loss": 2.467,
      "step": 660
    },
    {
      "epoch": 0.1072,
      "grad_norm": 0.5928957462310791,
      "learning_rate": 0.00019998323717492888,
      "loss": 2.4996,
      "step": 670
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.6370557546615601,
      "learning_rate": 0.00019997992530001524,
      "loss": 2.5216,
      "step": 680
    },
    {
      "epoch": 0.1104,
      "grad_norm": 0.5526365637779236,
      "learning_rate": 0.00019997631509964653,
      "loss": 2.4925,
      "step": 690
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.5874493718147278,
      "learning_rate": 0.0001999724065845951,
      "loss": 2.4987,
      "step": 700
    },
    {
      "epoch": 0.112,
      "eval_bleu": 34.64104527515829,
      "eval_gen_len": 31.967,
      "eval_loss": 2.636777877807617,
      "eval_runtime": 63.568,
      "eval_samples_per_second": 15.731,
      "eval_steps_per_second": 0.991,
      "step": 700
    },
    {
      "epoch": 0.1136,
      "grad_norm": 0.5809643864631653,
      "learning_rate": 0.00019996819976652336,
      "loss": 2.4918,
      "step": 710
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.5541697144508362,
      "learning_rate": 0.00019996369465798385,
      "loss": 2.4826,
      "step": 720
    },
    {
      "epoch": 0.1168,
      "grad_norm": 0.5577479004859924,
      "learning_rate": 0.00019995889127241915,
      "loss": 2.486,
      "step": 730
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.5801941156387329,
      "learning_rate": 0.0001999537896241619,
      "loss": 2.4883,
      "step": 740
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6088249683380127,
      "learning_rate": 0.00019994838972843461,
      "loss": 2.4832,
      "step": 750
    },
    {
      "epoch": 0.12,
      "eval_bleu": 34.71147965397308,
      "eval_gen_len": 31.659,
      "eval_loss": 2.637367010116577,
      "eval_runtime": 63.8541,
      "eval_samples_per_second": 15.661,
      "eval_steps_per_second": 0.987,
      "step": 750
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.5771800875663757,
      "learning_rate": 0.00019994269160134983,
      "loss": 2.5067,
      "step": 760
    },
    {
      "epoch": 0.1232,
      "grad_norm": 0.6054496169090271,
      "learning_rate": 0.0001999366952599099,
      "loss": 2.4881,
      "step": 770
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.5477044582366943,
      "learning_rate": 0.00019993040072200703,
      "loss": 2.4891,
      "step": 780
    },
    {
      "epoch": 0.1264,
      "grad_norm": 0.5959101915359497,
      "learning_rate": 0.00019992380800642318,
      "loss": 2.5099,
      "step": 790
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.5791676640510559,
      "learning_rate": 0.00019991691713283012,
      "loss": 2.4756,
      "step": 800
    },
    {
      "epoch": 0.128,
      "eval_bleu": 34.96436926114758,
      "eval_gen_len": 31.761,
      "eval_loss": 2.637347459793091,
      "eval_runtime": 64.6273,
      "eval_samples_per_second": 15.473,
      "eval_steps_per_second": 0.975,
      "step": 800
    },
    {
      "epoch": 0.1296,
      "grad_norm": 0.6059083938598633,
      "learning_rate": 0.00019990972812178914,
      "loss": 2.4715,
      "step": 810
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.5966028571128845,
      "learning_rate": 0.0001999022409947512,
      "loss": 2.4881,
      "step": 820
    },
    {
      "epoch": 0.1328,
      "grad_norm": 0.5956115126609802,
      "learning_rate": 0.00019989445577405686,
      "loss": 2.5126,
      "step": 830
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.5540766716003418,
      "learning_rate": 0.000199886372482936,
      "loss": 2.4662,
      "step": 840
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.554657518863678,
      "learning_rate": 0.00019987799114550798,
      "loss": 2.4603,
      "step": 850
    },
    {
      "epoch": 0.136,
      "eval_bleu": 34.983888562957006,
      "eval_gen_len": 31.747,
      "eval_loss": 2.6369309425354004,
      "eval_runtime": 62.9914,
      "eval_samples_per_second": 15.875,
      "eval_steps_per_second": 1.0,
      "step": 850
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.5524597764015198,
      "learning_rate": 0.0001998693117867815,
      "loss": 2.4858,
      "step": 860
    },
    {
      "epoch": 0.1392,
      "grad_norm": 0.5690308213233948,
      "learning_rate": 0.00019986033443265456,
      "loss": 2.483,
      "step": 870
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.4909220337867737,
      "learning_rate": 0.00019985105910991417,
      "loss": 2.451,
      "step": 880
    },
    {
      "epoch": 0.1424,
      "grad_norm": 0.5867102742195129,
      "learning_rate": 0.00019984148584623656,
      "loss": 2.4652,
      "step": 890
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.5553873777389526,
      "learning_rate": 0.00019983161467018701,
      "loss": 2.4772,
      "step": 900
    },
    {
      "epoch": 0.144,
      "eval_bleu": 34.712152897593214,
      "eval_gen_len": 31.955,
      "eval_loss": 2.6371586322784424,
      "eval_runtime": 62.8919,
      "eval_samples_per_second": 15.9,
      "eval_steps_per_second": 1.002,
      "step": 900
    },
    {
      "epoch": 0.1456,
      "grad_norm": 0.6131640076637268,
      "learning_rate": 0.0001998214456112196,
      "loss": 2.5089,
      "step": 910
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.5940343737602234,
      "learning_rate": 0.00019981097869967732,
      "loss": 2.4828,
      "step": 920
    },
    {
      "epoch": 0.1488,
      "grad_norm": 0.5574350953102112,
      "learning_rate": 0.0001998002139667919,
      "loss": 2.4786,
      "step": 930
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.5816562175750732,
      "learning_rate": 0.00019978915144468375,
      "loss": 2.4814,
      "step": 940
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.5369828343391418,
      "learning_rate": 0.0001997777911663618,
      "loss": 2.4997,
      "step": 950
    },
    {
      "epoch": 0.152,
      "eval_bleu": 34.46703487391993,
      "eval_gen_len": 31.925,
      "eval_loss": 2.63625168800354,
      "eval_runtime": 64.7924,
      "eval_samples_per_second": 15.434,
      "eval_steps_per_second": 0.972,
      "step": 950
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.6418201327323914,
      "learning_rate": 0.00019976613316572347,
      "loss": 2.4842,
      "step": 960
    },
    {
      "epoch": 0.1552,
      "grad_norm": 0.5482535362243652,
      "learning_rate": 0.00019975417747755453,
      "loss": 2.4957,
      "step": 970
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.6001078486442566,
      "learning_rate": 0.00019974192413752895,
      "loss": 2.4724,
      "step": 980
    },
    {
      "epoch": 0.1584,
      "grad_norm": 0.5617762207984924,
      "learning_rate": 0.00019972937318220896,
      "loss": 2.5091,
      "step": 990
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5827028155326843,
      "learning_rate": 0.00019971652464904476,
      "loss": 2.5024,
      "step": 1000
    },
    {
      "epoch": 0.16,
      "eval_bleu": 34.841307506926185,
      "eval_gen_len": 31.725,
      "eval_loss": 2.63472056388855,
      "eval_runtime": 63.3667,
      "eval_samples_per_second": 15.781,
      "eval_steps_per_second": 0.994,
      "step": 1000
    },
    {
      "epoch": 0.1616,
      "grad_norm": 0.5534873008728027,
      "learning_rate": 0.00019970337857637448,
      "loss": 2.4557,
      "step": 1010
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.6290519833564758,
      "learning_rate": 0.00019968993500342407,
      "loss": 2.5118,
      "step": 1020
    },
    {
      "epoch": 0.1648,
      "grad_norm": 0.5847122669219971,
      "learning_rate": 0.00019967619397030721,
      "loss": 2.5077,
      "step": 1030
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.5788456201553345,
      "learning_rate": 0.00019966215551802513,
      "loss": 2.458,
      "step": 1040
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.5814392566680908,
      "learning_rate": 0.0001996478196884665,
      "loss": 2.4615,
      "step": 1050
    },
    {
      "epoch": 0.168,
      "eval_bleu": 34.948080952512434,
      "eval_gen_len": 31.816,
      "eval_loss": 2.637514114379883,
      "eval_runtime": 62.2152,
      "eval_samples_per_second": 16.073,
      "eval_steps_per_second": 1.013,
      "step": 1050
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.5884240865707397,
      "learning_rate": 0.0001996331865244073,
      "loss": 2.4985,
      "step": 1060
    },
    {
      "epoch": 0.1712,
      "grad_norm": 0.5795058608055115,
      "learning_rate": 0.0001996182560695108,
      "loss": 2.4832,
      "step": 1070
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.5717353224754333,
      "learning_rate": 0.00019960302836832727,
      "loss": 2.4842,
      "step": 1080
    },
    {
      "epoch": 0.1744,
      "grad_norm": 0.5666792988777161,
      "learning_rate": 0.00019958750346629395,
      "loss": 2.4713,
      "step": 1090
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.5668736696243286,
      "learning_rate": 0.00019957168140973485,
      "loss": 2.4887,
      "step": 1100
    },
    {
      "epoch": 0.176,
      "eval_bleu": 34.750140924196145,
      "eval_gen_len": 31.682,
      "eval_loss": 2.6371588706970215,
      "eval_runtime": 62.4714,
      "eval_samples_per_second": 16.007,
      "eval_steps_per_second": 1.008,
      "step": 1100
    },
    {
      "epoch": 0.1776,
      "grad_norm": 0.578623354434967,
      "learning_rate": 0.00019955556224586073,
      "loss": 2.4634,
      "step": 1110
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.595986545085907,
      "learning_rate": 0.00019953914602276876,
      "loss": 2.5042,
      "step": 1120
    },
    {
      "epoch": 0.1808,
      "grad_norm": 0.5751603841781616,
      "learning_rate": 0.00019952243278944254,
      "loss": 2.4633,
      "step": 1130
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.5842922925949097,
      "learning_rate": 0.00019950542259575195,
      "loss": 2.4995,
      "step": 1140
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.5413796901702881,
      "learning_rate": 0.00019948811549245287,
      "loss": 2.4713,
      "step": 1150
    },
    {
      "epoch": 0.184,
      "eval_bleu": 34.94789582254062,
      "eval_gen_len": 31.883,
      "eval_loss": 2.632688283920288,
      "eval_runtime": 62.6768,
      "eval_samples_per_second": 15.955,
      "eval_steps_per_second": 1.005,
      "step": 1150
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.5817492008209229,
      "learning_rate": 0.00019947051153118724,
      "loss": 2.4671,
      "step": 1160
    },
    {
      "epoch": 0.1872,
      "grad_norm": 0.6561734676361084,
      "learning_rate": 0.0001994526107644826,
      "loss": 2.4732,
      "step": 1170
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.6000074148178101,
      "learning_rate": 0.00019943441324575228,
      "loss": 2.4911,
      "step": 1180
    },
    {
      "epoch": 0.1904,
      "grad_norm": 0.571090042591095,
      "learning_rate": 0.000199415919029295,
      "loss": 2.4879,
      "step": 1190
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.587221086025238,
      "learning_rate": 0.0001993971281702948,
      "loss": 2.5092,
      "step": 1200
    },
    {
      "epoch": 0.192,
      "eval_bleu": 34.694240933985135,
      "eval_gen_len": 31.783,
      "eval_loss": 2.637179374694824,
      "eval_runtime": 63.1776,
      "eval_samples_per_second": 15.828,
      "eval_steps_per_second": 0.997,
      "step": 1200
    },
    {
      "epoch": 0.1936,
      "grad_norm": 0.560499906539917,
      "learning_rate": 0.00019937804072482081,
      "loss": 2.4854,
      "step": 1210
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.6011127829551697,
      "learning_rate": 0.00019935865674982722,
      "loss": 2.4765,
      "step": 1220
    },
    {
      "epoch": 0.1968,
      "grad_norm": 0.5541332960128784,
      "learning_rate": 0.00019933897630315298,
      "loss": 2.495,
      "step": 1230
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.5342535972595215,
      "learning_rate": 0.00019931899944352163,
      "loss": 2.4695,
      "step": 1240
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5569395422935486,
      "learning_rate": 0.0001992987262305412,
      "loss": 2.4908,
      "step": 1250
    },
    {
      "epoch": 0.2,
      "eval_bleu": 34.82343562085743,
      "eval_gen_len": 31.888,
      "eval_loss": 2.6341235637664795,
      "eval_runtime": 62.3747,
      "eval_samples_per_second": 16.032,
      "eval_steps_per_second": 1.01,
      "step": 1250
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.5639801621437073,
      "learning_rate": 0.00019927815672470396,
      "loss": 2.4675,
      "step": 1260
    },
    {
      "epoch": 0.2032,
      "grad_norm": 0.5266862511634827,
      "learning_rate": 0.00019925729098738633,
      "loss": 2.4679,
      "step": 1270
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.5594245791435242,
      "learning_rate": 0.00019923612908084865,
      "loss": 2.4923,
      "step": 1280
    },
    {
      "epoch": 0.2064,
      "grad_norm": 0.5884586572647095,
      "learning_rate": 0.00019921467106823494,
      "loss": 2.5035,
      "step": 1290
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.5744320750236511,
      "learning_rate": 0.0001991929170135727,
      "loss": 2.4732,
      "step": 1300
    },
    {
      "epoch": 0.208,
      "eval_bleu": 35.014532286627144,
      "eval_gen_len": 31.801,
      "eval_loss": 2.634890079498291,
      "eval_runtime": 64.1266,
      "eval_samples_per_second": 15.594,
      "eval_steps_per_second": 0.982,
      "step": 1300
    },
    {
      "epoch": 0.2096,
      "grad_norm": 0.6317588686943054,
      "learning_rate": 0.0001991708669817729,
      "loss": 2.4918,
      "step": 1310
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.5849654078483582,
      "learning_rate": 0.0001991485210386296,
      "loss": 2.4426,
      "step": 1320
    },
    {
      "epoch": 0.2128,
      "grad_norm": 0.5779663324356079,
      "learning_rate": 0.0001991258792508198,
      "loss": 2.4814,
      "step": 1330
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.5916072726249695,
      "learning_rate": 0.0001991029416859033,
      "loss": 2.4841,
      "step": 1340
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.5872347950935364,
      "learning_rate": 0.0001990797084123224,
      "loss": 2.4746,
      "step": 1350
    },
    {
      "epoch": 0.216,
      "eval_bleu": 34.48685889018729,
      "eval_gen_len": 31.955,
      "eval_loss": 2.6348891258239746,
      "eval_runtime": 64.2486,
      "eval_samples_per_second": 15.565,
      "eval_steps_per_second": 0.981,
      "step": 1350
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.5846481323242188,
      "learning_rate": 0.0001990561794994019,
      "loss": 2.4793,
      "step": 1360
    },
    {
      "epoch": 0.2192,
      "grad_norm": 0.5812966227531433,
      "learning_rate": 0.00019903235501734845,
      "loss": 2.4556,
      "step": 1370
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.552887499332428,
      "learning_rate": 0.00019900823503725095,
      "loss": 2.4384,
      "step": 1380
    },
    {
      "epoch": 0.2224,
      "grad_norm": 0.5569549202919006,
      "learning_rate": 0.00019898381963107985,
      "loss": 2.4596,
      "step": 1390
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.5578663349151611,
      "learning_rate": 0.00019895910887168713,
      "loss": 2.4669,
      "step": 1400
    },
    {
      "epoch": 0.224,
      "eval_bleu": 35.01697975389119,
      "eval_gen_len": 31.901,
      "eval_loss": 2.6326868534088135,
      "eval_runtime": 64.354,
      "eval_samples_per_second": 15.539,
      "eval_steps_per_second": 0.979,
      "step": 1400
    },
    {
      "epoch": 0.2256,
      "grad_norm": 0.5236185789108276,
      "learning_rate": 0.0001989341028328061,
      "loss": 2.4664,
      "step": 1410
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.5012997388839722,
      "learning_rate": 0.0001989088015890511,
      "loss": 2.473,
      "step": 1420
    },
    {
      "epoch": 0.2288,
      "grad_norm": 0.6022862195968628,
      "learning_rate": 0.00019888320521591738,
      "loss": 2.4841,
      "step": 1430
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.5461508631706238,
      "learning_rate": 0.0001988573137897807,
      "loss": 2.454,
      "step": 1440
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.589809238910675,
      "learning_rate": 0.00019883112738789733,
      "loss": 2.4673,
      "step": 1450
    },
    {
      "epoch": 0.232,
      "eval_bleu": 34.68086913317515,
      "eval_gen_len": 31.762,
      "eval_loss": 2.6288352012634277,
      "eval_runtime": 64.1782,
      "eval_samples_per_second": 15.582,
      "eval_steps_per_second": 0.982,
      "step": 1450
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.6095070838928223,
      "learning_rate": 0.00019880464608840363,
      "loss": 2.4511,
      "step": 1460
    },
    {
      "epoch": 0.2352,
      "grad_norm": 0.5785512924194336,
      "learning_rate": 0.00019877786997031594,
      "loss": 2.4894,
      "step": 1470
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.5562993884086609,
      "learning_rate": 0.00019875079911353026,
      "loss": 2.479,
      "step": 1480
    },
    {
      "epoch": 0.2384,
      "grad_norm": 0.5901670455932617,
      "learning_rate": 0.00019872343359882212,
      "loss": 2.4842,
      "step": 1490
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5655435919761658,
      "learning_rate": 0.0001986957735078461,
      "loss": 2.4574,
      "step": 1500
    },
    {
      "epoch": 0.24,
      "eval_bleu": 34.849762980327334,
      "eval_gen_len": 31.999,
      "eval_loss": 2.627877950668335,
      "eval_runtime": 63.6775,
      "eval_samples_per_second": 15.704,
      "eval_steps_per_second": 0.989,
      "step": 1500
    },
    {
      "epoch": 0.2416,
      "grad_norm": 0.5810804963111877,
      "learning_rate": 0.00019866781892313598,
      "loss": 2.4731,
      "step": 1510
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.5509993433952332,
      "learning_rate": 0.00019863956992810405,
      "loss": 2.4675,
      "step": 1520
    },
    {
      "epoch": 0.2448,
      "grad_norm": 0.5621519088745117,
      "learning_rate": 0.00019861102660704126,
      "loss": 2.4647,
      "step": 1530
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.633882462978363,
      "learning_rate": 0.00019858218904511657,
      "loss": 2.4874,
      "step": 1540
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.5397360920906067,
      "learning_rate": 0.0001985530573283772,
      "loss": 2.4743,
      "step": 1550
    },
    {
      "epoch": 0.248,
      "eval_bleu": 34.8932059918317,
      "eval_gen_len": 31.879,
      "eval_loss": 2.6319167613983154,
      "eval_runtime": 63.575,
      "eval_samples_per_second": 15.729,
      "eval_steps_per_second": 0.991,
      "step": 1550
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.5577354431152344,
      "learning_rate": 0.00019852363154374784,
      "loss": 2.4482,
      "step": 1560
    },
    {
      "epoch": 0.2512,
      "grad_norm": 0.5655645728111267,
      "learning_rate": 0.0001984939117790307,
      "loss": 2.4523,
      "step": 1570
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.5298188924789429,
      "learning_rate": 0.00019846389812290524,
      "loss": 2.495,
      "step": 1580
    },
    {
      "epoch": 0.2544,
      "grad_norm": 0.5669528245925903,
      "learning_rate": 0.0001984335906649278,
      "loss": 2.4761,
      "step": 1590
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.5900402069091797,
      "learning_rate": 0.00019840298949553147,
      "loss": 2.443,
      "step": 1600
    },
    {
      "epoch": 0.256,
      "eval_bleu": 34.945657318584196,
      "eval_gen_len": 31.867,
      "eval_loss": 2.6280555725097656,
      "eval_runtime": 63.4041,
      "eval_samples_per_second": 15.772,
      "eval_steps_per_second": 0.994,
      "step": 1600
    },
    {
      "epoch": 0.2576,
      "grad_norm": 0.5443185567855835,
      "learning_rate": 0.00019837209470602556,
      "loss": 2.4711,
      "step": 1610
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.5667495727539062,
      "learning_rate": 0.0001983409063885956,
      "loss": 2.46,
      "step": 1620
    },
    {
      "epoch": 0.2608,
      "grad_norm": 0.5661446452140808,
      "learning_rate": 0.00019830942463630304,
      "loss": 2.4575,
      "step": 1630
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.5950779914855957,
      "learning_rate": 0.00019827764954308478,
      "loss": 2.4836,
      "step": 1640
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.5302138924598694,
      "learning_rate": 0.000198245581203753,
      "loss": 2.4445,
      "step": 1650
    },
    {
      "epoch": 0.264,
      "eval_bleu": 35.103962972937204,
      "eval_gen_len": 31.737,
      "eval_loss": 2.628026008605957,
      "eval_runtime": 62.8163,
      "eval_samples_per_second": 15.919,
      "eval_steps_per_second": 1.003,
      "step": 1650
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.5572234392166138,
      "learning_rate": 0.00019821321971399497,
      "loss": 2.4588,
      "step": 1660
    },
    {
      "epoch": 0.2672,
      "grad_norm": 0.5532022714614868,
      "learning_rate": 0.00019818056517037266,
      "loss": 2.4759,
      "step": 1670
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.5601279139518738,
      "learning_rate": 0.0001981476176703224,
      "loss": 2.4512,
      "step": 1680
    },
    {
      "epoch": 0.2704,
      "grad_norm": 0.5578556656837463,
      "learning_rate": 0.00019811437731215477,
      "loss": 2.4524,
      "step": 1690
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.5690515041351318,
      "learning_rate": 0.00019808084419505403,
      "loss": 2.4614,
      "step": 1700
    },
    {
      "epoch": 0.272,
      "eval_bleu": 34.865165866049715,
      "eval_gen_len": 31.827,
      "eval_loss": 2.6284496784210205,
      "eval_runtime": 63.5993,
      "eval_samples_per_second": 15.723,
      "eval_steps_per_second": 0.991,
      "step": 1700
    },
    {
      "epoch": 0.2736,
      "grad_norm": 0.538052499294281,
      "learning_rate": 0.00019804701841907816,
      "loss": 2.4807,
      "step": 1710
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.57154381275177,
      "learning_rate": 0.0001980129000851583,
      "loss": 2.4717,
      "step": 1720
    },
    {
      "epoch": 0.2768,
      "grad_norm": 0.6113143563270569,
      "learning_rate": 0.00019797848929509857,
      "loss": 2.4665,
      "step": 1730
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.5429868698120117,
      "learning_rate": 0.00019794378615157573,
      "loss": 2.4941,
      "step": 1740
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5588772296905518,
      "learning_rate": 0.00019790879075813885,
      "loss": 2.4593,
      "step": 1750
    },
    {
      "epoch": 0.28,
      "eval_bleu": 35.02832827642969,
      "eval_gen_len": 31.841,
      "eval_loss": 2.6300199031829834,
      "eval_runtime": 62.8759,
      "eval_samples_per_second": 15.904,
      "eval_steps_per_second": 1.002,
      "step": 1750
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.5677851438522339,
      "learning_rate": 0.00019787350321920914,
      "loss": 2.4659,
      "step": 1760
    },
    {
      "epoch": 0.2832,
      "grad_norm": 0.62111896276474,
      "learning_rate": 0.00019783792364007935,
      "loss": 2.4947,
      "step": 1770
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.594109833240509,
      "learning_rate": 0.00019780205212691378,
      "loss": 2.4873,
      "step": 1780
    },
    {
      "epoch": 0.2864,
      "grad_norm": 0.5351275205612183,
      "learning_rate": 0.0001977658887867478,
      "loss": 2.469,
      "step": 1790
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.5769303441047668,
      "learning_rate": 0.00019772943372748744,
      "loss": 2.4333,
      "step": 1800
    },
    {
      "epoch": 0.288,
      "eval_bleu": 34.96325493870961,
      "eval_gen_len": 31.838,
      "eval_loss": 2.6317410469055176,
      "eval_runtime": 62.9878,
      "eval_samples_per_second": 15.876,
      "eval_steps_per_second": 1.0,
      "step": 1800
    },
    {
      "epoch": 0.2896,
      "grad_norm": 0.5669177174568176,
      "learning_rate": 0.0001976926870579093,
      "loss": 2.4484,
      "step": 1810
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.5436453223228455,
      "learning_rate": 0.0001976556488876601,
      "loss": 2.4542,
      "step": 1820
    },
    {
      "epoch": 0.2928,
      "grad_norm": 0.5766653418540955,
      "learning_rate": 0.00019761831932725628,
      "loss": 2.4681,
      "step": 1830
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.5654007792472839,
      "learning_rate": 0.0001975806984880838,
      "loss": 2.4378,
      "step": 1840
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.5501854419708252,
      "learning_rate": 0.00019754278648239767,
      "loss": 2.4475,
      "step": 1850
    },
    {
      "epoch": 0.296,
      "eval_bleu": 34.41880462181343,
      "eval_gen_len": 31.879,
      "eval_loss": 2.6317696571350098,
      "eval_runtime": 63.2265,
      "eval_samples_per_second": 15.816,
      "eval_steps_per_second": 0.996,
      "step": 1850
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.543883740901947,
      "learning_rate": 0.00019750458342332182,
      "loss": 2.4525,
      "step": 1860
    },
    {
      "epoch": 0.2992,
      "grad_norm": 0.5395013093948364,
      "learning_rate": 0.0001974660894248486,
      "loss": 2.4796,
      "step": 1870
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.548356294631958,
      "learning_rate": 0.00019742730460183843,
      "loss": 2.4463,
      "step": 1880
    },
    {
      "epoch": 0.3024,
      "grad_norm": 0.5692775845527649,
      "learning_rate": 0.00019738822907001955,
      "loss": 2.4935,
      "step": 1890
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.5475708842277527,
      "learning_rate": 0.0001973488629459876,
      "loss": 2.4511,
      "step": 1900
    },
    {
      "epoch": 0.304,
      "eval_bleu": 34.72233220440043,
      "eval_gen_len": 31.883,
      "eval_loss": 2.627410411834717,
      "eval_runtime": 63.2053,
      "eval_samples_per_second": 15.821,
      "eval_steps_per_second": 0.997,
      "step": 1900
    },
    {
      "epoch": 0.3056,
      "grad_norm": 0.5623758435249329,
      "learning_rate": 0.00019730920634720539,
      "loss": 2.4712,
      "step": 1910
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.5850107669830322,
      "learning_rate": 0.00019726925939200234,
      "loss": 2.4405,
      "step": 1920
    },
    {
      "epoch": 0.3088,
      "grad_norm": 0.5701366662979126,
      "learning_rate": 0.00019722902219957436,
      "loss": 2.4699,
      "step": 1930
    },
    {
      "epoch": 0.3104,
      "grad_norm": 0.5785067677497864,
      "learning_rate": 0.00019718849488998332,
      "loss": 2.4521,
      "step": 1940
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.5383380055427551,
      "learning_rate": 0.00019714767758415675,
      "loss": 2.4509,
      "step": 1950
    },
    {
      "epoch": 0.312,
      "eval_bleu": 34.709212248133966,
      "eval_gen_len": 31.93,
      "eval_loss": 2.6274757385253906,
      "eval_runtime": 63.6007,
      "eval_samples_per_second": 15.723,
      "eval_steps_per_second": 0.991,
      "step": 1950
    },
    {
      "epoch": 0.3136,
      "grad_norm": 0.6180132627487183,
      "learning_rate": 0.00019710657040388757,
      "loss": 2.4585,
      "step": 1960
    },
    {
      "epoch": 0.3152,
      "grad_norm": 0.5866773128509521,
      "learning_rate": 0.00019706517347183353,
      "loss": 2.4624,
      "step": 1970
    },
    {
      "epoch": 0.3168,
      "grad_norm": 0.5460420250892639,
      "learning_rate": 0.00019702348691151707,
      "loss": 2.455,
      "step": 1980
    },
    {
      "epoch": 0.3184,
      "grad_norm": 0.5603464841842651,
      "learning_rate": 0.0001969815108473247,
      "loss": 2.4832,
      "step": 1990
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5205624103546143,
      "learning_rate": 0.00019693924540450694,
      "loss": 2.4455,
      "step": 2000
    },
    {
      "epoch": 0.32,
      "eval_bleu": 34.571978055419734,
      "eval_gen_len": 31.965,
      "eval_loss": 2.6289470195770264,
      "eval_runtime": 63.652,
      "eval_samples_per_second": 15.71,
      "eval_steps_per_second": 0.99,
      "step": 2000
    },
    {
      "epoch": 0.3216,
      "grad_norm": 0.5737565159797668,
      "learning_rate": 0.00019689669070917763,
      "loss": 2.4767,
      "step": 2010
    },
    {
      "epoch": 0.3232,
      "grad_norm": 0.5816032290458679,
      "learning_rate": 0.00019685384688831374,
      "loss": 2.4861,
      "step": 2020
    },
    {
      "epoch": 0.3248,
      "grad_norm": 0.5732737183570862,
      "learning_rate": 0.000196810714069755,
      "loss": 2.4792,
      "step": 2030
    },
    {
      "epoch": 0.3264,
      "grad_norm": 0.5440434813499451,
      "learning_rate": 0.00019676729238220336,
      "loss": 2.4598,
      "step": 2040
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.5926899909973145,
      "learning_rate": 0.00019672358195522286,
      "loss": 2.4642,
      "step": 2050
    },
    {
      "epoch": 0.328,
      "eval_bleu": 34.61239266806016,
      "eval_gen_len": 32.05,
      "eval_loss": 2.626882791519165,
      "eval_runtime": 67.2691,
      "eval_samples_per_second": 14.866,
      "eval_steps_per_second": 0.937,
      "step": 2050
    },
    {
      "epoch": 0.3296,
      "grad_norm": 0.544603168964386,
      "learning_rate": 0.00019667958291923893,
      "loss": 2.4612,
      "step": 2060
    },
    {
      "epoch": 0.3312,
      "grad_norm": 0.531577467918396,
      "learning_rate": 0.00019663529540553832,
      "loss": 2.4475,
      "step": 2070
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.5933319926261902,
      "learning_rate": 0.00019659071954626845,
      "loss": 2.4533,
      "step": 2080
    },
    {
      "epoch": 0.3344,
      "grad_norm": 0.5645747184753418,
      "learning_rate": 0.00019654585547443715,
      "loss": 2.4793,
      "step": 2090
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.6093629002571106,
      "learning_rate": 0.00019650070332391222,
      "loss": 2.4672,
      "step": 2100
    },
    {
      "epoch": 0.336,
      "eval_bleu": 34.72805686319804,
      "eval_gen_len": 31.697,
      "eval_loss": 2.6268577575683594,
      "eval_runtime": 63.1996,
      "eval_samples_per_second": 15.823,
      "eval_steps_per_second": 0.997,
      "step": 2100
    },
    {
      "epoch": 0.3376,
      "grad_norm": 0.5469384789466858,
      "learning_rate": 0.00019645526322942112,
      "loss": 2.4405,
      "step": 2110
    },
    {
      "epoch": 0.3392,
      "grad_norm": 0.5865528583526611,
      "learning_rate": 0.0001964095353265504,
      "loss": 2.4816,
      "step": 2120
    },
    {
      "epoch": 0.3408,
      "grad_norm": 0.5627039670944214,
      "learning_rate": 0.00019636351975174543,
      "loss": 2.4353,
      "step": 2130
    },
    {
      "epoch": 0.3424,
      "grad_norm": 0.5572008490562439,
      "learning_rate": 0.00019631721664230996,
      "loss": 2.4401,
      "step": 2140
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.5522891879081726,
      "learning_rate": 0.00019627062613640568,
      "loss": 2.4485,
      "step": 2150
    },
    {
      "epoch": 0.344,
      "eval_bleu": 34.770373582913145,
      "eval_gen_len": 31.922,
      "eval_loss": 2.625988483428955,
      "eval_runtime": 63.925,
      "eval_samples_per_second": 15.643,
      "eval_steps_per_second": 0.986,
      "step": 2150
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.5063963532447815,
      "learning_rate": 0.00019622374837305185,
      "loss": 2.4572,
      "step": 2160
    },
    {
      "epoch": 0.3472,
      "grad_norm": 0.5289586186408997,
      "learning_rate": 0.0001961765834921248,
      "loss": 2.4719,
      "step": 2170
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.5604714155197144,
      "learning_rate": 0.00019612913163435768,
      "loss": 2.4354,
      "step": 2180
    },
    {
      "epoch": 0.3504,
      "grad_norm": 0.5580554604530334,
      "learning_rate": 0.00019608139294133986,
      "loss": 2.472,
      "step": 2190
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.5545185208320618,
      "learning_rate": 0.00019603336755551665,
      "loss": 2.4403,
      "step": 2200
    },
    {
      "epoch": 0.352,
      "eval_bleu": 34.681948774906616,
      "eval_gen_len": 31.931,
      "eval_loss": 2.6288626194000244,
      "eval_runtime": 64.2123,
      "eval_samples_per_second": 15.573,
      "eval_steps_per_second": 0.981,
      "step": 2200
    },
    {
      "epoch": 0.3536,
      "grad_norm": 0.6094310879707336,
      "learning_rate": 0.0001959850556201887,
      "loss": 2.4451,
      "step": 2210
    },
    {
      "epoch": 0.3552,
      "grad_norm": 0.5652989149093628,
      "learning_rate": 0.0001959364572795118,
      "loss": 2.4705,
      "step": 2220
    },
    {
      "epoch": 0.3568,
      "grad_norm": 0.5603627562522888,
      "learning_rate": 0.00019588757267849626,
      "loss": 2.4349,
      "step": 2230
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.5397679209709167,
      "learning_rate": 0.00019583840196300657,
      "loss": 2.4673,
      "step": 2240
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5775654911994934,
      "learning_rate": 0.00019578894527976098,
      "loss": 2.4848,
      "step": 2250
    },
    {
      "epoch": 0.36,
      "eval_bleu": 34.48984652484627,
      "eval_gen_len": 31.924,
      "eval_loss": 2.626032829284668,
      "eval_runtime": 64.1077,
      "eval_samples_per_second": 15.599,
      "eval_steps_per_second": 0.983,
      "step": 2250
    },
    {
      "epoch": 0.3616,
      "grad_norm": 0.5321177244186401,
      "learning_rate": 0.00019573920277633091,
      "loss": 2.4599,
      "step": 2260
    },
    {
      "epoch": 0.3632,
      "grad_norm": 0.5364024043083191,
      "learning_rate": 0.0001956891746011408,
      "loss": 2.4709,
      "step": 2270
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.5850937366485596,
      "learning_rate": 0.00019563886090346734,
      "loss": 2.4436,
      "step": 2280
    },
    {
      "epoch": 0.3664,
      "grad_norm": 0.5717839598655701,
      "learning_rate": 0.00019558826183343925,
      "loss": 2.4761,
      "step": 2290
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.5458458065986633,
      "learning_rate": 0.00019553737754203672,
      "loss": 2.4356,
      "step": 2300
    },
    {
      "epoch": 0.368,
      "eval_bleu": 34.739852356377675,
      "eval_gen_len": 31.748,
      "eval_loss": 2.6244256496429443,
      "eval_runtime": 63.5512,
      "eval_samples_per_second": 15.735,
      "eval_steps_per_second": 0.991,
      "step": 2300
    },
    {
      "epoch": 0.3696,
      "grad_norm": 0.5345937609672546,
      "learning_rate": 0.00019548620818109105,
      "loss": 2.4425,
      "step": 2310
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.5456681251525879,
      "learning_rate": 0.00019543475390328415,
      "loss": 2.4928,
      "step": 2320
    },
    {
      "epoch": 0.3728,
      "grad_norm": 0.5408269762992859,
      "learning_rate": 0.00019538301486214798,
      "loss": 2.4789,
      "step": 2330
    },
    {
      "epoch": 0.3744,
      "grad_norm": 0.5683011412620544,
      "learning_rate": 0.00019533099121206432,
      "loss": 2.473,
      "step": 2340
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.5484177470207214,
      "learning_rate": 0.00019527868310826408,
      "loss": 2.4417,
      "step": 2350
    },
    {
      "epoch": 0.376,
      "eval_bleu": 35.060648143673234,
      "eval_gen_len": 31.782,
      "eval_loss": 2.6207876205444336,
      "eval_runtime": 62.478,
      "eval_samples_per_second": 16.006,
      "eval_steps_per_second": 1.008,
      "step": 2350
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.5182974338531494,
      "learning_rate": 0.00019522609070682704,
      "loss": 2.4498,
      "step": 2360
    },
    {
      "epoch": 0.3792,
      "grad_norm": 0.5080416798591614,
      "learning_rate": 0.00019517321416468112,
      "loss": 2.4473,
      "step": 2370
    },
    {
      "epoch": 0.3808,
      "grad_norm": 0.5305566191673279,
      "learning_rate": 0.0001951200536396023,
      "loss": 2.4372,
      "step": 2380
    },
    {
      "epoch": 0.3824,
      "grad_norm": 0.5505611896514893,
      "learning_rate": 0.00019506660929021372,
      "loss": 2.453,
      "step": 2390
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.5190448760986328,
      "learning_rate": 0.0001950128812759855,
      "loss": 2.4485,
      "step": 2400
    },
    {
      "epoch": 0.384,
      "eval_bleu": 35.14910965633205,
      "eval_gen_len": 31.849,
      "eval_loss": 2.6243386268615723,
      "eval_runtime": 63.2704,
      "eval_samples_per_second": 15.805,
      "eval_steps_per_second": 0.996,
      "step": 2400
    },
    {
      "epoch": 0.3856,
      "grad_norm": 0.5912378430366516,
      "learning_rate": 0.0001949588697572342,
      "loss": 2.435,
      "step": 2410
    },
    {
      "epoch": 0.3872,
      "grad_norm": 0.5433494448661804,
      "learning_rate": 0.0001949045748951223,
      "loss": 2.4654,
      "step": 2420
    },
    {
      "epoch": 0.3888,
      "grad_norm": 0.6177938580513,
      "learning_rate": 0.00019484999685165765,
      "loss": 2.4685,
      "step": 2430
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.5341494679450989,
      "learning_rate": 0.00019479513578969315,
      "loss": 2.4597,
      "step": 2440
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.5687639117240906,
      "learning_rate": 0.00019473999187292622,
      "loss": 2.4727,
      "step": 2450
    },
    {
      "epoch": 0.392,
      "eval_bleu": 35.3169204778032,
      "eval_gen_len": 31.721,
      "eval_loss": 2.6218059062957764,
      "eval_runtime": 63.2895,
      "eval_samples_per_second": 15.8,
      "eval_steps_per_second": 0.995,
      "step": 2450
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.6142840385437012,
      "learning_rate": 0.0001946845652658982,
      "loss": 2.4686,
      "step": 2460
    },
    {
      "epoch": 0.3952,
      "grad_norm": 0.5181723833084106,
      "learning_rate": 0.000194628856133994,
      "loss": 2.4458,
      "step": 2470
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.5769925117492676,
      "learning_rate": 0.00019457286464344143,
      "loss": 2.4676,
      "step": 2480
    },
    {
      "epoch": 0.3984,
      "grad_norm": 0.5525213479995728,
      "learning_rate": 0.000194516590961311,
      "loss": 2.4752,
      "step": 2490
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5571643710136414,
      "learning_rate": 0.00019446003525551507,
      "loss": 2.4718,
      "step": 2500
    },
    {
      "epoch": 0.4,
      "eval_bleu": 35.17822883331518,
      "eval_gen_len": 31.792,
      "eval_loss": 2.6235201358795166,
      "eval_runtime": 63.688,
      "eval_samples_per_second": 15.702,
      "eval_steps_per_second": 0.989,
      "step": 2500
    },
    {
      "epoch": 0.4016,
      "grad_norm": 0.5565257668495178,
      "learning_rate": 0.0001944031976948076,
      "loss": 2.4558,
      "step": 2510
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.5349408388137817,
      "learning_rate": 0.00019434607844878357,
      "loss": 2.4304,
      "step": 2520
    },
    {
      "epoch": 0.4048,
      "grad_norm": 0.5366164445877075,
      "learning_rate": 0.0001942886776878784,
      "loss": 2.4514,
      "step": 2530
    },
    {
      "epoch": 0.4064,
      "grad_norm": 0.5210527181625366,
      "learning_rate": 0.00019423099558336758,
      "loss": 2.4222,
      "step": 2540
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.5528488159179688,
      "learning_rate": 0.00019417303230736608,
      "loss": 2.4505,
      "step": 2550
    },
    {
      "epoch": 0.408,
      "eval_bleu": 35.055006096988976,
      "eval_gen_len": 31.954,
      "eval_loss": 2.619629383087158,
      "eval_runtime": 64.003,
      "eval_samples_per_second": 15.624,
      "eval_steps_per_second": 0.984,
      "step": 2550
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.5282501578330994,
      "learning_rate": 0.0001941147880328278,
      "loss": 2.4472,
      "step": 2560
    },
    {
      "epoch": 0.4112,
      "grad_norm": 0.5125888586044312,
      "learning_rate": 0.00019405626293354512,
      "loss": 2.4637,
      "step": 2570
    },
    {
      "epoch": 0.4128,
      "grad_norm": 0.5690082907676697,
      "learning_rate": 0.0001939974571841484,
      "loss": 2.4762,
      "step": 2580
    },
    {
      "epoch": 0.4144,
      "grad_norm": 0.523013174533844,
      "learning_rate": 0.00019393837096010535,
      "loss": 2.4424,
      "step": 2590
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.5464523434638977,
      "learning_rate": 0.00019387900443772064,
      "loss": 2.4406,
      "step": 2600
    },
    {
      "epoch": 0.416,
      "eval_bleu": 34.77158546564964,
      "eval_gen_len": 31.907,
      "eval_loss": 2.6235032081604004,
      "eval_runtime": 63.1931,
      "eval_samples_per_second": 15.825,
      "eval_steps_per_second": 0.997,
      "step": 2600
    },
    {
      "epoch": 0.4176,
      "grad_norm": 0.5738909840583801,
      "learning_rate": 0.00019381935779413527,
      "loss": 2.4428,
      "step": 2610
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.5551152229309082,
      "learning_rate": 0.00019375943120732606,
      "loss": 2.4492,
      "step": 2620
    },
    {
      "epoch": 0.4208,
      "grad_norm": 0.5760320425033569,
      "learning_rate": 0.0001936992248561052,
      "loss": 2.4588,
      "step": 2630
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.5395404696464539,
      "learning_rate": 0.00019363873892011958,
      "loss": 2.4591,
      "step": 2640
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.5924362540245056,
      "learning_rate": 0.00019357797357985045,
      "loss": 2.4464,
      "step": 2650
    },
    {
      "epoch": 0.424,
      "eval_bleu": 34.92761758077997,
      "eval_gen_len": 31.838,
      "eval_loss": 2.624295711517334,
      "eval_runtime": 63.9183,
      "eval_samples_per_second": 15.645,
      "eval_steps_per_second": 0.986,
      "step": 2650
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.5503965020179749,
      "learning_rate": 0.00019351692901661263,
      "loss": 2.4175,
      "step": 2660
    },
    {
      "epoch": 0.4272,
      "grad_norm": 0.544901430606842,
      "learning_rate": 0.00019345560541255416,
      "loss": 2.4339,
      "step": 2670
    },
    {
      "epoch": 0.4288,
      "grad_norm": 0.5668236017227173,
      "learning_rate": 0.00019339400295065572,
      "loss": 2.4545,
      "step": 2680
    },
    {
      "epoch": 0.4304,
      "grad_norm": 0.5234541893005371,
      "learning_rate": 0.00019333212181473,
      "loss": 2.4438,
      "step": 2690
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.5613487958908081,
      "learning_rate": 0.0001932699621894213,
      "loss": 2.452,
      "step": 2700
    },
    {
      "epoch": 0.432,
      "eval_bleu": 35.01580251941565,
      "eval_gen_len": 31.861,
      "eval_loss": 2.6240477561950684,
      "eval_runtime": 63.518,
      "eval_samples_per_second": 15.744,
      "eval_steps_per_second": 0.992,
      "step": 2700
    },
    {
      "epoch": 0.4336,
      "grad_norm": 0.5357480049133301,
      "learning_rate": 0.0001932075242602048,
      "loss": 2.4578,
      "step": 2710
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.5397265553474426,
      "learning_rate": 0.00019314480821338613,
      "loss": 2.4477,
      "step": 2720
    },
    {
      "epoch": 0.4368,
      "grad_norm": 0.554749608039856,
      "learning_rate": 0.00019308181423610083,
      "loss": 2.4744,
      "step": 2730
    },
    {
      "epoch": 0.4384,
      "grad_norm": 0.5804666876792908,
      "learning_rate": 0.00019301854251631363,
      "loss": 2.4567,
      "step": 2740
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5585403442382812,
      "learning_rate": 0.00019295499324281816,
      "loss": 2.4155,
      "step": 2750
    },
    {
      "epoch": 0.44,
      "eval_bleu": 34.820113436733536,
      "eval_gen_len": 31.821,
      "eval_loss": 2.6216578483581543,
      "eval_runtime": 63.4621,
      "eval_samples_per_second": 15.757,
      "eval_steps_per_second": 0.993,
      "step": 2750
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.5087590217590332,
      "learning_rate": 0.00019289116660523608,
      "loss": 2.4403,
      "step": 2760
    },
    {
      "epoch": 0.4432,
      "grad_norm": 0.5615323781967163,
      "learning_rate": 0.00019282706279401677,
      "loss": 2.4497,
      "step": 2770
    },
    {
      "epoch": 0.4448,
      "grad_norm": 0.5596563220024109,
      "learning_rate": 0.0001927626820004366,
      "loss": 2.4643,
      "step": 2780
    },
    {
      "epoch": 0.4464,
      "grad_norm": 0.564231812953949,
      "learning_rate": 0.0001926980244165984,
      "loss": 2.4497,
      "step": 2790
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.5376661419868469,
      "learning_rate": 0.000192633090235431,
      "loss": 2.4819,
      "step": 2800
    },
    {
      "epoch": 0.448,
      "eval_bleu": 34.88317216618466,
      "eval_gen_len": 31.819,
      "eval_loss": 2.6231424808502197,
      "eval_runtime": 64.0045,
      "eval_samples_per_second": 15.624,
      "eval_steps_per_second": 0.984,
      "step": 2800
    },
    {
      "epoch": 0.4496,
      "grad_norm": 0.5634507536888123,
      "learning_rate": 0.0001925678796506884,
      "loss": 2.4411,
      "step": 2810
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.5362609624862671,
      "learning_rate": 0.00019250239285694952,
      "loss": 2.4595,
      "step": 2820
    },
    {
      "epoch": 0.4528,
      "grad_norm": 0.5347289443016052,
      "learning_rate": 0.00019243663004961734,
      "loss": 2.4317,
      "step": 2830
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.5490057468414307,
      "learning_rate": 0.0001923705914249184,
      "loss": 2.4696,
      "step": 2840
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.5420364737510681,
      "learning_rate": 0.00019230427717990232,
      "loss": 2.4455,
      "step": 2850
    },
    {
      "epoch": 0.456,
      "eval_bleu": 35.0302722734427,
      "eval_gen_len": 31.782,
      "eval_loss": 2.6225368976593018,
      "eval_runtime": 63.5619,
      "eval_samples_per_second": 15.733,
      "eval_steps_per_second": 0.991,
      "step": 2850
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.5352621078491211,
      "learning_rate": 0.00019223768751244107,
      "loss": 2.442,
      "step": 2860
    },
    {
      "epoch": 0.4592,
      "grad_norm": 0.5890898704528809,
      "learning_rate": 0.0001921708226212285,
      "loss": 2.4518,
      "step": 2870
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.5612098574638367,
      "learning_rate": 0.00019210368270577966,
      "loss": 2.4629,
      "step": 2880
    },
    {
      "epoch": 0.4624,
      "grad_norm": 0.5715219974517822,
      "learning_rate": 0.00019203626796643016,
      "loss": 2.4515,
      "step": 2890
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.48430752754211426,
      "learning_rate": 0.0001919685786043358,
      "loss": 2.4373,
      "step": 2900
    },
    {
      "epoch": 0.464,
      "eval_bleu": 34.666586001830844,
      "eval_gen_len": 31.826,
      "eval_loss": 2.623509645462036,
      "eval_runtime": 63.7146,
      "eval_samples_per_second": 15.695,
      "eval_steps_per_second": 0.989,
      "step": 2900
    },
    {
      "epoch": 0.4656,
      "grad_norm": 0.5705018043518066,
      "learning_rate": 0.00019190061482147165,
      "loss": 2.4483,
      "step": 2910
    },
    {
      "epoch": 0.4672,
      "grad_norm": 0.5290376543998718,
      "learning_rate": 0.00019183237682063173,
      "loss": 2.4441,
      "step": 2920
    },
    {
      "epoch": 0.4688,
      "grad_norm": 0.5513256788253784,
      "learning_rate": 0.0001917638648054282,
      "loss": 2.4523,
      "step": 2930
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.6111246347427368,
      "learning_rate": 0.00019169507898029092,
      "loss": 2.4546,
      "step": 2940
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.5322933197021484,
      "learning_rate": 0.00019162601955046669,
      "loss": 2.456,
      "step": 2950
    },
    {
      "epoch": 0.472,
      "eval_bleu": 34.69693790539097,
      "eval_gen_len": 31.779,
      "eval_loss": 2.6268200874328613,
      "eval_runtime": 63.4158,
      "eval_samples_per_second": 15.769,
      "eval_steps_per_second": 0.993,
      "step": 2950
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.5944153070449829,
      "learning_rate": 0.00019155668672201875,
      "loss": 2.491,
      "step": 2960
    },
    {
      "epoch": 0.4752,
      "grad_norm": 0.5916215181350708,
      "learning_rate": 0.00019148708070182609,
      "loss": 2.472,
      "step": 2970
    },
    {
      "epoch": 0.4768,
      "grad_norm": 0.5048851370811462,
      "learning_rate": 0.0001914172016975829,
      "loss": 2.4196,
      "step": 2980
    },
    {
      "epoch": 0.4784,
      "grad_norm": 0.5501489639282227,
      "learning_rate": 0.0001913470499177979,
      "loss": 2.4435,
      "step": 2990
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5488091707229614,
      "learning_rate": 0.0001912766255717937,
      "loss": 2.4561,
      "step": 3000
    },
    {
      "epoch": 0.48,
      "eval_bleu": 34.53896212796501,
      "eval_gen_len": 31.715,
      "eval_loss": 2.62605881690979,
      "eval_runtime": 63.8306,
      "eval_samples_per_second": 15.666,
      "eval_steps_per_second": 0.987,
      "step": 3000
    },
    {
      "epoch": 0.4816,
      "grad_norm": 0.5300904512405396,
      "learning_rate": 0.00019120592886970626,
      "loss": 2.4613,
      "step": 3010
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.5299785137176514,
      "learning_rate": 0.00019113496002248415,
      "loss": 2.4581,
      "step": 3020
    },
    {
      "epoch": 0.4848,
      "grad_norm": 0.5189788341522217,
      "learning_rate": 0.00019106371924188805,
      "loss": 2.4671,
      "step": 3030
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.5531267523765564,
      "learning_rate": 0.00019099220674049003,
      "loss": 2.4416,
      "step": 3040
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.5733808875083923,
      "learning_rate": 0.0001909204227316729,
      "loss": 2.4282,
      "step": 3050
    },
    {
      "epoch": 0.488,
      "eval_bleu": 35.03900815773007,
      "eval_gen_len": 31.788,
      "eval_loss": 2.6214327812194824,
      "eval_runtime": 64.8751,
      "eval_samples_per_second": 15.414,
      "eval_steps_per_second": 0.971,
      "step": 3050
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.5441596508026123,
      "learning_rate": 0.00019084836742962958,
      "loss": 2.4332,
      "step": 3060
    },
    {
      "epoch": 0.4912,
      "grad_norm": 0.5482919812202454,
      "learning_rate": 0.00019077604104936264,
      "loss": 2.4454,
      "step": 3070
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.5364189147949219,
      "learning_rate": 0.00019070344380668332,
      "loss": 2.4566,
      "step": 3080
    },
    {
      "epoch": 0.4944,
      "grad_norm": 0.561967134475708,
      "learning_rate": 0.00019063057591821122,
      "loss": 2.4441,
      "step": 3090
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.5830311179161072,
      "learning_rate": 0.0001905574376013734,
      "loss": 2.4647,
      "step": 3100
    },
    {
      "epoch": 0.496,
      "eval_bleu": 34.86097183424901,
      "eval_gen_len": 31.808,
      "eval_loss": 2.6213457584381104,
      "eval_runtime": 63.7699,
      "eval_samples_per_second": 15.681,
      "eval_steps_per_second": 0.988,
      "step": 3100
    },
    {
      "epoch": 0.4976,
      "grad_norm": 0.5714299082756042,
      "learning_rate": 0.00019048402907440392,
      "loss": 2.4503,
      "step": 3110
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.5591803789138794,
      "learning_rate": 0.00019041035055634303,
      "loss": 2.463,
      "step": 3120
    },
    {
      "epoch": 0.5008,
      "grad_norm": 0.5577390789985657,
      "learning_rate": 0.00019033640226703673,
      "loss": 2.4409,
      "step": 3130
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.5963982343673706,
      "learning_rate": 0.00019026218442713577,
      "loss": 2.4533,
      "step": 3140
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.5407301187515259,
      "learning_rate": 0.00019018769725809542,
      "loss": 2.4343,
      "step": 3150
    },
    {
      "epoch": 0.504,
      "eval_bleu": 35.01541394617554,
      "eval_gen_len": 31.878,
      "eval_loss": 2.6212379932403564,
      "eval_runtime": 63.9524,
      "eval_samples_per_second": 15.637,
      "eval_steps_per_second": 0.985,
      "step": 3150
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.5294753909111023,
      "learning_rate": 0.00019011294098217438,
      "loss": 2.4452,
      "step": 3160
    },
    {
      "epoch": 0.5072,
      "grad_norm": 0.5574992299079895,
      "learning_rate": 0.00019003791582243454,
      "loss": 2.4462,
      "step": 3170
    },
    {
      "epoch": 0.5088,
      "grad_norm": 0.5386964082717896,
      "learning_rate": 0.00018996262200273988,
      "loss": 2.4579,
      "step": 3180
    },
    {
      "epoch": 0.5104,
      "grad_norm": 0.5844995379447937,
      "learning_rate": 0.00018988705974775621,
      "loss": 2.4551,
      "step": 3190
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.6021989583969116,
      "learning_rate": 0.0001898112292829502,
      "loss": 2.4416,
      "step": 3200
    },
    {
      "epoch": 0.512,
      "eval_bleu": 34.79598753170731,
      "eval_gen_len": 31.836,
      "eval_loss": 2.6209518909454346,
      "eval_runtime": 64.7633,
      "eval_samples_per_second": 15.441,
      "eval_steps_per_second": 0.973,
      "step": 3200
    },
    {
      "epoch": 0.5136,
      "grad_norm": 0.5808438062667847,
      "learning_rate": 0.00018973513083458883,
      "loss": 2.4506,
      "step": 3210
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.5317208170890808,
      "learning_rate": 0.0001896587646297388,
      "loss": 2.4509,
      "step": 3220
    },
    {
      "epoch": 0.5168,
      "grad_norm": 0.5620104074478149,
      "learning_rate": 0.00018958213089626563,
      "loss": 2.4593,
      "step": 3230
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.6538580656051636,
      "learning_rate": 0.00018950522986283314,
      "loss": 2.4549,
      "step": 3240
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5567104816436768,
      "learning_rate": 0.00018942806175890276,
      "loss": 2.4534,
      "step": 3250
    },
    {
      "epoch": 0.52,
      "eval_bleu": 34.785834019732185,
      "eval_gen_len": 31.891,
      "eval_loss": 2.619250774383545,
      "eval_runtime": 64.7011,
      "eval_samples_per_second": 15.456,
      "eval_steps_per_second": 0.974,
      "step": 3250
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.5349534153938293,
      "learning_rate": 0.00018935062681473287,
      "loss": 2.4135,
      "step": 3260
    },
    {
      "epoch": 0.5232,
      "grad_norm": 0.4919295907020569,
      "learning_rate": 0.00018927292526137795,
      "loss": 2.4449,
      "step": 3270
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.5244757533073425,
      "learning_rate": 0.00018919495733068804,
      "loss": 2.4228,
      "step": 3280
    },
    {
      "epoch": 0.5264,
      "grad_norm": 0.5785536170005798,
      "learning_rate": 0.00018911672325530807,
      "loss": 2.4381,
      "step": 3290
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.5974161624908447,
      "learning_rate": 0.00018903822326867703,
      "loss": 2.4239,
      "step": 3300
    },
    {
      "epoch": 0.528,
      "eval_bleu": 34.80890566791951,
      "eval_gen_len": 32.113,
      "eval_loss": 2.617861747741699,
      "eval_runtime": 66.9412,
      "eval_samples_per_second": 14.938,
      "eval_steps_per_second": 0.941,
      "step": 3300
    },
    {
      "epoch": 0.5296,
      "grad_norm": 0.5444634556770325,
      "learning_rate": 0.0001889594576050274,
      "loss": 2.4291,
      "step": 3310
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.5998923182487488,
      "learning_rate": 0.0001888804264993844,
      "loss": 2.4522,
      "step": 3320
    },
    {
      "epoch": 0.5328,
      "grad_norm": 0.571945071220398,
      "learning_rate": 0.00018880113018756523,
      "loss": 2.4223,
      "step": 3330
    },
    {
      "epoch": 0.5344,
      "grad_norm": 0.5006104707717896,
      "learning_rate": 0.0001887215689061785,
      "loss": 2.4383,
      "step": 3340
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.5437427759170532,
      "learning_rate": 0.00018864174289262345,
      "loss": 2.4394,
      "step": 3350
    },
    {
      "epoch": 0.536,
      "eval_bleu": 34.51368828531539,
      "eval_gen_len": 32.213,
      "eval_loss": 2.620283603668213,
      "eval_runtime": 67.7529,
      "eval_samples_per_second": 14.76,
      "eval_steps_per_second": 0.93,
      "step": 3350
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.5020503401756287,
      "learning_rate": 0.00018856165238508913,
      "loss": 2.4258,
      "step": 3360
    },
    {
      "epoch": 0.5392,
      "grad_norm": 0.5091574788093567,
      "learning_rate": 0.000188481297622554,
      "loss": 2.4442,
      "step": 3370
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.518076479434967,
      "learning_rate": 0.00018840067884478483,
      "loss": 2.4456,
      "step": 3380
    },
    {
      "epoch": 0.5424,
      "grad_norm": 0.5645824074745178,
      "learning_rate": 0.00018831979629233624,
      "loss": 2.4468,
      "step": 3390
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.5600224733352661,
      "learning_rate": 0.00018823865020654995,
      "loss": 2.4385,
      "step": 3400
    },
    {
      "epoch": 0.544,
      "eval_bleu": 35.272522258917036,
      "eval_gen_len": 31.833,
      "eval_loss": 2.618903875350952,
      "eval_runtime": 63.7004,
      "eval_samples_per_second": 15.698,
      "eval_steps_per_second": 0.989,
      "step": 3400
    },
    {
      "epoch": 0.5456,
      "grad_norm": 0.5116089582443237,
      "learning_rate": 0.000188157240829554,
      "loss": 2.4275,
      "step": 3410
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.5561004877090454,
      "learning_rate": 0.000188075568404262,
      "loss": 2.4546,
      "step": 3420
    },
    {
      "epoch": 0.5488,
      "grad_norm": 0.5697484612464905,
      "learning_rate": 0.00018799363317437262,
      "loss": 2.4747,
      "step": 3430
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.5744056105613708,
      "learning_rate": 0.00018791143538436845,
      "loss": 2.4597,
      "step": 3440
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.5545841455459595,
      "learning_rate": 0.0001878289752795157,
      "loss": 2.4448,
      "step": 3450
    },
    {
      "epoch": 0.552,
      "eval_bleu": 34.937769419819894,
      "eval_gen_len": 32.092,
      "eval_loss": 2.6196203231811523,
      "eval_runtime": 67.5341,
      "eval_samples_per_second": 14.807,
      "eval_steps_per_second": 0.933,
      "step": 3450
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.5850727558135986,
      "learning_rate": 0.0001877462531058633,
      "loss": 2.4639,
      "step": 3460
    },
    {
      "epoch": 0.5552,
      "grad_norm": 0.5730496644973755,
      "learning_rate": 0.00018766326911024206,
      "loss": 2.4589,
      "step": 3470
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.49014294147491455,
      "learning_rate": 0.00018758002354026407,
      "loss": 2.4405,
      "step": 3480
    },
    {
      "epoch": 0.5584,
      "grad_norm": 0.5401603579521179,
      "learning_rate": 0.00018749651664432194,
      "loss": 2.4516,
      "step": 3490
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.55101078748703,
      "learning_rate": 0.00018741274867158797,
      "loss": 2.4255,
      "step": 3500
    },
    {
      "epoch": 0.56,
      "eval_bleu": 35.19110358334637,
      "eval_gen_len": 31.737,
      "eval_loss": 2.6188671588897705,
      "eval_runtime": 64.1461,
      "eval_samples_per_second": 15.589,
      "eval_steps_per_second": 0.982,
      "step": 3500
    },
    {
      "epoch": 0.5616,
      "grad_norm": 0.5476838946342468,
      "learning_rate": 0.00018732871987201357,
      "loss": 2.4406,
      "step": 3510
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.5576762557029724,
      "learning_rate": 0.00018724443049632835,
      "loss": 2.4659,
      "step": 3520
    },
    {
      "epoch": 0.5648,
      "grad_norm": 0.5624735355377197,
      "learning_rate": 0.00018715988079603949,
      "loss": 2.4537,
      "step": 3530
    },
    {
      "epoch": 0.5664,
      "grad_norm": 0.5424456596374512,
      "learning_rate": 0.0001870750710234309,
      "loss": 2.4457,
      "step": 3540
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.5932437777519226,
      "learning_rate": 0.00018699000143156247,
      "loss": 2.4299,
      "step": 3550
    },
    {
      "epoch": 0.568,
      "eval_bleu": 35.25610912107107,
      "eval_gen_len": 31.847,
      "eval_loss": 2.614227294921875,
      "eval_runtime": 64.8311,
      "eval_samples_per_second": 15.425,
      "eval_steps_per_second": 0.972,
      "step": 3550
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.5388777256011963,
      "learning_rate": 0.00018690467227426945,
      "loss": 2.4356,
      "step": 3560
    },
    {
      "epoch": 0.5712,
      "grad_norm": 0.51324462890625,
      "learning_rate": 0.0001868190838061616,
      "loss": 2.4617,
      "step": 3570
    },
    {
      "epoch": 0.5728,
      "grad_norm": 0.5634928345680237,
      "learning_rate": 0.00018673323628262228,
      "loss": 2.4438,
      "step": 3580
    },
    {
      "epoch": 0.5744,
      "grad_norm": 0.5363436341285706,
      "learning_rate": 0.000186647129959808,
      "loss": 2.425,
      "step": 3590
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.5360598564147949,
      "learning_rate": 0.00018656076509464736,
      "loss": 2.4308,
      "step": 3600
    },
    {
      "epoch": 0.576,
      "eval_bleu": 34.852005895274104,
      "eval_gen_len": 31.812,
      "eval_loss": 2.6192142963409424,
      "eval_runtime": 63.6688,
      "eval_samples_per_second": 15.706,
      "eval_steps_per_second": 0.989,
      "step": 3600
    },
    {
      "epoch": 0.5776,
      "grad_norm": 0.5658209919929504,
      "learning_rate": 0.00018647414194484046,
      "loss": 2.4455,
      "step": 3610
    },
    {
      "epoch": 0.5792,
      "grad_norm": 0.5348993539810181,
      "learning_rate": 0.00018638726076885818,
      "loss": 2.4146,
      "step": 3620
    },
    {
      "epoch": 0.5808,
      "grad_norm": 0.5419418215751648,
      "learning_rate": 0.00018630012182594116,
      "loss": 2.4584,
      "step": 3630
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.5789118409156799,
      "learning_rate": 0.00018621272537609927,
      "loss": 2.4307,
      "step": 3640
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.5315631031990051,
      "learning_rate": 0.0001861250716801107,
      "loss": 2.4294,
      "step": 3650
    },
    {
      "epoch": 0.584,
      "eval_bleu": 35.368269282324036,
      "eval_gen_len": 31.855,
      "eval_loss": 2.6171772480010986,
      "eval_runtime": 64.4946,
      "eval_samples_per_second": 15.505,
      "eval_steps_per_second": 0.977,
      "step": 3650
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.5258187055587769,
      "learning_rate": 0.00018603716099952123,
      "loss": 2.4497,
      "step": 3660
    },
    {
      "epoch": 0.5872,
      "grad_norm": 0.5285698175430298,
      "learning_rate": 0.0001859489935966435,
      "loss": 2.4496,
      "step": 3670
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.5600507855415344,
      "learning_rate": 0.00018586056973455607,
      "loss": 2.4434,
      "step": 3680
    },
    {
      "epoch": 0.5904,
      "grad_norm": 0.5469633340835571,
      "learning_rate": 0.00018577188967710287,
      "loss": 2.434,
      "step": 3690
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.5166456699371338,
      "learning_rate": 0.00018568295368889213,
      "loss": 2.461,
      "step": 3700
    },
    {
      "epoch": 0.592,
      "eval_bleu": 35.026864041738435,
      "eval_gen_len": 31.85,
      "eval_loss": 2.61735200881958,
      "eval_runtime": 64.0554,
      "eval_samples_per_second": 15.611,
      "eval_steps_per_second": 0.984,
      "step": 3700
    },
    {
      "epoch": 0.5936,
      "grad_norm": 0.5218036770820618,
      "learning_rate": 0.00018559376203529585,
      "loss": 2.4368,
      "step": 3710
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.49302423000335693,
      "learning_rate": 0.00018550431498244883,
      "loss": 2.4358,
      "step": 3720
    },
    {
      "epoch": 0.5968,
      "grad_norm": 0.5513613820075989,
      "learning_rate": 0.00018541461279724804,
      "loss": 2.4699,
      "step": 3730
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.5311385989189148,
      "learning_rate": 0.00018532465574735163,
      "loss": 2.4482,
      "step": 3740
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5394654870033264,
      "learning_rate": 0.00018523444410117822,
      "loss": 2.4258,
      "step": 3750
    },
    {
      "epoch": 0.6,
      "eval_bleu": 35.46576000845171,
      "eval_gen_len": 31.638,
      "eval_loss": 2.6189510822296143,
      "eval_runtime": 63.1693,
      "eval_samples_per_second": 15.83,
      "eval_steps_per_second": 0.997,
      "step": 3750
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.5363439321517944,
      "learning_rate": 0.00018514397812790625,
      "loss": 2.4032,
      "step": 3760
    },
    {
      "epoch": 0.6032,
      "grad_norm": 0.5541663765907288,
      "learning_rate": 0.00018505325809747283,
      "loss": 2.4713,
      "step": 3770
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.53883957862854,
      "learning_rate": 0.0001849622842805733,
      "loss": 2.4481,
      "step": 3780
    },
    {
      "epoch": 0.6064,
      "grad_norm": 0.5442807674407959,
      "learning_rate": 0.0001848710569486602,
      "loss": 2.4021,
      "step": 3790
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.5266618132591248,
      "learning_rate": 0.0001847795763739425,
      "loss": 2.4545,
      "step": 3800
    },
    {
      "epoch": 0.608,
      "eval_bleu": 35.141165365927215,
      "eval_gen_len": 31.826,
      "eval_loss": 2.6193931102752686,
      "eval_runtime": 64.3533,
      "eval_samples_per_second": 15.539,
      "eval_steps_per_second": 0.979,
      "step": 3800
    },
    {
      "epoch": 0.6096,
      "grad_norm": 0.512222409248352,
      "learning_rate": 0.00018468784282938493,
      "loss": 2.4344,
      "step": 3810
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.5941186547279358,
      "learning_rate": 0.00018459585658870683,
      "loss": 2.4328,
      "step": 3820
    },
    {
      "epoch": 0.6128,
      "grad_norm": 0.5571104288101196,
      "learning_rate": 0.00018450361792638175,
      "loss": 2.4229,
      "step": 3830
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.5329973697662354,
      "learning_rate": 0.00018441112711763632,
      "loss": 2.4527,
      "step": 3840
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.5377981066703796,
      "learning_rate": 0.00018431838443844957,
      "loss": 2.4744,
      "step": 3850
    },
    {
      "epoch": 0.616,
      "eval_bleu": 35.18657759455454,
      "eval_gen_len": 31.772,
      "eval_loss": 2.61749529838562,
      "eval_runtime": 64.1103,
      "eval_samples_per_second": 15.598,
      "eval_steps_per_second": 0.983,
      "step": 3850
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.5709603428840637,
      "learning_rate": 0.0001842253901655521,
      "loss": 2.4454,
      "step": 3860
    },
    {
      "epoch": 0.6192,
      "grad_norm": 0.5525354146957397,
      "learning_rate": 0.00018413214457642515,
      "loss": 2.4245,
      "step": 3870
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.5782626867294312,
      "learning_rate": 0.00018403864794929993,
      "loss": 2.4422,
      "step": 3880
    },
    {
      "epoch": 0.6224,
      "grad_norm": 0.5542911291122437,
      "learning_rate": 0.0001839449005631567,
      "loss": 2.4329,
      "step": 3890
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.5432235598564148,
      "learning_rate": 0.00018385090269772389,
      "loss": 2.4201,
      "step": 3900
    },
    {
      "epoch": 0.624,
      "eval_bleu": 34.93491507628095,
      "eval_gen_len": 31.616,
      "eval_loss": 2.614806890487671,
      "eval_runtime": 63.6262,
      "eval_samples_per_second": 15.717,
      "eval_steps_per_second": 0.99,
      "step": 3900
    },
    {
      "epoch": 0.6256,
      "grad_norm": 0.5556415319442749,
      "learning_rate": 0.00018375665463347742,
      "loss": 2.446,
      "step": 3910
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.5488077998161316,
      "learning_rate": 0.00018366215665163965,
      "loss": 2.4274,
      "step": 3920
    },
    {
      "epoch": 0.6288,
      "grad_norm": 0.4977738559246063,
      "learning_rate": 0.0001835674090341788,
      "loss": 2.4242,
      "step": 3930
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.5575947761535645,
      "learning_rate": 0.00018347241206380778,
      "loss": 2.4562,
      "step": 3940
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.5465856790542603,
      "learning_rate": 0.0001833771660239837,
      "loss": 2.4207,
      "step": 3950
    },
    {
      "epoch": 0.632,
      "eval_bleu": 35.218695796324496,
      "eval_gen_len": 31.858,
      "eval_loss": 2.6155192852020264,
      "eval_runtime": 63.7826,
      "eval_samples_per_second": 15.678,
      "eval_steps_per_second": 0.988,
      "step": 3950
    },
    {
      "epoch": 0.6336,
      "grad_norm": 0.565631628036499,
      "learning_rate": 0.0001832816711989068,
      "loss": 2.4315,
      "step": 3960
    },
    {
      "epoch": 0.6352,
      "grad_norm": 0.5911774635314941,
      "learning_rate": 0.00018318592787351962,
      "loss": 2.429,
      "step": 3970
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.5384973287582397,
      "learning_rate": 0.00018308993633350628,
      "loss": 2.4442,
      "step": 3980
    },
    {
      "epoch": 0.6384,
      "grad_norm": 0.5581870675086975,
      "learning_rate": 0.00018299369686529138,
      "loss": 2.4119,
      "step": 3990
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5607624053955078,
      "learning_rate": 0.00018289720975603948,
      "loss": 2.4362,
      "step": 4000
    },
    {
      "epoch": 0.64,
      "eval_bleu": 35.46710947757396,
      "eval_gen_len": 31.666,
      "eval_loss": 2.61757755279541,
      "eval_runtime": 63.7799,
      "eval_samples_per_second": 15.679,
      "eval_steps_per_second": 0.988,
      "step": 4000
    },
    {
      "epoch": 0.6416,
      "grad_norm": 0.5160451531410217,
      "learning_rate": 0.00018280047529365396,
      "loss": 2.4444,
      "step": 4010
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.5417025685310364,
      "learning_rate": 0.0001827034937667763,
      "loss": 2.4383,
      "step": 4020
    },
    {
      "epoch": 0.6448,
      "grad_norm": 0.498138964176178,
      "learning_rate": 0.00018260626546478514,
      "loss": 2.4611,
      "step": 4030
    },
    {
      "epoch": 0.6464,
      "grad_norm": 0.5705128908157349,
      "learning_rate": 0.0001825087906777955,
      "loss": 2.4526,
      "step": 4040
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.5269201397895813,
      "learning_rate": 0.00018241106969665792,
      "loss": 2.4328,
      "step": 4050
    },
    {
      "epoch": 0.648,
      "eval_bleu": 35.34690604128494,
      "eval_gen_len": 31.721,
      "eval_loss": 2.618591785430908,
      "eval_runtime": 63.5498,
      "eval_samples_per_second": 15.736,
      "eval_steps_per_second": 0.991,
      "step": 4050
    },
    {
      "epoch": 0.6496,
      "grad_norm": 0.5657871961593628,
      "learning_rate": 0.00018231310281295745,
      "loss": 2.425,
      "step": 4060
    },
    {
      "epoch": 0.6512,
      "grad_norm": 0.5462732315063477,
      "learning_rate": 0.00018221489031901295,
      "loss": 2.4286,
      "step": 4070
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.5162791013717651,
      "learning_rate": 0.00018211643250787605,
      "loss": 2.4277,
      "step": 4080
    },
    {
      "epoch": 0.6544,
      "grad_norm": 0.5635241866111755,
      "learning_rate": 0.00018201772967333052,
      "loss": 2.4343,
      "step": 4090
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.5446639657020569,
      "learning_rate": 0.00018191878210989116,
      "loss": 2.4472,
      "step": 4100
    },
    {
      "epoch": 0.656,
      "eval_bleu": 35.2583346969922,
      "eval_gen_len": 31.847,
      "eval_loss": 2.6168673038482666,
      "eval_runtime": 64.1457,
      "eval_samples_per_second": 15.59,
      "eval_steps_per_second": 0.982,
      "step": 4100
    },
    {
      "epoch": 0.6576,
      "grad_norm": 0.5575298070907593,
      "learning_rate": 0.00018181959011280294,
      "loss": 2.4314,
      "step": 4110
    },
    {
      "epoch": 0.6592,
      "grad_norm": 0.5547745227813721,
      "learning_rate": 0.00018172015397804035,
      "loss": 2.4249,
      "step": 4120
    },
    {
      "epoch": 0.6608,
      "grad_norm": 0.5576786994934082,
      "learning_rate": 0.00018162047400230614,
      "loss": 2.4275,
      "step": 4130
    },
    {
      "epoch": 0.6624,
      "grad_norm": 0.535448431968689,
      "learning_rate": 0.00018152055048303086,
      "loss": 2.4377,
      "step": 4140
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.5666283369064331,
      "learning_rate": 0.00018142038371837162,
      "loss": 2.4308,
      "step": 4150
    },
    {
      "epoch": 0.664,
      "eval_bleu": 35.70169773654265,
      "eval_gen_len": 31.703,
      "eval_loss": 2.615108013153076,
      "eval_runtime": 63.818,
      "eval_samples_per_second": 15.67,
      "eval_steps_per_second": 0.987,
      "step": 4150
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.5548684000968933,
      "learning_rate": 0.00018131997400721135,
      "loss": 2.4092,
      "step": 4160
    },
    {
      "epoch": 0.6672,
      "grad_norm": 0.4821940064430237,
      "learning_rate": 0.00018121932164915795,
      "loss": 2.436,
      "step": 4170
    },
    {
      "epoch": 0.6688,
      "grad_norm": 0.5222958326339722,
      "learning_rate": 0.00018111842694454335,
      "loss": 2.4212,
      "step": 4180
    },
    {
      "epoch": 0.6704,
      "grad_norm": 0.5394180417060852,
      "learning_rate": 0.00018101729019442248,
      "loss": 2.4409,
      "step": 4190
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.5142242312431335,
      "learning_rate": 0.0001809159117005727,
      "loss": 2.4681,
      "step": 4200
    },
    {
      "epoch": 0.672,
      "eval_bleu": 35.2001202840066,
      "eval_gen_len": 31.768,
      "eval_loss": 2.614943265914917,
      "eval_runtime": 64.0014,
      "eval_samples_per_second": 15.625,
      "eval_steps_per_second": 0.984,
      "step": 4200
    },
    {
      "epoch": 0.6736,
      "grad_norm": 0.5661136507987976,
      "learning_rate": 0.0001808142917654925,
      "loss": 2.4898,
      "step": 4210
    },
    {
      "epoch": 0.6752,
      "grad_norm": 0.5049082636833191,
      "learning_rate": 0.00018071243069240093,
      "loss": 2.4223,
      "step": 4220
    },
    {
      "epoch": 0.6768,
      "grad_norm": 0.5246099233627319,
      "learning_rate": 0.0001806103287852365,
      "loss": 2.4604,
      "step": 4230
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.6055980324745178,
      "learning_rate": 0.00018050798634865634,
      "loss": 2.4675,
      "step": 4240
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5437787175178528,
      "learning_rate": 0.00018040540368803533,
      "loss": 2.44,
      "step": 4250
    },
    {
      "epoch": 0.68,
      "eval_bleu": 35.15931826818096,
      "eval_gen_len": 31.675,
      "eval_loss": 2.6143856048583984,
      "eval_runtime": 63.5282,
      "eval_samples_per_second": 15.741,
      "eval_steps_per_second": 0.992,
      "step": 4250
    },
    {
      "epoch": 0.6816,
      "grad_norm": 0.5639077425003052,
      "learning_rate": 0.00018030258110946504,
      "loss": 2.4438,
      "step": 4260
    },
    {
      "epoch": 0.6832,
      "grad_norm": 0.5047808289527893,
      "learning_rate": 0.0001801995189197531,
      "loss": 2.4116,
      "step": 4270
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.5256365537643433,
      "learning_rate": 0.00018009621742642184,
      "loss": 2.4474,
      "step": 4280
    },
    {
      "epoch": 0.6864,
      "grad_norm": 0.5543226003646851,
      "learning_rate": 0.00017999267693770792,
      "loss": 2.4481,
      "step": 4290
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.5384081602096558,
      "learning_rate": 0.00017988889776256092,
      "loss": 2.4451,
      "step": 4300
    },
    {
      "epoch": 0.688,
      "eval_bleu": 35.4298317979789,
      "eval_gen_len": 31.756,
      "eval_loss": 2.611999750137329,
      "eval_runtime": 63.1508,
      "eval_samples_per_second": 15.835,
      "eval_steps_per_second": 0.998,
      "step": 4300
    },
    {
      "epoch": 0.6896,
      "grad_norm": 0.5497207045555115,
      "learning_rate": 0.0001797848802106427,
      "loss": 2.4264,
      "step": 4310
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.5313152074813843,
      "learning_rate": 0.00017968062459232647,
      "loss": 2.4508,
      "step": 4320
    },
    {
      "epoch": 0.6928,
      "grad_norm": 0.5618687272071838,
      "learning_rate": 0.0001795761312186956,
      "loss": 2.4501,
      "step": 4330
    },
    {
      "epoch": 0.6944,
      "grad_norm": 0.5390526652336121,
      "learning_rate": 0.00017947140040154314,
      "loss": 2.4276,
      "step": 4340
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.5422683358192444,
      "learning_rate": 0.00017936643245337048,
      "loss": 2.4403,
      "step": 4350
    },
    {
      "epoch": 0.696,
      "eval_bleu": 35.20170157714726,
      "eval_gen_len": 31.765,
      "eval_loss": 2.6118853092193604,
      "eval_runtime": 64.1929,
      "eval_samples_per_second": 15.578,
      "eval_steps_per_second": 0.981,
      "step": 4350
    },
    {
      "epoch": 0.6976,
      "grad_norm": 0.5557370185852051,
      "learning_rate": 0.00017926122768738658,
      "loss": 2.4424,
      "step": 4360
    },
    {
      "epoch": 0.6992,
      "grad_norm": 0.5297425985336304,
      "learning_rate": 0.00017915578641750703,
      "loss": 2.4186,
      "step": 4370
    },
    {
      "epoch": 0.7008,
      "grad_norm": 0.5695915222167969,
      "learning_rate": 0.0001790501089583532,
      "loss": 2.4346,
      "step": 4380
    },
    {
      "epoch": 0.7024,
      "grad_norm": 0.5114157795906067,
      "learning_rate": 0.0001789441956252511,
      "loss": 2.4447,
      "step": 4390
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.5692060589790344,
      "learning_rate": 0.00017883804673423065,
      "loss": 2.4185,
      "step": 4400
    },
    {
      "epoch": 0.704,
      "eval_bleu": 35.373713429441004,
      "eval_gen_len": 31.708,
      "eval_loss": 2.610032320022583,
      "eval_runtime": 64.0574,
      "eval_samples_per_second": 15.611,
      "eval_steps_per_second": 0.983,
      "step": 4400
    },
    {
      "epoch": 0.7056,
      "grad_norm": 0.5314663648605347,
      "learning_rate": 0.00017873166260202455,
      "loss": 2.4139,
      "step": 4410
    },
    {
      "epoch": 0.7072,
      "grad_norm": 0.5486118197441101,
      "learning_rate": 0.00017862504354606751,
      "loss": 2.4317,
      "step": 4420
    },
    {
      "epoch": 0.7088,
      "grad_norm": 0.50159752368927,
      "learning_rate": 0.00017851818988449516,
      "loss": 2.4125,
      "step": 4430
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.5314662456512451,
      "learning_rate": 0.00017841110193614316,
      "loss": 2.4365,
      "step": 4440
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.5110848546028137,
      "learning_rate": 0.0001783037800205463,
      "loss": 2.439,
      "step": 4450
    },
    {
      "epoch": 0.712,
      "eval_bleu": 35.04063640303192,
      "eval_gen_len": 31.754,
      "eval_loss": 2.6123173236846924,
      "eval_runtime": 63.9647,
      "eval_samples_per_second": 15.634,
      "eval_steps_per_second": 0.985,
      "step": 4450
    },
    {
      "epoch": 0.7136,
      "grad_norm": 0.585841715335846,
      "learning_rate": 0.0001781962244579374,
      "loss": 2.4173,
      "step": 4460
    },
    {
      "epoch": 0.7152,
      "grad_norm": 0.5243849158287048,
      "learning_rate": 0.00017808843556924663,
      "loss": 2.4212,
      "step": 4470
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.5051359534263611,
      "learning_rate": 0.00017798041367610013,
      "loss": 2.4101,
      "step": 4480
    },
    {
      "epoch": 0.7184,
      "grad_norm": 0.5328106880187988,
      "learning_rate": 0.0001778721591008194,
      "loss": 2.4731,
      "step": 4490
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5181156396865845,
      "learning_rate": 0.00017776367216642034,
      "loss": 2.448,
      "step": 4500
    },
    {
      "epoch": 0.72,
      "eval_bleu": 35.23888213881162,
      "eval_gen_len": 31.757,
      "eval_loss": 2.6094906330108643,
      "eval_runtime": 63.7842,
      "eval_samples_per_second": 15.678,
      "eval_steps_per_second": 0.988,
      "step": 4500
    },
    {
      "epoch": 0.7216,
      "grad_norm": 0.5403249263763428,
      "learning_rate": 0.000177654953196612,
      "loss": 2.4374,
      "step": 4510
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.5610525608062744,
      "learning_rate": 0.00017754600251579586,
      "loss": 2.4421,
      "step": 4520
    },
    {
      "epoch": 0.7248,
      "grad_norm": 0.5002774596214294,
      "learning_rate": 0.0001774368204490649,
      "loss": 2.4434,
      "step": 4530
    },
    {
      "epoch": 0.7264,
      "grad_norm": 0.49036064743995667,
      "learning_rate": 0.00017732740732220224,
      "loss": 2.4047,
      "step": 4540
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.5371989011764526,
      "learning_rate": 0.00017721776346168078,
      "loss": 2.4587,
      "step": 4550
    },
    {
      "epoch": 0.728,
      "eval_bleu": 35.13328471660829,
      "eval_gen_len": 31.827,
      "eval_loss": 2.6111555099487305,
      "eval_runtime": 64.2028,
      "eval_samples_per_second": 15.576,
      "eval_steps_per_second": 0.981,
      "step": 4550
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.5322328209877014,
      "learning_rate": 0.0001771078891946617,
      "loss": 2.4392,
      "step": 4560
    },
    {
      "epoch": 0.7312,
      "grad_norm": 0.5560448169708252,
      "learning_rate": 0.00017699778484899366,
      "loss": 2.4299,
      "step": 4570
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.5169970989227295,
      "learning_rate": 0.000176887450753212,
      "loss": 2.4333,
      "step": 4580
    },
    {
      "epoch": 0.7344,
      "grad_norm": 0.5456804037094116,
      "learning_rate": 0.0001767768872365374,
      "loss": 2.4414,
      "step": 4590
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.5622116923332214,
      "learning_rate": 0.00017666609462887526,
      "loss": 2.4124,
      "step": 4600
    },
    {
      "epoch": 0.736,
      "eval_bleu": 35.337687021413494,
      "eval_gen_len": 31.753,
      "eval_loss": 2.6063599586486816,
      "eval_runtime": 64.2578,
      "eval_samples_per_second": 15.562,
      "eval_steps_per_second": 0.98,
      "step": 4600
    },
    {
      "epoch": 0.7376,
      "grad_norm": 0.5794228911399841,
      "learning_rate": 0.00017655507326081452,
      "loss": 2.4123,
      "step": 4610
    },
    {
      "epoch": 0.7392,
      "grad_norm": 0.509111225605011,
      "learning_rate": 0.00017644382346362666,
      "loss": 2.4076,
      "step": 4620
    },
    {
      "epoch": 0.7408,
      "grad_norm": 0.5542154908180237,
      "learning_rate": 0.00017633234556926474,
      "loss": 2.4303,
      "step": 4630
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.5605373978614807,
      "learning_rate": 0.00017622063991036256,
      "loss": 2.3955,
      "step": 4640
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.5136520862579346,
      "learning_rate": 0.00017610870682023335,
      "loss": 2.4456,
      "step": 4650
    },
    {
      "epoch": 0.744,
      "eval_bleu": 35.28973388892799,
      "eval_gen_len": 31.745,
      "eval_loss": 2.610311985015869,
      "eval_runtime": 63.9194,
      "eval_samples_per_second": 15.645,
      "eval_steps_per_second": 0.986,
      "step": 4650
    },
    {
      "epoch": 0.7456,
      "grad_norm": 0.5484238266944885,
      "learning_rate": 0.00017599654663286914,
      "loss": 2.4421,
      "step": 4660
    },
    {
      "epoch": 0.7472,
      "grad_norm": 0.5454878807067871,
      "learning_rate": 0.00017588415968293944,
      "loss": 2.4738,
      "step": 4670
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.5543761849403381,
      "learning_rate": 0.00017577154630579048,
      "loss": 2.4558,
      "step": 4680
    },
    {
      "epoch": 0.7504,
      "grad_norm": 0.5180754661560059,
      "learning_rate": 0.0001756587068374441,
      "loss": 2.4436,
      "step": 4690
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.5264847278594971,
      "learning_rate": 0.0001755456416145967,
      "loss": 2.4032,
      "step": 4700
    },
    {
      "epoch": 0.752,
      "eval_bleu": 35.17362811194407,
      "eval_gen_len": 31.771,
      "eval_loss": 2.611027717590332,
      "eval_runtime": 64.505,
      "eval_samples_per_second": 15.503,
      "eval_steps_per_second": 0.977,
      "step": 4700
    },
    {
      "epoch": 0.7536,
      "grad_norm": 0.6087058186531067,
      "learning_rate": 0.0001754323509746184,
      "loss": 2.4323,
      "step": 4710
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.5507537722587585,
      "learning_rate": 0.00017531883525555183,
      "loss": 2.4406,
      "step": 4720
    },
    {
      "epoch": 0.7568,
      "grad_norm": 0.5551027059555054,
      "learning_rate": 0.0001752050947961113,
      "loss": 2.4385,
      "step": 4730
    },
    {
      "epoch": 0.7584,
      "grad_norm": 0.6375995874404907,
      "learning_rate": 0.0001750911299356817,
      "loss": 2.4694,
      "step": 4740
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5414566397666931,
      "learning_rate": 0.00017497694101431744,
      "loss": 2.4171,
      "step": 4750
    },
    {
      "epoch": 0.76,
      "eval_bleu": 35.05311985047617,
      "eval_gen_len": 31.855,
      "eval_loss": 2.6093356609344482,
      "eval_runtime": 63.9582,
      "eval_samples_per_second": 15.635,
      "eval_steps_per_second": 0.985,
      "step": 4750
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.5798640251159668,
      "learning_rate": 0.0001748625283727416,
      "loss": 2.4346,
      "step": 4760
    },
    {
      "epoch": 0.7632,
      "grad_norm": 0.5178951025009155,
      "learning_rate": 0.00017474789235234469,
      "loss": 2.4059,
      "step": 4770
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.4960543215274811,
      "learning_rate": 0.0001746330332951838,
      "loss": 2.4053,
      "step": 4780
    },
    {
      "epoch": 0.7664,
      "grad_norm": 0.5122098326683044,
      "learning_rate": 0.00017451795154398156,
      "loss": 2.4171,
      "step": 4790
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.5238186717033386,
      "learning_rate": 0.00017440264744212507,
      "loss": 2.4483,
      "step": 4800
    },
    {
      "epoch": 0.768,
      "eval_bleu": 34.9534907311235,
      "eval_gen_len": 31.696,
      "eval_loss": 2.6117591857910156,
      "eval_runtime": 64.0006,
      "eval_samples_per_second": 15.625,
      "eval_steps_per_second": 0.984,
      "step": 4800
    },
    {
      "epoch": 0.7696,
      "grad_norm": 0.5388983488082886,
      "learning_rate": 0.0001742871213336649,
      "loss": 2.4144,
      "step": 4810
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.5386590957641602,
      "learning_rate": 0.000174171373563314,
      "loss": 2.4228,
      "step": 4820
    },
    {
      "epoch": 0.7728,
      "grad_norm": 0.5526246428489685,
      "learning_rate": 0.00017405540447644677,
      "loss": 2.4048,
      "step": 4830
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.5575724244117737,
      "learning_rate": 0.00017393921441909797,
      "loss": 2.4405,
      "step": 4840
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.5229154825210571,
      "learning_rate": 0.00017382280373796175,
      "loss": 2.4386,
      "step": 4850
    },
    {
      "epoch": 0.776,
      "eval_bleu": 34.79706264429799,
      "eval_gen_len": 31.8,
      "eval_loss": 2.612346649169922,
      "eval_runtime": 64.3307,
      "eval_samples_per_second": 15.545,
      "eval_steps_per_second": 0.979,
      "step": 4850
    },
    {
      "epoch": 0.7776,
      "grad_norm": 0.5372157692909241,
      "learning_rate": 0.00017370617278039053,
      "loss": 2.4486,
      "step": 4860
    },
    {
      "epoch": 0.7792,
      "grad_norm": 0.566862165927887,
      "learning_rate": 0.00017358932189439404,
      "loss": 2.4161,
      "step": 4870
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.5583751797676086,
      "learning_rate": 0.00017347225142863812,
      "loss": 2.4441,
      "step": 4880
    },
    {
      "epoch": 0.7824,
      "grad_norm": 0.5088236331939697,
      "learning_rate": 0.00017335496173244392,
      "loss": 2.4351,
      "step": 4890
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.5399400591850281,
      "learning_rate": 0.0001732374531557868,
      "loss": 2.422,
      "step": 4900
    },
    {
      "epoch": 0.784,
      "eval_bleu": 35.22418192836499,
      "eval_gen_len": 31.694,
      "eval_loss": 2.6091182231903076,
      "eval_runtime": 64.1499,
      "eval_samples_per_second": 15.588,
      "eval_steps_per_second": 0.982,
      "step": 4900
    },
    {
      "epoch": 0.7856,
      "grad_norm": 0.5372832417488098,
      "learning_rate": 0.00017311972604929502,
      "loss": 2.4106,
      "step": 4910
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.5181683897972107,
      "learning_rate": 0.00017300178076424914,
      "loss": 2.4001,
      "step": 4920
    },
    {
      "epoch": 0.7888,
      "grad_norm": 0.5016700029373169,
      "learning_rate": 0.00017288361765258053,
      "loss": 2.427,
      "step": 4930
    },
    {
      "epoch": 0.7904,
      "grad_norm": 0.5381554365158081,
      "learning_rate": 0.00017276523706687065,
      "loss": 2.4263,
      "step": 4940
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.5282131433486938,
      "learning_rate": 0.00017264663936034986,
      "loss": 2.4401,
      "step": 4950
    },
    {
      "epoch": 0.792,
      "eval_bleu": 35.04415366852934,
      "eval_gen_len": 31.652,
      "eval_loss": 2.6127867698669434,
      "eval_runtime": 63.9096,
      "eval_samples_per_second": 15.647,
      "eval_steps_per_second": 0.986,
      "step": 4950
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.5284457206726074,
      "learning_rate": 0.0001725278248868963,
      "loss": 2.4145,
      "step": 4960
    },
    {
      "epoch": 0.7952,
      "grad_norm": 0.5911382436752319,
      "learning_rate": 0.00017240879400103496,
      "loss": 2.4295,
      "step": 4970
    },
    {
      "epoch": 0.7968,
      "grad_norm": 0.5419144034385681,
      "learning_rate": 0.00017228954705793655,
      "loss": 2.4621,
      "step": 4980
    },
    {
      "epoch": 0.7984,
      "grad_norm": 0.5561596751213074,
      "learning_rate": 0.0001721700844134166,
      "loss": 2.4186,
      "step": 4990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5376057028770447,
      "learning_rate": 0.000172050406423934,
      "loss": 2.4065,
      "step": 5000
    },
    {
      "epoch": 0.8,
      "eval_bleu": 35.23176549476275,
      "eval_gen_len": 31.693,
      "eval_loss": 2.611436367034912,
      "eval_runtime": 63.6463,
      "eval_samples_per_second": 15.712,
      "eval_steps_per_second": 0.99,
      "step": 5000
    },
    {
      "epoch": 0.8016,
      "grad_norm": 0.5232565999031067,
      "learning_rate": 0.0001719305134465904,
      "loss": 2.4381,
      "step": 5010
    },
    {
      "epoch": 0.8032,
      "grad_norm": 0.5215950012207031,
      "learning_rate": 0.00017181040583912896,
      "loss": 2.4508,
      "step": 5020
    },
    {
      "epoch": 0.8048,
      "grad_norm": 0.5580304265022278,
      "learning_rate": 0.00017169008395993306,
      "loss": 2.419,
      "step": 5030
    },
    {
      "epoch": 0.8064,
      "grad_norm": 0.5333212018013,
      "learning_rate": 0.0001715695481680257,
      "loss": 2.453,
      "step": 5040
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.5473572015762329,
      "learning_rate": 0.00017144879882306788,
      "loss": 2.4449,
      "step": 5050
    },
    {
      "epoch": 0.808,
      "eval_bleu": 34.883744650008836,
      "eval_gen_len": 31.883,
      "eval_loss": 2.6125526428222656,
      "eval_runtime": 63.8183,
      "eval_samples_per_second": 15.669,
      "eval_steps_per_second": 0.987,
      "step": 5050
    },
    {
      "epoch": 0.8096,
      "grad_norm": 0.5387657880783081,
      "learning_rate": 0.00017132783628535808,
      "loss": 2.4268,
      "step": 5060
    },
    {
      "epoch": 0.8112,
      "grad_norm": 0.5473445653915405,
      "learning_rate": 0.00017120666091583077,
      "loss": 2.4221,
      "step": 5070
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.5558676719665527,
      "learning_rate": 0.0001710852730760555,
      "loss": 2.3904,
      "step": 5080
    },
    {
      "epoch": 0.8144,
      "grad_norm": 0.546021044254303,
      "learning_rate": 0.0001709636731282358,
      "loss": 2.4096,
      "step": 5090
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.5690796971321106,
      "learning_rate": 0.00017084186143520808,
      "loss": 2.4529,
      "step": 5100
    },
    {
      "epoch": 0.816,
      "eval_bleu": 35.49113787458676,
      "eval_gen_len": 31.666,
      "eval_loss": 2.609800338745117,
      "eval_runtime": 63.4326,
      "eval_samples_per_second": 15.765,
      "eval_steps_per_second": 0.993,
      "step": 5100
    },
    {
      "epoch": 0.8176,
      "grad_norm": 0.5667163133621216,
      "learning_rate": 0.00017071983836044064,
      "loss": 2.458,
      "step": 5110
    },
    {
      "epoch": 0.8192,
      "grad_norm": 0.5125985741615295,
      "learning_rate": 0.00017059760426803248,
      "loss": 2.465,
      "step": 5120
    },
    {
      "epoch": 0.8208,
      "grad_norm": 0.5346309542655945,
      "learning_rate": 0.0001704751595227122,
      "loss": 2.4384,
      "step": 5130
    },
    {
      "epoch": 0.8224,
      "grad_norm": 0.5156815052032471,
      "learning_rate": 0.00017035250448983695,
      "loss": 2.4007,
      "step": 5140
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.5291903018951416,
      "learning_rate": 0.00017022963953539143,
      "loss": 2.4361,
      "step": 5150
    },
    {
      "epoch": 0.824,
      "eval_bleu": 35.025710771217,
      "eval_gen_len": 31.676,
      "eval_loss": 2.6088080406188965,
      "eval_runtime": 64.002,
      "eval_samples_per_second": 15.625,
      "eval_steps_per_second": 0.984,
      "step": 5150
    },
    {
      "epoch": 0.8256,
      "grad_norm": 0.4795572757720947,
      "learning_rate": 0.00017010656502598664,
      "loss": 2.4452,
      "step": 5160
    },
    {
      "epoch": 0.8272,
      "grad_norm": 0.5535340905189514,
      "learning_rate": 0.00016998328132885893,
      "loss": 2.4243,
      "step": 5170
    },
    {
      "epoch": 0.8288,
      "grad_norm": 0.5588687658309937,
      "learning_rate": 0.0001698597888118688,
      "loss": 2.4244,
      "step": 5180
    },
    {
      "epoch": 0.8304,
      "grad_norm": 0.5417929887771606,
      "learning_rate": 0.0001697360878434998,
      "loss": 2.422,
      "step": 5190
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.5162193775177002,
      "learning_rate": 0.00016961217879285756,
      "loss": 2.449,
      "step": 5200
    },
    {
      "epoch": 0.832,
      "eval_bleu": 35.03672056596206,
      "eval_gen_len": 31.55,
      "eval_loss": 2.6118876934051514,
      "eval_runtime": 62.7915,
      "eval_samples_per_second": 15.926,
      "eval_steps_per_second": 1.003,
      "step": 5200
    },
    {
      "epoch": 0.8336,
      "grad_norm": 0.5436781644821167,
      "learning_rate": 0.00016948806202966846,
      "loss": 2.4318,
      "step": 5210
    },
    {
      "epoch": 0.8352,
      "grad_norm": 0.5231519341468811,
      "learning_rate": 0.00016936373792427877,
      "loss": 2.4506,
      "step": 5220
    },
    {
      "epoch": 0.8368,
      "grad_norm": 0.5465768575668335,
      "learning_rate": 0.00016923920684765346,
      "loss": 2.4474,
      "step": 5230
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.5053412318229675,
      "learning_rate": 0.000169114469171375,
      "loss": 2.4388,
      "step": 5240
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.4962049126625061,
      "learning_rate": 0.00016898952526764232,
      "loss": 2.4296,
      "step": 5250
    },
    {
      "epoch": 0.84,
      "eval_bleu": 35.07496785518001,
      "eval_gen_len": 31.601,
      "eval_loss": 2.6104280948638916,
      "eval_runtime": 63.88,
      "eval_samples_per_second": 15.654,
      "eval_steps_per_second": 0.986,
      "step": 5250
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.5772114992141724,
      "learning_rate": 0.00016886437550926977,
      "loss": 2.4163,
      "step": 5260
    },
    {
      "epoch": 0.8432,
      "grad_norm": 0.556808352470398,
      "learning_rate": 0.00016873902026968586,
      "loss": 2.4412,
      "step": 5270
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.5467678308486938,
      "learning_rate": 0.00016861345992293228,
      "loss": 2.4282,
      "step": 5280
    },
    {
      "epoch": 0.8464,
      "grad_norm": 0.5438292026519775,
      "learning_rate": 0.00016848769484366277,
      "loss": 2.4411,
      "step": 5290
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.5742560625076294,
      "learning_rate": 0.0001683617254071418,
      "loss": 2.4276,
      "step": 5300
    },
    {
      "epoch": 0.848,
      "eval_bleu": 34.96969396773142,
      "eval_gen_len": 32.004,
      "eval_loss": 2.6100497245788574,
      "eval_runtime": 67.9041,
      "eval_samples_per_second": 14.727,
      "eval_steps_per_second": 0.928,
      "step": 5300
    },
    {
      "epoch": 0.8496,
      "grad_norm": 0.5367726683616638,
      "learning_rate": 0.00016823555198924387,
      "loss": 2.4284,
      "step": 5310
    },
    {
      "epoch": 0.8512,
      "grad_norm": 0.5243744850158691,
      "learning_rate": 0.00016810917496645184,
      "loss": 2.4252,
      "step": 5320
    },
    {
      "epoch": 0.8528,
      "grad_norm": 0.5299890041351318,
      "learning_rate": 0.00016798259471585632,
      "loss": 2.4439,
      "step": 5330
    },
    {
      "epoch": 0.8544,
      "grad_norm": 0.5614192485809326,
      "learning_rate": 0.0001678558116151542,
      "loss": 2.4401,
      "step": 5340
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.5695623159408569,
      "learning_rate": 0.00016772882604264769,
      "loss": 2.4157,
      "step": 5350
    },
    {
      "epoch": 0.856,
      "eval_bleu": 35.2946832428957,
      "eval_gen_len": 31.617,
      "eval_loss": 2.6084816455841064,
      "eval_runtime": 63.5195,
      "eval_samples_per_second": 15.743,
      "eval_steps_per_second": 0.992,
      "step": 5350
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.492206335067749,
      "learning_rate": 0.00016760163837724315,
      "loss": 2.4205,
      "step": 5360
    },
    {
      "epoch": 0.8592,
      "grad_norm": 0.4930073022842407,
      "learning_rate": 0.00016747424899844995,
      "loss": 2.4348,
      "step": 5370
    },
    {
      "epoch": 0.8608,
      "grad_norm": 0.5409738421440125,
      "learning_rate": 0.00016734665828637937,
      "loss": 2.4442,
      "step": 5380
    },
    {
      "epoch": 0.8624,
      "grad_norm": 0.5381169319152832,
      "learning_rate": 0.00016721886662174335,
      "loss": 2.4188,
      "step": 5390
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.5229994058609009,
      "learning_rate": 0.00016709087438585352,
      "loss": 2.4341,
      "step": 5400
    },
    {
      "epoch": 0.864,
      "eval_bleu": 34.99136034210376,
      "eval_gen_len": 31.616,
      "eval_loss": 2.6103200912475586,
      "eval_runtime": 63.4965,
      "eval_samples_per_second": 15.749,
      "eval_steps_per_second": 0.992,
      "step": 5400
    },
    {
      "epoch": 0.8656,
      "grad_norm": 0.5524007678031921,
      "learning_rate": 0.00016696268196062,
      "loss": 2.428,
      "step": 5410
    },
    {
      "epoch": 0.8672,
      "grad_norm": 0.5289884805679321,
      "learning_rate": 0.0001668342897285502,
      "loss": 2.4758,
      "step": 5420
    },
    {
      "epoch": 0.8688,
      "grad_norm": 0.5530375242233276,
      "learning_rate": 0.00016670569807274768,
      "loss": 2.4446,
      "step": 5430
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.5318901538848877,
      "learning_rate": 0.0001665769073769112,
      "loss": 2.4098,
      "step": 5440
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.5321178436279297,
      "learning_rate": 0.00016644791802533323,
      "loss": 2.4353,
      "step": 5450
    },
    {
      "epoch": 0.872,
      "eval_bleu": 35.23833667464332,
      "eval_gen_len": 31.651,
      "eval_loss": 2.6096041202545166,
      "eval_runtime": 63.369,
      "eval_samples_per_second": 15.781,
      "eval_steps_per_second": 0.994,
      "step": 5450
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.5870377421379089,
      "learning_rate": 0.00016631873040289923,
      "loss": 2.4292,
      "step": 5460
    },
    {
      "epoch": 0.8752,
      "grad_norm": 0.5587865114212036,
      "learning_rate": 0.00016618934489508606,
      "loss": 2.4118,
      "step": 5470
    },
    {
      "epoch": 0.8768,
      "grad_norm": 0.5816035270690918,
      "learning_rate": 0.00016605976188796112,
      "loss": 2.4623,
      "step": 5480
    },
    {
      "epoch": 0.8784,
      "grad_norm": 0.5105233788490295,
      "learning_rate": 0.0001659299817681812,
      "loss": 2.442,
      "step": 5490
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5404421091079712,
      "learning_rate": 0.00016580000492299112,
      "loss": 2.4188,
      "step": 5500
    },
    {
      "epoch": 0.88,
      "eval_bleu": 34.77389889666207,
      "eval_gen_len": 32.047,
      "eval_loss": 2.6092121601104736,
      "eval_runtime": 67.2588,
      "eval_samples_per_second": 14.868,
      "eval_steps_per_second": 0.937,
      "step": 5500
    },
    {
      "epoch": 0.8816,
      "grad_norm": 0.5382159948348999,
      "learning_rate": 0.00016566983174022272,
      "loss": 2.4199,
      "step": 5510
    },
    {
      "epoch": 0.8832,
      "grad_norm": 0.5741884112358093,
      "learning_rate": 0.0001655394626082938,
      "loss": 2.4078,
      "step": 5520
    },
    {
      "epoch": 0.8848,
      "grad_norm": 0.5838706493377686,
      "learning_rate": 0.00016540889791620664,
      "loss": 2.4185,
      "step": 5530
    },
    {
      "epoch": 0.8864,
      "grad_norm": 0.5278031826019287,
      "learning_rate": 0.00016527813805354728,
      "loss": 2.4397,
      "step": 5540
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.5439137816429138,
      "learning_rate": 0.00016514718341048394,
      "loss": 2.4234,
      "step": 5550
    },
    {
      "epoch": 0.888,
      "eval_bleu": 35.30629260042377,
      "eval_gen_len": 31.663,
      "eval_loss": 2.607145071029663,
      "eval_runtime": 63.8755,
      "eval_samples_per_second": 15.655,
      "eval_steps_per_second": 0.986,
      "step": 5550
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.5801452994346619,
      "learning_rate": 0.00016501603437776608,
      "loss": 2.4351,
      "step": 5560
    },
    {
      "epoch": 0.8912,
      "grad_norm": 0.5555487275123596,
      "learning_rate": 0.00016488469134672324,
      "loss": 2.4174,
      "step": 5570
    },
    {
      "epoch": 0.8928,
      "grad_norm": 0.577958881855011,
      "learning_rate": 0.00016475315470926378,
      "loss": 2.4325,
      "step": 5580
    },
    {
      "epoch": 0.8944,
      "grad_norm": 0.5281853675842285,
      "learning_rate": 0.00016462142485787378,
      "loss": 2.4113,
      "step": 5590
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.4901077449321747,
      "learning_rate": 0.0001644895021856158,
      "loss": 2.4355,
      "step": 5600
    },
    {
      "epoch": 0.896,
      "eval_bleu": 34.8644463136623,
      "eval_gen_len": 31.76,
      "eval_loss": 2.6095919609069824,
      "eval_runtime": 63.807,
      "eval_samples_per_second": 15.672,
      "eval_steps_per_second": 0.987,
      "step": 5600
    },
    {
      "epoch": 0.8976,
      "grad_norm": 0.5225483775138855,
      "learning_rate": 0.00016435738708612776,
      "loss": 2.4238,
      "step": 5610
    },
    {
      "epoch": 0.8992,
      "grad_norm": 0.5196423530578613,
      "learning_rate": 0.0001642250799536218,
      "loss": 2.4188,
      "step": 5620
    },
    {
      "epoch": 0.9008,
      "grad_norm": 0.5380530953407288,
      "learning_rate": 0.00016409258118288303,
      "loss": 2.4231,
      "step": 5630
    },
    {
      "epoch": 0.9024,
      "grad_norm": 0.5564432144165039,
      "learning_rate": 0.00016395989116926835,
      "loss": 2.4497,
      "step": 5640
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.5058199167251587,
      "learning_rate": 0.00016382701030870535,
      "loss": 2.4317,
      "step": 5650
    },
    {
      "epoch": 0.904,
      "eval_bleu": 34.748563988565174,
      "eval_gen_len": 31.665,
      "eval_loss": 2.6090645790100098,
      "eval_runtime": 64.4192,
      "eval_samples_per_second": 15.523,
      "eval_steps_per_second": 0.978,
      "step": 5650
    },
    {
      "epoch": 0.9056,
      "grad_norm": 0.4964121878147125,
      "learning_rate": 0.00016369393899769104,
      "loss": 2.4362,
      "step": 5660
    },
    {
      "epoch": 0.9072,
      "grad_norm": 0.5116639733314514,
      "learning_rate": 0.00016356067763329075,
      "loss": 2.4224,
      "step": 5670
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.551900327205658,
      "learning_rate": 0.00016342722661313682,
      "loss": 2.4101,
      "step": 5680
    },
    {
      "epoch": 0.9104,
      "grad_norm": 0.4985223412513733,
      "learning_rate": 0.00016329358633542765,
      "loss": 2.4357,
      "step": 5690
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.5753145217895508,
      "learning_rate": 0.00016315975719892616,
      "loss": 2.4318,
      "step": 5700
    },
    {
      "epoch": 0.912,
      "eval_bleu": 35.12551354757694,
      "eval_gen_len": 31.766,
      "eval_loss": 2.609954357147217,
      "eval_runtime": 64.0643,
      "eval_samples_per_second": 15.609,
      "eval_steps_per_second": 0.983,
      "step": 5700
    },
    {
      "epoch": 0.9136,
      "grad_norm": 0.556428849697113,
      "learning_rate": 0.00016302573960295892,
      "loss": 2.4076,
      "step": 5710
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.5028076171875,
      "learning_rate": 0.00016289153394741484,
      "loss": 2.4139,
      "step": 5720
    },
    {
      "epoch": 0.9168,
      "grad_norm": 0.49126073718070984,
      "learning_rate": 0.00016275714063274395,
      "loss": 2.4147,
      "step": 5730
    },
    {
      "epoch": 0.9184,
      "grad_norm": 0.5294412970542908,
      "learning_rate": 0.00016262256005995614,
      "loss": 2.4098,
      "step": 5740
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5156711935997009,
      "learning_rate": 0.00016248779263062016,
      "loss": 2.4152,
      "step": 5750
    },
    {
      "epoch": 0.92,
      "eval_bleu": 35.173702550885295,
      "eval_gen_len": 31.761,
      "eval_loss": 2.60786509513855,
      "eval_runtime": 63.6665,
      "eval_samples_per_second": 15.707,
      "eval_steps_per_second": 0.99,
      "step": 5750
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.5617889165878296,
      "learning_rate": 0.00016235283874686238,
      "loss": 2.4423,
      "step": 5760
    },
    {
      "epoch": 0.9232,
      "grad_norm": 0.592781662940979,
      "learning_rate": 0.0001622176988113653,
      "loss": 2.4565,
      "step": 5770
    },
    {
      "epoch": 0.9248,
      "grad_norm": 0.5535364151000977,
      "learning_rate": 0.00016208237322736676,
      "loss": 2.4091,
      "step": 5780
    },
    {
      "epoch": 0.9264,
      "grad_norm": 0.5574116706848145,
      "learning_rate": 0.00016194686239865845,
      "loss": 2.4378,
      "step": 5790
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.6223654747009277,
      "learning_rate": 0.00016181116672958488,
      "loss": 2.4117,
      "step": 5800
    },
    {
      "epoch": 0.928,
      "eval_bleu": 35.15238696612909,
      "eval_gen_len": 31.628,
      "eval_loss": 2.6109671592712402,
      "eval_runtime": 63.9418,
      "eval_samples_per_second": 15.639,
      "eval_steps_per_second": 0.985,
      "step": 5800
    },
    {
      "epoch": 0.9296,
      "grad_norm": 0.5125978589057922,
      "learning_rate": 0.00016167528662504205,
      "loss": 2.4267,
      "step": 5810
    },
    {
      "epoch": 0.9312,
      "grad_norm": 0.5439479351043701,
      "learning_rate": 0.0001615392224904762,
      "loss": 2.4399,
      "step": 5820
    },
    {
      "epoch": 0.9328,
      "grad_norm": 0.5724326372146606,
      "learning_rate": 0.0001614029747318829,
      "loss": 2.4158,
      "step": 5830
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.5581102967262268,
      "learning_rate": 0.00016126654375580546,
      "loss": 2.4236,
      "step": 5840
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.5024745464324951,
      "learning_rate": 0.00016112992996933394,
      "loss": 2.4367,
      "step": 5850
    },
    {
      "epoch": 0.936,
      "eval_bleu": 34.759703959747675,
      "eval_gen_len": 31.84,
      "eval_loss": 2.6104400157928467,
      "eval_runtime": 63.9097,
      "eval_samples_per_second": 15.647,
      "eval_steps_per_second": 0.986,
      "step": 5850
    },
    {
      "epoch": 0.9376,
      "grad_norm": 0.5249859094619751,
      "learning_rate": 0.00016099313378010384,
      "loss": 2.4389,
      "step": 5860
    },
    {
      "epoch": 0.9392,
      "grad_norm": 0.5750454068183899,
      "learning_rate": 0.00016085615559629498,
      "loss": 2.4083,
      "step": 5870
    },
    {
      "epoch": 0.9408,
      "grad_norm": 0.5906510949134827,
      "learning_rate": 0.00016071899582663024,
      "loss": 2.4351,
      "step": 5880
    },
    {
      "epoch": 0.9424,
      "grad_norm": 0.5483089685440063,
      "learning_rate": 0.0001605816548803742,
      "loss": 2.4314,
      "step": 5890
    },
    {
      "epoch": 0.944,
      "grad_norm": 12.345478057861328,
      "learning_rate": 0.00016044413316733223,
      "loss": 2.4435,
      "step": 5900
    },
    {
      "epoch": 0.944,
      "eval_bleu": 34.74254775971118,
      "eval_gen_len": 31.831,
      "eval_loss": 2.60806941986084,
      "eval_runtime": 63.5976,
      "eval_samples_per_second": 15.724,
      "eval_steps_per_second": 0.991,
      "step": 5900
    },
    {
      "epoch": 0.9456,
      "grad_norm": 0.520046055316925,
      "learning_rate": 0.00016030643109784889,
      "loss": 2.4177,
      "step": 5910
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.5648034811019897,
      "learning_rate": 0.000160168549082807,
      "loss": 2.4496,
      "step": 5920
    },
    {
      "epoch": 0.9488,
      "grad_norm": 0.5703719854354858,
      "learning_rate": 0.00016003048753362637,
      "loss": 2.411,
      "step": 5930
    },
    {
      "epoch": 0.9504,
      "grad_norm": 0.5618353486061096,
      "learning_rate": 0.0001598922468622624,
      "loss": 2.4815,
      "step": 5940
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.5208358764648438,
      "learning_rate": 0.000159753827481205,
      "loss": 2.4309,
      "step": 5950
    },
    {
      "epoch": 0.952,
      "eval_bleu": 34.67934546802746,
      "eval_gen_len": 31.823,
      "eval_loss": 2.6135520935058594,
      "eval_runtime": 63.8186,
      "eval_samples_per_second": 15.669,
      "eval_steps_per_second": 0.987,
      "step": 5950
    },
    {
      "epoch": 0.9536,
      "grad_norm": 1.1849641799926758,
      "learning_rate": 0.00015961522980347735,
      "loss": 2.4073,
      "step": 5960
    },
    {
      "epoch": 0.9552,
      "grad_norm": 0.5403069853782654,
      "learning_rate": 0.00015947645424263458,
      "loss": 2.4616,
      "step": 5970
    },
    {
      "epoch": 0.9568,
      "grad_norm": 0.5230897068977356,
      "learning_rate": 0.0001593375012127627,
      "loss": 2.4284,
      "step": 5980
    },
    {
      "epoch": 0.9584,
      "grad_norm": 0.57648104429245,
      "learning_rate": 0.00015919837112847714,
      "loss": 2.4099,
      "step": 5990
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5571533441543579,
      "learning_rate": 0.00015905906440492177,
      "loss": 2.4434,
      "step": 6000
    },
    {
      "epoch": 0.96,
      "eval_bleu": 35.16943071211566,
      "eval_gen_len": 31.82,
      "eval_loss": 2.608447313308716,
      "eval_runtime": 63.8596,
      "eval_samples_per_second": 15.659,
      "eval_steps_per_second": 0.987,
      "step": 6000
    },
    {
      "epoch": 0.9616,
      "grad_norm": 0.5075969099998474,
      "learning_rate": 0.0001589195814577674,
      "loss": 2.4175,
      "step": 6010
    },
    {
      "epoch": 0.9632,
      "grad_norm": 0.5383301377296448,
      "learning_rate": 0.00015877992270321075,
      "loss": 2.4296,
      "step": 6020
    },
    {
      "epoch": 0.9648,
      "grad_norm": 0.5367223620414734,
      "learning_rate": 0.00015864008855797303,
      "loss": 2.4175,
      "step": 6030
    },
    {
      "epoch": 0.9664,
      "grad_norm": 0.542026698589325,
      "learning_rate": 0.0001585000794392989,
      "loss": 2.4083,
      "step": 6040
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.5722491145133972,
      "learning_rate": 0.00015835989576495506,
      "loss": 2.4193,
      "step": 6050
    },
    {
      "epoch": 0.968,
      "eval_bleu": 35.029937516258265,
      "eval_gen_len": 31.613,
      "eval_loss": 2.6075148582458496,
      "eval_runtime": 63.6567,
      "eval_samples_per_second": 15.709,
      "eval_steps_per_second": 0.99,
      "step": 6050
    },
    {
      "epoch": 0.9696,
      "grad_norm": 0.5346860885620117,
      "learning_rate": 0.00015821953795322905,
      "loss": 2.4399,
      "step": 6060
    },
    {
      "epoch": 0.9712,
      "grad_norm": 0.5289663672447205,
      "learning_rate": 0.00015807900642292807,
      "loss": 2.4229,
      "step": 6070
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.5361405611038208,
      "learning_rate": 0.00015793830159337757,
      "loss": 2.4449,
      "step": 6080
    },
    {
      "epoch": 0.9744,
      "grad_norm": 0.49037474393844604,
      "learning_rate": 0.00015779742388442015,
      "loss": 2.4222,
      "step": 6090
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.5703381299972534,
      "learning_rate": 0.00015765637371641434,
      "loss": 2.4362,
      "step": 6100
    },
    {
      "epoch": 0.976,
      "eval_bleu": 35.12024362468302,
      "eval_gen_len": 31.78,
      "eval_loss": 2.6102731227874756,
      "eval_runtime": 63.9594,
      "eval_samples_per_second": 15.635,
      "eval_steps_per_second": 0.985,
      "step": 6100
    },
    {
      "epoch": 0.9776,
      "grad_norm": 0.5458482503890991,
      "learning_rate": 0.00015751515151023307,
      "loss": 2.4421,
      "step": 6110
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.5564740300178528,
      "learning_rate": 0.00015737375768726282,
      "loss": 2.4143,
      "step": 6120
    },
    {
      "epoch": 0.9808,
      "grad_norm": 0.5564168691635132,
      "learning_rate": 0.00015723219266940201,
      "loss": 2.4332,
      "step": 6130
    },
    {
      "epoch": 0.9824,
      "grad_norm": 0.527489185333252,
      "learning_rate": 0.00015709045687905992,
      "loss": 2.4307,
      "step": 6140
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.5372986793518066,
      "learning_rate": 0.0001569485507391554,
      "loss": 2.4307,
      "step": 6150
    },
    {
      "epoch": 0.984,
      "eval_bleu": 34.95508773053088,
      "eval_gen_len": 31.71,
      "eval_loss": 2.607701301574707,
      "eval_runtime": 64.3153,
      "eval_samples_per_second": 15.548,
      "eval_steps_per_second": 0.98,
      "step": 6150
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.5239235162734985,
      "learning_rate": 0.00015680647467311557,
      "loss": 2.4269,
      "step": 6160
    },
    {
      "epoch": 0.9872,
      "grad_norm": 0.49101948738098145,
      "learning_rate": 0.00015666422910487466,
      "loss": 2.4014,
      "step": 6170
    },
    {
      "epoch": 0.9888,
      "grad_norm": 0.5197691917419434,
      "learning_rate": 0.00015652181445887254,
      "loss": 2.4194,
      "step": 6180
    },
    {
      "epoch": 0.9904,
      "grad_norm": 0.593239426612854,
      "learning_rate": 0.00015637923116005372,
      "loss": 2.4346,
      "step": 6190
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.5236043930053711,
      "learning_rate": 0.00015623647963386583,
      "loss": 2.4059,
      "step": 6200
    },
    {
      "epoch": 0.992,
      "eval_bleu": 34.97859422126264,
      "eval_gen_len": 31.687,
      "eval_loss": 2.608015775680542,
      "eval_runtime": 63.7852,
      "eval_samples_per_second": 15.678,
      "eval_steps_per_second": 0.988,
      "step": 6200
    },
    {
      "epoch": 0.9936,
      "grad_norm": 0.5427815914154053,
      "learning_rate": 0.00015609356030625853,
      "loss": 2.4123,
      "step": 6210
    },
    {
      "epoch": 0.9952,
      "grad_norm": 0.5451362729072571,
      "learning_rate": 0.00015595047360368217,
      "loss": 2.4369,
      "step": 6220
    },
    {
      "epoch": 0.9968,
      "grad_norm": 0.5247001647949219,
      "learning_rate": 0.00015580721995308653,
      "loss": 2.4012,
      "step": 6230
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.556018054485321,
      "learning_rate": 0.00015566379978191954,
      "loss": 2.4255,
      "step": 6240
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5210297703742981,
      "learning_rate": 0.00015552021351812595,
      "loss": 2.4375,
      "step": 6250
    },
    {
      "epoch": 1.0,
      "eval_bleu": 34.8389271444895,
      "eval_gen_len": 31.657,
      "eval_loss": 2.6067545413970947,
      "eval_runtime": 63.7549,
      "eval_samples_per_second": 15.685,
      "eval_steps_per_second": 0.988,
      "step": 6250
    },
    {
      "epoch": 1.0016,
      "grad_norm": 0.5418568849563599,
      "learning_rate": 0.00015537646159014614,
      "loss": 2.4132,
      "step": 6260
    },
    {
      "epoch": 1.0032,
      "grad_norm": 0.5012544393539429,
      "learning_rate": 0.00015523254442691479,
      "loss": 2.4011,
      "step": 6270
    },
    {
      "epoch": 1.0048,
      "grad_norm": 0.5302914977073669,
      "learning_rate": 0.00015508846245785972,
      "loss": 2.4232,
      "step": 6280
    },
    {
      "epoch": 1.0064,
      "grad_norm": 0.5028155446052551,
      "learning_rate": 0.0001549442161129004,
      "loss": 2.3882,
      "step": 6290
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.5509851574897766,
      "learning_rate": 0.00015479980582244673,
      "loss": 2.3981,
      "step": 6300
    },
    {
      "epoch": 1.008,
      "eval_bleu": 34.8271474872659,
      "eval_gen_len": 31.597,
      "eval_loss": 2.6122093200683594,
      "eval_runtime": 63.2863,
      "eval_samples_per_second": 15.801,
      "eval_steps_per_second": 0.995,
      "step": 6300
    },
    {
      "epoch": 1.0096,
      "grad_norm": 0.5207374095916748,
      "learning_rate": 0.0001546552320173979,
      "loss": 2.3901,
      "step": 6310
    },
    {
      "epoch": 1.0112,
      "grad_norm": 0.5591912269592285,
      "learning_rate": 0.00015451049512914104,
      "loss": 2.3666,
      "step": 6320
    },
    {
      "epoch": 1.0128,
      "grad_norm": 0.5331781506538391,
      "learning_rate": 0.00015436559558954971,
      "loss": 2.3969,
      "step": 6330
    },
    {
      "epoch": 1.0144,
      "grad_norm": 0.5293523669242859,
      "learning_rate": 0.00015422053383098305,
      "loss": 2.4021,
      "step": 6340
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.4970517158508301,
      "learning_rate": 0.000154075310286284,
      "loss": 2.3813,
      "step": 6350
    },
    {
      "epoch": 1.016,
      "eval_bleu": 34.61202995270791,
      "eval_gen_len": 31.73,
      "eval_loss": 2.6112775802612305,
      "eval_runtime": 64.1057,
      "eval_samples_per_second": 15.599,
      "eval_steps_per_second": 0.983,
      "step": 6350
    },
    {
      "epoch": 1.0176,
      "grad_norm": 0.5510627031326294,
      "learning_rate": 0.00015392992538877838,
      "loss": 2.3743,
      "step": 6360
    },
    {
      "epoch": 1.0192,
      "grad_norm": 0.5083834528923035,
      "learning_rate": 0.0001537843795722734,
      "loss": 2.3746,
      "step": 6370
    },
    {
      "epoch": 1.0208,
      "grad_norm": 0.5645709037780762,
      "learning_rate": 0.00015363867327105655,
      "loss": 2.3951,
      "step": 6380
    },
    {
      "epoch": 1.0224,
      "grad_norm": 0.5243424773216248,
      "learning_rate": 0.000153492806919894,
      "loss": 2.4022,
      "step": 6390
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.5045472979545593,
      "learning_rate": 0.0001533467809540296,
      "loss": 2.4025,
      "step": 6400
    },
    {
      "epoch": 1.024,
      "eval_bleu": 34.62889515579242,
      "eval_gen_len": 31.657,
      "eval_loss": 2.610605001449585,
      "eval_runtime": 63.0058,
      "eval_samples_per_second": 15.872,
      "eval_steps_per_second": 1.0,
      "step": 6400
    },
    {
      "epoch": 1.0256,
      "grad_norm": 0.5539517998695374,
      "learning_rate": 0.00015320059580918352,
      "loss": 2.4177,
      "step": 6410
    },
    {
      "epoch": 1.0272,
      "grad_norm": 0.5302140712738037,
      "learning_rate": 0.00015305425192155075,
      "loss": 2.411,
      "step": 6420
    },
    {
      "epoch": 1.0288,
      "grad_norm": 0.5556113719940186,
      "learning_rate": 0.00015290774972780003,
      "loss": 2.4103,
      "step": 6430
    },
    {
      "epoch": 1.0304,
      "grad_norm": 0.5152773857116699,
      "learning_rate": 0.00015276108966507247,
      "loss": 2.3654,
      "step": 6440
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.5561937689781189,
      "learning_rate": 0.0001526142721709802,
      "loss": 2.3868,
      "step": 6450
    },
    {
      "epoch": 1.032,
      "eval_bleu": 34.8685019718914,
      "eval_gen_len": 31.692,
      "eval_loss": 2.6098880767822266,
      "eval_runtime": 63.3677,
      "eval_samples_per_second": 15.781,
      "eval_steps_per_second": 0.994,
      "step": 6450
    },
    {
      "epoch": 1.0336,
      "grad_norm": 0.5164684653282166,
      "learning_rate": 0.0001524672976836051,
      "loss": 2.3785,
      "step": 6460
    },
    {
      "epoch": 1.0352,
      "grad_norm": 0.5262543559074402,
      "learning_rate": 0.0001523201666414976,
      "loss": 2.4027,
      "step": 6470
    },
    {
      "epoch": 1.0368,
      "grad_norm": 0.5196444392204285,
      "learning_rate": 0.0001521728794836751,
      "loss": 2.3941,
      "step": 6480
    },
    {
      "epoch": 1.0384,
      "grad_norm": 0.5477906465530396,
      "learning_rate": 0.00015202543664962094,
      "loss": 2.3993,
      "step": 6490
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.5431935787200928,
      "learning_rate": 0.00015187783857928291,
      "loss": 2.3902,
      "step": 6500
    },
    {
      "epoch": 1.04,
      "eval_bleu": 34.81825595841933,
      "eval_gen_len": 31.723,
      "eval_loss": 2.611675500869751,
      "eval_runtime": 62.9538,
      "eval_samples_per_second": 15.885,
      "eval_steps_per_second": 1.001,
      "step": 6500
    },
    {
      "epoch": 1.0416,
      "grad_norm": 0.5195338129997253,
      "learning_rate": 0.00015173008571307207,
      "loss": 2.4159,
      "step": 6510
    },
    {
      "epoch": 1.0432,
      "grad_norm": 0.5332886576652527,
      "learning_rate": 0.00015158217849186136,
      "loss": 2.4074,
      "step": 6520
    },
    {
      "epoch": 1.0448,
      "grad_norm": 0.5760420560836792,
      "learning_rate": 0.00015143411735698422,
      "loss": 2.3762,
      "step": 6530
    },
    {
      "epoch": 1.0464,
      "grad_norm": 0.521429181098938,
      "learning_rate": 0.00015128590275023345,
      "loss": 2.398,
      "step": 6540
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.5336079597473145,
      "learning_rate": 0.0001511375351138596,
      "loss": 2.3973,
      "step": 6550
    },
    {
      "epoch": 1.048,
      "eval_bleu": 34.70986374931221,
      "eval_gen_len": 31.787,
      "eval_loss": 2.609905958175659,
      "eval_runtime": 63.7863,
      "eval_samples_per_second": 15.677,
      "eval_steps_per_second": 0.988,
      "step": 6550
    },
    {
      "epoch": 1.0496,
      "grad_norm": 0.4935389757156372,
      "learning_rate": 0.00015098901489057011,
      "loss": 2.386,
      "step": 6560
    },
    {
      "epoch": 1.0512,
      "grad_norm": 0.5496881604194641,
      "learning_rate": 0.00015084034252352754,
      "loss": 2.3807,
      "step": 6570
    },
    {
      "epoch": 1.0528,
      "grad_norm": 0.5841277837753296,
      "learning_rate": 0.00015069151845634843,
      "loss": 2.3997,
      "step": 6580
    },
    {
      "epoch": 1.0544,
      "grad_norm": 0.5231354236602783,
      "learning_rate": 0.000150542543133102,
      "loss": 2.4005,
      "step": 6590
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.5704634785652161,
      "learning_rate": 0.00015039341699830887,
      "loss": 2.3904,
      "step": 6600
    },
    {
      "epoch": 1.056,
      "eval_bleu": 34.904428679990936,
      "eval_gen_len": 31.55,
      "eval_loss": 2.6102609634399414,
      "eval_runtime": 63.379,
      "eval_samples_per_second": 15.778,
      "eval_steps_per_second": 0.994,
      "step": 6600
    },
    {
      "epoch": 1.0576,
      "grad_norm": 0.5077332258224487,
      "learning_rate": 0.00015024414049693947,
      "loss": 2.3919,
      "step": 6610
    },
    {
      "epoch": 1.0592,
      "grad_norm": 0.5298551321029663,
      "learning_rate": 0.0001500947140744131,
      "loss": 2.3898,
      "step": 6620
    },
    {
      "epoch": 1.0608,
      "grad_norm": 0.5316786766052246,
      "learning_rate": 0.0001499451381765963,
      "loss": 2.4,
      "step": 6630
    },
    {
      "epoch": 1.0624,
      "grad_norm": 0.5336244702339172,
      "learning_rate": 0.00014979541324980163,
      "loss": 2.3859,
      "step": 6640
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.5961079001426697,
      "learning_rate": 0.00014964553974078636,
      "loss": 2.397,
      "step": 6650
    },
    {
      "epoch": 1.064,
      "eval_bleu": 34.90898947293035,
      "eval_gen_len": 31.721,
      "eval_loss": 2.608690023422241,
      "eval_runtime": 63.4048,
      "eval_samples_per_second": 15.772,
      "eval_steps_per_second": 0.994,
      "step": 6650
    },
    {
      "epoch": 1.0656,
      "grad_norm": 0.4894319772720337,
      "learning_rate": 0.0001494955180967511,
      "loss": 2.3954,
      "step": 6660
    },
    {
      "epoch": 1.0672,
      "grad_norm": 0.5073197484016418,
      "learning_rate": 0.00014934534876533847,
      "loss": 2.4004,
      "step": 6670
    },
    {
      "epoch": 1.0688,
      "grad_norm": 0.588138222694397,
      "learning_rate": 0.00014919503219463172,
      "loss": 2.4228,
      "step": 6680
    },
    {
      "epoch": 1.0704,
      "grad_norm": 0.5406789183616638,
      "learning_rate": 0.0001490445688331535,
      "loss": 2.3846,
      "step": 6690
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.5075154304504395,
      "learning_rate": 0.0001488939591298645,
      "loss": 2.4025,
      "step": 6700
    },
    {
      "epoch": 1.072,
      "eval_bleu": 34.648514332101854,
      "eval_gen_len": 31.751,
      "eval_loss": 2.611295223236084,
      "eval_runtime": 64.0652,
      "eval_samples_per_second": 15.609,
      "eval_steps_per_second": 0.983,
      "step": 6700
    },
    {
      "epoch": 1.0735999999999999,
      "grad_norm": 0.5683305859565735,
      "learning_rate": 0.00014874320353416195,
      "loss": 2.4079,
      "step": 6710
    },
    {
      "epoch": 1.0752,
      "grad_norm": 0.510856568813324,
      "learning_rate": 0.00014859230249587846,
      "loss": 2.3661,
      "step": 6720
    },
    {
      "epoch": 1.0768,
      "grad_norm": 0.5449805855751038,
      "learning_rate": 0.00014844125646528068,
      "loss": 2.4009,
      "step": 6730
    },
    {
      "epoch": 1.0784,
      "grad_norm": 0.5659570693969727,
      "learning_rate": 0.00014829006589306784,
      "loss": 2.361,
      "step": 6740
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.5446857213973999,
      "learning_rate": 0.00014813873123037044,
      "loss": 2.3731,
      "step": 6750
    },
    {
      "epoch": 1.08,
      "eval_bleu": 34.962305193492405,
      "eval_gen_len": 31.737,
      "eval_loss": 2.6115994453430176,
      "eval_runtime": 63.8948,
      "eval_samples_per_second": 15.651,
      "eval_steps_per_second": 0.986,
      "step": 6750
    },
    {
      "epoch": 1.0816,
      "grad_norm": 0.5529990196228027,
      "learning_rate": 0.00014798725292874897,
      "loss": 2.392,
      "step": 6760
    },
    {
      "epoch": 1.0832,
      "grad_norm": 0.5166081786155701,
      "learning_rate": 0.0001478356314401925,
      "loss": 2.4084,
      "step": 6770
    },
    {
      "epoch": 1.0848,
      "grad_norm": 0.49592170119285583,
      "learning_rate": 0.00014768386721711733,
      "loss": 2.4204,
      "step": 6780
    },
    {
      "epoch": 1.0864,
      "grad_norm": 0.5304082036018372,
      "learning_rate": 0.0001475319607123657,
      "loss": 2.3928,
      "step": 6790
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.5090344548225403,
      "learning_rate": 0.00014737991237920433,
      "loss": 2.4001,
      "step": 6800
    },
    {
      "epoch": 1.088,
      "eval_bleu": 34.87216141179358,
      "eval_gen_len": 31.692,
      "eval_loss": 2.6102139949798584,
      "eval_runtime": 63.6165,
      "eval_samples_per_second": 15.719,
      "eval_steps_per_second": 0.99,
      "step": 6800
    },
    {
      "epoch": 1.0896,
      "grad_norm": 0.5969576239585876,
      "learning_rate": 0.00014722772267132322,
      "loss": 2.3904,
      "step": 6810
    },
    {
      "epoch": 1.0912,
      "grad_norm": 0.5588803887367249,
      "learning_rate": 0.0001470753920428341,
      "loss": 2.376,
      "step": 6820
    },
    {
      "epoch": 1.0928,
      "grad_norm": 0.4851745069026947,
      "learning_rate": 0.00014692292094826937,
      "loss": 2.3819,
      "step": 6830
    },
    {
      "epoch": 1.0944,
      "grad_norm": 0.4825136959552765,
      "learning_rate": 0.0001467703098425804,
      "loss": 2.3704,
      "step": 6840
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.5136505365371704,
      "learning_rate": 0.00014661755918113635,
      "loss": 2.4061,
      "step": 6850
    },
    {
      "epoch": 1.096,
      "eval_bleu": 34.79097217244909,
      "eval_gen_len": 31.625,
      "eval_loss": 2.6107914447784424,
      "eval_runtime": 63.6561,
      "eval_samples_per_second": 15.709,
      "eval_steps_per_second": 0.99,
      "step": 6850
    },
    {
      "epoch": 1.0976,
      "grad_norm": 0.5398387312889099,
      "learning_rate": 0.00014646466941972285,
      "loss": 2.4039,
      "step": 6860
    },
    {
      "epoch": 1.0992,
      "grad_norm": 0.4988069236278534,
      "learning_rate": 0.0001463116410145405,
      "loss": 2.3994,
      "step": 6870
    },
    {
      "epoch": 1.1008,
      "grad_norm": 0.5257502198219299,
      "learning_rate": 0.00014615847442220377,
      "loss": 2.3772,
      "step": 6880
    },
    {
      "epoch": 1.1024,
      "grad_norm": 0.5367221236228943,
      "learning_rate": 0.00014600517009973925,
      "loss": 2.4074,
      "step": 6890
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.5684187412261963,
      "learning_rate": 0.00014585172850458458,
      "loss": 2.393,
      "step": 6900
    },
    {
      "epoch": 1.104,
      "eval_bleu": 34.83728342554478,
      "eval_gen_len": 31.725,
      "eval_loss": 2.6109883785247803,
      "eval_runtime": 64.5363,
      "eval_samples_per_second": 15.495,
      "eval_steps_per_second": 0.976,
      "step": 6900
    },
    {
      "epoch": 1.1056,
      "grad_norm": 0.5121862292289734,
      "learning_rate": 0.00014569815009458703,
      "loss": 2.4081,
      "step": 6910
    },
    {
      "epoch": 1.1072,
      "grad_norm": 0.498577743768692,
      "learning_rate": 0.0001455444353280021,
      "loss": 2.4043,
      "step": 6920
    },
    {
      "epoch": 1.1088,
      "grad_norm": 0.5230783224105835,
      "learning_rate": 0.00014539058466349217,
      "loss": 2.4054,
      "step": 6930
    },
    {
      "epoch": 1.1104,
      "grad_norm": 0.5483117699623108,
      "learning_rate": 0.00014523659856012502,
      "loss": 2.3964,
      "step": 6940
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.5265204906463623,
      "learning_rate": 0.00014508247747737265,
      "loss": 2.4068,
      "step": 6950
    },
    {
      "epoch": 1.112,
      "eval_bleu": 34.72805393361678,
      "eval_gen_len": 31.764,
      "eval_loss": 2.608405113220215,
      "eval_runtime": 63.3561,
      "eval_samples_per_second": 15.784,
      "eval_steps_per_second": 0.994,
      "step": 6950
    },
    {
      "epoch": 1.1136,
      "grad_norm": 0.5879172682762146,
      "learning_rate": 0.00014492822187510982,
      "loss": 2.4131,
      "step": 6960
    },
    {
      "epoch": 1.1152,
      "grad_norm": 0.5410283803939819,
      "learning_rate": 0.00014477383221361264,
      "loss": 2.4235,
      "step": 6970
    },
    {
      "epoch": 1.1168,
      "grad_norm": 0.5056635141372681,
      "learning_rate": 0.00014461930895355728,
      "loss": 2.3859,
      "step": 6980
    },
    {
      "epoch": 1.1184,
      "grad_norm": 0.5375158786773682,
      "learning_rate": 0.00014446465255601852,
      "loss": 2.3972,
      "step": 6990
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.5853419303894043,
      "learning_rate": 0.0001443098634824683,
      "loss": 2.4205,
      "step": 7000
    },
    {
      "epoch": 1.12,
      "eval_bleu": 34.72504366525851,
      "eval_gen_len": 31.582,
      "eval_loss": 2.6100757122039795,
      "eval_runtime": 63.0686,
      "eval_samples_per_second": 15.856,
      "eval_steps_per_second": 0.999,
      "step": 7000
    },
    {
      "epoch": 1.1216,
      "grad_norm": 0.557845950126648,
      "learning_rate": 0.0001441549421947747,
      "loss": 2.3779,
      "step": 7010
    },
    {
      "epoch": 1.1232,
      "grad_norm": 0.4976887106895447,
      "learning_rate": 0.00014399988915520006,
      "loss": 2.3794,
      "step": 7020
    },
    {
      "epoch": 1.1248,
      "grad_norm": 0.5706403255462646,
      "learning_rate": 0.00014384470482639995,
      "loss": 2.4023,
      "step": 7030
    },
    {
      "epoch": 1.1264,
      "grad_norm": 0.5385144948959351,
      "learning_rate": 0.00014368938967142166,
      "loss": 2.3742,
      "step": 7040
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.5377922058105469,
      "learning_rate": 0.00014353394415370297,
      "loss": 2.3855,
      "step": 7050
    },
    {
      "epoch": 1.1280000000000001,
      "eval_bleu": 34.55489123263235,
      "eval_gen_len": 31.659,
      "eval_loss": 2.6091420650482178,
      "eval_runtime": 63.4983,
      "eval_samples_per_second": 15.748,
      "eval_steps_per_second": 0.992,
      "step": 7050
    },
    {
      "epoch": 1.1296,
      "grad_norm": 0.5646582841873169,
      "learning_rate": 0.00014337836873707044,
      "loss": 2.3991,
      "step": 7060
    },
    {
      "epoch": 1.1312,
      "grad_norm": 0.5111270546913147,
      "learning_rate": 0.00014322266388573835,
      "loss": 2.3854,
      "step": 7070
    },
    {
      "epoch": 1.1328,
      "grad_norm": 0.5240054130554199,
      "learning_rate": 0.00014306683006430715,
      "loss": 2.4127,
      "step": 7080
    },
    {
      "epoch": 1.1344,
      "grad_norm": 0.5329105257987976,
      "learning_rate": 0.0001429108677377622,
      "loss": 2.401,
      "step": 7090
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.5683350563049316,
      "learning_rate": 0.00014275477737147224,
      "loss": 2.4152,
      "step": 7100
    },
    {
      "epoch": 1.1360000000000001,
      "eval_bleu": 34.64769350073125,
      "eval_gen_len": 31.633,
      "eval_loss": 2.611348867416382,
      "eval_runtime": 63.6527,
      "eval_samples_per_second": 15.71,
      "eval_steps_per_second": 0.99,
      "step": 7100
    },
    {
      "epoch": 1.1376,
      "grad_norm": 0.5132683515548706,
      "learning_rate": 0.00014259855943118803,
      "loss": 2.3882,
      "step": 7110
    },
    {
      "epoch": 1.1392,
      "grad_norm": 0.5059805512428284,
      "learning_rate": 0.00014244221438304103,
      "loss": 2.4049,
      "step": 7120
    },
    {
      "epoch": 1.1408,
      "grad_norm": 0.5561797022819519,
      "learning_rate": 0.00014228574269354194,
      "loss": 2.4132,
      "step": 7130
    },
    {
      "epoch": 1.1424,
      "grad_norm": 0.5278750061988831,
      "learning_rate": 0.0001421291448295794,
      "loss": 2.3806,
      "step": 7140
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.5288801789283752,
      "learning_rate": 0.00014197242125841853,
      "loss": 2.3937,
      "step": 7150
    },
    {
      "epoch": 1.144,
      "eval_bleu": 34.84914146957811,
      "eval_gen_len": 31.776,
      "eval_loss": 2.607203960418701,
      "eval_runtime": 63.6974,
      "eval_samples_per_second": 15.699,
      "eval_steps_per_second": 0.989,
      "step": 7150
    },
    {
      "epoch": 1.1456,
      "grad_norm": 0.565731942653656,
      "learning_rate": 0.00014181557244769948,
      "loss": 2.4217,
      "step": 7160
    },
    {
      "epoch": 1.1472,
      "grad_norm": 0.4896540641784668,
      "learning_rate": 0.0001416585988654361,
      "loss": 2.4204,
      "step": 7170
    },
    {
      "epoch": 1.1488,
      "grad_norm": 0.5331474542617798,
      "learning_rate": 0.00014150150098001465,
      "loss": 2.3912,
      "step": 7180
    },
    {
      "epoch": 1.1504,
      "grad_norm": 0.5455505847930908,
      "learning_rate": 0.00014134427926019213,
      "loss": 2.3701,
      "step": 7190
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.5547994375228882,
      "learning_rate": 0.00014118693417509518,
      "loss": 2.3781,
      "step": 7200
    },
    {
      "epoch": 1.152,
      "eval_bleu": 34.84792085798356,
      "eval_gen_len": 31.713,
      "eval_loss": 2.6103923320770264,
      "eval_runtime": 63.1935,
      "eval_samples_per_second": 15.824,
      "eval_steps_per_second": 0.997,
      "step": 7200
    },
    {
      "epoch": 1.1536,
      "grad_norm": 0.5207794308662415,
      "learning_rate": 0.00014102946619421846,
      "loss": 2.3933,
      "step": 7210
    },
    {
      "epoch": 1.1552,
      "grad_norm": 0.5373099446296692,
      "learning_rate": 0.0001408718757874234,
      "loss": 2.3903,
      "step": 7220
    },
    {
      "epoch": 1.1568,
      "grad_norm": 0.5312297344207764,
      "learning_rate": 0.00014071416342493665,
      "loss": 2.387,
      "step": 7230
    },
    {
      "epoch": 1.1584,
      "grad_norm": 0.5511961579322815,
      "learning_rate": 0.00014055632957734888,
      "loss": 2.39,
      "step": 7240
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.5622299313545227,
      "learning_rate": 0.00014039837471561308,
      "loss": 2.397,
      "step": 7250
    },
    {
      "epoch": 1.16,
      "eval_bleu": 34.76438101152762,
      "eval_gen_len": 31.669,
      "eval_loss": 2.6086983680725098,
      "eval_runtime": 63.7055,
      "eval_samples_per_second": 15.697,
      "eval_steps_per_second": 0.989,
      "step": 7250
    },
    {
      "epoch": 1.1616,
      "grad_norm": 0.5039335489273071,
      "learning_rate": 0.00014024029931104345,
      "loss": 2.3827,
      "step": 7260
    },
    {
      "epoch": 1.1632,
      "grad_norm": 0.5959492325782776,
      "learning_rate": 0.0001400821038353139,
      "loss": 2.3627,
      "step": 7270
    },
    {
      "epoch": 1.1648,
      "grad_norm": 0.527221143245697,
      "learning_rate": 0.00013992378876045652,
      "loss": 2.3786,
      "step": 7280
    },
    {
      "epoch": 1.1663999999999999,
      "grad_norm": 0.5109727382659912,
      "learning_rate": 0.0001397653545588603,
      "loss": 2.3947,
      "step": 7290
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.5366919636726379,
      "learning_rate": 0.0001396068017032697,
      "loss": 2.4179,
      "step": 7300
    },
    {
      "epoch": 1.168,
      "eval_bleu": 34.629313751956104,
      "eval_gen_len": 31.727,
      "eval_loss": 2.6097047328948975,
      "eval_runtime": 63.4429,
      "eval_samples_per_second": 15.762,
      "eval_steps_per_second": 0.993,
      "step": 7300
    },
    {
      "epoch": 1.1696,
      "grad_norm": 0.5778073072433472,
      "learning_rate": 0.00013944813066678327,
      "loss": 2.383,
      "step": 7310
    },
    {
      "epoch": 1.1712,
      "grad_norm": 0.5457191467285156,
      "learning_rate": 0.00013928934192285208,
      "loss": 2.3665,
      "step": 7320
    },
    {
      "epoch": 1.1728,
      "grad_norm": 0.5472123622894287,
      "learning_rate": 0.00013913043594527852,
      "loss": 2.389,
      "step": 7330
    },
    {
      "epoch": 1.1743999999999999,
      "grad_norm": 0.5354562997817993,
      "learning_rate": 0.00013897141320821476,
      "loss": 2.3739,
      "step": 7340
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.5098159313201904,
      "learning_rate": 0.00013881227418616134,
      "loss": 2.4165,
      "step": 7350
    },
    {
      "epoch": 1.176,
      "eval_bleu": 35.009161572192404,
      "eval_gen_len": 31.717,
      "eval_loss": 2.609262228012085,
      "eval_runtime": 64.4378,
      "eval_samples_per_second": 15.519,
      "eval_steps_per_second": 0.978,
      "step": 7350
    },
    {
      "epoch": 1.1776,
      "grad_norm": 0.5463024973869324,
      "learning_rate": 0.00013865301935396578,
      "loss": 2.374,
      "step": 7360
    },
    {
      "epoch": 1.1792,
      "grad_norm": 0.5050698518753052,
      "learning_rate": 0.00013849364918682125,
      "loss": 2.3784,
      "step": 7370
    },
    {
      "epoch": 1.1808,
      "grad_norm": 0.5475553274154663,
      "learning_rate": 0.00013833416416026488,
      "loss": 2.3883,
      "step": 7380
    },
    {
      "epoch": 1.1824,
      "grad_norm": 0.5051479339599609,
      "learning_rate": 0.0001381745647501767,
      "loss": 2.3918,
      "step": 7390
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.552741527557373,
      "learning_rate": 0.00013801485143277798,
      "loss": 2.381,
      "step": 7400
    },
    {
      "epoch": 1.184,
      "eval_bleu": 34.90481668225724,
      "eval_gen_len": 31.614,
      "eval_loss": 2.6088597774505615,
      "eval_runtime": 63.5315,
      "eval_samples_per_second": 15.74,
      "eval_steps_per_second": 0.992,
      "step": 7400
    },
    {
      "epoch": 1.1856,
      "grad_norm": 0.5074896216392517,
      "learning_rate": 0.00013785502468462987,
      "loss": 2.3752,
      "step": 7410
    },
    {
      "epoch": 1.1872,
      "grad_norm": 0.5445446968078613,
      "learning_rate": 0.000137695084982632,
      "loss": 2.3608,
      "step": 7420
    },
    {
      "epoch": 1.1888,
      "grad_norm": 0.5113115310668945,
      "learning_rate": 0.00013753503280402094,
      "loss": 2.3754,
      "step": 7430
    },
    {
      "epoch": 1.1904,
      "grad_norm": 0.4931996464729309,
      "learning_rate": 0.000137374868626369,
      "loss": 2.4003,
      "step": 7440
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.5174157023429871,
      "learning_rate": 0.00013721459292758258,
      "loss": 2.3624,
      "step": 7450
    },
    {
      "epoch": 1.192,
      "eval_bleu": 35.21093807656644,
      "eval_gen_len": 31.739,
      "eval_loss": 2.6068623065948486,
      "eval_runtime": 63.7495,
      "eval_samples_per_second": 15.686,
      "eval_steps_per_second": 0.988,
      "step": 7450
    },
    {
      "epoch": 1.1936,
      "grad_norm": 0.5706629157066345,
      "learning_rate": 0.00013705420618590101,
      "loss": 2.4058,
      "step": 7460
    },
    {
      "epoch": 1.1952,
      "grad_norm": 0.5482184886932373,
      "learning_rate": 0.00013689370887989474,
      "loss": 2.3891,
      "step": 7470
    },
    {
      "epoch": 1.1968,
      "grad_norm": 0.5470378398895264,
      "learning_rate": 0.00013673310148846427,
      "loss": 2.4047,
      "step": 7480
    },
    {
      "epoch": 1.1984,
      "grad_norm": 0.5417112708091736,
      "learning_rate": 0.00013657238449083848,
      "loss": 2.4032,
      "step": 7490
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.4946289360523224,
      "learning_rate": 0.00013641155836657343,
      "loss": 2.3812,
      "step": 7500
    },
    {
      "epoch": 1.2,
      "eval_bleu": 35.150834572823186,
      "eval_gen_len": 31.641,
      "eval_loss": 2.609659433364868,
      "eval_runtime": 63.6773,
      "eval_samples_per_second": 15.704,
      "eval_steps_per_second": 0.989,
      "step": 7500
    },
    {
      "epoch": 1.2016,
      "grad_norm": 0.524590253829956,
      "learning_rate": 0.00013625062359555066,
      "loss": 2.3774,
      "step": 7510
    },
    {
      "epoch": 1.2032,
      "grad_norm": 0.5898842215538025,
      "learning_rate": 0.000136089580657976,
      "loss": 2.3826,
      "step": 7520
    },
    {
      "epoch": 1.2048,
      "grad_norm": 0.5470332503318787,
      "learning_rate": 0.00013592843003437798,
      "loss": 2.407,
      "step": 7530
    },
    {
      "epoch": 1.2064,
      "grad_norm": 0.5753147006034851,
      "learning_rate": 0.00013576717220560643,
      "loss": 2.3725,
      "step": 7540
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.5527398586273193,
      "learning_rate": 0.00013560580765283113,
      "loss": 2.3894,
      "step": 7550
    },
    {
      "epoch": 1.208,
      "eval_bleu": 34.73470843335558,
      "eval_gen_len": 31.94,
      "eval_loss": 2.6075143814086914,
      "eval_runtime": 68.0371,
      "eval_samples_per_second": 14.698,
      "eval_steps_per_second": 0.926,
      "step": 7550
    },
    {
      "epoch": 1.2096,
      "grad_norm": 0.5410558581352234,
      "learning_rate": 0.00013544433685754026,
      "loss": 2.3991,
      "step": 7560
    },
    {
      "epoch": 1.2112,
      "grad_norm": 0.5242137908935547,
      "learning_rate": 0.000135282760301539,
      "loss": 2.3965,
      "step": 7570
    },
    {
      "epoch": 1.2128,
      "grad_norm": 0.5498985052108765,
      "learning_rate": 0.0001351210784669482,
      "loss": 2.391,
      "step": 7580
    },
    {
      "epoch": 1.2144,
      "grad_norm": 0.5873207449913025,
      "learning_rate": 0.00013495929183620273,
      "loss": 2.3767,
      "step": 7590
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.5196835398674011,
      "learning_rate": 0.0001347974008920502,
      "loss": 2.3834,
      "step": 7600
    },
    {
      "epoch": 1.216,
      "eval_bleu": 35.14430683928077,
      "eval_gen_len": 31.724,
      "eval_loss": 2.607083797454834,
      "eval_runtime": 64.5069,
      "eval_samples_per_second": 15.502,
      "eval_steps_per_second": 0.977,
      "step": 7600
    },
    {
      "epoch": 1.2176,
      "grad_norm": 0.5071470141410828,
      "learning_rate": 0.00013463540611754948,
      "loss": 2.3741,
      "step": 7610
    },
    {
      "epoch": 1.2192,
      "grad_norm": 0.5580874681472778,
      "learning_rate": 0.00013447330799606927,
      "loss": 2.4143,
      "step": 7620
    },
    {
      "epoch": 1.2208,
      "grad_norm": 0.5529886484146118,
      "learning_rate": 0.00013431110701128657,
      "loss": 2.3811,
      "step": 7630
    },
    {
      "epoch": 1.2224,
      "grad_norm": 0.5397706031799316,
      "learning_rate": 0.00013414880364718545,
      "loss": 2.4178,
      "step": 7640
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.5439139008522034,
      "learning_rate": 0.00013398639838805535,
      "loss": 2.3933,
      "step": 7650
    },
    {
      "epoch": 1.224,
      "eval_bleu": 35.137423662606956,
      "eval_gen_len": 31.728,
      "eval_loss": 2.606539487838745,
      "eval_runtime": 63.8531,
      "eval_samples_per_second": 15.661,
      "eval_steps_per_second": 0.987,
      "step": 7650
    },
    {
      "epoch": 1.2256,
      "grad_norm": 0.5316042900085449,
      "learning_rate": 0.00013382389171848975,
      "loss": 2.3849,
      "step": 7660
    },
    {
      "epoch": 1.2272,
      "grad_norm": 0.5513225197792053,
      "learning_rate": 0.0001336612841233847,
      "loss": 2.3792,
      "step": 7670
    },
    {
      "epoch": 1.2288000000000001,
      "grad_norm": 0.5400747060775757,
      "learning_rate": 0.00013349857608793762,
      "loss": 2.3939,
      "step": 7680
    },
    {
      "epoch": 1.2304,
      "grad_norm": 0.5320238471031189,
      "learning_rate": 0.0001333357680976453,
      "loss": 2.4195,
      "step": 7690
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.4907292127609253,
      "learning_rate": 0.00013317286063830303,
      "loss": 2.4031,
      "step": 7700
    },
    {
      "epoch": 1.232,
      "eval_bleu": 35.23499317751131,
      "eval_gen_len": 31.587,
      "eval_loss": 2.607707977294922,
      "eval_runtime": 63.4154,
      "eval_samples_per_second": 15.769,
      "eval_steps_per_second": 0.993,
      "step": 7700
    },
    {
      "epoch": 1.2336,
      "grad_norm": 0.5382689237594604,
      "learning_rate": 0.00013300985419600276,
      "loss": 2.4155,
      "step": 7710
    },
    {
      "epoch": 1.2352,
      "grad_norm": 0.5043011903762817,
      "learning_rate": 0.00013284674925713186,
      "loss": 2.4163,
      "step": 7720
    },
    {
      "epoch": 1.2368000000000001,
      "grad_norm": 0.5332481861114502,
      "learning_rate": 0.00013268354630837156,
      "loss": 2.3891,
      "step": 7730
    },
    {
      "epoch": 1.2384,
      "grad_norm": 0.5142402052879333,
      "learning_rate": 0.00013252024583669563,
      "loss": 2.3781,
      "step": 7740
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.5290013551712036,
      "learning_rate": 0.00013235684832936867,
      "loss": 2.3984,
      "step": 7750
    },
    {
      "epoch": 1.24,
      "eval_bleu": 35.034508088857834,
      "eval_gen_len": 31.662,
      "eval_loss": 2.6067776679992676,
      "eval_runtime": 63.6707,
      "eval_samples_per_second": 15.706,
      "eval_steps_per_second": 0.989,
      "step": 7750
    },
    {
      "epoch": 1.2416,
      "grad_norm": 0.5599568486213684,
      "learning_rate": 0.00013219335427394496,
      "loss": 2.3682,
      "step": 7760
    },
    {
      "epoch": 1.2432,
      "grad_norm": 0.5477780699729919,
      "learning_rate": 0.00013202976415826683,
      "loss": 2.3759,
      "step": 7770
    },
    {
      "epoch": 1.2448,
      "grad_norm": 0.5601740479469299,
      "learning_rate": 0.0001318660784704632,
      "loss": 2.3833,
      "step": 7780
    },
    {
      "epoch": 1.2464,
      "grad_norm": 0.5632876753807068,
      "learning_rate": 0.0001317022976989482,
      "loss": 2.3942,
      "step": 7790
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.5631659626960754,
      "learning_rate": 0.00013153842233241963,
      "loss": 2.3984,
      "step": 7800
    },
    {
      "epoch": 1.248,
      "eval_bleu": 34.780792032835514,
      "eval_gen_len": 31.647,
      "eval_loss": 2.6077535152435303,
      "eval_runtime": 63.4599,
      "eval_samples_per_second": 15.758,
      "eval_steps_per_second": 0.993,
      "step": 7800
    },
    {
      "epoch": 1.2496,
      "grad_norm": 0.5477734804153442,
      "learning_rate": 0.00013137445285985765,
      "loss": 2.3869,
      "step": 7810
    },
    {
      "epoch": 1.2511999999999999,
      "grad_norm": 0.5363377928733826,
      "learning_rate": 0.00013121038977052316,
      "loss": 2.3941,
      "step": 7820
    },
    {
      "epoch": 1.2528000000000001,
      "grad_norm": 0.5492692589759827,
      "learning_rate": 0.00013104623355395632,
      "loss": 2.397,
      "step": 7830
    },
    {
      "epoch": 1.2544,
      "grad_norm": 0.5528539419174194,
      "learning_rate": 0.00013088198469997527,
      "loss": 2.3795,
      "step": 7840
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.5556055307388306,
      "learning_rate": 0.00013071764369867452,
      "loss": 2.3553,
      "step": 7850
    },
    {
      "epoch": 1.256,
      "eval_bleu": 34.9629786650927,
      "eval_gen_len": 31.725,
      "eval_loss": 2.607567310333252,
      "eval_runtime": 64.6754,
      "eval_samples_per_second": 15.462,
      "eval_steps_per_second": 0.974,
      "step": 7850
    },
    {
      "epoch": 1.2576,
      "grad_norm": 0.5589317679405212,
      "learning_rate": 0.0001305532110404236,
      "loss": 2.3907,
      "step": 7860
    },
    {
      "epoch": 1.2591999999999999,
      "grad_norm": 0.5499301552772522,
      "learning_rate": 0.00013038868721586543,
      "loss": 2.4065,
      "step": 7870
    },
    {
      "epoch": 1.2608,
      "grad_norm": 0.5205825567245483,
      "learning_rate": 0.00013022407271591507,
      "loss": 2.396,
      "step": 7880
    },
    {
      "epoch": 1.2624,
      "grad_norm": 0.5212436318397522,
      "learning_rate": 0.00013005936803175798,
      "loss": 2.3782,
      "step": 7890
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.5088358521461487,
      "learning_rate": 0.0001298945736548489,
      "loss": 2.3767,
      "step": 7900
    },
    {
      "epoch": 1.264,
      "eval_bleu": 35.34455242092432,
      "eval_gen_len": 31.773,
      "eval_loss": 2.6076762676239014,
      "eval_runtime": 64.2943,
      "eval_samples_per_second": 15.553,
      "eval_steps_per_second": 0.98,
      "step": 7900
    },
    {
      "epoch": 1.2656,
      "grad_norm": 0.5312427878379822,
      "learning_rate": 0.0001297296900769101,
      "loss": 2.3857,
      "step": 7910
    },
    {
      "epoch": 1.2671999999999999,
      "grad_norm": 0.5046682357788086,
      "learning_rate": 0.00012956471778993001,
      "loss": 2.4082,
      "step": 7920
    },
    {
      "epoch": 1.2688,
      "grad_norm": 0.5613501667976379,
      "learning_rate": 0.00012939965728616182,
      "loss": 2.3963,
      "step": 7930
    },
    {
      "epoch": 1.2704,
      "grad_norm": 0.5211318135261536,
      "learning_rate": 0.00012923450905812182,
      "loss": 2.4025,
      "step": 7940
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.5557630062103271,
      "learning_rate": 0.0001290692735985882,
      "loss": 2.3997,
      "step": 7950
    },
    {
      "epoch": 1.272,
      "eval_bleu": 35.014714226998464,
      "eval_gen_len": 31.564,
      "eval_loss": 2.6084651947021484,
      "eval_runtime": 63.2991,
      "eval_samples_per_second": 15.798,
      "eval_steps_per_second": 0.995,
      "step": 7950
    },
    {
      "epoch": 1.2736,
      "grad_norm": 0.5337818264961243,
      "learning_rate": 0.00012890395140059937,
      "loss": 2.3823,
      "step": 7960
    },
    {
      "epoch": 1.2752,
      "grad_norm": 0.5394061803817749,
      "learning_rate": 0.00012873854295745253,
      "loss": 2.3876,
      "step": 7970
    },
    {
      "epoch": 1.2768,
      "grad_norm": 0.5211759209632874,
      "learning_rate": 0.00012857304876270225,
      "loss": 2.3916,
      "step": 7980
    },
    {
      "epoch": 1.2784,
      "grad_norm": 0.578571081161499,
      "learning_rate": 0.000128407469310159,
      "loss": 2.3848,
      "step": 7990
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5412635207176208,
      "learning_rate": 0.0001282418050938876,
      "loss": 2.3644,
      "step": 8000
    },
    {
      "epoch": 1.28,
      "eval_bleu": 34.90454470122868,
      "eval_gen_len": 31.643,
      "eval_loss": 2.607785224914551,
      "eval_runtime": 64.3559,
      "eval_samples_per_second": 15.539,
      "eval_steps_per_second": 0.979,
      "step": 8000
    },
    {
      "epoch": 1.2816,
      "grad_norm": 0.5923673510551453,
      "learning_rate": 0.0001280760566082058,
      "loss": 2.4186,
      "step": 8010
    },
    {
      "epoch": 1.2832,
      "grad_norm": 0.522226870059967,
      "learning_rate": 0.00012791022434768286,
      "loss": 2.4043,
      "step": 8020
    },
    {
      "epoch": 1.2848,
      "grad_norm": 0.530537486076355,
      "learning_rate": 0.00012774430880713785,
      "loss": 2.396,
      "step": 8030
    },
    {
      "epoch": 1.2864,
      "grad_norm": 0.5312196612358093,
      "learning_rate": 0.00012757831048163852,
      "loss": 2.37,
      "step": 8040
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.5209006071090698,
      "learning_rate": 0.00012741222986649962,
      "loss": 2.3985,
      "step": 8050
    },
    {
      "epoch": 1.288,
      "eval_bleu": 34.951103731614346,
      "eval_gen_len": 31.644,
      "eval_loss": 2.6079459190368652,
      "eval_runtime": 64.3599,
      "eval_samples_per_second": 15.538,
      "eval_steps_per_second": 0.979,
      "step": 8050
    },
    {
      "epoch": 1.2896,
      "grad_norm": 0.551449716091156,
      "learning_rate": 0.00012724606745728124,
      "loss": 2.3792,
      "step": 8060
    },
    {
      "epoch": 1.2912,
      "grad_norm": 0.5475093126296997,
      "learning_rate": 0.0001270798237497878,
      "loss": 2.4061,
      "step": 8070
    },
    {
      "epoch": 1.2928,
      "grad_norm": 0.5378689169883728,
      "learning_rate": 0.0001269134992400661,
      "loss": 2.4037,
      "step": 8080
    },
    {
      "epoch": 1.2944,
      "grad_norm": 0.5459840297698975,
      "learning_rate": 0.00012674709442440417,
      "loss": 2.3993,
      "step": 8090
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.5456594228744507,
      "learning_rate": 0.00012658060979932957,
      "loss": 2.3932,
      "step": 8100
    },
    {
      "epoch": 1.296,
      "eval_bleu": 34.9686672720077,
      "eval_gen_len": 31.707,
      "eval_loss": 2.6063320636749268,
      "eval_runtime": 64.1799,
      "eval_samples_per_second": 15.581,
      "eval_steps_per_second": 0.982,
      "step": 8100
    },
    {
      "epoch": 1.2976,
      "grad_norm": 0.5737445950508118,
      "learning_rate": 0.0001264140458616081,
      "loss": 2.4087,
      "step": 8110
    },
    {
      "epoch": 1.2992,
      "grad_norm": 0.5581077933311462,
      "learning_rate": 0.00012624740310824206,
      "loss": 2.3822,
      "step": 8120
    },
    {
      "epoch": 1.3008,
      "grad_norm": 0.5747368931770325,
      "learning_rate": 0.0001260806820364691,
      "loss": 2.3986,
      "step": 8130
    },
    {
      "epoch": 1.3024,
      "grad_norm": 0.5412918329238892,
      "learning_rate": 0.00012591388314376045,
      "loss": 2.3883,
      "step": 8140
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.5258675217628479,
      "learning_rate": 0.0001257470069278196,
      "loss": 2.3967,
      "step": 8150
    },
    {
      "epoch": 1.304,
      "eval_bleu": 34.93948474809825,
      "eval_gen_len": 31.677,
      "eval_loss": 2.6096010208129883,
      "eval_runtime": 63.7462,
      "eval_samples_per_second": 15.687,
      "eval_steps_per_second": 0.988,
      "step": 8150
    },
    {
      "epoch": 1.3056,
      "grad_norm": 0.5134792327880859,
      "learning_rate": 0.00012558005388658072,
      "loss": 2.3926,
      "step": 8160
    },
    {
      "epoch": 1.3072,
      "grad_norm": 0.5628483295440674,
      "learning_rate": 0.00012541302451820723,
      "loss": 2.4128,
      "step": 8170
    },
    {
      "epoch": 1.3088,
      "grad_norm": 0.5343819856643677,
      "learning_rate": 0.00012524591932109032,
      "loss": 2.3973,
      "step": 8180
    },
    {
      "epoch": 1.3104,
      "grad_norm": 0.5416732430458069,
      "learning_rate": 0.00012507873879384743,
      "loss": 2.3885,
      "step": 8190
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.5414940714836121,
      "learning_rate": 0.0001249114834353207,
      "loss": 2.3834,
      "step": 8200
    },
    {
      "epoch": 1.312,
      "eval_bleu": 35.19722510967044,
      "eval_gen_len": 31.655,
      "eval_loss": 2.606607437133789,
      "eval_runtime": 64.1879,
      "eval_samples_per_second": 15.579,
      "eval_steps_per_second": 0.981,
      "step": 8200
    },
    {
      "epoch": 1.3136,
      "grad_norm": 0.5545210242271423,
      "learning_rate": 0.00012474415374457573,
      "loss": 2.392,
      "step": 8210
    },
    {
      "epoch": 1.3152,
      "grad_norm": 0.5414279699325562,
      "learning_rate": 0.00012457675022089978,
      "loss": 2.3896,
      "step": 8220
    },
    {
      "epoch": 1.3168,
      "grad_norm": 0.5630460977554321,
      "learning_rate": 0.00012440927336380042,
      "loss": 2.3987,
      "step": 8230
    },
    {
      "epoch": 1.3184,
      "grad_norm": 0.5038475394248962,
      "learning_rate": 0.0001242417236730041,
      "loss": 2.3672,
      "step": 8240
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.5281910300254822,
      "learning_rate": 0.0001240741016484545,
      "loss": 2.3766,
      "step": 8250
    },
    {
      "epoch": 1.32,
      "eval_bleu": 35.106990983458765,
      "eval_gen_len": 31.666,
      "eval_loss": 2.6106116771698,
      "eval_runtime": 64.2831,
      "eval_samples_per_second": 15.556,
      "eval_steps_per_second": 0.98,
      "step": 8250
    },
    {
      "epoch": 1.3216,
      "grad_norm": 0.5821345448493958,
      "learning_rate": 0.00012390640779031122,
      "loss": 2.4081,
      "step": 8260
    },
    {
      "epoch": 1.3232,
      "grad_norm": 0.5004534125328064,
      "learning_rate": 0.00012373864259894823,
      "loss": 2.3684,
      "step": 8270
    },
    {
      "epoch": 1.3248,
      "grad_norm": 0.5772533416748047,
      "learning_rate": 0.00012357080657495224,
      "loss": 2.4305,
      "step": 8280
    },
    {
      "epoch": 1.3264,
      "grad_norm": 0.5106385350227356,
      "learning_rate": 0.00012340290021912136,
      "loss": 2.3985,
      "step": 8290
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.5295565724372864,
      "learning_rate": 0.00012323492403246356,
      "loss": 2.4094,
      "step": 8300
    },
    {
      "epoch": 1.328,
      "eval_bleu": 35.128179216561904,
      "eval_gen_len": 31.717,
      "eval_loss": 2.6053171157836914,
      "eval_runtime": 64.213,
      "eval_samples_per_second": 15.573,
      "eval_steps_per_second": 0.981,
      "step": 8300
    },
    {
      "epoch": 1.3296000000000001,
      "grad_norm": 0.5484667420387268,
      "learning_rate": 0.00012306687851619525,
      "loss": 2.3975,
      "step": 8310
    },
    {
      "epoch": 1.3312,
      "grad_norm": 0.5603460669517517,
      "learning_rate": 0.00012289876417173956,
      "loss": 2.4078,
      "step": 8320
    },
    {
      "epoch": 1.3328,
      "grad_norm": 0.5311607122421265,
      "learning_rate": 0.0001227305815007251,
      "loss": 2.3756,
      "step": 8330
    },
    {
      "epoch": 1.3344,
      "grad_norm": 0.5586471557617188,
      "learning_rate": 0.00012256233100498435,
      "loss": 2.3855,
      "step": 8340
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.542592465877533,
      "learning_rate": 0.0001223940131865521,
      "loss": 2.3783,
      "step": 8350
    },
    {
      "epoch": 1.336,
      "eval_bleu": 35.24887867247203,
      "eval_gen_len": 31.644,
      "eval_loss": 2.607196092605591,
      "eval_runtime": 63.9435,
      "eval_samples_per_second": 15.639,
      "eval_steps_per_second": 0.985,
      "step": 8350
    },
    {
      "epoch": 1.3376000000000001,
      "grad_norm": 0.4948579668998718,
      "learning_rate": 0.00012222562854766414,
      "loss": 2.3972,
      "step": 8360
    },
    {
      "epoch": 1.3392,
      "grad_norm": 0.5376349687576294,
      "learning_rate": 0.00012205717759075555,
      "loss": 2.3642,
      "step": 8370
    },
    {
      "epoch": 1.3408,
      "grad_norm": 0.5771769881248474,
      "learning_rate": 0.00012188866081845925,
      "loss": 2.39,
      "step": 8380
    },
    {
      "epoch": 1.3424,
      "grad_norm": 0.5531021952629089,
      "learning_rate": 0.00012172007873360467,
      "loss": 2.3861,
      "step": 8390
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.5126239061355591,
      "learning_rate": 0.00012155143183921607,
      "loss": 2.3782,
      "step": 8400
    },
    {
      "epoch": 1.3439999999999999,
      "eval_bleu": 35.21930071707417,
      "eval_gen_len": 31.63,
      "eval_loss": 2.605581760406494,
      "eval_runtime": 63.5479,
      "eval_samples_per_second": 15.736,
      "eval_steps_per_second": 0.991,
      "step": 8400
    },
    {
      "epoch": 1.3456000000000001,
      "grad_norm": 0.5666579008102417,
      "learning_rate": 0.00012138272063851109,
      "loss": 2.4075,
      "step": 8410
    },
    {
      "epoch": 1.3472,
      "grad_norm": 0.562140703201294,
      "learning_rate": 0.00012121394563489918,
      "loss": 2.3859,
      "step": 8420
    },
    {
      "epoch": 1.3488,
      "grad_norm": 0.5086864233016968,
      "learning_rate": 0.00012104510733198029,
      "loss": 2.3825,
      "step": 8430
    },
    {
      "epoch": 1.3504,
      "grad_norm": 0.5141990780830383,
      "learning_rate": 0.00012087620623354317,
      "loss": 2.4055,
      "step": 8440
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.5139147639274597,
      "learning_rate": 0.00012070724284356398,
      "loss": 2.3909,
      "step": 8450
    },
    {
      "epoch": 1.3519999999999999,
      "eval_bleu": 35.1360155504178,
      "eval_gen_len": 31.699,
      "eval_loss": 2.605633497238159,
      "eval_runtime": 63.5777,
      "eval_samples_per_second": 15.729,
      "eval_steps_per_second": 0.991,
      "step": 8450
    },
    {
      "epoch": 1.3536000000000001,
      "grad_norm": 0.5010629892349243,
      "learning_rate": 0.00012053821766620473,
      "loss": 2.3758,
      "step": 8460
    },
    {
      "epoch": 1.3552,
      "grad_norm": 0.5216473340988159,
      "learning_rate": 0.00012036913120581177,
      "loss": 2.374,
      "step": 8470
    },
    {
      "epoch": 1.3568,
      "grad_norm": 0.5248671770095825,
      "learning_rate": 0.00012019998396691434,
      "loss": 2.388,
      "step": 8480
    },
    {
      "epoch": 1.3584,
      "grad_norm": 0.5485430955886841,
      "learning_rate": 0.00012003077645422305,
      "loss": 2.3775,
      "step": 8490
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.5339625477790833,
      "learning_rate": 0.00011986150917262833,
      "loss": 2.3775,
      "step": 8500
    },
    {
      "epoch": 1.3599999999999999,
      "eval_bleu": 35.51392699924999,
      "eval_gen_len": 31.69,
      "eval_loss": 2.6027188301086426,
      "eval_runtime": 63.6515,
      "eval_samples_per_second": 15.711,
      "eval_steps_per_second": 0.99,
      "step": 8500
    },
    {
      "epoch": 1.3616,
      "grad_norm": 0.6070391535758972,
      "learning_rate": 0.00011969218262719897,
      "loss": 2.3845,
      "step": 8510
    },
    {
      "epoch": 1.3632,
      "grad_norm": 0.5269948244094849,
      "learning_rate": 0.00011952279732318054,
      "loss": 2.3918,
      "step": 8520
    },
    {
      "epoch": 1.3648,
      "grad_norm": 0.5537024736404419,
      "learning_rate": 0.00011935335376599402,
      "loss": 2.4198,
      "step": 8530
    },
    {
      "epoch": 1.3664,
      "grad_norm": 0.5189903378486633,
      "learning_rate": 0.00011918385246123416,
      "loss": 2.392,
      "step": 8540
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.5297314524650574,
      "learning_rate": 0.000119014293914668,
      "loss": 2.4002,
      "step": 8550
    },
    {
      "epoch": 1.3679999999999999,
      "eval_bleu": 35.03442143731172,
      "eval_gen_len": 31.594,
      "eval_loss": 2.6055169105529785,
      "eval_runtime": 63.8509,
      "eval_samples_per_second": 15.661,
      "eval_steps_per_second": 0.987,
      "step": 8550
    },
    {
      "epoch": 1.3696,
      "grad_norm": 0.5125858187675476,
      "learning_rate": 0.0001188446786322335,
      "loss": 2.3847,
      "step": 8560
    },
    {
      "epoch": 1.3712,
      "grad_norm": 0.5537229776382446,
      "learning_rate": 0.00011867500712003771,
      "loss": 2.3819,
      "step": 8570
    },
    {
      "epoch": 1.3728,
      "grad_norm": 0.5094672441482544,
      "learning_rate": 0.00011850527988435567,
      "loss": 2.3968,
      "step": 8580
    },
    {
      "epoch": 1.3744,
      "grad_norm": 0.5965744256973267,
      "learning_rate": 0.00011833549743162853,
      "loss": 2.3662,
      "step": 8590
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.5716083645820618,
      "learning_rate": 0.00011816566026846229,
      "loss": 2.3794,
      "step": 8600
    },
    {
      "epoch": 1.376,
      "eval_bleu": 35.23961905232051,
      "eval_gen_len": 31.613,
      "eval_loss": 2.6038625240325928,
      "eval_runtime": 63.7646,
      "eval_samples_per_second": 15.683,
      "eval_steps_per_second": 0.988,
      "step": 8600
    },
    {
      "epoch": 1.3776,
      "grad_norm": 0.5820402503013611,
      "learning_rate": 0.00011799576890162616,
      "loss": 2.4146,
      "step": 8610
    },
    {
      "epoch": 1.3792,
      "grad_norm": 0.5395552515983582,
      "learning_rate": 0.0001178258238380511,
      "loss": 2.3618,
      "step": 8620
    },
    {
      "epoch": 1.3808,
      "grad_norm": 0.4973672330379486,
      "learning_rate": 0.00011765582558482832,
      "loss": 2.3873,
      "step": 8630
    },
    {
      "epoch": 1.3824,
      "grad_norm": 0.530974268913269,
      "learning_rate": 0.00011748577464920769,
      "loss": 2.3997,
      "step": 8640
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.5310158133506775,
      "learning_rate": 0.00011731567153859631,
      "loss": 2.3508,
      "step": 8650
    },
    {
      "epoch": 1.384,
      "eval_bleu": 35.20953545847527,
      "eval_gen_len": 31.607,
      "eval_loss": 2.6059441566467285,
      "eval_runtime": 63.7374,
      "eval_samples_per_second": 15.689,
      "eval_steps_per_second": 0.988,
      "step": 8650
    },
    {
      "epoch": 1.3856,
      "grad_norm": 0.5166403651237488,
      "learning_rate": 0.00011714551676055689,
      "loss": 2.3899,
      "step": 8660
    },
    {
      "epoch": 1.3872,
      "grad_norm": 0.5096768140792847,
      "learning_rate": 0.00011697531082280644,
      "loss": 2.3686,
      "step": 8670
    },
    {
      "epoch": 1.3888,
      "grad_norm": 0.5325955748558044,
      "learning_rate": 0.00011680505423321452,
      "loss": 2.3794,
      "step": 8680
    },
    {
      "epoch": 1.3904,
      "grad_norm": 0.5639634132385254,
      "learning_rate": 0.0001166347474998019,
      "loss": 2.4304,
      "step": 8690
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.564126193523407,
      "learning_rate": 0.00011646439113073888,
      "loss": 2.3874,
      "step": 8700
    },
    {
      "epoch": 1.392,
      "eval_bleu": 35.57567766034053,
      "eval_gen_len": 31.697,
      "eval_loss": 2.6042394638061523,
      "eval_runtime": 63.5452,
      "eval_samples_per_second": 15.737,
      "eval_steps_per_second": 0.991,
      "step": 8700
    },
    {
      "epoch": 1.3936,
      "grad_norm": 0.5191873908042908,
      "learning_rate": 0.00011629398563434392,
      "loss": 2.4056,
      "step": 8710
    },
    {
      "epoch": 1.3952,
      "grad_norm": 0.5437560677528381,
      "learning_rate": 0.00011612353151908211,
      "loss": 2.4201,
      "step": 8720
    },
    {
      "epoch": 1.3968,
      "grad_norm": 0.5270253419876099,
      "learning_rate": 0.00011595302929356351,
      "loss": 2.4063,
      "step": 8730
    },
    {
      "epoch": 1.3984,
      "grad_norm": 0.5156602263450623,
      "learning_rate": 0.00011578247946654181,
      "loss": 2.3719,
      "step": 8740
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5638382434844971,
      "learning_rate": 0.00011561188254691274,
      "loss": 2.4054,
      "step": 8750
    },
    {
      "epoch": 1.4,
      "eval_bleu": 35.2118563825756,
      "eval_gen_len": 31.685,
      "eval_loss": 2.603468894958496,
      "eval_runtime": 63.9524,
      "eval_samples_per_second": 15.637,
      "eval_steps_per_second": 0.985,
      "step": 8750
    },
    {
      "epoch": 1.4016,
      "grad_norm": 0.5436751246452332,
      "learning_rate": 0.00011544123904371251,
      "loss": 2.3889,
      "step": 8760
    },
    {
      "epoch": 1.4032,
      "grad_norm": 0.5743021368980408,
      "learning_rate": 0.00011527054946611635,
      "loss": 2.3774,
      "step": 8770
    },
    {
      "epoch": 1.4048,
      "grad_norm": 0.5610101222991943,
      "learning_rate": 0.00011509981432343697,
      "loss": 2.396,
      "step": 8780
    },
    {
      "epoch": 1.4064,
      "grad_norm": 0.5812128782272339,
      "learning_rate": 0.00011492903412512297,
      "loss": 2.3792,
      "step": 8790
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.5510600209236145,
      "learning_rate": 0.0001147582093807575,
      "loss": 2.385,
      "step": 8800
    },
    {
      "epoch": 1.408,
      "eval_bleu": 34.98911941818452,
      "eval_gen_len": 31.744,
      "eval_loss": 2.6061484813690186,
      "eval_runtime": 63.8182,
      "eval_samples_per_second": 15.67,
      "eval_steps_per_second": 0.987,
      "step": 8800
    },
    {
      "epoch": 1.4096,
      "grad_norm": 0.5313840508460999,
      "learning_rate": 0.0001145873406000566,
      "loss": 2.3732,
      "step": 8810
    },
    {
      "epoch": 1.4112,
      "grad_norm": 0.5609495639801025,
      "learning_rate": 0.00011441642829286767,
      "loss": 2.3823,
      "step": 8820
    },
    {
      "epoch": 1.4128,
      "grad_norm": 0.5353567600250244,
      "learning_rate": 0.00011424547296916801,
      "loss": 2.3966,
      "step": 8830
    },
    {
      "epoch": 1.4144,
      "grad_norm": 0.5106562972068787,
      "learning_rate": 0.00011407447513906322,
      "loss": 2.3674,
      "step": 8840
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.509165346622467,
      "learning_rate": 0.00011390343531278583,
      "loss": 2.3957,
      "step": 8850
    },
    {
      "epoch": 1.416,
      "eval_bleu": 35.136207600309774,
      "eval_gen_len": 31.797,
      "eval_loss": 2.6057865619659424,
      "eval_runtime": 64.3704,
      "eval_samples_per_second": 15.535,
      "eval_steps_per_second": 0.979,
      "step": 8850
    },
    {
      "epoch": 1.4176,
      "grad_norm": 0.6015145778656006,
      "learning_rate": 0.00011373235400069361,
      "loss": 2.4067,
      "step": 8860
    },
    {
      "epoch": 1.4192,
      "grad_norm": 0.5425600409507751,
      "learning_rate": 0.00011356123171326821,
      "loss": 2.3771,
      "step": 8870
    },
    {
      "epoch": 1.4208,
      "grad_norm": 0.5525609254837036,
      "learning_rate": 0.00011339006896111337,
      "loss": 2.3974,
      "step": 8880
    },
    {
      "epoch": 1.4224,
      "grad_norm": 0.5279015302658081,
      "learning_rate": 0.00011321886625495375,
      "loss": 2.4117,
      "step": 8890
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.5545186400413513,
      "learning_rate": 0.0001130476241056331,
      "loss": 2.3613,
      "step": 8900
    },
    {
      "epoch": 1.424,
      "eval_bleu": 35.29995086641951,
      "eval_gen_len": 31.741,
      "eval_loss": 2.605579137802124,
      "eval_runtime": 64.3143,
      "eval_samples_per_second": 15.549,
      "eval_steps_per_second": 0.98,
      "step": 8900
    },
    {
      "epoch": 1.4256,
      "grad_norm": 0.5543776154518127,
      "learning_rate": 0.00011287634302411296,
      "loss": 2.37,
      "step": 8910
    },
    {
      "epoch": 1.4272,
      "grad_norm": 0.503635823726654,
      "learning_rate": 0.00011270502352147098,
      "loss": 2.3691,
      "step": 8920
    },
    {
      "epoch": 1.4288,
      "grad_norm": 0.5595602989196777,
      "learning_rate": 0.00011253366610889944,
      "loss": 2.3793,
      "step": 8930
    },
    {
      "epoch": 1.4304000000000001,
      "grad_norm": 0.5699053406715393,
      "learning_rate": 0.00011236227129770383,
      "loss": 2.3982,
      "step": 8940
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.5490238070487976,
      "learning_rate": 0.00011219083959930108,
      "loss": 2.4112,
      "step": 8950
    },
    {
      "epoch": 1.432,
      "eval_bleu": 35.28777888971279,
      "eval_gen_len": 31.685,
      "eval_loss": 2.6072583198547363,
      "eval_runtime": 63.631,
      "eval_samples_per_second": 15.716,
      "eval_steps_per_second": 0.99,
      "step": 8950
    },
    {
      "epoch": 1.4336,
      "grad_norm": 0.5708601474761963,
      "learning_rate": 0.00011201937152521833,
      "loss": 2.4028,
      "step": 8960
    },
    {
      "epoch": 1.4352,
      "grad_norm": 0.5188197493553162,
      "learning_rate": 0.00011184786758709119,
      "loss": 2.4044,
      "step": 8970
    },
    {
      "epoch": 1.4368,
      "grad_norm": 0.5420824289321899,
      "learning_rate": 0.00011167632829666225,
      "loss": 2.3894,
      "step": 8980
    },
    {
      "epoch": 1.4384000000000001,
      "grad_norm": 0.5632250905036926,
      "learning_rate": 0.00011150475416577972,
      "loss": 2.39,
      "step": 8990
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.5262824296951294,
      "learning_rate": 0.00011133314570639561,
      "loss": 2.3967,
      "step": 9000
    },
    {
      "epoch": 1.44,
      "eval_bleu": 35.32603242208793,
      "eval_gen_len": 31.677,
      "eval_loss": 2.606966733932495,
      "eval_runtime": 63.3189,
      "eval_samples_per_second": 15.793,
      "eval_steps_per_second": 0.995,
      "step": 9000
    },
    {
      "epoch": 1.4416,
      "grad_norm": 0.5293445587158203,
      "learning_rate": 0.00011116150343056446,
      "loss": 2.3858,
      "step": 9010
    },
    {
      "epoch": 1.4432,
      "grad_norm": 0.5696396827697754,
      "learning_rate": 0.00011098982785044166,
      "loss": 2.3951,
      "step": 9020
    },
    {
      "epoch": 1.4447999999999999,
      "grad_norm": 0.5316266417503357,
      "learning_rate": 0.000110818119478282,
      "loss": 2.3978,
      "step": 9030
    },
    {
      "epoch": 1.4464000000000001,
      "grad_norm": 0.5498268008232117,
      "learning_rate": 0.00011064637882643815,
      "loss": 2.3712,
      "step": 9040
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.5632900595664978,
      "learning_rate": 0.00011047460640735905,
      "loss": 2.3937,
      "step": 9050
    },
    {
      "epoch": 1.448,
      "eval_bleu": 35.16693271782191,
      "eval_gen_len": 31.76,
      "eval_loss": 2.6083943843841553,
      "eval_runtime": 64.0313,
      "eval_samples_per_second": 15.617,
      "eval_steps_per_second": 0.984,
      "step": 9050
    },
    {
      "epoch": 1.4496,
      "grad_norm": 0.5173579454421997,
      "learning_rate": 0.00011030280273358841,
      "loss": 2.3786,
      "step": 9060
    },
    {
      "epoch": 1.4512,
      "grad_norm": 0.5553725361824036,
      "learning_rate": 0.00011013096831776331,
      "loss": 2.3842,
      "step": 9070
    },
    {
      "epoch": 1.4527999999999999,
      "grad_norm": 0.4996206760406494,
      "learning_rate": 0.00010995910367261237,
      "loss": 2.3666,
      "step": 9080
    },
    {
      "epoch": 1.4544000000000001,
      "grad_norm": 0.5771286487579346,
      "learning_rate": 0.00010978720931095461,
      "loss": 2.3893,
      "step": 9090
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.5172504782676697,
      "learning_rate": 0.00010961528574569761,
      "loss": 2.4174,
      "step": 9100
    },
    {
      "epoch": 1.456,
      "eval_bleu": 35.447392497336345,
      "eval_gen_len": 31.627,
      "eval_loss": 2.6070451736450195,
      "eval_runtime": 63.0444,
      "eval_samples_per_second": 15.862,
      "eval_steps_per_second": 0.999,
      "step": 9100
    },
    {
      "epoch": 1.4576,
      "grad_norm": 0.5697312355041504,
      "learning_rate": 0.00010944333348983609,
      "loss": 2.385,
      "step": 9110
    },
    {
      "epoch": 1.4592,
      "grad_norm": 0.5459081530570984,
      "learning_rate": 0.00010927135305645043,
      "loss": 2.3717,
      "step": 9120
    },
    {
      "epoch": 1.4607999999999999,
      "grad_norm": 0.5544365644454956,
      "learning_rate": 0.00010909934495870501,
      "loss": 2.3912,
      "step": 9130
    },
    {
      "epoch": 1.4624,
      "grad_norm": 0.544954776763916,
      "learning_rate": 0.00010892730970984683,
      "loss": 2.3852,
      "step": 9140
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.546186089515686,
      "learning_rate": 0.0001087552478232039,
      "loss": 2.3828,
      "step": 9150
    },
    {
      "epoch": 1.464,
      "eval_bleu": 35.37141157489951,
      "eval_gen_len": 31.788,
      "eval_loss": 2.6067702770233154,
      "eval_runtime": 63.5636,
      "eval_samples_per_second": 15.732,
      "eval_steps_per_second": 0.991,
      "step": 9150
    },
    {
      "epoch": 1.4656,
      "grad_norm": 0.5570729374885559,
      "learning_rate": 0.00010858315981218366,
      "loss": 2.3857,
      "step": 9160
    },
    {
      "epoch": 1.4672,
      "grad_norm": 0.5404826998710632,
      "learning_rate": 0.00010841104619027155,
      "loss": 2.3813,
      "step": 9170
    },
    {
      "epoch": 1.4687999999999999,
      "grad_norm": 0.5376919507980347,
      "learning_rate": 0.00010823890747102941,
      "loss": 2.3815,
      "step": 9180
    },
    {
      "epoch": 1.4704,
      "grad_norm": 0.5341330170631409,
      "learning_rate": 0.00010806674416809395,
      "loss": 2.4278,
      "step": 9190
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.5742166042327881,
      "learning_rate": 0.00010789455679517527,
      "loss": 2.3966,
      "step": 9200
    },
    {
      "epoch": 1.472,
      "eval_bleu": 35.450524120703754,
      "eval_gen_len": 31.709,
      "eval_loss": 2.6064236164093018,
      "eval_runtime": 64.6229,
      "eval_samples_per_second": 15.474,
      "eval_steps_per_second": 0.975,
      "step": 9200
    },
    {
      "epoch": 1.4736,
      "grad_norm": 0.5241162180900574,
      "learning_rate": 0.00010772234586605527,
      "loss": 2.3751,
      "step": 9210
    },
    {
      "epoch": 1.4752,
      "grad_norm": 0.5308117866516113,
      "learning_rate": 0.00010755011189458615,
      "loss": 2.375,
      "step": 9220
    },
    {
      "epoch": 1.4768,
      "grad_norm": 0.5517515540122986,
      "learning_rate": 0.00010737785539468885,
      "loss": 2.4045,
      "step": 9230
    },
    {
      "epoch": 1.4784,
      "grad_norm": 0.5801862478256226,
      "learning_rate": 0.00010720557688035153,
      "loss": 2.3638,
      "step": 9240
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.5570066571235657,
      "learning_rate": 0.00010703327686562806,
      "loss": 2.3614,
      "step": 9250
    },
    {
      "epoch": 1.48,
      "eval_bleu": 35.11539512999822,
      "eval_gen_len": 31.723,
      "eval_loss": 2.6039135456085205,
      "eval_runtime": 64.6736,
      "eval_samples_per_second": 15.462,
      "eval_steps_per_second": 0.974,
      "step": 9250
    },
    {
      "epoch": 1.4816,
      "grad_norm": 0.5448171496391296,
      "learning_rate": 0.00010686095586463644,
      "loss": 2.3752,
      "step": 9260
    },
    {
      "epoch": 1.4832,
      "grad_norm": 0.5102360248565674,
      "learning_rate": 0.00010668861439155733,
      "loss": 2.3824,
      "step": 9270
    },
    {
      "epoch": 1.4848,
      "grad_norm": 0.5485404133796692,
      "learning_rate": 0.00010651625296063242,
      "loss": 2.3752,
      "step": 9280
    },
    {
      "epoch": 1.4864,
      "grad_norm": 0.5645152926445007,
      "learning_rate": 0.00010634387208616295,
      "loss": 2.3932,
      "step": 9290
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.506259024143219,
      "learning_rate": 0.00010617147228250825,
      "loss": 2.3729,
      "step": 9300
    },
    {
      "epoch": 1.488,
      "eval_bleu": 34.999038292149685,
      "eval_gen_len": 31.798,
      "eval_loss": 2.606492757797241,
      "eval_runtime": 64.8272,
      "eval_samples_per_second": 15.426,
      "eval_steps_per_second": 0.972,
      "step": 9300
    },
    {
      "epoch": 1.4896,
      "grad_norm": 0.542674720287323,
      "learning_rate": 0.00010599905406408406,
      "loss": 2.3737,
      "step": 9310
    },
    {
      "epoch": 1.4912,
      "grad_norm": 0.5527278780937195,
      "learning_rate": 0.0001058266179453611,
      "loss": 2.3858,
      "step": 9320
    },
    {
      "epoch": 1.4928,
      "grad_norm": 0.532433032989502,
      "learning_rate": 0.00010565416444086353,
      "loss": 2.3683,
      "step": 9330
    },
    {
      "epoch": 1.4944,
      "grad_norm": 0.5394845008850098,
      "learning_rate": 0.00010548169406516731,
      "loss": 2.3748,
      "step": 9340
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.5451290011405945,
      "learning_rate": 0.00010530920733289878,
      "loss": 2.4044,
      "step": 9350
    },
    {
      "epoch": 1.496,
      "eval_bleu": 35.34072215821291,
      "eval_gen_len": 31.777,
      "eval_loss": 2.604771137237549,
      "eval_runtime": 64.0292,
      "eval_samples_per_second": 15.618,
      "eval_steps_per_second": 0.984,
      "step": 9350
    },
    {
      "epoch": 1.4976,
      "grad_norm": 0.5388076901435852,
      "learning_rate": 0.00010513670475873312,
      "loss": 2.3988,
      "step": 9360
    },
    {
      "epoch": 1.4992,
      "grad_norm": 0.5353609323501587,
      "learning_rate": 0.00010496418685739271,
      "loss": 2.3846,
      "step": 9370
    },
    {
      "epoch": 1.5008,
      "grad_norm": 0.5076361894607544,
      "learning_rate": 0.00010479165414364571,
      "loss": 2.3848,
      "step": 9380
    },
    {
      "epoch": 1.5024,
      "grad_norm": 0.530317485332489,
      "learning_rate": 0.00010461910713230452,
      "loss": 2.4093,
      "step": 9390
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.5579835176467896,
      "learning_rate": 0.0001044465463382241,
      "loss": 2.3847,
      "step": 9400
    },
    {
      "epoch": 1.504,
      "eval_bleu": 35.45606915765557,
      "eval_gen_len": 31.757,
      "eval_loss": 2.6045658588409424,
      "eval_runtime": 64.2739,
      "eval_samples_per_second": 15.558,
      "eval_steps_per_second": 0.98,
      "step": 9400
    },
    {
      "epoch": 1.5056,
      "grad_norm": 0.530372679233551,
      "learning_rate": 0.0001042739722763006,
      "loss": 2.4014,
      "step": 9410
    },
    {
      "epoch": 1.5072,
      "grad_norm": 0.5623717904090881,
      "learning_rate": 0.00010410138546146975,
      "loss": 2.3896,
      "step": 9420
    },
    {
      "epoch": 1.5088,
      "grad_norm": 0.5377649068832397,
      "learning_rate": 0.00010392878640870531,
      "loss": 2.4025,
      "step": 9430
    },
    {
      "epoch": 1.5104,
      "grad_norm": 0.5280619859695435,
      "learning_rate": 0.00010375617563301765,
      "loss": 2.3941,
      "step": 9440
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.5984174013137817,
      "learning_rate": 0.00010358355364945196,
      "loss": 2.4109,
      "step": 9450
    },
    {
      "epoch": 1.512,
      "eval_bleu": 35.070476004399865,
      "eval_gen_len": 31.74,
      "eval_loss": 2.60552978515625,
      "eval_runtime": 64.2438,
      "eval_samples_per_second": 15.566,
      "eval_steps_per_second": 0.981,
      "step": 9450
    },
    {
      "epoch": 1.5135999999999998,
      "grad_norm": 0.5649425387382507,
      "learning_rate": 0.000103410920973087,
      "loss": 2.3829,
      "step": 9460
    },
    {
      "epoch": 1.5152,
      "grad_norm": 0.5481292009353638,
      "learning_rate": 0.00010323827811903337,
      "loss": 2.3845,
      "step": 9470
    },
    {
      "epoch": 1.5168,
      "grad_norm": 0.512252151966095,
      "learning_rate": 0.0001030656256024321,
      "loss": 2.3738,
      "step": 9480
    },
    {
      "epoch": 1.5184,
      "grad_norm": 0.5351002216339111,
      "learning_rate": 0.00010289296393845296,
      "loss": 2.4047,
      "step": 9490
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5675930976867676,
      "learning_rate": 0.00010272029364229314,
      "loss": 2.3724,
      "step": 9500
    },
    {
      "epoch": 1.52,
      "eval_bleu": 35.4004206695789,
      "eval_gen_len": 31.589,
      "eval_loss": 2.606377601623535,
      "eval_runtime": 63.8037,
      "eval_samples_per_second": 15.673,
      "eval_steps_per_second": 0.987,
      "step": 9500
    },
    {
      "epoch": 1.5215999999999998,
      "grad_norm": 0.5350260734558105,
      "learning_rate": 0.00010254761522917546,
      "loss": 2.3872,
      "step": 9510
    },
    {
      "epoch": 1.5232,
      "grad_norm": 0.586702287197113,
      "learning_rate": 0.00010237492921434703,
      "loss": 2.3667,
      "step": 9520
    },
    {
      "epoch": 1.5248,
      "grad_norm": 0.546531617641449,
      "learning_rate": 0.00010220223611307764,
      "loss": 2.4051,
      "step": 9530
    },
    {
      "epoch": 1.5264,
      "grad_norm": 0.556644856929779,
      "learning_rate": 0.00010202953644065822,
      "loss": 2.3555,
      "step": 9540
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.5743717551231384,
      "learning_rate": 0.00010185683071239924,
      "loss": 2.3845,
      "step": 9550
    },
    {
      "epoch": 1.528,
      "eval_bleu": 35.33381846642402,
      "eval_gen_len": 31.765,
      "eval_loss": 2.6048786640167236,
      "eval_runtime": 64.2435,
      "eval_samples_per_second": 15.566,
      "eval_steps_per_second": 0.981,
      "step": 9550
    },
    {
      "epoch": 1.5295999999999998,
      "grad_norm": 0.5180618762969971,
      "learning_rate": 0.00010168411944362937,
      "loss": 2.4001,
      "step": 9560
    },
    {
      "epoch": 1.5312000000000001,
      "grad_norm": 0.5891891717910767,
      "learning_rate": 0.00010151140314969373,
      "loss": 2.394,
      "step": 9570
    },
    {
      "epoch": 1.5328,
      "grad_norm": 0.556633710861206,
      "learning_rate": 0.00010133868234595246,
      "loss": 2.3915,
      "step": 9580
    },
    {
      "epoch": 1.5344,
      "grad_norm": 0.5866604447364807,
      "learning_rate": 0.00010116595754777909,
      "loss": 2.4129,
      "step": 9590
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.5459519624710083,
      "learning_rate": 0.00010099322927055915,
      "loss": 2.3609,
      "step": 9600
    },
    {
      "epoch": 1.536,
      "eval_bleu": 35.3788445418208,
      "eval_gen_len": 31.714,
      "eval_loss": 2.6046974658966064,
      "eval_runtime": 64.3497,
      "eval_samples_per_second": 15.54,
      "eval_steps_per_second": 0.979,
      "step": 9600
    },
    {
      "epoch": 1.5375999999999999,
      "grad_norm": 0.5121420621871948,
      "learning_rate": 0.00010082049802968852,
      "loss": 2.4068,
      "step": 9610
    },
    {
      "epoch": 1.5392000000000001,
      "grad_norm": 0.49785828590393066,
      "learning_rate": 0.00010064776434057196,
      "loss": 2.3752,
      "step": 9620
    },
    {
      "epoch": 1.5408,
      "grad_norm": 0.5365146398544312,
      "learning_rate": 0.00010047502871862145,
      "loss": 2.3807,
      "step": 9630
    },
    {
      "epoch": 1.5424,
      "grad_norm": 0.5768697261810303,
      "learning_rate": 0.00010030229167925482,
      "loss": 2.3938,
      "step": 9640
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.577469527721405,
      "learning_rate": 0.00010012955373789406,
      "loss": 2.3754,
      "step": 9650
    },
    {
      "epoch": 1.544,
      "eval_bleu": 35.416913129644456,
      "eval_gen_len": 31.801,
      "eval_loss": 2.6048879623413086,
      "eval_runtime": 65.0798,
      "eval_samples_per_second": 15.366,
      "eval_steps_per_second": 0.968,
      "step": 9650
    },
    {
      "epoch": 1.5455999999999999,
      "grad_norm": 0.5773869752883911,
      "learning_rate": 9.995681540996393e-05,
      "loss": 2.3907,
      "step": 9660
    },
    {
      "epoch": 1.5472000000000001,
      "grad_norm": 0.5333753824234009,
      "learning_rate": 9.978407721089032e-05,
      "loss": 2.3836,
      "step": 9670
    },
    {
      "epoch": 1.5488,
      "grad_norm": 0.543522298336029,
      "learning_rate": 9.961133965609869e-05,
      "loss": 2.3878,
      "step": 9680
    },
    {
      "epoch": 1.5504,
      "grad_norm": 0.5935506820678711,
      "learning_rate": 9.94386032610126e-05,
      "loss": 2.3893,
      "step": 9690
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.5771437287330627,
      "learning_rate": 9.926586854105214e-05,
      "loss": 2.3955,
      "step": 9700
    },
    {
      "epoch": 1.552,
      "eval_bleu": 35.50643887772258,
      "eval_gen_len": 31.804,
      "eval_loss": 2.606341600418091,
      "eval_runtime": 65.1147,
      "eval_samples_per_second": 15.358,
      "eval_steps_per_second": 0.968,
      "step": 9700
    },
    {
      "epoch": 1.5535999999999999,
      "grad_norm": 0.5077915191650391,
      "learning_rate": 9.909313601163247e-05,
      "loss": 2.3686,
      "step": 9710
    },
    {
      "epoch": 1.5552000000000001,
      "grad_norm": 0.5593973994255066,
      "learning_rate": 9.892040618816212e-05,
      "loss": 2.3915,
      "step": 9720
    },
    {
      "epoch": 1.5568,
      "grad_norm": 0.5037922263145447,
      "learning_rate": 9.874767958604158e-05,
      "loss": 2.3948,
      "step": 9730
    },
    {
      "epoch": 1.5584,
      "grad_norm": 0.5337445735931396,
      "learning_rate": 9.857495672066178e-05,
      "loss": 2.3867,
      "step": 9740
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5634691119194031,
      "learning_rate": 9.840223810740238e-05,
      "loss": 2.3905,
      "step": 9750
    },
    {
      "epoch": 1.56,
      "eval_bleu": 35.149085940242344,
      "eval_gen_len": 31.816,
      "eval_loss": 2.6049399375915527,
      "eval_runtime": 64.6647,
      "eval_samples_per_second": 15.464,
      "eval_steps_per_second": 0.974,
      "step": 9750
    },
    {
      "epoch": 1.5615999999999999,
      "grad_norm": 0.511038064956665,
      "learning_rate": 9.822952426163052e-05,
      "loss": 2.3834,
      "step": 9760
    },
    {
      "epoch": 1.5632000000000001,
      "grad_norm": 0.5395445823669434,
      "learning_rate": 9.805681569869897e-05,
      "loss": 2.3689,
      "step": 9770
    },
    {
      "epoch": 1.5648,
      "grad_norm": 0.518589973449707,
      "learning_rate": 9.788411293394482e-05,
      "loss": 2.3875,
      "step": 9780
    },
    {
      "epoch": 1.5664,
      "grad_norm": 0.5448502898216248,
      "learning_rate": 9.771141648268776e-05,
      "loss": 2.3959,
      "step": 9790
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.5395134091377258,
      "learning_rate": 9.753872686022878e-05,
      "loss": 2.3858,
      "step": 9800
    },
    {
      "epoch": 1.568,
      "eval_bleu": 35.28016444228588,
      "eval_gen_len": 31.824,
      "eval_loss": 2.6061625480651855,
      "eval_runtime": 64.2744,
      "eval_samples_per_second": 15.558,
      "eval_steps_per_second": 0.98,
      "step": 9800
    },
    {
      "epoch": 1.5695999999999999,
      "grad_norm": 0.5563472509384155,
      "learning_rate": 9.736604458184839e-05,
      "loss": 2.4174,
      "step": 9810
    },
    {
      "epoch": 1.5712000000000002,
      "grad_norm": 0.5068543553352356,
      "learning_rate": 9.719337016280524e-05,
      "loss": 2.3754,
      "step": 9820
    },
    {
      "epoch": 1.5728,
      "grad_norm": 0.5353646874427795,
      "learning_rate": 9.702070411833446e-05,
      "loss": 2.3922,
      "step": 9830
    },
    {
      "epoch": 1.5744,
      "grad_norm": 0.590503990650177,
      "learning_rate": 9.68480469636463e-05,
      "loss": 2.3966,
      "step": 9840
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.5278748273849487,
      "learning_rate": 9.667539921392439e-05,
      "loss": 2.3643,
      "step": 9850
    },
    {
      "epoch": 1.576,
      "eval_bleu": 35.49438788507532,
      "eval_gen_len": 31.805,
      "eval_loss": 2.6062605381011963,
      "eval_runtime": 63.8204,
      "eval_samples_per_second": 15.669,
      "eval_steps_per_second": 0.987,
      "step": 9850
    },
    {
      "epoch": 1.5776,
      "grad_norm": 0.5803035497665405,
      "learning_rate": 9.650276138432434e-05,
      "loss": 2.4045,
      "step": 9860
    },
    {
      "epoch": 1.5792000000000002,
      "grad_norm": 0.5255987644195557,
      "learning_rate": 9.633013398997212e-05,
      "loss": 2.4101,
      "step": 9870
    },
    {
      "epoch": 1.5808,
      "grad_norm": 0.5102807879447937,
      "learning_rate": 9.615751754596262e-05,
      "loss": 2.3978,
      "step": 9880
    },
    {
      "epoch": 1.5824,
      "grad_norm": 0.5389339327812195,
      "learning_rate": 9.598491256735807e-05,
      "loss": 2.4005,
      "step": 9890
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.5491532683372498,
      "learning_rate": 9.58123195691864e-05,
      "loss": 2.3779,
      "step": 9900
    },
    {
      "epoch": 1.584,
      "eval_bleu": 35.68798013520383,
      "eval_gen_len": 31.865,
      "eval_loss": 2.60599684715271,
      "eval_runtime": 64.3422,
      "eval_samples_per_second": 15.542,
      "eval_steps_per_second": 0.979,
      "step": 9900
    },
    {
      "epoch": 1.5856,
      "grad_norm": 0.5438152551651001,
      "learning_rate": 9.563973906643985e-05,
      "loss": 2.385,
      "step": 9910
    },
    {
      "epoch": 1.5872000000000002,
      "grad_norm": 0.5341200828552246,
      "learning_rate": 9.546717157407336e-05,
      "loss": 2.3897,
      "step": 9920
    },
    {
      "epoch": 1.5888,
      "grad_norm": 0.5792675018310547,
      "learning_rate": 9.529461760700308e-05,
      "loss": 2.3701,
      "step": 9930
    },
    {
      "epoch": 1.5904,
      "grad_norm": 0.5346018075942993,
      "learning_rate": 9.512207768010475e-05,
      "loss": 2.4054,
      "step": 9940
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.5281454920768738,
      "learning_rate": 9.494955230821224e-05,
      "loss": 2.3806,
      "step": 9950
    },
    {
      "epoch": 1.592,
      "eval_bleu": 35.41500597423979,
      "eval_gen_len": 31.885,
      "eval_loss": 2.6038661003112793,
      "eval_runtime": 64.5474,
      "eval_samples_per_second": 15.492,
      "eval_steps_per_second": 0.976,
      "step": 9950
    },
    {
      "epoch": 1.5936,
      "grad_norm": 0.5854355096817017,
      "learning_rate": 9.4777042006116e-05,
      "loss": 2.4002,
      "step": 9960
    },
    {
      "epoch": 1.5952,
      "grad_norm": 0.5033359527587891,
      "learning_rate": 9.460454728856153e-05,
      "loss": 2.3936,
      "step": 9970
    },
    {
      "epoch": 1.5968,
      "grad_norm": 0.5421310663223267,
      "learning_rate": 9.443206867024774e-05,
      "loss": 2.369,
      "step": 9980
    },
    {
      "epoch": 1.5984,
      "grad_norm": 0.5954499244689941,
      "learning_rate": 9.425960666582566e-05,
      "loss": 2.3697,
      "step": 9990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5567716360092163,
      "learning_rate": 9.40871617898966e-05,
      "loss": 2.393,
      "step": 10000
    },
    {
      "epoch": 1.6,
      "eval_bleu": 35.54162723595353,
      "eval_gen_len": 31.792,
      "eval_loss": 2.6056020259857178,
      "eval_runtime": 66.8608,
      "eval_samples_per_second": 14.956,
      "eval_steps_per_second": 0.942,
      "step": 10000
    },
    {
      "epoch": 1.6016,
      "grad_norm": 0.5658271908760071,
      "learning_rate": 9.391473455701085e-05,
      "loss": 2.3891,
      "step": 10010
    },
    {
      "epoch": 1.6032,
      "grad_norm": 0.5903609395027161,
      "learning_rate": 9.374232548166595e-05,
      "loss": 2.4089,
      "step": 10020
    },
    {
      "epoch": 1.6048,
      "grad_norm": 0.5813903212547302,
      "learning_rate": 9.35699350783054e-05,
      "loss": 2.3889,
      "step": 10030
    },
    {
      "epoch": 1.6064,
      "grad_norm": 0.5554575324058533,
      "learning_rate": 9.339756386131689e-05,
      "loss": 2.3773,
      "step": 10040
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.4963899850845337,
      "learning_rate": 9.322521234503088e-05,
      "loss": 2.3757,
      "step": 10050
    },
    {
      "epoch": 1.608,
      "eval_bleu": 35.50638399926506,
      "eval_gen_len": 31.815,
      "eval_loss": 2.604696035385132,
      "eval_runtime": 64.4065,
      "eval_samples_per_second": 15.526,
      "eval_steps_per_second": 0.978,
      "step": 10050
    },
    {
      "epoch": 1.6096,
      "grad_norm": 0.5477702617645264,
      "learning_rate": 9.305288104371909e-05,
      "loss": 2.3814,
      "step": 10060
    },
    {
      "epoch": 1.6112,
      "grad_norm": 0.5897723436355591,
      "learning_rate": 9.288057047159285e-05,
      "loss": 2.391,
      "step": 10070
    },
    {
      "epoch": 1.6128,
      "grad_norm": 0.5187656879425049,
      "learning_rate": 9.27082811428017e-05,
      "loss": 2.4102,
      "step": 10080
    },
    {
      "epoch": 1.6143999999999998,
      "grad_norm": 0.5861486792564392,
      "learning_rate": 9.253601357143171e-05,
      "loss": 2.4129,
      "step": 10090
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.5384039878845215,
      "learning_rate": 9.236376827150412e-05,
      "loss": 2.3792,
      "step": 10100
    },
    {
      "epoch": 1.616,
      "eval_bleu": 35.63780421083272,
      "eval_gen_len": 31.791,
      "eval_loss": 2.604686737060547,
      "eval_runtime": 64.1244,
      "eval_samples_per_second": 15.595,
      "eval_steps_per_second": 0.982,
      "step": 10100
    },
    {
      "epoch": 1.6176,
      "grad_norm": 0.516836941242218,
      "learning_rate": 9.21915457569737e-05,
      "loss": 2.3873,
      "step": 10110
    },
    {
      "epoch": 1.6192,
      "grad_norm": 0.5050800442695618,
      "learning_rate": 9.20193465417272e-05,
      "loss": 2.39,
      "step": 10120
    },
    {
      "epoch": 1.6208,
      "grad_norm": 0.5462073087692261,
      "learning_rate": 9.184717113958185e-05,
      "loss": 2.3744,
      "step": 10130
    },
    {
      "epoch": 1.6223999999999998,
      "grad_norm": 0.5560688972473145,
      "learning_rate": 9.167502006428386e-05,
      "loss": 2.3838,
      "step": 10140
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.5227625370025635,
      "learning_rate": 9.150289382950677e-05,
      "loss": 2.3682,
      "step": 10150
    },
    {
      "epoch": 1.624,
      "eval_bleu": 35.521864638249774,
      "eval_gen_len": 31.767,
      "eval_loss": 2.603651285171509,
      "eval_runtime": 63.811,
      "eval_samples_per_second": 15.671,
      "eval_steps_per_second": 0.987,
      "step": 10150
    },
    {
      "epoch": 1.6256,
      "grad_norm": 0.5739177465438843,
      "learning_rate": 9.13307929488501e-05,
      "loss": 2.3599,
      "step": 10160
    },
    {
      "epoch": 1.6272,
      "grad_norm": 0.534525454044342,
      "learning_rate": 9.115871793583769e-05,
      "loss": 2.3837,
      "step": 10170
    },
    {
      "epoch": 1.6288,
      "grad_norm": 0.5257818102836609,
      "learning_rate": 9.098666930391615e-05,
      "loss": 2.3946,
      "step": 10180
    },
    {
      "epoch": 1.6303999999999998,
      "grad_norm": 0.5564687252044678,
      "learning_rate": 9.081464756645337e-05,
      "loss": 2.3708,
      "step": 10190
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.5234661102294922,
      "learning_rate": 9.064265323673709e-05,
      "loss": 2.3696,
      "step": 10200
    },
    {
      "epoch": 1.6320000000000001,
      "eval_bleu": 35.72534113980952,
      "eval_gen_len": 31.819,
      "eval_loss": 2.6041667461395264,
      "eval_runtime": 64.1625,
      "eval_samples_per_second": 15.585,
      "eval_steps_per_second": 0.982,
      "step": 10200
    },
    {
      "epoch": 1.6336,
      "grad_norm": 0.48447492718696594,
      "learning_rate": 9.047068682797318e-05,
      "loss": 2.3565,
      "step": 10210
    },
    {
      "epoch": 1.6352,
      "grad_norm": 0.4950839579105377,
      "learning_rate": 9.029874885328413e-05,
      "loss": 2.3689,
      "step": 10220
    },
    {
      "epoch": 1.6368,
      "grad_norm": 0.5516993403434753,
      "learning_rate": 9.012683982570782e-05,
      "loss": 2.4097,
      "step": 10230
    },
    {
      "epoch": 1.6383999999999999,
      "grad_norm": 0.5332735776901245,
      "learning_rate": 8.995496025819554e-05,
      "loss": 2.36,
      "step": 10240
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.5878176093101501,
      "learning_rate": 8.978311066361075e-05,
      "loss": 2.3929,
      "step": 10250
    },
    {
      "epoch": 1.6400000000000001,
      "eval_bleu": 35.452940520859734,
      "eval_gen_len": 31.827,
      "eval_loss": 2.6047251224517822,
      "eval_runtime": 63.724,
      "eval_samples_per_second": 15.693,
      "eval_steps_per_second": 0.989,
      "step": 10250
    },
    {
      "epoch": 1.6416,
      "grad_norm": 0.5056371092796326,
      "learning_rate": 8.961129155472748e-05,
      "loss": 2.3949,
      "step": 10260
    },
    {
      "epoch": 1.6432,
      "grad_norm": 0.5726327896118164,
      "learning_rate": 8.94395034442288e-05,
      "loss": 2.4109,
      "step": 10270
    },
    {
      "epoch": 1.6448,
      "grad_norm": 0.6044368147850037,
      "learning_rate": 8.926774684470523e-05,
      "loss": 2.3677,
      "step": 10280
    },
    {
      "epoch": 1.6463999999999999,
      "grad_norm": 0.5737152695655823,
      "learning_rate": 8.909602226865334e-05,
      "loss": 2.3773,
      "step": 10290
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.5446227788925171,
      "learning_rate": 8.892433022847414e-05,
      "loss": 2.3957,
      "step": 10300
    },
    {
      "epoch": 1.6480000000000001,
      "eval_bleu": 35.07523074387689,
      "eval_gen_len": 31.8,
      "eval_loss": 2.6058480739593506,
      "eval_runtime": 63.8709,
      "eval_samples_per_second": 15.657,
      "eval_steps_per_second": 0.986,
      "step": 10300
    },
    {
      "epoch": 1.6496,
      "grad_norm": 0.5132411122322083,
      "learning_rate": 8.87526712364715e-05,
      "loss": 2.3547,
      "step": 10310
    },
    {
      "epoch": 1.6512,
      "grad_norm": 0.5402506589889526,
      "learning_rate": 8.858104580485069e-05,
      "loss": 2.3916,
      "step": 10320
    },
    {
      "epoch": 1.6528,
      "grad_norm": 0.5514023303985596,
      "learning_rate": 8.840945444571694e-05,
      "loss": 2.4027,
      "step": 10330
    },
    {
      "epoch": 1.6543999999999999,
      "grad_norm": 0.5354554653167725,
      "learning_rate": 8.823789767107361e-05,
      "loss": 2.396,
      "step": 10340
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.5316563844680786,
      "learning_rate": 8.806637599282114e-05,
      "loss": 2.3906,
      "step": 10350
    },
    {
      "epoch": 1.6560000000000001,
      "eval_bleu": 35.57358487361386,
      "eval_gen_len": 31.751,
      "eval_loss": 2.6033527851104736,
      "eval_runtime": 63.1818,
      "eval_samples_per_second": 15.827,
      "eval_steps_per_second": 0.997,
      "step": 10350
    },
    {
      "epoch": 1.6576,
      "grad_norm": 0.5577273368835449,
      "learning_rate": 8.789488992275502e-05,
      "loss": 2.394,
      "step": 10360
    },
    {
      "epoch": 1.6592,
      "grad_norm": 0.5191096663475037,
      "learning_rate": 8.772343997256455e-05,
      "loss": 2.373,
      "step": 10370
    },
    {
      "epoch": 1.6608,
      "grad_norm": 0.5817920565605164,
      "learning_rate": 8.755202665383133e-05,
      "loss": 2.417,
      "step": 10380
    },
    {
      "epoch": 1.6623999999999999,
      "grad_norm": 0.5793619751930237,
      "learning_rate": 8.738065047802757e-05,
      "loss": 2.4044,
      "step": 10390
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.5576056241989136,
      "learning_rate": 8.720931195651468e-05,
      "loss": 2.3965,
      "step": 10400
    },
    {
      "epoch": 1.6640000000000001,
      "eval_bleu": 35.246634841878446,
      "eval_gen_len": 31.73,
      "eval_loss": 2.6053683757781982,
      "eval_runtime": 64.9825,
      "eval_samples_per_second": 15.389,
      "eval_steps_per_second": 0.969,
      "step": 10400
    },
    {
      "epoch": 1.6656,
      "grad_norm": 0.5439233183860779,
      "learning_rate": 8.70380116005417e-05,
      "loss": 2.406,
      "step": 10410
    },
    {
      "epoch": 1.6672,
      "grad_norm": 0.5474940538406372,
      "learning_rate": 8.686674992124384e-05,
      "loss": 2.3976,
      "step": 10420
    },
    {
      "epoch": 1.6688,
      "grad_norm": 0.5382832884788513,
      "learning_rate": 8.669552742964084e-05,
      "loss": 2.3918,
      "step": 10430
    },
    {
      "epoch": 1.6703999999999999,
      "grad_norm": 0.4919874370098114,
      "learning_rate": 8.652434463663557e-05,
      "loss": 2.3818,
      "step": 10440
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.49328771233558655,
      "learning_rate": 8.635320205301233e-05,
      "loss": 2.3801,
      "step": 10450
    },
    {
      "epoch": 1.6720000000000002,
      "eval_bleu": 35.14336241487128,
      "eval_gen_len": 31.74,
      "eval_loss": 2.602714776992798,
      "eval_runtime": 63.5159,
      "eval_samples_per_second": 15.744,
      "eval_steps_per_second": 0.992,
      "step": 10450
    },
    {
      "epoch": 1.6736,
      "grad_norm": 0.6002168655395508,
      "learning_rate": 8.618210018943566e-05,
      "loss": 2.3709,
      "step": 10460
    },
    {
      "epoch": 1.6752,
      "grad_norm": 0.5337062478065491,
      "learning_rate": 8.601103955644834e-05,
      "loss": 2.3895,
      "step": 10470
    },
    {
      "epoch": 1.6768,
      "grad_norm": 0.5233415961265564,
      "learning_rate": 8.584002066447036e-05,
      "loss": 2.3952,
      "step": 10480
    },
    {
      "epoch": 1.6784,
      "grad_norm": 0.5383243560791016,
      "learning_rate": 8.566904402379696e-05,
      "loss": 2.4018,
      "step": 10490
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.4877234995365143,
      "learning_rate": 8.549811014459745e-05,
      "loss": 2.3553,
      "step": 10500
    },
    {
      "epoch": 1.6800000000000002,
      "eval_bleu": 35.25026206133343,
      "eval_gen_len": 31.729,
      "eval_loss": 2.603153705596924,
      "eval_runtime": 63.7599,
      "eval_samples_per_second": 15.684,
      "eval_steps_per_second": 0.988,
      "step": 10500
    },
    {
      "epoch": 1.6816,
      "grad_norm": 0.5479464530944824,
      "learning_rate": 8.532721953691343e-05,
      "loss": 2.3986,
      "step": 10510
    },
    {
      "epoch": 1.6832,
      "grad_norm": 0.5687940120697021,
      "learning_rate": 8.515637271065751e-05,
      "loss": 2.3755,
      "step": 10520
    },
    {
      "epoch": 1.6848,
      "grad_norm": 0.510204553604126,
      "learning_rate": 8.498557017561157e-05,
      "loss": 2.3781,
      "step": 10530
    },
    {
      "epoch": 1.6864,
      "grad_norm": 0.5713706612586975,
      "learning_rate": 8.481481244142537e-05,
      "loss": 2.3797,
      "step": 10540
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.535412609577179,
      "learning_rate": 8.464410001761493e-05,
      "loss": 2.3786,
      "step": 10550
    },
    {
      "epoch": 1.688,
      "eval_bleu": 35.468128456528746,
      "eval_gen_len": 31.701,
      "eval_loss": 2.603631019592285,
      "eval_runtime": 63.8651,
      "eval_samples_per_second": 15.658,
      "eval_steps_per_second": 0.986,
      "step": 10550
    },
    {
      "epoch": 1.6896,
      "grad_norm": 0.6038718819618225,
      "learning_rate": 8.447343341356121e-05,
      "loss": 2.3856,
      "step": 10560
    },
    {
      "epoch": 1.6912,
      "grad_norm": 0.5474247932434082,
      "learning_rate": 8.430281313850829e-05,
      "loss": 2.3953,
      "step": 10570
    },
    {
      "epoch": 1.6928,
      "grad_norm": 0.575844943523407,
      "learning_rate": 8.413223970156213e-05,
      "loss": 2.3885,
      "step": 10580
    },
    {
      "epoch": 1.6944,
      "grad_norm": 0.5459827184677124,
      "learning_rate": 8.396171361168888e-05,
      "loss": 2.3743,
      "step": 10590
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.5471497774124146,
      "learning_rate": 8.379123537771338e-05,
      "loss": 2.3846,
      "step": 10600
    },
    {
      "epoch": 1.696,
      "eval_bleu": 35.231244326504076,
      "eval_gen_len": 31.749,
      "eval_loss": 2.6031675338745117,
      "eval_runtime": 63.458,
      "eval_samples_per_second": 15.758,
      "eval_steps_per_second": 0.993,
      "step": 10600
    },
    {
      "epoch": 1.6976,
      "grad_norm": 0.5224770307540894,
      "learning_rate": 8.362080550831776e-05,
      "loss": 2.3968,
      "step": 10610
    },
    {
      "epoch": 1.6992,
      "grad_norm": 0.5389636158943176,
      "learning_rate": 8.345042451203979e-05,
      "loss": 2.37,
      "step": 10620
    },
    {
      "epoch": 1.7008,
      "grad_norm": 0.5037452578544617,
      "learning_rate": 8.328009289727138e-05,
      "loss": 2.3656,
      "step": 10630
    },
    {
      "epoch": 1.7024,
      "grad_norm": 0.5874589681625366,
      "learning_rate": 8.310981117225711e-05,
      "loss": 2.3777,
      "step": 10640
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.5732898712158203,
      "learning_rate": 8.293957984509276e-05,
      "loss": 2.3838,
      "step": 10650
    },
    {
      "epoch": 1.704,
      "eval_bleu": 35.20278175464893,
      "eval_gen_len": 31.753,
      "eval_loss": 2.601330041885376,
      "eval_runtime": 63.6701,
      "eval_samples_per_second": 15.706,
      "eval_steps_per_second": 0.989,
      "step": 10650
    },
    {
      "epoch": 1.7056,
      "grad_norm": 0.558627724647522,
      "learning_rate": 8.276939942372366e-05,
      "loss": 2.3983,
      "step": 10660
    },
    {
      "epoch": 1.7072,
      "grad_norm": 0.5770310759544373,
      "learning_rate": 8.259927041594325e-05,
      "loss": 2.3989,
      "step": 10670
    },
    {
      "epoch": 1.7088,
      "grad_norm": 0.587893009185791,
      "learning_rate": 8.242919332939156e-05,
      "loss": 2.3548,
      "step": 10680
    },
    {
      "epoch": 1.7104,
      "grad_norm": 0.5525707006454468,
      "learning_rate": 8.225916867155372e-05,
      "loss": 2.4,
      "step": 10690
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.6060121059417725,
      "learning_rate": 8.208919694975846e-05,
      "loss": 2.3952,
      "step": 10700
    },
    {
      "epoch": 1.712,
      "eval_bleu": 35.58140876941197,
      "eval_gen_len": 31.826,
      "eval_loss": 2.6020095348358154,
      "eval_runtime": 63.9145,
      "eval_samples_per_second": 15.646,
      "eval_steps_per_second": 0.986,
      "step": 10700
    },
    {
      "epoch": 1.7136,
      "grad_norm": 0.5899191498756409,
      "learning_rate": 8.191927867117645e-05,
      "loss": 2.3769,
      "step": 10710
    },
    {
      "epoch": 1.7151999999999998,
      "grad_norm": 0.521236002445221,
      "learning_rate": 8.1749414342819e-05,
      "loss": 2.3599,
      "step": 10720
    },
    {
      "epoch": 1.7168,
      "grad_norm": 0.5273451209068298,
      "learning_rate": 8.157960447153631e-05,
      "loss": 2.3764,
      "step": 10730
    },
    {
      "epoch": 1.7184,
      "grad_norm": 0.5486270785331726,
      "learning_rate": 8.140984956401623e-05,
      "loss": 2.377,
      "step": 10740
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.5725268125534058,
      "learning_rate": 8.124015012678253e-05,
      "loss": 2.3911,
      "step": 10750
    },
    {
      "epoch": 1.72,
      "eval_bleu": 35.19620632352909,
      "eval_gen_len": 31.685,
      "eval_loss": 2.6012985706329346,
      "eval_runtime": 66.5749,
      "eval_samples_per_second": 15.021,
      "eval_steps_per_second": 0.946,
      "step": 10750
    },
    {
      "epoch": 1.7216,
      "grad_norm": 0.5721226930618286,
      "learning_rate": 8.107050666619347e-05,
      "loss": 2.3998,
      "step": 10760
    },
    {
      "epoch": 1.7231999999999998,
      "grad_norm": 0.5384736657142639,
      "learning_rate": 8.090091968844027e-05,
      "loss": 2.3591,
      "step": 10770
    },
    {
      "epoch": 1.7248,
      "grad_norm": 0.5183674693107605,
      "learning_rate": 8.07313896995457e-05,
      "loss": 2.3966,
      "step": 10780
    },
    {
      "epoch": 1.7264,
      "grad_norm": 0.5505023002624512,
      "learning_rate": 8.056191720536236e-05,
      "loss": 2.3723,
      "step": 10790
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.5508324503898621,
      "learning_rate": 8.039250271157134e-05,
      "loss": 2.3851,
      "step": 10800
    },
    {
      "epoch": 1.728,
      "eval_bleu": 35.41931119911079,
      "eval_gen_len": 31.764,
      "eval_loss": 2.601505756378174,
      "eval_runtime": 63.1996,
      "eval_samples_per_second": 15.823,
      "eval_steps_per_second": 0.997,
      "step": 10800
    },
    {
      "epoch": 1.7296,
      "grad_norm": 0.5289133191108704,
      "learning_rate": 8.022314672368077e-05,
      "loss": 2.3648,
      "step": 10810
    },
    {
      "epoch": 1.7311999999999999,
      "grad_norm": 0.5277541875839233,
      "learning_rate": 8.005384974702403e-05,
      "loss": 2.3954,
      "step": 10820
    },
    {
      "epoch": 1.7328000000000001,
      "grad_norm": 0.5532515645027161,
      "learning_rate": 7.988461228675854e-05,
      "loss": 2.3554,
      "step": 10830
    },
    {
      "epoch": 1.7344,
      "grad_norm": 0.5277793407440186,
      "learning_rate": 7.971543484786408e-05,
      "loss": 2.3845,
      "step": 10840
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.5590259432792664,
      "learning_rate": 7.954631793514138e-05,
      "loss": 2.3695,
      "step": 10850
    },
    {
      "epoch": 1.736,
      "eval_bleu": 35.27054707997986,
      "eval_gen_len": 31.75,
      "eval_loss": 2.603408098220825,
      "eval_runtime": 63.576,
      "eval_samples_per_second": 15.729,
      "eval_steps_per_second": 0.991,
      "step": 10850
    },
    {
      "epoch": 1.7376,
      "grad_norm": 0.5669142603874207,
      "learning_rate": 7.937726205321051e-05,
      "loss": 2.3989,
      "step": 10860
    },
    {
      "epoch": 1.7391999999999999,
      "grad_norm": 0.5001118779182434,
      "learning_rate": 7.920826770650947e-05,
      "loss": 2.3625,
      "step": 10870
    },
    {
      "epoch": 1.7408000000000001,
      "grad_norm": 0.5471991896629333,
      "learning_rate": 7.903933539929265e-05,
      "loss": 2.3663,
      "step": 10880
    },
    {
      "epoch": 1.7424,
      "grad_norm": 0.5826259255409241,
      "learning_rate": 7.887046563562932e-05,
      "loss": 2.3909,
      "step": 10890
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.5692521333694458,
      "learning_rate": 7.870165891940209e-05,
      "loss": 2.3997,
      "step": 10900
    },
    {
      "epoch": 1.744,
      "eval_bleu": 35.229627226878584,
      "eval_gen_len": 31.882,
      "eval_loss": 2.6048786640167236,
      "eval_runtime": 64.6851,
      "eval_samples_per_second": 15.46,
      "eval_steps_per_second": 0.974,
      "step": 10900
    },
    {
      "epoch": 1.7456,
      "grad_norm": 0.5958741903305054,
      "learning_rate": 7.853291575430553e-05,
      "loss": 2.3877,
      "step": 10910
    },
    {
      "epoch": 1.7471999999999999,
      "grad_norm": 0.5748047828674316,
      "learning_rate": 7.836423664384445e-05,
      "loss": 2.3983,
      "step": 10920
    },
    {
      "epoch": 1.7488000000000001,
      "grad_norm": 0.5134322643280029,
      "learning_rate": 7.819562209133272e-05,
      "loss": 2.3857,
      "step": 10930
    },
    {
      "epoch": 1.7504,
      "grad_norm": 0.5707576870918274,
      "learning_rate": 7.802707259989142e-05,
      "loss": 2.4105,
      "step": 10940
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.5385900139808655,
      "learning_rate": 7.785858867244755e-05,
      "loss": 2.3805,
      "step": 10950
    },
    {
      "epoch": 1.752,
      "eval_bleu": 35.10967563318322,
      "eval_gen_len": 31.806,
      "eval_loss": 2.603438138961792,
      "eval_runtime": 64.0187,
      "eval_samples_per_second": 15.62,
      "eval_steps_per_second": 0.984,
      "step": 10950
    },
    {
      "epoch": 1.7536,
      "grad_norm": 0.5546247959136963,
      "learning_rate": 7.769017081173246e-05,
      "loss": 2.3825,
      "step": 10960
    },
    {
      "epoch": 1.7551999999999999,
      "grad_norm": 0.5491384267807007,
      "learning_rate": 7.75218195202804e-05,
      "loss": 2.3825,
      "step": 10970
    },
    {
      "epoch": 1.7568000000000001,
      "grad_norm": 0.5618571639060974,
      "learning_rate": 7.735353530042697e-05,
      "loss": 2.4051,
      "step": 10980
    },
    {
      "epoch": 1.7584,
      "grad_norm": 0.5607051253318787,
      "learning_rate": 7.718531865430763e-05,
      "loss": 2.3939,
      "step": 10990
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5641059279441833,
      "learning_rate": 7.701717008385619e-05,
      "loss": 2.3884,
      "step": 11000
    },
    {
      "epoch": 1.76,
      "eval_bleu": 34.83455271674354,
      "eval_gen_len": 32.004,
      "eval_loss": 2.604304313659668,
      "eval_runtime": 66.9587,
      "eval_samples_per_second": 14.935,
      "eval_steps_per_second": 0.941,
      "step": 11000
    },
    {
      "epoch": 1.7616,
      "grad_norm": 0.5438135862350464,
      "learning_rate": 7.684909009080342e-05,
      "loss": 2.3856,
      "step": 11010
    },
    {
      "epoch": 1.7631999999999999,
      "grad_norm": 0.4984036087989807,
      "learning_rate": 7.668107917667537e-05,
      "loss": 2.3861,
      "step": 11020
    },
    {
      "epoch": 1.7648000000000001,
      "grad_norm": 0.5557815432548523,
      "learning_rate": 7.6513137842792e-05,
      "loss": 2.3771,
      "step": 11030
    },
    {
      "epoch": 1.7664,
      "grad_norm": 0.503434956073761,
      "learning_rate": 7.63452665902656e-05,
      "loss": 2.3817,
      "step": 11040
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.538676381111145,
      "learning_rate": 7.617746591999951e-05,
      "loss": 2.3938,
      "step": 11050
    },
    {
      "epoch": 1.768,
      "eval_bleu": 35.25281650817215,
      "eval_gen_len": 31.802,
      "eval_loss": 2.6041462421417236,
      "eval_runtime": 63.9373,
      "eval_samples_per_second": 15.64,
      "eval_steps_per_second": 0.985,
      "step": 11050
    },
    {
      "epoch": 1.7696,
      "grad_norm": 0.5501751899719238,
      "learning_rate": 7.60097363326863e-05,
      "loss": 2.3657,
      "step": 11060
    },
    {
      "epoch": 1.7711999999999999,
      "grad_norm": 0.55366450548172,
      "learning_rate": 7.58420783288065e-05,
      "loss": 2.4069,
      "step": 11070
    },
    {
      "epoch": 1.7728000000000002,
      "grad_norm": 0.5590780973434448,
      "learning_rate": 7.567449240862706e-05,
      "loss": 2.4034,
      "step": 11080
    },
    {
      "epoch": 1.7744,
      "grad_norm": 0.5128145217895508,
      "learning_rate": 7.550697907219978e-05,
      "loss": 2.3837,
      "step": 11090
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.5803083181381226,
      "learning_rate": 7.533953881935996e-05,
      "loss": 2.3641,
      "step": 11100
    },
    {
      "epoch": 1.776,
      "eval_bleu": 34.901369100627456,
      "eval_gen_len": 31.959,
      "eval_loss": 2.60193133354187,
      "eval_runtime": 66.5611,
      "eval_samples_per_second": 15.024,
      "eval_steps_per_second": 0.946,
      "step": 11100
    },
    {
      "epoch": 1.7776,
      "grad_norm": 0.5244950652122498,
      "learning_rate": 7.517217214972478e-05,
      "loss": 2.3844,
      "step": 11110
    },
    {
      "epoch": 1.7792,
      "grad_norm": 0.5588251352310181,
      "learning_rate": 7.500487956269189e-05,
      "loss": 2.394,
      "step": 11120
    },
    {
      "epoch": 1.7808000000000002,
      "grad_norm": 0.5249931812286377,
      "learning_rate": 7.483766155743781e-05,
      "loss": 2.3848,
      "step": 11130
    },
    {
      "epoch": 1.7824,
      "grad_norm": 0.49351635575294495,
      "learning_rate": 7.467051863291666e-05,
      "loss": 2.3445,
      "step": 11140
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.5469911098480225,
      "learning_rate": 7.450345128785833e-05,
      "loss": 2.4003,
      "step": 11150
    },
    {
      "epoch": 1.784,
      "eval_bleu": 35.10651477391575,
      "eval_gen_len": 31.771,
      "eval_loss": 2.603748083114624,
      "eval_runtime": 62.9194,
      "eval_samples_per_second": 15.893,
      "eval_steps_per_second": 1.001,
      "step": 11150
    },
    {
      "epoch": 1.7856,
      "grad_norm": 0.5241238474845886,
      "learning_rate": 7.433646002076747e-05,
      "loss": 2.396,
      "step": 11160
    },
    {
      "epoch": 1.7872,
      "grad_norm": 0.5268886089324951,
      "learning_rate": 7.416954532992147e-05,
      "loss": 2.4041,
      "step": 11170
    },
    {
      "epoch": 1.7888,
      "grad_norm": 0.5212109088897705,
      "learning_rate": 7.400270771336933e-05,
      "loss": 2.3737,
      "step": 11180
    },
    {
      "epoch": 1.7904,
      "grad_norm": 0.5238746404647827,
      "learning_rate": 7.383594766893005e-05,
      "loss": 2.3937,
      "step": 11190
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.5571846961975098,
      "learning_rate": 7.366926569419123e-05,
      "loss": 2.3877,
      "step": 11200
    },
    {
      "epoch": 1.792,
      "eval_bleu": 35.511191461396834,
      "eval_gen_len": 31.725,
      "eval_loss": 2.6032052040100098,
      "eval_runtime": 64.2994,
      "eval_samples_per_second": 15.552,
      "eval_steps_per_second": 0.98,
      "step": 11200
    },
    {
      "epoch": 1.7936,
      "grad_norm": 0.5262211561203003,
      "learning_rate": 7.350266228650746e-05,
      "loss": 2.4087,
      "step": 11210
    },
    {
      "epoch": 1.7952,
      "grad_norm": 0.5267476439476013,
      "learning_rate": 7.333613794299885e-05,
      "loss": 2.3522,
      "step": 11220
    },
    {
      "epoch": 1.7968,
      "grad_norm": 0.5189518332481384,
      "learning_rate": 7.316969316054973e-05,
      "loss": 2.3581,
      "step": 11230
    },
    {
      "epoch": 1.7984,
      "grad_norm": 0.6001799702644348,
      "learning_rate": 7.30033284358069e-05,
      "loss": 2.3766,
      "step": 11240
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5443314909934998,
      "learning_rate": 7.283704426517839e-05,
      "loss": 2.3792,
      "step": 11250
    },
    {
      "epoch": 1.8,
      "eval_bleu": 35.347369499860946,
      "eval_gen_len": 31.781,
      "eval_loss": 2.6030211448669434,
      "eval_runtime": 65.0759,
      "eval_samples_per_second": 15.367,
      "eval_steps_per_second": 0.968,
      "step": 11250
    },
    {
      "epoch": 1.8016,
      "grad_norm": 0.5283582210540771,
      "learning_rate": 7.267084114483173e-05,
      "loss": 2.37,
      "step": 11260
    },
    {
      "epoch": 1.8032,
      "grad_norm": 0.5060104727745056,
      "learning_rate": 7.250471957069277e-05,
      "loss": 2.3777,
      "step": 11270
    },
    {
      "epoch": 1.8048,
      "grad_norm": 0.5543087720870972,
      "learning_rate": 7.23386800384439e-05,
      "loss": 2.3842,
      "step": 11280
    },
    {
      "epoch": 1.8064,
      "grad_norm": 0.5688833594322205,
      "learning_rate": 7.217272304352285e-05,
      "loss": 2.3771,
      "step": 11290
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.5846405029296875,
      "learning_rate": 7.200684908112091e-05,
      "loss": 2.3842,
      "step": 11300
    },
    {
      "epoch": 1.808,
      "eval_bleu": 35.49226967193113,
      "eval_gen_len": 31.749,
      "eval_loss": 2.6030194759368896,
      "eval_runtime": 64.2565,
      "eval_samples_per_second": 15.563,
      "eval_steps_per_second": 0.98,
      "step": 11300
    },
    {
      "epoch": 1.8096,
      "grad_norm": 0.5452021360397339,
      "learning_rate": 7.184105864618172e-05,
      "loss": 2.3658,
      "step": 11310
    },
    {
      "epoch": 1.8112,
      "grad_norm": 0.5108242630958557,
      "learning_rate": 7.167535223339964e-05,
      "loss": 2.3734,
      "step": 11320
    },
    {
      "epoch": 1.8128,
      "grad_norm": 0.5056204199790955,
      "learning_rate": 7.150973033721838e-05,
      "loss": 2.4218,
      "step": 11330
    },
    {
      "epoch": 1.8144,
      "grad_norm": 0.5692785382270813,
      "learning_rate": 7.134419345182938e-05,
      "loss": 2.3837,
      "step": 11340
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.5962476134300232,
      "learning_rate": 7.117874207117048e-05,
      "loss": 2.3918,
      "step": 11350
    },
    {
      "epoch": 1.8159999999999998,
      "eval_bleu": 35.53760352894574,
      "eval_gen_len": 31.804,
      "eval_loss": 2.6042227745056152,
      "eval_runtime": 64.185,
      "eval_samples_per_second": 15.58,
      "eval_steps_per_second": 0.982,
      "step": 11350
    },
    {
      "epoch": 1.8176,
      "grad_norm": 0.5054916143417358,
      "learning_rate": 7.101337668892436e-05,
      "loss": 2.3482,
      "step": 11360
    },
    {
      "epoch": 1.8192,
      "grad_norm": 0.5711713433265686,
      "learning_rate": 7.084809779851714e-05,
      "loss": 2.3902,
      "step": 11370
    },
    {
      "epoch": 1.8208,
      "grad_norm": 0.5468345880508423,
      "learning_rate": 7.068290589311677e-05,
      "loss": 2.3853,
      "step": 11380
    },
    {
      "epoch": 1.8224,
      "grad_norm": 0.5439866185188293,
      "learning_rate": 7.05178014656317e-05,
      "loss": 2.3819,
      "step": 11390
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.49613019824028015,
      "learning_rate": 7.035278500870944e-05,
      "loss": 2.3956,
      "step": 11400
    },
    {
      "epoch": 1.8239999999999998,
      "eval_bleu": 35.31700994809327,
      "eval_gen_len": 31.79,
      "eval_loss": 2.6034798622131348,
      "eval_runtime": 64.2034,
      "eval_samples_per_second": 15.576,
      "eval_steps_per_second": 0.981,
      "step": 11400
    },
    {
      "epoch": 1.8256000000000001,
      "grad_norm": 0.5626808404922485,
      "learning_rate": 7.018785701473484e-05,
      "loss": 2.3653,
      "step": 11410
    },
    {
      "epoch": 1.8272,
      "grad_norm": 0.5908664464950562,
      "learning_rate": 7.002301797582896e-05,
      "loss": 2.38,
      "step": 11420
    },
    {
      "epoch": 1.8288,
      "grad_norm": 0.529248058795929,
      "learning_rate": 6.98582683838473e-05,
      "loss": 2.386,
      "step": 11430
    },
    {
      "epoch": 1.8304,
      "grad_norm": 0.5647768378257751,
      "learning_rate": 6.969360873037853e-05,
      "loss": 2.3813,
      "step": 11440
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.5468521118164062,
      "learning_rate": 6.952903950674292e-05,
      "loss": 2.3354,
      "step": 11450
    },
    {
      "epoch": 1.8319999999999999,
      "eval_bleu": 35.13564902372652,
      "eval_gen_len": 32.128,
      "eval_loss": 2.6026902198791504,
      "eval_runtime": 67.6168,
      "eval_samples_per_second": 14.789,
      "eval_steps_per_second": 0.932,
      "step": 11450
    },
    {
      "epoch": 1.8336000000000001,
      "grad_norm": 0.536334753036499,
      "learning_rate": 6.936456120399099e-05,
      "loss": 2.3695,
      "step": 11460
    },
    {
      "epoch": 1.8352,
      "grad_norm": 0.5332905054092407,
      "learning_rate": 6.920017431290184e-05,
      "loss": 2.3736,
      "step": 11470
    },
    {
      "epoch": 1.8368,
      "grad_norm": 0.508599579334259,
      "learning_rate": 6.903587932398193e-05,
      "loss": 2.3793,
      "step": 11480
    },
    {
      "epoch": 1.8384,
      "grad_norm": 0.5756316184997559,
      "learning_rate": 6.88716767274634e-05,
      "loss": 2.3978,
      "step": 11490
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.5804696679115295,
      "learning_rate": 6.870756701330277e-05,
      "loss": 2.3817,
      "step": 11500
    },
    {
      "epoch": 1.8399999999999999,
      "eval_bleu": 35.64089295824297,
      "eval_gen_len": 31.691,
      "eval_loss": 2.6027822494506836,
      "eval_runtime": 63.3219,
      "eval_samples_per_second": 15.792,
      "eval_steps_per_second": 0.995,
      "step": 11500
    },
    {
      "epoch": 1.8416000000000001,
      "grad_norm": 0.5249425768852234,
      "learning_rate": 6.85435506711794e-05,
      "loss": 2.3658,
      "step": 11510
    },
    {
      "epoch": 1.8432,
      "grad_norm": 0.529202938079834,
      "learning_rate": 6.837962819049407e-05,
      "loss": 2.3818,
      "step": 11520
    },
    {
      "epoch": 1.8448,
      "grad_norm": 0.5198588967323303,
      "learning_rate": 6.821580006036739e-05,
      "loss": 2.3605,
      "step": 11530
    },
    {
      "epoch": 1.8464,
      "grad_norm": 0.5503648519515991,
      "learning_rate": 6.805206676963853e-05,
      "loss": 2.3745,
      "step": 11540
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.5501954555511475,
      "learning_rate": 6.788842880686367e-05,
      "loss": 2.4098,
      "step": 11550
    },
    {
      "epoch": 1.8479999999999999,
      "eval_bleu": 35.810321176925605,
      "eval_gen_len": 31.807,
      "eval_loss": 2.6018857955932617,
      "eval_runtime": 64.0197,
      "eval_samples_per_second": 15.62,
      "eval_steps_per_second": 0.984,
      "step": 11550
    },
    {
      "epoch": 1.8496000000000001,
      "grad_norm": 0.5736914873123169,
      "learning_rate": 6.772488666031451e-05,
      "loss": 2.3981,
      "step": 11560
    },
    {
      "epoch": 1.8512,
      "grad_norm": 0.5719299912452698,
      "learning_rate": 6.756144081797689e-05,
      "loss": 2.4026,
      "step": 11570
    },
    {
      "epoch": 1.8528,
      "grad_norm": 0.5310307741165161,
      "learning_rate": 6.73980917675492e-05,
      "loss": 2.3752,
      "step": 11580
    },
    {
      "epoch": 1.8544,
      "grad_norm": 0.5417618751525879,
      "learning_rate": 6.723483999644115e-05,
      "loss": 2.3933,
      "step": 11590
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.5389187932014465,
      "learning_rate": 6.707168599177212e-05,
      "loss": 2.3721,
      "step": 11600
    },
    {
      "epoch": 1.8559999999999999,
      "eval_bleu": 35.71740995883798,
      "eval_gen_len": 31.765,
      "eval_loss": 2.6029930114746094,
      "eval_runtime": 64.05,
      "eval_samples_per_second": 15.613,
      "eval_steps_per_second": 0.984,
      "step": 11600
    },
    {
      "epoch": 1.8576000000000001,
      "grad_norm": 0.5157022476196289,
      "learning_rate": 6.69086302403697e-05,
      "loss": 2.3736,
      "step": 11610
    },
    {
      "epoch": 1.8592,
      "grad_norm": 0.5548132658004761,
      "learning_rate": 6.674567322876841e-05,
      "loss": 2.3837,
      "step": 11620
    },
    {
      "epoch": 1.8608,
      "grad_norm": 0.5814404487609863,
      "learning_rate": 6.658281544320814e-05,
      "loss": 2.3967,
      "step": 11630
    },
    {
      "epoch": 1.8624,
      "grad_norm": 0.5458473563194275,
      "learning_rate": 6.642005736963262e-05,
      "loss": 2.3734,
      "step": 11640
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.532230794429779,
      "learning_rate": 6.625739949368814e-05,
      "loss": 2.3888,
      "step": 11650
    },
    {
      "epoch": 1.8639999999999999,
      "eval_bleu": 35.429278822799304,
      "eval_gen_len": 31.781,
      "eval_loss": 2.603076219558716,
      "eval_runtime": 63.9779,
      "eval_samples_per_second": 15.63,
      "eval_steps_per_second": 0.985,
      "step": 11650
    },
    {
      "epoch": 1.8656000000000001,
      "grad_norm": 0.566949188709259,
      "learning_rate": 6.609484230072199e-05,
      "loss": 2.3779,
      "step": 11660
    },
    {
      "epoch": 1.8672,
      "grad_norm": 0.5407467484474182,
      "learning_rate": 6.5932386275781e-05,
      "loss": 2.3776,
      "step": 11670
    },
    {
      "epoch": 1.8688,
      "grad_norm": 0.5686498880386353,
      "learning_rate": 6.577003190361014e-05,
      "loss": 2.37,
      "step": 11680
    },
    {
      "epoch": 1.8704,
      "grad_norm": 0.5406011939048767,
      "learning_rate": 6.560777966865113e-05,
      "loss": 2.3941,
      "step": 11690
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.5308868885040283,
      "learning_rate": 6.544563005504084e-05,
      "loss": 2.3974,
      "step": 11700
    },
    {
      "epoch": 1.8719999999999999,
      "eval_bleu": 35.39066438367831,
      "eval_gen_len": 31.731,
      "eval_loss": 2.602203130722046,
      "eval_runtime": 64.3843,
      "eval_samples_per_second": 15.532,
      "eval_steps_per_second": 0.978,
      "step": 11700
    },
    {
      "epoch": 1.8736000000000002,
      "grad_norm": 0.5583497881889343,
      "learning_rate": 6.528358354660996e-05,
      "loss": 2.3927,
      "step": 11710
    },
    {
      "epoch": 1.8752,
      "grad_norm": 0.5513116717338562,
      "learning_rate": 6.512164062688158e-05,
      "loss": 2.3807,
      "step": 11720
    },
    {
      "epoch": 1.8768,
      "grad_norm": 0.5399806499481201,
      "learning_rate": 6.495980177906965e-05,
      "loss": 2.3641,
      "step": 11730
    },
    {
      "epoch": 1.8784,
      "grad_norm": 0.5416405200958252,
      "learning_rate": 6.479806748607753e-05,
      "loss": 2.3717,
      "step": 11740
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.5919175744056702,
      "learning_rate": 6.463643823049674e-05,
      "loss": 2.397,
      "step": 11750
    },
    {
      "epoch": 1.88,
      "eval_bleu": 35.36311378067169,
      "eval_gen_len": 31.774,
      "eval_loss": 2.6011834144592285,
      "eval_runtime": 64.5128,
      "eval_samples_per_second": 15.501,
      "eval_steps_per_second": 0.977,
      "step": 11750
    },
    {
      "epoch": 1.8816000000000002,
      "grad_norm": 0.5512363314628601,
      "learning_rate": 6.447491449460529e-05,
      "loss": 2.359,
      "step": 11760
    },
    {
      "epoch": 1.8832,
      "grad_norm": 0.512503981590271,
      "learning_rate": 6.431349676036633e-05,
      "loss": 2.3836,
      "step": 11770
    },
    {
      "epoch": 1.8848,
      "grad_norm": 0.5538185834884644,
      "learning_rate": 6.415218550942675e-05,
      "loss": 2.4045,
      "step": 11780
    },
    {
      "epoch": 1.8864,
      "grad_norm": 0.5629356503486633,
      "learning_rate": 6.399098122311571e-05,
      "loss": 2.3643,
      "step": 11790
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.5628117918968201,
      "learning_rate": 6.382988438244319e-05,
      "loss": 2.3533,
      "step": 11800
    },
    {
      "epoch": 1.888,
      "eval_bleu": 35.41138925328321,
      "eval_gen_len": 31.756,
      "eval_loss": 2.6028859615325928,
      "eval_runtime": 63.3124,
      "eval_samples_per_second": 15.795,
      "eval_steps_per_second": 0.995,
      "step": 11800
    },
    {
      "epoch": 1.8896,
      "grad_norm": 0.6356649398803711,
      "learning_rate": 6.366889546809853e-05,
      "loss": 2.3907,
      "step": 11810
    },
    {
      "epoch": 1.8912,
      "grad_norm": 0.5765467286109924,
      "learning_rate": 6.350801496044914e-05,
      "loss": 2.3806,
      "step": 11820
    },
    {
      "epoch": 1.8928,
      "grad_norm": 0.5040643811225891,
      "learning_rate": 6.334724333953886e-05,
      "loss": 2.3765,
      "step": 11830
    },
    {
      "epoch": 1.8944,
      "grad_norm": 0.5327680706977844,
      "learning_rate": 6.318658108508664e-05,
      "loss": 2.3739,
      "step": 11840
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.5242185592651367,
      "learning_rate": 6.302602867648513e-05,
      "loss": 2.4027,
      "step": 11850
    },
    {
      "epoch": 1.896,
      "eval_bleu": 35.3367626883177,
      "eval_gen_len": 31.708,
      "eval_loss": 2.6010544300079346,
      "eval_runtime": 63.6811,
      "eval_samples_per_second": 15.703,
      "eval_steps_per_second": 0.989,
      "step": 11850
    },
    {
      "epoch": 1.8976,
      "grad_norm": 0.5451813340187073,
      "learning_rate": 6.28655865927992e-05,
      "loss": 2.3878,
      "step": 11860
    },
    {
      "epoch": 1.8992,
      "grad_norm": 0.5705596804618835,
      "learning_rate": 6.270525531276457e-05,
      "loss": 2.3733,
      "step": 11870
    },
    {
      "epoch": 1.9008,
      "grad_norm": 0.5623754262924194,
      "learning_rate": 6.254503531478628e-05,
      "loss": 2.3406,
      "step": 11880
    },
    {
      "epoch": 1.9024,
      "grad_norm": 0.536034345626831,
      "learning_rate": 6.238492707693734e-05,
      "loss": 2.3923,
      "step": 11890
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.521543562412262,
      "learning_rate": 6.222493107695727e-05,
      "loss": 2.3617,
      "step": 11900
    },
    {
      "epoch": 1.904,
      "eval_bleu": 35.454001758805724,
      "eval_gen_len": 31.73,
      "eval_loss": 2.599083423614502,
      "eval_runtime": 63.9173,
      "eval_samples_per_second": 15.645,
      "eval_steps_per_second": 0.986,
      "step": 11900
    },
    {
      "epoch": 1.9056,
      "grad_norm": 0.5277134776115417,
      "learning_rate": 6.20650477922507e-05,
      "loss": 2.3779,
      "step": 11910
    },
    {
      "epoch": 1.9072,
      "grad_norm": 0.5506564974784851,
      "learning_rate": 6.190527769988597e-05,
      "loss": 2.3994,
      "step": 11920
    },
    {
      "epoch": 1.9088,
      "grad_norm": 0.5217567682266235,
      "learning_rate": 6.17456212765936e-05,
      "loss": 2.3712,
      "step": 11930
    },
    {
      "epoch": 1.9104,
      "grad_norm": 0.5757546424865723,
      "learning_rate": 6.158607899876497e-05,
      "loss": 2.4132,
      "step": 11940
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.5331911444664001,
      "learning_rate": 6.142665134245093e-05,
      "loss": 2.4197,
      "step": 11950
    },
    {
      "epoch": 1.912,
      "eval_bleu": 35.2453430376225,
      "eval_gen_len": 31.701,
      "eval_loss": 2.599020481109619,
      "eval_runtime": 63.5701,
      "eval_samples_per_second": 15.731,
      "eval_steps_per_second": 0.991,
      "step": 11950
    },
    {
      "epoch": 1.9136,
      "grad_norm": 0.498486191034317,
      "learning_rate": 6.126733878336019e-05,
      "loss": 2.3754,
      "step": 11960
    },
    {
      "epoch": 1.9152,
      "grad_norm": 0.5277700424194336,
      "learning_rate": 6.110814179685811e-05,
      "loss": 2.349,
      "step": 11970
    },
    {
      "epoch": 1.9167999999999998,
      "grad_norm": 0.5424351692199707,
      "learning_rate": 6.0949060857965235e-05,
      "loss": 2.3768,
      "step": 11980
    },
    {
      "epoch": 1.9184,
      "grad_norm": 0.5533198714256287,
      "learning_rate": 6.079009644135575e-05,
      "loss": 2.3783,
      "step": 11990
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.5694267749786377,
      "learning_rate": 6.063124902135617e-05,
      "loss": 2.3977,
      "step": 12000
    },
    {
      "epoch": 1.92,
      "eval_bleu": 35.292920320735625,
      "eval_gen_len": 31.7,
      "eval_loss": 2.5992562770843506,
      "eval_runtime": 63.4218,
      "eval_samples_per_second": 15.767,
      "eval_steps_per_second": 0.993,
      "step": 12000
    },
    {
      "epoch": 1.9216,
      "grad_norm": 0.5631796717643738,
      "learning_rate": 6.0472519071943976e-05,
      "loss": 2.3993,
      "step": 12010
    },
    {
      "epoch": 1.9232,
      "grad_norm": 0.5697488784790039,
      "learning_rate": 6.031390706674609e-05,
      "loss": 2.3687,
      "step": 12020
    },
    {
      "epoch": 1.9247999999999998,
      "grad_norm": 0.5212904214859009,
      "learning_rate": 6.0155413479037456e-05,
      "loss": 2.3549,
      "step": 12030
    },
    {
      "epoch": 1.9264000000000001,
      "grad_norm": 0.5356845855712891,
      "learning_rate": 5.99970387817398e-05,
      "loss": 2.3913,
      "step": 12040
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.5815582275390625,
      "learning_rate": 5.9838783447419974e-05,
      "loss": 2.3976,
      "step": 12050
    },
    {
      "epoch": 1.928,
      "eval_bleu": 35.32200013246893,
      "eval_gen_len": 31.816,
      "eval_loss": 2.600261688232422,
      "eval_runtime": 64.6333,
      "eval_samples_per_second": 15.472,
      "eval_steps_per_second": 0.975,
      "step": 12050
    },
    {
      "epoch": 1.9296,
      "grad_norm": 0.5495690703392029,
      "learning_rate": 5.968064794828875e-05,
      "loss": 2.3862,
      "step": 12060
    },
    {
      "epoch": 1.9312,
      "grad_norm": 0.5902572870254517,
      "learning_rate": 5.952263275619925e-05,
      "loss": 2.3929,
      "step": 12070
    },
    {
      "epoch": 1.9327999999999999,
      "grad_norm": 0.5305599570274353,
      "learning_rate": 5.9364738342645706e-05,
      "loss": 2.3612,
      "step": 12080
    },
    {
      "epoch": 1.9344000000000001,
      "grad_norm": 0.5120882987976074,
      "learning_rate": 5.9206965178761894e-05,
      "loss": 2.3626,
      "step": 12090
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.5315858125686646,
      "learning_rate": 5.90493137353199e-05,
      "loss": 2.3673,
      "step": 12100
    },
    {
      "epoch": 1.936,
      "eval_bleu": 35.42316493399971,
      "eval_gen_len": 31.734,
      "eval_loss": 2.6004629135131836,
      "eval_runtime": 63.7429,
      "eval_samples_per_second": 15.688,
      "eval_steps_per_second": 0.988,
      "step": 12100
    },
    {
      "epoch": 1.9376,
      "grad_norm": 0.4870031774044037,
      "learning_rate": 5.8891784482728475e-05,
      "loss": 2.3679,
      "step": 12110
    },
    {
      "epoch": 1.9392,
      "grad_norm": 0.5337024331092834,
      "learning_rate": 5.8734377891031865e-05,
      "loss": 2.363,
      "step": 12120
    },
    {
      "epoch": 1.9407999999999999,
      "grad_norm": 0.529453694820404,
      "learning_rate": 5.857709442990826e-05,
      "loss": 2.3918,
      "step": 12130
    },
    {
      "epoch": 1.9424000000000001,
      "grad_norm": 0.5454234480857849,
      "learning_rate": 5.8419934568668525e-05,
      "loss": 2.3724,
      "step": 12140
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.5584367513656616,
      "learning_rate": 5.826289877625461e-05,
      "loss": 2.377,
      "step": 12150
    },
    {
      "epoch": 1.944,
      "eval_bleu": 35.569818250926936,
      "eval_gen_len": 31.713,
      "eval_loss": 2.5993258953094482,
      "eval_runtime": 63.1323,
      "eval_samples_per_second": 15.84,
      "eval_steps_per_second": 0.998,
      "step": 12150
    },
    {
      "epoch": 1.9456,
      "grad_norm": 0.5109836459159851,
      "learning_rate": 5.810598752123837e-05,
      "loss": 2.3728,
      "step": 12160
    },
    {
      "epoch": 1.9472,
      "grad_norm": 0.585736095905304,
      "learning_rate": 5.794920127182001e-05,
      "loss": 2.3769,
      "step": 12170
    },
    {
      "epoch": 1.9487999999999999,
      "grad_norm": 0.5318217873573303,
      "learning_rate": 5.7792540495826676e-05,
      "loss": 2.4085,
      "step": 12180
    },
    {
      "epoch": 1.9504000000000001,
      "grad_norm": 0.5595441460609436,
      "learning_rate": 5.7636005660711234e-05,
      "loss": 2.3626,
      "step": 12190
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.5598157644271851,
      "learning_rate": 5.747959723355072e-05,
      "loss": 2.3572,
      "step": 12200
    },
    {
      "epoch": 1.952,
      "eval_bleu": 35.3701703166262,
      "eval_gen_len": 31.805,
      "eval_loss": 2.5989809036254883,
      "eval_runtime": 63.8061,
      "eval_samples_per_second": 15.672,
      "eval_steps_per_second": 0.987,
      "step": 12200
    },
    {
      "epoch": 1.9536,
      "grad_norm": 0.5095769166946411,
      "learning_rate": 5.732331568104489e-05,
      "loss": 2.3685,
      "step": 12210
    },
    {
      "epoch": 1.9552,
      "grad_norm": 0.5206692814826965,
      "learning_rate": 5.716716146951514e-05,
      "loss": 2.3911,
      "step": 12220
    },
    {
      "epoch": 1.9567999999999999,
      "grad_norm": 0.5242315530776978,
      "learning_rate": 5.7011135064902656e-05,
      "loss": 2.3664,
      "step": 12230
    },
    {
      "epoch": 1.9584000000000001,
      "grad_norm": 0.5655657649040222,
      "learning_rate": 5.685523693276743e-05,
      "loss": 2.3504,
      "step": 12240
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.5813314318656921,
      "learning_rate": 5.6699467538286685e-05,
      "loss": 2.3965,
      "step": 12250
    },
    {
      "epoch": 1.96,
      "eval_bleu": 35.33165336835464,
      "eval_gen_len": 31.792,
      "eval_loss": 2.601639986038208,
      "eval_runtime": 64.3236,
      "eval_samples_per_second": 15.546,
      "eval_steps_per_second": 0.979,
      "step": 12250
    },
    {
      "epoch": 1.9616,
      "grad_norm": 0.5721524357795715,
      "learning_rate": 5.654382734625341e-05,
      "loss": 2.3935,
      "step": 12260
    },
    {
      "epoch": 1.9632,
      "grad_norm": 0.5603009462356567,
      "learning_rate": 5.638831682107522e-05,
      "loss": 2.3711,
      "step": 12270
    },
    {
      "epoch": 1.9647999999999999,
      "grad_norm": 0.5314328074455261,
      "learning_rate": 5.623293642677265e-05,
      "loss": 2.3716,
      "step": 12280
    },
    {
      "epoch": 1.9664000000000001,
      "grad_norm": 0.5238741636276245,
      "learning_rate": 5.607768662697812e-05,
      "loss": 2.3731,
      "step": 12290
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.5663348436355591,
      "learning_rate": 5.5922567884934306e-05,
      "loss": 2.3865,
      "step": 12300
    },
    {
      "epoch": 1.968,
      "eval_bleu": 35.27825017181847,
      "eval_gen_len": 31.743,
      "eval_loss": 2.599804401397705,
      "eval_runtime": 63.6608,
      "eval_samples_per_second": 15.708,
      "eval_steps_per_second": 0.99,
      "step": 12300
    },
    {
      "epoch": 1.9696,
      "grad_norm": 0.5401078462600708,
      "learning_rate": 5.5767580663492756e-05,
      "loss": 2.3801,
      "step": 12310
    },
    {
      "epoch": 1.9712,
      "grad_norm": 0.5585622787475586,
      "learning_rate": 5.561272542511267e-05,
      "loss": 2.3841,
      "step": 12320
    },
    {
      "epoch": 1.9727999999999999,
      "grad_norm": 0.5054473876953125,
      "learning_rate": 5.5458002631859394e-05,
      "loss": 2.3747,
      "step": 12330
    },
    {
      "epoch": 1.9744000000000002,
      "grad_norm": 0.4901413917541504,
      "learning_rate": 5.530341274540309e-05,
      "loss": 2.3645,
      "step": 12340
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.5542665719985962,
      "learning_rate": 5.514895622701739e-05,
      "loss": 2.3834,
      "step": 12350
    },
    {
      "epoch": 1.976,
      "eval_bleu": 35.364981370054736,
      "eval_gen_len": 31.784,
      "eval_loss": 2.600111246109009,
      "eval_runtime": 64.2462,
      "eval_samples_per_second": 15.565,
      "eval_steps_per_second": 0.981,
      "step": 12350
    },
    {
      "epoch": 1.9776,
      "grad_norm": 0.5994014143943787,
      "learning_rate": 5.4994633537577836e-05,
      "loss": 2.3812,
      "step": 12360
    },
    {
      "epoch": 1.9792,
      "grad_norm": 0.591452956199646,
      "learning_rate": 5.484044513756077e-05,
      "loss": 2.3777,
      "step": 12370
    },
    {
      "epoch": 1.9808,
      "grad_norm": 0.5803909301757812,
      "learning_rate": 5.4686391487041845e-05,
      "loss": 2.3765,
      "step": 12380
    },
    {
      "epoch": 1.9824000000000002,
      "grad_norm": 0.541860044002533,
      "learning_rate": 5.453247304569451e-05,
      "loss": 2.3917,
      "step": 12390
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.5370111465454102,
      "learning_rate": 5.437869027278893e-05,
      "loss": 2.3895,
      "step": 12400
    },
    {
      "epoch": 1.984,
      "eval_bleu": 35.4677031361144,
      "eval_gen_len": 31.744,
      "eval_loss": 2.6007962226867676,
      "eval_runtime": 63.8789,
      "eval_samples_per_second": 15.655,
      "eval_steps_per_second": 0.986,
      "step": 12400
    },
    {
      "epoch": 1.9856,
      "grad_norm": 0.5437649488449097,
      "learning_rate": 5.4225043627190283e-05,
      "loss": 2.3984,
      "step": 12410
    },
    {
      "epoch": 1.9872,
      "grad_norm": 0.5954484343528748,
      "learning_rate": 5.407153356735772e-05,
      "loss": 2.3928,
      "step": 12420
    },
    {
      "epoch": 1.9888,
      "grad_norm": 0.5347803831100464,
      "learning_rate": 5.3918160551342824e-05,
      "loss": 2.3507,
      "step": 12430
    },
    {
      "epoch": 1.9904,
      "grad_norm": 0.5248757004737854,
      "learning_rate": 5.376492503678807e-05,
      "loss": 2.3523,
      "step": 12440
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.5014564394950867,
      "learning_rate": 5.3611827480925956e-05,
      "loss": 2.3681,
      "step": 12450
    },
    {
      "epoch": 1.992,
      "eval_bleu": 35.569437425320885,
      "eval_gen_len": 31.713,
      "eval_loss": 2.5981125831604004,
      "eval_runtime": 63.4824,
      "eval_samples_per_second": 15.752,
      "eval_steps_per_second": 0.992,
      "step": 12450
    },
    {
      "epoch": 1.9936,
      "grad_norm": 0.5184687376022339,
      "learning_rate": 5.345886834057707e-05,
      "loss": 2.3767,
      "step": 12460
    },
    {
      "epoch": 1.9952,
      "grad_norm": 0.5192435383796692,
      "learning_rate": 5.330604807214909e-05,
      "loss": 2.3849,
      "step": 12470
    },
    {
      "epoch": 1.9968,
      "grad_norm": 0.5144312977790833,
      "learning_rate": 5.31533671316354e-05,
      "loss": 2.3775,
      "step": 12480
    },
    {
      "epoch": 1.9984,
      "grad_norm": 0.5049441456794739,
      "learning_rate": 5.3000825974613454e-05,
      "loss": 2.3734,
      "step": 12490
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5524105429649353,
      "learning_rate": 5.284842505624381e-05,
      "loss": 2.3699,
      "step": 12500
    },
    {
      "epoch": 2.0,
      "eval_bleu": 35.70911211345966,
      "eval_gen_len": 31.731,
      "eval_loss": 2.5988149642944336,
      "eval_runtime": 63.7627,
      "eval_samples_per_second": 15.683,
      "eval_steps_per_second": 0.988,
      "step": 12500
    },
    {
      "epoch": 2.0016,
      "grad_norm": 0.5035766959190369,
      "learning_rate": 5.2696164831268424e-05,
      "loss": 2.3489,
      "step": 12510
    },
    {
      "epoch": 2.0032,
      "grad_norm": 0.5265891551971436,
      "learning_rate": 5.254404575400953e-05,
      "loss": 2.375,
      "step": 12520
    },
    {
      "epoch": 2.0048,
      "grad_norm": 0.5133561491966248,
      "learning_rate": 5.2392068278368225e-05,
      "loss": 2.3361,
      "step": 12530
    },
    {
      "epoch": 2.0064,
      "grad_norm": 0.5554326176643372,
      "learning_rate": 5.224023285782296e-05,
      "loss": 2.358,
      "step": 12540
    },
    {
      "epoch": 2.008,
      "grad_norm": 0.5239599943161011,
      "learning_rate": 5.2088539945428416e-05,
      "loss": 2.3518,
      "step": 12550
    },
    {
      "epoch": 2.008,
      "eval_bleu": 35.23736105541576,
      "eval_gen_len": 31.769,
      "eval_loss": 2.602205514907837,
      "eval_runtime": 65.9246,
      "eval_samples_per_second": 15.169,
      "eval_steps_per_second": 0.956,
      "step": 12550
    },
    {
      "epoch": 2.0096,
      "grad_norm": 0.5696014761924744,
      "learning_rate": 5.1936989993814064e-05,
      "loss": 2.3492,
      "step": 12560
    },
    {
      "epoch": 2.0112,
      "grad_norm": 0.5597238540649414,
      "learning_rate": 5.1785583455182754e-05,
      "loss": 2.3639,
      "step": 12570
    },
    {
      "epoch": 2.0128,
      "grad_norm": 0.5294756889343262,
      "learning_rate": 5.1634320781309434e-05,
      "loss": 2.355,
      "step": 12580
    },
    {
      "epoch": 2.0144,
      "grad_norm": 0.5611149072647095,
      "learning_rate": 5.1483202423539724e-05,
      "loss": 2.3727,
      "step": 12590
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.5736925601959229,
      "learning_rate": 5.13322288327887e-05,
      "loss": 2.3498,
      "step": 12600
    },
    {
      "epoch": 2.016,
      "eval_bleu": 35.17871199259402,
      "eval_gen_len": 31.676,
      "eval_loss": 2.6014797687530518,
      "eval_runtime": 66.7593,
      "eval_samples_per_second": 14.979,
      "eval_steps_per_second": 0.944,
      "step": 12600
    },
    {
      "epoch": 2.0176,
      "grad_norm": 0.5257967710494995,
      "learning_rate": 5.1181400459539495e-05,
      "loss": 2.3424,
      "step": 12610
    },
    {
      "epoch": 2.0192,
      "grad_norm": 0.5847456455230713,
      "learning_rate": 5.1030717753841785e-05,
      "loss": 2.3594,
      "step": 12620
    },
    {
      "epoch": 2.0208,
      "grad_norm": 0.5463986396789551,
      "learning_rate": 5.0880181165310795e-05,
      "loss": 2.3566,
      "step": 12630
    },
    {
      "epoch": 2.0224,
      "grad_norm": 0.5474458932876587,
      "learning_rate": 5.072979114312557e-05,
      "loss": 2.3576,
      "step": 12640
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.5700957775115967,
      "learning_rate": 5.0579548136027966e-05,
      "loss": 2.3696,
      "step": 12650
    },
    {
      "epoch": 2.024,
      "eval_bleu": 35.36225069645139,
      "eval_gen_len": 31.756,
      "eval_loss": 2.603621244430542,
      "eval_runtime": 67.1332,
      "eval_samples_per_second": 14.896,
      "eval_steps_per_second": 0.938,
      "step": 12650
    },
    {
      "epoch": 2.0256,
      "grad_norm": 0.5725476741790771,
      "learning_rate": 5.0429452592321125e-05,
      "loss": 2.3727,
      "step": 12660
    },
    {
      "epoch": 2.0272,
      "grad_norm": 0.5851902961730957,
      "learning_rate": 5.0279504959868086e-05,
      "loss": 2.3749,
      "step": 12670
    },
    {
      "epoch": 2.0288,
      "grad_norm": 0.5518525242805481,
      "learning_rate": 5.012970568609075e-05,
      "loss": 2.3493,
      "step": 12680
    },
    {
      "epoch": 2.0304,
      "grad_norm": 0.6194823384284973,
      "learning_rate": 4.9980055217968116e-05,
      "loss": 2.3682,
      "step": 12690
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.5738052129745483,
      "learning_rate": 4.983055400203528e-05,
      "loss": 2.3627,
      "step": 12700
    },
    {
      "epoch": 2.032,
      "eval_bleu": 35.17070859728413,
      "eval_gen_len": 31.726,
      "eval_loss": 2.604867458343506,
      "eval_runtime": 66.4399,
      "eval_samples_per_second": 15.051,
      "eval_steps_per_second": 0.948,
      "step": 12700
    },
    {
      "epoch": 2.0336,
      "grad_norm": 0.5470172166824341,
      "learning_rate": 4.968120248438204e-05,
      "loss": 2.3491,
      "step": 12710
    },
    {
      "epoch": 2.0352,
      "grad_norm": 0.5320737361907959,
      "learning_rate": 4.953200111065136e-05,
      "loss": 2.3575,
      "step": 12720
    },
    {
      "epoch": 2.0368,
      "grad_norm": 0.5180642604827881,
      "learning_rate": 4.9382950326038324e-05,
      "loss": 2.3711,
      "step": 12730
    },
    {
      "epoch": 2.0384,
      "grad_norm": 0.597466766834259,
      "learning_rate": 4.9234050575288704e-05,
      "loss": 2.3652,
      "step": 12740
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.557363748550415,
      "learning_rate": 4.908530230269746e-05,
      "loss": 2.3584,
      "step": 12750
    },
    {
      "epoch": 2.04,
      "eval_bleu": 35.311045362552534,
      "eval_gen_len": 31.681,
      "eval_loss": 2.6029155254364014,
      "eval_runtime": 67.0164,
      "eval_samples_per_second": 14.922,
      "eval_steps_per_second": 0.94,
      "step": 12750
    },
    {
      "epoch": 2.0416,
      "grad_norm": 0.5649069547653198,
      "learning_rate": 4.893670595210771e-05,
      "loss": 2.3595,
      "step": 12760
    },
    {
      "epoch": 2.0432,
      "grad_norm": 0.557360827922821,
      "learning_rate": 4.878826196690915e-05,
      "loss": 2.3794,
      "step": 12770
    },
    {
      "epoch": 2.0448,
      "grad_norm": 0.5589833855628967,
      "learning_rate": 4.863997079003694e-05,
      "loss": 2.3822,
      "step": 12780
    },
    {
      "epoch": 2.0464,
      "grad_norm": 0.533936083316803,
      "learning_rate": 4.849183286397021e-05,
      "loss": 2.3667,
      "step": 12790
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.5897966623306274,
      "learning_rate": 4.834384863073085e-05,
      "loss": 2.4014,
      "step": 12800
    },
    {
      "epoch": 2.048,
      "eval_bleu": 35.357204351204935,
      "eval_gen_len": 31.762,
      "eval_loss": 2.603346586227417,
      "eval_runtime": 67.6028,
      "eval_samples_per_second": 14.792,
      "eval_steps_per_second": 0.932,
      "step": 12800
    },
    {
      "epoch": 2.0496,
      "grad_norm": 0.5613061189651489,
      "learning_rate": 4.819601853188217e-05,
      "loss": 2.3763,
      "step": 12810
    },
    {
      "epoch": 2.0512,
      "grad_norm": 0.49733442068099976,
      "learning_rate": 4.804834300852746e-05,
      "loss": 2.371,
      "step": 12820
    },
    {
      "epoch": 2.0528,
      "grad_norm": 0.5736902356147766,
      "learning_rate": 4.790082250130891e-05,
      "loss": 2.3967,
      "step": 12830
    },
    {
      "epoch": 2.0544,
      "grad_norm": 0.5226795077323914,
      "learning_rate": 4.775345745040612e-05,
      "loss": 2.373,
      "step": 12840
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.5536108016967773,
      "learning_rate": 4.760624829553477e-05,
      "loss": 2.3557,
      "step": 12850
    },
    {
      "epoch": 2.056,
      "eval_bleu": 35.181601933040696,
      "eval_gen_len": 31.732,
      "eval_loss": 2.603886604309082,
      "eval_runtime": 68.319,
      "eval_samples_per_second": 14.637,
      "eval_steps_per_second": 0.922,
      "step": 12850
    },
    {
      "epoch": 2.0576,
      "grad_norm": 0.5478889346122742,
      "learning_rate": 4.745919547594547e-05,
      "loss": 2.3601,
      "step": 12860
    },
    {
      "epoch": 2.0592,
      "grad_norm": 0.5373307466506958,
      "learning_rate": 4.731229943042225e-05,
      "loss": 2.3507,
      "step": 12870
    },
    {
      "epoch": 2.0608,
      "grad_norm": 0.5278614163398743,
      "learning_rate": 4.71655605972814e-05,
      "loss": 2.3305,
      "step": 12880
    },
    {
      "epoch": 2.0624,
      "grad_norm": 0.579955518245697,
      "learning_rate": 4.701897941437018e-05,
      "loss": 2.3775,
      "step": 12890
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.5452237129211426,
      "learning_rate": 4.687255631906527e-05,
      "loss": 2.3679,
      "step": 12900
    },
    {
      "epoch": 2.064,
      "eval_bleu": 35.12450745240965,
      "eval_gen_len": 31.715,
      "eval_loss": 2.6028151512145996,
      "eval_runtime": 67.5666,
      "eval_samples_per_second": 14.8,
      "eval_steps_per_second": 0.932,
      "step": 12900
    },
    {
      "epoch": 2.0656,
      "grad_norm": 0.5669715404510498,
      "learning_rate": 4.672629174827181e-05,
      "loss": 2.3612,
      "step": 12910
    },
    {
      "epoch": 2.0672,
      "grad_norm": 0.578122079372406,
      "learning_rate": 4.658018613842183e-05,
      "loss": 2.3559,
      "step": 12920
    },
    {
      "epoch": 2.0688,
      "grad_norm": 0.5273522734642029,
      "learning_rate": 4.643423992547309e-05,
      "loss": 2.3421,
      "step": 12930
    },
    {
      "epoch": 2.0704,
      "grad_norm": 0.5649831295013428,
      "learning_rate": 4.628845354490775e-05,
      "loss": 2.3502,
      "step": 12940
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.5510855317115784,
      "learning_rate": 4.614282743173094e-05,
      "loss": 2.3855,
      "step": 12950
    },
    {
      "epoch": 2.072,
      "eval_bleu": 35.54470235649239,
      "eval_gen_len": 31.756,
      "eval_loss": 2.6028025150299072,
      "eval_runtime": 67.7802,
      "eval_samples_per_second": 14.754,
      "eval_steps_per_second": 0.929,
      "step": 12950
    },
    {
      "epoch": 2.0736,
      "grad_norm": 0.5511250495910645,
      "learning_rate": 4.5997362020469693e-05,
      "loss": 2.3461,
      "step": 12960
    },
    {
      "epoch": 2.0752,
      "grad_norm": 0.5527908802032471,
      "learning_rate": 4.585205774517154e-05,
      "loss": 2.3591,
      "step": 12970
    },
    {
      "epoch": 2.0768,
      "grad_norm": 0.5833191871643066,
      "learning_rate": 4.570691503940307e-05,
      "loss": 2.3575,
      "step": 12980
    },
    {
      "epoch": 2.0784,
      "grad_norm": 0.5240541100502014,
      "learning_rate": 4.5561934336248934e-05,
      "loss": 2.3578,
      "step": 12990
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.522953987121582,
      "learning_rate": 4.541711606831026e-05,
      "loss": 2.3488,
      "step": 13000
    },
    {
      "epoch": 2.08,
      "eval_bleu": 35.42233039398145,
      "eval_gen_len": 31.709,
      "eval_loss": 2.603806734085083,
      "eval_runtime": 67.6743,
      "eval_samples_per_second": 14.777,
      "eval_steps_per_second": 0.931,
      "step": 13000
    },
    {
      "epoch": 2.0816,
      "grad_norm": 0.5922940373420715,
      "learning_rate": 4.527246066770358e-05,
      "loss": 2.3642,
      "step": 13010
    },
    {
      "epoch": 2.0832,
      "grad_norm": 0.5671331882476807,
      "learning_rate": 4.512796856605945e-05,
      "loss": 2.3465,
      "step": 13020
    },
    {
      "epoch": 2.0848,
      "grad_norm": 0.5346348285675049,
      "learning_rate": 4.4983640194521045e-05,
      "loss": 2.3779,
      "step": 13030
    },
    {
      "epoch": 2.0864,
      "grad_norm": 0.5431179404258728,
      "learning_rate": 4.4839475983743226e-05,
      "loss": 2.3609,
      "step": 13040
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.6019107699394226,
      "learning_rate": 4.469547636389079e-05,
      "loss": 2.3836,
      "step": 13050
    },
    {
      "epoch": 2.088,
      "eval_bleu": 35.38771233676505,
      "eval_gen_len": 31.841,
      "eval_loss": 2.603689432144165,
      "eval_runtime": 67.8024,
      "eval_samples_per_second": 14.749,
      "eval_steps_per_second": 0.929,
      "step": 13050
    },
    {
      "epoch": 2.0896,
      "grad_norm": 0.528332531452179,
      "learning_rate": 4.455164176463754e-05,
      "loss": 2.325,
      "step": 13060
    },
    {
      "epoch": 2.0912,
      "grad_norm": 0.5732199549674988,
      "learning_rate": 4.4407972615164884e-05,
      "loss": 2.3519,
      "step": 13070
    },
    {
      "epoch": 2.0928,
      "grad_norm": 0.5440359115600586,
      "learning_rate": 4.426446934416046e-05,
      "loss": 2.3563,
      "step": 13080
    },
    {
      "epoch": 2.0944,
      "grad_norm": 0.6383847594261169,
      "learning_rate": 4.412113237981706e-05,
      "loss": 2.3596,
      "step": 13090
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.5560620427131653,
      "learning_rate": 4.397796214983121e-05,
      "loss": 2.3719,
      "step": 13100
    },
    {
      "epoch": 2.096,
      "eval_bleu": 35.274195677170106,
      "eval_gen_len": 31.76,
      "eval_loss": 2.603195905685425,
      "eval_runtime": 66.9257,
      "eval_samples_per_second": 14.942,
      "eval_steps_per_second": 0.941,
      "step": 13100
    },
    {
      "epoch": 2.0976,
      "grad_norm": 0.554434597492218,
      "learning_rate": 4.383495908140185e-05,
      "loss": 2.3574,
      "step": 13110
    },
    {
      "epoch": 2.0992,
      "grad_norm": 0.5383232831954956,
      "learning_rate": 4.369212360122926e-05,
      "loss": 2.3835,
      "step": 13120
    },
    {
      "epoch": 2.1008,
      "grad_norm": 0.5455724000930786,
      "learning_rate": 4.354945613551352e-05,
      "loss": 2.3509,
      "step": 13130
    },
    {
      "epoch": 2.1024,
      "grad_norm": 0.5026989579200745,
      "learning_rate": 4.340695710995349e-05,
      "loss": 2.3561,
      "step": 13140
    },
    {
      "epoch": 2.104,
      "grad_norm": 0.5639000535011292,
      "learning_rate": 4.32646269497454e-05,
      "loss": 2.38,
      "step": 13150
    },
    {
      "epoch": 2.104,
      "eval_bleu": 35.392489654938,
      "eval_gen_len": 31.719,
      "eval_loss": 2.602787494659424,
      "eval_runtime": 66.9112,
      "eval_samples_per_second": 14.945,
      "eval_steps_per_second": 0.942,
      "step": 13150
    },
    {
      "epoch": 2.1056,
      "grad_norm": 0.5695866942405701,
      "learning_rate": 4.312246607958161e-05,
      "loss": 2.3867,
      "step": 13160
    },
    {
      "epoch": 2.1072,
      "grad_norm": 0.5667710304260254,
      "learning_rate": 4.298047492364935e-05,
      "loss": 2.3767,
      "step": 13170
    },
    {
      "epoch": 2.1088,
      "grad_norm": 0.5594437718391418,
      "learning_rate": 4.283865390562939e-05,
      "loss": 2.3667,
      "step": 13180
    },
    {
      "epoch": 2.1104,
      "grad_norm": 0.5157884955406189,
      "learning_rate": 4.26970034486949e-05,
      "loss": 2.3404,
      "step": 13190
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.4976426362991333,
      "learning_rate": 4.255552397551012e-05,
      "loss": 2.3493,
      "step": 13200
    },
    {
      "epoch": 2.112,
      "eval_bleu": 35.32457582555152,
      "eval_gen_len": 31.88,
      "eval_loss": 2.603797197341919,
      "eval_runtime": 68.6977,
      "eval_samples_per_second": 14.557,
      "eval_steps_per_second": 0.917,
      "step": 13200
    },
    {
      "epoch": 2.1136,
      "grad_norm": 0.5511054992675781,
      "learning_rate": 4.241421590822903e-05,
      "loss": 2.3578,
      "step": 13210
    },
    {
      "epoch": 2.1152,
      "grad_norm": 0.5430213212966919,
      "learning_rate": 4.2273079668494234e-05,
      "loss": 2.3859,
      "step": 13220
    },
    {
      "epoch": 2.1168,
      "grad_norm": 0.5298767685890198,
      "learning_rate": 4.213211567743564e-05,
      "loss": 2.3634,
      "step": 13230
    },
    {
      "epoch": 2.1184,
      "grad_norm": 0.529369056224823,
      "learning_rate": 4.1991324355669085e-05,
      "loss": 2.3614,
      "step": 13240
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.5822128057479858,
      "learning_rate": 4.1850706123295314e-05,
      "loss": 2.3571,
      "step": 13250
    },
    {
      "epoch": 2.12,
      "eval_bleu": 35.30236493336294,
      "eval_gen_len": 31.822,
      "eval_loss": 2.6035349369049072,
      "eval_runtime": 67.6638,
      "eval_samples_per_second": 14.779,
      "eval_steps_per_second": 0.931,
      "step": 13250
    },
    {
      "epoch": 2.1216,
      "grad_norm": 0.4956713616847992,
      "learning_rate": 4.171026139989844e-05,
      "loss": 2.3369,
      "step": 13260
    },
    {
      "epoch": 2.1232,
      "grad_norm": 0.5192974805831909,
      "learning_rate": 4.15699906045451e-05,
      "loss": 2.35,
      "step": 13270
    },
    {
      "epoch": 2.1248,
      "grad_norm": 0.5929336547851562,
      "learning_rate": 4.1429894155782686e-05,
      "loss": 2.3418,
      "step": 13280
    },
    {
      "epoch": 2.1264,
      "grad_norm": 0.5602583289146423,
      "learning_rate": 4.1289972471638526e-05,
      "loss": 2.3521,
      "step": 13290
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.5109929442405701,
      "learning_rate": 4.1150225969618475e-05,
      "loss": 2.3647,
      "step": 13300
    },
    {
      "epoch": 2.128,
      "eval_bleu": 35.574828607022795,
      "eval_gen_len": 31.821,
      "eval_loss": 2.603478193283081,
      "eval_runtime": 67.9931,
      "eval_samples_per_second": 14.707,
      "eval_steps_per_second": 0.927,
      "step": 13300
    },
    {
      "epoch": 2.1296,
      "grad_norm": 0.5453001856803894,
      "learning_rate": 4.101065506670554e-05,
      "loss": 2.338,
      "step": 13310
    },
    {
      "epoch": 2.1312,
      "grad_norm": 0.5186697244644165,
      "learning_rate": 4.0871260179358895e-05,
      "loss": 2.3243,
      "step": 13320
    },
    {
      "epoch": 2.1328,
      "grad_norm": 0.5597323179244995,
      "learning_rate": 4.073204172351251e-05,
      "loss": 2.3594,
      "step": 13330
    },
    {
      "epoch": 2.1344,
      "grad_norm": 0.5287715792655945,
      "learning_rate": 4.059300011457381e-05,
      "loss": 2.3527,
      "step": 13340
    },
    {
      "epoch": 2.136,
      "grad_norm": 0.5650032758712769,
      "learning_rate": 4.045413576742264e-05,
      "loss": 2.3584,
      "step": 13350
    },
    {
      "epoch": 2.136,
      "eval_bleu": 35.434310824796526,
      "eval_gen_len": 31.796,
      "eval_loss": 2.6040596961975098,
      "eval_runtime": 66.9729,
      "eval_samples_per_second": 14.931,
      "eval_steps_per_second": 0.941,
      "step": 13350
    },
    {
      "epoch": 2.1376,
      "grad_norm": 0.5241771340370178,
      "learning_rate": 4.031544909640983e-05,
      "loss": 2.3364,
      "step": 13360
    },
    {
      "epoch": 2.1391999999999998,
      "grad_norm": 0.5226497650146484,
      "learning_rate": 4.017694051535611e-05,
      "loss": 2.3736,
      "step": 13370
    },
    {
      "epoch": 2.1408,
      "grad_norm": 0.5585300326347351,
      "learning_rate": 4.0038610437550814e-05,
      "loss": 2.3656,
      "step": 13380
    },
    {
      "epoch": 2.1424,
      "grad_norm": 0.5278311967849731,
      "learning_rate": 3.9900459275750624e-05,
      "loss": 2.3326,
      "step": 13390
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.5459612607955933,
      "learning_rate": 3.976248744217842e-05,
      "loss": 2.3769,
      "step": 13400
    },
    {
      "epoch": 2.144,
      "eval_bleu": 35.346595698993454,
      "eval_gen_len": 31.777,
      "eval_loss": 2.602907180786133,
      "eval_runtime": 66.7466,
      "eval_samples_per_second": 14.982,
      "eval_steps_per_second": 0.944,
      "step": 13400
    },
    {
      "epoch": 2.1456,
      "grad_norm": 0.6028030514717102,
      "learning_rate": 3.962469534852188e-05,
      "loss": 2.3704,
      "step": 13410
    },
    {
      "epoch": 2.1471999999999998,
      "grad_norm": 0.5825819969177246,
      "learning_rate": 3.948708340593246e-05,
      "loss": 2.3659,
      "step": 13420
    },
    {
      "epoch": 2.1488,
      "grad_norm": 0.5319246649742126,
      "learning_rate": 3.9349652025024066e-05,
      "loss": 2.4085,
      "step": 13430
    },
    {
      "epoch": 2.1504,
      "grad_norm": 0.5429398417472839,
      "learning_rate": 3.921240161587176e-05,
      "loss": 2.3838,
      "step": 13440
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.5548965334892273,
      "learning_rate": 3.90753325880107e-05,
      "loss": 2.3978,
      "step": 13450
    },
    {
      "epoch": 2.152,
      "eval_bleu": 35.349558429332355,
      "eval_gen_len": 31.794,
      "eval_loss": 2.6035358905792236,
      "eval_runtime": 66.9584,
      "eval_samples_per_second": 14.935,
      "eval_steps_per_second": 0.941,
      "step": 13450
    },
    {
      "epoch": 2.1536,
      "grad_norm": 0.5237571597099304,
      "learning_rate": 3.893844535043481e-05,
      "loss": 2.3376,
      "step": 13460
    },
    {
      "epoch": 2.1552,
      "grad_norm": 0.5357208847999573,
      "learning_rate": 3.880174031159551e-05,
      "loss": 2.3967,
      "step": 13470
    },
    {
      "epoch": 2.1568,
      "grad_norm": 0.5519906282424927,
      "learning_rate": 3.8665217879400675e-05,
      "loss": 2.3847,
      "step": 13480
    },
    {
      "epoch": 2.1584,
      "grad_norm": 0.5051364898681641,
      "learning_rate": 3.8528878461213136e-05,
      "loss": 2.3433,
      "step": 13490
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.5282073616981506,
      "learning_rate": 3.839272246384991e-05,
      "loss": 2.3606,
      "step": 13500
    },
    {
      "epoch": 2.16,
      "eval_bleu": 35.3114200505196,
      "eval_gen_len": 31.763,
      "eval_loss": 2.6024696826934814,
      "eval_runtime": 67.1633,
      "eval_samples_per_second": 14.889,
      "eval_steps_per_second": 0.938,
      "step": 13500
    },
    {
      "epoch": 2.1616,
      "grad_norm": 0.5352007746696472,
      "learning_rate": 3.825675029358041e-05,
      "loss": 2.3569,
      "step": 13510
    },
    {
      "epoch": 2.1632,
      "grad_norm": 0.6002614498138428,
      "learning_rate": 3.8120962356125766e-05,
      "loss": 2.3642,
      "step": 13520
    },
    {
      "epoch": 2.1648,
      "grad_norm": 0.5405141115188599,
      "learning_rate": 3.798535905665729e-05,
      "loss": 2.3445,
      "step": 13530
    },
    {
      "epoch": 2.1664,
      "grad_norm": 0.5144091844558716,
      "learning_rate": 3.784994079979532e-05,
      "loss": 2.3544,
      "step": 13540
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.5486323237419128,
      "learning_rate": 3.771470798960812e-05,
      "loss": 2.3548,
      "step": 13550
    },
    {
      "epoch": 2.168,
      "eval_bleu": 35.29472271353244,
      "eval_gen_len": 31.768,
      "eval_loss": 2.6028122901916504,
      "eval_runtime": 67.2592,
      "eval_samples_per_second": 14.868,
      "eval_steps_per_second": 0.937,
      "step": 13550
    },
    {
      "epoch": 2.1696,
      "grad_norm": 0.5389690399169922,
      "learning_rate": 3.7579661029610654e-05,
      "loss": 2.3547,
      "step": 13560
    },
    {
      "epoch": 2.1712,
      "grad_norm": 0.5018671751022339,
      "learning_rate": 3.7444800322763176e-05,
      "loss": 2.3332,
      "step": 13570
    },
    {
      "epoch": 2.1728,
      "grad_norm": 0.5564442873001099,
      "learning_rate": 3.731012627147034e-05,
      "loss": 2.3663,
      "step": 13580
    },
    {
      "epoch": 2.1744,
      "grad_norm": 0.5463542342185974,
      "learning_rate": 3.717563927757981e-05,
      "loss": 2.3632,
      "step": 13590
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.5258272886276245,
      "learning_rate": 3.704133974238102e-05,
      "loss": 2.3705,
      "step": 13600
    },
    {
      "epoch": 2.176,
      "eval_bleu": 35.280122961773046,
      "eval_gen_len": 31.808,
      "eval_loss": 2.6036252975463867,
      "eval_runtime": 67.1496,
      "eval_samples_per_second": 14.892,
      "eval_steps_per_second": 0.938,
      "step": 13600
    },
    {
      "epoch": 2.1776,
      "grad_norm": 0.5153448581695557,
      "learning_rate": 3.690722806660414e-05,
      "loss": 2.3651,
      "step": 13610
    },
    {
      "epoch": 2.1792,
      "grad_norm": 0.5421403646469116,
      "learning_rate": 3.6773304650418785e-05,
      "loss": 2.3771,
      "step": 13620
    },
    {
      "epoch": 2.1808,
      "grad_norm": 0.525142252445221,
      "learning_rate": 3.6639569893432845e-05,
      "loss": 2.3526,
      "step": 13630
    },
    {
      "epoch": 2.1824,
      "grad_norm": 0.5476612448692322,
      "learning_rate": 3.650602419469117e-05,
      "loss": 2.3674,
      "step": 13640
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.5609980821609497,
      "learning_rate": 3.637266795267461e-05,
      "loss": 2.3505,
      "step": 13650
    },
    {
      "epoch": 2.184,
      "eval_bleu": 35.4228298887288,
      "eval_gen_len": 31.713,
      "eval_loss": 2.6036465167999268,
      "eval_runtime": 67.1872,
      "eval_samples_per_second": 14.884,
      "eval_steps_per_second": 0.938,
      "step": 13650
    },
    {
      "epoch": 2.1856,
      "grad_norm": 0.5176594853401184,
      "learning_rate": 3.62395015652987e-05,
      "loss": 2.3505,
      "step": 13660
    },
    {
      "epoch": 2.1872,
      "grad_norm": 0.535144031047821,
      "learning_rate": 3.6106525429912364e-05,
      "loss": 2.3612,
      "step": 13670
    },
    {
      "epoch": 2.1888,
      "grad_norm": 0.5260616540908813,
      "learning_rate": 3.597373994329696e-05,
      "loss": 2.3525,
      "step": 13680
    },
    {
      "epoch": 2.1904,
      "grad_norm": 0.5178719162940979,
      "learning_rate": 3.584114550166494e-05,
      "loss": 2.3575,
      "step": 13690
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.5644270181655884,
      "learning_rate": 3.570874250065865e-05,
      "loss": 2.3748,
      "step": 13700
    },
    {
      "epoch": 2.192,
      "eval_bleu": 35.49843015555975,
      "eval_gen_len": 31.773,
      "eval_loss": 2.6028800010681152,
      "eval_runtime": 66.9826,
      "eval_samples_per_second": 14.929,
      "eval_steps_per_second": 0.941,
      "step": 13700
    },
    {
      "epoch": 2.1936,
      "grad_norm": 0.614454448223114,
      "learning_rate": 3.557653133534931e-05,
      "loss": 2.3845,
      "step": 13710
    },
    {
      "epoch": 2.1952,
      "grad_norm": 0.567747175693512,
      "learning_rate": 3.544451240023566e-05,
      "loss": 2.3815,
      "step": 13720
    },
    {
      "epoch": 2.1968,
      "grad_norm": 0.563075065612793,
      "learning_rate": 3.531268608924281e-05,
      "loss": 2.3546,
      "step": 13730
    },
    {
      "epoch": 2.1984,
      "grad_norm": 0.541021466255188,
      "learning_rate": 3.518105279572128e-05,
      "loss": 2.3597,
      "step": 13740
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5356302857398987,
      "learning_rate": 3.504961291244544e-05,
      "loss": 2.3835,
      "step": 13750
    },
    {
      "epoch": 2.2,
      "eval_bleu": 35.28386132330664,
      "eval_gen_len": 31.801,
      "eval_loss": 2.60398268699646,
      "eval_runtime": 67.586,
      "eval_samples_per_second": 14.796,
      "eval_steps_per_second": 0.932,
      "step": 13750
    },
    {
      "epoch": 2.2016,
      "grad_norm": 0.5454393625259399,
      "learning_rate": 3.491836683161273e-05,
      "loss": 2.369,
      "step": 13760
    },
    {
      "epoch": 2.2032,
      "grad_norm": 0.5367892980575562,
      "learning_rate": 3.4787314944842156e-05,
      "loss": 2.3723,
      "step": 13770
    },
    {
      "epoch": 2.2048,
      "grad_norm": 0.5338094234466553,
      "learning_rate": 3.46564576431734e-05,
      "loss": 2.3893,
      "step": 13780
    },
    {
      "epoch": 2.2064,
      "grad_norm": 0.5474802255630493,
      "learning_rate": 3.45257953170655e-05,
      "loss": 2.3549,
      "step": 13790
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.569827675819397,
      "learning_rate": 3.439532835639566e-05,
      "loss": 2.3624,
      "step": 13800
    },
    {
      "epoch": 2.208,
      "eval_bleu": 35.52687677265865,
      "eval_gen_len": 31.736,
      "eval_loss": 2.602145195007324,
      "eval_runtime": 66.8869,
      "eval_samples_per_second": 14.951,
      "eval_steps_per_second": 0.942,
      "step": 13800
    },
    {
      "epoch": 2.2096,
      "grad_norm": 0.5974500179290771,
      "learning_rate": 3.42650571504582e-05,
      "loss": 2.3525,
      "step": 13810
    },
    {
      "epoch": 2.2112,
      "grad_norm": 0.5088686347007751,
      "learning_rate": 3.4134982087963364e-05,
      "loss": 2.3761,
      "step": 13820
    },
    {
      "epoch": 2.2128,
      "grad_norm": 0.5457280874252319,
      "learning_rate": 3.400510355703601e-05,
      "loss": 2.385,
      "step": 13830
    },
    {
      "epoch": 2.2144,
      "grad_norm": 0.5538635849952698,
      "learning_rate": 3.387542194521469e-05,
      "loss": 2.3374,
      "step": 13840
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.5709328651428223,
      "learning_rate": 3.374593763945035e-05,
      "loss": 2.348,
      "step": 13850
    },
    {
      "epoch": 2.216,
      "eval_bleu": 35.48327604279509,
      "eval_gen_len": 31.726,
      "eval_loss": 2.603179454803467,
      "eval_runtime": 66.6039,
      "eval_samples_per_second": 15.014,
      "eval_steps_per_second": 0.946,
      "step": 13850
    },
    {
      "epoch": 2.2176,
      "grad_norm": 0.5884390473365784,
      "learning_rate": 3.3616651026105195e-05,
      "loss": 2.3808,
      "step": 13860
    },
    {
      "epoch": 2.2192,
      "grad_norm": 0.5717592835426331,
      "learning_rate": 3.3487562490951576e-05,
      "loss": 2.3512,
      "step": 13870
    },
    {
      "epoch": 2.2208,
      "grad_norm": 0.5277503728866577,
      "learning_rate": 3.33586724191707e-05,
      "loss": 2.3666,
      "step": 13880
    },
    {
      "epoch": 2.2224,
      "grad_norm": 0.5626149773597717,
      "learning_rate": 3.322998119535176e-05,
      "loss": 2.3825,
      "step": 13890
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.5349565148353577,
      "learning_rate": 3.310148920349041e-05,
      "loss": 2.3392,
      "step": 13900
    },
    {
      "epoch": 2.224,
      "eval_bleu": 35.4928096824065,
      "eval_gen_len": 31.734,
      "eval_loss": 2.603504180908203,
      "eval_runtime": 67.3133,
      "eval_samples_per_second": 14.856,
      "eval_steps_per_second": 0.936,
      "step": 13900
    },
    {
      "epoch": 2.2256,
      "grad_norm": 0.539142906665802,
      "learning_rate": 3.297319682698801e-05,
      "loss": 2.3403,
      "step": 13910
    },
    {
      "epoch": 2.2272,
      "grad_norm": 0.5463541150093079,
      "learning_rate": 3.284510444865023e-05,
      "loss": 2.3811,
      "step": 13920
    },
    {
      "epoch": 2.2288,
      "grad_norm": 0.5264583826065063,
      "learning_rate": 3.271721245068593e-05,
      "loss": 2.3812,
      "step": 13930
    },
    {
      "epoch": 2.2304,
      "grad_norm": 0.5949192643165588,
      "learning_rate": 3.2589521214706095e-05,
      "loss": 2.3755,
      "step": 13940
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.5703097581863403,
      "learning_rate": 3.246203112172275e-05,
      "loss": 2.3585,
      "step": 13950
    },
    {
      "epoch": 2.232,
      "eval_bleu": 35.356738460831146,
      "eval_gen_len": 31.74,
      "eval_loss": 2.6019465923309326,
      "eval_runtime": 66.8098,
      "eval_samples_per_second": 14.968,
      "eval_steps_per_second": 0.943,
      "step": 13950
    },
    {
      "epoch": 2.2336,
      "grad_norm": 0.5516942143440247,
      "learning_rate": 3.2334742552147536e-05,
      "loss": 2.3524,
      "step": 13960
    },
    {
      "epoch": 2.2352,
      "grad_norm": 0.5621036887168884,
      "learning_rate": 3.220765588579103e-05,
      "loss": 2.3456,
      "step": 13970
    },
    {
      "epoch": 2.2368,
      "grad_norm": 0.5392322540283203,
      "learning_rate": 3.208077150186115e-05,
      "loss": 2.3733,
      "step": 13980
    },
    {
      "epoch": 2.2384,
      "grad_norm": 0.559587299823761,
      "learning_rate": 3.1954089778962374e-05,
      "loss": 2.3799,
      "step": 13990
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.5723318457603455,
      "learning_rate": 3.1827611095094346e-05,
      "loss": 2.3699,
      "step": 14000
    },
    {
      "epoch": 2.24,
      "eval_bleu": 35.30611365427946,
      "eval_gen_len": 31.721,
      "eval_loss": 2.603074312210083,
      "eval_runtime": 66.3983,
      "eval_samples_per_second": 15.061,
      "eval_steps_per_second": 0.949,
      "step": 14000
    },
    {
      "epoch": 2.2416,
      "grad_norm": 0.5551806688308716,
      "learning_rate": 3.1701335827650967e-05,
      "loss": 2.3477,
      "step": 14010
    },
    {
      "epoch": 2.2432,
      "grad_norm": 0.5721673965454102,
      "learning_rate": 3.157526435341919e-05,
      "loss": 2.3239,
      "step": 14020
    },
    {
      "epoch": 2.2448,
      "grad_norm": 0.5721824169158936,
      "learning_rate": 3.1449397048577735e-05,
      "loss": 2.3842,
      "step": 14030
    },
    {
      "epoch": 2.2464,
      "grad_norm": 0.5332202911376953,
      "learning_rate": 3.132373428869626e-05,
      "loss": 2.3568,
      "step": 14040
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.5690281987190247,
      "learning_rate": 3.1198276448734064e-05,
      "loss": 2.3536,
      "step": 14050
    },
    {
      "epoch": 2.248,
      "eval_bleu": 35.49761510346628,
      "eval_gen_len": 31.793,
      "eval_loss": 2.6018214225769043,
      "eval_runtime": 67.7512,
      "eval_samples_per_second": 14.76,
      "eval_steps_per_second": 0.93,
      "step": 14050
    },
    {
      "epoch": 2.2496,
      "grad_norm": 0.5477402806282043,
      "learning_rate": 3.107302390303891e-05,
      "loss": 2.35,
      "step": 14060
    },
    {
      "epoch": 2.2512,
      "grad_norm": 0.5613493919372559,
      "learning_rate": 3.094797702534608e-05,
      "loss": 2.3609,
      "step": 14070
    },
    {
      "epoch": 2.2528,
      "grad_norm": 0.5536848306655884,
      "learning_rate": 3.082313618877713e-05,
      "loss": 2.3782,
      "step": 14080
    },
    {
      "epoch": 2.2544,
      "grad_norm": 0.5273656845092773,
      "learning_rate": 3.069850176583886e-05,
      "loss": 2.3762,
      "step": 14090
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.5847275257110596,
      "learning_rate": 3.057407412842216e-05,
      "loss": 2.3567,
      "step": 14100
    },
    {
      "epoch": 2.2560000000000002,
      "eval_bleu": 35.25235274334745,
      "eval_gen_len": 31.748,
      "eval_loss": 2.603606700897217,
      "eval_runtime": 67.2824,
      "eval_samples_per_second": 14.863,
      "eval_steps_per_second": 0.936,
      "step": 14100
    },
    {
      "epoch": 2.2576,
      "grad_norm": 0.5624591112136841,
      "learning_rate": 3.0449853647800786e-05,
      "loss": 2.3551,
      "step": 14110
    },
    {
      "epoch": 2.2592,
      "grad_norm": 0.5501644611358643,
      "learning_rate": 3.0325840694630557e-05,
      "loss": 2.3721,
      "step": 14120
    },
    {
      "epoch": 2.2608,
      "grad_norm": 0.5311108231544495,
      "learning_rate": 3.020203563894789e-05,
      "loss": 2.348,
      "step": 14130
    },
    {
      "epoch": 2.2624,
      "grad_norm": 0.5279009938240051,
      "learning_rate": 3.0078438850168965e-05,
      "loss": 2.3689,
      "step": 14140
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.6200090646743774,
      "learning_rate": 2.995505069708854e-05,
      "loss": 2.3724,
      "step": 14150
    },
    {
      "epoch": 2.2640000000000002,
      "eval_bleu": 35.19059891970452,
      "eval_gen_len": 31.741,
      "eval_loss": 2.602975368499756,
      "eval_runtime": 68.3148,
      "eval_samples_per_second": 14.638,
      "eval_steps_per_second": 0.922,
      "step": 14150
    },
    {
      "epoch": 2.2656,
      "grad_norm": 0.5293769240379333,
      "learning_rate": 2.983187154787871e-05,
      "loss": 2.3741,
      "step": 14160
    },
    {
      "epoch": 2.2672,
      "grad_norm": 0.5899881720542908,
      "learning_rate": 2.9708901770088084e-05,
      "loss": 2.3542,
      "step": 14170
    },
    {
      "epoch": 2.2688,
      "grad_norm": 0.5256963968276978,
      "learning_rate": 2.958614173064046e-05,
      "loss": 2.3411,
      "step": 14180
    },
    {
      "epoch": 2.2704,
      "grad_norm": 0.5132701992988586,
      "learning_rate": 2.9463591795833755e-05,
      "loss": 2.3349,
      "step": 14190
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.5122636556625366,
      "learning_rate": 2.9341252331339152e-05,
      "loss": 2.3725,
      "step": 14200
    },
    {
      "epoch": 2.2720000000000002,
      "eval_bleu": 35.17252799459547,
      "eval_gen_len": 31.724,
      "eval_loss": 2.602872133255005,
      "eval_runtime": 67.0999,
      "eval_samples_per_second": 14.903,
      "eval_steps_per_second": 0.939,
      "step": 14200
    },
    {
      "epoch": 2.2736,
      "grad_norm": 0.5630570650100708,
      "learning_rate": 2.921912370219958e-05,
      "loss": 2.3575,
      "step": 14210
    },
    {
      "epoch": 2.2752,
      "grad_norm": 0.5881439447402954,
      "learning_rate": 2.9097206272829024e-05,
      "loss": 2.3857,
      "step": 14220
    },
    {
      "epoch": 2.2768,
      "grad_norm": 0.5111440420150757,
      "learning_rate": 2.8975500407011282e-05,
      "loss": 2.3876,
      "step": 14230
    },
    {
      "epoch": 2.2784,
      "grad_norm": 0.5272552967071533,
      "learning_rate": 2.8854006467898752e-05,
      "loss": 2.3402,
      "step": 14240
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.5704591870307922,
      "learning_rate": 2.8732724818011636e-05,
      "loss": 2.3599,
      "step": 14250
    },
    {
      "epoch": 2.2800000000000002,
      "eval_bleu": 35.43649894928698,
      "eval_gen_len": 31.747,
      "eval_loss": 2.6033809185028076,
      "eval_runtime": 66.7098,
      "eval_samples_per_second": 14.99,
      "eval_steps_per_second": 0.944,
      "step": 14250
    },
    {
      "epoch": 2.2816,
      "grad_norm": 0.5384263396263123,
      "learning_rate": 2.8611655819236537e-05,
      "loss": 2.3531,
      "step": 14260
    },
    {
      "epoch": 2.2832,
      "grad_norm": 0.5347633957862854,
      "learning_rate": 2.8490799832825666e-05,
      "loss": 2.3704,
      "step": 14270
    },
    {
      "epoch": 2.2848,
      "grad_norm": 0.5483222603797913,
      "learning_rate": 2.8370157219395598e-05,
      "loss": 2.3468,
      "step": 14280
    },
    {
      "epoch": 2.2864,
      "grad_norm": 0.5298739075660706,
      "learning_rate": 2.8249728338926175e-05,
      "loss": 2.3695,
      "step": 14290
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.5500065684318542,
      "learning_rate": 2.8129513550759556e-05,
      "loss": 2.3365,
      "step": 14300
    },
    {
      "epoch": 2.288,
      "eval_bleu": 35.42408444513899,
      "eval_gen_len": 31.777,
      "eval_loss": 2.602505683898926,
      "eval_runtime": 66.684,
      "eval_samples_per_second": 14.996,
      "eval_steps_per_second": 0.945,
      "step": 14300
    },
    {
      "epoch": 2.2896,
      "grad_norm": 0.5071449875831604,
      "learning_rate": 2.8009513213599092e-05,
      "loss": 2.3669,
      "step": 14310
    },
    {
      "epoch": 2.2912,
      "grad_norm": 0.5577744245529175,
      "learning_rate": 2.788972768550818e-05,
      "loss": 2.3937,
      "step": 14320
    },
    {
      "epoch": 2.2928,
      "grad_norm": 0.5549293756484985,
      "learning_rate": 2.7770157323909353e-05,
      "loss": 2.368,
      "step": 14330
    },
    {
      "epoch": 2.2944,
      "grad_norm": 0.5487207770347595,
      "learning_rate": 2.7650802485582984e-05,
      "loss": 2.3668,
      "step": 14340
    },
    {
      "epoch": 2.296,
      "grad_norm": 0.5921465158462524,
      "learning_rate": 2.753166352666645e-05,
      "loss": 2.363,
      "step": 14350
    },
    {
      "epoch": 2.296,
      "eval_bleu": 35.54542811930457,
      "eval_gen_len": 31.725,
      "eval_loss": 2.6011149883270264,
      "eval_runtime": 67.1704,
      "eval_samples_per_second": 14.888,
      "eval_steps_per_second": 0.938,
      "step": 14350
    },
    {
      "epoch": 2.2976,
      "grad_norm": 0.5157827138900757,
      "learning_rate": 2.7412740802653014e-05,
      "loss": 2.3381,
      "step": 14360
    },
    {
      "epoch": 2.2992,
      "grad_norm": 0.5685476660728455,
      "learning_rate": 2.7294034668390588e-05,
      "loss": 2.3646,
      "step": 14370
    },
    {
      "epoch": 2.3008,
      "grad_norm": 0.5741767287254333,
      "learning_rate": 2.7175545478080965e-05,
      "loss": 2.3439,
      "step": 14380
    },
    {
      "epoch": 2.3024,
      "grad_norm": 0.5209742188453674,
      "learning_rate": 2.7057273585278464e-05,
      "loss": 2.352,
      "step": 14390
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.5179345607757568,
      "learning_rate": 2.693921934288912e-05,
      "loss": 2.3377,
      "step": 14400
    },
    {
      "epoch": 2.304,
      "eval_bleu": 35.58024156031853,
      "eval_gen_len": 31.796,
      "eval_loss": 2.6021621227264404,
      "eval_runtime": 67.2545,
      "eval_samples_per_second": 14.869,
      "eval_steps_per_second": 0.937,
      "step": 14400
    },
    {
      "epoch": 2.3056,
      "grad_norm": 0.5304871797561646,
      "learning_rate": 2.6821383103169552e-05,
      "loss": 2.3658,
      "step": 14410
    },
    {
      "epoch": 2.3072,
      "grad_norm": 0.559900164604187,
      "learning_rate": 2.6703765217725775e-05,
      "loss": 2.3465,
      "step": 14420
    },
    {
      "epoch": 2.3088,
      "grad_norm": 0.5310159921646118,
      "learning_rate": 2.6586366037512345e-05,
      "loss": 2.3875,
      "step": 14430
    },
    {
      "epoch": 2.3104,
      "grad_norm": 0.5280927419662476,
      "learning_rate": 2.646918591283124e-05,
      "loss": 2.3519,
      "step": 14440
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.5411534309387207,
      "learning_rate": 2.6352225193330794e-05,
      "loss": 2.3585,
      "step": 14450
    },
    {
      "epoch": 2.312,
      "eval_bleu": 35.34593414925497,
      "eval_gen_len": 31.747,
      "eval_loss": 2.6024084091186523,
      "eval_runtime": 66.9304,
      "eval_samples_per_second": 14.941,
      "eval_steps_per_second": 0.941,
      "step": 14450
    },
    {
      "epoch": 2.3136,
      "grad_norm": 0.49434253573417664,
      "learning_rate": 2.623548422800469e-05,
      "loss": 2.3532,
      "step": 14460
    },
    {
      "epoch": 2.3152,
      "grad_norm": 0.5895388722419739,
      "learning_rate": 2.611896336519081e-05,
      "loss": 2.3912,
      "step": 14470
    },
    {
      "epoch": 2.3168,
      "grad_norm": 0.5568904876708984,
      "learning_rate": 2.600266295257041e-05,
      "loss": 2.3549,
      "step": 14480
    },
    {
      "epoch": 2.3184,
      "grad_norm": 0.6085360646247864,
      "learning_rate": 2.5886583337166815e-05,
      "loss": 2.3802,
      "step": 14490
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.5499080419540405,
      "learning_rate": 2.5770724865344644e-05,
      "loss": 2.3382,
      "step": 14500
    },
    {
      "epoch": 2.32,
      "eval_bleu": 35.32741511736258,
      "eval_gen_len": 31.781,
      "eval_loss": 2.602154016494751,
      "eval_runtime": 66.608,
      "eval_samples_per_second": 15.013,
      "eval_steps_per_second": 0.946,
      "step": 14500
    },
    {
      "epoch": 2.3216,
      "grad_norm": 0.5829828977584839,
      "learning_rate": 2.5655087882808636e-05,
      "loss": 2.3877,
      "step": 14510
    },
    {
      "epoch": 2.3232,
      "grad_norm": 0.5493476390838623,
      "learning_rate": 2.5539672734602536e-05,
      "loss": 2.3507,
      "step": 14520
    },
    {
      "epoch": 2.3247999999999998,
      "grad_norm": 0.5291074514389038,
      "learning_rate": 2.54244797651083e-05,
      "loss": 2.3721,
      "step": 14530
    },
    {
      "epoch": 2.3264,
      "grad_norm": 0.4913311004638672,
      "learning_rate": 2.530950931804489e-05,
      "loss": 2.3454,
      "step": 14540
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.5448663234710693,
      "learning_rate": 2.5194761736467197e-05,
      "loss": 2.3777,
      "step": 14550
    },
    {
      "epoch": 2.328,
      "eval_bleu": 35.398956462810226,
      "eval_gen_len": 31.719,
      "eval_loss": 2.601978063583374,
      "eval_runtime": 67.3612,
      "eval_samples_per_second": 14.845,
      "eval_steps_per_second": 0.935,
      "step": 14550
    },
    {
      "epoch": 2.3296,
      "grad_norm": 0.5409573316574097,
      "learning_rate": 2.5080237362765325e-05,
      "loss": 2.3685,
      "step": 14560
    },
    {
      "epoch": 2.3312,
      "grad_norm": 0.5031480193138123,
      "learning_rate": 2.4965936538663138e-05,
      "loss": 2.3255,
      "step": 14570
    },
    {
      "epoch": 2.3327999999999998,
      "grad_norm": 0.49364548921585083,
      "learning_rate": 2.4851859605217576e-05,
      "loss": 2.3566,
      "step": 14580
    },
    {
      "epoch": 2.3344,
      "grad_norm": 0.5179325938224792,
      "learning_rate": 2.4738006902817547e-05,
      "loss": 2.3511,
      "step": 14590
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.5492497682571411,
      "learning_rate": 2.4624378771182787e-05,
      "loss": 2.3297,
      "step": 14600
    },
    {
      "epoch": 2.336,
      "eval_bleu": 35.59652053400906,
      "eval_gen_len": 31.777,
      "eval_loss": 2.602097749710083,
      "eval_runtime": 67.8459,
      "eval_samples_per_second": 14.739,
      "eval_steps_per_second": 0.929,
      "step": 14600
    },
    {
      "epoch": 2.3376,
      "grad_norm": 0.5635749697685242,
      "learning_rate": 2.4510975549363036e-05,
      "loss": 2.3569,
      "step": 14610
    },
    {
      "epoch": 2.3392,
      "grad_norm": 0.5300503969192505,
      "learning_rate": 2.4397797575736857e-05,
      "loss": 2.3925,
      "step": 14620
    },
    {
      "epoch": 2.3407999999999998,
      "grad_norm": 0.5521494150161743,
      "learning_rate": 2.4284845188010775e-05,
      "loss": 2.3828,
      "step": 14630
    },
    {
      "epoch": 2.3424,
      "grad_norm": 0.6009182333946228,
      "learning_rate": 2.4172118723218205e-05,
      "loss": 2.3623,
      "step": 14640
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.5524471402168274,
      "learning_rate": 2.4059618517718354e-05,
      "loss": 2.3595,
      "step": 14650
    },
    {
      "epoch": 2.344,
      "eval_bleu": 35.44909910159398,
      "eval_gen_len": 31.788,
      "eval_loss": 2.601897716522217,
      "eval_runtime": 66.9693,
      "eval_samples_per_second": 14.932,
      "eval_steps_per_second": 0.941,
      "step": 14650
    },
    {
      "epoch": 2.3456,
      "grad_norm": 0.5496682524681091,
      "learning_rate": 2.3947344907195367e-05,
      "loss": 2.3891,
      "step": 14660
    },
    {
      "epoch": 2.3472,
      "grad_norm": 0.5723068714141846,
      "learning_rate": 2.3835298226657275e-05,
      "loss": 2.352,
      "step": 14670
    },
    {
      "epoch": 2.3487999999999998,
      "grad_norm": 0.5756466388702393,
      "learning_rate": 2.3723478810434975e-05,
      "loss": 2.3611,
      "step": 14680
    },
    {
      "epoch": 2.3504,
      "grad_norm": 0.5069252848625183,
      "learning_rate": 2.361188699218123e-05,
      "loss": 2.3396,
      "step": 14690
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.5361648201942444,
      "learning_rate": 2.350052310486963e-05,
      "loss": 2.3549,
      "step": 14700
    },
    {
      "epoch": 2.352,
      "eval_bleu": 35.52940814364823,
      "eval_gen_len": 31.779,
      "eval_loss": 2.601675271987915,
      "eval_runtime": 67.2644,
      "eval_samples_per_second": 14.867,
      "eval_steps_per_second": 0.937,
      "step": 14700
    },
    {
      "epoch": 2.3536,
      "grad_norm": 0.5623311996459961,
      "learning_rate": 2.3389387480793757e-05,
      "loss": 2.3377,
      "step": 14710
    },
    {
      "epoch": 2.3552,
      "grad_norm": 0.5350399613380432,
      "learning_rate": 2.3278480451566044e-05,
      "loss": 2.3598,
      "step": 14720
    },
    {
      "epoch": 2.3568,
      "grad_norm": 0.5335819721221924,
      "learning_rate": 2.3167802348116773e-05,
      "loss": 2.3337,
      "step": 14730
    },
    {
      "epoch": 2.3584,
      "grad_norm": 0.5314493775367737,
      "learning_rate": 2.3057353500693256e-05,
      "loss": 2.3573,
      "step": 14740
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.5242034792900085,
      "learning_rate": 2.2947134238858625e-05,
      "loss": 2.3225,
      "step": 14750
    },
    {
      "epoch": 2.36,
      "eval_bleu": 35.5571455151808,
      "eval_gen_len": 31.83,
      "eval_loss": 2.602294445037842,
      "eval_runtime": 67.2577,
      "eval_samples_per_second": 14.868,
      "eval_steps_per_second": 0.937,
      "step": 14750
    },
    {
      "epoch": 2.3616,
      "grad_norm": 0.6092470288276672,
      "learning_rate": 2.2837144891491026e-05,
      "loss": 2.3665,
      "step": 14760
    },
    {
      "epoch": 2.3632,
      "grad_norm": 0.596865713596344,
      "learning_rate": 2.2727385786782617e-05,
      "loss": 2.359,
      "step": 14770
    },
    {
      "epoch": 2.3648,
      "grad_norm": 0.5272191762924194,
      "learning_rate": 2.2617857252238383e-05,
      "loss": 2.3514,
      "step": 14780
    },
    {
      "epoch": 2.3664,
      "grad_norm": 0.5269789099693298,
      "learning_rate": 2.250855961467556e-05,
      "loss": 2.3686,
      "step": 14790
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.5314186811447144,
      "learning_rate": 2.239949320022221e-05,
      "loss": 2.383,
      "step": 14800
    },
    {
      "epoch": 2.368,
      "eval_bleu": 35.3866239135056,
      "eval_gen_len": 31.822,
      "eval_loss": 2.6019859313964844,
      "eval_runtime": 66.5143,
      "eval_samples_per_second": 15.034,
      "eval_steps_per_second": 0.947,
      "step": 14800
    },
    {
      "epoch": 2.3696,
      "grad_norm": 0.526764452457428,
      "learning_rate": 2.229065833431655e-05,
      "loss": 2.332,
      "step": 14810
    },
    {
      "epoch": 2.3712,
      "grad_norm": 0.5533561110496521,
      "learning_rate": 2.218205534170593e-05,
      "loss": 2.3685,
      "step": 14820
    },
    {
      "epoch": 2.3728,
      "grad_norm": 0.5351603031158447,
      "learning_rate": 2.2073684546445706e-05,
      "loss": 2.3723,
      "step": 14830
    },
    {
      "epoch": 2.3744,
      "grad_norm": 0.5479146838188171,
      "learning_rate": 2.196554627189852e-05,
      "loss": 2.384,
      "step": 14840
    },
    {
      "epoch": 2.376,
      "grad_norm": 0.5387640595436096,
      "learning_rate": 2.1857640840733097e-05,
      "loss": 2.3586,
      "step": 14850
    },
    {
      "epoch": 2.376,
      "eval_bleu": 35.37849594694001,
      "eval_gen_len": 31.757,
      "eval_loss": 2.6025562286376953,
      "eval_runtime": 66.7494,
      "eval_samples_per_second": 14.981,
      "eval_steps_per_second": 0.944,
      "step": 14850
    },
    {
      "epoch": 2.3776,
      "grad_norm": 0.5171869993209839,
      "learning_rate": 2.1749968574923453e-05,
      "loss": 2.3877,
      "step": 14860
    },
    {
      "epoch": 2.3792,
      "grad_norm": 0.5662190914154053,
      "learning_rate": 2.1642529795747902e-05,
      "loss": 2.3604,
      "step": 14870
    },
    {
      "epoch": 2.3808,
      "grad_norm": 0.5251250267028809,
      "learning_rate": 2.153532482378796e-05,
      "loss": 2.3697,
      "step": 14880
    },
    {
      "epoch": 2.3824,
      "grad_norm": 0.5374813675880432,
      "learning_rate": 2.1428353978927606e-05,
      "loss": 2.355,
      "step": 14890
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.5406767725944519,
      "learning_rate": 2.132161758035216e-05,
      "loss": 2.3487,
      "step": 14900
    },
    {
      "epoch": 2.384,
      "eval_bleu": 35.403934682843605,
      "eval_gen_len": 31.796,
      "eval_loss": 2.6028330326080322,
      "eval_runtime": 67.9005,
      "eval_samples_per_second": 14.727,
      "eval_steps_per_second": 0.928,
      "step": 14900
    },
    {
      "epoch": 2.3856,
      "grad_norm": 0.5524157285690308,
      "learning_rate": 2.1215115946547413e-05,
      "loss": 2.3783,
      "step": 14910
    },
    {
      "epoch": 2.3872,
      "grad_norm": 0.5700698494911194,
      "learning_rate": 2.110884939529868e-05,
      "loss": 2.3565,
      "step": 14920
    },
    {
      "epoch": 2.3888,
      "grad_norm": 0.5660792589187622,
      "learning_rate": 2.1002818243689703e-05,
      "loss": 2.3621,
      "step": 14930
    },
    {
      "epoch": 2.3904,
      "grad_norm": 0.5087817907333374,
      "learning_rate": 2.089702280810196e-05,
      "loss": 2.3324,
      "step": 14940
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.5105445981025696,
      "learning_rate": 2.0791463404213573e-05,
      "loss": 2.3549,
      "step": 14950
    },
    {
      "epoch": 2.392,
      "eval_bleu": 35.37542045025203,
      "eval_gen_len": 31.815,
      "eval_loss": 2.603058099746704,
      "eval_runtime": 67.1678,
      "eval_samples_per_second": 14.888,
      "eval_steps_per_second": 0.938,
      "step": 14950
    },
    {
      "epoch": 2.3936,
      "grad_norm": 0.6055552363395691,
      "learning_rate": 2.0686140346998263e-05,
      "loss": 2.3557,
      "step": 14960
    },
    {
      "epoch": 2.3952,
      "grad_norm": 0.526763916015625,
      "learning_rate": 2.058105395072467e-05,
      "loss": 2.3482,
      "step": 14970
    },
    {
      "epoch": 2.3968,
      "grad_norm": 0.5532928705215454,
      "learning_rate": 2.047620452895518e-05,
      "loss": 2.3515,
      "step": 14980
    },
    {
      "epoch": 2.3984,
      "grad_norm": 0.5156667828559875,
      "learning_rate": 2.0371592394545102e-05,
      "loss": 2.3542,
      "step": 14990
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.5010555982589722,
      "learning_rate": 2.0267217859641786e-05,
      "loss": 2.3484,
      "step": 15000
    },
    {
      "epoch": 2.4,
      "eval_bleu": 35.40717283353776,
      "eval_gen_len": 31.809,
      "eval_loss": 2.60296630859375,
      "eval_runtime": 67.4649,
      "eval_samples_per_second": 14.823,
      "eval_steps_per_second": 0.934,
      "step": 15000
    },
    {
      "epoch": 2.4016,
      "grad_norm": 0.5298597812652588,
      "learning_rate": 2.0163081235683456e-05,
      "loss": 2.3389,
      "step": 15010
    },
    {
      "epoch": 2.4032,
      "grad_norm": 0.5739134550094604,
      "learning_rate": 2.005918283339866e-05,
      "loss": 2.3579,
      "step": 15020
    },
    {
      "epoch": 2.4048,
      "grad_norm": 0.5235658884048462,
      "learning_rate": 1.995552296280494e-05,
      "loss": 2.3503,
      "step": 15030
    },
    {
      "epoch": 2.4064,
      "grad_norm": 0.5581408143043518,
      "learning_rate": 1.985210193320819e-05,
      "loss": 2.3604,
      "step": 15040
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.5656309723854065,
      "learning_rate": 1.9748920053201646e-05,
      "loss": 2.3775,
      "step": 15050
    },
    {
      "epoch": 2.408,
      "eval_bleu": 35.5700912054858,
      "eval_gen_len": 31.907,
      "eval_loss": 2.6032156944274902,
      "eval_runtime": 67.4373,
      "eval_samples_per_second": 14.829,
      "eval_steps_per_second": 0.934,
      "step": 15050
    },
    {
      "epoch": 2.4096,
      "grad_norm": 0.5149828791618347,
      "learning_rate": 1.9645977630664867e-05,
      "loss": 2.3882,
      "step": 15060
    },
    {
      "epoch": 2.4112,
      "grad_norm": 0.5943813920021057,
      "learning_rate": 1.9543274972762993e-05,
      "loss": 2.384,
      "step": 15070
    },
    {
      "epoch": 2.4128,
      "grad_norm": 0.54815274477005,
      "learning_rate": 1.944081238594575e-05,
      "loss": 2.3483,
      "step": 15080
    },
    {
      "epoch": 2.4144,
      "grad_norm": 0.5705281496047974,
      "learning_rate": 1.9338590175946437e-05,
      "loss": 2.3596,
      "step": 15090
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.5278105735778809,
      "learning_rate": 1.9236608647781206e-05,
      "loss": 2.3284,
      "step": 15100
    },
    {
      "epoch": 2.416,
      "eval_bleu": 35.47790101775259,
      "eval_gen_len": 31.831,
      "eval_loss": 2.6026124954223633,
      "eval_runtime": 67.4237,
      "eval_samples_per_second": 14.832,
      "eval_steps_per_second": 0.934,
      "step": 15100
    },
    {
      "epoch": 2.4176,
      "grad_norm": 0.5862336754798889,
      "learning_rate": 1.9134868105747948e-05,
      "loss": 2.3672,
      "step": 15110
    },
    {
      "epoch": 2.4192,
      "grad_norm": 0.5668318867683411,
      "learning_rate": 1.903336885342557e-05,
      "loss": 2.3627,
      "step": 15120
    },
    {
      "epoch": 2.4208,
      "grad_norm": 0.5137292742729187,
      "learning_rate": 1.8932111193672973e-05,
      "loss": 2.3527,
      "step": 15130
    },
    {
      "epoch": 2.4224,
      "grad_norm": 0.5456418991088867,
      "learning_rate": 1.88310954286282e-05,
      "loss": 2.3782,
      "step": 15140
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.533604085445404,
      "learning_rate": 1.87303218597075e-05,
      "loss": 2.3535,
      "step": 15150
    },
    {
      "epoch": 2.424,
      "eval_bleu": 35.469918485257075,
      "eval_gen_len": 31.883,
      "eval_loss": 2.6024248600006104,
      "eval_runtime": 66.8366,
      "eval_samples_per_second": 14.962,
      "eval_steps_per_second": 0.943,
      "step": 15150
    },
    {
      "epoch": 2.4256,
      "grad_norm": 0.5545517206192017,
      "learning_rate": 1.8629790787604416e-05,
      "loss": 2.3488,
      "step": 15160
    },
    {
      "epoch": 2.4272,
      "grad_norm": 0.5598055124282837,
      "learning_rate": 1.8529502512288953e-05,
      "loss": 2.3486,
      "step": 15170
    },
    {
      "epoch": 2.4288,
      "grad_norm": 0.49074000120162964,
      "learning_rate": 1.8429457333006673e-05,
      "loss": 2.3367,
      "step": 15180
    },
    {
      "epoch": 2.4304,
      "grad_norm": 0.530921220779419,
      "learning_rate": 1.832965554827769e-05,
      "loss": 2.3621,
      "step": 15190
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.5517061948776245,
      "learning_rate": 1.8230097455895923e-05,
      "loss": 2.3597,
      "step": 15200
    },
    {
      "epoch": 2.432,
      "eval_bleu": 35.43100481705574,
      "eval_gen_len": 31.792,
      "eval_loss": 2.6034936904907227,
      "eval_runtime": 67.5614,
      "eval_samples_per_second": 14.801,
      "eval_steps_per_second": 0.932,
      "step": 15200
    },
    {
      "epoch": 2.4336,
      "grad_norm": 0.5253973603248596,
      "learning_rate": 1.8130783352928183e-05,
      "loss": 2.3298,
      "step": 15210
    },
    {
      "epoch": 2.4352,
      "grad_norm": 0.5744786262512207,
      "learning_rate": 1.8031713535713158e-05,
      "loss": 2.3573,
      "step": 15220
    },
    {
      "epoch": 2.4368,
      "grad_norm": 0.5075920224189758,
      "learning_rate": 1.7932888299860705e-05,
      "loss": 2.3609,
      "step": 15230
    },
    {
      "epoch": 2.4384,
      "grad_norm": 0.5251518487930298,
      "learning_rate": 1.7834307940250826e-05,
      "loss": 2.336,
      "step": 15240
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.5619168281555176,
      "learning_rate": 1.7735972751032894e-05,
      "loss": 2.342,
      "step": 15250
    },
    {
      "epoch": 2.44,
      "eval_bleu": 35.4652792599769,
      "eval_gen_len": 31.774,
      "eval_loss": 2.602693796157837,
      "eval_runtime": 67.1455,
      "eval_samples_per_second": 14.893,
      "eval_steps_per_second": 0.938,
      "step": 15250
    },
    {
      "epoch": 2.4416,
      "grad_norm": 0.5367917418479919,
      "learning_rate": 1.7637883025624715e-05,
      "loss": 2.3604,
      "step": 15260
    },
    {
      "epoch": 2.4432,
      "grad_norm": 0.5800161957740784,
      "learning_rate": 1.7540039056711656e-05,
      "loss": 2.352,
      "step": 15270
    },
    {
      "epoch": 2.4448,
      "grad_norm": 0.5511854887008667,
      "learning_rate": 1.7442441136245825e-05,
      "loss": 2.3609,
      "step": 15280
    },
    {
      "epoch": 2.4464,
      "grad_norm": 0.5353341698646545,
      "learning_rate": 1.734508955544506e-05,
      "loss": 2.3509,
      "step": 15290
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.5881171226501465,
      "learning_rate": 1.7247984604792266e-05,
      "loss": 2.3464,
      "step": 15300
    },
    {
      "epoch": 2.448,
      "eval_bleu": 35.44616288535517,
      "eval_gen_len": 31.838,
      "eval_loss": 2.6027300357818604,
      "eval_runtime": 67.9509,
      "eval_samples_per_second": 14.717,
      "eval_steps_per_second": 0.927,
      "step": 15300
    },
    {
      "epoch": 2.4496,
      "grad_norm": 0.5631342530250549,
      "learning_rate": 1.7151126574034405e-05,
      "loss": 2.3746,
      "step": 15310
    },
    {
      "epoch": 2.4512,
      "grad_norm": 0.5440390110015869,
      "learning_rate": 1.705451575218161e-05,
      "loss": 2.3609,
      "step": 15320
    },
    {
      "epoch": 2.4528,
      "grad_norm": 0.575246274471283,
      "learning_rate": 1.6958152427506478e-05,
      "loss": 2.3842,
      "step": 15330
    },
    {
      "epoch": 2.4544,
      "grad_norm": 0.512633740901947,
      "learning_rate": 1.6862036887542997e-05,
      "loss": 2.3563,
      "step": 15340
    },
    {
      "epoch": 2.456,
      "grad_norm": 0.5977848768234253,
      "learning_rate": 1.676616941908591e-05,
      "loss": 2.3753,
      "step": 15350
    },
    {
      "epoch": 2.456,
      "eval_bleu": 35.48917135002112,
      "eval_gen_len": 31.806,
      "eval_loss": 2.6028354167938232,
      "eval_runtime": 67.4034,
      "eval_samples_per_second": 14.836,
      "eval_steps_per_second": 0.935,
      "step": 15350
    },
    {
      "epoch": 2.4576000000000002,
      "grad_norm": 0.5175755023956299,
      "learning_rate": 1.667055030818967e-05,
      "loss": 2.3436,
      "step": 15360
    },
    {
      "epoch": 2.4592,
      "grad_norm": 0.5436550378799438,
      "learning_rate": 1.657517984016773e-05,
      "loss": 2.3737,
      "step": 15370
    },
    {
      "epoch": 2.4608,
      "grad_norm": 0.5557228922843933,
      "learning_rate": 1.6480058299591617e-05,
      "loss": 2.3621,
      "step": 15380
    },
    {
      "epoch": 2.4624,
      "grad_norm": 0.5646586418151855,
      "learning_rate": 1.6385185970290006e-05,
      "loss": 2.3577,
      "step": 15390
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.5012543201446533,
      "learning_rate": 1.629056313534809e-05,
      "loss": 2.3518,
      "step": 15400
    },
    {
      "epoch": 2.464,
      "eval_bleu": 35.52745552833643,
      "eval_gen_len": 31.779,
      "eval_loss": 2.601696729660034,
      "eval_runtime": 66.9428,
      "eval_samples_per_second": 14.938,
      "eval_steps_per_second": 0.941,
      "step": 15400
    },
    {
      "epoch": 2.4656000000000002,
      "grad_norm": 0.5335679650306702,
      "learning_rate": 1.6196190077106566e-05,
      "loss": 2.3447,
      "step": 15410
    },
    {
      "epoch": 2.4672,
      "grad_norm": 0.5222405791282654,
      "learning_rate": 1.6102067077160754e-05,
      "loss": 2.3745,
      "step": 15420
    },
    {
      "epoch": 2.4688,
      "grad_norm": 0.5870319604873657,
      "learning_rate": 1.6008194416359933e-05,
      "loss": 2.3338,
      "step": 15430
    },
    {
      "epoch": 2.4704,
      "grad_norm": 0.5394832491874695,
      "learning_rate": 1.5914572374806413e-05,
      "loss": 2.3573,
      "step": 15440
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.5355581641197205,
      "learning_rate": 1.5821201231854598e-05,
      "loss": 2.3578,
      "step": 15450
    },
    {
      "epoch": 2.472,
      "eval_bleu": 35.54176632477791,
      "eval_gen_len": 31.815,
      "eval_loss": 2.6020143032073975,
      "eval_runtime": 66.9806,
      "eval_samples_per_second": 14.93,
      "eval_steps_per_second": 0.941,
      "step": 15450
    },
    {
      "epoch": 2.4736000000000002,
      "grad_norm": 0.5585504174232483,
      "learning_rate": 1.572808126611035e-05,
      "loss": 2.3451,
      "step": 15460
    },
    {
      "epoch": 2.4752,
      "grad_norm": 0.5558875799179077,
      "learning_rate": 1.563521275542996e-05,
      "loss": 2.3407,
      "step": 15470
    },
    {
      "epoch": 2.4768,
      "grad_norm": 0.5672215223312378,
      "learning_rate": 1.5542595976919506e-05,
      "loss": 2.3641,
      "step": 15480
    },
    {
      "epoch": 2.4784,
      "grad_norm": 0.532613217830658,
      "learning_rate": 1.5450231206933864e-05,
      "loss": 2.3807,
      "step": 15490
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.550070583820343,
      "learning_rate": 1.5358118721075987e-05,
      "loss": 2.3768,
      "step": 15500
    },
    {
      "epoch": 2.48,
      "eval_bleu": 35.56452978637874,
      "eval_gen_len": 31.827,
      "eval_loss": 2.6025359630584717,
      "eval_runtime": 66.8529,
      "eval_samples_per_second": 14.958,
      "eval_steps_per_second": 0.942,
      "step": 15500
    },
    {
      "epoch": 2.4816,
      "grad_norm": 0.5133243799209595,
      "learning_rate": 1.5266258794196087e-05,
      "loss": 2.3789,
      "step": 15510
    },
    {
      "epoch": 2.4832,
      "grad_norm": 0.571466326713562,
      "learning_rate": 1.5174651700390651e-05,
      "loss": 2.3582,
      "step": 15520
    },
    {
      "epoch": 2.4848,
      "grad_norm": 0.5603309273719788,
      "learning_rate": 1.5083297713001898e-05,
      "loss": 2.3527,
      "step": 15530
    },
    {
      "epoch": 2.4864,
      "grad_norm": 0.5720536112785339,
      "learning_rate": 1.4992197104616735e-05,
      "loss": 2.3682,
      "step": 15540
    },
    {
      "epoch": 2.488,
      "grad_norm": 0.5142843127250671,
      "learning_rate": 1.4901350147065995e-05,
      "loss": 2.3466,
      "step": 15550
    },
    {
      "epoch": 2.488,
      "eval_bleu": 35.46953390206096,
      "eval_gen_len": 31.815,
      "eval_loss": 2.602534294128418,
      "eval_runtime": 66.802,
      "eval_samples_per_second": 14.97,
      "eval_steps_per_second": 0.943,
      "step": 15550
    },
    {
      "epoch": 2.4896,
      "grad_norm": 0.5437710285186768,
      "learning_rate": 1.4810757111423735e-05,
      "loss": 2.3764,
      "step": 15560
    },
    {
      "epoch": 2.4912,
      "grad_norm": 0.5244897603988647,
      "learning_rate": 1.472041826800632e-05,
      "loss": 2.3463,
      "step": 15570
    },
    {
      "epoch": 2.4928,
      "grad_norm": 0.5335734486579895,
      "learning_rate": 1.4630333886371583e-05,
      "loss": 2.3701,
      "step": 15580
    },
    {
      "epoch": 2.4944,
      "grad_norm": 0.527561366558075,
      "learning_rate": 1.4540504235318164e-05,
      "loss": 2.3498,
      "step": 15590
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.528937578201294,
      "learning_rate": 1.445092958288452e-05,
      "loss": 2.3325,
      "step": 15600
    },
    {
      "epoch": 2.496,
      "eval_bleu": 35.35701501388049,
      "eval_gen_len": 31.798,
      "eval_loss": 2.603010416030884,
      "eval_runtime": 67.3736,
      "eval_samples_per_second": 14.843,
      "eval_steps_per_second": 0.935,
      "step": 15600
    },
    {
      "epoch": 2.4976,
      "grad_norm": 0.568947434425354,
      "learning_rate": 1.4361610196348396e-05,
      "loss": 2.368,
      "step": 15610
    },
    {
      "epoch": 2.4992,
      "grad_norm": 0.55121248960495,
      "learning_rate": 1.427254634222569e-05,
      "loss": 2.3446,
      "step": 15620
    },
    {
      "epoch": 2.5008,
      "grad_norm": 0.6118751168251038,
      "learning_rate": 1.4183738286269921e-05,
      "loss": 2.3709,
      "step": 15630
    },
    {
      "epoch": 2.5023999999999997,
      "grad_norm": 0.5269823670387268,
      "learning_rate": 1.4095186293471341e-05,
      "loss": 2.3513,
      "step": 15640
    },
    {
      "epoch": 2.504,
      "grad_norm": 0.5202484726905823,
      "learning_rate": 1.400689062805608e-05,
      "loss": 2.3399,
      "step": 15650
    },
    {
      "epoch": 2.504,
      "eval_bleu": 35.32994847875885,
      "eval_gen_len": 31.795,
      "eval_loss": 2.6026864051818848,
      "eval_runtime": 67.2562,
      "eval_samples_per_second": 14.869,
      "eval_steps_per_second": 0.937,
      "step": 15650
    },
    {
      "epoch": 2.5056000000000003,
      "grad_norm": 0.5311720967292786,
      "learning_rate": 1.3918851553485501e-05,
      "loss": 2.3888,
      "step": 15660
    },
    {
      "epoch": 2.5072,
      "grad_norm": 0.5373992919921875,
      "learning_rate": 1.3831069332455337e-05,
      "loss": 2.3637,
      "step": 15670
    },
    {
      "epoch": 2.5088,
      "grad_norm": 0.5449669361114502,
      "learning_rate": 1.3743544226894822e-05,
      "loss": 2.3448,
      "step": 15680
    },
    {
      "epoch": 2.5103999999999997,
      "grad_norm": 0.5601445436477661,
      "learning_rate": 1.3656276497966114e-05,
      "loss": 2.36,
      "step": 15690
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.5464855432510376,
      "learning_rate": 1.3569266406063274e-05,
      "loss": 2.3264,
      "step": 15700
    },
    {
      "epoch": 2.512,
      "eval_bleu": 35.40380974961413,
      "eval_gen_len": 31.772,
      "eval_loss": 2.602147102355957,
      "eval_runtime": 67.2919,
      "eval_samples_per_second": 14.861,
      "eval_steps_per_second": 0.936,
      "step": 15700
    },
    {
      "epoch": 2.5136,
      "grad_norm": 0.5326206088066101,
      "learning_rate": 1.3482514210811703e-05,
      "loss": 2.3445,
      "step": 15710
    },
    {
      "epoch": 2.5152,
      "grad_norm": 0.538587212562561,
      "learning_rate": 1.3396020171067247e-05,
      "loss": 2.3581,
      "step": 15720
    },
    {
      "epoch": 2.5168,
      "grad_norm": 0.6046273112297058,
      "learning_rate": 1.330978454491546e-05,
      "loss": 2.3655,
      "step": 15730
    },
    {
      "epoch": 2.5183999999999997,
      "grad_norm": 0.5203344225883484,
      "learning_rate": 1.3223807589670834e-05,
      "loss": 2.364,
      "step": 15740
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.5511735677719116,
      "learning_rate": 1.3138089561875965e-05,
      "loss": 2.3895,
      "step": 15750
    },
    {
      "epoch": 2.52,
      "eval_bleu": 35.436772282669544,
      "eval_gen_len": 31.753,
      "eval_loss": 2.601726770401001,
      "eval_runtime": 66.8945,
      "eval_samples_per_second": 14.949,
      "eval_steps_per_second": 0.942,
      "step": 15750
    },
    {
      "epoch": 2.5216,
      "grad_norm": 0.5417230129241943,
      "learning_rate": 1.3052630717300928e-05,
      "loss": 2.3692,
      "step": 15760
    },
    {
      "epoch": 2.5232,
      "grad_norm": 0.5333230495452881,
      "learning_rate": 1.2967431310942412e-05,
      "loss": 2.3494,
      "step": 15770
    },
    {
      "epoch": 2.5248,
      "grad_norm": 0.5609286427497864,
      "learning_rate": 1.288249159702294e-05,
      "loss": 2.349,
      "step": 15780
    },
    {
      "epoch": 2.5263999999999998,
      "grad_norm": 0.561798095703125,
      "learning_rate": 1.2797811828990181e-05,
      "loss": 2.3641,
      "step": 15790
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.5280707478523254,
      "learning_rate": 1.2713392259516188e-05,
      "loss": 2.3956,
      "step": 15800
    },
    {
      "epoch": 2.528,
      "eval_bleu": 35.25020125323126,
      "eval_gen_len": 31.778,
      "eval_loss": 2.6019434928894043,
      "eval_runtime": 67.0363,
      "eval_samples_per_second": 14.917,
      "eval_steps_per_second": 0.94,
      "step": 15800
    },
    {
      "epoch": 2.5296,
      "grad_norm": 0.512681782245636,
      "learning_rate": 1.2629233140496565e-05,
      "loss": 2.3521,
      "step": 15810
    },
    {
      "epoch": 2.5312,
      "grad_norm": 0.5720409750938416,
      "learning_rate": 1.2545334723049817e-05,
      "loss": 2.3582,
      "step": 15820
    },
    {
      "epoch": 2.5328,
      "grad_norm": 0.5520113706588745,
      "learning_rate": 1.2461697257516491e-05,
      "loss": 2.3723,
      "step": 15830
    },
    {
      "epoch": 2.5343999999999998,
      "grad_norm": 0.585176944732666,
      "learning_rate": 1.2378320993458592e-05,
      "loss": 2.3484,
      "step": 15840
    },
    {
      "epoch": 2.536,
      "grad_norm": 0.5498862862586975,
      "learning_rate": 1.229520617965868e-05,
      "loss": 2.3925,
      "step": 15850
    },
    {
      "epoch": 2.536,
      "eval_bleu": 35.25469032071975,
      "eval_gen_len": 31.772,
      "eval_loss": 2.602710485458374,
      "eval_runtime": 67.7853,
      "eval_samples_per_second": 14.752,
      "eval_steps_per_second": 0.929,
      "step": 15850
    },
    {
      "epoch": 2.5376,
      "grad_norm": 0.5429428219795227,
      "learning_rate": 1.2212353064119142e-05,
      "loss": 2.3424,
      "step": 15860
    },
    {
      "epoch": 2.5392,
      "grad_norm": 0.5339909791946411,
      "learning_rate": 1.2129761894061587e-05,
      "loss": 2.3633,
      "step": 15870
    },
    {
      "epoch": 2.5408,
      "grad_norm": 0.5534701943397522,
      "learning_rate": 1.2047432915925938e-05,
      "loss": 2.3267,
      "step": 15880
    },
    {
      "epoch": 2.5423999999999998,
      "grad_norm": 0.5092426538467407,
      "learning_rate": 1.1965366375369812e-05,
      "loss": 2.3663,
      "step": 15890
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.5597130060195923,
      "learning_rate": 1.1883562517267776e-05,
      "loss": 2.3653,
      "step": 15900
    },
    {
      "epoch": 2.544,
      "eval_bleu": 35.251643400147216,
      "eval_gen_len": 31.801,
      "eval_loss": 2.6025002002716064,
      "eval_runtime": 67.2772,
      "eval_samples_per_second": 14.864,
      "eval_steps_per_second": 0.936,
      "step": 15900
    },
    {
      "epoch": 2.5456,
      "grad_norm": 0.5689621567726135,
      "learning_rate": 1.1802021585710532e-05,
      "loss": 2.3564,
      "step": 15910
    },
    {
      "epoch": 2.5472,
      "grad_norm": 0.5924171209335327,
      "learning_rate": 1.1720743824004277e-05,
      "loss": 2.3648,
      "step": 15920
    },
    {
      "epoch": 2.5488,
      "grad_norm": 0.49636200070381165,
      "learning_rate": 1.163972947466998e-05,
      "loss": 2.3321,
      "step": 15930
    },
    {
      "epoch": 2.5504,
      "grad_norm": 0.5667545199394226,
      "learning_rate": 1.1558978779442565e-05,
      "loss": 2.3623,
      "step": 15940
    },
    {
      "epoch": 2.552,
      "grad_norm": 0.5514921545982361,
      "learning_rate": 1.147849197927029e-05,
      "loss": 2.359,
      "step": 15950
    },
    {
      "epoch": 2.552,
      "eval_bleu": 35.293003765037085,
      "eval_gen_len": 31.771,
      "eval_loss": 2.6025941371917725,
      "eval_runtime": 67.0541,
      "eval_samples_per_second": 14.913,
      "eval_steps_per_second": 0.94,
      "step": 15950
    },
    {
      "epoch": 2.5536,
      "grad_norm": 0.5599974989891052,
      "learning_rate": 1.139826931431397e-05,
      "loss": 2.3502,
      "step": 15960
    },
    {
      "epoch": 2.5552,
      "grad_norm": 0.5264594554901123,
      "learning_rate": 1.1318311023946326e-05,
      "loss": 2.3648,
      "step": 15970
    },
    {
      "epoch": 2.5568,
      "grad_norm": 0.5615081787109375,
      "learning_rate": 1.1238617346751134e-05,
      "loss": 2.3581,
      "step": 15980
    },
    {
      "epoch": 2.5584,
      "grad_norm": 0.5463338494300842,
      "learning_rate": 1.115918852052269e-05,
      "loss": 2.3456,
      "step": 15990
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.5280167460441589,
      "learning_rate": 1.1080024782264986e-05,
      "loss": 2.3556,
      "step": 16000
    },
    {
      "epoch": 2.56,
      "eval_bleu": 35.369740467592024,
      "eval_gen_len": 31.767,
      "eval_loss": 2.602555513381958,
      "eval_runtime": 67.2588,
      "eval_samples_per_second": 14.868,
      "eval_steps_per_second": 0.937,
      "step": 16000
    },
    {
      "epoch": 2.5616,
      "grad_norm": 0.5996688008308411,
      "learning_rate": 1.1001126368190995e-05,
      "loss": 2.3749,
      "step": 16010
    },
    {
      "epoch": 2.5632,
      "grad_norm": 0.5383699536323547,
      "learning_rate": 1.0922493513722032e-05,
      "loss": 2.3546,
      "step": 16020
    },
    {
      "epoch": 2.5648,
      "grad_norm": 0.5145198702812195,
      "learning_rate": 1.0844126453487047e-05,
      "loss": 2.3556,
      "step": 16030
    },
    {
      "epoch": 2.5664,
      "grad_norm": 0.5556652545928955,
      "learning_rate": 1.0766025421321845e-05,
      "loss": 2.3676,
      "step": 16040
    },
    {
      "epoch": 2.568,
      "grad_norm": 0.5560131072998047,
      "learning_rate": 1.068819065026847e-05,
      "loss": 2.371,
      "step": 16050
    },
    {
      "epoch": 2.568,
      "eval_bleu": 35.3942308060142,
      "eval_gen_len": 31.819,
      "eval_loss": 2.602482795715332,
      "eval_runtime": 67.4719,
      "eval_samples_per_second": 14.821,
      "eval_steps_per_second": 0.934,
      "step": 16050
    },
    {
      "epoch": 2.5696,
      "grad_norm": 0.5129698514938354,
      "learning_rate": 1.0610622372574508e-05,
      "loss": 2.3387,
      "step": 16060
    },
    {
      "epoch": 2.5712,
      "grad_norm": 0.5392214059829712,
      "learning_rate": 1.0533320819692271e-05,
      "loss": 2.3431,
      "step": 16070
    },
    {
      "epoch": 2.5728,
      "grad_norm": 0.5412020683288574,
      "learning_rate": 1.0456286222278366e-05,
      "loss": 2.3629,
      "step": 16080
    },
    {
      "epoch": 2.5744,
      "grad_norm": 0.5288213491439819,
      "learning_rate": 1.037951881019269e-05,
      "loss": 2.3707,
      "step": 16090
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.5640935301780701,
      "learning_rate": 1.0303018812497978e-05,
      "loss": 2.3884,
      "step": 16100
    },
    {
      "epoch": 2.576,
      "eval_bleu": 35.28000307847419,
      "eval_gen_len": 31.765,
      "eval_loss": 2.602632522583008,
      "eval_runtime": 67.3763,
      "eval_samples_per_second": 14.842,
      "eval_steps_per_second": 0.935,
      "step": 16100
    },
    {
      "epoch": 2.5776,
      "grad_norm": 0.5550195574760437,
      "learning_rate": 1.0226786457459003e-05,
      "loss": 2.3217,
      "step": 16110
    },
    {
      "epoch": 2.5792,
      "grad_norm": 0.5722303986549377,
      "learning_rate": 1.0150821972541946e-05,
      "loss": 2.3712,
      "step": 16120
    },
    {
      "epoch": 2.5808,
      "grad_norm": 0.5310932397842407,
      "learning_rate": 1.0075125584413748e-05,
      "loss": 2.3624,
      "step": 16130
    },
    {
      "epoch": 2.5824,
      "grad_norm": 0.4989975392818451,
      "learning_rate": 9.999697518941298e-06,
      "loss": 2.3498,
      "step": 16140
    },
    {
      "epoch": 2.584,
      "grad_norm": 0.5496639013290405,
      "learning_rate": 9.924538001190908e-06,
      "loss": 2.3502,
      "step": 16150
    },
    {
      "epoch": 2.584,
      "eval_bleu": 35.42905671547204,
      "eval_gen_len": 31.78,
      "eval_loss": 2.603019952774048,
      "eval_runtime": 67.3161,
      "eval_samples_per_second": 14.855,
      "eval_steps_per_second": 0.936,
      "step": 16150
    },
    {
      "epoch": 2.5856,
      "grad_norm": 0.5422201156616211,
      "learning_rate": 9.849647255427596e-06,
      "loss": 2.3723,
      "step": 16160
    },
    {
      "epoch": 2.5872,
      "grad_norm": 0.5692650079727173,
      "learning_rate": 9.775025505114343e-06,
      "loss": 2.3626,
      "step": 16170
    },
    {
      "epoch": 2.5888,
      "grad_norm": 0.5586729049682617,
      "learning_rate": 9.70067297291154e-06,
      "loss": 2.3807,
      "step": 16180
    },
    {
      "epoch": 2.5904,
      "grad_norm": 0.5402510166168213,
      "learning_rate": 9.62658988067625e-06,
      "loss": 2.3707,
      "step": 16190
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.5651043057441711,
      "learning_rate": 9.552776449461586e-06,
      "loss": 2.3343,
      "step": 16200
    },
    {
      "epoch": 2.592,
      "eval_bleu": 35.33847314739148,
      "eval_gen_len": 31.722,
      "eval_loss": 2.602780342102051,
      "eval_runtime": 67.3469,
      "eval_samples_per_second": 14.848,
      "eval_steps_per_second": 0.935,
      "step": 16200
    },
    {
      "epoch": 2.5936,
      "grad_norm": 0.5507596731185913,
      "learning_rate": 9.479232899516022e-06,
      "loss": 2.3672,
      "step": 16210
    },
    {
      "epoch": 2.5952,
      "grad_norm": 0.5762956142425537,
      "learning_rate": 9.405959450282709e-06,
      "loss": 2.367,
      "step": 16220
    },
    {
      "epoch": 2.5968,
      "grad_norm": 0.5231370329856873,
      "learning_rate": 9.332956320398923e-06,
      "loss": 2.3707,
      "step": 16230
    },
    {
      "epoch": 2.5984,
      "grad_norm": 0.5258899927139282,
      "learning_rate": 9.260223727695273e-06,
      "loss": 2.3892,
      "step": 16240
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5357019901275635,
      "learning_rate": 9.18776188919519e-06,
      "loss": 2.3729,
      "step": 16250
    },
    {
      "epoch": 2.6,
      "eval_bleu": 35.25581418520602,
      "eval_gen_len": 31.721,
      "eval_loss": 2.602459192276001,
      "eval_runtime": 66.8457,
      "eval_samples_per_second": 14.96,
      "eval_steps_per_second": 0.942,
      "step": 16250
    },
    {
      "epoch": 2.6016,
      "grad_norm": 0.5596814751625061,
      "learning_rate": 9.11557102111421e-06,
      "loss": 2.3281,
      "step": 16260
    },
    {
      "epoch": 2.6032,
      "grad_norm": 0.5480571389198303,
      "learning_rate": 9.04365133885925e-06,
      "loss": 2.3571,
      "step": 16270
    },
    {
      "epoch": 2.6048,
      "grad_norm": 0.5670208930969238,
      "learning_rate": 8.972003057028155e-06,
      "loss": 2.3686,
      "step": 16280
    },
    {
      "epoch": 2.6064,
      "grad_norm": 0.5111687779426575,
      "learning_rate": 8.900626389408907e-06,
      "loss": 2.3634,
      "step": 16290
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.5331395864486694,
      "learning_rate": 8.82952154897898e-06,
      "loss": 2.3677,
      "step": 16300
    },
    {
      "epoch": 2.608,
      "eval_bleu": 35.443884869893026,
      "eval_gen_len": 31.727,
      "eval_loss": 2.602351188659668,
      "eval_runtime": 66.666,
      "eval_samples_per_second": 15.0,
      "eval_steps_per_second": 0.945,
      "step": 16300
    },
    {
      "epoch": 2.6096,
      "grad_norm": 0.548904538154602,
      "learning_rate": 8.758688747904887e-06,
      "loss": 2.3773,
      "step": 16310
    },
    {
      "epoch": 2.6112,
      "grad_norm": 0.5494308471679688,
      "learning_rate": 8.688128197541257e-06,
      "loss": 2.3336,
      "step": 16320
    },
    {
      "epoch": 2.6128,
      "grad_norm": 0.5154440402984619,
      "learning_rate": 8.617840108430497e-06,
      "loss": 2.3623,
      "step": 16330
    },
    {
      "epoch": 2.6144,
      "grad_norm": 0.5614835023880005,
      "learning_rate": 8.547824690301908e-06,
      "loss": 2.3561,
      "step": 16340
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.6077502965927124,
      "learning_rate": 8.478082152071298e-06,
      "loss": 2.357,
      "step": 16350
    },
    {
      "epoch": 2.616,
      "eval_bleu": 35.129880265941274,
      "eval_gen_len": 31.736,
      "eval_loss": 2.6022911071777344,
      "eval_runtime": 67.5354,
      "eval_samples_per_second": 14.807,
      "eval_steps_per_second": 0.933,
      "step": 16350
    },
    {
      "epoch": 2.6176,
      "grad_norm": 0.5490341782569885,
      "learning_rate": 8.408612701840169e-06,
      "loss": 2.3575,
      "step": 16360
    },
    {
      "epoch": 2.6192,
      "grad_norm": 0.5543854236602783,
      "learning_rate": 8.339416546895173e-06,
      "loss": 2.3483,
      "step": 16370
    },
    {
      "epoch": 2.6208,
      "grad_norm": 0.5280988216400146,
      "learning_rate": 8.270493893707521e-06,
      "loss": 2.3568,
      "step": 16380
    },
    {
      "epoch": 2.6224,
      "grad_norm": 0.5237910747528076,
      "learning_rate": 8.201844947932324e-06,
      "loss": 2.3577,
      "step": 16390
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.5703596472740173,
      "learning_rate": 8.133469914407955e-06,
      "loss": 2.3663,
      "step": 16400
    },
    {
      "epoch": 2.624,
      "eval_bleu": 35.36761814744136,
      "eval_gen_len": 31.739,
      "eval_loss": 2.602369546890259,
      "eval_runtime": 67.7385,
      "eval_samples_per_second": 14.763,
      "eval_steps_per_second": 0.93,
      "step": 16400
    },
    {
      "epoch": 2.6256,
      "grad_norm": 0.5179752707481384,
      "learning_rate": 8.065368997155508e-06,
      "loss": 2.3426,
      "step": 16410
    },
    {
      "epoch": 2.6272,
      "grad_norm": 0.5545024275779724,
      "learning_rate": 7.997542399378155e-06,
      "loss": 2.3508,
      "step": 16420
    },
    {
      "epoch": 2.6288,
      "grad_norm": 0.5739415287971497,
      "learning_rate": 7.929990323460534e-06,
      "loss": 2.3527,
      "step": 16430
    },
    {
      "epoch": 2.6304,
      "grad_norm": 0.5343635678291321,
      "learning_rate": 7.862712970968156e-06,
      "loss": 2.3355,
      "step": 16440
    },
    {
      "epoch": 2.632,
      "grad_norm": 0.5456739068031311,
      "learning_rate": 7.79571054264675e-06,
      "loss": 2.3594,
      "step": 16450
    },
    {
      "epoch": 2.632,
      "eval_bleu": 35.182233306057846,
      "eval_gen_len": 31.766,
      "eval_loss": 2.6029226779937744,
      "eval_runtime": 68.2417,
      "eval_samples_per_second": 14.654,
      "eval_steps_per_second": 0.923,
      "step": 16450
    },
    {
      "epoch": 2.6336,
      "grad_norm": 0.595275342464447,
      "learning_rate": 7.728983238421794e-06,
      "loss": 2.345,
      "step": 16460
    },
    {
      "epoch": 2.6352,
      "grad_norm": 0.6017230153083801,
      "learning_rate": 7.662531257397754e-06,
      "loss": 2.3631,
      "step": 16470
    },
    {
      "epoch": 2.6368,
      "grad_norm": 0.5284201502799988,
      "learning_rate": 7.59635479785763e-06,
      "loss": 2.3591,
      "step": 16480
    },
    {
      "epoch": 2.6384,
      "grad_norm": 0.6289486289024353,
      "learning_rate": 7.530454057262293e-06,
      "loss": 2.3392,
      "step": 16490
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.5503219366073608,
      "learning_rate": 7.464829232249882e-06,
      "loss": 2.3559,
      "step": 16500
    },
    {
      "epoch": 2.64,
      "eval_bleu": 35.40039045493349,
      "eval_gen_len": 31.702,
      "eval_loss": 2.602552652359009,
      "eval_runtime": 67.9801,
      "eval_samples_per_second": 14.71,
      "eval_steps_per_second": 0.927,
      "step": 16500
    },
    {
      "epoch": 2.6416,
      "grad_norm": 0.5380790829658508,
      "learning_rate": 7.399480518635271e-06,
      "loss": 2.3662,
      "step": 16510
    },
    {
      "epoch": 2.6432,
      "grad_norm": 0.5160571336746216,
      "learning_rate": 7.334408111409463e-06,
      "loss": 2.3625,
      "step": 16520
    },
    {
      "epoch": 2.6448,
      "grad_norm": 0.5625000596046448,
      "learning_rate": 7.269612204738951e-06,
      "loss": 2.3431,
      "step": 16530
    },
    {
      "epoch": 2.6464,
      "grad_norm": 0.6086649298667908,
      "learning_rate": 7.20509299196529e-06,
      "loss": 2.358,
      "step": 16540
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.5575401186943054,
      "learning_rate": 7.1408506656043264e-06,
      "loss": 2.3653,
      "step": 16550
    },
    {
      "epoch": 2.648,
      "eval_bleu": 35.383885780529965,
      "eval_gen_len": 31.764,
      "eval_loss": 2.6028506755828857,
      "eval_runtime": 66.735,
      "eval_samples_per_second": 14.985,
      "eval_steps_per_second": 0.944,
      "step": 16550
    },
    {
      "epoch": 2.6496,
      "grad_norm": 0.5366730093955994,
      "learning_rate": 7.076885417345758e-06,
      "loss": 2.3609,
      "step": 16560
    },
    {
      "epoch": 2.6512000000000002,
      "grad_norm": 0.5693549513816833,
      "learning_rate": 7.013197438052532e-06,
      "loss": 2.388,
      "step": 16570
    },
    {
      "epoch": 2.6528,
      "grad_norm": 0.5432193279266357,
      "learning_rate": 6.949786917760226e-06,
      "loss": 2.3368,
      "step": 16580
    },
    {
      "epoch": 2.6544,
      "grad_norm": 0.5052900314331055,
      "learning_rate": 6.8866540456765774e-06,
      "loss": 2.3317,
      "step": 16590
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.5304678678512573,
      "learning_rate": 6.823799010180798e-06,
      "loss": 2.3773,
      "step": 16600
    },
    {
      "epoch": 2.656,
      "eval_bleu": 35.25302448026689,
      "eval_gen_len": 31.75,
      "eval_loss": 2.6031606197357178,
      "eval_runtime": 66.5019,
      "eval_samples_per_second": 15.037,
      "eval_steps_per_second": 0.947,
      "step": 16600
    },
    {
      "epoch": 2.6576,
      "grad_norm": 0.5105074048042297,
      "learning_rate": 6.76122199882312e-06,
      "loss": 2.3614,
      "step": 16610
    },
    {
      "epoch": 2.6592000000000002,
      "grad_norm": 0.5494639873504639,
      "learning_rate": 6.698923198324203e-06,
      "loss": 2.3355,
      "step": 16620
    },
    {
      "epoch": 2.6608,
      "grad_norm": 0.5423338413238525,
      "learning_rate": 6.6369027945745176e-06,
      "loss": 2.3704,
      "step": 16630
    },
    {
      "epoch": 2.6624,
      "grad_norm": 0.6184262037277222,
      "learning_rate": 6.575160972633865e-06,
      "loss": 2.3585,
      "step": 16640
    },
    {
      "epoch": 2.664,
      "grad_norm": 0.5275170803070068,
      "learning_rate": 6.5136979167308095e-06,
      "loss": 2.381,
      "step": 16650
    },
    {
      "epoch": 2.664,
      "eval_bleu": 35.27595034168923,
      "eval_gen_len": 31.795,
      "eval_loss": 2.6029365062713623,
      "eval_runtime": 67.0168,
      "eval_samples_per_second": 14.922,
      "eval_steps_per_second": 0.94,
      "step": 16650
    },
    {
      "epoch": 2.6656,
      "grad_norm": 0.5760545134544373,
      "learning_rate": 6.452513810262117e-06,
      "loss": 2.3657,
      "step": 16660
    },
    {
      "epoch": 2.6672000000000002,
      "grad_norm": 0.5571241974830627,
      "learning_rate": 6.391608835792195e-06,
      "loss": 2.3442,
      "step": 16670
    },
    {
      "epoch": 2.6688,
      "grad_norm": 0.5767856240272522,
      "learning_rate": 6.330983175052563e-06,
      "loss": 2.3518,
      "step": 16680
    },
    {
      "epoch": 2.6704,
      "grad_norm": 0.5574162602424622,
      "learning_rate": 6.2706370089413045e-06,
      "loss": 2.355,
      "step": 16690
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.5410871505737305,
      "learning_rate": 6.2105705175225736e-06,
      "loss": 2.3603,
      "step": 16700
    },
    {
      "epoch": 2.672,
      "eval_bleu": 35.21499899897693,
      "eval_gen_len": 31.765,
      "eval_loss": 2.6032872200012207,
      "eval_runtime": 66.6798,
      "eval_samples_per_second": 14.997,
      "eval_steps_per_second": 0.945,
      "step": 16700
    },
    {
      "epoch": 2.6736,
      "grad_norm": 0.4935069978237152,
      "learning_rate": 6.150783880025945e-06,
      "loss": 2.3585,
      "step": 16710
    },
    {
      "epoch": 2.6752000000000002,
      "grad_norm": 0.5381131768226624,
      "learning_rate": 6.091277274846019e-06,
      "loss": 2.3411,
      "step": 16720
    },
    {
      "epoch": 2.6768,
      "grad_norm": 0.5285493731498718,
      "learning_rate": 6.032050879541773e-06,
      "loss": 2.3463,
      "step": 16730
    },
    {
      "epoch": 2.6784,
      "grad_norm": 0.5389332175254822,
      "learning_rate": 5.973104870836099e-06,
      "loss": 2.3564,
      "step": 16740
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.5163483619689941,
      "learning_rate": 5.91443942461527e-06,
      "loss": 2.3451,
      "step": 16750
    },
    {
      "epoch": 2.68,
      "eval_bleu": 35.41812483221798,
      "eval_gen_len": 31.756,
      "eval_loss": 2.6025023460388184,
      "eval_runtime": 66.8322,
      "eval_samples_per_second": 14.963,
      "eval_steps_per_second": 0.943,
      "step": 16750
    },
    {
      "epoch": 2.6816,
      "grad_norm": 0.5400753617286682,
      "learning_rate": 5.856054715928361e-06,
      "loss": 2.3803,
      "step": 16760
    },
    {
      "epoch": 2.6832000000000003,
      "grad_norm": 0.5092787146568298,
      "learning_rate": 5.7979509189868055e-06,
      "loss": 2.3473,
      "step": 16770
    },
    {
      "epoch": 2.6848,
      "grad_norm": 0.5140727162361145,
      "learning_rate": 5.74012820716383e-06,
      "loss": 2.3195,
      "step": 16780
    },
    {
      "epoch": 2.6864,
      "grad_norm": 0.5781421661376953,
      "learning_rate": 5.6825867529939235e-06,
      "loss": 2.3561,
      "step": 16790
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.5525548458099365,
      "learning_rate": 5.625326728172386e-06,
      "loss": 2.3704,
      "step": 16800
    },
    {
      "epoch": 2.6879999999999997,
      "eval_bleu": 35.34019138379547,
      "eval_gen_len": 31.768,
      "eval_loss": 2.6025543212890625,
      "eval_runtime": 67.016,
      "eval_samples_per_second": 14.922,
      "eval_steps_per_second": 0.94,
      "step": 16800
    },
    {
      "epoch": 2.6896,
      "grad_norm": 0.5713160634040833,
      "learning_rate": 5.568348303554716e-06,
      "loss": 2.3697,
      "step": 16810
    },
    {
      "epoch": 2.6912000000000003,
      "grad_norm": 0.567054808139801,
      "learning_rate": 5.511651649156213e-06,
      "loss": 2.3581,
      "step": 16820
    },
    {
      "epoch": 2.6928,
      "grad_norm": 0.5316662192344666,
      "learning_rate": 5.455236934151364e-06,
      "loss": 2.3397,
      "step": 16830
    },
    {
      "epoch": 2.6944,
      "grad_norm": 0.5068902969360352,
      "learning_rate": 5.399104326873428e-06,
      "loss": 2.3576,
      "step": 16840
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 0.5167750716209412,
      "learning_rate": 5.343253994813901e-06,
      "loss": 2.3616,
      "step": 16850
    },
    {
      "epoch": 2.6959999999999997,
      "eval_bleu": 35.30988046839867,
      "eval_gen_len": 31.802,
      "eval_loss": 2.6026813983917236,
      "eval_runtime": 67.199,
      "eval_samples_per_second": 14.881,
      "eval_steps_per_second": 0.938,
      "step": 16850
    },
    {
      "epoch": 2.6976,
      "grad_norm": 0.5142713785171509,
      "learning_rate": 5.287686104621958e-06,
      "loss": 2.3538,
      "step": 16860
    },
    {
      "epoch": 2.6992000000000003,
      "grad_norm": 0.5148425698280334,
      "learning_rate": 5.232400822104077e-06,
      "loss": 2.385,
      "step": 16870
    },
    {
      "epoch": 2.7008,
      "grad_norm": 0.535158097743988,
      "learning_rate": 5.177398312223425e-06,
      "loss": 2.3295,
      "step": 16880
    },
    {
      "epoch": 2.7024,
      "grad_norm": 0.5321037173271179,
      "learning_rate": 5.122678739099451e-06,
      "loss": 2.3557,
      "step": 16890
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.546136736869812,
      "learning_rate": 5.068242266007361e-06,
      "loss": 2.3588,
      "step": 16900
    },
    {
      "epoch": 2.7039999999999997,
      "eval_bleu": 35.35215599158811,
      "eval_gen_len": 31.78,
      "eval_loss": 2.602400064468384,
      "eval_runtime": 68.2925,
      "eval_samples_per_second": 14.643,
      "eval_steps_per_second": 0.923,
      "step": 16900
    },
    {
      "epoch": 2.7056,
      "grad_norm": 0.5255212187767029,
      "learning_rate": 5.01408905537758e-06,
      "loss": 2.352,
      "step": 16910
    },
    {
      "epoch": 2.7072000000000003,
      "grad_norm": 0.5511406660079956,
      "learning_rate": 4.9602192687953855e-06,
      "loss": 2.3482,
      "step": 16920
    },
    {
      "epoch": 2.7088,
      "grad_norm": 0.5444019436836243,
      "learning_rate": 4.906633067000332e-06,
      "loss": 2.3559,
      "step": 16930
    },
    {
      "epoch": 2.7104,
      "grad_norm": 0.526482880115509,
      "learning_rate": 4.8533306098857755e-06,
      "loss": 2.3409,
      "step": 16940
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.5011523365974426,
      "learning_rate": 4.800312056498468e-06,
      "loss": 2.3592,
      "step": 16950
    },
    {
      "epoch": 2.7119999999999997,
      "eval_bleu": 35.50865622165989,
      "eval_gen_len": 31.745,
      "eval_loss": 2.602449893951416,
      "eval_runtime": 68.3827,
      "eval_samples_per_second": 14.624,
      "eval_steps_per_second": 0.921,
      "step": 16950
    },
    {
      "epoch": 2.7136,
      "grad_norm": 0.577518880367279,
      "learning_rate": 4.747577565037986e-06,
      "loss": 2.3477,
      "step": 16960
    },
    {
      "epoch": 2.7152,
      "grad_norm": 0.5422285795211792,
      "learning_rate": 4.695127292856338e-06,
      "loss": 2.3621,
      "step": 16970
    },
    {
      "epoch": 2.7168,
      "grad_norm": 0.5487441420555115,
      "learning_rate": 4.642961396457468e-06,
      "loss": 2.3668,
      "step": 16980
    },
    {
      "epoch": 2.7184,
      "grad_norm": 0.5492100715637207,
      "learning_rate": 4.591080031496753e-06,
      "loss": 2.3738,
      "step": 16990
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.541470468044281,
      "learning_rate": 4.5394833527805935e-06,
      "loss": 2.3275,
      "step": 17000
    },
    {
      "epoch": 2.7199999999999998,
      "eval_bleu": 35.358230751255896,
      "eval_gen_len": 31.772,
      "eval_loss": 2.602419853210449,
      "eval_runtime": 67.3121,
      "eval_samples_per_second": 14.856,
      "eval_steps_per_second": 0.936,
      "step": 17000
    },
    {
      "epoch": 2.7216,
      "grad_norm": 0.5664238333702087,
      "learning_rate": 4.488171514265915e-06,
      "loss": 2.383,
      "step": 17010
    },
    {
      "epoch": 2.7232,
      "grad_norm": 0.5645037889480591,
      "learning_rate": 4.437144669059745e-06,
      "loss": 2.3477,
      "step": 17020
    },
    {
      "epoch": 2.7248,
      "grad_norm": 0.6167669296264648,
      "learning_rate": 4.386402969418712e-06,
      "loss": 2.3693,
      "step": 17030
    },
    {
      "epoch": 2.7264,
      "grad_norm": 0.5336945652961731,
      "learning_rate": 4.335946566748616e-06,
      "loss": 2.3675,
      "step": 17040
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.5476008057594299,
      "learning_rate": 4.285775611603959e-06,
      "loss": 2.3299,
      "step": 17050
    },
    {
      "epoch": 2.7279999999999998,
      "eval_bleu": 35.39968079441061,
      "eval_gen_len": 31.764,
      "eval_loss": 2.6021058559417725,
      "eval_runtime": 67.6938,
      "eval_samples_per_second": 14.772,
      "eval_steps_per_second": 0.931,
      "step": 17050
    },
    {
      "epoch": 2.7296,
      "grad_norm": 0.5246288180351257,
      "learning_rate": 4.2358902536875575e-06,
      "loss": 2.3846,
      "step": 17060
    },
    {
      "epoch": 2.7312,
      "grad_norm": 0.539962112903595,
      "learning_rate": 4.186290641849966e-06,
      "loss": 2.351,
      "step": 17070
    },
    {
      "epoch": 2.7328,
      "grad_norm": 0.5605239868164062,
      "learning_rate": 4.136976924089209e-06,
      "loss": 2.3432,
      "step": 17080
    },
    {
      "epoch": 2.7344,
      "grad_norm": 0.5061987042427063,
      "learning_rate": 4.0879492475501715e-06,
      "loss": 2.3422,
      "step": 17090
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.5849219560623169,
      "learning_rate": 4.039207758524255e-06,
      "loss": 2.3643,
      "step": 17100
    },
    {
      "epoch": 2.7359999999999998,
      "eval_bleu": 35.27820986514812,
      "eval_gen_len": 31.773,
      "eval_loss": 2.6023361682891846,
      "eval_runtime": 66.9044,
      "eval_samples_per_second": 14.947,
      "eval_steps_per_second": 0.942,
      "step": 17100
    },
    {
      "epoch": 2.7376,
      "grad_norm": 0.5381724238395691,
      "learning_rate": 3.990752602448955e-06,
      "loss": 2.3396,
      "step": 17110
    },
    {
      "epoch": 2.7392,
      "grad_norm": 0.5940499305725098,
      "learning_rate": 3.942583923907317e-06,
      "loss": 2.3557,
      "step": 17120
    },
    {
      "epoch": 2.7408,
      "grad_norm": 0.5557436347007751,
      "learning_rate": 3.89470186662767e-06,
      "loss": 2.3643,
      "step": 17130
    },
    {
      "epoch": 2.7424,
      "grad_norm": 0.5986272692680359,
      "learning_rate": 3.847106573483028e-06,
      "loss": 2.3597,
      "step": 17140
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.6056349873542786,
      "learning_rate": 3.7997981864907883e-06,
      "loss": 2.3503,
      "step": 17150
    },
    {
      "epoch": 2.7439999999999998,
      "eval_bleu": 35.391863277111185,
      "eval_gen_len": 31.759,
      "eval_loss": 2.602487564086914,
      "eval_runtime": 66.707,
      "eval_samples_per_second": 14.991,
      "eval_steps_per_second": 0.944,
      "step": 17150
    },
    {
      "epoch": 2.7456,
      "grad_norm": 0.5370936989784241,
      "learning_rate": 3.752776846812256e-06,
      "loss": 2.3509,
      "step": 17160
    },
    {
      "epoch": 2.7472,
      "grad_norm": 0.573424756526947,
      "learning_rate": 3.7060426947521985e-06,
      "loss": 2.3669,
      "step": 17170
    },
    {
      "epoch": 2.7488,
      "grad_norm": 0.5101690292358398,
      "learning_rate": 3.659595869758503e-06,
      "loss": 2.3385,
      "step": 17180
    },
    {
      "epoch": 2.7504,
      "grad_norm": 0.5915752053260803,
      "learning_rate": 3.613436510421697e-06,
      "loss": 2.3479,
      "step": 17190
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.5697360038757324,
      "learning_rate": 3.5675647544745284e-06,
      "loss": 2.3824,
      "step": 17200
    },
    {
      "epoch": 2.752,
      "eval_bleu": 35.41264917396644,
      "eval_gen_len": 31.77,
      "eval_loss": 2.602473258972168,
      "eval_runtime": 67.3766,
      "eval_samples_per_second": 14.842,
      "eval_steps_per_second": 0.935,
      "step": 17200
    },
    {
      "epoch": 2.7536,
      "grad_norm": 0.5360822677612305,
      "learning_rate": 3.5219807387916083e-06,
      "loss": 2.3581,
      "step": 17210
    },
    {
      "epoch": 2.7552,
      "grad_norm": 0.5766757130622864,
      "learning_rate": 3.4766845993889684e-06,
      "loss": 2.3522,
      "step": 17220
    },
    {
      "epoch": 2.7568,
      "grad_norm": 0.5490065813064575,
      "learning_rate": 3.4316764714236503e-06,
      "loss": 2.3603,
      "step": 17230
    },
    {
      "epoch": 2.7584,
      "grad_norm": 0.5430091619491577,
      "learning_rate": 3.3869564891933047e-06,
      "loss": 2.3684,
      "step": 17240
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.5583913326263428,
      "learning_rate": 3.3425247861358367e-06,
      "loss": 2.3379,
      "step": 17250
    },
    {
      "epoch": 2.76,
      "eval_bleu": 35.23406699110339,
      "eval_gen_len": 31.788,
      "eval_loss": 2.6025478839874268,
      "eval_runtime": 67.2035,
      "eval_samples_per_second": 14.88,
      "eval_steps_per_second": 0.937,
      "step": 17250
    },
    {
      "epoch": 2.7616,
      "grad_norm": 0.5585739612579346,
      "learning_rate": 3.298381494828928e-06,
      "loss": 2.3558,
      "step": 17260
    },
    {
      "epoch": 2.7632,
      "grad_norm": 0.5711935758590698,
      "learning_rate": 3.254526746989683e-06,
      "loss": 2.3874,
      "step": 17270
    },
    {
      "epoch": 2.7648,
      "grad_norm": 0.5864253044128418,
      "learning_rate": 3.2109606734742616e-06,
      "loss": 2.3743,
      "step": 17280
    },
    {
      "epoch": 2.7664,
      "grad_norm": 0.5957036018371582,
      "learning_rate": 3.167683404277455e-06,
      "loss": 2.373,
      "step": 17290
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.6113703846931458,
      "learning_rate": 3.1246950685322685e-06,
      "loss": 2.3933,
      "step": 17300
    },
    {
      "epoch": 2.768,
      "eval_bleu": 35.40220344112401,
      "eval_gen_len": 31.759,
      "eval_loss": 2.602597713470459,
      "eval_runtime": 67.2676,
      "eval_samples_per_second": 14.866,
      "eval_steps_per_second": 0.937,
      "step": 17300
    },
    {
      "epoch": 2.7696,
      "grad_norm": 0.5122935771942139,
      "learning_rate": 3.081995794509629e-06,
      "loss": 2.3505,
      "step": 17310
    },
    {
      "epoch": 2.7712,
      "grad_norm": 0.5563782453536987,
      "learning_rate": 3.039585709617887e-06,
      "loss": 2.355,
      "step": 17320
    },
    {
      "epoch": 2.7728,
      "grad_norm": 0.54914790391922,
      "learning_rate": 2.9974649404025503e-06,
      "loss": 2.363,
      "step": 17330
    },
    {
      "epoch": 2.7744,
      "grad_norm": 0.5431055426597595,
      "learning_rate": 2.9556336125458273e-06,
      "loss": 2.3616,
      "step": 17340
    },
    {
      "epoch": 2.776,
      "grad_norm": 0.5597915649414062,
      "learning_rate": 2.9140918508662407e-06,
      "loss": 2.3923,
      "step": 17350
    },
    {
      "epoch": 2.776,
      "eval_bleu": 35.21750928357872,
      "eval_gen_len": 31.774,
      "eval_loss": 2.602489709854126,
      "eval_runtime": 67.4928,
      "eval_samples_per_second": 14.816,
      "eval_steps_per_second": 0.933,
      "step": 17350
    },
    {
      "epoch": 2.7776,
      "grad_norm": 0.5252090096473694,
      "learning_rate": 2.8728397793183703e-06,
      "loss": 2.3456,
      "step": 17360
    },
    {
      "epoch": 2.7792,
      "grad_norm": 0.5467891097068787,
      "learning_rate": 2.83187752099231e-06,
      "loss": 2.357,
      "step": 17370
    },
    {
      "epoch": 2.7808,
      "grad_norm": 0.5618640184402466,
      "learning_rate": 2.791205198113478e-06,
      "loss": 2.3529,
      "step": 17380
    },
    {
      "epoch": 2.7824,
      "grad_norm": 0.5336976051330566,
      "learning_rate": 2.7508229320421185e-06,
      "loss": 2.357,
      "step": 17390
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.5647136569023132,
      "learning_rate": 2.7107308432729796e-06,
      "loss": 2.3754,
      "step": 17400
    },
    {
      "epoch": 2.784,
      "eval_bleu": 35.48822741729564,
      "eval_gen_len": 31.752,
      "eval_loss": 2.6026103496551514,
      "eval_runtime": 67.1731,
      "eval_samples_per_second": 14.887,
      "eval_steps_per_second": 0.938,
      "step": 17400
    },
    {
      "epoch": 2.7856,
      "grad_norm": 0.5358963012695312,
      "learning_rate": 2.6709290514350007e-06,
      "loss": 2.353,
      "step": 17410
    },
    {
      "epoch": 2.7872,
      "grad_norm": 0.5650075674057007,
      "learning_rate": 2.6314176752909035e-06,
      "loss": 2.3218,
      "step": 17420
    },
    {
      "epoch": 2.7888,
      "grad_norm": 0.5471001863479614,
      "learning_rate": 2.5921968327368372e-06,
      "loss": 2.3647,
      "step": 17430
    },
    {
      "epoch": 2.7904,
      "grad_norm": 0.542506992816925,
      "learning_rate": 2.5532666408020655e-06,
      "loss": 2.3446,
      "step": 17440
    },
    {
      "epoch": 2.792,
      "grad_norm": 0.5296882390975952,
      "learning_rate": 2.5146272156485572e-06,
      "loss": 2.3683,
      "step": 17450
    },
    {
      "epoch": 2.792,
      "eval_bleu": 35.30014929469603,
      "eval_gen_len": 31.759,
      "eval_loss": 2.6025991439819336,
      "eval_runtime": 67.3432,
      "eval_samples_per_second": 14.849,
      "eval_steps_per_second": 0.936,
      "step": 17450
    },
    {
      "epoch": 2.7936,
      "grad_norm": 0.5162841081619263,
      "learning_rate": 2.47627867257072e-06,
      "loss": 2.374,
      "step": 17460
    },
    {
      "epoch": 2.7952,
      "grad_norm": 0.5373915433883667,
      "learning_rate": 2.438221125994977e-06,
      "loss": 2.3334,
      "step": 17470
    },
    {
      "epoch": 2.7968,
      "grad_norm": 0.5510628819465637,
      "learning_rate": 2.4004546894794698e-06,
      "loss": 2.3528,
      "step": 17480
    },
    {
      "epoch": 2.7984,
      "grad_norm": 0.6467455625534058,
      "learning_rate": 2.3629794757137445e-06,
      "loss": 2.3628,
      "step": 17490
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.5178306102752686,
      "learning_rate": 2.32579559651831e-06,
      "loss": 2.3711,
      "step": 17500
    },
    {
      "epoch": 2.8,
      "eval_bleu": 35.29038731070019,
      "eval_gen_len": 31.763,
      "eval_loss": 2.602675676345825,
      "eval_runtime": 67.3592,
      "eval_samples_per_second": 14.846,
      "eval_steps_per_second": 0.935,
      "step": 17500
    },
    {
      "epoch": 2.8016,
      "grad_norm": 0.5733275413513184,
      "learning_rate": 2.2889031628444356e-06,
      "loss": 2.3508,
      "step": 17510
    },
    {
      "epoch": 2.8032,
      "grad_norm": 0.5202029347419739,
      "learning_rate": 2.252302284773755e-06,
      "loss": 2.3672,
      "step": 17520
    },
    {
      "epoch": 2.8048,
      "grad_norm": 0.6113468408584595,
      "learning_rate": 2.2159930715179077e-06,
      "loss": 2.3311,
      "step": 17530
    },
    {
      "epoch": 2.8064,
      "grad_norm": 0.5356191992759705,
      "learning_rate": 2.179975631418263e-06,
      "loss": 2.3526,
      "step": 17540
    },
    {
      "epoch": 2.808,
      "grad_norm": 0.5417593717575073,
      "learning_rate": 2.1442500719456193e-06,
      "loss": 2.3545,
      "step": 17550
    },
    {
      "epoch": 2.808,
      "eval_bleu": 35.36175362997976,
      "eval_gen_len": 31.734,
      "eval_loss": 2.6026883125305176,
      "eval_runtime": 67.1378,
      "eval_samples_per_second": 14.895,
      "eval_steps_per_second": 0.938,
      "step": 17550
    },
    {
      "epoch": 2.8096,
      "grad_norm": 0.5577756762504578,
      "learning_rate": 2.1088164996997727e-06,
      "loss": 2.3473,
      "step": 17560
    },
    {
      "epoch": 2.8112,
      "grad_norm": 0.558333694934845,
      "learning_rate": 2.073675020409349e-06,
      "loss": 2.3752,
      "step": 17570
    },
    {
      "epoch": 2.8128,
      "grad_norm": 0.5803550481796265,
      "learning_rate": 2.0388257389313494e-06,
      "loss": 2.3576,
      "step": 17580
    },
    {
      "epoch": 2.8144,
      "grad_norm": 0.5270223021507263,
      "learning_rate": 2.004268759250938e-06,
      "loss": 2.3474,
      "step": 17590
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.5891052484512329,
      "learning_rate": 1.970004184481089e-06,
      "loss": 2.371,
      "step": 17600
    },
    {
      "epoch": 2.816,
      "eval_bleu": 35.34775420834964,
      "eval_gen_len": 31.776,
      "eval_loss": 2.6027424335479736,
      "eval_runtime": 67.4314,
      "eval_samples_per_second": 14.83,
      "eval_steps_per_second": 0.934,
      "step": 17600
    },
    {
      "epoch": 2.8176,
      "grad_norm": 0.5594507455825806,
      "learning_rate": 1.9360321168622632e-06,
      "loss": 2.3617,
      "step": 17610
    },
    {
      "epoch": 2.8192,
      "grad_norm": 0.6275246739387512,
      "learning_rate": 1.9023526577621409e-06,
      "loss": 2.3558,
      "step": 17620
    },
    {
      "epoch": 2.8208,
      "grad_norm": 0.575503408908844,
      "learning_rate": 1.8689659076752908e-06,
      "loss": 2.3737,
      "step": 17630
    },
    {
      "epoch": 2.8224,
      "grad_norm": 0.5288619995117188,
      "learning_rate": 1.8358719662228906e-06,
      "loss": 2.3426,
      "step": 17640
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.5163313150405884,
      "learning_rate": 1.8030709321524286e-06,
      "loss": 2.3705,
      "step": 17650
    },
    {
      "epoch": 2.824,
      "eval_bleu": 35.37133972487909,
      "eval_gen_len": 31.798,
      "eval_loss": 2.602715492248535,
      "eval_runtime": 67.2428,
      "eval_samples_per_second": 14.871,
      "eval_steps_per_second": 0.937,
      "step": 17650
    },
    {
      "epoch": 2.8256,
      "grad_norm": 0.5155178308486938,
      "learning_rate": 1.7705629033373472e-06,
      "loss": 2.3376,
      "step": 17660
    },
    {
      "epoch": 2.8272,
      "grad_norm": 0.5444048047065735,
      "learning_rate": 1.7383479767768884e-06,
      "loss": 2.3873,
      "step": 17670
    },
    {
      "epoch": 2.8288,
      "grad_norm": 0.5380796790122986,
      "learning_rate": 1.7064262485956384e-06,
      "loss": 2.3472,
      "step": 17680
    },
    {
      "epoch": 2.8304,
      "grad_norm": 0.5500059127807617,
      "learning_rate": 1.6747978140433829e-06,
      "loss": 2.368,
      "step": 17690
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.5250706076622009,
      "learning_rate": 1.64346276749473e-06,
      "loss": 2.3714,
      "step": 17700
    },
    {
      "epoch": 2.832,
      "eval_bleu": 35.292854950221596,
      "eval_gen_len": 31.796,
      "eval_loss": 2.6028835773468018,
      "eval_runtime": 67.2183,
      "eval_samples_per_second": 14.877,
      "eval_steps_per_second": 0.937,
      "step": 17700
    },
    {
      "epoch": 2.8336,
      "grad_norm": 0.5422923564910889,
      "learning_rate": 1.6124212024488771e-06,
      "loss": 2.3627,
      "step": 17710
    },
    {
      "epoch": 2.8352,
      "grad_norm": 0.5373226404190063,
      "learning_rate": 1.5816732115292998e-06,
      "loss": 2.3935,
      "step": 17720
    },
    {
      "epoch": 2.8368,
      "grad_norm": 0.5588178038597107,
      "learning_rate": 1.5512188864834965e-06,
      "loss": 2.3537,
      "step": 17730
    },
    {
      "epoch": 2.8384,
      "grad_norm": 0.5591049194335938,
      "learning_rate": 1.521058318182722e-06,
      "loss": 2.3314,
      "step": 17740
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6201377511024475,
      "learning_rate": 1.4911915966216993e-06,
      "loss": 2.3432,
      "step": 17750
    },
    {
      "epoch": 2.84,
      "eval_bleu": 35.36470239880798,
      "eval_gen_len": 31.742,
      "eval_loss": 2.602818489074707,
      "eval_runtime": 67.3087,
      "eval_samples_per_second": 14.857,
      "eval_steps_per_second": 0.936,
      "step": 17750
    },
    {
      "epoch": 2.8416,
      "grad_norm": 0.5387316346168518,
      "learning_rate": 1.4616188109183304e-06,
      "loss": 2.3566,
      "step": 17760
    },
    {
      "epoch": 2.8432,
      "grad_norm": 0.5482121706008911,
      "learning_rate": 1.4323400493134964e-06,
      "loss": 2.3448,
      "step": 17770
    },
    {
      "epoch": 2.8448,
      "grad_norm": 0.5004248023033142,
      "learning_rate": 1.403355399170736e-06,
      "loss": 2.3506,
      "step": 17780
    },
    {
      "epoch": 2.8464,
      "grad_norm": 0.5657770037651062,
      "learning_rate": 1.3746649469759787e-06,
      "loss": 2.3334,
      "step": 17790
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.555302619934082,
      "learning_rate": 1.3462687783373673e-06,
      "loss": 2.3564,
      "step": 17800
    },
    {
      "epoch": 2.848,
      "eval_bleu": 35.38257722933952,
      "eval_gen_len": 31.781,
      "eval_loss": 2.602836847305298,
      "eval_runtime": 67.73,
      "eval_samples_per_second": 14.765,
      "eval_steps_per_second": 0.93,
      "step": 17800
    },
    {
      "epoch": 2.8496,
      "grad_norm": 0.5378940105438232,
      "learning_rate": 1.3181669779848692e-06,
      "loss": 2.3572,
      "step": 17810
    },
    {
      "epoch": 2.8512,
      "grad_norm": 0.5542454719543457,
      "learning_rate": 1.2903596297701547e-06,
      "loss": 2.378,
      "step": 17820
    },
    {
      "epoch": 2.8528000000000002,
      "grad_norm": 0.5862261056900024,
      "learning_rate": 1.2628468166663077e-06,
      "loss": 2.3757,
      "step": 17830
    },
    {
      "epoch": 2.8544,
      "grad_norm": 0.507901132106781,
      "learning_rate": 1.2356286207675039e-06,
      "loss": 2.3547,
      "step": 17840
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.5371140837669373,
      "learning_rate": 1.2087051232888558e-06,
      "loss": 2.3538,
      "step": 17850
    },
    {
      "epoch": 2.856,
      "eval_bleu": 35.30475503392945,
      "eval_gen_len": 31.789,
      "eval_loss": 2.602843761444092,
      "eval_runtime": 67.2106,
      "eval_samples_per_second": 14.879,
      "eval_steps_per_second": 0.937,
      "step": 17850
    },
    {
      "epoch": 2.8576,
      "grad_norm": 0.5254151821136475,
      "learning_rate": 1.1820764045661458e-06,
      "loss": 2.3708,
      "step": 17860
    },
    {
      "epoch": 2.8592,
      "grad_norm": 0.5763217806816101,
      "learning_rate": 1.1557425440555602e-06,
      "loss": 2.345,
      "step": 17870
    },
    {
      "epoch": 2.8608000000000002,
      "grad_norm": 0.5512347221374512,
      "learning_rate": 1.1297036203335e-06,
      "loss": 2.3552,
      "step": 17880
    },
    {
      "epoch": 2.8624,
      "grad_norm": 0.537409782409668,
      "learning_rate": 1.1039597110962808e-06,
      "loss": 2.3718,
      "step": 17890
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.5449439883232117,
      "learning_rate": 1.0785108931599674e-06,
      "loss": 2.3916,
      "step": 17900
    },
    {
      "epoch": 2.864,
      "eval_bleu": 35.33241258082275,
      "eval_gen_len": 31.783,
      "eval_loss": 2.6028308868408203,
      "eval_runtime": 67.1981,
      "eval_samples_per_second": 14.881,
      "eval_steps_per_second": 0.938,
      "step": 17900
    },
    {
      "epoch": 2.8656,
      "grad_norm": 0.5272974371910095,
      "learning_rate": 1.0533572424601069e-06,
      "loss": 2.3247,
      "step": 17910
    },
    {
      "epoch": 2.8672,
      "grad_norm": 0.5324875712394714,
      "learning_rate": 1.0284988340515055e-06,
      "loss": 2.3412,
      "step": 17920
    },
    {
      "epoch": 2.8688000000000002,
      "grad_norm": 0.5196545124053955,
      "learning_rate": 1.0039357421080087e-06,
      "loss": 2.3519,
      "step": 17930
    },
    {
      "epoch": 2.8704,
      "grad_norm": 0.5810553431510925,
      "learning_rate": 9.79668039922288e-07,
      "loss": 2.3738,
      "step": 17940
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.5175272822380066,
      "learning_rate": 9.556957999056204e-07,
      "loss": 2.3573,
      "step": 17950
    },
    {
      "epoch": 2.872,
      "eval_bleu": 35.38915093814046,
      "eval_gen_len": 31.786,
      "eval_loss": 2.602846384048462,
      "eval_runtime": 67.9134,
      "eval_samples_per_second": 14.725,
      "eval_steps_per_second": 0.928,
      "step": 17950
    },
    {
      "epoch": 2.8736,
      "grad_norm": 0.49789321422576904,
      "learning_rate": 9.320190935876549e-07,
      "loss": 2.3754,
      "step": 17960
    },
    {
      "epoch": 2.8752,
      "grad_norm": 0.5655662417411804,
      "learning_rate": 9.086379916162125e-07,
      "loss": 2.3529,
      "step": 17970
    },
    {
      "epoch": 2.8768000000000002,
      "grad_norm": 0.5057987570762634,
      "learning_rate": 8.855525637570861e-07,
      "loss": 2.3489,
      "step": 17980
    },
    {
      "epoch": 2.8784,
      "grad_norm": 0.5267655253410339,
      "learning_rate": 8.627628788938081e-07,
      "loss": 2.3407,
      "step": 17990
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5507989525794983,
      "learning_rate": 8.402690050274497e-07,
      "loss": 2.3784,
      "step": 18000
    },
    {
      "epoch": 2.88,
      "eval_bleu": 35.37896984248153,
      "eval_gen_len": 31.732,
      "eval_loss": 2.6028311252593994,
      "eval_runtime": 68.2169,
      "eval_samples_per_second": 14.659,
      "eval_steps_per_second": 0.924,
      "step": 18000
    },
    {
      "epoch": 2.8816,
      "grad_norm": 0.5802255868911743,
      "learning_rate": 8.180710092764554e-07,
      "loss": 2.3522,
      "step": 18010
    },
    {
      "epoch": 2.8832,
      "grad_norm": 0.5129509568214417,
      "learning_rate": 7.961689578763643e-07,
      "loss": 2.3672,
      "step": 18020
    },
    {
      "epoch": 2.8848000000000003,
      "grad_norm": 0.5496119856834412,
      "learning_rate": 7.745629161797219e-07,
      "loss": 2.352,
      "step": 18030
    },
    {
      "epoch": 2.8864,
      "grad_norm": 0.547216534614563,
      "learning_rate": 7.532529486557805e-07,
      "loss": 2.3451,
      "step": 18040
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.5742252469062805,
      "learning_rate": 7.322391188903543e-07,
      "loss": 2.387,
      "step": 18050
    },
    {
      "epoch": 2.888,
      "eval_bleu": 35.31703212031822,
      "eval_gen_len": 31.78,
      "eval_loss": 2.6027443408966064,
      "eval_runtime": 66.8277,
      "eval_samples_per_second": 14.964,
      "eval_steps_per_second": 0.943,
      "step": 18050
    },
    {
      "epoch": 2.8895999999999997,
      "grad_norm": 0.5514999628067017,
      "learning_rate": 7.115214895856426e-07,
      "loss": 2.3732,
      "step": 18060
    },
    {
      "epoch": 2.8912,
      "grad_norm": 0.4895942807197571,
      "learning_rate": 6.911001225600178e-07,
      "loss": 2.3352,
      "step": 18070
    },
    {
      "epoch": 2.8928000000000003,
      "grad_norm": 0.5683090090751648,
      "learning_rate": 6.709750787478486e-07,
      "loss": 2.337,
      "step": 18080
    },
    {
      "epoch": 2.8944,
      "grad_norm": 0.5606749057769775,
      "learning_rate": 6.51146418199311e-07,
      "loss": 2.3476,
      "step": 18090
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.5651887655258179,
      "learning_rate": 6.316142000802327e-07,
      "loss": 2.3889,
      "step": 18100
    },
    {
      "epoch": 2.896,
      "eval_bleu": 35.37069396136666,
      "eval_gen_len": 31.765,
      "eval_loss": 2.602811813354492,
      "eval_runtime": 67.384,
      "eval_samples_per_second": 14.84,
      "eval_steps_per_second": 0.935,
      "step": 18100
    },
    {
      "epoch": 2.8975999999999997,
      "grad_norm": 0.5371765494346619,
      "learning_rate": 6.123784826718826e-07,
      "loss": 2.3318,
      "step": 18110
    },
    {
      "epoch": 2.8992,
      "grad_norm": 0.5114750266075134,
      "learning_rate": 5.934393233708369e-07,
      "loss": 2.3273,
      "step": 18120
    },
    {
      "epoch": 2.9008000000000003,
      "grad_norm": 0.5241976380348206,
      "learning_rate": 5.747967786887576e-07,
      "loss": 2.3631,
      "step": 18130
    },
    {
      "epoch": 2.9024,
      "grad_norm": 0.5242293477058411,
      "learning_rate": 5.564509042522814e-07,
      "loss": 2.3723,
      "step": 18140
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.5675972700119019,
      "learning_rate": 5.384017548028086e-07,
      "loss": 2.3658,
      "step": 18150
    },
    {
      "epoch": 2.904,
      "eval_bleu": 35.31168379337602,
      "eval_gen_len": 31.76,
      "eval_loss": 2.60288143157959,
      "eval_runtime": 67.2571,
      "eval_samples_per_second": 14.868,
      "eval_steps_per_second": 0.937,
      "step": 18150
    },
    {
      "epoch": 2.9055999999999997,
      "grad_norm": 0.5350801348686218,
      "learning_rate": 5.206493841963589e-07,
      "loss": 2.3867,
      "step": 18160
    },
    {
      "epoch": 2.9072,
      "grad_norm": 0.5355334877967834,
      "learning_rate": 5.031938454033935e-07,
      "loss": 2.3533,
      "step": 18170
    },
    {
      "epoch": 2.9088000000000003,
      "grad_norm": 0.534912645816803,
      "learning_rate": 4.860351905086935e-07,
      "loss": 2.3516,
      "step": 18180
    },
    {
      "epoch": 2.9104,
      "grad_norm": 0.5340864658355713,
      "learning_rate": 4.6917347071118167e-07,
      "loss": 2.3524,
      "step": 18190
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.5945965051651001,
      "learning_rate": 4.5260873632374525e-07,
      "loss": 2.3636,
      "step": 18200
    },
    {
      "epoch": 2.912,
      "eval_bleu": 35.356255406472485,
      "eval_gen_len": 31.744,
      "eval_loss": 2.602853536605835,
      "eval_runtime": 67.3327,
      "eval_samples_per_second": 14.852,
      "eval_steps_per_second": 0.936,
      "step": 18200
    },
    {
      "epoch": 2.9135999999999997,
      "grad_norm": 0.5300131440162659,
      "learning_rate": 4.3634103677312466e-07,
      "loss": 2.3535,
      "step": 18210
    },
    {
      "epoch": 2.9152,
      "grad_norm": 0.5380419492721558,
      "learning_rate": 4.203704205997694e-07,
      "loss": 2.3626,
      "step": 18220
    },
    {
      "epoch": 2.9168,
      "grad_norm": 0.503213107585907,
      "learning_rate": 4.0469693545764906e-07,
      "loss": 2.3524,
      "step": 18230
    },
    {
      "epoch": 2.9184,
      "grad_norm": 0.5059991478919983,
      "learning_rate": 3.893206281141426e-07,
      "loss": 2.3343,
      "step": 18240
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.5333313345909119,
      "learning_rate": 3.7424154444990476e-07,
      "loss": 2.3487,
      "step": 18250
    },
    {
      "epoch": 2.92,
      "eval_bleu": 35.4096764864102,
      "eval_gen_len": 31.768,
      "eval_loss": 2.602773904800415,
      "eval_runtime": 68.6145,
      "eval_samples_per_second": 14.574,
      "eval_steps_per_second": 0.918,
      "step": 18250
    },
    {
      "epoch": 2.9215999999999998,
      "grad_norm": 0.5875424742698669,
      "learning_rate": 3.59459729458711e-07,
      "loss": 2.3667,
      "step": 18260
    },
    {
      "epoch": 2.9232,
      "grad_norm": 0.5409170389175415,
      "learning_rate": 3.449752272473461e-07,
      "loss": 2.3713,
      "step": 18270
    },
    {
      "epoch": 2.9248,
      "grad_norm": 0.5373361706733704,
      "learning_rate": 3.3078808103542693e-07,
      "loss": 2.3336,
      "step": 18280
    },
    {
      "epoch": 2.9264,
      "grad_norm": 0.5808079838752747,
      "learning_rate": 3.1689833315531326e-07,
      "loss": 2.3546,
      "step": 18290
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.550052285194397,
      "learning_rate": 3.0330602505199704e-07,
      "loss": 2.3632,
      "step": 18300
    },
    {
      "epoch": 2.928,
      "eval_bleu": 35.30499230331372,
      "eval_gen_len": 31.779,
      "eval_loss": 2.602801561355591,
      "eval_runtime": 68.6847,
      "eval_samples_per_second": 14.559,
      "eval_steps_per_second": 0.917,
      "step": 18300
    },
    {
      "epoch": 2.9295999999999998,
      "grad_norm": 0.5372792482376099,
      "learning_rate": 2.9001119728293557e-07,
      "loss": 2.3396,
      "step": 18310
    },
    {
      "epoch": 2.9312,
      "grad_norm": 0.550499439239502,
      "learning_rate": 2.7701388951794084e-07,
      "loss": 2.3701,
      "step": 18320
    },
    {
      "epoch": 2.9328,
      "grad_norm": 0.5658116936683655,
      "learning_rate": 2.643141405390681e-07,
      "loss": 2.3516,
      "step": 18330
    },
    {
      "epoch": 2.9344,
      "grad_norm": 0.5263766646385193,
      "learning_rate": 2.519119882405163e-07,
      "loss": 2.3587,
      "step": 18340
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.5423718690872192,
      "learning_rate": 2.3980746962849464e-07,
      "loss": 2.3686,
      "step": 18350
    },
    {
      "epoch": 2.936,
      "eval_bleu": 35.21559994578614,
      "eval_gen_len": 31.758,
      "eval_loss": 2.6027438640594482,
      "eval_runtime": 69.1517,
      "eval_samples_per_second": 14.461,
      "eval_steps_per_second": 0.911,
      "step": 18350
    },
    {
      "epoch": 2.9375999999999998,
      "grad_norm": 0.6011696457862854,
      "learning_rate": 2.2800062082111162e-07,
      "loss": 2.3718,
      "step": 18360
    },
    {
      "epoch": 2.9392,
      "grad_norm": 0.4935884177684784,
      "learning_rate": 2.16491477048264e-07,
      "loss": 2.3684,
      "step": 18370
    },
    {
      "epoch": 2.9408,
      "grad_norm": 0.5917419791221619,
      "learning_rate": 2.0528007265157024e-07,
      "loss": 2.3681,
      "step": 18380
    },
    {
      "epoch": 2.9424,
      "grad_norm": 0.5374414920806885,
      "learning_rate": 1.9436644108420388e-07,
      "loss": 2.3636,
      "step": 18390
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.5242874026298523,
      "learning_rate": 1.837506149108603e-07,
      "loss": 2.3589,
      "step": 18400
    },
    {
      "epoch": 2.944,
      "eval_bleu": 35.32950999527737,
      "eval_gen_len": 31.768,
      "eval_loss": 2.602825403213501,
      "eval_runtime": 69.1941,
      "eval_samples_per_second": 14.452,
      "eval_steps_per_second": 0.91,
      "step": 18400
    },
    {
      "epoch": 2.9455999999999998,
      "grad_norm": 0.5621705055236816,
      "learning_rate": 1.7343262580759023e-07,
      "loss": 2.355,
      "step": 18410
    },
    {
      "epoch": 2.9472,
      "grad_norm": 0.562490701675415,
      "learning_rate": 1.6341250456176626e-07,
      "loss": 2.3644,
      "step": 18420
    },
    {
      "epoch": 2.9488,
      "grad_norm": 0.5716776251792908,
      "learning_rate": 1.5369028107198314e-07,
      "loss": 2.3551,
      "step": 18430
    },
    {
      "epoch": 2.9504,
      "grad_norm": 0.6102888584136963,
      "learning_rate": 1.4426598434790218e-07,
      "loss": 2.3711,
      "step": 18440
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.562475323677063,
      "learning_rate": 1.3513964251026244e-07,
      "loss": 2.3442,
      "step": 18450
    },
    {
      "epoch": 2.952,
      "eval_bleu": 35.27479867210431,
      "eval_gen_len": 31.725,
      "eval_loss": 2.602756977081299,
      "eval_runtime": 68.085,
      "eval_samples_per_second": 14.688,
      "eval_steps_per_second": 0.925,
      "step": 18450
    },
    {
      "epoch": 2.9536,
      "grad_norm": 0.559577465057373,
      "learning_rate": 1.2631128279073645e-07,
      "loss": 2.3605,
      "step": 18460
    },
    {
      "epoch": 2.9552,
      "grad_norm": 0.5271635055541992,
      "learning_rate": 1.1778093153184122e-07,
      "loss": 2.3654,
      "step": 18470
    },
    {
      "epoch": 2.9568,
      "grad_norm": 0.5132507681846619,
      "learning_rate": 1.09548614186894e-07,
      "loss": 2.3529,
      "step": 18480
    },
    {
      "epoch": 2.9584,
      "grad_norm": 0.5638495087623596,
      "learning_rate": 1.0161435531994556e-07,
      "loss": 2.3705,
      "step": 18490
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.5387692451477051,
      "learning_rate": 9.397817860564707e-08,
      "loss": 2.3427,
      "step": 18500
    },
    {
      "epoch": 2.96,
      "eval_bleu": 35.356636577863,
      "eval_gen_len": 31.783,
      "eval_loss": 2.6027204990386963,
      "eval_runtime": 66.9889,
      "eval_samples_per_second": 14.928,
      "eval_steps_per_second": 0.94,
      "step": 18500
    },
    {
      "epoch": 2.9616,
      "grad_norm": 0.5574727058410645,
      "learning_rate": 8.664010682922775e-08,
      "loss": 2.3612,
      "step": 18510
    },
    {
      "epoch": 2.9632,
      "grad_norm": 0.49621862173080444,
      "learning_rate": 7.960016188642838e-08,
      "loss": 2.3665,
      "step": 18520
    },
    {
      "epoch": 2.9648,
      "grad_norm": 0.5645440816879272,
      "learning_rate": 7.285836478341246e-08,
      "loss": 2.3797,
      "step": 18530
    },
    {
      "epoch": 2.9664,
      "grad_norm": 0.5104511976242065,
      "learning_rate": 6.641473563671064e-08,
      "loss": 2.3407,
      "step": 18540
    },
    {
      "epoch": 2.968,
      "grad_norm": 0.5475716590881348,
      "learning_rate": 6.026929367316525e-08,
      "loss": 2.3536,
      "step": 18550
    },
    {
      "epoch": 2.968,
      "eval_bleu": 35.17099929159261,
      "eval_gen_len": 31.765,
      "eval_loss": 2.602865695953369,
      "eval_runtime": 66.8432,
      "eval_samples_per_second": 14.96,
      "eval_steps_per_second": 0.943,
      "step": 18550
    },
    {
      "epoch": 2.9696,
      "grad_norm": 0.5488204956054688,
      "learning_rate": 5.442205722988592e-08,
      "loss": 2.3582,
      "step": 18560
    },
    {
      "epoch": 2.9712,
      "grad_norm": 0.532248854637146,
      "learning_rate": 4.8873043754171786e-08,
      "loss": 2.346,
      "step": 18570
    },
    {
      "epoch": 2.9728,
      "grad_norm": 0.5254302024841309,
      "learning_rate": 4.3622269803456075e-08,
      "loss": 2.3704,
      "step": 18580
    },
    {
      "epoch": 2.9744,
      "grad_norm": 0.574393093585968,
      "learning_rate": 3.8669751045272705e-08,
      "loss": 2.3555,
      "step": 18590
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.5343925356864929,
      "learning_rate": 3.401550225723416e-08,
      "loss": 2.3626,
      "step": 18600
    },
    {
      "epoch": 2.976,
      "eval_bleu": 35.333292007050034,
      "eval_gen_len": 31.776,
      "eval_loss": 2.602722644805908,
      "eval_runtime": 66.5964,
      "eval_samples_per_second": 15.016,
      "eval_steps_per_second": 0.946,
      "step": 18600
    },
    {
      "epoch": 2.9776,
      "grad_norm": 0.5297040939331055,
      "learning_rate": 2.9659537326920393e-08,
      "loss": 2.3376,
      "step": 18610
    },
    {
      "epoch": 2.9792,
      "grad_norm": 0.4944075047969818,
      "learning_rate": 2.560186925190111e-08,
      "loss": 2.3447,
      "step": 18620
    },
    {
      "epoch": 2.9808,
      "grad_norm": 0.5828500986099243,
      "learning_rate": 2.184251013965799e-08,
      "loss": 2.3658,
      "step": 18630
    },
    {
      "epoch": 2.9824,
      "grad_norm": 0.5100476741790771,
      "learning_rate": 1.838147120757361e-08,
      "loss": 2.3666,
      "step": 18640
    },
    {
      "epoch": 2.984,
      "grad_norm": 0.509356677532196,
      "learning_rate": 1.5218762782875928e-08,
      "loss": 2.3757,
      "step": 18650
    },
    {
      "epoch": 2.984,
      "eval_bleu": 35.32430334341915,
      "eval_gen_len": 31.761,
      "eval_loss": 2.602747917175293,
      "eval_runtime": 68.0814,
      "eval_samples_per_second": 14.688,
      "eval_steps_per_second": 0.925,
      "step": 18650
    },
    {
      "epoch": 2.9856,
      "grad_norm": 0.5552392601966858,
      "learning_rate": 1.2354394302627193e-08,
      "loss": 2.3934,
      "step": 18660
    },
    {
      "epoch": 2.9872,
      "grad_norm": 0.5197590589523315,
      "learning_rate": 9.788374313679516e-09,
      "loss": 2.3447,
      "step": 18670
    },
    {
      "epoch": 2.9888,
      "grad_norm": 0.6094269156455994,
      "learning_rate": 7.520710472663784e-09,
      "loss": 2.3726,
      "step": 18680
    },
    {
      "epoch": 2.9904,
      "grad_norm": 0.5716117024421692,
      "learning_rate": 5.551409545967445e-09,
      "loss": 2.3678,
      "step": 18690
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.5318481922149658,
      "learning_rate": 3.880477409667904e-09,
      "loss": 2.3562,
      "step": 18700
    },
    {
      "epoch": 2.992,
      "eval_bleu": 35.39269745964671,
      "eval_gen_len": 31.753,
      "eval_loss": 2.602823257446289,
      "eval_runtime": 68.5003,
      "eval_samples_per_second": 14.598,
      "eval_steps_per_second": 0.92,
      "step": 18700
    },
    {
      "epoch": 2.9936,
      "grad_norm": 0.5282006859779358,
      "learning_rate": 2.50791904961023e-09,
      "loss": 2.3532,
      "step": 18710
    },
    {
      "epoch": 2.9952,
      "grad_norm": 0.5420368313789368,
      "learning_rate": 1.4337385612961385e-09,
      "loss": 2.3557,
      "step": 18720
    },
    {
      "epoch": 2.9968,
      "grad_norm": 0.5266605615615845,
      "learning_rate": 6.579391499172971e-10,
      "loss": 2.3746,
      "step": 18730
    },
    {
      "epoch": 2.9984,
      "grad_norm": 0.5393006205558777,
      "learning_rate": 1.8052313035532564e-10,
      "loss": 2.3328,
      "step": 18740
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.5560125112533569,
      "learning_rate": 1.4919271373869948e-12,
      "loss": 2.3441,
      "step": 18750
    },
    {
      "epoch": 3.0,
      "eval_bleu": 35.36691103468125,
      "eval_gen_len": 31.812,
      "eval_loss": 2.602811574935913,
      "eval_runtime": 67.6875,
      "eval_samples_per_second": 14.774,
      "eval_steps_per_second": 0.931,
      "step": 18750
    },
    {
      "epoch": 3.0,
      "step": 18750,
      "total_flos": 2.229961449728901e+17,
      "train_loss": 2.400928554789225,
      "train_runtime": 37757.0624,
      "train_samples_per_second": 31.782,
      "train_steps_per_second": 0.497
    }
  ],
  "logging_steps": 10,
  "max_steps": 18750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.229961449728901e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
